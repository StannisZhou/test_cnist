I0528 2019-01-16 11:31:04.551709 ops/training.py:229 Log written to /gpfs_home/dlinsley/cluttered_nist_experiments/logs/nist_3_ix2v2_50k_2019_01_16_11_30_14_313845
I0528 2019-01-16 11:35:02.519177 ops/training.py:396 Failed to save checkpoint: global name 'db' is not defined
I0528 2019-01-16 11:35:02.520069 ops/training.py:41 2019-01-16 11:35:02.520019: step 0, loss = 0.80 (0.1 examples/sec; 218.772 sec/batch) | Training accuracy = 0.53125 | Validation accuracy = 0.5078 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_11_30_14_313845
I0528 2019-01-16 11:35:03.291045 ops/training.py:65 2019-01-16 11:35:03.290970: step 1, loss = 0.80041 (41.6 examples/sec; 0.770 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:35:04.055943 ops/training.py:65 2019-01-16 11:35:04.055884: step 2, loss = 0.68548 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:35:04.822193 ops/training.py:65 2019-01-16 11:35:04.822137: step 3, loss = 0.83966 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:35:05.586603 ops/training.py:65 2019-01-16 11:35:05.586559: step 4, loss = 0.85310 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:35:06.353060 ops/training.py:65 2019-01-16 11:35:06.353023: step 5, loss = 0.79203 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:35:07.118933 ops/training.py:65 2019-01-16 11:35:07.118880: step 6, loss = 0.75941 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:35:07.885834 ops/training.py:65 2019-01-16 11:35:07.885778: step 7, loss = 0.75994 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:35:08.652450 ops/training.py:65 2019-01-16 11:35:08.652406: step 8, loss = 0.80622 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:35:09.420315 ops/training.py:65 2019-01-16 11:35:09.420282: step 9, loss = 0.70889 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:35:10.185754 ops/training.py:65 2019-01-16 11:35:10.185727: step 10, loss = 0.86890 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:35:10.952396 ops/training.py:65 2019-01-16 11:35:10.952334: step 11, loss = 0.79037 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:35:11.720784 ops/training.py:65 2019-01-16 11:35:11.720730: step 12, loss = 0.62715 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:35:12.486459 ops/training.py:65 2019-01-16 11:35:12.486385: step 13, loss = 0.82169 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:35:13.254378 ops/training.py:65 2019-01-16 11:35:13.254311: step 14, loss = 0.70325 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 11:35:14.018916 ops/training.py:65 2019-01-16 11:35:14.018848: step 15, loss = 0.72755 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:35:14.784402 ops/training.py:65 2019-01-16 11:35:14.784349: step 16, loss = 0.79541 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:35:15.551447 ops/training.py:65 2019-01-16 11:35:15.551391: step 17, loss = 0.79446 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:35:16.318675 ops/training.py:65 2019-01-16 11:35:16.318623: step 18, loss = 0.70406 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:35:17.086707 ops/training.py:65 2019-01-16 11:35:17.086669: step 19, loss = 0.73287 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:35:17.855448 ops/training.py:65 2019-01-16 11:35:17.855421: step 20, loss = 0.72719 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:35:18.624342 ops/training.py:65 2019-01-16 11:35:18.624289: step 21, loss = 0.82929 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:35:19.390375 ops/training.py:65 2019-01-16 11:35:19.390322: step 22, loss = 0.67996 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:35:20.156125 ops/training.py:65 2019-01-16 11:35:20.156072: step 23, loss = 0.69795 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:35:20.923435 ops/training.py:65 2019-01-16 11:35:20.923382: step 24, loss = 0.88398 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:35:21.689985 ops/training.py:65 2019-01-16 11:35:21.689950: step 25, loss = 0.87319 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:35:22.456038 ops/training.py:65 2019-01-16 11:35:22.455971: step 26, loss = 0.76084 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:35:23.224514 ops/training.py:65 2019-01-16 11:35:23.224464: step 27, loss = 0.67855 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:35:23.990159 ops/training.py:65 2019-01-16 11:35:23.990111: step 28, loss = 0.76189 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:35:24.753617 ops/training.py:65 2019-01-16 11:35:24.753571: step 29, loss = 0.78981 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:35:25.520914 ops/training.py:65 2019-01-16 11:35:25.520841: step 30, loss = 0.83489 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:35:26.286538 ops/training.py:65 2019-01-16 11:35:26.286466: step 31, loss = 0.73845 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:35:27.051087 ops/training.py:65 2019-01-16 11:35:27.051013: step 32, loss = 0.77896 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:35:27.819048 ops/training.py:65 2019-01-16 11:35:27.818973: step 33, loss = 0.78218 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:35:28.586381 ops/training.py:65 2019-01-16 11:35:28.586328: step 34, loss = 0.83784 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:35:29.353615 ops/training.py:65 2019-01-16 11:35:29.353542: step 35, loss = 0.92468 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:35:30.119939 ops/training.py:65 2019-01-16 11:35:30.119887: step 36, loss = 0.74690 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:35:30.887626 ops/training.py:65 2019-01-16 11:35:30.887572: step 37, loss = 0.77749 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:35:31.654780 ops/training.py:65 2019-01-16 11:35:31.654716: step 38, loss = 0.83590 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:35:32.421136 ops/training.py:65 2019-01-16 11:35:32.421085: step 39, loss = 0.90622 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:35:33.191527 ops/training.py:65 2019-01-16 11:35:33.191438: step 40, loss = 0.71878 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:35:33.960100 ops/training.py:65 2019-01-16 11:35:33.960029: step 41, loss = 0.62150 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:35:34.726985 ops/training.py:65 2019-01-16 11:35:34.726915: step 42, loss = 0.76374 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:35:35.494115 ops/training.py:65 2019-01-16 11:35:35.494045: step 43, loss = 0.81470 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:35:36.258374 ops/training.py:65 2019-01-16 11:35:36.258317: step 44, loss = 0.78944 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:35:37.021959 ops/training.py:65 2019-01-16 11:35:37.021907: step 45, loss = 0.85082 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:35:37.790417 ops/training.py:65 2019-01-16 11:35:37.790348: step 46, loss = 0.71865 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:35:38.558569 ops/training.py:65 2019-01-16 11:35:38.558507: step 47, loss = 0.86258 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:35:39.326057 ops/training.py:65 2019-01-16 11:35:39.326009: step 48, loss = 0.81354 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:35:40.093748 ops/training.py:65 2019-01-16 11:35:40.093719: step 49, loss = 0.80575 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:35:40.858940 ops/training.py:65 2019-01-16 11:35:40.858886: step 50, loss = 0.88371 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:35:41.627106 ops/training.py:65 2019-01-16 11:35:41.627055: step 51, loss = 0.62434 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 11:35:42.391690 ops/training.py:65 2019-01-16 11:35:42.391631: step 52, loss = 0.77254 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:35:43.158596 ops/training.py:65 2019-01-16 11:35:43.158546: step 53, loss = 0.73987 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:35:43.925661 ops/training.py:65 2019-01-16 11:35:43.925609: step 54, loss = 0.72458 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:35:44.690607 ops/training.py:65 2019-01-16 11:35:44.690550: step 55, loss = 0.75103 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:35:45.454841 ops/training.py:65 2019-01-16 11:35:45.454777: step 56, loss = 0.96320 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 11:35:46.219877 ops/training.py:65 2019-01-16 11:35:46.219813: step 57, loss = 0.87431 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:35:46.987075 ops/training.py:65 2019-01-16 11:35:46.987028: step 58, loss = 0.82527 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:35:47.752737 ops/training.py:65 2019-01-16 11:35:47.752710: step 59, loss = 0.70283 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:35:48.519475 ops/training.py:65 2019-01-16 11:35:48.519422: step 60, loss = 0.92537 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:35:49.287039 ops/training.py:65 2019-01-16 11:35:49.286986: step 61, loss = 0.98560 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:35:50.053332 ops/training.py:65 2019-01-16 11:35:50.053265: step 62, loss = 0.77691 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:35:50.817967 ops/training.py:65 2019-01-16 11:35:50.817907: step 63, loss = 0.76739 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:35:51.581602 ops/training.py:65 2019-01-16 11:35:51.581552: step 64, loss = 0.60210 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 11:35:52.345885 ops/training.py:65 2019-01-16 11:35:52.345821: step 65, loss = 0.93845 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:35:53.113386 ops/training.py:65 2019-01-16 11:35:53.113329: step 66, loss = 0.76380 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:35:53.882487 ops/training.py:65 2019-01-16 11:35:53.882430: step 67, loss = 0.76067 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:35:54.647844 ops/training.py:65 2019-01-16 11:35:54.647782: step 68, loss = 0.82281 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:35:55.414131 ops/training.py:65 2019-01-16 11:35:55.414089: step 69, loss = 0.92701 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:35:56.180957 ops/training.py:65 2019-01-16 11:35:56.180894: step 70, loss = 0.78814 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:35:56.947651 ops/training.py:65 2019-01-16 11:35:56.947607: step 71, loss = 0.78658 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:35:57.715448 ops/training.py:65 2019-01-16 11:35:57.715389: step 72, loss = 0.92764 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:35:58.482737 ops/training.py:65 2019-01-16 11:35:58.482694: step 73, loss = 0.78965 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:35:59.249720 ops/training.py:65 2019-01-16 11:35:59.249691: step 74, loss = 0.94368 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:36:00.016382 ops/training.py:65 2019-01-16 11:36:00.016320: step 75, loss = 0.75109 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:36:00.780589 ops/training.py:65 2019-01-16 11:36:00.780519: step 76, loss = 0.65551 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 11:36:01.544419 ops/training.py:65 2019-01-16 11:36:01.544360: step 77, loss = 0.93828 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:36:02.308959 ops/training.py:65 2019-01-16 11:36:02.308908: step 78, loss = 0.78999 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:36:03.074847 ops/training.py:65 2019-01-16 11:36:03.074813: step 79, loss = 0.75830 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:36:03.840964 ops/training.py:65 2019-01-16 11:36:03.840912: step 80, loss = 0.91688 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:36:04.607781 ops/training.py:65 2019-01-16 11:36:04.607730: step 81, loss = 0.84449 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:36:05.371634 ops/training.py:65 2019-01-16 11:36:05.371581: step 82, loss = 0.75855 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:36:06.134925 ops/training.py:65 2019-01-16 11:36:06.134881: step 83, loss = 1.01183 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.21875
I0528 2019-01-16 11:36:06.897946 ops/training.py:65 2019-01-16 11:36:06.897901: step 84, loss = 0.79413 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:36:07.663718 ops/training.py:65 2019-01-16 11:36:07.663662: step 85, loss = 0.66616 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:36:08.430762 ops/training.py:65 2019-01-16 11:36:08.430708: step 86, loss = 0.94335 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:36:09.197344 ops/training.py:65 2019-01-16 11:36:09.197288: step 87, loss = 0.97295 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:36:09.960893 ops/training.py:65 2019-01-16 11:36:09.960833: step 88, loss = 0.70714 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:36:10.724572 ops/training.py:65 2019-01-16 11:36:10.724518: step 89, loss = 0.74809 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:36:11.488892 ops/training.py:65 2019-01-16 11:36:11.488820: step 90, loss = 0.78996 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:36:12.255588 ops/training.py:65 2019-01-16 11:36:12.255535: step 91, loss = 0.87788 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:36:13.021647 ops/training.py:65 2019-01-16 11:36:13.021590: step 92, loss = 0.86115 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:36:13.787712 ops/training.py:65 2019-01-16 11:36:13.787658: step 93, loss = 0.76721 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:36:14.553447 ops/training.py:65 2019-01-16 11:36:14.553376: step 94, loss = 0.87724 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:36:15.319547 ops/training.py:65 2019-01-16 11:36:15.319475: step 95, loss = 1.00527 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:36:16.083711 ops/training.py:65 2019-01-16 11:36:16.083636: step 96, loss = 0.79512 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:36:16.849075 ops/training.py:65 2019-01-16 11:36:16.849016: step 97, loss = 0.79097 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:36:17.617988 ops/training.py:65 2019-01-16 11:36:17.617959: step 98, loss = 0.87931 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:36:18.384706 ops/training.py:65 2019-01-16 11:36:18.384652: step 99, loss = 0.74428 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:36:19.152091 ops/training.py:65 2019-01-16 11:36:19.152031: step 100, loss = 0.94311 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:36:19.917915 ops/training.py:65 2019-01-16 11:36:19.917852: step 101, loss = 0.83722 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:36:20.683938 ops/training.py:65 2019-01-16 11:36:20.683871: step 102, loss = 0.89342 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:36:21.450234 ops/training.py:65 2019-01-16 11:36:21.450178: step 103, loss = 0.94138 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:36:22.214391 ops/training.py:65 2019-01-16 11:36:22.214317: step 104, loss = 0.77509 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:36:22.980118 ops/training.py:65 2019-01-16 11:36:22.980044: step 105, loss = 0.78459 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:36:23.745815 ops/training.py:65 2019-01-16 11:36:23.745745: step 106, loss = 0.73936 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:36:24.511160 ops/training.py:65 2019-01-16 11:36:24.511087: step 107, loss = 0.81823 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:36:25.276532 ops/training.py:65 2019-01-16 11:36:25.276497: step 108, loss = 0.97950 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:36:26.044147 ops/training.py:65 2019-01-16 11:36:26.044091: step 109, loss = 0.65946 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:36:26.809494 ops/training.py:65 2019-01-16 11:36:26.809448: step 110, loss = 0.60230 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 11:36:27.575581 ops/training.py:65 2019-01-16 11:36:27.575530: step 111, loss = 0.66523 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:36:28.345920 ops/training.py:65 2019-01-16 11:36:28.345871: step 112, loss = 0.82430 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:36:29.112118 ops/training.py:65 2019-01-16 11:36:29.112086: step 113, loss = 0.83421 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:36:29.876664 ops/training.py:65 2019-01-16 11:36:29.876606: step 114, loss = 0.75431 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:36:30.642915 ops/training.py:65 2019-01-16 11:36:30.642858: step 115, loss = 0.71664 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:36:31.409510 ops/training.py:65 2019-01-16 11:36:31.409453: step 116, loss = 0.91917 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:36:32.176475 ops/training.py:65 2019-01-16 11:36:32.176419: step 117, loss = 0.64729 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:36:32.944025 ops/training.py:65 2019-01-16 11:36:32.943998: step 118, loss = 0.80136 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:36:33.711074 ops/training.py:65 2019-01-16 11:36:33.711016: step 119, loss = 0.70368 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:36:34.476407 ops/training.py:65 2019-01-16 11:36:34.476351: step 120, loss = 0.83942 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:36:35.243841 ops/training.py:65 2019-01-16 11:36:35.243785: step 121, loss = 0.78426 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:36:36.013532 ops/training.py:65 2019-01-16 11:36:36.013480: step 122, loss = 0.84827 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:36:36.780900 ops/training.py:65 2019-01-16 11:36:36.780851: step 123, loss = 0.91764 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:36:37.546379 ops/training.py:65 2019-01-16 11:36:37.546321: step 124, loss = 0.84953 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:36:38.310493 ops/training.py:65 2019-01-16 11:36:38.310438: step 125, loss = 0.69456 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:36:39.074076 ops/training.py:65 2019-01-16 11:36:39.074008: step 126, loss = 0.87125 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:36:39.837398 ops/training.py:65 2019-01-16 11:36:39.837351: step 127, loss = 0.66433 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:36:40.601156 ops/training.py:65 2019-01-16 11:36:40.601096: step 128, loss = 0.83584 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:36:41.364764 ops/training.py:65 2019-01-16 11:36:41.364701: step 129, loss = 0.74453 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:36:42.129250 ops/training.py:65 2019-01-16 11:36:42.129187: step 130, loss = 0.90028 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:36:42.893710 ops/training.py:65 2019-01-16 11:36:42.893650: step 131, loss = 0.74534 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:36:43.657893 ops/training.py:65 2019-01-16 11:36:43.657827: step 132, loss = 0.77158 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:36:44.424336 ops/training.py:65 2019-01-16 11:36:44.424303: step 133, loss = 0.75109 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:36:45.190972 ops/training.py:65 2019-01-16 11:36:45.190910: step 134, loss = 0.79518 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:36:45.956710 ops/training.py:65 2019-01-16 11:36:45.956643: step 135, loss = 0.80414 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:36:46.721707 ops/training.py:65 2019-01-16 11:36:46.721645: step 136, loss = 0.77282 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:36:47.489829 ops/training.py:65 2019-01-16 11:36:47.489779: step 137, loss = 0.69204 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:36:48.255680 ops/training.py:65 2019-01-16 11:36:48.255603: step 138, loss = 0.73956 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:36:49.020421 ops/training.py:65 2019-01-16 11:36:49.020352: step 139, loss = 0.75669 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:36:49.785236 ops/training.py:65 2019-01-16 11:36:49.785174: step 140, loss = 0.85370 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:36:50.549224 ops/training.py:65 2019-01-16 11:36:50.549160: step 141, loss = 0.80210 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:36:51.316929 ops/training.py:65 2019-01-16 11:36:51.316883: step 142, loss = 0.64929 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 11:36:52.083100 ops/training.py:65 2019-01-16 11:36:52.083044: step 143, loss = 0.69660 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:36:52.848510 ops/training.py:65 2019-01-16 11:36:52.848442: step 144, loss = 0.74160 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:36:53.613805 ops/training.py:65 2019-01-16 11:36:53.613736: step 145, loss = 0.75951 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:36:54.379188 ops/training.py:65 2019-01-16 11:36:54.379119: step 146, loss = 0.74236 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:36:55.143356 ops/training.py:65 2019-01-16 11:36:55.143311: step 147, loss = 0.74826 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:36:55.908874 ops/training.py:65 2019-01-16 11:36:55.908807: step 148, loss = 0.80993 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:36:56.674978 ops/training.py:65 2019-01-16 11:36:56.674904: step 149, loss = 0.81600 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:36:57.441342 ops/training.py:65 2019-01-16 11:36:57.441281: step 150, loss = 0.91877 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:36:58.207185 ops/training.py:65 2019-01-16 11:36:58.207133: step 151, loss = 0.74596 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:36:58.971591 ops/training.py:65 2019-01-16 11:36:58.971541: step 152, loss = 0.71295 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:36:59.738005 ops/training.py:65 2019-01-16 11:36:59.737941: step 153, loss = 0.73194 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:37:00.504033 ops/training.py:65 2019-01-16 11:37:00.503971: step 154, loss = 0.69990 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:37:01.270478 ops/training.py:65 2019-01-16 11:37:01.270415: step 155, loss = 0.77484 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:37:02.037372 ops/training.py:65 2019-01-16 11:37:02.037301: step 156, loss = 0.80454 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:37:02.803807 ops/training.py:65 2019-01-16 11:37:02.803742: step 157, loss = 0.71189 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:37:03.570971 ops/training.py:65 2019-01-16 11:37:03.570905: step 158, loss = 0.73801 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:37:04.336441 ops/training.py:65 2019-01-16 11:37:04.336372: step 159, loss = 0.72659 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:37:05.101581 ops/training.py:65 2019-01-16 11:37:05.101522: step 160, loss = 0.93132 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.25
I0528 2019-01-16 11:37:05.866415 ops/training.py:65 2019-01-16 11:37:05.866363: step 161, loss = 0.69437 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:37:06.630868 ops/training.py:65 2019-01-16 11:37:06.630817: step 162, loss = 0.72268 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:37:07.397297 ops/training.py:65 2019-01-16 11:37:07.397233: step 163, loss = 0.69384 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:37:08.161107 ops/training.py:65 2019-01-16 11:37:08.161037: step 164, loss = 0.76622 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:37:08.927451 ops/training.py:65 2019-01-16 11:37:08.927394: step 165, loss = 0.83687 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 11:37:09.692560 ops/training.py:65 2019-01-16 11:37:09.692507: step 166, loss = 0.70539 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:37:10.461495 ops/training.py:65 2019-01-16 11:37:10.461468: step 167, loss = 0.82288 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:37:11.226943 ops/training.py:65 2019-01-16 11:37:11.226893: step 168, loss = 0.81817 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:37:11.991687 ops/training.py:65 2019-01-16 11:37:11.991632: step 169, loss = 0.74984 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:37:12.756749 ops/training.py:65 2019-01-16 11:37:12.756691: step 170, loss = 0.71132 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:37:13.521668 ops/training.py:65 2019-01-16 11:37:13.521617: step 171, loss = 0.74944 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:37:14.290555 ops/training.py:65 2019-01-16 11:37:14.290527: step 172, loss = 0.75315 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:37:15.056079 ops/training.py:65 2019-01-16 11:37:15.056025: step 173, loss = 0.74238 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:37:15.821351 ops/training.py:65 2019-01-16 11:37:15.821285: step 174, loss = 0.77948 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:37:16.587036 ops/training.py:65 2019-01-16 11:37:16.586965: step 175, loss = 0.80579 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:37:17.352349 ops/training.py:65 2019-01-16 11:37:17.352304: step 176, loss = 0.70340 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:37:18.117371 ops/training.py:65 2019-01-16 11:37:18.117320: step 177, loss = 0.74560 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:37:18.882605 ops/training.py:65 2019-01-16 11:37:18.882539: step 178, loss = 0.79202 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:37:19.647881 ops/training.py:65 2019-01-16 11:37:19.647811: step 179, loss = 0.67380 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:37:20.413489 ops/training.py:65 2019-01-16 11:37:20.413428: step 180, loss = 0.80329 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:37:21.177761 ops/training.py:65 2019-01-16 11:37:21.177715: step 181, loss = 0.63939 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:37:21.943376 ops/training.py:65 2019-01-16 11:37:21.943340: step 182, loss = 0.76409 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:37:22.711697 ops/training.py:65 2019-01-16 11:37:22.711635: step 183, loss = 0.81526 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:37:23.476003 ops/training.py:65 2019-01-16 11:37:23.475937: step 184, loss = 0.77207 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:37:24.239020 ops/training.py:65 2019-01-16 11:37:24.238960: step 185, loss = 0.74282 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:37:25.001776 ops/training.py:65 2019-01-16 11:37:25.001732: step 186, loss = 0.76059 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:37:25.767285 ops/training.py:65 2019-01-16 11:37:25.767220: step 187, loss = 0.71462 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:37:26.532274 ops/training.py:65 2019-01-16 11:37:26.532209: step 188, loss = 0.69523 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:37:27.296440 ops/training.py:65 2019-01-16 11:37:27.296374: step 189, loss = 0.73961 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:37:28.063499 ops/training.py:65 2019-01-16 11:37:28.063435: step 190, loss = 0.79215 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:37:28.827864 ops/training.py:65 2019-01-16 11:37:28.827800: step 191, loss = 0.76114 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:37:29.592121 ops/training.py:65 2019-01-16 11:37:29.592051: step 192, loss = 0.65070 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:37:30.355615 ops/training.py:65 2019-01-16 11:37:30.355544: step 193, loss = 0.65318 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:37:31.118681 ops/training.py:65 2019-01-16 11:37:31.118611: step 194, loss = 0.71197 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:37:31.883963 ops/training.py:65 2019-01-16 11:37:31.883891: step 195, loss = 0.73213 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:37:32.649408 ops/training.py:65 2019-01-16 11:37:32.649340: step 196, loss = 0.79452 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:37:33.412854 ops/training.py:65 2019-01-16 11:37:33.412787: step 197, loss = 0.66847 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:37:34.177514 ops/training.py:65 2019-01-16 11:37:34.177447: step 198, loss = 0.81830 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:37:34.944409 ops/training.py:65 2019-01-16 11:37:34.944337: step 199, loss = 0.81777 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:37:35.710596 ops/training.py:65 2019-01-16 11:37:35.710532: step 200, loss = 0.73878 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:37:36.478575 ops/training.py:65 2019-01-16 11:37:36.478509: step 201, loss = 0.72835 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:37:37.244148 ops/training.py:65 2019-01-16 11:37:37.244094: step 202, loss = 0.74035 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:37:38.008954 ops/training.py:65 2019-01-16 11:37:38.008883: step 203, loss = 0.72483 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:37:38.772406 ops/training.py:65 2019-01-16 11:37:38.772341: step 204, loss = 0.74640 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:37:39.536157 ops/training.py:65 2019-01-16 11:37:39.536093: step 205, loss = 0.72898 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:37:40.299376 ops/training.py:65 2019-01-16 11:37:40.299332: step 206, loss = 0.66947 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:37:41.064119 ops/training.py:65 2019-01-16 11:37:41.064061: step 207, loss = 0.68405 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:37:41.828007 ops/training.py:65 2019-01-16 11:37:41.827927: step 208, loss = 0.75900 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:37:42.592034 ops/training.py:65 2019-01-16 11:37:42.591962: step 209, loss = 0.70785 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:37:43.357634 ops/training.py:65 2019-01-16 11:37:43.357578: step 210, loss = 0.76607 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:37:44.121216 ops/training.py:65 2019-01-16 11:37:44.121161: step 211, loss = 0.69105 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:37:44.884446 ops/training.py:65 2019-01-16 11:37:44.884379: step 212, loss = 0.79776 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:37:45.649394 ops/training.py:65 2019-01-16 11:37:45.649332: step 213, loss = 0.71371 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:37:46.413493 ops/training.py:65 2019-01-16 11:37:46.413423: step 214, loss = 0.70976 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:37:47.178089 ops/training.py:65 2019-01-16 11:37:47.178020: step 215, loss = 0.79164 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:37:47.944318 ops/training.py:65 2019-01-16 11:37:47.944260: step 216, loss = 0.78416 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:37:48.712494 ops/training.py:65 2019-01-16 11:37:48.712421: step 217, loss = 0.71031 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:37:49.477775 ops/training.py:65 2019-01-16 11:37:49.477722: step 218, loss = 0.74356 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:37:50.242466 ops/training.py:65 2019-01-16 11:37:50.242403: step 219, loss = 0.66761 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:37:51.006756 ops/training.py:65 2019-01-16 11:37:51.006699: step 220, loss = 0.70094 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:37:51.771399 ops/training.py:65 2019-01-16 11:37:51.771346: step 221, loss = 0.76750 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:37:52.535856 ops/training.py:65 2019-01-16 11:37:52.535787: step 222, loss = 0.69730 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:37:53.300223 ops/training.py:65 2019-01-16 11:37:53.300154: step 223, loss = 0.72744 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:37:54.063969 ops/training.py:65 2019-01-16 11:37:54.063899: step 224, loss = 0.66624 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:37:54.827648 ops/training.py:65 2019-01-16 11:37:54.827594: step 225, loss = 0.71774 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:37:55.591585 ops/training.py:65 2019-01-16 11:37:55.591531: step 226, loss = 0.62829 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 11:37:56.356614 ops/training.py:65 2019-01-16 11:37:56.356549: step 227, loss = 0.74953 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:37:57.120898 ops/training.py:65 2019-01-16 11:37:57.120847: step 228, loss = 0.69751 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:37:57.885324 ops/training.py:65 2019-01-16 11:37:57.885256: step 229, loss = 0.71238 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:37:58.651296 ops/training.py:65 2019-01-16 11:37:58.651232: step 230, loss = 0.69784 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:37:59.414971 ops/training.py:65 2019-01-16 11:37:59.414899: step 231, loss = 0.76623 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:38:00.181093 ops/training.py:65 2019-01-16 11:38:00.181024: step 232, loss = 0.80866 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:38:00.946781 ops/training.py:65 2019-01-16 11:38:00.946717: step 233, loss = 0.75890 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:38:01.715271 ops/training.py:65 2019-01-16 11:38:01.715218: step 234, loss = 0.69783 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:38:02.483483 ops/training.py:65 2019-01-16 11:38:02.483440: step 235, loss = 0.67595 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:38:03.248938 ops/training.py:65 2019-01-16 11:38:03.248884: step 236, loss = 0.72956 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:38:04.012869 ops/training.py:65 2019-01-16 11:38:04.012807: step 237, loss = 0.69582 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:38:04.778587 ops/training.py:65 2019-01-16 11:38:04.778526: step 238, loss = 0.72553 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:38:05.544416 ops/training.py:65 2019-01-16 11:38:05.544351: step 239, loss = 0.68725 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:38:06.312590 ops/training.py:65 2019-01-16 11:38:06.312518: step 240, loss = 0.70669 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:38:07.079797 ops/training.py:65 2019-01-16 11:38:07.079729: step 241, loss = 0.75960 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:38:07.846509 ops/training.py:65 2019-01-16 11:38:07.846437: step 242, loss = 0.70754 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:38:08.611778 ops/training.py:65 2019-01-16 11:38:08.611718: step 243, loss = 0.66801 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:38:09.376183 ops/training.py:65 2019-01-16 11:38:09.376125: step 244, loss = 0.69165 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:38:10.140664 ops/training.py:65 2019-01-16 11:38:10.140595: step 245, loss = 0.76071 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:38:10.905128 ops/training.py:65 2019-01-16 11:38:10.905065: step 246, loss = 0.76309 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:38:11.670026 ops/training.py:65 2019-01-16 11:38:11.669955: step 247, loss = 0.66082 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:38:12.436043 ops/training.py:65 2019-01-16 11:38:12.435978: step 248, loss = 0.66788 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:38:13.199572 ops/training.py:65 2019-01-16 11:38:13.199511: step 249, loss = 0.65677 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:38:13.964923 ops/training.py:65 2019-01-16 11:38:13.964868: step 250, loss = 0.69854 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:38:14.729500 ops/training.py:65 2019-01-16 11:38:14.729432: step 251, loss = 0.73271 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:38:15.493672 ops/training.py:65 2019-01-16 11:38:15.493607: step 252, loss = 0.67877 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:38:16.259686 ops/training.py:65 2019-01-16 11:38:16.259619: step 253, loss = 0.72855 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:38:17.024176 ops/training.py:65 2019-01-16 11:38:17.024115: step 254, loss = 0.72378 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:38:17.788392 ops/training.py:65 2019-01-16 11:38:17.788339: step 255, loss = 0.74139 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:38:18.552773 ops/training.py:65 2019-01-16 11:38:18.552703: step 256, loss = 0.72129 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:38:19.317221 ops/training.py:65 2019-01-16 11:38:19.317150: step 257, loss = 0.70373 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:38:20.081848 ops/training.py:65 2019-01-16 11:38:20.081780: step 258, loss = 0.74324 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:38:20.846603 ops/training.py:65 2019-01-16 11:38:20.846536: step 259, loss = 0.71652 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:38:21.610281 ops/training.py:65 2019-01-16 11:38:21.610226: step 260, loss = 0.73686 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:38:22.374605 ops/training.py:65 2019-01-16 11:38:22.374535: step 261, loss = 0.72388 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:38:23.138618 ops/training.py:65 2019-01-16 11:38:23.138552: step 262, loss = 0.75174 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:38:23.903305 ops/training.py:65 2019-01-16 11:38:23.903244: step 263, loss = 0.77254 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:38:24.667127 ops/training.py:65 2019-01-16 11:38:24.667066: step 264, loss = 0.80269 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:38:25.431222 ops/training.py:65 2019-01-16 11:38:25.431166: step 265, loss = 0.71867 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:38:26.194872 ops/training.py:65 2019-01-16 11:38:26.194803: step 266, loss = 0.70497 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:38:26.959175 ops/training.py:65 2019-01-16 11:38:26.959083: step 267, loss = 0.76131 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:38:27.723464 ops/training.py:65 2019-01-16 11:38:27.723413: step 268, loss = 0.75856 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:38:28.487860 ops/training.py:65 2019-01-16 11:38:28.487798: step 269, loss = 0.75932 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:38:29.252002 ops/training.py:65 2019-01-16 11:38:29.251945: step 270, loss = 0.78484 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:38:30.016672 ops/training.py:65 2019-01-16 11:38:30.016621: step 271, loss = 0.62441 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:38:30.782597 ops/training.py:65 2019-01-16 11:38:30.782546: step 272, loss = 0.67296 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:38:31.548288 ops/training.py:65 2019-01-16 11:38:31.548217: step 273, loss = 0.72428 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:38:32.312337 ops/training.py:65 2019-01-16 11:38:32.312285: step 274, loss = 0.76308 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:38:33.076887 ops/training.py:65 2019-01-16 11:38:33.076833: step 275, loss = 0.73747 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:38:33.840797 ops/training.py:65 2019-01-16 11:38:33.840724: step 276, loss = 0.76068 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:38:34.605426 ops/training.py:65 2019-01-16 11:38:34.605359: step 277, loss = 0.75585 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:38:35.369140 ops/training.py:65 2019-01-16 11:38:35.369075: step 278, loss = 0.65055 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:38:36.133391 ops/training.py:65 2019-01-16 11:38:36.133346: step 279, loss = 0.68030 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:38:36.896389 ops/training.py:65 2019-01-16 11:38:36.896338: step 280, loss = 0.72130 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:38:37.660899 ops/training.py:65 2019-01-16 11:38:37.660829: step 281, loss = 0.69354 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:38:38.427027 ops/training.py:65 2019-01-16 11:38:38.426961: step 282, loss = 0.75829 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:38:39.192441 ops/training.py:65 2019-01-16 11:38:39.192383: step 283, loss = 0.77466 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:38:39.958036 ops/training.py:65 2019-01-16 11:38:39.957980: step 284, loss = 0.77982 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:38:40.722940 ops/training.py:65 2019-01-16 11:38:40.722876: step 285, loss = 0.64765 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:38:41.488710 ops/training.py:65 2019-01-16 11:38:41.488646: step 286, loss = 0.61559 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:38:42.252965 ops/training.py:65 2019-01-16 11:38:42.252898: step 287, loss = 0.67497 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:38:43.018147 ops/training.py:65 2019-01-16 11:38:43.018075: step 288, loss = 0.68159 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:38:43.783751 ops/training.py:65 2019-01-16 11:38:43.783679: step 289, loss = 0.85503 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:38:44.548008 ops/training.py:65 2019-01-16 11:38:44.547943: step 290, loss = 0.67439 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:38:45.313522 ops/training.py:65 2019-01-16 11:38:45.313454: step 291, loss = 0.66914 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 11:38:46.077567 ops/training.py:65 2019-01-16 11:38:46.077502: step 292, loss = 0.63116 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:38:46.842138 ops/training.py:65 2019-01-16 11:38:46.842080: step 293, loss = 0.77802 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:38:47.608141 ops/training.py:65 2019-01-16 11:38:47.608084: step 294, loss = 0.64737 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:38:48.374448 ops/training.py:65 2019-01-16 11:38:48.374394: step 295, loss = 0.68844 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:38:49.140820 ops/training.py:65 2019-01-16 11:38:49.140751: step 296, loss = 0.71633 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:38:49.907312 ops/training.py:65 2019-01-16 11:38:49.907225: step 297, loss = 0.73413 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:38:50.674717 ops/training.py:65 2019-01-16 11:38:50.674661: step 298, loss = 0.69868 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:38:51.440760 ops/training.py:65 2019-01-16 11:38:51.440702: step 299, loss = 0.77894 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:38:52.204909 ops/training.py:65 2019-01-16 11:38:52.204840: step 300, loss = 0.80256 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:38:52.970188 ops/training.py:65 2019-01-16 11:38:52.970122: step 301, loss = 0.82975 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 11:38:53.736536 ops/training.py:65 2019-01-16 11:38:53.736464: step 302, loss = 0.81974 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:38:54.500839 ops/training.py:65 2019-01-16 11:38:54.500766: step 303, loss = 0.70636 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:38:55.265152 ops/training.py:65 2019-01-16 11:38:55.265089: step 304, loss = 0.77337 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:38:56.029507 ops/training.py:65 2019-01-16 11:38:56.029439: step 305, loss = 0.79373 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:38:56.793761 ops/training.py:65 2019-01-16 11:38:56.793699: step 306, loss = 0.68897 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:38:57.560364 ops/training.py:65 2019-01-16 11:38:57.560294: step 307, loss = 0.80848 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:38:58.324007 ops/training.py:65 2019-01-16 11:38:58.323949: step 308, loss = 0.70856 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:38:59.087308 ops/training.py:65 2019-01-16 11:38:59.087258: step 309, loss = 0.65865 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:38:59.852437 ops/training.py:65 2019-01-16 11:38:59.852372: step 310, loss = 0.84335 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:39:00.622988 ops/training.py:65 2019-01-16 11:39:00.622933: step 311, loss = 0.79201 (41.6 examples/sec; 0.770 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:39:01.388935 ops/training.py:65 2019-01-16 11:39:01.388863: step 312, loss = 0.75622 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:39:02.155813 ops/training.py:65 2019-01-16 11:39:02.155753: step 313, loss = 0.72652 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:39:02.922782 ops/training.py:65 2019-01-16 11:39:02.922749: step 314, loss = 0.67431 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:39:03.688276 ops/training.py:65 2019-01-16 11:39:03.688210: step 315, loss = 0.91037 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 11:39:04.454106 ops/training.py:65 2019-01-16 11:39:04.454040: step 316, loss = 0.91106 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 11:39:05.219189 ops/training.py:65 2019-01-16 11:39:05.219128: step 317, loss = 0.81406 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:39:05.983538 ops/training.py:65 2019-01-16 11:39:05.983477: step 318, loss = 0.82146 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:39:06.747430 ops/training.py:65 2019-01-16 11:39:06.747375: step 319, loss = 0.64472 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 11:39:07.513080 ops/training.py:65 2019-01-16 11:39:07.513019: step 320, loss = 0.69936 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:39:08.279137 ops/training.py:65 2019-01-16 11:39:08.279069: step 321, loss = 0.65844 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:39:09.043590 ops/training.py:65 2019-01-16 11:39:09.043525: step 322, loss = 0.71030 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:39:09.808415 ops/training.py:65 2019-01-16 11:39:09.808344: step 323, loss = 0.72583 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:39:10.574345 ops/training.py:65 2019-01-16 11:39:10.574280: step 324, loss = 0.70893 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:39:11.341221 ops/training.py:65 2019-01-16 11:39:11.341147: step 325, loss = 0.74239 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:39:12.106276 ops/training.py:65 2019-01-16 11:39:12.106207: step 326, loss = 0.81719 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:39:12.870407 ops/training.py:65 2019-01-16 11:39:12.870339: step 327, loss = 0.78768 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:39:13.633873 ops/training.py:65 2019-01-16 11:39:13.633812: step 328, loss = 0.81427 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:39:14.396506 ops/training.py:65 2019-01-16 11:39:14.396460: step 329, loss = 0.70142 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:39:15.160279 ops/training.py:65 2019-01-16 11:39:15.160213: step 330, loss = 0.80755 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:39:15.923490 ops/training.py:65 2019-01-16 11:39:15.923422: step 331, loss = 0.64103 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:39:16.689127 ops/training.py:65 2019-01-16 11:39:16.689062: step 332, loss = 0.88406 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:39:17.455089 ops/training.py:65 2019-01-16 11:39:17.455022: step 333, loss = 0.72127 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:39:18.223451 ops/training.py:65 2019-01-16 11:39:18.223396: step 334, loss = 0.66386 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:39:18.989563 ops/training.py:65 2019-01-16 11:39:18.989506: step 335, loss = 0.77328 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:39:19.756331 ops/training.py:65 2019-01-16 11:39:19.756267: step 336, loss = 0.66193 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:39:20.522294 ops/training.py:65 2019-01-16 11:39:20.522239: step 337, loss = 0.74498 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:39:21.287638 ops/training.py:65 2019-01-16 11:39:21.287590: step 338, loss = 0.78934 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:39:22.051248 ops/training.py:65 2019-01-16 11:39:22.051184: step 339, loss = 0.84068 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:39:22.817570 ops/training.py:65 2019-01-16 11:39:22.817506: step 340, loss = 0.94200 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:39:23.586474 ops/training.py:65 2019-01-16 11:39:23.586412: step 341, loss = 0.78434 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:39:24.353826 ops/training.py:65 2019-01-16 11:39:24.353768: step 342, loss = 0.75769 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:39:25.119454 ops/training.py:65 2019-01-16 11:39:25.119408: step 343, loss = 0.81228 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:39:25.883793 ops/training.py:65 2019-01-16 11:39:25.883731: step 344, loss = 0.95099 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:39:26.649246 ops/training.py:65 2019-01-16 11:39:26.649181: step 345, loss = 0.81230 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:39:27.414213 ops/training.py:65 2019-01-16 11:39:27.414147: step 346, loss = 0.79277 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:39:28.178592 ops/training.py:65 2019-01-16 11:39:28.178534: step 347, loss = 0.69986 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:39:28.941814 ops/training.py:65 2019-01-16 11:39:28.941763: step 348, loss = 0.84954 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:39:29.705831 ops/training.py:65 2019-01-16 11:39:29.705769: step 349, loss = 0.71855 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:39:30.471106 ops/training.py:65 2019-01-16 11:39:30.471045: step 350, loss = 0.69133 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:39:31.236587 ops/training.py:65 2019-01-16 11:39:31.236528: step 351, loss = 0.92917 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 11:39:32.001349 ops/training.py:65 2019-01-16 11:39:32.001300: step 352, loss = 0.57219 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.75
I0528 2019-01-16 11:39:32.767161 ops/training.py:65 2019-01-16 11:39:32.767118: step 353, loss = 0.81204 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:39:33.536257 ops/training.py:65 2019-01-16 11:39:33.536207: step 354, loss = 0.76147 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:39:34.304141 ops/training.py:65 2019-01-16 11:39:34.304076: step 355, loss = 0.80058 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:39:35.070719 ops/training.py:65 2019-01-16 11:39:35.070661: step 356, loss = 0.82389 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:39:35.836701 ops/training.py:65 2019-01-16 11:39:35.836658: step 357, loss = 0.77645 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:39:36.602769 ops/training.py:65 2019-01-16 11:39:36.602715: step 358, loss = 0.81031 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:39:37.368060 ops/training.py:65 2019-01-16 11:39:37.368002: step 359, loss = 0.80403 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:39:38.133909 ops/training.py:65 2019-01-16 11:39:38.133846: step 360, loss = 0.71777 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:39:38.900405 ops/training.py:65 2019-01-16 11:39:38.900343: step 361, loss = 0.74819 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:39:39.664317 ops/training.py:65 2019-01-16 11:39:39.664273: step 362, loss = 0.73021 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:39:40.429446 ops/training.py:65 2019-01-16 11:39:40.429403: step 363, loss = 0.79228 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:39:41.195799 ops/training.py:65 2019-01-16 11:39:41.195739: step 364, loss = 0.72862 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:39:41.961785 ops/training.py:65 2019-01-16 11:39:41.961715: step 365, loss = 0.71727 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:39:42.728646 ops/training.py:65 2019-01-16 11:39:42.728577: step 366, loss = 0.73410 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:39:43.499147 ops/training.py:65 2019-01-16 11:39:43.499073: step 367, loss = 0.86582 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:39:44.264448 ops/training.py:65 2019-01-16 11:39:44.264382: step 368, loss = 0.73957 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:39:45.028506 ops/training.py:65 2019-01-16 11:39:45.028436: step 369, loss = 0.72900 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:39:45.792294 ops/training.py:65 2019-01-16 11:39:45.792222: step 370, loss = 0.81167 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:39:46.557957 ops/training.py:65 2019-01-16 11:39:46.557887: step 371, loss = 0.82340 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:39:47.323543 ops/training.py:65 2019-01-16 11:39:47.323480: step 372, loss = 0.89398 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:39:48.088703 ops/training.py:65 2019-01-16 11:39:48.088659: step 373, loss = 0.82936 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:39:48.853007 ops/training.py:65 2019-01-16 11:39:48.852941: step 374, loss = 0.87376 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:39:49.616946 ops/training.py:65 2019-01-16 11:39:49.616876: step 375, loss = 0.74008 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:39:50.381858 ops/training.py:65 2019-01-16 11:39:50.381767: step 376, loss = 0.69849 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:39:51.146579 ops/training.py:65 2019-01-16 11:39:51.146512: step 377, loss = 0.81515 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:39:51.913112 ops/training.py:65 2019-01-16 11:39:51.913058: step 378, loss = 0.89491 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:39:52.678943 ops/training.py:65 2019-01-16 11:39:52.678873: step 379, loss = 0.83366 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:39:53.445278 ops/training.py:65 2019-01-16 11:39:53.445210: step 380, loss = 0.87781 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:39:54.209152 ops/training.py:65 2019-01-16 11:39:54.209092: step 381, loss = 0.74133 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:39:54.973914 ops/training.py:65 2019-01-16 11:39:54.973853: step 382, loss = 0.88347 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:39:55.739146 ops/training.py:65 2019-01-16 11:39:55.739074: step 383, loss = 0.75693 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:39:56.504374 ops/training.py:65 2019-01-16 11:39:56.504304: step 384, loss = 0.70515 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:39:57.269449 ops/training.py:65 2019-01-16 11:39:57.269376: step 385, loss = 0.62926 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:39:58.035204 ops/training.py:65 2019-01-16 11:39:58.035142: step 386, loss = 0.75976 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:39:58.801349 ops/training.py:65 2019-01-16 11:39:58.801297: step 387, loss = 0.77377 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:39:59.567384 ops/training.py:65 2019-01-16 11:39:59.567319: step 388, loss = 0.80825 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:40:00.333526 ops/training.py:65 2019-01-16 11:40:00.333456: step 389, loss = 0.70728 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:40:01.098045 ops/training.py:65 2019-01-16 11:40:01.097980: step 390, loss = 0.66022 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:40:01.862243 ops/training.py:65 2019-01-16 11:40:01.862186: step 391, loss = 0.63926 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:40:02.629539 ops/training.py:65 2019-01-16 11:40:02.629478: step 392, loss = 0.61898 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 11:40:03.395311 ops/training.py:65 2019-01-16 11:40:03.395256: step 393, loss = 0.82326 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:40:04.162425 ops/training.py:65 2019-01-16 11:40:04.162356: step 394, loss = 0.70407 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:40:04.927132 ops/training.py:65 2019-01-16 11:40:04.927053: step 395, loss = 0.76797 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:40:05.692131 ops/training.py:65 2019-01-16 11:40:05.692052: step 396, loss = 0.79077 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:40:06.458833 ops/training.py:65 2019-01-16 11:40:06.458752: step 397, loss = 0.76845 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:40:07.227570 ops/training.py:65 2019-01-16 11:40:07.227511: step 398, loss = 0.91991 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:40:07.992280 ops/training.py:65 2019-01-16 11:40:07.992201: step 399, loss = 0.67569 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:40:08.756654 ops/training.py:65 2019-01-16 11:40:08.756576: step 400, loss = 0.66911 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:40:09.520696 ops/training.py:65 2019-01-16 11:40:09.520628: step 401, loss = 0.87441 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:40:10.284792 ops/training.py:65 2019-01-16 11:40:10.284735: step 402, loss = 0.73921 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:40:11.050202 ops/training.py:65 2019-01-16 11:40:11.050127: step 403, loss = 0.75100 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:40:11.814070 ops/training.py:65 2019-01-16 11:40:11.813999: step 404, loss = 0.71201 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:40:12.578259 ops/training.py:65 2019-01-16 11:40:12.578193: step 405, loss = 0.78036 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:40:13.344333 ops/training.py:65 2019-01-16 11:40:13.344290: step 406, loss = 0.82285 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:40:14.113060 ops/training.py:65 2019-01-16 11:40:14.112980: step 407, loss = 0.69841 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:40:14.880325 ops/training.py:65 2019-01-16 11:40:14.880247: step 408, loss = 0.81231 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:40:15.646690 ops/training.py:65 2019-01-16 11:40:15.646617: step 409, loss = 0.78739 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:40:16.410782 ops/training.py:65 2019-01-16 11:40:16.410709: step 410, loss = 0.77956 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:40:17.176637 ops/training.py:65 2019-01-16 11:40:17.176566: step 411, loss = 0.72166 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:40:17.941647 ops/training.py:65 2019-01-16 11:40:17.941599: step 412, loss = 0.65068 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:40:18.709471 ops/training.py:65 2019-01-16 11:40:18.709394: step 413, loss = 0.72172 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:40:19.477909 ops/training.py:65 2019-01-16 11:40:19.477807: step 414, loss = 0.72240 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:40:20.243310 ops/training.py:65 2019-01-16 11:40:20.243240: step 415, loss = 0.76333 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:40:21.009573 ops/training.py:65 2019-01-16 11:40:21.009468: step 416, loss = 0.68296 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:40:21.777148 ops/training.py:65 2019-01-16 11:40:21.777093: step 417, loss = 0.72310 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:40:22.540592 ops/training.py:65 2019-01-16 11:40:22.540518: step 418, loss = 0.69701 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:40:23.308740 ops/training.py:65 2019-01-16 11:40:23.308673: step 419, loss = 0.74552 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:40:24.075155 ops/training.py:65 2019-01-16 11:40:24.075092: step 420, loss = 0.75970 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:40:24.840936 ops/training.py:65 2019-01-16 11:40:24.840878: step 421, loss = 0.78020 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:40:25.605979 ops/training.py:65 2019-01-16 11:40:25.605925: step 422, loss = 0.71390 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:40:26.370310 ops/training.py:65 2019-01-16 11:40:26.370237: step 423, loss = 0.85569 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:40:27.136191 ops/training.py:65 2019-01-16 11:40:27.136119: step 424, loss = 0.64191 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:40:27.903541 ops/training.py:65 2019-01-16 11:40:27.903463: step 425, loss = 0.77208 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:40:28.669290 ops/training.py:65 2019-01-16 11:40:28.669232: step 426, loss = 0.80525 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:40:29.436464 ops/training.py:65 2019-01-16 11:40:29.436416: step 427, loss = 0.72316 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:40:30.203503 ops/training.py:65 2019-01-16 11:40:30.203431: step 428, loss = 0.75026 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:40:30.969997 ops/training.py:65 2019-01-16 11:40:30.969915: step 429, loss = 0.75913 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:40:31.737601 ops/training.py:65 2019-01-16 11:40:31.737537: step 430, loss = 0.69671 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:40:32.501880 ops/training.py:65 2019-01-16 11:40:32.501837: step 431, loss = 0.63228 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:40:33.268052 ops/training.py:65 2019-01-16 11:40:33.268006: step 432, loss = 0.78929 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:40:34.037209 ops/training.py:65 2019-01-16 11:40:34.037134: step 433, loss = 0.70332 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:40:34.804820 ops/training.py:65 2019-01-16 11:40:34.804745: step 434, loss = 0.77085 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:40:35.572156 ops/training.py:65 2019-01-16 11:40:35.572087: step 435, loss = 0.67595 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:40:36.337437 ops/training.py:65 2019-01-16 11:40:36.337382: step 436, loss = 0.77738 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:40:37.101238 ops/training.py:65 2019-01-16 11:40:37.101186: step 437, loss = 0.84102 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:40:37.866442 ops/training.py:65 2019-01-16 11:40:37.866366: step 438, loss = 0.78389 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:40:38.632688 ops/training.py:65 2019-01-16 11:40:38.632626: step 439, loss = 0.81653 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:40:39.398111 ops/training.py:65 2019-01-16 11:40:39.398038: step 440, loss = 0.80834 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:40:40.162881 ops/training.py:65 2019-01-16 11:40:40.162827: step 441, loss = 0.89522 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 11:40:40.926390 ops/training.py:65 2019-01-16 11:40:40.926320: step 442, loss = 0.68533 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:40:41.693758 ops/training.py:65 2019-01-16 11:40:41.693671: step 443, loss = 0.71474 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:40:42.461586 ops/training.py:65 2019-01-16 11:40:42.461514: step 444, loss = 0.81218 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:40:43.228579 ops/training.py:65 2019-01-16 11:40:43.228509: step 445, loss = 0.82627 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:40:43.993753 ops/training.py:65 2019-01-16 11:40:43.993677: step 446, loss = 0.78037 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:40:44.759900 ops/training.py:65 2019-01-16 11:40:44.759830: step 447, loss = 0.79882 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:40:45.525120 ops/training.py:65 2019-01-16 11:40:45.525051: step 448, loss = 0.87126 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 11:40:46.291229 ops/training.py:65 2019-01-16 11:40:46.291155: step 449, loss = 0.75888 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:40:47.054909 ops/training.py:65 2019-01-16 11:40:47.054845: step 450, loss = 0.82858 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:40:47.819991 ops/training.py:65 2019-01-16 11:40:47.819930: step 451, loss = 0.67590 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:40:48.585151 ops/training.py:65 2019-01-16 11:40:48.585097: step 452, loss = 0.80042 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:40:49.350172 ops/training.py:65 2019-01-16 11:40:49.350105: step 453, loss = 0.72324 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:40:50.114865 ops/training.py:65 2019-01-16 11:40:50.114792: step 454, loss = 0.78797 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:40:50.879710 ops/training.py:65 2019-01-16 11:40:50.879637: step 455, loss = 0.71949 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:40:51.643920 ops/training.py:65 2019-01-16 11:40:51.643861: step 456, loss = 0.68814 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:40:52.409029 ops/training.py:65 2019-01-16 11:40:52.408951: step 457, loss = 0.66530 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 11:40:53.172899 ops/training.py:65 2019-01-16 11:40:53.172830: step 458, loss = 0.67155 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:40:53.936794 ops/training.py:65 2019-01-16 11:40:53.936722: step 459, loss = 0.64166 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:40:54.702488 ops/training.py:65 2019-01-16 11:40:54.702415: step 460, loss = 0.68481 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:40:55.467929 ops/training.py:65 2019-01-16 11:40:55.467873: step 461, loss = 0.81197 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:40:56.232880 ops/training.py:65 2019-01-16 11:40:56.232811: step 462, loss = 0.72560 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:40:56.997174 ops/training.py:65 2019-01-16 11:40:56.997104: step 463, loss = 0.69669 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:40:57.761462 ops/training.py:65 2019-01-16 11:40:57.761392: step 464, loss = 0.75994 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:40:58.526010 ops/training.py:65 2019-01-16 11:40:58.525951: step 465, loss = 0.87430 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 11:40:59.292443 ops/training.py:65 2019-01-16 11:40:59.292389: step 466, loss = 0.78851 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:41:00.060950 ops/training.py:65 2019-01-16 11:41:00.060871: step 467, loss = 0.80531 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:41:00.827890 ops/training.py:65 2019-01-16 11:41:00.827815: step 468, loss = 0.79482 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:41:01.594041 ops/training.py:65 2019-01-16 11:41:01.593980: step 469, loss = 0.79002 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:41:02.359987 ops/training.py:65 2019-01-16 11:41:02.359931: step 470, loss = 0.73156 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:41:03.125134 ops/training.py:65 2019-01-16 11:41:03.125081: step 471, loss = 0.72594 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:41:03.890256 ops/training.py:65 2019-01-16 11:41:03.890187: step 472, loss = 0.66571 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:41:04.655380 ops/training.py:65 2019-01-16 11:41:04.655311: step 473, loss = 0.73208 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:41:05.422031 ops/training.py:65 2019-01-16 11:41:05.421962: step 474, loss = 0.70006 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:41:06.188036 ops/training.py:65 2019-01-16 11:41:06.187973: step 475, loss = 0.78524 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:41:06.956742 ops/training.py:65 2019-01-16 11:41:06.956688: step 476, loss = 0.75691 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:41:07.723963 ops/training.py:65 2019-01-16 11:41:07.723887: step 477, loss = 0.78963 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:41:08.494611 ops/training.py:65 2019-01-16 11:41:08.494538: step 478, loss = 0.76768 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:41:09.260758 ops/training.py:65 2019-01-16 11:41:09.260674: step 479, loss = 0.70053 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:41:10.026140 ops/training.py:65 2019-01-16 11:41:10.026092: step 480, loss = 0.70075 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:41:10.790190 ops/training.py:65 2019-01-16 11:41:10.790137: step 481, loss = 0.74775 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:41:11.556308 ops/training.py:65 2019-01-16 11:41:11.556235: step 482, loss = 0.72079 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:41:12.323137 ops/training.py:65 2019-01-16 11:41:12.323067: step 483, loss = 0.71415 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:41:13.089449 ops/training.py:65 2019-01-16 11:41:13.089377: step 484, loss = 0.69989 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:41:13.856497 ops/training.py:65 2019-01-16 11:41:13.856439: step 485, loss = 0.72763 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:41:14.623457 ops/training.py:65 2019-01-16 11:41:14.623382: step 486, loss = 0.80679 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:41:15.388682 ops/training.py:65 2019-01-16 11:41:15.388617: step 487, loss = 0.70967 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:41:16.154065 ops/training.py:65 2019-01-16 11:41:16.153998: step 488, loss = 0.79821 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:41:16.917946 ops/training.py:65 2019-01-16 11:41:16.917873: step 489, loss = 0.72524 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:41:17.681792 ops/training.py:65 2019-01-16 11:41:17.681740: step 490, loss = 0.83151 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:41:18.446950 ops/training.py:65 2019-01-16 11:41:18.446883: step 491, loss = 0.74417 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:41:19.213544 ops/training.py:65 2019-01-16 11:41:19.213478: step 492, loss = 0.69725 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:41:19.981961 ops/training.py:65 2019-01-16 11:41:19.981882: step 493, loss = 0.84102 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:41:20.750379 ops/training.py:65 2019-01-16 11:41:20.750323: step 494, loss = 0.68272 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:41:21.515932 ops/training.py:65 2019-01-16 11:41:21.515881: step 495, loss = 0.70800 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:41:22.279940 ops/training.py:65 2019-01-16 11:41:22.279871: step 496, loss = 0.80114 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:41:23.043544 ops/training.py:65 2019-01-16 11:41:23.043476: step 497, loss = 0.71811 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:41:23.808465 ops/training.py:65 2019-01-16 11:41:23.808389: step 498, loss = 0.78757 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:41:24.573200 ops/training.py:65 2019-01-16 11:41:24.573135: step 499, loss = 0.66140 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:41:25.336505 ops/training.py:65 2019-01-16 11:41:25.336454: step 500, loss = 0.78425 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:41:26.103223 ops/training.py:65 2019-01-16 11:41:26.103156: step 501, loss = 0.77038 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:41:26.870225 ops/training.py:65 2019-01-16 11:41:26.870145: step 502, loss = 0.69841 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:41:27.638339 ops/training.py:65 2019-01-16 11:41:27.638269: step 503, loss = 0.68633 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:41:28.404771 ops/training.py:65 2019-01-16 11:41:28.404705: step 504, loss = 0.71102 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:41:29.172532 ops/training.py:65 2019-01-16 11:41:29.172460: step 505, loss = 0.76929 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:41:29.939555 ops/training.py:65 2019-01-16 11:41:29.939482: step 506, loss = 0.73561 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:41:30.706866 ops/training.py:65 2019-01-16 11:41:30.706791: step 507, loss = 0.71894 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:41:31.471382 ops/training.py:65 2019-01-16 11:41:31.471309: step 508, loss = 0.83796 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:41:32.237190 ops/training.py:65 2019-01-16 11:41:32.237129: step 509, loss = 0.74280 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:41:33.005766 ops/training.py:65 2019-01-16 11:41:33.005691: step 510, loss = 0.84485 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:41:33.773223 ops/training.py:65 2019-01-16 11:41:33.773149: step 511, loss = 0.66901 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:41:34.539073 ops/training.py:65 2019-01-16 11:41:34.539003: step 512, loss = 0.72337 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:41:35.305730 ops/training.py:65 2019-01-16 11:41:35.305655: step 513, loss = 0.82858 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:41:36.071633 ops/training.py:65 2019-01-16 11:41:36.071558: step 514, loss = 0.63392 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.75
I0528 2019-01-16 11:41:36.838619 ops/training.py:65 2019-01-16 11:41:36.838543: step 515, loss = 0.65561 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:41:37.604109 ops/training.py:65 2019-01-16 11:41:37.604037: step 516, loss = 0.80888 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:41:38.369223 ops/training.py:65 2019-01-16 11:41:38.369146: step 517, loss = 0.75402 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:41:39.134657 ops/training.py:65 2019-01-16 11:41:39.134586: step 518, loss = 0.73554 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:41:39.899640 ops/training.py:65 2019-01-16 11:41:39.899578: step 519, loss = 0.70388 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:41:40.666279 ops/training.py:65 2019-01-16 11:41:40.666221: step 520, loss = 0.76851 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:41:41.432902 ops/training.py:65 2019-01-16 11:41:41.432832: step 521, loss = 0.80398 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:41:42.199543 ops/training.py:65 2019-01-16 11:41:42.199489: step 522, loss = 0.82419 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:41:42.966231 ops/training.py:65 2019-01-16 11:41:42.966154: step 523, loss = 0.67200 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:41:43.733167 ops/training.py:65 2019-01-16 11:41:43.733103: step 524, loss = 0.70299 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:41:44.499490 ops/training.py:65 2019-01-16 11:41:44.499418: step 525, loss = 0.82233 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:41:45.266144 ops/training.py:65 2019-01-16 11:41:45.266075: step 526, loss = 0.60729 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:41:46.034537 ops/training.py:65 2019-01-16 11:41:46.034461: step 527, loss = 0.86087 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:41:46.801228 ops/training.py:65 2019-01-16 11:41:46.801159: step 528, loss = 0.83397 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:41:47.567581 ops/training.py:65 2019-01-16 11:41:47.567519: step 529, loss = 0.76776 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:41:48.332604 ops/training.py:65 2019-01-16 11:41:48.332548: step 530, loss = 0.68905 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:41:49.096292 ops/training.py:65 2019-01-16 11:41:49.096220: step 531, loss = 0.77508 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:41:49.859351 ops/training.py:65 2019-01-16 11:41:49.859291: step 532, loss = 0.74953 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:41:50.624196 ops/training.py:65 2019-01-16 11:41:50.624101: step 533, loss = 0.75524 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:41:51.388058 ops/training.py:65 2019-01-16 11:41:51.388013: step 534, loss = 0.79792 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:41:52.152099 ops/training.py:65 2019-01-16 11:41:52.152045: step 535, loss = 0.84718 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:41:52.916497 ops/training.py:65 2019-01-16 11:41:52.916427: step 536, loss = 0.84628 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:41:53.683279 ops/training.py:65 2019-01-16 11:41:53.683204: step 537, loss = 0.77900 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:41:54.450407 ops/training.py:65 2019-01-16 11:41:54.450332: step 538, loss = 0.78824 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:41:55.217476 ops/training.py:65 2019-01-16 11:41:55.217421: step 539, loss = 0.79189 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:41:56.012777 ops/training.py:65 2019-01-16 11:41:56.012702: step 540, loss = 0.77206 (40.3 examples/sec; 0.794 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:41:56.780898 ops/training.py:65 2019-01-16 11:41:56.780828: step 541, loss = 0.78434 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:41:57.547643 ops/training.py:65 2019-01-16 11:41:57.547566: step 542, loss = 0.73291 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:41:58.314357 ops/training.py:65 2019-01-16 11:41:58.314287: step 543, loss = 0.74227 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:41:59.079922 ops/training.py:65 2019-01-16 11:41:59.079856: step 544, loss = 0.78837 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:41:59.845843 ops/training.py:65 2019-01-16 11:41:59.845788: step 545, loss = 0.75721 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:42:00.608762 ops/training.py:65 2019-01-16 11:42:00.608694: step 546, loss = 0.72562 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:42:01.372761 ops/training.py:65 2019-01-16 11:42:01.372687: step 547, loss = 0.78424 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:42:02.136978 ops/training.py:65 2019-01-16 11:42:02.136913: step 548, loss = 0.76232 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:42:02.900409 ops/training.py:65 2019-01-16 11:42:02.900367: step 549, loss = 0.73850 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:42:03.665461 ops/training.py:65 2019-01-16 11:42:03.665408: step 550, loss = 0.72351 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:42:04.432136 ops/training.py:65 2019-01-16 11:42:04.432063: step 551, loss = 0.72899 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:42:05.199486 ops/training.py:65 2019-01-16 11:42:05.199427: step 552, loss = 0.72775 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:42:05.966838 ops/training.py:65 2019-01-16 11:42:05.966761: step 553, loss = 0.72302 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:42:06.733807 ops/training.py:65 2019-01-16 11:42:06.733733: step 554, loss = 0.71744 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:42:07.501446 ops/training.py:65 2019-01-16 11:42:07.501386: step 555, loss = 0.64102 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:42:08.268358 ops/training.py:65 2019-01-16 11:42:08.268279: step 556, loss = 0.78819 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:42:09.035463 ops/training.py:65 2019-01-16 11:42:09.035390: step 557, loss = 0.60910 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:42:09.802310 ops/training.py:65 2019-01-16 11:42:09.802237: step 558, loss = 0.71222 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:42:10.570665 ops/training.py:65 2019-01-16 11:42:10.570593: step 559, loss = 0.78373 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:42:11.338631 ops/training.py:65 2019-01-16 11:42:11.338557: step 560, loss = 0.69650 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:42:12.104441 ops/training.py:65 2019-01-16 11:42:12.104367: step 561, loss = 0.70214 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:42:12.868255 ops/training.py:65 2019-01-16 11:42:12.868187: step 562, loss = 0.66041 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:42:13.632557 ops/training.py:65 2019-01-16 11:42:13.632496: step 563, loss = 0.67411 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:42:14.396058 ops/training.py:65 2019-01-16 11:42:14.396006: step 564, loss = 0.68963 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:42:15.160001 ops/training.py:65 2019-01-16 11:42:15.159923: step 565, loss = 0.64606 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:42:15.925742 ops/training.py:65 2019-01-16 11:42:15.925668: step 566, loss = 0.73522 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:42:16.691878 ops/training.py:65 2019-01-16 11:42:16.691820: step 567, loss = 0.73645 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:42:17.459922 ops/training.py:65 2019-01-16 11:42:17.459870: step 568, loss = 0.78287 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:42:18.226581 ops/training.py:65 2019-01-16 11:42:18.226506: step 569, loss = 0.71822 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:42:18.994621 ops/training.py:65 2019-01-16 11:42:18.994549: step 570, loss = 0.68663 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:42:19.761703 ops/training.py:65 2019-01-16 11:42:19.761629: step 571, loss = 0.73049 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:42:20.528291 ops/training.py:65 2019-01-16 11:42:20.528236: step 572, loss = 0.78787 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:42:21.295839 ops/training.py:65 2019-01-16 11:42:21.295769: step 573, loss = 0.72840 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:42:22.062074 ops/training.py:65 2019-01-16 11:42:22.062006: step 574, loss = 0.65420 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:42:22.828347 ops/training.py:65 2019-01-16 11:42:22.828277: step 575, loss = 0.75257 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:42:23.592368 ops/training.py:65 2019-01-16 11:42:23.592297: step 576, loss = 0.70517 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:42:24.358723 ops/training.py:65 2019-01-16 11:42:24.358657: step 577, loss = 0.76444 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:42:25.126834 ops/training.py:65 2019-01-16 11:42:25.126761: step 578, loss = 0.73604 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:42:25.893999 ops/training.py:65 2019-01-16 11:42:25.893926: step 579, loss = 0.67053 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:42:26.659543 ops/training.py:65 2019-01-16 11:42:26.659494: step 580, loss = 0.66453 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:42:27.425573 ops/training.py:65 2019-01-16 11:42:27.425516: step 581, loss = 0.68633 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:42:28.189218 ops/training.py:65 2019-01-16 11:42:28.189164: step 582, loss = 0.62760 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:42:28.953313 ops/training.py:65 2019-01-16 11:42:28.953267: step 583, loss = 0.78281 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:42:29.716112 ops/training.py:65 2019-01-16 11:42:29.716043: step 584, loss = 0.72282 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:42:30.480882 ops/training.py:65 2019-01-16 11:42:30.480813: step 585, loss = 0.72026 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:42:31.246704 ops/training.py:65 2019-01-16 11:42:31.246636: step 586, loss = 0.73931 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:42:32.015439 ops/training.py:65 2019-01-16 11:42:32.015366: step 587, loss = 0.71311 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:42:32.781465 ops/training.py:65 2019-01-16 11:42:32.781407: step 588, loss = 0.64516 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:42:33.546095 ops/training.py:65 2019-01-16 11:42:33.546040: step 589, loss = 0.79663 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:42:34.311727 ops/training.py:65 2019-01-16 11:42:34.311660: step 590, loss = 0.67887 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:42:35.079121 ops/training.py:65 2019-01-16 11:42:35.079050: step 591, loss = 0.71542 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:42:35.845790 ops/training.py:65 2019-01-16 11:42:35.845726: step 592, loss = 0.72770 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:42:36.611076 ops/training.py:65 2019-01-16 11:42:36.611026: step 593, loss = 0.79542 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:42:37.377214 ops/training.py:65 2019-01-16 11:42:37.377156: step 594, loss = 0.66790 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:42:38.143440 ops/training.py:65 2019-01-16 11:42:38.143366: step 595, loss = 0.69998 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:42:38.909723 ops/training.py:65 2019-01-16 11:42:38.909663: step 596, loss = 0.73384 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:42:39.676714 ops/training.py:65 2019-01-16 11:42:39.676662: step 597, loss = 0.69951 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:42:40.442080 ops/training.py:65 2019-01-16 11:42:40.442030: step 598, loss = 0.70854 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:42:41.208343 ops/training.py:65 2019-01-16 11:42:41.208267: step 599, loss = 0.67401 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:42:41.975977 ops/training.py:65 2019-01-16 11:42:41.975908: step 600, loss = 0.71751 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:42:42.742699 ops/training.py:65 2019-01-16 11:42:42.742624: step 601, loss = 0.81014 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:42:43.509751 ops/training.py:65 2019-01-16 11:42:43.509683: step 602, loss = 0.81070 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 11:42:44.276988 ops/training.py:65 2019-01-16 11:42:44.276927: step 603, loss = 0.77434 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:42:45.041542 ops/training.py:65 2019-01-16 11:42:45.041477: step 604, loss = 0.65950 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:42:45.804933 ops/training.py:65 2019-01-16 11:42:45.804861: step 605, loss = 0.72213 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:42:46.569890 ops/training.py:65 2019-01-16 11:42:46.569819: step 606, loss = 0.74242 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:42:47.333743 ops/training.py:65 2019-01-16 11:42:47.333676: step 607, loss = 0.75441 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:42:48.097324 ops/training.py:65 2019-01-16 11:42:48.097269: step 608, loss = 0.65221 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:42:48.861179 ops/training.py:65 2019-01-16 11:42:48.861133: step 609, loss = 0.65783 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:42:49.625333 ops/training.py:65 2019-01-16 11:42:49.625263: step 610, loss = 0.73161 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:42:50.388504 ops/training.py:65 2019-01-16 11:42:50.388444: step 611, loss = 0.79681 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:42:51.153872 ops/training.py:65 2019-01-16 11:42:51.153803: step 612, loss = 0.78086 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:42:51.922086 ops/training.py:65 2019-01-16 11:42:51.922008: step 613, loss = 0.74025 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:42:52.688502 ops/training.py:65 2019-01-16 11:42:52.688428: step 614, loss = 0.70496 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:42:53.455429 ops/training.py:65 2019-01-16 11:42:53.455361: step 615, loss = 0.78625 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:42:54.222712 ops/training.py:65 2019-01-16 11:42:54.222645: step 616, loss = 0.60482 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 11:42:54.990704 ops/training.py:65 2019-01-16 11:42:54.990649: step 617, loss = 0.86058 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:42:55.758144 ops/training.py:65 2019-01-16 11:42:55.758072: step 618, loss = 0.72224 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:42:56.523818 ops/training.py:65 2019-01-16 11:42:56.523755: step 619, loss = 0.70033 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:42:57.286739 ops/training.py:65 2019-01-16 11:42:57.286664: step 620, loss = 0.72599 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:42:58.050634 ops/training.py:65 2019-01-16 11:42:58.050558: step 621, loss = 0.83090 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:42:58.815678 ops/training.py:65 2019-01-16 11:42:58.815610: step 622, loss = 0.72177 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:42:59.583139 ops/training.py:65 2019-01-16 11:42:59.583079: step 623, loss = 0.81763 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:43:00.350018 ops/training.py:65 2019-01-16 11:43:00.349941: step 624, loss = 0.76970 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:43:01.116623 ops/training.py:65 2019-01-16 11:43:01.116549: step 625, loss = 0.73348 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:43:01.880763 ops/training.py:65 2019-01-16 11:43:01.880695: step 626, loss = 0.71384 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:43:02.646661 ops/training.py:65 2019-01-16 11:43:02.646604: step 627, loss = 0.80100 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:43:03.413963 ops/training.py:65 2019-01-16 11:43:03.413887: step 628, loss = 0.68928 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:43:04.181044 ops/training.py:65 2019-01-16 11:43:04.180977: step 629, loss = 0.68819 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:43:04.944571 ops/training.py:65 2019-01-16 11:43:04.944507: step 630, loss = 0.80047 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:43:05.707621 ops/training.py:65 2019-01-16 11:43:05.707558: step 631, loss = 0.73372 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:43:06.471303 ops/training.py:65 2019-01-16 11:43:06.471260: step 632, loss = 0.74999 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:43:07.235343 ops/training.py:65 2019-01-16 11:43:07.235285: step 633, loss = 0.84382 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:43:08.000254 ops/training.py:65 2019-01-16 11:43:08.000190: step 634, loss = 0.80542 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:43:08.765306 ops/training.py:65 2019-01-16 11:43:08.765247: step 635, loss = 0.71944 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:43:09.532179 ops/training.py:65 2019-01-16 11:43:09.532121: step 636, loss = 0.71919 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:43:10.298166 ops/training.py:65 2019-01-16 11:43:10.298108: step 637, loss = 0.75034 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:43:11.064811 ops/training.py:65 2019-01-16 11:43:11.064734: step 638, loss = 0.80700 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:43:11.833952 ops/training.py:65 2019-01-16 11:43:11.833876: step 639, loss = 0.73690 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:43:12.600605 ops/training.py:65 2019-01-16 11:43:12.600530: step 640, loss = 0.67817 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:43:13.368350 ops/training.py:65 2019-01-16 11:43:13.368282: step 641, loss = 0.68747 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:43:14.131979 ops/training.py:65 2019-01-16 11:43:14.131929: step 642, loss = 0.74448 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:43:14.896603 ops/training.py:65 2019-01-16 11:43:14.896550: step 643, loss = 0.81329 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:43:15.660955 ops/training.py:65 2019-01-16 11:43:15.660886: step 644, loss = 0.93517 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:43:16.425539 ops/training.py:65 2019-01-16 11:43:16.425474: step 645, loss = 0.69840 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:43:17.189878 ops/training.py:65 2019-01-16 11:43:17.189823: step 646, loss = 0.68599 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:43:17.953259 ops/training.py:65 2019-01-16 11:43:17.953217: step 647, loss = 0.65139 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:43:18.717006 ops/training.py:65 2019-01-16 11:43:18.716955: step 648, loss = 0.73733 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:43:19.480851 ops/training.py:65 2019-01-16 11:43:19.480785: step 649, loss = 0.74120 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:43:20.244355 ops/training.py:65 2019-01-16 11:43:20.244303: step 650, loss = 0.76035 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:43:21.009654 ops/training.py:65 2019-01-16 11:43:21.009600: step 651, loss = 0.87123 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:43:21.774262 ops/training.py:65 2019-01-16 11:43:21.774212: step 652, loss = 0.73575 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:43:22.537970 ops/training.py:65 2019-01-16 11:43:22.537903: step 653, loss = 0.78013 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:43:23.304481 ops/training.py:65 2019-01-16 11:43:23.304415: step 654, loss = 0.76122 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:43:24.072421 ops/training.py:65 2019-01-16 11:43:24.072353: step 655, loss = 0.74745 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:43:24.838745 ops/training.py:65 2019-01-16 11:43:24.838692: step 656, loss = 0.76140 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:43:25.604852 ops/training.py:65 2019-01-16 11:43:25.604802: step 657, loss = 0.70514 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:43:26.371537 ops/training.py:65 2019-01-16 11:43:26.371469: step 658, loss = 0.69312 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:43:27.138912 ops/training.py:65 2019-01-16 11:43:27.138844: step 659, loss = 0.65083 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:43:27.906051 ops/training.py:65 2019-01-16 11:43:27.905982: step 660, loss = 0.76325 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:43:28.672489 ops/training.py:65 2019-01-16 11:43:28.672428: step 661, loss = 0.73863 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:43:29.437649 ops/training.py:65 2019-01-16 11:43:29.437579: step 662, loss = 0.74816 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:43:30.204199 ops/training.py:65 2019-01-16 11:43:30.204127: step 663, loss = 0.72329 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:43:30.969888 ops/training.py:65 2019-01-16 11:43:30.969819: step 664, loss = 0.70674 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:43:31.734807 ops/training.py:65 2019-01-16 11:43:31.734738: step 665, loss = 0.75721 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:43:32.498391 ops/training.py:65 2019-01-16 11:43:32.498340: step 666, loss = 0.80104 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:43:33.262645 ops/training.py:65 2019-01-16 11:43:33.262594: step 667, loss = 0.68846 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:43:34.026375 ops/training.py:65 2019-01-16 11:43:34.026305: step 668, loss = 0.66977 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:43:34.790664 ops/training.py:65 2019-01-16 11:43:34.790592: step 669, loss = 0.69258 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:43:35.557069 ops/training.py:65 2019-01-16 11:43:35.557001: step 670, loss = 0.70996 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:43:36.325281 ops/training.py:65 2019-01-16 11:43:36.325221: step 671, loss = 0.67267 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:43:37.092904 ops/training.py:65 2019-01-16 11:43:37.092846: step 672, loss = 0.68753 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:43:37.858719 ops/training.py:65 2019-01-16 11:43:37.858649: step 673, loss = 0.71107 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:43:38.623590 ops/training.py:65 2019-01-16 11:43:38.623522: step 674, loss = 0.72836 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:43:39.389252 ops/training.py:65 2019-01-16 11:43:39.389182: step 675, loss = 0.75399 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:43:40.152974 ops/training.py:65 2019-01-16 11:43:40.152929: step 676, loss = 0.69460 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:43:40.915861 ops/training.py:65 2019-01-16 11:43:40.915811: step 677, loss = 0.68153 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:43:41.679066 ops/training.py:65 2019-01-16 11:43:41.678993: step 678, loss = 0.71927 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:43:42.445435 ops/training.py:65 2019-01-16 11:43:42.445364: step 679, loss = 0.70432 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:43:43.211117 ops/training.py:65 2019-01-16 11:43:43.211049: step 680, loss = 0.70589 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:43:43.977945 ops/training.py:65 2019-01-16 11:43:43.977892: step 681, loss = 0.72696 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:43:44.741685 ops/training.py:65 2019-01-16 11:43:44.741614: step 682, loss = 0.75011 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:43:45.505889 ops/training.py:65 2019-01-16 11:43:45.505820: step 683, loss = 0.69345 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:43:46.269748 ops/training.py:65 2019-01-16 11:43:46.269671: step 684, loss = 0.68557 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 11:43:47.034105 ops/training.py:65 2019-01-16 11:43:47.034046: step 685, loss = 0.69822 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:43:47.799555 ops/training.py:65 2019-01-16 11:43:47.799506: step 686, loss = 0.70620 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:43:48.564701 ops/training.py:65 2019-01-16 11:43:48.564627: step 687, loss = 0.74599 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:43:49.330529 ops/training.py:65 2019-01-16 11:43:49.330460: step 688, loss = 0.74471 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:43:50.098698 ops/training.py:65 2019-01-16 11:43:50.098626: step 689, loss = 0.71145 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:43:50.865042 ops/training.py:65 2019-01-16 11:43:50.864984: step 690, loss = 0.70301 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:43:51.631788 ops/training.py:65 2019-01-16 11:43:51.631740: step 691, loss = 0.66467 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:43:52.400378 ops/training.py:65 2019-01-16 11:43:52.400303: step 692, loss = 0.73743 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 11:43:53.167889 ops/training.py:65 2019-01-16 11:43:53.167827: step 693, loss = 0.69022 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:43:53.934628 ops/training.py:65 2019-01-16 11:43:53.934556: step 694, loss = 0.70860 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:43:54.700331 ops/training.py:65 2019-01-16 11:43:54.700261: step 695, loss = 0.73594 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:43:55.464220 ops/training.py:65 2019-01-16 11:43:55.464168: step 696, loss = 0.67096 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:43:56.227845 ops/training.py:65 2019-01-16 11:43:56.227781: step 697, loss = 0.70389 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:43:56.992498 ops/training.py:65 2019-01-16 11:43:56.992436: step 698, loss = 0.69605 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:43:57.757928 ops/training.py:65 2019-01-16 11:43:57.757861: step 699, loss = 0.72377 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:43:58.522392 ops/training.py:65 2019-01-16 11:43:58.522325: step 700, loss = 0.68647 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:43:59.286239 ops/training.py:65 2019-01-16 11:43:59.286192: step 701, loss = 0.72433 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:44:00.050641 ops/training.py:65 2019-01-16 11:44:00.050577: step 702, loss = 0.68423 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:44:00.813667 ops/training.py:65 2019-01-16 11:44:00.813601: step 703, loss = 0.68222 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:44:01.577255 ops/training.py:65 2019-01-16 11:44:01.577201: step 704, loss = 0.68438 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:44:02.341468 ops/training.py:65 2019-01-16 11:44:02.341405: step 705, loss = 0.64659 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 11:44:03.106340 ops/training.py:65 2019-01-16 11:44:03.106288: step 706, loss = 0.70641 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:44:03.870856 ops/training.py:65 2019-01-16 11:44:03.870785: step 707, loss = 0.66905 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:44:04.634611 ops/training.py:65 2019-01-16 11:44:04.634548: step 708, loss = 0.71151 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:44:05.398170 ops/training.py:65 2019-01-16 11:44:05.398118: step 709, loss = 0.67802 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 11:44:06.162839 ops/training.py:65 2019-01-16 11:44:06.162776: step 710, loss = 0.72187 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:44:06.926390 ops/training.py:65 2019-01-16 11:44:06.926341: step 711, loss = 0.73379 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:44:07.690803 ops/training.py:65 2019-01-16 11:44:07.690745: step 712, loss = 0.73405 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:44:08.454673 ops/training.py:65 2019-01-16 11:44:08.454603: step 713, loss = 0.73088 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:44:09.218772 ops/training.py:65 2019-01-16 11:44:09.218700: step 714, loss = 0.65734 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:44:09.985809 ops/training.py:65 2019-01-16 11:44:09.985724: step 715, loss = 0.64684 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 11:44:10.752650 ops/training.py:65 2019-01-16 11:44:10.752580: step 716, loss = 0.75221 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:44:11.518628 ops/training.py:65 2019-01-16 11:44:11.518551: step 717, loss = 0.73063 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:44:12.284939 ops/training.py:65 2019-01-16 11:44:12.284863: step 718, loss = 0.71151 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:44:13.050020 ops/training.py:65 2019-01-16 11:44:13.049945: step 719, loss = 0.69784 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:44:13.814801 ops/training.py:65 2019-01-16 11:44:13.814733: step 720, loss = 0.69577 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:44:14.580757 ops/training.py:65 2019-01-16 11:44:14.580701: step 721, loss = 0.71235 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:44:15.349725 ops/training.py:65 2019-01-16 11:44:15.349653: step 722, loss = 0.69363 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:44:16.115634 ops/training.py:65 2019-01-16 11:44:16.115567: step 723, loss = 0.69883 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:44:16.879279 ops/training.py:65 2019-01-16 11:44:16.879216: step 724, loss = 0.69978 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:44:17.645018 ops/training.py:65 2019-01-16 11:44:17.644948: step 725, loss = 0.76469 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 11:44:18.412013 ops/training.py:65 2019-01-16 11:44:18.411939: step 726, loss = 0.77958 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:44:19.179765 ops/training.py:65 2019-01-16 11:44:19.179694: step 727, loss = 0.73405 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:44:19.945164 ops/training.py:65 2019-01-16 11:44:19.945111: step 728, loss = 0.76130 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:44:20.710348 ops/training.py:65 2019-01-16 11:44:20.710290: step 729, loss = 0.73385 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:44:21.476877 ops/training.py:65 2019-01-16 11:44:21.476797: step 730, loss = 0.70774 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:44:22.243333 ops/training.py:65 2019-01-16 11:44:22.243284: step 731, loss = 0.73630 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:44:23.008311 ops/training.py:65 2019-01-16 11:44:23.008250: step 732, loss = 0.68378 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:44:23.774803 ops/training.py:65 2019-01-16 11:44:23.774745: step 733, loss = 0.71448 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:44:24.541310 ops/training.py:65 2019-01-16 11:44:24.541222: step 734, loss = 0.76310 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:44:25.307837 ops/training.py:65 2019-01-16 11:44:25.307760: step 735, loss = 0.74175 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:44:26.072412 ops/training.py:65 2019-01-16 11:44:26.072352: step 736, loss = 0.74655 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:44:26.836298 ops/training.py:65 2019-01-16 11:44:26.836250: step 737, loss = 0.68522 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:44:27.601131 ops/training.py:65 2019-01-16 11:44:27.601072: step 738, loss = 0.67604 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:44:28.370550 ops/training.py:65 2019-01-16 11:44:28.370492: step 739, loss = 0.73127 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:44:29.137361 ops/training.py:65 2019-01-16 11:44:29.137280: step 740, loss = 0.64826 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:44:29.903649 ops/training.py:65 2019-01-16 11:44:29.903600: step 741, loss = 0.71075 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:44:30.670604 ops/training.py:65 2019-01-16 11:44:30.670540: step 742, loss = 0.71003 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:44:31.438506 ops/training.py:65 2019-01-16 11:44:31.438436: step 743, loss = 0.65587 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:44:32.204683 ops/training.py:65 2019-01-16 11:44:32.204616: step 744, loss = 0.81040 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:44:32.968391 ops/training.py:65 2019-01-16 11:44:32.968342: step 745, loss = 0.76497 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:44:33.731070 ops/training.py:65 2019-01-16 11:44:33.731000: step 746, loss = 0.86353 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:44:34.494563 ops/training.py:65 2019-01-16 11:44:34.494494: step 747, loss = 0.76574 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:44:35.258096 ops/training.py:65 2019-01-16 11:44:35.258042: step 748, loss = 0.71192 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:44:36.022496 ops/training.py:65 2019-01-16 11:44:36.022435: step 749, loss = 0.74712 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:44:36.785826 ops/training.py:65 2019-01-16 11:44:36.785772: step 750, loss = 0.82199 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:44:37.549524 ops/training.py:65 2019-01-16 11:44:37.549471: step 751, loss = 0.80449 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:44:38.314642 ops/training.py:65 2019-01-16 11:44:38.314571: step 752, loss = 0.79941 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:44:39.079332 ops/training.py:65 2019-01-16 11:44:39.079263: step 753, loss = 0.83814 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:44:39.844143 ops/training.py:65 2019-01-16 11:44:39.844076: step 754, loss = 0.87813 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:44:40.610511 ops/training.py:65 2019-01-16 11:44:40.610465: step 755, loss = 0.80107 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:44:41.376265 ops/training.py:65 2019-01-16 11:44:41.376198: step 756, loss = 0.78437 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:44:42.143706 ops/training.py:65 2019-01-16 11:44:42.143633: step 757, loss = 0.71635 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:44:42.910487 ops/training.py:65 2019-01-16 11:44:42.910417: step 758, loss = 0.86476 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:44:43.676664 ops/training.py:65 2019-01-16 11:44:43.676598: step 759, loss = 0.69887 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:44:44.440965 ops/training.py:65 2019-01-16 11:44:44.440913: step 760, loss = 0.66526 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:44:45.206214 ops/training.py:65 2019-01-16 11:44:45.206148: step 761, loss = 0.69041 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:44:45.970568 ops/training.py:65 2019-01-16 11:44:45.970497: step 762, loss = 0.96996 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:44:46.737010 ops/training.py:65 2019-01-16 11:44:46.736946: step 763, loss = 0.77361 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:44:47.505056 ops/training.py:65 2019-01-16 11:44:47.504987: step 764, loss = 0.82543 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:44:48.272229 ops/training.py:65 2019-01-16 11:44:48.272153: step 765, loss = 0.63826 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:44:49.038300 ops/training.py:65 2019-01-16 11:44:49.038237: step 766, loss = 0.63877 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:44:49.803264 ops/training.py:65 2019-01-16 11:44:49.803200: step 767, loss = 0.72301 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:44:50.568173 ops/training.py:65 2019-01-16 11:44:50.568110: step 768, loss = 0.72462 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:44:51.334961 ops/training.py:65 2019-01-16 11:44:51.334895: step 769, loss = 0.81281 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:44:52.101689 ops/training.py:65 2019-01-16 11:44:52.101613: step 770, loss = 0.73471 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:44:52.867313 ops/training.py:65 2019-01-16 11:44:52.867250: step 771, loss = 0.72179 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:44:53.631566 ops/training.py:65 2019-01-16 11:44:53.631504: step 772, loss = 0.73330 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:44:54.398859 ops/training.py:65 2019-01-16 11:44:54.398788: step 773, loss = 0.77737 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:44:55.164240 ops/training.py:65 2019-01-16 11:44:55.164172: step 774, loss = 0.83499 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:44:55.929006 ops/training.py:65 2019-01-16 11:44:55.928948: step 775, loss = 0.73103 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:44:56.693816 ops/training.py:65 2019-01-16 11:44:56.693745: step 776, loss = 0.92925 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:44:57.458879 ops/training.py:65 2019-01-16 11:44:57.458809: step 777, loss = 0.65069 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:44:58.224935 ops/training.py:65 2019-01-16 11:44:58.224865: step 778, loss = 0.82987 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:44:58.991839 ops/training.py:65 2019-01-16 11:44:58.991771: step 779, loss = 0.72273 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:44:59.760877 ops/training.py:65 2019-01-16 11:44:59.760800: step 780, loss = 0.76982 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:45:00.527112 ops/training.py:65 2019-01-16 11:45:00.527049: step 781, loss = 0.73729 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:45:01.292921 ops/training.py:65 2019-01-16 11:45:01.292852: step 782, loss = 0.71368 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:45:02.059382 ops/training.py:65 2019-01-16 11:45:02.059326: step 783, loss = 0.73444 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:45:02.825140 ops/training.py:65 2019-01-16 11:45:02.825067: step 784, loss = 0.73856 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:45:03.593951 ops/training.py:65 2019-01-16 11:45:03.593895: step 785, loss = 0.79809 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:45:04.359454 ops/training.py:65 2019-01-16 11:45:04.359391: step 786, loss = 0.74889 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:45:05.125179 ops/training.py:65 2019-01-16 11:45:05.125116: step 787, loss = 0.78580 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:45:05.890034 ops/training.py:65 2019-01-16 11:45:05.889981: step 788, loss = 0.78351 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:45:06.655953 ops/training.py:65 2019-01-16 11:45:06.655879: step 789, loss = 0.73892 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:45:07.423009 ops/training.py:65 2019-01-16 11:45:07.422956: step 790, loss = 0.73987 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:45:08.187571 ops/training.py:65 2019-01-16 11:45:08.187496: step 791, loss = 0.71166 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:45:08.951982 ops/training.py:65 2019-01-16 11:45:08.951915: step 792, loss = 0.70280 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:45:09.717232 ops/training.py:65 2019-01-16 11:45:09.717163: step 793, loss = 0.78036 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:45:10.482155 ops/training.py:65 2019-01-16 11:45:10.482073: step 794, loss = 0.72255 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:45:11.247861 ops/training.py:65 2019-01-16 11:45:11.247808: step 795, loss = 0.71604 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:45:12.011358 ops/training.py:65 2019-01-16 11:45:12.011297: step 796, loss = 0.70132 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:45:12.776573 ops/training.py:65 2019-01-16 11:45:12.776507: step 797, loss = 0.72416 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:45:13.540822 ops/training.py:65 2019-01-16 11:45:13.540758: step 798, loss = 0.65004 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:45:14.305747 ops/training.py:65 2019-01-16 11:45:14.305669: step 799, loss = 0.73119 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:45:15.071692 ops/training.py:65 2019-01-16 11:45:15.071647: step 800, loss = 0.67293 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:45:15.838597 ops/training.py:65 2019-01-16 11:45:15.838529: step 801, loss = 0.65007 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:45:16.604660 ops/training.py:65 2019-01-16 11:45:16.604590: step 802, loss = 0.79515 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:45:17.369330 ops/training.py:65 2019-01-16 11:45:17.369265: step 803, loss = 0.63028 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:45:18.134238 ops/training.py:65 2019-01-16 11:45:18.134163: step 804, loss = 0.85711 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:45:18.901138 ops/training.py:65 2019-01-16 11:45:18.901070: step 805, loss = 0.68248 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:45:19.668790 ops/training.py:65 2019-01-16 11:45:19.668723: step 806, loss = 0.69288 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:45:20.436746 ops/training.py:65 2019-01-16 11:45:20.436681: step 807, loss = 0.70340 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:45:21.201726 ops/training.py:65 2019-01-16 11:45:21.201655: step 808, loss = 0.63223 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:45:21.966296 ops/training.py:65 2019-01-16 11:45:21.966231: step 809, loss = 0.72275 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:45:22.730308 ops/training.py:65 2019-01-16 11:45:22.730257: step 810, loss = 0.70734 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:45:23.494045 ops/training.py:65 2019-01-16 11:45:23.493993: step 811, loss = 0.71448 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:45:24.257127 ops/training.py:65 2019-01-16 11:45:24.257076: step 812, loss = 0.76560 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:45:25.021835 ops/training.py:65 2019-01-16 11:45:25.021792: step 813, loss = 0.85014 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 11:45:25.787381 ops/training.py:65 2019-01-16 11:45:25.787324: step 814, loss = 0.77118 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:45:26.556182 ops/training.py:65 2019-01-16 11:45:26.556125: step 815, loss = 0.93347 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:45:27.322058 ops/training.py:65 2019-01-16 11:45:27.321985: step 816, loss = 0.86091 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:45:28.088670 ops/training.py:65 2019-01-16 11:45:28.088610: step 817, loss = 0.80331 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:45:28.855437 ops/training.py:65 2019-01-16 11:45:28.855369: step 818, loss = 0.87240 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:45:29.622631 ops/training.py:65 2019-01-16 11:45:29.622549: step 819, loss = 0.92792 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:45:30.390213 ops/training.py:65 2019-01-16 11:45:30.390160: step 820, loss = 0.79933 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:45:31.155991 ops/training.py:65 2019-01-16 11:45:31.155929: step 821, loss = 0.86426 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:45:31.922597 ops/training.py:65 2019-01-16 11:45:31.922524: step 822, loss = 0.75849 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:45:32.687932 ops/training.py:65 2019-01-16 11:45:32.687816: step 823, loss = 0.93444 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:45:33.453790 ops/training.py:65 2019-01-16 11:45:33.453734: step 824, loss = 0.69476 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:45:34.217715 ops/training.py:65 2019-01-16 11:45:34.217667: step 825, loss = 0.61664 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:45:34.987406 ops/training.py:65 2019-01-16 11:45:34.987337: step 826, loss = 0.83037 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:45:35.754794 ops/training.py:65 2019-01-16 11:45:35.754719: step 827, loss = 0.75381 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:45:36.522347 ops/training.py:65 2019-01-16 11:45:36.522277: step 828, loss = 0.79541 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:45:37.289719 ops/training.py:65 2019-01-16 11:45:37.289662: step 829, loss = 0.86141 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:45:38.057478 ops/training.py:65 2019-01-16 11:45:38.057416: step 830, loss = 0.65307 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:45:38.828065 ops/training.py:65 2019-01-16 11:45:38.828001: step 831, loss = 0.70005 (41.6 examples/sec; 0.770 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:45:39.595313 ops/training.py:65 2019-01-16 11:45:39.595237: step 832, loss = 0.76646 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:45:40.360232 ops/training.py:65 2019-01-16 11:45:40.360156: step 833, loss = 0.74747 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:45:41.125551 ops/training.py:65 2019-01-16 11:45:41.125491: step 834, loss = 0.76557 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:45:41.890168 ops/training.py:65 2019-01-16 11:45:41.890121: step 835, loss = 0.71022 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:45:42.653887 ops/training.py:65 2019-01-16 11:45:42.653833: step 836, loss = 0.68959 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:45:43.423676 ops/training.py:65 2019-01-16 11:45:43.423609: step 837, loss = 0.83592 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:45:44.191690 ops/training.py:65 2019-01-16 11:45:44.191612: step 838, loss = 0.73710 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:45:44.958187 ops/training.py:65 2019-01-16 11:45:44.958116: step 839, loss = 0.79903 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:45:45.724386 ops/training.py:65 2019-01-16 11:45:45.724317: step 840, loss = 0.80667 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:45:46.491014 ops/training.py:65 2019-01-16 11:45:46.490968: step 841, loss = 0.71745 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:45:47.256161 ops/training.py:65 2019-01-16 11:45:47.256097: step 842, loss = 0.63375 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 11:45:48.021405 ops/training.py:65 2019-01-16 11:45:48.021330: step 843, loss = 0.71266 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:45:48.789399 ops/training.py:65 2019-01-16 11:45:48.789331: step 844, loss = 0.75160 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:45:49.554220 ops/training.py:65 2019-01-16 11:45:49.554157: step 845, loss = 0.73230 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:45:50.319931 ops/training.py:65 2019-01-16 11:45:50.319869: step 846, loss = 0.82094 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 11:45:51.084045 ops/training.py:65 2019-01-16 11:45:51.083996: step 847, loss = 0.68660 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:45:51.849235 ops/training.py:65 2019-01-16 11:45:51.849162: step 848, loss = 0.67418 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:45:52.616646 ops/training.py:65 2019-01-16 11:45:52.616585: step 849, loss = 0.75362 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:45:53.382431 ops/training.py:65 2019-01-16 11:45:53.382382: step 850, loss = 0.73267 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:45:54.149182 ops/training.py:65 2019-01-16 11:45:54.149119: step 851, loss = 0.72793 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:45:54.915384 ops/training.py:65 2019-01-16 11:45:54.915323: step 852, loss = 0.65750 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:45:55.682147 ops/training.py:65 2019-01-16 11:45:55.682091: step 853, loss = 0.74040 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:45:56.447134 ops/training.py:65 2019-01-16 11:45:56.447087: step 854, loss = 0.72992 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:45:57.211274 ops/training.py:65 2019-01-16 11:45:57.211227: step 855, loss = 0.82273 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 11:45:57.975169 ops/training.py:65 2019-01-16 11:45:57.975127: step 856, loss = 0.75533 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:45:58.738986 ops/training.py:65 2019-01-16 11:45:58.738941: step 857, loss = 0.66267 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:45:59.503718 ops/training.py:65 2019-01-16 11:45:59.503668: step 858, loss = 0.66793 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:46:00.268786 ops/training.py:65 2019-01-16 11:46:00.268737: step 859, loss = 0.74275 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:46:01.033389 ops/training.py:65 2019-01-16 11:46:01.033342: step 860, loss = 0.67061 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:46:01.797349 ops/training.py:65 2019-01-16 11:46:01.797299: step 861, loss = 0.73138 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:46:02.563259 ops/training.py:65 2019-01-16 11:46:02.563211: step 862, loss = 0.79318 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:46:03.331045 ops/training.py:65 2019-01-16 11:46:03.330995: step 863, loss = 0.74853 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:46:04.096694 ops/training.py:65 2019-01-16 11:46:04.096624: step 864, loss = 0.82220 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:46:04.865557 ops/training.py:65 2019-01-16 11:46:04.865495: step 865, loss = 0.77226 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:46:05.633667 ops/training.py:65 2019-01-16 11:46:05.633620: step 866, loss = 0.73965 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:46:06.400435 ops/training.py:65 2019-01-16 11:46:06.400386: step 867, loss = 0.69782 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:46:07.166962 ops/training.py:65 2019-01-16 11:46:07.166908: step 868, loss = 0.82392 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:46:07.935514 ops/training.py:65 2019-01-16 11:46:07.935457: step 869, loss = 0.74168 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:46:08.702628 ops/training.py:65 2019-01-16 11:46:08.702565: step 870, loss = 0.79438 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:46:09.468667 ops/training.py:65 2019-01-16 11:46:09.468606: step 871, loss = 0.72671 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:46:10.234129 ops/training.py:65 2019-01-16 11:46:10.234065: step 872, loss = 0.68792 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 11:46:11.002948 ops/training.py:65 2019-01-16 11:46:11.002871: step 873, loss = 0.66687 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:46:11.767136 ops/training.py:65 2019-01-16 11:46:11.767069: step 874, loss = 0.77770 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:46:12.532650 ops/training.py:65 2019-01-16 11:46:12.532590: step 875, loss = 0.68781 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:46:13.297637 ops/training.py:65 2019-01-16 11:46:13.297573: step 876, loss = 0.72272 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:46:14.062490 ops/training.py:65 2019-01-16 11:46:14.062422: step 877, loss = 0.74995 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:46:14.829297 ops/training.py:65 2019-01-16 11:46:14.829232: step 878, loss = 0.73636 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:46:15.594885 ops/training.py:65 2019-01-16 11:46:15.594824: step 879, loss = 0.74886 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:46:16.361203 ops/training.py:65 2019-01-16 11:46:16.361123: step 880, loss = 0.77793 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:46:17.128095 ops/training.py:65 2019-01-16 11:46:17.128032: step 881, loss = 0.72202 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:46:17.895936 ops/training.py:65 2019-01-16 11:46:17.895868: step 882, loss = 0.75669 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:46:18.661358 ops/training.py:65 2019-01-16 11:46:18.661282: step 883, loss = 0.86040 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:46:19.427199 ops/training.py:65 2019-01-16 11:46:19.427132: step 884, loss = 0.88374 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:46:20.192002 ops/training.py:65 2019-01-16 11:46:20.191919: step 885, loss = 0.68125 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:46:20.958255 ops/training.py:65 2019-01-16 11:46:20.958198: step 886, loss = 0.75880 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:46:21.724715 ops/training.py:65 2019-01-16 11:46:21.724637: step 887, loss = 0.80277 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:46:22.489886 ops/training.py:65 2019-01-16 11:46:22.489823: step 888, loss = 0.65154 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:46:23.255153 ops/training.py:65 2019-01-16 11:46:23.255105: step 889, loss = 0.69996 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:46:24.019446 ops/training.py:65 2019-01-16 11:46:24.019399: step 890, loss = 0.76603 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:46:24.783356 ops/training.py:65 2019-01-16 11:46:24.783297: step 891, loss = 0.76427 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:46:25.549096 ops/training.py:65 2019-01-16 11:46:25.549021: step 892, loss = 0.69462 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:46:26.313361 ops/training.py:65 2019-01-16 11:46:26.313308: step 893, loss = 0.85393 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:46:27.078301 ops/training.py:65 2019-01-16 11:46:27.078237: step 894, loss = 0.77888 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:46:27.843610 ops/training.py:65 2019-01-16 11:46:27.843547: step 895, loss = 0.86520 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:46:28.608536 ops/training.py:65 2019-01-16 11:46:28.608473: step 896, loss = 0.59705 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:46:29.374095 ops/training.py:65 2019-01-16 11:46:29.374018: step 897, loss = 0.80630 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:46:30.139170 ops/training.py:65 2019-01-16 11:46:30.139118: step 898, loss = 0.75802 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:46:30.903315 ops/training.py:65 2019-01-16 11:46:30.903266: step 899, loss = 0.77891 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:46:31.666634 ops/training.py:65 2019-01-16 11:46:31.666589: step 900, loss = 0.73126 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:46:32.432322 ops/training.py:65 2019-01-16 11:46:32.432278: step 901, loss = 0.67729 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:46:33.198919 ops/training.py:65 2019-01-16 11:46:33.198849: step 902, loss = 0.72416 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:46:33.965227 ops/training.py:65 2019-01-16 11:46:33.965168: step 903, loss = 0.96435 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 11:46:34.732793 ops/training.py:65 2019-01-16 11:46:34.732733: step 904, loss = 0.83638 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:46:35.500816 ops/training.py:65 2019-01-16 11:46:35.500763: step 905, loss = 0.78350 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:46:36.265790 ops/training.py:65 2019-01-16 11:46:36.265743: step 906, loss = 0.99008 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:46:37.031952 ops/training.py:65 2019-01-16 11:46:37.031903: step 907, loss = 0.80831 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:46:37.797985 ops/training.py:65 2019-01-16 11:46:37.797942: step 908, loss = 0.75608 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:46:38.566883 ops/training.py:65 2019-01-16 11:46:38.566828: step 909, loss = 0.73269 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:46:39.333811 ops/training.py:65 2019-01-16 11:46:39.333746: step 910, loss = 0.95812 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.25
I0528 2019-01-16 11:46:40.098220 ops/training.py:65 2019-01-16 11:46:40.098166: step 911, loss = 0.65372 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:46:40.863705 ops/training.py:65 2019-01-16 11:46:40.863630: step 912, loss = 0.72797 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:46:41.628245 ops/training.py:65 2019-01-16 11:46:41.628197: step 913, loss = 0.81297 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:46:42.391746 ops/training.py:65 2019-01-16 11:46:42.391697: step 914, loss = 0.85239 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:46:43.156929 ops/training.py:65 2019-01-16 11:46:43.156878: step 915, loss = 0.64262 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:46:43.920885 ops/training.py:65 2019-01-16 11:46:43.920817: step 916, loss = 0.90689 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:46:44.685255 ops/training.py:65 2019-01-16 11:46:44.685180: step 917, loss = 0.77688 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:46:45.448494 ops/training.py:65 2019-01-16 11:46:45.448447: step 918, loss = 0.84248 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:46:46.213018 ops/training.py:65 2019-01-16 11:46:46.212960: step 919, loss = 0.62247 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:46:46.978401 ops/training.py:65 2019-01-16 11:46:46.978339: step 920, loss = 0.76260 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:46:47.743418 ops/training.py:65 2019-01-16 11:46:47.743359: step 921, loss = 0.80847 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:46:48.508533 ops/training.py:65 2019-01-16 11:46:48.508477: step 922, loss = 0.79452 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:46:49.272968 ops/training.py:65 2019-01-16 11:46:49.272920: step 923, loss = 0.94358 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:46:50.038152 ops/training.py:65 2019-01-16 11:46:50.038082: step 924, loss = 0.86185 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:46:50.803653 ops/training.py:65 2019-01-16 11:46:50.803595: step 925, loss = 0.68200 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:46:51.568813 ops/training.py:65 2019-01-16 11:46:51.568765: step 926, loss = 0.70570 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:46:52.333483 ops/training.py:65 2019-01-16 11:46:52.333426: step 927, loss = 0.63634 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:46:53.099214 ops/training.py:65 2019-01-16 11:46:53.099155: step 928, loss = 0.90747 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:46:53.864725 ops/training.py:65 2019-01-16 11:46:53.864655: step 929, loss = 1.02485 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:46:54.630551 ops/training.py:65 2019-01-16 11:46:54.630485: step 930, loss = 0.63963 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:46:55.395957 ops/training.py:65 2019-01-16 11:46:55.395900: step 931, loss = 0.83822 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:46:56.160407 ops/training.py:65 2019-01-16 11:46:56.160336: step 932, loss = 0.88222 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:46:56.925682 ops/training.py:65 2019-01-16 11:46:56.925617: step 933, loss = 0.77126 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:46:57.691634 ops/training.py:65 2019-01-16 11:46:57.691567: step 934, loss = 0.92071 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:46:58.457114 ops/training.py:65 2019-01-16 11:46:58.457048: step 935, loss = 0.68525 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:46:59.221712 ops/training.py:65 2019-01-16 11:46:59.221665: step 936, loss = 0.89160 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:46:59.986928 ops/training.py:65 2019-01-16 11:46:59.986858: step 937, loss = 0.63162 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:47:00.750747 ops/training.py:65 2019-01-16 11:47:00.750680: step 938, loss = 0.68624 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:47:01.515854 ops/training.py:65 2019-01-16 11:47:01.515800: step 939, loss = 0.90007 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:47:02.280033 ops/training.py:65 2019-01-16 11:47:02.279968: step 940, loss = 0.76335 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:47:03.044804 ops/training.py:65 2019-01-16 11:47:03.044723: step 941, loss = 0.78306 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:47:03.810679 ops/training.py:65 2019-01-16 11:47:03.810632: step 942, loss = 0.82408 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:47:04.575963 ops/training.py:65 2019-01-16 11:47:04.575911: step 943, loss = 0.76082 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:47:05.340267 ops/training.py:65 2019-01-16 11:47:05.340217: step 944, loss = 0.82044 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:47:06.105071 ops/training.py:65 2019-01-16 11:47:06.105010: step 945, loss = 0.89074 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:47:06.870413 ops/training.py:65 2019-01-16 11:47:06.870337: step 946, loss = 0.79143 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:47:07.634557 ops/training.py:65 2019-01-16 11:47:07.634506: step 947, loss = 0.70250 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:47:08.399224 ops/training.py:65 2019-01-16 11:47:08.399159: step 948, loss = 0.77777 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:47:09.163988 ops/training.py:65 2019-01-16 11:47:09.163926: step 949, loss = 0.75341 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:47:09.929345 ops/training.py:65 2019-01-16 11:47:09.929278: step 950, loss = 0.80928 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:47:10.694282 ops/training.py:65 2019-01-16 11:47:10.694208: step 951, loss = 0.87141 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:47:11.460240 ops/training.py:65 2019-01-16 11:47:11.460166: step 952, loss = 0.70750 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:47:12.225628 ops/training.py:65 2019-01-16 11:47:12.225560: step 953, loss = 0.71612 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:47:12.990821 ops/training.py:65 2019-01-16 11:47:12.990766: step 954, loss = 0.79607 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:47:13.756729 ops/training.py:65 2019-01-16 11:47:13.756674: step 955, loss = 0.70658 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:47:14.521358 ops/training.py:65 2019-01-16 11:47:14.521286: step 956, loss = 0.74876 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:47:15.285240 ops/training.py:65 2019-01-16 11:47:15.285173: step 957, loss = 0.64063 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:47:16.050521 ops/training.py:65 2019-01-16 11:47:16.050460: step 958, loss = 0.72435 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:47:16.815164 ops/training.py:65 2019-01-16 11:47:16.815110: step 959, loss = 0.89042 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 11:47:17.579571 ops/training.py:65 2019-01-16 11:47:17.579522: step 960, loss = 0.80480 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 11:47:18.347613 ops/training.py:65 2019-01-16 11:47:18.347538: step 961, loss = 1.00949 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 11:47:19.112879 ops/training.py:65 2019-01-16 11:47:19.112815: step 962, loss = 0.80175 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:47:19.876798 ops/training.py:65 2019-01-16 11:47:19.876733: step 963, loss = 0.71794 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:47:20.642261 ops/training.py:65 2019-01-16 11:47:20.642197: step 964, loss = 0.68019 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:47:21.408143 ops/training.py:65 2019-01-16 11:47:21.408085: step 965, loss = 0.88208 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:47:22.173198 ops/training.py:65 2019-01-16 11:47:22.173117: step 966, loss = 0.66759 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:47:22.937676 ops/training.py:65 2019-01-16 11:47:22.937615: step 967, loss = 0.67816 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:47:23.703198 ops/training.py:65 2019-01-16 11:47:23.703135: step 968, loss = 0.75677 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:47:24.468110 ops/training.py:65 2019-01-16 11:47:24.468048: step 969, loss = 0.87118 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:47:25.232648 ops/training.py:65 2019-01-16 11:47:25.232585: step 970, loss = 0.68181 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:47:25.999553 ops/training.py:65 2019-01-16 11:47:25.999478: step 971, loss = 0.92423 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:47:26.764927 ops/training.py:65 2019-01-16 11:47:26.764861: step 972, loss = 0.76177 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:47:27.530464 ops/training.py:65 2019-01-16 11:47:27.530403: step 973, loss = 0.71448 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:47:28.295356 ops/training.py:65 2019-01-16 11:47:28.295294: step 974, loss = 0.68583 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:47:29.059714 ops/training.py:65 2019-01-16 11:47:29.059655: step 975, loss = 0.63448 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:47:29.825133 ops/training.py:65 2019-01-16 11:47:29.825063: step 976, loss = 0.84745 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:47:30.590188 ops/training.py:65 2019-01-16 11:47:30.590130: step 977, loss = 0.67247 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:47:31.355473 ops/training.py:65 2019-01-16 11:47:31.355410: step 978, loss = 0.77710 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:47:32.119728 ops/training.py:65 2019-01-16 11:47:32.119646: step 979, loss = 0.79764 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:47:32.883496 ops/training.py:65 2019-01-16 11:47:32.883419: step 980, loss = 0.82207 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:47:33.646725 ops/training.py:65 2019-01-16 11:47:33.646657: step 981, loss = 0.67319 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:47:34.410616 ops/training.py:65 2019-01-16 11:47:34.410569: step 982, loss = 0.72106 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:47:35.174783 ops/training.py:65 2019-01-16 11:47:35.174714: step 983, loss = 0.71672 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:47:35.939066 ops/training.py:65 2019-01-16 11:47:35.939001: step 984, loss = 0.68180 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:47:36.704379 ops/training.py:65 2019-01-16 11:47:36.704306: step 985, loss = 0.72882 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:47:37.472056 ops/training.py:65 2019-01-16 11:47:37.472005: step 986, loss = 0.73570 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:47:38.239610 ops/training.py:65 2019-01-16 11:47:38.239528: step 987, loss = 0.77124 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:47:39.007474 ops/training.py:65 2019-01-16 11:47:39.007405: step 988, loss = 0.80117 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:47:39.774704 ops/training.py:65 2019-01-16 11:47:39.774621: step 989, loss = 0.80295 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:47:40.544662 ops/training.py:65 2019-01-16 11:47:40.544572: step 990, loss = 0.80964 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:47:41.312473 ops/training.py:65 2019-01-16 11:47:41.312420: step 991, loss = 0.79212 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:47:42.080173 ops/training.py:65 2019-01-16 11:47:42.080105: step 992, loss = 0.80688 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:47:42.843764 ops/training.py:65 2019-01-16 11:47:42.843683: step 993, loss = 0.72212 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:47:43.611326 ops/training.py:65 2019-01-16 11:47:43.611268: step 994, loss = 0.74447 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:47:44.379185 ops/training.py:65 2019-01-16 11:47:44.379123: step 995, loss = 0.64007 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:47:45.145389 ops/training.py:65 2019-01-16 11:47:45.145323: step 996, loss = 0.77924 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:47:45.910598 ops/training.py:65 2019-01-16 11:47:45.910526: step 997, loss = 0.75100 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 11:47:46.675196 ops/training.py:65 2019-01-16 11:47:46.675126: step 998, loss = 0.67670 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:47:47.441458 ops/training.py:65 2019-01-16 11:47:47.441382: step 999, loss = 0.70383 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:47:48.206285 ops/training.py:65 2019-01-16 11:47:48.206210: step 1000, loss = 0.69684 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:47:48.970775 ops/training.py:65 2019-01-16 11:47:48.970708: step 1001, loss = 0.74127 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:47:49.735303 ops/training.py:65 2019-01-16 11:47:49.735236: step 1002, loss = 0.70719 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:47:50.501858 ops/training.py:65 2019-01-16 11:47:50.501796: step 1003, loss = 0.67440 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:47:51.267989 ops/training.py:65 2019-01-16 11:47:51.267929: step 1004, loss = 0.69367 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:47:52.032103 ops/training.py:65 2019-01-16 11:47:52.032029: step 1005, loss = 0.70477 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:47:52.798151 ops/training.py:65 2019-01-16 11:47:52.798099: step 1006, loss = 0.69638 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:47:53.564925 ops/training.py:65 2019-01-16 11:47:53.564863: step 1007, loss = 0.68637 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:47:54.329465 ops/training.py:65 2019-01-16 11:47:54.329395: step 1008, loss = 0.68381 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:47:55.099640 ops/training.py:65 2019-01-16 11:47:55.099599: step 1009, loss = 0.69951 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:47:55.863786 ops/training.py:65 2019-01-16 11:47:55.863754: step 1010, loss = 0.66798 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:47:56.631094 ops/training.py:65 2019-01-16 11:47:56.631026: step 1011, loss = 0.70711 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:47:57.398628 ops/training.py:65 2019-01-16 11:47:57.398569: step 1012, loss = 0.72847 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:47:58.167147 ops/training.py:65 2019-01-16 11:47:58.167098: step 1013, loss = 0.69659 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:47:58.936455 ops/training.py:65 2019-01-16 11:47:58.936410: step 1014, loss = 0.73868 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:47:59.704440 ops/training.py:65 2019-01-16 11:47:59.704381: step 1015, loss = 0.66958 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:48:00.468686 ops/training.py:65 2019-01-16 11:48:00.468652: step 1016, loss = 0.70892 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:48:01.231258 ops/training.py:65 2019-01-16 11:48:01.231220: step 1017, loss = 0.70089 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:48:01.997698 ops/training.py:65 2019-01-16 11:48:01.997667: step 1018, loss = 0.73348 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:48:02.763690 ops/training.py:65 2019-01-16 11:48:02.763649: step 1019, loss = 0.64102 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:48:03.529935 ops/training.py:65 2019-01-16 11:48:03.529862: step 1020, loss = 0.69047 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:48:04.295206 ops/training.py:65 2019-01-16 11:48:04.295157: step 1021, loss = 0.67880 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:48:05.059569 ops/training.py:65 2019-01-16 11:48:05.059503: step 1022, loss = 0.72766 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:48:05.823885 ops/training.py:65 2019-01-16 11:48:05.823825: step 1023, loss = 0.70928 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:48:06.588970 ops/training.py:65 2019-01-16 11:48:06.588929: step 1024, loss = 0.67590 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:48:07.357368 ops/training.py:65 2019-01-16 11:48:07.357312: step 1025, loss = 0.76944 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:48:08.124629 ops/training.py:65 2019-01-16 11:48:08.124553: step 1026, loss = 0.76534 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:48:08.891400 ops/training.py:65 2019-01-16 11:48:08.891340: step 1027, loss = 0.59616 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.75
I0528 2019-01-16 11:48:09.655832 ops/training.py:65 2019-01-16 11:48:09.655778: step 1028, loss = 0.71611 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:48:10.420199 ops/training.py:65 2019-01-16 11:48:10.420163: step 1029, loss = 0.76046 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:48:11.185238 ops/training.py:65 2019-01-16 11:48:11.185181: step 1030, loss = 0.74552 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:48:11.950565 ops/training.py:65 2019-01-16 11:48:11.950504: step 1031, loss = 0.73403 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:48:12.715461 ops/training.py:65 2019-01-16 11:48:12.715407: step 1032, loss = 0.66974 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:48:13.479257 ops/training.py:65 2019-01-16 11:48:13.479200: step 1033, loss = 0.67199 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:48:14.243322 ops/training.py:65 2019-01-16 11:48:14.243282: step 1034, loss = 0.72779 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:48:15.009258 ops/training.py:65 2019-01-16 11:48:15.009206: step 1035, loss = 0.69751 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:48:15.777147 ops/training.py:65 2019-01-16 11:48:15.777060: step 1036, loss = 0.65230 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:48:16.545035 ops/training.py:65 2019-01-16 11:48:16.544965: step 1037, loss = 0.79953 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:48:17.317826 ops/training.py:65 2019-01-16 11:48:17.317745: step 1038, loss = 0.74684 (41.5 examples/sec; 0.771 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:48:18.084425 ops/training.py:65 2019-01-16 11:48:18.084355: step 1039, loss = 0.72589 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:48:18.851899 ops/training.py:65 2019-01-16 11:48:18.851844: step 1040, loss = 0.94399 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 11:48:19.619446 ops/training.py:65 2019-01-16 11:48:19.619380: step 1041, loss = 0.69419 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:48:20.384880 ops/training.py:65 2019-01-16 11:48:20.384817: step 1042, loss = 0.69649 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:48:21.150193 ops/training.py:65 2019-01-16 11:48:21.150139: step 1043, loss = 0.76598 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:48:21.915318 ops/training.py:65 2019-01-16 11:48:21.915246: step 1044, loss = 0.76360 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:48:22.678928 ops/training.py:65 2019-01-16 11:48:22.678858: step 1045, loss = 0.70107 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:48:23.446691 ops/training.py:65 2019-01-16 11:48:23.446660: step 1046, loss = 0.65323 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:48:24.213114 ops/training.py:65 2019-01-16 11:48:24.213080: step 1047, loss = 0.69067 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.75
I0528 2019-01-16 11:48:24.980571 ops/training.py:65 2019-01-16 11:48:24.980531: step 1048, loss = 0.58419 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 11:48:25.747839 ops/training.py:65 2019-01-16 11:48:25.747797: step 1049, loss = 0.81611 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:48:26.512414 ops/training.py:65 2019-01-16 11:48:26.512366: step 1050, loss = 0.72343 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:48:27.276147 ops/training.py:65 2019-01-16 11:48:27.276103: step 1051, loss = 0.67792 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:48:28.040152 ops/training.py:65 2019-01-16 11:48:28.040112: step 1052, loss = 0.83949 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 11:48:28.804925 ops/training.py:65 2019-01-16 11:48:28.804893: step 1053, loss = 0.78778 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:48:29.569087 ops/training.py:65 2019-01-16 11:48:29.569057: step 1054, loss = 0.80755 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:48:30.334232 ops/training.py:65 2019-01-16 11:48:30.334169: step 1055, loss = 0.72866 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:48:31.098651 ops/training.py:65 2019-01-16 11:48:31.098581: step 1056, loss = 0.69234 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:48:31.865276 ops/training.py:65 2019-01-16 11:48:31.865214: step 1057, loss = 0.64024 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:48:32.631733 ops/training.py:65 2019-01-16 11:48:32.631660: step 1058, loss = 0.79146 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:48:33.396312 ops/training.py:65 2019-01-16 11:48:33.396239: step 1059, loss = 0.69866 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:48:34.160627 ops/training.py:65 2019-01-16 11:48:34.160554: step 1060, loss = 0.79751 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:48:34.925542 ops/training.py:65 2019-01-16 11:48:34.925490: step 1061, loss = 0.72454 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:48:35.692458 ops/training.py:65 2019-01-16 11:48:35.692427: step 1062, loss = 0.65093 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:48:36.459637 ops/training.py:65 2019-01-16 11:48:36.459604: step 1063, loss = 0.68708 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:48:37.224408 ops/training.py:65 2019-01-16 11:48:37.224368: step 1064, loss = 0.81941 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:48:37.989985 ops/training.py:65 2019-01-16 11:48:37.989932: step 1065, loss = 0.73455 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:48:38.756048 ops/training.py:65 2019-01-16 11:48:38.756020: step 1066, loss = 0.76454 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:48:39.520053 ops/training.py:65 2019-01-16 11:48:39.520024: step 1067, loss = 0.75397 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:48:40.284124 ops/training.py:65 2019-01-16 11:48:40.284089: step 1068, loss = 0.73425 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:48:41.048771 ops/training.py:65 2019-01-16 11:48:41.048742: step 1069, loss = 0.67092 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:48:41.814424 ops/training.py:65 2019-01-16 11:48:41.814380: step 1070, loss = 0.67260 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:48:42.581801 ops/training.py:65 2019-01-16 11:48:42.581769: step 1071, loss = 0.80206 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:48:43.348876 ops/training.py:65 2019-01-16 11:48:43.348846: step 1072, loss = 0.69864 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:48:44.115409 ops/training.py:65 2019-01-16 11:48:44.115349: step 1073, loss = 0.72371 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:48:44.881370 ops/training.py:65 2019-01-16 11:48:44.881295: step 1074, loss = 0.74407 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:48:45.648579 ops/training.py:65 2019-01-16 11:48:45.648539: step 1075, loss = 0.75086 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:48:46.414931 ops/training.py:65 2019-01-16 11:48:46.414869: step 1076, loss = 0.72794 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:48:47.181697 ops/training.py:65 2019-01-16 11:48:47.181642: step 1077, loss = 0.68364 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:48:47.948595 ops/training.py:65 2019-01-16 11:48:47.948541: step 1078, loss = 0.71714 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:48:48.715061 ops/training.py:65 2019-01-16 11:48:48.714995: step 1079, loss = 0.71091 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:48:49.483900 ops/training.py:65 2019-01-16 11:48:49.483845: step 1080, loss = 0.82697 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:48:50.250344 ops/training.py:65 2019-01-16 11:48:50.250312: step 1081, loss = 0.73806 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:48:51.016992 ops/training.py:65 2019-01-16 11:48:51.016961: step 1082, loss = 0.77322 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:48:51.781014 ops/training.py:65 2019-01-16 11:48:51.780981: step 1083, loss = 0.75631 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:48:52.546669 ops/training.py:65 2019-01-16 11:48:52.546642: step 1084, loss = 0.72756 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:48:53.313392 ops/training.py:65 2019-01-16 11:48:53.313358: step 1085, loss = 0.71926 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:48:54.079136 ops/training.py:65 2019-01-16 11:48:54.079108: step 1086, loss = 0.73586 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:48:54.843757 ops/training.py:65 2019-01-16 11:48:54.843728: step 1087, loss = 0.68707 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:48:55.609276 ops/training.py:65 2019-01-16 11:48:55.609239: step 1088, loss = 0.68477 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:48:56.375354 ops/training.py:65 2019-01-16 11:48:56.375325: step 1089, loss = 0.76819 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:48:57.141724 ops/training.py:65 2019-01-16 11:48:57.141689: step 1090, loss = 0.70677 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:48:57.907403 ops/training.py:65 2019-01-16 11:48:57.907366: step 1091, loss = 0.70402 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:48:58.672911 ops/training.py:65 2019-01-16 11:48:58.672854: step 1092, loss = 0.71517 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:48:59.441231 ops/training.py:65 2019-01-16 11:48:59.441193: step 1093, loss = 0.75391 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:49:00.207331 ops/training.py:65 2019-01-16 11:49:00.207270: step 1094, loss = 0.69504 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:49:00.973353 ops/training.py:65 2019-01-16 11:49:00.973295: step 1095, loss = 0.60580 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:49:01.738270 ops/training.py:65 2019-01-16 11:49:01.738223: step 1096, loss = 0.73946 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:49:02.503249 ops/training.py:65 2019-01-16 11:49:02.503208: step 1097, loss = 0.66845 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:49:03.269351 ops/training.py:65 2019-01-16 11:49:03.269310: step 1098, loss = 0.67158 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:49:04.035782 ops/training.py:65 2019-01-16 11:49:04.035731: step 1099, loss = 0.77829 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:49:04.800618 ops/training.py:65 2019-01-16 11:49:04.800552: step 1100, loss = 0.74890 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:49:05.565245 ops/training.py:65 2019-01-16 11:49:05.565177: step 1101, loss = 0.66843 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:49:06.330122 ops/training.py:65 2019-01-16 11:49:06.330050: step 1102, loss = 0.74885 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:49:07.093990 ops/training.py:65 2019-01-16 11:49:07.093922: step 1103, loss = 0.72481 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:49:07.861596 ops/training.py:65 2019-01-16 11:49:07.861541: step 1104, loss = 0.70123 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:49:08.626186 ops/training.py:65 2019-01-16 11:49:08.626139: step 1105, loss = 0.69528 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:49:09.391207 ops/training.py:65 2019-01-16 11:49:09.391155: step 1106, loss = 0.70278 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:49:10.158534 ops/training.py:65 2019-01-16 11:49:10.158478: step 1107, loss = 0.72496 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:49:10.924752 ops/training.py:65 2019-01-16 11:49:10.924703: step 1108, loss = 0.70395 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:49:11.691921 ops/training.py:65 2019-01-16 11:49:11.691854: step 1109, loss = 0.73498 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:49:12.457626 ops/training.py:65 2019-01-16 11:49:12.457573: step 1110, loss = 0.72668 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:49:13.222310 ops/training.py:65 2019-01-16 11:49:13.222249: step 1111, loss = 0.70860 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:49:13.986659 ops/training.py:65 2019-01-16 11:49:13.986616: step 1112, loss = 0.70944 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:49:14.751628 ops/training.py:65 2019-01-16 11:49:14.751578: step 1113, loss = 0.74535 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:49:15.516351 ops/training.py:65 2019-01-16 11:49:15.516284: step 1114, loss = 0.70354 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:49:16.280514 ops/training.py:65 2019-01-16 11:49:16.280455: step 1115, loss = 0.75264 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:49:17.045790 ops/training.py:65 2019-01-16 11:49:17.045740: step 1116, loss = 0.76867 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 11:49:17.810985 ops/training.py:65 2019-01-16 11:49:17.810935: step 1117, loss = 0.71405 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:49:18.575605 ops/training.py:65 2019-01-16 11:49:18.575549: step 1118, loss = 0.74599 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:49:19.340437 ops/training.py:65 2019-01-16 11:49:19.340387: step 1119, loss = 0.75670 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:49:20.105704 ops/training.py:65 2019-01-16 11:49:20.105647: step 1120, loss = 0.70929 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:49:20.871373 ops/training.py:65 2019-01-16 11:49:20.871307: step 1121, loss = 0.76894 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:49:21.636206 ops/training.py:65 2019-01-16 11:49:21.636135: step 1122, loss = 0.74322 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:49:22.401357 ops/training.py:65 2019-01-16 11:49:22.401298: step 1123, loss = 0.78281 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:49:23.166097 ops/training.py:65 2019-01-16 11:49:23.166036: step 1124, loss = 0.69946 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:49:23.934018 ops/training.py:65 2019-01-16 11:49:23.933955: step 1125, loss = 0.82454 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:49:24.697836 ops/training.py:65 2019-01-16 11:49:24.697763: step 1126, loss = 0.72017 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:49:25.464046 ops/training.py:65 2019-01-16 11:49:25.463982: step 1127, loss = 0.69977 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:49:26.229864 ops/training.py:65 2019-01-16 11:49:26.229810: step 1128, loss = 0.69203 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:49:26.995225 ops/training.py:65 2019-01-16 11:49:26.995165: step 1129, loss = 0.73086 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:49:27.762045 ops/training.py:65 2019-01-16 11:49:27.761984: step 1130, loss = 0.76906 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.25
I0528 2019-01-16 11:49:28.528107 ops/training.py:65 2019-01-16 11:49:28.528037: step 1131, loss = 0.75386 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:49:29.295069 ops/training.py:65 2019-01-16 11:49:29.295000: step 1132, loss = 0.68030 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:49:30.060532 ops/training.py:65 2019-01-16 11:49:30.060476: step 1133, loss = 0.75850 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:49:30.824455 ops/training.py:65 2019-01-16 11:49:30.824385: step 1134, loss = 0.68604 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:49:31.592893 ops/training.py:65 2019-01-16 11:49:31.592839: step 1135, loss = 0.71502 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:49:32.359158 ops/training.py:65 2019-01-16 11:49:32.359101: step 1136, loss = 0.69925 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:49:33.125618 ops/training.py:65 2019-01-16 11:49:33.125575: step 1137, loss = 0.69037 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:49:33.892919 ops/training.py:65 2019-01-16 11:49:33.892882: step 1138, loss = 0.70883 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:49:34.661035 ops/training.py:65 2019-01-16 11:49:34.660993: step 1139, loss = 0.71150 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:49:35.450686 ops/training.py:65 2019-01-16 11:49:35.450649: step 1140, loss = 0.73425 (40.6 examples/sec; 0.789 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:49:36.217485 ops/training.py:65 2019-01-16 11:49:36.217450: step 1141, loss = 0.73312 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:49:36.984667 ops/training.py:65 2019-01-16 11:49:36.984632: step 1142, loss = 0.69493 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:49:37.750377 ops/training.py:65 2019-01-16 11:49:37.750340: step 1143, loss = 0.70540 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:49:38.518073 ops/training.py:65 2019-01-16 11:49:38.518043: step 1144, loss = 0.64196 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:49:39.282724 ops/training.py:65 2019-01-16 11:49:39.282667: step 1145, loss = 0.73879 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:49:40.049509 ops/training.py:65 2019-01-16 11:49:40.049463: step 1146, loss = 0.70256 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:49:40.813602 ops/training.py:65 2019-01-16 11:49:40.813554: step 1147, loss = 0.73161 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:49:41.577971 ops/training.py:65 2019-01-16 11:49:41.577910: step 1148, loss = 0.74784 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:49:42.342677 ops/training.py:65 2019-01-16 11:49:42.342624: step 1149, loss = 0.73946 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:49:43.107175 ops/training.py:65 2019-01-16 11:49:43.107116: step 1150, loss = 0.66804 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:49:43.872114 ops/training.py:65 2019-01-16 11:49:43.872074: step 1151, loss = 0.71682 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:49:44.636047 ops/training.py:65 2019-01-16 11:49:44.635995: step 1152, loss = 0.69137 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:49:45.400007 ops/training.py:65 2019-01-16 11:49:45.399944: step 1153, loss = 0.63431 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:49:46.166398 ops/training.py:65 2019-01-16 11:49:46.166357: step 1154, loss = 0.72875 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:49:46.933461 ops/training.py:65 2019-01-16 11:49:46.933423: step 1155, loss = 0.70329 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:49:47.698720 ops/training.py:65 2019-01-16 11:49:47.698670: step 1156, loss = 0.69923 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:49:48.464048 ops/training.py:65 2019-01-16 11:49:48.463978: step 1157, loss = 0.75062 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:49:49.229294 ops/training.py:65 2019-01-16 11:49:49.229223: step 1158, loss = 0.67009 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:49:49.993771 ops/training.py:65 2019-01-16 11:49:49.993727: step 1159, loss = 0.75859 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:49:50.757976 ops/training.py:65 2019-01-16 11:49:50.757911: step 1160, loss = 0.70044 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:49:51.522573 ops/training.py:65 2019-01-16 11:49:51.522513: step 1161, loss = 0.68557 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:49:52.286428 ops/training.py:65 2019-01-16 11:49:52.286357: step 1162, loss = 0.59372 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.75
I0528 2019-01-16 11:49:53.050815 ops/training.py:65 2019-01-16 11:49:53.050746: step 1163, loss = 0.72798 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:49:53.815826 ops/training.py:65 2019-01-16 11:49:53.815749: step 1164, loss = 0.74423 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:49:54.581598 ops/training.py:65 2019-01-16 11:49:54.581522: step 1165, loss = 0.65429 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:49:55.346149 ops/training.py:65 2019-01-16 11:49:55.346079: step 1166, loss = 0.63975 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:49:56.110683 ops/training.py:65 2019-01-16 11:49:56.110625: step 1167, loss = 0.76751 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:49:56.877748 ops/training.py:65 2019-01-16 11:49:56.877691: step 1168, loss = 0.65229 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:49:57.645566 ops/training.py:65 2019-01-16 11:49:57.645512: step 1169, loss = 0.66733 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:49:58.412344 ops/training.py:65 2019-01-16 11:49:58.412270: step 1170, loss = 0.61035 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:49:59.178121 ops/training.py:65 2019-01-16 11:49:59.178062: step 1171, loss = 0.70836 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:49:59.943653 ops/training.py:65 2019-01-16 11:49:59.943594: step 1172, loss = 0.62763 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:50:00.708142 ops/training.py:65 2019-01-16 11:50:00.708069: step 1173, loss = 0.77645 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:50:01.474118 ops/training.py:65 2019-01-16 11:50:01.474054: step 1174, loss = 0.77356 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:50:02.239439 ops/training.py:65 2019-01-16 11:50:02.239382: step 1175, loss = 0.72828 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:50:03.007282 ops/training.py:65 2019-01-16 11:50:03.007229: step 1176, loss = 0.66180 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 11:50:03.775187 ops/training.py:65 2019-01-16 11:50:03.775112: step 1177, loss = 0.67894 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:50:04.540843 ops/training.py:65 2019-01-16 11:50:04.540773: step 1178, loss = 0.75987 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:50:05.305310 ops/training.py:65 2019-01-16 11:50:05.305253: step 1179, loss = 0.72874 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:50:06.069702 ops/training.py:65 2019-01-16 11:50:06.069648: step 1180, loss = 0.72570 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:50:06.832772 ops/training.py:65 2019-01-16 11:50:06.832714: step 1181, loss = 0.80544 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:50:07.596797 ops/training.py:65 2019-01-16 11:50:07.596745: step 1182, loss = 0.71241 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:50:08.362946 ops/training.py:65 2019-01-16 11:50:08.362885: step 1183, loss = 0.67805 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:50:09.128661 ops/training.py:65 2019-01-16 11:50:09.128605: step 1184, loss = 0.80403 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 11:50:09.894817 ops/training.py:65 2019-01-16 11:50:09.894762: step 1185, loss = 0.75858 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:50:10.662083 ops/training.py:65 2019-01-16 11:50:10.662015: step 1186, loss = 0.81673 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:50:11.428851 ops/training.py:65 2019-01-16 11:50:11.428783: step 1187, loss = 0.73469 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:50:12.195687 ops/training.py:65 2019-01-16 11:50:12.195619: step 1188, loss = 0.72743 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:50:12.962931 ops/training.py:65 2019-01-16 11:50:12.962888: step 1189, loss = 0.73385 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:50:13.730569 ops/training.py:65 2019-01-16 11:50:13.730492: step 1190, loss = 0.71564 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:50:14.498027 ops/training.py:65 2019-01-16 11:50:14.497956: step 1191, loss = 0.73904 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:50:15.265089 ops/training.py:65 2019-01-16 11:50:15.265016: step 1192, loss = 0.66889 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:50:16.029779 ops/training.py:65 2019-01-16 11:50:16.029724: step 1193, loss = 0.74099 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:50:16.793427 ops/training.py:65 2019-01-16 11:50:16.793377: step 1194, loss = 0.69673 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:50:17.558239 ops/training.py:65 2019-01-16 11:50:17.558186: step 1195, loss = 0.74140 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:50:18.322391 ops/training.py:65 2019-01-16 11:50:18.322335: step 1196, loss = 0.67924 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:50:19.085362 ops/training.py:65 2019-01-16 11:50:19.085300: step 1197, loss = 0.65455 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:50:19.849856 ops/training.py:65 2019-01-16 11:50:19.849801: step 1198, loss = 0.74817 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:50:20.613522 ops/training.py:65 2019-01-16 11:50:20.613472: step 1199, loss = 0.82893 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:50:21.377692 ops/training.py:65 2019-01-16 11:50:21.377631: step 1200, loss = 0.67213 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:50:22.142357 ops/training.py:65 2019-01-16 11:50:22.142296: step 1201, loss = 0.73929 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:50:22.906919 ops/training.py:65 2019-01-16 11:50:22.906866: step 1202, loss = 0.65742 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:50:23.672241 ops/training.py:65 2019-01-16 11:50:23.672182: step 1203, loss = 0.68357 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:50:24.437917 ops/training.py:65 2019-01-16 11:50:24.437850: step 1204, loss = 0.68607 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:50:25.203413 ops/training.py:65 2019-01-16 11:50:25.203362: step 1205, loss = 0.76515 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:50:25.970897 ops/training.py:65 2019-01-16 11:50:25.970844: step 1206, loss = 0.79282 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:50:26.739508 ops/training.py:65 2019-01-16 11:50:26.739434: step 1207, loss = 0.72987 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:50:27.506599 ops/training.py:65 2019-01-16 11:50:27.506528: step 1208, loss = 0.69223 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:50:28.273837 ops/training.py:65 2019-01-16 11:50:28.273762: step 1209, loss = 0.69341 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:50:29.042033 ops/training.py:65 2019-01-16 11:50:29.041965: step 1210, loss = 0.71587 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:50:29.808119 ops/training.py:65 2019-01-16 11:50:29.808057: step 1211, loss = 0.70334 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:50:30.574944 ops/training.py:65 2019-01-16 11:50:30.574875: step 1212, loss = 0.64278 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:50:31.342426 ops/training.py:65 2019-01-16 11:50:31.342355: step 1213, loss = 0.65601 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:50:32.109747 ops/training.py:65 2019-01-16 11:50:32.109677: step 1214, loss = 0.67097 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:50:32.875020 ops/training.py:65 2019-01-16 11:50:32.874947: step 1215, loss = 0.72727 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:50:33.640775 ops/training.py:65 2019-01-16 11:50:33.640702: step 1216, loss = 0.76208 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:50:34.406008 ops/training.py:65 2019-01-16 11:50:34.405939: step 1217, loss = 0.70029 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:50:35.171576 ops/training.py:65 2019-01-16 11:50:35.171498: step 1218, loss = 0.69108 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:50:35.937195 ops/training.py:65 2019-01-16 11:50:35.937126: step 1219, loss = 0.74582 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:50:36.702586 ops/training.py:65 2019-01-16 11:50:36.702525: step 1220, loss = 0.70481 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:50:37.466522 ops/training.py:65 2019-01-16 11:50:37.466466: step 1221, loss = 0.66985 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:50:38.230816 ops/training.py:65 2019-01-16 11:50:38.230757: step 1222, loss = 0.75799 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:50:38.995861 ops/training.py:65 2019-01-16 11:50:38.995803: step 1223, loss = 0.69862 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:50:39.761943 ops/training.py:65 2019-01-16 11:50:39.761880: step 1224, loss = 0.76830 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:50:40.527516 ops/training.py:65 2019-01-16 11:50:40.527456: step 1225, loss = 0.71346 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:50:41.293265 ops/training.py:65 2019-01-16 11:50:41.293206: step 1226, loss = 0.70202 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:50:42.058825 ops/training.py:65 2019-01-16 11:50:42.058773: step 1227, loss = 0.66718 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:50:42.824936 ops/training.py:65 2019-01-16 11:50:42.824893: step 1228, loss = 0.69606 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:50:43.594387 ops/training.py:65 2019-01-16 11:50:43.594316: step 1229, loss = 0.75714 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:50:44.362077 ops/training.py:65 2019-01-16 11:50:44.362004: step 1230, loss = 0.76899 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:50:45.128001 ops/training.py:65 2019-01-16 11:50:45.127949: step 1231, loss = 0.77966 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:50:45.892689 ops/training.py:65 2019-01-16 11:50:45.892638: step 1232, loss = 0.71935 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:50:46.656505 ops/training.py:65 2019-01-16 11:50:46.656459: step 1233, loss = 0.73214 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:50:47.420618 ops/training.py:65 2019-01-16 11:50:47.420567: step 1234, loss = 0.74637 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:50:48.185248 ops/training.py:65 2019-01-16 11:50:48.185182: step 1235, loss = 0.72446 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:50:48.949700 ops/training.py:65 2019-01-16 11:50:48.949650: step 1236, loss = 0.75266 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 11:50:49.714449 ops/training.py:65 2019-01-16 11:50:49.714396: step 1237, loss = 0.71634 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:50:50.480367 ops/training.py:65 2019-01-16 11:50:50.480312: step 1238, loss = 0.76711 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 11:50:51.246302 ops/training.py:65 2019-01-16 11:50:51.246243: step 1239, loss = 0.70483 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:50:52.011272 ops/training.py:65 2019-01-16 11:50:52.011221: step 1240, loss = 0.76522 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:50:52.776277 ops/training.py:65 2019-01-16 11:50:52.776219: step 1241, loss = 0.66795 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:50:53.540317 ops/training.py:65 2019-01-16 11:50:53.540260: step 1242, loss = 0.70714 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:50:54.305163 ops/training.py:65 2019-01-16 11:50:54.305104: step 1243, loss = 0.69573 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:50:55.068680 ops/training.py:65 2019-01-16 11:50:55.068629: step 1244, loss = 0.71671 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:50:55.832229 ops/training.py:65 2019-01-16 11:50:55.832176: step 1245, loss = 0.74302 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:50:56.594622 ops/training.py:65 2019-01-16 11:50:56.594569: step 1246, loss = 0.69991 (42.0 examples/sec; 0.761 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:50:57.358728 ops/training.py:65 2019-01-16 11:50:57.358677: step 1247, loss = 0.64480 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:50:58.122480 ops/training.py:65 2019-01-16 11:50:58.122428: step 1248, loss = 0.67909 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 11:50:58.886669 ops/training.py:65 2019-01-16 11:50:58.886619: step 1249, loss = 0.65847 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:50:59.650534 ops/training.py:65 2019-01-16 11:50:59.650471: step 1250, loss = 0.70390 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:51:00.415144 ops/training.py:65 2019-01-16 11:51:00.415085: step 1251, loss = 0.72018 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:51:01.180243 ops/training.py:65 2019-01-16 11:51:01.180182: step 1252, loss = 0.72643 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:51:01.946299 ops/training.py:65 2019-01-16 11:51:01.946245: step 1253, loss = 0.74903 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:51:02.712643 ops/training.py:65 2019-01-16 11:51:02.712586: step 1254, loss = 0.70048 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:51:03.478482 ops/training.py:65 2019-01-16 11:51:03.478423: step 1255, loss = 0.74808 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:51:04.243416 ops/training.py:65 2019-01-16 11:51:04.243357: step 1256, loss = 0.72562 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:51:05.008188 ops/training.py:65 2019-01-16 11:51:05.008134: step 1257, loss = 0.69700 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:51:05.774194 ops/training.py:65 2019-01-16 11:51:05.774140: step 1258, loss = 0.70855 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:51:06.540531 ops/training.py:65 2019-01-16 11:51:06.540472: step 1259, loss = 0.68214 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:51:07.306718 ops/training.py:65 2019-01-16 11:51:07.306656: step 1260, loss = 0.72779 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:51:08.072037 ops/training.py:65 2019-01-16 11:51:08.071980: step 1261, loss = 0.70287 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:51:08.836394 ops/training.py:65 2019-01-16 11:51:08.836323: step 1262, loss = 0.73843 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:51:09.601996 ops/training.py:65 2019-01-16 11:51:09.601917: step 1263, loss = 0.72691 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:51:10.366912 ops/training.py:65 2019-01-16 11:51:10.366852: step 1264, loss = 0.70403 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:51:11.131732 ops/training.py:65 2019-01-16 11:51:11.131673: step 1265, loss = 0.66938 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:51:11.896340 ops/training.py:65 2019-01-16 11:51:11.896284: step 1266, loss = 0.70247 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:51:12.661270 ops/training.py:65 2019-01-16 11:51:12.661225: step 1267, loss = 0.71462 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:51:13.427112 ops/training.py:65 2019-01-16 11:51:13.427055: step 1268, loss = 0.75601 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:51:14.192424 ops/training.py:65 2019-01-16 11:51:14.192367: step 1269, loss = 0.71058 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:51:14.957390 ops/training.py:65 2019-01-16 11:51:14.957336: step 1270, loss = 0.73338 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:51:15.721953 ops/training.py:65 2019-01-16 11:51:15.721892: step 1271, loss = 0.62539 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 11:51:16.487392 ops/training.py:65 2019-01-16 11:51:16.487335: step 1272, loss = 0.71422 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:51:17.253086 ops/training.py:65 2019-01-16 11:51:17.253034: step 1273, loss = 0.78258 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:51:18.017949 ops/training.py:65 2019-01-16 11:51:18.017889: step 1274, loss = 0.71840 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:51:18.783529 ops/training.py:65 2019-01-16 11:51:18.783480: step 1275, loss = 0.71835 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:51:19.549012 ops/training.py:65 2019-01-16 11:51:19.548958: step 1276, loss = 0.73132 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:51:20.314840 ops/training.py:65 2019-01-16 11:51:20.314783: step 1277, loss = 0.77116 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:51:21.079516 ops/training.py:65 2019-01-16 11:51:21.079458: step 1278, loss = 0.70321 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:51:21.843770 ops/training.py:65 2019-01-16 11:51:21.843718: step 1279, loss = 0.62601 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 11:51:22.607588 ops/training.py:65 2019-01-16 11:51:22.607534: step 1280, loss = 0.73706 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:51:23.373067 ops/training.py:65 2019-01-16 11:51:23.373011: step 1281, loss = 0.70097 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:51:24.138631 ops/training.py:65 2019-01-16 11:51:24.138580: step 1282, loss = 0.71973 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:51:24.904655 ops/training.py:65 2019-01-16 11:51:24.904601: step 1283, loss = 0.74479 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 11:51:25.671702 ops/training.py:65 2019-01-16 11:51:25.671650: step 1284, loss = 0.71768 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:51:26.438674 ops/training.py:65 2019-01-16 11:51:26.438606: step 1285, loss = 0.73590 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:51:27.206424 ops/training.py:65 2019-01-16 11:51:27.206352: step 1286, loss = 0.70889 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:51:27.974159 ops/training.py:65 2019-01-16 11:51:27.974090: step 1287, loss = 0.73401 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:51:28.741313 ops/training.py:65 2019-01-16 11:51:28.741250: step 1288, loss = 0.69284 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:51:29.508395 ops/training.py:65 2019-01-16 11:51:29.508323: step 1289, loss = 0.67288 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:51:30.275513 ops/training.py:65 2019-01-16 11:51:30.275440: step 1290, loss = 0.71085 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:51:31.043580 ops/training.py:65 2019-01-16 11:51:31.043508: step 1291, loss = 0.69745 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:51:31.813734 ops/training.py:65 2019-01-16 11:51:31.813673: step 1292, loss = 0.71587 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:51:32.581813 ops/training.py:65 2019-01-16 11:51:32.581737: step 1293, loss = 0.77936 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:51:33.349431 ops/training.py:65 2019-01-16 11:51:33.349374: step 1294, loss = 0.73730 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:51:34.115453 ops/training.py:65 2019-01-16 11:51:34.115399: step 1295, loss = 0.70950 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:51:34.881159 ops/training.py:65 2019-01-16 11:51:34.881107: step 1296, loss = 0.70930 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:51:35.649218 ops/training.py:65 2019-01-16 11:51:35.649140: step 1297, loss = 0.74786 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:51:36.416796 ops/training.py:65 2019-01-16 11:51:36.416721: step 1298, loss = 0.72238 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:51:37.183797 ops/training.py:65 2019-01-16 11:51:37.183720: step 1299, loss = 0.70674 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:51:37.951104 ops/training.py:65 2019-01-16 11:51:37.951043: step 1300, loss = 0.70719 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:51:38.720377 ops/training.py:65 2019-01-16 11:51:38.720312: step 1301, loss = 0.68850 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:51:39.486959 ops/training.py:65 2019-01-16 11:51:39.486887: step 1302, loss = 0.69302 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:51:40.251715 ops/training.py:65 2019-01-16 11:51:40.251660: step 1303, loss = 0.74589 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:51:41.015211 ops/training.py:65 2019-01-16 11:51:41.015151: step 1304, loss = 0.76355 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:51:41.780910 ops/training.py:65 2019-01-16 11:51:41.780852: step 1305, loss = 0.75956 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:51:42.546339 ops/training.py:65 2019-01-16 11:51:42.546284: step 1306, loss = 0.70259 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:51:43.312349 ops/training.py:65 2019-01-16 11:51:43.312291: step 1307, loss = 0.74118 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:51:44.079209 ops/training.py:65 2019-01-16 11:51:44.079138: step 1308, loss = 0.67002 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:51:44.847654 ops/training.py:65 2019-01-16 11:51:44.847579: step 1309, loss = 0.71491 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:51:45.615105 ops/training.py:65 2019-01-16 11:51:45.615024: step 1310, loss = 0.69692 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:51:46.385847 ops/training.py:65 2019-01-16 11:51:46.385766: step 1311, loss = 0.68386 (41.6 examples/sec; 0.770 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:51:47.153409 ops/training.py:65 2019-01-16 11:51:47.153354: step 1312, loss = 0.73112 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:51:47.920847 ops/training.py:65 2019-01-16 11:51:47.920770: step 1313, loss = 0.70365 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:51:48.686454 ops/training.py:65 2019-01-16 11:51:48.686389: step 1314, loss = 0.75315 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:51:49.453437 ops/training.py:65 2019-01-16 11:51:49.453379: step 1315, loss = 0.72398 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:51:50.219486 ops/training.py:65 2019-01-16 11:51:50.219430: step 1316, loss = 0.71706 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:51:50.985336 ops/training.py:65 2019-01-16 11:51:50.985280: step 1317, loss = 0.72236 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:51:51.752066 ops/training.py:65 2019-01-16 11:51:51.752007: step 1318, loss = 0.75198 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 11:51:52.517512 ops/training.py:65 2019-01-16 11:51:52.517456: step 1319, loss = 0.70313 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:51:53.283975 ops/training.py:65 2019-01-16 11:51:53.283920: step 1320, loss = 0.67823 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:51:54.050126 ops/training.py:65 2019-01-16 11:51:54.050072: step 1321, loss = 0.76843 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:51:54.815048 ops/training.py:65 2019-01-16 11:51:54.814992: step 1322, loss = 0.79442 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:51:55.579913 ops/training.py:65 2019-01-16 11:51:55.579857: step 1323, loss = 0.77357 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:51:56.345296 ops/training.py:65 2019-01-16 11:51:56.345238: step 1324, loss = 0.72141 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:51:57.111047 ops/training.py:65 2019-01-16 11:51:57.110991: step 1325, loss = 0.66461 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:51:57.875916 ops/training.py:65 2019-01-16 11:51:57.875869: step 1326, loss = 0.72537 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:51:58.640113 ops/training.py:65 2019-01-16 11:51:58.640058: step 1327, loss = 0.66643 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:51:59.403779 ops/training.py:65 2019-01-16 11:51:59.403726: step 1328, loss = 0.77015 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:52:00.167779 ops/training.py:65 2019-01-16 11:52:00.167725: step 1329, loss = 0.64475 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:52:00.933097 ops/training.py:65 2019-01-16 11:52:00.933041: step 1330, loss = 0.65068 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:52:01.698887 ops/training.py:65 2019-01-16 11:52:01.698844: step 1331, loss = 0.74660 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:52:02.465420 ops/training.py:65 2019-01-16 11:52:02.465349: step 1332, loss = 0.76461 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:52:03.232330 ops/training.py:65 2019-01-16 11:52:03.232257: step 1333, loss = 0.64005 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:52:04.001402 ops/training.py:65 2019-01-16 11:52:04.001329: step 1334, loss = 0.68253 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:52:04.769446 ops/training.py:65 2019-01-16 11:52:04.769373: step 1335, loss = 0.60801 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.75
I0528 2019-01-16 11:52:05.536454 ops/training.py:65 2019-01-16 11:52:05.536403: step 1336, loss = 0.73394 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:52:06.302392 ops/training.py:65 2019-01-16 11:52:06.302323: step 1337, loss = 0.75124 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:52:07.068424 ops/training.py:65 2019-01-16 11:52:07.068351: step 1338, loss = 0.75986 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:52:07.835051 ops/training.py:65 2019-01-16 11:52:07.834978: step 1339, loss = 0.63533 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:52:08.600764 ops/training.py:65 2019-01-16 11:52:08.600687: step 1340, loss = 0.71072 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:52:09.366276 ops/training.py:65 2019-01-16 11:52:09.366197: step 1341, loss = 0.75831 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:52:10.131530 ops/training.py:65 2019-01-16 11:52:10.131455: step 1342, loss = 0.64138 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:52:10.894409 ops/training.py:65 2019-01-16 11:52:10.894336: step 1343, loss = 0.74582 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:52:11.658285 ops/training.py:65 2019-01-16 11:52:11.658203: step 1344, loss = 0.72865 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:52:12.424746 ops/training.py:65 2019-01-16 11:52:12.424670: step 1345, loss = 0.72342 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:52:13.192993 ops/training.py:65 2019-01-16 11:52:13.192924: step 1346, loss = 0.75184 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:52:13.959645 ops/training.py:65 2019-01-16 11:52:13.959573: step 1347, loss = 0.72628 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:52:14.725600 ops/training.py:65 2019-01-16 11:52:14.725526: step 1348, loss = 0.69988 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:52:15.493271 ops/training.py:65 2019-01-16 11:52:15.493201: step 1349, loss = 0.77999 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:52:16.259625 ops/training.py:65 2019-01-16 11:52:16.259550: step 1350, loss = 0.74294 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:52:17.027301 ops/training.py:65 2019-01-16 11:52:17.027226: step 1351, loss = 0.72609 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:52:17.794118 ops/training.py:65 2019-01-16 11:52:17.794047: step 1352, loss = 0.73986 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:52:18.558276 ops/training.py:65 2019-01-16 11:52:18.558227: step 1353, loss = 0.73521 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:52:19.323247 ops/training.py:65 2019-01-16 11:52:19.323193: step 1354, loss = 0.68648 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:52:20.088921 ops/training.py:65 2019-01-16 11:52:20.088867: step 1355, loss = 0.72943 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:52:20.854630 ops/training.py:65 2019-01-16 11:52:20.854575: step 1356, loss = 0.73279 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:52:21.618865 ops/training.py:65 2019-01-16 11:52:21.618813: step 1357, loss = 0.68217 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:52:22.383053 ops/training.py:65 2019-01-16 11:52:22.382998: step 1358, loss = 0.74620 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:52:23.148782 ops/training.py:65 2019-01-16 11:52:23.148727: step 1359, loss = 0.75910 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:52:23.914802 ops/training.py:65 2019-01-16 11:52:23.914761: step 1360, loss = 0.67175 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:52:24.680266 ops/training.py:65 2019-01-16 11:52:24.680212: step 1361, loss = 0.74605 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:52:25.444340 ops/training.py:65 2019-01-16 11:52:25.444285: step 1362, loss = 0.70228 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:52:26.209763 ops/training.py:65 2019-01-16 11:52:26.209692: step 1363, loss = 0.66675 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:52:26.973937 ops/training.py:65 2019-01-16 11:52:26.973862: step 1364, loss = 0.75470 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:52:27.739234 ops/training.py:65 2019-01-16 11:52:27.739179: step 1365, loss = 0.73126 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:52:28.506150 ops/training.py:65 2019-01-16 11:52:28.506074: step 1366, loss = 0.73290 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:52:29.273308 ops/training.py:65 2019-01-16 11:52:29.273232: step 1367, loss = 0.75412 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:52:30.041655 ops/training.py:65 2019-01-16 11:52:30.041581: step 1368, loss = 0.68777 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:52:30.808402 ops/training.py:65 2019-01-16 11:52:30.808344: step 1369, loss = 0.74403 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:52:31.574548 ops/training.py:65 2019-01-16 11:52:31.574494: step 1370, loss = 0.70971 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:52:32.339519 ops/training.py:65 2019-01-16 11:52:32.339461: step 1371, loss = 0.68748 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:52:33.104173 ops/training.py:65 2019-01-16 11:52:33.104112: step 1372, loss = 0.68281 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:52:33.868560 ops/training.py:65 2019-01-16 11:52:33.868503: step 1373, loss = 0.64137 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:52:34.632977 ops/training.py:65 2019-01-16 11:52:34.632920: step 1374, loss = 0.72493 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:52:35.397256 ops/training.py:65 2019-01-16 11:52:35.397205: step 1375, loss = 0.68913 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:52:36.161610 ops/training.py:65 2019-01-16 11:52:36.161555: step 1376, loss = 0.70750 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:52:36.926567 ops/training.py:65 2019-01-16 11:52:36.926516: step 1377, loss = 0.72527 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:52:37.690340 ops/training.py:65 2019-01-16 11:52:37.690286: step 1378, loss = 0.68097 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:52:38.459136 ops/training.py:65 2019-01-16 11:52:38.459085: step 1379, loss = 0.68613 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:52:39.226173 ops/training.py:65 2019-01-16 11:52:39.226123: step 1380, loss = 0.68437 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:52:39.994956 ops/training.py:65 2019-01-16 11:52:39.994891: step 1381, loss = 0.68493 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:52:40.760493 ops/training.py:65 2019-01-16 11:52:40.760436: step 1382, loss = 0.71489 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:52:41.525201 ops/training.py:65 2019-01-16 11:52:41.525146: step 1383, loss = 0.75211 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:52:42.288637 ops/training.py:65 2019-01-16 11:52:42.288579: step 1384, loss = 0.69976 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:52:43.055761 ops/training.py:65 2019-01-16 11:52:43.055725: step 1385, loss = 0.68450 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:52:43.825086 ops/training.py:65 2019-01-16 11:52:43.825055: step 1386, loss = 0.71652 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:52:44.591129 ops/training.py:65 2019-01-16 11:52:44.591101: step 1387, loss = 0.69622 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:52:45.360542 ops/training.py:65 2019-01-16 11:52:45.360513: step 1388, loss = 0.72818 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:52:46.128107 ops/training.py:65 2019-01-16 11:52:46.128078: step 1389, loss = 0.73229 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:52:46.894649 ops/training.py:65 2019-01-16 11:52:46.894620: step 1390, loss = 0.60977 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.8125
I0528 2019-01-16 11:52:47.662296 ops/training.py:65 2019-01-16 11:52:47.662268: step 1391, loss = 0.70114 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:52:48.435144 ops/training.py:65 2019-01-16 11:52:48.435115: step 1392, loss = 0.75159 (41.4 examples/sec; 0.772 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:52:49.200334 ops/training.py:65 2019-01-16 11:52:49.200306: step 1393, loss = 0.73235 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:52:49.965176 ops/training.py:65 2019-01-16 11:52:49.965112: step 1394, loss = 0.69824 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:52:50.729335 ops/training.py:65 2019-01-16 11:52:50.729283: step 1395, loss = 0.75540 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:52:51.493849 ops/training.py:65 2019-01-16 11:52:51.493791: step 1396, loss = 0.74886 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:52:52.258433 ops/training.py:65 2019-01-16 11:52:52.258381: step 1397, loss = 0.70090 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:52:53.027172 ops/training.py:65 2019-01-16 11:52:53.027115: step 1398, loss = 0.72337 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:52:53.791552 ops/training.py:65 2019-01-16 11:52:53.791483: step 1399, loss = 0.70991 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:52:54.555718 ops/training.py:65 2019-01-16 11:52:54.555647: step 1400, loss = 0.76117 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:52:55.320616 ops/training.py:65 2019-01-16 11:52:55.320544: step 1401, loss = 0.69351 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:52:56.084669 ops/training.py:65 2019-01-16 11:52:56.084592: step 1402, loss = 0.75679 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:52:56.849709 ops/training.py:65 2019-01-16 11:52:56.849653: step 1403, loss = 0.72919 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:52:57.613883 ops/training.py:65 2019-01-16 11:52:57.613828: step 1404, loss = 0.69374 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:52:58.378835 ops/training.py:65 2019-01-16 11:52:58.378774: step 1405, loss = 0.71452 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:52:59.144977 ops/training.py:65 2019-01-16 11:52:59.144912: step 1406, loss = 0.66465 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:52:59.910504 ops/training.py:65 2019-01-16 11:52:59.910450: step 1407, loss = 0.71113 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:53:00.676104 ops/training.py:65 2019-01-16 11:53:00.676050: step 1408, loss = 0.67412 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:53:01.442660 ops/training.py:65 2019-01-16 11:53:01.442590: step 1409, loss = 0.68094 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:53:02.209172 ops/training.py:65 2019-01-16 11:53:02.209106: step 1410, loss = 0.68502 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:53:02.975352 ops/training.py:65 2019-01-16 11:53:02.975278: step 1411, loss = 0.79681 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 11:53:03.744309 ops/training.py:65 2019-01-16 11:53:03.744233: step 1412, loss = 0.71957 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:53:04.511774 ops/training.py:65 2019-01-16 11:53:04.511691: step 1413, loss = 0.70797 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:53:05.278834 ops/training.py:65 2019-01-16 11:53:05.278781: step 1414, loss = 0.73322 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:53:06.045370 ops/training.py:65 2019-01-16 11:53:06.045323: step 1415, loss = 0.67076 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:53:06.812579 ops/training.py:65 2019-01-16 11:53:06.812532: step 1416, loss = 0.74386 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:53:07.579222 ops/training.py:65 2019-01-16 11:53:07.579165: step 1417, loss = 0.75694 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:53:08.345589 ops/training.py:65 2019-01-16 11:53:08.345539: step 1418, loss = 0.77535 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:53:09.112479 ops/training.py:65 2019-01-16 11:53:09.112415: step 1419, loss = 0.70152 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:53:09.879531 ops/training.py:65 2019-01-16 11:53:09.879461: step 1420, loss = 0.75127 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:53:10.646356 ops/training.py:65 2019-01-16 11:53:10.646282: step 1421, loss = 0.68817 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:53:11.411938 ops/training.py:65 2019-01-16 11:53:11.411864: step 1422, loss = 0.65475 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:53:12.178849 ops/training.py:65 2019-01-16 11:53:12.178785: step 1423, loss = 0.70755 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:53:12.944349 ops/training.py:65 2019-01-16 11:53:12.944298: step 1424, loss = 0.68921 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:53:13.710021 ops/training.py:65 2019-01-16 11:53:13.709942: step 1425, loss = 0.68728 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:53:14.474997 ops/training.py:65 2019-01-16 11:53:14.474938: step 1426, loss = 0.68060 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:53:15.240220 ops/training.py:65 2019-01-16 11:53:15.240161: step 1427, loss = 0.67953 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:53:16.004825 ops/training.py:65 2019-01-16 11:53:16.004772: step 1428, loss = 0.70356 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:53:16.771184 ops/training.py:65 2019-01-16 11:53:16.771141: step 1429, loss = 0.70406 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:53:17.540194 ops/training.py:65 2019-01-16 11:53:17.540107: step 1430, loss = 0.61541 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.78125
I0528 2019-01-16 11:53:18.309593 ops/training.py:65 2019-01-16 11:53:18.309518: step 1431, loss = 0.64382 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:53:19.077395 ops/training.py:65 2019-01-16 11:53:19.077341: step 1432, loss = 0.66879 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:53:19.843071 ops/training.py:65 2019-01-16 11:53:19.843015: step 1433, loss = 0.73574 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:53:20.609594 ops/training.py:65 2019-01-16 11:53:20.609543: step 1434, loss = 0.74114 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:53:21.375647 ops/training.py:65 2019-01-16 11:53:21.375593: step 1435, loss = 0.70943 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:53:22.141081 ops/training.py:65 2019-01-16 11:53:22.141026: step 1436, loss = 0.71863 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:53:22.908060 ops/training.py:65 2019-01-16 11:53:22.908002: step 1437, loss = 0.70461 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:53:23.676538 ops/training.py:65 2019-01-16 11:53:23.676458: step 1438, loss = 0.75721 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:53:24.444279 ops/training.py:65 2019-01-16 11:53:24.444202: step 1439, loss = 0.67741 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:53:25.212995 ops/training.py:65 2019-01-16 11:53:25.212915: step 1440, loss = 0.64797 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 11:53:25.981220 ops/training.py:65 2019-01-16 11:53:25.981142: step 1441, loss = 0.75759 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:53:26.748235 ops/training.py:65 2019-01-16 11:53:26.748162: step 1442, loss = 0.73177 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:53:27.516504 ops/training.py:65 2019-01-16 11:53:27.516427: step 1443, loss = 0.71421 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:53:28.283641 ops/training.py:65 2019-01-16 11:53:28.283576: step 1444, loss = 0.74063 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:53:29.049629 ops/training.py:65 2019-01-16 11:53:29.049577: step 1445, loss = 0.70119 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:53:29.815976 ops/training.py:65 2019-01-16 11:53:29.815923: step 1446, loss = 0.69251 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:53:30.584354 ops/training.py:65 2019-01-16 11:53:30.584281: step 1447, loss = 0.74522 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:53:31.351507 ops/training.py:65 2019-01-16 11:53:31.351431: step 1448, loss = 0.75827 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:53:32.118867 ops/training.py:65 2019-01-16 11:53:32.118816: step 1449, loss = 0.72004 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:53:32.884317 ops/training.py:65 2019-01-16 11:53:32.884258: step 1450, loss = 0.72954 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:53:33.649086 ops/training.py:65 2019-01-16 11:53:33.649008: step 1451, loss = 0.74984 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 11:53:34.414496 ops/training.py:65 2019-01-16 11:53:34.414420: step 1452, loss = 0.75261 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:53:35.181526 ops/training.py:65 2019-01-16 11:53:35.181453: step 1453, loss = 0.72408 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:53:35.947783 ops/training.py:65 2019-01-16 11:53:35.947706: step 1454, loss = 0.71632 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:53:36.715160 ops/training.py:65 2019-01-16 11:53:36.715068: step 1455, loss = 0.68800 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:53:37.480618 ops/training.py:65 2019-01-16 11:53:37.480544: step 1456, loss = 0.78681 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:53:38.247728 ops/training.py:65 2019-01-16 11:53:38.247665: step 1457, loss = 0.71833 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:53:39.014740 ops/training.py:65 2019-01-16 11:53:39.014668: step 1458, loss = 0.74719 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:53:39.781151 ops/training.py:65 2019-01-16 11:53:39.781074: step 1459, loss = 0.64106 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 11:53:40.549524 ops/training.py:65 2019-01-16 11:53:40.549444: step 1460, loss = 0.71520 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:53:41.315193 ops/training.py:65 2019-01-16 11:53:41.315125: step 1461, loss = 0.72193 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:53:42.081666 ops/training.py:65 2019-01-16 11:53:42.081593: step 1462, loss = 0.64283 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:53:42.849532 ops/training.py:65 2019-01-16 11:53:42.849482: step 1463, loss = 0.69225 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:53:43.614477 ops/training.py:65 2019-01-16 11:53:43.614421: step 1464, loss = 0.69683 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:53:44.378704 ops/training.py:65 2019-01-16 11:53:44.378633: step 1465, loss = 0.68166 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:53:45.144894 ops/training.py:65 2019-01-16 11:53:45.144816: step 1466, loss = 0.70881 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:53:45.912035 ops/training.py:65 2019-01-16 11:53:45.911961: step 1467, loss = 0.71544 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:53:46.678444 ops/training.py:65 2019-01-16 11:53:46.678365: step 1468, loss = 0.71356 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:53:47.444688 ops/training.py:65 2019-01-16 11:53:47.444616: step 1469, loss = 0.72858 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:53:48.211299 ops/training.py:65 2019-01-16 11:53:48.211222: step 1470, loss = 0.74706 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:53:48.980647 ops/training.py:65 2019-01-16 11:53:48.980569: step 1471, loss = 0.69388 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:53:49.749107 ops/training.py:65 2019-01-16 11:53:49.749029: step 1472, loss = 0.73983 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:53:50.515018 ops/training.py:65 2019-01-16 11:53:50.514941: step 1473, loss = 0.70819 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:53:51.282008 ops/training.py:65 2019-01-16 11:53:51.281932: step 1474, loss = 0.74335 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:53:52.051265 ops/training.py:65 2019-01-16 11:53:52.051169: step 1475, loss = 0.67517 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:53:52.817349 ops/training.py:65 2019-01-16 11:53:52.817273: step 1476, loss = 0.70607 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:53:53.582797 ops/training.py:65 2019-01-16 11:53:53.582723: step 1477, loss = 0.67642 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:53:54.348282 ops/training.py:65 2019-01-16 11:53:54.348207: step 1478, loss = 0.68597 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:53:55.114470 ops/training.py:65 2019-01-16 11:53:55.114400: step 1479, loss = 0.75210 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:53:55.879629 ops/training.py:65 2019-01-16 11:53:55.879554: step 1480, loss = 0.72242 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:53:56.647545 ops/training.py:65 2019-01-16 11:53:56.647474: step 1481, loss = 0.76222 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:53:57.414076 ops/training.py:65 2019-01-16 11:53:57.414003: step 1482, loss = 0.78186 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:53:58.180098 ops/training.py:65 2019-01-16 11:53:58.180053: step 1483, loss = 0.69280 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:53:58.946956 ops/training.py:65 2019-01-16 11:53:58.946889: step 1484, loss = 0.67707 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:53:59.712216 ops/training.py:65 2019-01-16 11:53:59.712160: step 1485, loss = 0.71325 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:54:00.477317 ops/training.py:65 2019-01-16 11:54:00.477262: step 1486, loss = 0.73500 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:54:01.242474 ops/training.py:65 2019-01-16 11:54:01.242428: step 1487, loss = 0.73883 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:54:02.007354 ops/training.py:65 2019-01-16 11:54:02.007300: step 1488, loss = 0.76025 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:54:02.773178 ops/training.py:65 2019-01-16 11:54:02.773102: step 1489, loss = 0.64644 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:54:03.540076 ops/training.py:65 2019-01-16 11:54:03.540008: step 1490, loss = 0.76054 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:54:04.305893 ops/training.py:65 2019-01-16 11:54:04.305833: step 1491, loss = 0.73050 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:54:05.071466 ops/training.py:65 2019-01-16 11:54:05.071392: step 1492, loss = 0.72955 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:54:05.835845 ops/training.py:65 2019-01-16 11:54:05.835795: step 1493, loss = 0.73928 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:54:06.600550 ops/training.py:65 2019-01-16 11:54:06.600498: step 1494, loss = 0.73351 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:54:07.365347 ops/training.py:65 2019-01-16 11:54:07.365306: step 1495, loss = 0.69339 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:54:08.133839 ops/training.py:65 2019-01-16 11:54:08.133785: step 1496, loss = 0.74790 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:54:08.901758 ops/training.py:65 2019-01-16 11:54:08.901699: step 1497, loss = 0.72157 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:54:09.667420 ops/training.py:65 2019-01-16 11:54:09.667354: step 1498, loss = 0.63038 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 11:54:10.435455 ops/training.py:65 2019-01-16 11:54:10.435383: step 1499, loss = 0.70494 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:54:11.201640 ops/training.py:65 2019-01-16 11:54:11.201575: step 1500, loss = 0.74285 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:54:11.969106 ops/training.py:65 2019-01-16 11:54:11.969040: step 1501, loss = 0.71706 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:54:12.736132 ops/training.py:65 2019-01-16 11:54:12.736087: step 1502, loss = 0.64584 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:54:13.503037 ops/training.py:65 2019-01-16 11:54:13.502977: step 1503, loss = 0.69961 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:54:14.272078 ops/training.py:65 2019-01-16 11:54:14.271999: step 1504, loss = 0.66530 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:54:15.037457 ops/training.py:65 2019-01-16 11:54:15.037394: step 1505, loss = 0.72802 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:54:15.803262 ops/training.py:65 2019-01-16 11:54:15.803218: step 1506, loss = 0.75066 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:54:16.568663 ops/training.py:65 2019-01-16 11:54:16.568621: step 1507, loss = 0.74844 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:54:17.335367 ops/training.py:65 2019-01-16 11:54:17.335315: step 1508, loss = 0.75061 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:54:18.102585 ops/training.py:65 2019-01-16 11:54:18.102513: step 1509, loss = 0.67756 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:54:18.869524 ops/training.py:65 2019-01-16 11:54:18.869473: step 1510, loss = 0.73617 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:54:19.637234 ops/training.py:65 2019-01-16 11:54:19.637171: step 1511, loss = 0.69828 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:54:20.404913 ops/training.py:65 2019-01-16 11:54:20.404851: step 1512, loss = 0.67004 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:54:21.171527 ops/training.py:65 2019-01-16 11:54:21.171465: step 1513, loss = 0.75349 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:54:21.937877 ops/training.py:65 2019-01-16 11:54:21.937831: step 1514, loss = 0.63241 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:54:22.703862 ops/training.py:65 2019-01-16 11:54:22.703804: step 1515, loss = 0.68298 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:54:23.471952 ops/training.py:65 2019-01-16 11:54:23.471891: step 1516, loss = 0.70989 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:54:24.239173 ops/training.py:65 2019-01-16 11:54:24.239111: step 1517, loss = 0.73387 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:54:25.005599 ops/training.py:65 2019-01-16 11:54:25.005535: step 1518, loss = 0.73150 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:54:25.771546 ops/training.py:65 2019-01-16 11:54:25.771473: step 1519, loss = 0.70893 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:54:26.537106 ops/training.py:65 2019-01-16 11:54:26.537044: step 1520, loss = 0.67291 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:54:27.302919 ops/training.py:65 2019-01-16 11:54:27.302854: step 1521, loss = 0.68697 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:54:28.068560 ops/training.py:65 2019-01-16 11:54:28.068495: step 1522, loss = 0.71922 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:54:28.835459 ops/training.py:65 2019-01-16 11:54:28.835399: step 1523, loss = 0.74432 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:54:29.601657 ops/training.py:65 2019-01-16 11:54:29.601581: step 1524, loss = 0.70294 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:54:30.370489 ops/training.py:65 2019-01-16 11:54:30.370424: step 1525, loss = 0.70467 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:54:31.138691 ops/training.py:65 2019-01-16 11:54:31.138619: step 1526, loss = 0.71219 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:54:31.904744 ops/training.py:65 2019-01-16 11:54:31.904705: step 1527, loss = 0.66539 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:54:32.670283 ops/training.py:65 2019-01-16 11:54:32.670214: step 1528, loss = 0.66372 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:54:33.438612 ops/training.py:65 2019-01-16 11:54:33.438553: step 1529, loss = 0.70760 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:54:34.207037 ops/training.py:65 2019-01-16 11:54:34.206966: step 1530, loss = 0.71061 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:54:34.973750 ops/training.py:65 2019-01-16 11:54:34.973695: step 1531, loss = 0.73141 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:54:35.740387 ops/training.py:65 2019-01-16 11:54:35.740321: step 1532, loss = 0.68145 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:54:36.507298 ops/training.py:65 2019-01-16 11:54:36.507221: step 1533, loss = 0.70211 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:54:37.272967 ops/training.py:65 2019-01-16 11:54:37.272890: step 1534, loss = 0.72048 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:54:38.039710 ops/training.py:65 2019-01-16 11:54:38.039648: step 1535, loss = 0.64430 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:54:38.807827 ops/training.py:65 2019-01-16 11:54:38.807763: step 1536, loss = 0.62353 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 11:54:39.573601 ops/training.py:65 2019-01-16 11:54:39.573550: step 1537, loss = 0.71574 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:54:40.339141 ops/training.py:65 2019-01-16 11:54:40.339086: step 1538, loss = 0.67067 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:54:41.105631 ops/training.py:65 2019-01-16 11:54:41.105571: step 1539, loss = 0.72396 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:54:41.872311 ops/training.py:65 2019-01-16 11:54:41.872257: step 1540, loss = 0.65348 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:54:42.638681 ops/training.py:65 2019-01-16 11:54:42.638625: step 1541, loss = 0.78855 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:54:43.403676 ops/training.py:65 2019-01-16 11:54:43.403622: step 1542, loss = 0.73597 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:54:44.168938 ops/training.py:65 2019-01-16 11:54:44.168880: step 1543, loss = 0.72359 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:54:44.932969 ops/training.py:65 2019-01-16 11:54:44.932914: step 1544, loss = 0.74704 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:54:45.700265 ops/training.py:65 2019-01-16 11:54:45.700213: step 1545, loss = 0.72192 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:54:46.466683 ops/training.py:65 2019-01-16 11:54:46.466626: step 1546, loss = 0.77305 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 11:54:47.234182 ops/training.py:65 2019-01-16 11:54:47.234131: step 1547, loss = 0.74107 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:54:48.003083 ops/training.py:65 2019-01-16 11:54:48.003005: step 1548, loss = 0.69402 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:54:48.769369 ops/training.py:65 2019-01-16 11:54:48.769314: step 1549, loss = 0.77200 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:54:49.534991 ops/training.py:65 2019-01-16 11:54:49.534934: step 1550, loss = 0.74929 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:54:50.300375 ops/training.py:65 2019-01-16 11:54:50.300324: step 1551, loss = 0.67854 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:54:51.063799 ops/training.py:65 2019-01-16 11:54:51.063748: step 1552, loss = 0.73705 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:54:51.828324 ops/training.py:65 2019-01-16 11:54:51.828275: step 1553, loss = 0.72466 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:54:52.594676 ops/training.py:65 2019-01-16 11:54:52.594609: step 1554, loss = 0.68740 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:54:53.362895 ops/training.py:65 2019-01-16 11:54:53.362826: step 1555, loss = 0.76346 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:54:54.130827 ops/training.py:65 2019-01-16 11:54:54.130773: step 1556, loss = 0.69111 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:54:54.897656 ops/training.py:65 2019-01-16 11:54:54.897602: step 1557, loss = 0.75956 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:54:55.666430 ops/training.py:65 2019-01-16 11:54:55.666350: step 1558, loss = 0.70749 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:54:56.435258 ops/training.py:65 2019-01-16 11:54:56.435196: step 1559, loss = 0.68288 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:54:57.200420 ops/training.py:65 2019-01-16 11:54:57.200374: step 1560, loss = 0.76429 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:54:57.964710 ops/training.py:65 2019-01-16 11:54:57.964653: step 1561, loss = 0.63005 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:54:58.727661 ops/training.py:65 2019-01-16 11:54:58.727609: step 1562, loss = 0.70485 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:54:59.491208 ops/training.py:65 2019-01-16 11:54:59.491160: step 1563, loss = 0.73880 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:55:00.255277 ops/training.py:65 2019-01-16 11:55:00.255211: step 1564, loss = 0.67877 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:55:01.020131 ops/training.py:65 2019-01-16 11:55:01.020060: step 1565, loss = 0.77727 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:55:01.784735 ops/training.py:65 2019-01-16 11:55:01.784663: step 1566, loss = 0.76645 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:55:02.552514 ops/training.py:65 2019-01-16 11:55:02.552468: step 1567, loss = 0.67244 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:55:03.320650 ops/training.py:65 2019-01-16 11:55:03.320577: step 1568, loss = 0.70656 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:55:04.088127 ops/training.py:65 2019-01-16 11:55:04.088073: step 1569, loss = 0.71197 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:55:04.856193 ops/training.py:65 2019-01-16 11:55:04.856144: step 1570, loss = 0.73590 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:55:05.624912 ops/training.py:65 2019-01-16 11:55:05.624859: step 1571, loss = 0.73869 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:55:06.392168 ops/training.py:65 2019-01-16 11:55:06.392118: step 1572, loss = 0.75922 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:55:07.157267 ops/training.py:65 2019-01-16 11:55:07.157194: step 1573, loss = 0.69445 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:55:07.924314 ops/training.py:65 2019-01-16 11:55:07.924256: step 1574, loss = 0.70560 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:55:08.691372 ops/training.py:65 2019-01-16 11:55:08.691310: step 1575, loss = 0.71316 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:55:09.456586 ops/training.py:65 2019-01-16 11:55:09.456518: step 1576, loss = 0.69627 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:55:10.222880 ops/training.py:65 2019-01-16 11:55:10.222813: step 1577, loss = 0.76484 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:55:10.987043 ops/training.py:65 2019-01-16 11:55:10.986994: step 1578, loss = 0.75942 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:55:11.751224 ops/training.py:65 2019-01-16 11:55:11.751155: step 1579, loss = 0.67159 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:55:12.516372 ops/training.py:65 2019-01-16 11:55:12.516305: step 1580, loss = 0.67092 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:55:13.281727 ops/training.py:65 2019-01-16 11:55:13.281656: step 1581, loss = 0.74172 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:55:14.046067 ops/training.py:65 2019-01-16 11:55:14.046010: step 1582, loss = 0.73388 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:55:14.810250 ops/training.py:65 2019-01-16 11:55:14.810197: step 1583, loss = 0.67692 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:55:15.574921 ops/training.py:65 2019-01-16 11:55:15.574859: step 1584, loss = 0.67211 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:55:16.339077 ops/training.py:65 2019-01-16 11:55:16.339020: step 1585, loss = 0.69182 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:55:17.103780 ops/training.py:65 2019-01-16 11:55:17.103729: step 1586, loss = 0.68317 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:55:17.868018 ops/training.py:65 2019-01-16 11:55:17.867975: step 1587, loss = 0.72662 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:55:18.632363 ops/training.py:65 2019-01-16 11:55:18.632311: step 1588, loss = 0.71726 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:55:19.396722 ops/training.py:65 2019-01-16 11:55:19.396663: step 1589, loss = 0.71807 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:55:20.160902 ops/training.py:65 2019-01-16 11:55:20.160844: step 1590, loss = 0.68464 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:55:20.925126 ops/training.py:65 2019-01-16 11:55:20.925075: step 1591, loss = 0.70588 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:55:21.689397 ops/training.py:65 2019-01-16 11:55:21.689348: step 1592, loss = 0.64962 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:55:22.454199 ops/training.py:65 2019-01-16 11:55:22.454137: step 1593, loss = 0.75937 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:55:23.221455 ops/training.py:65 2019-01-16 11:55:23.221385: step 1594, loss = 0.66949 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:55:23.989609 ops/training.py:65 2019-01-16 11:55:23.989536: step 1595, loss = 0.71444 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:55:24.757869 ops/training.py:65 2019-01-16 11:55:24.757819: step 1596, loss = 0.71906 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:55:25.525510 ops/training.py:65 2019-01-16 11:55:25.525439: step 1597, loss = 0.73404 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:55:26.292276 ops/training.py:65 2019-01-16 11:55:26.292222: step 1598, loss = 0.76485 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 11:55:27.059731 ops/training.py:65 2019-01-16 11:55:27.059663: step 1599, loss = 0.71202 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:55:27.827746 ops/training.py:65 2019-01-16 11:55:27.827682: step 1600, loss = 0.78802 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:55:28.593707 ops/training.py:65 2019-01-16 11:55:28.593657: step 1601, loss = 0.73365 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:55:29.360768 ops/training.py:65 2019-01-16 11:55:29.360726: step 1602, loss = 0.67129 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:55:30.129060 ops/training.py:65 2019-01-16 11:55:30.128993: step 1603, loss = 0.68169 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:55:30.898707 ops/training.py:65 2019-01-16 11:55:30.898635: step 1604, loss = 0.69457 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:55:31.666266 ops/training.py:65 2019-01-16 11:55:31.666200: step 1605, loss = 0.71035 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:55:32.432571 ops/training.py:65 2019-01-16 11:55:32.432517: step 1606, loss = 0.72106 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:55:33.197267 ops/training.py:65 2019-01-16 11:55:33.197219: step 1607, loss = 0.71552 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:55:33.961918 ops/training.py:65 2019-01-16 11:55:33.961860: step 1608, loss = 0.73985 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:55:34.725179 ops/training.py:65 2019-01-16 11:55:34.725113: step 1609, loss = 0.75002 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 11:55:35.488709 ops/training.py:65 2019-01-16 11:55:35.488659: step 1610, loss = 0.71644 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:55:36.252886 ops/training.py:65 2019-01-16 11:55:36.252837: step 1611, loss = 0.66972 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:55:37.015698 ops/training.py:65 2019-01-16 11:55:37.015646: step 1612, loss = 0.67479 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:55:37.779167 ops/training.py:65 2019-01-16 11:55:37.779114: step 1613, loss = 0.67618 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:55:38.542992 ops/training.py:65 2019-01-16 11:55:38.542926: step 1614, loss = 0.77717 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.21875
I0528 2019-01-16 11:55:39.306376 ops/training.py:65 2019-01-16 11:55:39.306317: step 1615, loss = 0.71138 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:55:40.073612 ops/training.py:65 2019-01-16 11:55:40.073540: step 1616, loss = 0.70317 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:55:40.841134 ops/training.py:65 2019-01-16 11:55:40.841061: step 1617, loss = 0.72625 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:55:41.608669 ops/training.py:65 2019-01-16 11:55:41.608621: step 1618, loss = 0.71086 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:55:42.375174 ops/training.py:65 2019-01-16 11:55:42.375114: step 1619, loss = 0.76766 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:55:43.143322 ops/training.py:65 2019-01-16 11:55:43.143264: step 1620, loss = 0.69007 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:55:43.911073 ops/training.py:65 2019-01-16 11:55:43.911005: step 1621, loss = 0.71995 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:55:44.677534 ops/training.py:65 2019-01-16 11:55:44.677452: step 1622, loss = 0.76901 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:55:45.443435 ops/training.py:65 2019-01-16 11:55:45.443386: step 1623, loss = 0.74997 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 11:55:46.211676 ops/training.py:65 2019-01-16 11:55:46.211606: step 1624, loss = 0.71705 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:55:46.979518 ops/training.py:65 2019-01-16 11:55:46.979460: step 1625, loss = 0.71415 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:55:47.748690 ops/training.py:65 2019-01-16 11:55:47.748624: step 1626, loss = 0.71939 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:55:48.517278 ops/training.py:65 2019-01-16 11:55:48.517208: step 1627, loss = 0.70502 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:55:49.286279 ops/training.py:65 2019-01-16 11:55:49.286218: step 1628, loss = 0.76509 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:55:50.054020 ops/training.py:65 2019-01-16 11:55:50.053947: step 1629, loss = 0.68874 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:55:50.822594 ops/training.py:65 2019-01-16 11:55:50.822522: step 1630, loss = 0.68704 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:55:51.589088 ops/training.py:65 2019-01-16 11:55:51.589026: step 1631, loss = 0.69320 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:55:52.357735 ops/training.py:65 2019-01-16 11:55:52.357663: step 1632, loss = 0.67012 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:55:53.126332 ops/training.py:65 2019-01-16 11:55:53.126268: step 1633, loss = 0.70927 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:55:53.894576 ops/training.py:65 2019-01-16 11:55:53.894507: step 1634, loss = 0.71756 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:55:54.664105 ops/training.py:65 2019-01-16 11:55:54.664031: step 1635, loss = 0.74468 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:55:55.433218 ops/training.py:65 2019-01-16 11:55:55.433163: step 1636, loss = 0.67701 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:55:56.198674 ops/training.py:65 2019-01-16 11:55:56.198610: step 1637, loss = 0.69280 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:55:56.962653 ops/training.py:65 2019-01-16 11:55:56.962607: step 1638, loss = 0.72784 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:55:57.729617 ops/training.py:65 2019-01-16 11:55:57.729556: step 1639, loss = 0.74492 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:55:58.497998 ops/training.py:65 2019-01-16 11:55:58.497937: step 1640, loss = 0.68084 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:55:59.266623 ops/training.py:65 2019-01-16 11:55:59.266574: step 1641, loss = 0.68452 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:56:00.033432 ops/training.py:65 2019-01-16 11:56:00.033358: step 1642, loss = 0.71324 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:56:00.797773 ops/training.py:65 2019-01-16 11:56:00.797720: step 1643, loss = 0.71781 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:56:01.561807 ops/training.py:65 2019-01-16 11:56:01.561750: step 1644, loss = 0.65814 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:56:02.326511 ops/training.py:65 2019-01-16 11:56:02.326456: step 1645, loss = 0.71029 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:56:03.090684 ops/training.py:65 2019-01-16 11:56:03.090639: step 1646, loss = 0.72749 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:56:03.854751 ops/training.py:65 2019-01-16 11:56:03.854696: step 1647, loss = 0.73324 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:56:04.619248 ops/training.py:65 2019-01-16 11:56:04.619191: step 1648, loss = 0.76755 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:56:05.384015 ops/training.py:65 2019-01-16 11:56:05.383957: step 1649, loss = 0.69282 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:56:06.150170 ops/training.py:65 2019-01-16 11:56:06.150103: step 1650, loss = 0.71004 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:56:06.917397 ops/training.py:65 2019-01-16 11:56:06.917345: step 1651, loss = 0.71277 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:56:07.684376 ops/training.py:65 2019-01-16 11:56:07.684325: step 1652, loss = 0.73776 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:56:08.451657 ops/training.py:65 2019-01-16 11:56:08.451583: step 1653, loss = 0.70513 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:56:09.217052 ops/training.py:65 2019-01-16 11:56:09.216989: step 1654, loss = 0.73556 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:56:09.984347 ops/training.py:65 2019-01-16 11:56:09.984281: step 1655, loss = 0.68250 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:56:10.753240 ops/training.py:65 2019-01-16 11:56:10.753191: step 1656, loss = 0.72987 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:56:11.523194 ops/training.py:65 2019-01-16 11:56:11.523142: step 1657, loss = 0.74130 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:56:12.292350 ops/training.py:65 2019-01-16 11:56:12.292285: step 1658, loss = 0.67155 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:56:13.061395 ops/training.py:65 2019-01-16 11:56:13.061340: step 1659, loss = 0.65200 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:56:13.830366 ops/training.py:65 2019-01-16 11:56:13.830302: step 1660, loss = 0.75464 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:56:14.597718 ops/training.py:65 2019-01-16 11:56:14.597678: step 1661, loss = 0.69030 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:56:15.364186 ops/training.py:65 2019-01-16 11:56:15.364134: step 1662, loss = 0.75146 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:56:16.130578 ops/training.py:65 2019-01-16 11:56:16.130522: step 1663, loss = 0.69028 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:56:16.896514 ops/training.py:65 2019-01-16 11:56:16.896459: step 1664, loss = 0.71698 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:56:17.662518 ops/training.py:65 2019-01-16 11:56:17.662451: step 1665, loss = 0.75622 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:56:18.428404 ops/training.py:65 2019-01-16 11:56:18.428359: step 1666, loss = 0.71224 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:56:19.193213 ops/training.py:65 2019-01-16 11:56:19.193161: step 1667, loss = 0.69244 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:56:19.957268 ops/training.py:65 2019-01-16 11:56:19.957217: step 1668, loss = 0.66259 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:56:20.720798 ops/training.py:65 2019-01-16 11:56:20.720736: step 1669, loss = 0.65188 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:56:21.483918 ops/training.py:65 2019-01-16 11:56:21.483859: step 1670, loss = 0.68817 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:56:22.247554 ops/training.py:65 2019-01-16 11:56:22.247508: step 1671, loss = 0.68540 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:56:23.016674 ops/training.py:65 2019-01-16 11:56:23.016623: step 1672, loss = 0.69678 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:56:23.784957 ops/training.py:65 2019-01-16 11:56:23.784896: step 1673, loss = 0.69863 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:56:24.554525 ops/training.py:65 2019-01-16 11:56:24.554480: step 1674, loss = 0.67249 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:56:25.322644 ops/training.py:65 2019-01-16 11:56:25.322574: step 1675, loss = 0.77840 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:56:26.090321 ops/training.py:65 2019-01-16 11:56:26.090262: step 1676, loss = 0.68673 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:56:26.855788 ops/training.py:65 2019-01-16 11:56:26.855714: step 1677, loss = 0.68988 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:56:27.623968 ops/training.py:65 2019-01-16 11:56:27.623899: step 1678, loss = 0.76052 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:56:28.392440 ops/training.py:65 2019-01-16 11:56:28.392381: step 1679, loss = 0.70034 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:56:29.160656 ops/training.py:65 2019-01-16 11:56:29.160601: step 1680, loss = 0.65986 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.78125
I0528 2019-01-16 11:56:29.929181 ops/training.py:65 2019-01-16 11:56:29.929143: step 1681, loss = 0.71544 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:56:30.697908 ops/training.py:65 2019-01-16 11:56:30.697836: step 1682, loss = 0.71111 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:56:31.466152 ops/training.py:65 2019-01-16 11:56:31.466087: step 1683, loss = 0.69291 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:56:32.234924 ops/training.py:65 2019-01-16 11:56:32.234864: step 1684, loss = 0.75948 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:56:33.002796 ops/training.py:65 2019-01-16 11:56:33.002723: step 1685, loss = 0.71944 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:56:33.771239 ops/training.py:65 2019-01-16 11:56:33.771167: step 1686, loss = 0.66940 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:56:34.535497 ops/training.py:65 2019-01-16 11:56:34.535436: step 1687, loss = 0.72408 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:56:35.299750 ops/training.py:65 2019-01-16 11:56:35.299696: step 1688, loss = 0.70086 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:56:36.063793 ops/training.py:65 2019-01-16 11:56:36.063727: step 1689, loss = 0.70180 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:56:36.828100 ops/training.py:65 2019-01-16 11:56:36.828048: step 1690, loss = 0.76980 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:56:37.592742 ops/training.py:65 2019-01-16 11:56:37.592694: step 1691, loss = 0.68978 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:56:38.355935 ops/training.py:65 2019-01-16 11:56:38.355868: step 1692, loss = 0.69587 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:56:39.121096 ops/training.py:65 2019-01-16 11:56:39.121028: step 1693, loss = 0.66507 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:56:39.885737 ops/training.py:65 2019-01-16 11:56:39.885678: step 1694, loss = 0.67757 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:56:40.650632 ops/training.py:65 2019-01-16 11:56:40.650575: step 1695, loss = 0.73393 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.25
I0528 2019-01-16 11:56:41.416232 ops/training.py:65 2019-01-16 11:56:41.416185: step 1696, loss = 0.67929 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:56:42.180134 ops/training.py:65 2019-01-16 11:56:42.180084: step 1697, loss = 0.71571 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:56:42.944343 ops/training.py:65 2019-01-16 11:56:42.944295: step 1698, loss = 0.67544 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:56:43.708547 ops/training.py:65 2019-01-16 11:56:43.708490: step 1699, loss = 0.69765 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:56:44.473005 ops/training.py:65 2019-01-16 11:56:44.472947: step 1700, loss = 0.70370 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:56:45.237722 ops/training.py:65 2019-01-16 11:56:45.237675: step 1701, loss = 0.67807 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:56:46.005065 ops/training.py:65 2019-01-16 11:56:46.004999: step 1702, loss = 0.65889 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:56:46.772821 ops/training.py:65 2019-01-16 11:56:46.772762: step 1703, loss = 0.76783 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 11:56:47.541450 ops/training.py:65 2019-01-16 11:56:47.541388: step 1704, loss = 0.69228 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:56:48.308421 ops/training.py:65 2019-01-16 11:56:48.308355: step 1705, loss = 0.69892 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:56:49.074669 ops/training.py:65 2019-01-16 11:56:49.074610: step 1706, loss = 0.68875 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:56:49.838525 ops/training.py:65 2019-01-16 11:56:49.838473: step 1707, loss = 0.68457 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:56:50.602089 ops/training.py:65 2019-01-16 11:56:50.602033: step 1708, loss = 0.69535 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:56:51.366949 ops/training.py:65 2019-01-16 11:56:51.366900: step 1709, loss = 0.66837 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:56:52.133396 ops/training.py:65 2019-01-16 11:56:52.133340: step 1710, loss = 0.71300 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:56:52.897898 ops/training.py:65 2019-01-16 11:56:52.897845: step 1711, loss = 0.73366 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:56:53.662826 ops/training.py:65 2019-01-16 11:56:53.662767: step 1712, loss = 0.68886 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:56:54.426781 ops/training.py:65 2019-01-16 11:56:54.426722: step 1713, loss = 0.71558 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:56:55.191135 ops/training.py:65 2019-01-16 11:56:55.191084: step 1714, loss = 0.69720 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:56:55.954727 ops/training.py:65 2019-01-16 11:56:55.954685: step 1715, loss = 0.73256 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.25
I0528 2019-01-16 11:56:56.717971 ops/training.py:65 2019-01-16 11:56:56.717919: step 1716, loss = 0.73543 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:56:57.482342 ops/training.py:65 2019-01-16 11:56:57.482287: step 1717, loss = 0.68003 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:56:58.250799 ops/training.py:65 2019-01-16 11:56:58.250734: step 1718, loss = 0.75208 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:56:59.018277 ops/training.py:65 2019-01-16 11:56:59.018214: step 1719, loss = 0.67582 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 11:56:59.787495 ops/training.py:65 2019-01-16 11:56:59.787422: step 1720, loss = 0.69353 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:57:00.556059 ops/training.py:65 2019-01-16 11:57:00.555988: step 1721, loss = 0.67439 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:57:01.323509 ops/training.py:65 2019-01-16 11:57:01.323451: step 1722, loss = 0.71458 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:57:02.088772 ops/training.py:65 2019-01-16 11:57:02.088724: step 1723, loss = 0.69021 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:57:02.852996 ops/training.py:65 2019-01-16 11:57:02.852944: step 1724, loss = 0.68876 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:57:03.617033 ops/training.py:65 2019-01-16 11:57:03.616982: step 1725, loss = 0.72618 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:57:04.381348 ops/training.py:65 2019-01-16 11:57:04.381291: step 1726, loss = 0.70658 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:57:05.145325 ops/training.py:65 2019-01-16 11:57:05.145270: step 1727, loss = 0.69689 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:57:05.909890 ops/training.py:65 2019-01-16 11:57:05.909837: step 1728, loss = 0.69921 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:57:06.679222 ops/training.py:65 2019-01-16 11:57:06.679152: step 1729, loss = 0.70598 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:57:07.448115 ops/training.py:65 2019-01-16 11:57:07.448080: step 1730, loss = 0.67635 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:57:08.217172 ops/training.py:65 2019-01-16 11:57:08.217117: step 1731, loss = 0.68809 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:57:08.984076 ops/training.py:65 2019-01-16 11:57:08.984016: step 1732, loss = 0.73251 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:57:09.750646 ops/training.py:65 2019-01-16 11:57:09.750559: step 1733, loss = 0.67767 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:57:10.516895 ops/training.py:65 2019-01-16 11:57:10.516837: step 1734, loss = 0.69303 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:57:11.281964 ops/training.py:65 2019-01-16 11:57:11.281892: step 1735, loss = 0.67179 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:57:12.046280 ops/training.py:65 2019-01-16 11:57:12.046223: step 1736, loss = 0.69746 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:57:12.809644 ops/training.py:65 2019-01-16 11:57:12.809576: step 1737, loss = 0.68827 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:57:13.573915 ops/training.py:65 2019-01-16 11:57:13.573861: step 1738, loss = 0.67380 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:57:14.338674 ops/training.py:65 2019-01-16 11:57:14.338624: step 1739, loss = 0.69092 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:57:15.103025 ops/training.py:65 2019-01-16 11:57:15.102980: step 1740, loss = 0.69341 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:57:15.867522 ops/training.py:65 2019-01-16 11:57:15.867472: step 1741, loss = 0.71918 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:57:16.631948 ops/training.py:65 2019-01-16 11:57:16.631885: step 1742, loss = 0.72607 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:57:17.395888 ops/training.py:65 2019-01-16 11:57:17.395825: step 1743, loss = 0.68105 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:57:18.163648 ops/training.py:65 2019-01-16 11:57:18.163583: step 1744, loss = 0.71960 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:57:18.932638 ops/training.py:65 2019-01-16 11:57:18.932605: step 1745, loss = 0.71440 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:57:19.701853 ops/training.py:65 2019-01-16 11:57:19.701781: step 1746, loss = 0.70210 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:57:20.471338 ops/training.py:65 2019-01-16 11:57:20.471265: step 1747, loss = 0.67858 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:57:21.239500 ops/training.py:65 2019-01-16 11:57:21.239440: step 1748, loss = 0.65623 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:57:22.005891 ops/training.py:65 2019-01-16 11:57:22.005831: step 1749, loss = 0.68393 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:57:22.771587 ops/training.py:65 2019-01-16 11:57:22.771536: step 1750, loss = 0.72504 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:57:23.536348 ops/training.py:65 2019-01-16 11:57:23.536295: step 1751, loss = 0.73313 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:57:24.300737 ops/training.py:65 2019-01-16 11:57:24.300681: step 1752, loss = 0.70754 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:57:25.065445 ops/training.py:65 2019-01-16 11:57:25.065391: step 1753, loss = 0.69727 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:57:25.831660 ops/training.py:65 2019-01-16 11:57:25.831594: step 1754, loss = 0.71224 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:57:26.599332 ops/training.py:65 2019-01-16 11:57:26.599260: step 1755, loss = 0.70384 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:57:27.366610 ops/training.py:65 2019-01-16 11:57:27.366534: step 1756, loss = 0.70276 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:57:28.132992 ops/training.py:65 2019-01-16 11:57:28.132943: step 1757, loss = 0.69069 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:57:28.899711 ops/training.py:65 2019-01-16 11:57:28.899658: step 1758, loss = 0.68298 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:57:29.667243 ops/training.py:65 2019-01-16 11:57:29.667173: step 1759, loss = 0.70854 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:57:30.436025 ops/training.py:65 2019-01-16 11:57:30.435954: step 1760, loss = 0.70734 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:57:31.203391 ops/training.py:65 2019-01-16 11:57:31.203319: step 1761, loss = 0.70360 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:57:31.969961 ops/training.py:65 2019-01-16 11:57:31.969906: step 1762, loss = 0.67188 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:57:32.735465 ops/training.py:65 2019-01-16 11:57:32.735404: step 1763, loss = 0.68667 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:57:33.504216 ops/training.py:65 2019-01-16 11:57:33.504145: step 1764, loss = 0.69368 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:57:34.272395 ops/training.py:65 2019-01-16 11:57:34.272317: step 1765, loss = 0.70202 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:57:35.037461 ops/training.py:65 2019-01-16 11:57:35.037391: step 1766, loss = 0.70906 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:57:35.802288 ops/training.py:65 2019-01-16 11:57:35.802218: step 1767, loss = 0.69996 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:57:36.569239 ops/training.py:65 2019-01-16 11:57:36.569168: step 1768, loss = 0.66596 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:57:37.337437 ops/training.py:65 2019-01-16 11:57:37.337387: step 1769, loss = 0.71623 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:57:38.104900 ops/training.py:65 2019-01-16 11:57:38.104842: step 1770, loss = 0.70501 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:57:38.872081 ops/training.py:65 2019-01-16 11:57:38.872018: step 1771, loss = 0.68121 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:57:39.640594 ops/training.py:65 2019-01-16 11:57:39.640524: step 1772, loss = 0.72158 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:57:40.409129 ops/training.py:65 2019-01-16 11:57:40.409065: step 1773, loss = 0.70543 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:57:41.176781 ops/training.py:65 2019-01-16 11:57:41.176707: step 1774, loss = 0.68961 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:57:41.941890 ops/training.py:65 2019-01-16 11:57:41.941820: step 1775, loss = 0.69400 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:57:42.710691 ops/training.py:65 2019-01-16 11:57:42.710634: step 1776, loss = 0.71889 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:57:43.477245 ops/training.py:65 2019-01-16 11:57:43.477186: step 1777, loss = 0.68897 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:57:44.241542 ops/training.py:65 2019-01-16 11:57:44.241475: step 1778, loss = 0.71525 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:57:45.010263 ops/training.py:65 2019-01-16 11:57:45.010196: step 1779, loss = 0.73416 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:57:45.777706 ops/training.py:65 2019-01-16 11:57:45.777653: step 1780, loss = 0.68744 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:57:46.544128 ops/training.py:65 2019-01-16 11:57:46.544053: step 1781, loss = 0.69700 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:57:47.311478 ops/training.py:65 2019-01-16 11:57:47.311429: step 1782, loss = 0.72143 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:57:48.077608 ops/training.py:65 2019-01-16 11:57:48.077540: step 1783, loss = 0.68934 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:57:48.841373 ops/training.py:65 2019-01-16 11:57:48.841329: step 1784, loss = 0.70667 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:57:49.605050 ops/training.py:65 2019-01-16 11:57:49.604997: step 1785, loss = 0.69673 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:57:50.371164 ops/training.py:65 2019-01-16 11:57:50.371097: step 1786, loss = 0.71899 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 11:57:51.138947 ops/training.py:65 2019-01-16 11:57:51.138874: step 1787, loss = 0.71154 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:57:51.906187 ops/training.py:65 2019-01-16 11:57:51.906099: step 1788, loss = 0.74494 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:57:52.674393 ops/training.py:65 2019-01-16 11:57:52.674345: step 1789, loss = 0.69559 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:57:53.443154 ops/training.py:65 2019-01-16 11:57:53.443078: step 1790, loss = 0.66594 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:57:54.211811 ops/training.py:65 2019-01-16 11:57:54.211739: step 1791, loss = 0.70670 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:57:54.979290 ops/training.py:65 2019-01-16 11:57:54.979215: step 1792, loss = 0.69716 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:57:55.747231 ops/training.py:65 2019-01-16 11:57:55.747159: step 1793, loss = 0.71331 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:57:56.514996 ops/training.py:65 2019-01-16 11:57:56.514945: step 1794, loss = 0.71435 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:57:57.282854 ops/training.py:65 2019-01-16 11:57:57.282784: step 1795, loss = 0.68033 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:57:58.050242 ops/training.py:65 2019-01-16 11:57:58.050187: step 1796, loss = 0.67022 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:57:58.816526 ops/training.py:65 2019-01-16 11:57:58.816470: step 1797, loss = 0.72672 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:57:59.580711 ops/training.py:65 2019-01-16 11:57:59.580643: step 1798, loss = 0.73443 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:58:00.345303 ops/training.py:65 2019-01-16 11:58:00.345258: step 1799, loss = 0.74960 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:58:01.108570 ops/training.py:65 2019-01-16 11:58:01.108480: step 1800, loss = 0.74595 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:58:01.872993 ops/training.py:65 2019-01-16 11:58:01.872935: step 1801, loss = 0.68986 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:58:02.637727 ops/training.py:65 2019-01-16 11:58:02.637665: step 1802, loss = 0.63716 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:58:03.402295 ops/training.py:65 2019-01-16 11:58:03.402228: step 1803, loss = 0.70071 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:58:04.166759 ops/training.py:65 2019-01-16 11:58:04.166715: step 1804, loss = 0.72707 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:58:04.930246 ops/training.py:65 2019-01-16 11:58:04.930180: step 1805, loss = 0.71262 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:58:05.695098 ops/training.py:65 2019-01-16 11:58:05.695037: step 1806, loss = 0.69119 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:58:06.459021 ops/training.py:65 2019-01-16 11:58:06.458955: step 1807, loss = 0.65433 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:58:07.223800 ops/training.py:65 2019-01-16 11:58:07.223725: step 1808, loss = 0.71871 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:58:07.988714 ops/training.py:65 2019-01-16 11:58:07.988654: step 1809, loss = 0.78295 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:58:08.756663 ops/training.py:65 2019-01-16 11:58:08.756597: step 1810, loss = 0.69026 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:58:09.524648 ops/training.py:65 2019-01-16 11:58:09.524585: step 1811, loss = 0.69537 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:58:10.292266 ops/training.py:65 2019-01-16 11:58:10.292213: step 1812, loss = 0.73203 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:58:11.058169 ops/training.py:65 2019-01-16 11:58:11.058114: step 1813, loss = 0.75853 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:58:11.824284 ops/training.py:65 2019-01-16 11:58:11.824219: step 1814, loss = 0.78030 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:58:12.590458 ops/training.py:65 2019-01-16 11:58:12.590402: step 1815, loss = 0.71347 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:58:13.355650 ops/training.py:65 2019-01-16 11:58:13.355592: step 1816, loss = 0.69466 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:58:14.121456 ops/training.py:65 2019-01-16 11:58:14.121394: step 1817, loss = 0.73381 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:58:14.886444 ops/training.py:65 2019-01-16 11:58:14.886379: step 1818, loss = 0.69469 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:58:15.649879 ops/training.py:65 2019-01-16 11:58:15.649833: step 1819, loss = 0.75424 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:58:16.413101 ops/training.py:65 2019-01-16 11:58:16.413032: step 1820, loss = 0.72212 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:58:17.176944 ops/training.py:65 2019-01-16 11:58:17.176893: step 1821, loss = 0.70325 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:58:17.940309 ops/training.py:65 2019-01-16 11:58:17.940245: step 1822, loss = 0.76525 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:58:18.704011 ops/training.py:65 2019-01-16 11:58:18.703951: step 1823, loss = 0.71913 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:58:19.466970 ops/training.py:65 2019-01-16 11:58:19.466924: step 1824, loss = 0.71531 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:58:20.230228 ops/training.py:65 2019-01-16 11:58:20.230154: step 1825, loss = 0.73750 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:58:20.994487 ops/training.py:65 2019-01-16 11:58:20.994415: step 1826, loss = 0.69171 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:58:21.757665 ops/training.py:65 2019-01-16 11:58:21.757599: step 1827, loss = 0.71966 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:58:22.521350 ops/training.py:65 2019-01-16 11:58:22.521286: step 1828, loss = 0.76612 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:58:23.285853 ops/training.py:65 2019-01-16 11:58:23.285805: step 1829, loss = 0.71578 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:58:24.050122 ops/training.py:65 2019-01-16 11:58:24.050055: step 1830, loss = 0.67901 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:58:24.814328 ops/training.py:65 2019-01-16 11:58:24.814256: step 1831, loss = 0.71291 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:58:25.578707 ops/training.py:65 2019-01-16 11:58:25.578639: step 1832, loss = 0.75369 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:58:26.342700 ops/training.py:65 2019-01-16 11:58:26.342652: step 1833, loss = 0.69464 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:58:27.106058 ops/training.py:65 2019-01-16 11:58:27.105993: step 1834, loss = 0.72014 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:58:27.870423 ops/training.py:65 2019-01-16 11:58:27.870355: step 1835, loss = 0.69851 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:58:28.634444 ops/training.py:65 2019-01-16 11:58:28.634377: step 1836, loss = 0.73104 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:58:29.397916 ops/training.py:65 2019-01-16 11:58:29.397850: step 1837, loss = 0.76907 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.25
I0528 2019-01-16 11:58:30.163050 ops/training.py:65 2019-01-16 11:58:30.163003: step 1838, loss = 0.73044 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:58:30.926860 ops/training.py:65 2019-01-16 11:58:30.926794: step 1839, loss = 0.74521 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:58:31.691422 ops/training.py:65 2019-01-16 11:58:31.691355: step 1840, loss = 0.69074 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:58:32.458841 ops/training.py:65 2019-01-16 11:58:32.458774: step 1841, loss = 0.72239 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:58:33.225909 ops/training.py:65 2019-01-16 11:58:33.225839: step 1842, loss = 0.75767 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:58:33.992639 ops/training.py:65 2019-01-16 11:58:33.992566: step 1843, loss = 0.73538 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:58:34.756748 ops/training.py:65 2019-01-16 11:58:34.756679: step 1844, loss = 0.69113 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:58:35.521054 ops/training.py:65 2019-01-16 11:58:35.520990: step 1845, loss = 0.69082 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:58:36.285050 ops/training.py:65 2019-01-16 11:58:36.284982: step 1846, loss = 0.70580 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:58:37.048549 ops/training.py:65 2019-01-16 11:58:37.048483: step 1847, loss = 0.67611 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:58:37.812544 ops/training.py:65 2019-01-16 11:58:37.812491: step 1848, loss = 0.74994 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:58:38.578188 ops/training.py:65 2019-01-16 11:58:38.578124: step 1849, loss = 0.71413 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:58:39.345632 ops/training.py:65 2019-01-16 11:58:39.345568: step 1850, loss = 0.70648 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:58:40.114169 ops/training.py:65 2019-01-16 11:58:40.114099: step 1851, loss = 0.69057 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:58:40.882683 ops/training.py:65 2019-01-16 11:58:40.882606: step 1852, loss = 0.63935 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:58:41.647220 ops/training.py:65 2019-01-16 11:58:41.647155: step 1853, loss = 0.66562 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:58:42.413535 ops/training.py:65 2019-01-16 11:58:42.413465: step 1854, loss = 0.67356 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:58:43.181716 ops/training.py:65 2019-01-16 11:58:43.181658: step 1855, loss = 0.67068 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:58:43.948450 ops/training.py:65 2019-01-16 11:58:43.948362: step 1856, loss = 0.69900 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:58:44.713312 ops/training.py:65 2019-01-16 11:58:44.713241: step 1857, loss = 0.71912 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:58:45.476745 ops/training.py:65 2019-01-16 11:58:45.476696: step 1858, loss = 0.74144 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:58:46.240850 ops/training.py:65 2019-01-16 11:58:46.240784: step 1859, loss = 0.68595 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:58:47.005215 ops/training.py:65 2019-01-16 11:58:47.005171: step 1860, loss = 0.69496 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:58:47.769229 ops/training.py:65 2019-01-16 11:58:47.769163: step 1861, loss = 0.74386 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:58:48.534221 ops/training.py:65 2019-01-16 11:58:48.534152: step 1862, loss = 0.70955 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:58:49.298730 ops/training.py:65 2019-01-16 11:58:49.298677: step 1863, loss = 0.69986 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:58:50.066529 ops/training.py:65 2019-01-16 11:58:50.066458: step 1864, loss = 0.70576 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:58:50.834453 ops/training.py:65 2019-01-16 11:58:50.834380: step 1865, loss = 0.70567 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:58:51.601045 ops/training.py:65 2019-01-16 11:58:51.600972: step 1866, loss = 0.68093 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 11:58:52.365185 ops/training.py:65 2019-01-16 11:58:52.365120: step 1867, loss = 0.69087 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:58:53.128875 ops/training.py:65 2019-01-16 11:58:53.128820: step 1868, loss = 0.68735 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:58:53.896956 ops/training.py:65 2019-01-16 11:58:53.896883: step 1869, loss = 0.71495 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:58:54.664897 ops/training.py:65 2019-01-16 11:58:54.664817: step 1870, loss = 0.76397 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:58:55.433907 ops/training.py:65 2019-01-16 11:58:55.433833: step 1871, loss = 0.69245 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:58:56.200996 ops/training.py:65 2019-01-16 11:58:56.200936: step 1872, loss = 0.70603 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:58:56.967627 ops/training.py:65 2019-01-16 11:58:56.967552: step 1873, loss = 0.71019 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:58:57.734155 ops/training.py:65 2019-01-16 11:58:57.734088: step 1874, loss = 0.69745 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:58:58.499802 ops/training.py:65 2019-01-16 11:58:58.499730: step 1875, loss = 0.68049 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:58:59.264379 ops/training.py:65 2019-01-16 11:58:59.264315: step 1876, loss = 0.74438 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:59:00.028005 ops/training.py:65 2019-01-16 11:59:00.027959: step 1877, loss = 0.78742 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.21875
I0528 2019-01-16 11:59:00.791836 ops/training.py:65 2019-01-16 11:59:00.791784: step 1878, loss = 0.65353 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:59:01.555585 ops/training.py:65 2019-01-16 11:59:01.555522: step 1879, loss = 0.75687 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:59:02.319999 ops/training.py:65 2019-01-16 11:59:02.319934: step 1880, loss = 0.72184 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:59:03.083984 ops/training.py:65 2019-01-16 11:59:03.083915: step 1881, loss = 0.66268 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:59:03.848408 ops/training.py:65 2019-01-16 11:59:03.848361: step 1882, loss = 0.73104 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:59:04.612741 ops/training.py:65 2019-01-16 11:59:04.612674: step 1883, loss = 0.75596 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:59:05.376852 ops/training.py:65 2019-01-16 11:59:05.376787: step 1884, loss = 0.69168 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:59:06.140604 ops/training.py:65 2019-01-16 11:59:06.140540: step 1885, loss = 0.75549 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:59:06.903759 ops/training.py:65 2019-01-16 11:59:06.903691: step 1886, loss = 0.68504 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:59:07.667663 ops/training.py:65 2019-01-16 11:59:07.667612: step 1887, loss = 0.66348 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:59:08.432119 ops/training.py:65 2019-01-16 11:59:08.432065: step 1888, loss = 0.73311 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:59:09.197656 ops/training.py:65 2019-01-16 11:59:09.197589: step 1889, loss = 0.72331 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:59:09.964660 ops/training.py:65 2019-01-16 11:59:09.964592: step 1890, loss = 0.71686 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:59:10.731992 ops/training.py:65 2019-01-16 11:59:10.731919: step 1891, loss = 0.70937 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:59:11.500671 ops/training.py:65 2019-01-16 11:59:11.500606: step 1892, loss = 0.67235 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:59:12.268019 ops/training.py:65 2019-01-16 11:59:12.267949: step 1893, loss = 0.67762 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:59:13.033367 ops/training.py:65 2019-01-16 11:59:13.033295: step 1894, loss = 0.74048 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:59:13.798092 ops/training.py:65 2019-01-16 11:59:13.798024: step 1895, loss = 0.70292 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:59:14.562645 ops/training.py:65 2019-01-16 11:59:14.562575: step 1896, loss = 0.73165 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:59:15.326732 ops/training.py:65 2019-01-16 11:59:15.326688: step 1897, loss = 0.71336 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:59:16.091412 ops/training.py:65 2019-01-16 11:59:16.091362: step 1898, loss = 0.74147 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 11:59:16.854726 ops/training.py:65 2019-01-16 11:59:16.854663: step 1899, loss = 0.75350 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:59:17.618159 ops/training.py:65 2019-01-16 11:59:17.618094: step 1900, loss = 0.77063 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:59:18.382312 ops/training.py:65 2019-01-16 11:59:18.382243: step 1901, loss = 0.69372 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:59:19.146500 ops/training.py:65 2019-01-16 11:59:19.146455: step 1902, loss = 0.74149 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:59:19.910285 ops/training.py:65 2019-01-16 11:59:19.910218: step 1903, loss = 0.75411 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:59:20.673914 ops/training.py:65 2019-01-16 11:59:20.673846: step 1904, loss = 0.76447 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:59:21.437773 ops/training.py:65 2019-01-16 11:59:21.437699: step 1905, loss = 0.74281 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:59:22.202029 ops/training.py:65 2019-01-16 11:59:22.201962: step 1906, loss = 0.67199 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:59:22.966033 ops/training.py:65 2019-01-16 11:59:22.965982: step 1907, loss = 0.68255 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:59:23.730116 ops/training.py:65 2019-01-16 11:59:23.730049: step 1908, loss = 0.68954 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:59:24.494603 ops/training.py:65 2019-01-16 11:59:24.494533: step 1909, loss = 0.74591 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:59:25.260599 ops/training.py:65 2019-01-16 11:59:25.260529: step 1910, loss = 0.69926 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 11:59:26.025103 ops/training.py:65 2019-01-16 11:59:26.025042: step 1911, loss = 0.66828 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:59:26.789871 ops/training.py:65 2019-01-16 11:59:26.789823: step 1912, loss = 0.70159 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:59:27.553932 ops/training.py:65 2019-01-16 11:59:27.553882: step 1913, loss = 0.68043 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:59:28.318154 ops/training.py:65 2019-01-16 11:59:28.318094: step 1914, loss = 0.65677 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:59:29.082968 ops/training.py:65 2019-01-16 11:59:29.082882: step 1915, loss = 0.71879 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:59:29.847628 ops/training.py:65 2019-01-16 11:59:29.847581: step 1916, loss = 0.70136 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:59:30.611869 ops/training.py:65 2019-01-16 11:59:30.611802: step 1917, loss = 0.68629 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:59:31.375300 ops/training.py:65 2019-01-16 11:59:31.375248: step 1918, loss = 0.70711 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:59:32.138972 ops/training.py:65 2019-01-16 11:59:32.138904: step 1919, loss = 0.67912 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:59:32.903690 ops/training.py:65 2019-01-16 11:59:32.903622: step 1920, loss = 0.69419 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:59:33.667296 ops/training.py:65 2019-01-16 11:59:33.667249: step 1921, loss = 0.76289 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:59:34.431226 ops/training.py:65 2019-01-16 11:59:34.431157: step 1922, loss = 0.72180 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 11:59:35.195207 ops/training.py:65 2019-01-16 11:59:35.195142: step 1923, loss = 0.72444 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:59:35.959126 ops/training.py:65 2019-01-16 11:59:35.959056: step 1924, loss = 0.71406 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:59:36.724606 ops/training.py:65 2019-01-16 11:59:36.724537: step 1925, loss = 0.70750 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:59:37.488396 ops/training.py:65 2019-01-16 11:59:37.488347: step 1926, loss = 0.74181 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:59:38.252536 ops/training.py:65 2019-01-16 11:59:38.252482: step 1927, loss = 0.73983 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:59:39.016889 ops/training.py:65 2019-01-16 11:59:39.016822: step 1928, loss = 0.67223 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:59:39.781896 ops/training.py:65 2019-01-16 11:59:39.781823: step 1929, loss = 0.73713 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:59:40.546853 ops/training.py:65 2019-01-16 11:59:40.546785: step 1930, loss = 0.69151 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:59:41.311226 ops/training.py:65 2019-01-16 11:59:41.311172: step 1931, loss = 0.71362 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:59:42.075040 ops/training.py:65 2019-01-16 11:59:42.074995: step 1932, loss = 0.73287 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:59:42.838565 ops/training.py:65 2019-01-16 11:59:42.838493: step 1933, loss = 0.69509 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:59:43.602720 ops/training.py:65 2019-01-16 11:59:43.602669: step 1934, loss = 0.71985 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:59:44.367056 ops/training.py:65 2019-01-16 11:59:44.366988: step 1935, loss = 0.69657 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:59:45.130779 ops/training.py:65 2019-01-16 11:59:45.130732: step 1936, loss = 0.72894 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:59:45.894894 ops/training.py:65 2019-01-16 11:59:45.894825: step 1937, loss = 0.69177 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 11:59:46.658168 ops/training.py:65 2019-01-16 11:59:46.658103: step 1938, loss = 0.67359 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:59:47.421797 ops/training.py:65 2019-01-16 11:59:47.421727: step 1939, loss = 0.70974 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:59:48.185145 ops/training.py:65 2019-01-16 11:59:48.185078: step 1940, loss = 0.71263 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:59:48.948521 ops/training.py:65 2019-01-16 11:59:48.948477: step 1941, loss = 0.65712 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 11:59:49.711777 ops/training.py:65 2019-01-16 11:59:49.711710: step 1942, loss = 0.74860 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 11:59:50.475930 ops/training.py:65 2019-01-16 11:59:50.475866: step 1943, loss = 0.64184 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 11:59:51.239475 ops/training.py:65 2019-01-16 11:59:51.239406: step 1944, loss = 0.71333 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:59:52.003236 ops/training.py:65 2019-01-16 11:59:52.003195: step 1945, loss = 0.68327 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:59:52.766604 ops/training.py:65 2019-01-16 11:59:52.766556: step 1946, loss = 0.73589 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:59:53.530453 ops/training.py:65 2019-01-16 11:59:53.530387: step 1947, loss = 0.73096 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 11:59:54.294237 ops/training.py:65 2019-01-16 11:59:54.294171: step 1948, loss = 0.67083 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 11:59:55.058330 ops/training.py:65 2019-01-16 11:59:55.058261: step 1949, loss = 0.69104 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:59:55.822039 ops/training.py:65 2019-01-16 11:59:55.821990: step 1950, loss = 0.66088 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:59:56.586207 ops/training.py:65 2019-01-16 11:59:56.586140: step 1951, loss = 0.69863 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 11:59:57.350014 ops/training.py:65 2019-01-16 11:59:57.349959: step 1952, loss = 0.77313 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 11:59:58.113522 ops/training.py:65 2019-01-16 11:59:58.113455: step 1953, loss = 0.68216 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:59:58.877053 ops/training.py:65 2019-01-16 11:59:58.876992: step 1954, loss = 0.72197 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 11:59:59.641318 ops/training.py:65 2019-01-16 11:59:59.641263: step 1955, loss = 0.76775 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:00:00.405738 ops/training.py:65 2019-01-16 12:00:00.405672: step 1956, loss = 0.69513 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:00:01.169298 ops/training.py:65 2019-01-16 12:00:01.169253: step 1957, loss = 0.69049 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:00:01.934075 ops/training.py:65 2019-01-16 12:00:01.934006: step 1958, loss = 0.71347 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:00:02.698976 ops/training.py:65 2019-01-16 12:00:02.698887: step 1959, loss = 0.82979 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 12:00:03.463007 ops/training.py:65 2019-01-16 12:00:03.462960: step 1960, loss = 0.80913 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:00:04.227205 ops/training.py:65 2019-01-16 12:00:04.227109: step 1961, loss = 0.66302 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:00:04.991586 ops/training.py:65 2019-01-16 12:00:04.991516: step 1962, loss = 0.76546 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:00:05.754971 ops/training.py:65 2019-01-16 12:00:05.754897: step 1963, loss = 0.67702 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:00:06.519046 ops/training.py:65 2019-01-16 12:00:06.518971: step 1964, loss = 0.73211 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:00:07.284732 ops/training.py:65 2019-01-16 12:00:07.284670: step 1965, loss = 0.78302 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:00:08.052250 ops/training.py:65 2019-01-16 12:00:08.052198: step 1966, loss = 0.77108 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:00:08.820521 ops/training.py:65 2019-01-16 12:00:08.820451: step 1967, loss = 0.72375 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:00:09.587725 ops/training.py:65 2019-01-16 12:00:09.587654: step 1968, loss = 0.67528 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:00:10.355638 ops/training.py:65 2019-01-16 12:00:10.355569: step 1969, loss = 0.70863 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:00:11.121950 ops/training.py:65 2019-01-16 12:00:11.121877: step 1970, loss = 0.70601 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:00:11.885718 ops/training.py:65 2019-01-16 12:00:11.885645: step 1971, loss = 0.72507 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:00:12.649387 ops/training.py:65 2019-01-16 12:00:12.649322: step 1972, loss = 0.69485 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:00:13.413258 ops/training.py:65 2019-01-16 12:00:13.413188: step 1973, loss = 0.72578 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:00:14.177547 ops/training.py:65 2019-01-16 12:00:14.177479: step 1974, loss = 0.71476 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:00:14.941127 ops/training.py:65 2019-01-16 12:00:14.941080: step 1975, loss = 0.75143 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:00:15.705889 ops/training.py:65 2019-01-16 12:00:15.705823: step 1976, loss = 0.65926 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:00:16.470939 ops/training.py:65 2019-01-16 12:00:16.470874: step 1977, loss = 0.63680 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:00:17.234020 ops/training.py:65 2019-01-16 12:00:17.233953: step 1978, loss = 0.77427 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:00:17.997994 ops/training.py:65 2019-01-16 12:00:17.997930: step 1979, loss = 0.71859 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:00:18.762046 ops/training.py:65 2019-01-16 12:00:18.762002: step 1980, loss = 0.72047 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:00:19.526097 ops/training.py:65 2019-01-16 12:00:19.526029: step 1981, loss = 0.66175 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:00:20.290017 ops/training.py:65 2019-01-16 12:00:20.289939: step 1982, loss = 0.70862 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:00:21.054099 ops/training.py:65 2019-01-16 12:00:21.054031: step 1983, loss = 0.71646 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:00:21.818222 ops/training.py:65 2019-01-16 12:00:21.818173: step 1984, loss = 0.65595 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:00:22.583911 ops/training.py:65 2019-01-16 12:00:22.583840: step 1985, loss = 0.67485 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:00:23.347599 ops/training.py:65 2019-01-16 12:00:23.347531: step 1986, loss = 0.69268 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:00:24.111127 ops/training.py:65 2019-01-16 12:00:24.111063: step 1987, loss = 0.72403 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:00:24.875291 ops/training.py:65 2019-01-16 12:00:24.875223: step 1988, loss = 0.71220 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:00:25.640174 ops/training.py:65 2019-01-16 12:00:25.640126: step 1989, loss = 0.73119 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:00:26.403807 ops/training.py:65 2019-01-16 12:00:26.403739: step 1990, loss = 0.69406 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:00:27.167786 ops/training.py:65 2019-01-16 12:00:27.167736: step 1991, loss = 0.67094 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:00:27.931392 ops/training.py:65 2019-01-16 12:00:27.931331: step 1992, loss = 0.70878 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:00:28.694132 ops/training.py:65 2019-01-16 12:00:28.694073: step 1993, loss = 0.68970 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:00:29.459703 ops/training.py:65 2019-01-16 12:00:29.459652: step 1994, loss = 0.71107 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:00:30.226856 ops/training.py:65 2019-01-16 12:00:30.226781: step 1995, loss = 0.70966 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:00:30.993497 ops/training.py:65 2019-01-16 12:00:30.993429: step 1996, loss = 0.68669 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:00:31.759755 ops/training.py:65 2019-01-16 12:00:31.759690: step 1997, loss = 0.76317 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:00:32.523973 ops/training.py:65 2019-01-16 12:00:32.523902: step 1998, loss = 0.75964 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:00:33.291918 ops/training.py:65 2019-01-16 12:00:33.291866: step 1999, loss = 0.73113 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:04:05.718835 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I0528 2019-01-16 12:04:05.719725 ops/training.py:41 2019-01-16 12:04:05.719671: step 2000, loss = 0.72 (0.2 examples/sec; 211.659 sec/batch) | Training accuracy = 0.5 | Validation accuracy = 0.49455 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_11_30_14_313845
I0528 2019-01-16 12:04:06.488313 ops/training.py:65 2019-01-16 12:04:06.488258: step 2001, loss = 0.73803 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:04:07.255956 ops/training.py:65 2019-01-16 12:04:07.255883: step 2002, loss = 0.71560 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:04:08.023677 ops/training.py:65 2019-01-16 12:04:08.023598: step 2003, loss = 0.73384 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:04:08.789537 ops/training.py:65 2019-01-16 12:04:08.789484: step 2004, loss = 0.70231 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:04:09.553531 ops/training.py:65 2019-01-16 12:04:09.553462: step 2005, loss = 0.71558 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:04:10.317661 ops/training.py:65 2019-01-16 12:04:10.317597: step 2006, loss = 0.71655 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:04:11.084506 ops/training.py:65 2019-01-16 12:04:11.084432: step 2007, loss = 0.71726 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:04:11.852442 ops/training.py:65 2019-01-16 12:04:11.852367: step 2008, loss = 0.70535 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:04:12.618934 ops/training.py:65 2019-01-16 12:04:12.618868: step 2009, loss = 0.78069 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:04:13.387783 ops/training.py:65 2019-01-16 12:04:13.387716: step 2010, loss = 0.75558 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:04:14.155461 ops/training.py:65 2019-01-16 12:04:14.155389: step 2011, loss = 0.75320 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:04:14.923062 ops/training.py:65 2019-01-16 12:04:14.922994: step 2012, loss = 0.74285 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:04:15.687550 ops/training.py:65 2019-01-16 12:04:15.687503: step 2013, loss = 0.75050 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:04:16.452583 ops/training.py:65 2019-01-16 12:04:16.452535: step 2014, loss = 0.72775 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:04:17.217359 ops/training.py:65 2019-01-16 12:04:17.217296: step 2015, loss = 0.69435 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:04:17.982103 ops/training.py:65 2019-01-16 12:04:17.982036: step 2016, loss = 0.71344 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:04:18.747320 ops/training.py:65 2019-01-16 12:04:18.747263: step 2017, loss = 0.68897 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:04:19.512241 ops/training.py:65 2019-01-16 12:04:19.512190: step 2018, loss = 0.67428 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:04:20.276810 ops/training.py:65 2019-01-16 12:04:20.276720: step 2019, loss = 0.74772 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:04:21.040995 ops/training.py:65 2019-01-16 12:04:21.040929: step 2020, loss = 0.76826 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:04:21.805694 ops/training.py:65 2019-01-16 12:04:21.805631: step 2021, loss = 0.66775 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:04:22.569688 ops/training.py:65 2019-01-16 12:04:22.569619: step 2022, loss = 0.73006 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:04:23.333906 ops/training.py:65 2019-01-16 12:04:23.333860: step 2023, loss = 0.73927 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:04:24.098423 ops/training.py:65 2019-01-16 12:04:24.098356: step 2024, loss = 0.74610 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:04:24.862909 ops/training.py:65 2019-01-16 12:04:24.862842: step 2025, loss = 0.70030 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:04:25.625898 ops/training.py:65 2019-01-16 12:04:25.625832: step 2026, loss = 0.70357 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:04:26.389876 ops/training.py:65 2019-01-16 12:04:26.389805: step 2027, loss = 0.76631 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:04:27.157876 ops/training.py:65 2019-01-16 12:04:27.157848: step 2028, loss = 0.75188 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:04:27.924782 ops/training.py:65 2019-01-16 12:04:27.924720: step 2029, loss = 0.68520 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:04:28.692999 ops/training.py:65 2019-01-16 12:04:28.692956: step 2030, loss = 0.74870 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:04:29.459404 ops/training.py:65 2019-01-16 12:04:29.459353: step 2031, loss = 0.74414 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:04:30.227330 ops/training.py:65 2019-01-16 12:04:30.227293: step 2032, loss = 0.69152 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:04:30.996418 ops/training.py:65 2019-01-16 12:04:30.996355: step 2033, loss = 0.73749 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:04:31.764109 ops/training.py:65 2019-01-16 12:04:31.764056: step 2034, loss = 0.70261 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:04:32.527537 ops/training.py:65 2019-01-16 12:04:32.527477: step 2035, loss = 0.74230 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:04:33.296141 ops/training.py:65 2019-01-16 12:04:33.296073: step 2036, loss = 0.64312 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:04:34.062491 ops/training.py:65 2019-01-16 12:04:34.062423: step 2037, loss = 0.72214 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:04:34.828107 ops/training.py:65 2019-01-16 12:04:34.828031: step 2038, loss = 0.71679 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:04:35.592387 ops/training.py:65 2019-01-16 12:04:35.592314: step 2039, loss = 0.72284 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:04:36.355729 ops/training.py:65 2019-01-16 12:04:36.355679: step 2040, loss = 0.67204 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:04:37.118941 ops/training.py:65 2019-01-16 12:04:37.118875: step 2041, loss = 0.64964 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:04:37.881579 ops/training.py:65 2019-01-16 12:04:37.881517: step 2042, loss = 0.68216 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:04:38.645601 ops/training.py:65 2019-01-16 12:04:38.645561: step 2043, loss = 0.76232 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:04:39.410347 ops/training.py:65 2019-01-16 12:04:39.410294: step 2044, loss = 0.72142 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:04:40.175009 ops/training.py:65 2019-01-16 12:04:40.174957: step 2045, loss = 0.70546 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:04:40.938884 ops/training.py:65 2019-01-16 12:04:40.938824: step 2046, loss = 0.69196 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:04:41.702479 ops/training.py:65 2019-01-16 12:04:41.702448: step 2047, loss = 0.68999 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:04:42.465817 ops/training.py:65 2019-01-16 12:04:42.465763: step 2048, loss = 0.71489 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:04:43.228955 ops/training.py:65 2019-01-16 12:04:43.228902: step 2049, loss = 0.73603 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:04:43.994000 ops/training.py:65 2019-01-16 12:04:43.993940: step 2050, loss = 0.67763 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:04:44.760035 ops/training.py:65 2019-01-16 12:04:44.759982: step 2051, loss = 0.74054 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:04:45.526077 ops/training.py:65 2019-01-16 12:04:45.526051: step 2052, loss = 0.66035 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:04:46.293741 ops/training.py:65 2019-01-16 12:04:46.293685: step 2053, loss = 0.70504 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:04:47.060210 ops/training.py:65 2019-01-16 12:04:47.060158: step 2054, loss = 0.68013 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:04:47.825012 ops/training.py:65 2019-01-16 12:04:47.824958: step 2055, loss = 0.69338 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:04:48.589778 ops/training.py:65 2019-01-16 12:04:48.589719: step 2056, loss = 0.71336 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:04:49.354377 ops/training.py:65 2019-01-16 12:04:49.354342: step 2057, loss = 0.70633 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:04:50.118928 ops/training.py:65 2019-01-16 12:04:50.118854: step 2058, loss = 0.68486 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:04:50.886878 ops/training.py:65 2019-01-16 12:04:50.886829: step 2059, loss = 0.68505 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:04:51.655255 ops/training.py:65 2019-01-16 12:04:51.655193: step 2060, loss = 0.70847 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:04:52.422078 ops/training.py:65 2019-01-16 12:04:52.422015: step 2061, loss = 0.71344 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:04:53.186663 ops/training.py:65 2019-01-16 12:04:53.186605: step 2062, loss = 0.68642 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:04:53.954857 ops/training.py:65 2019-01-16 12:04:53.954791: step 2063, loss = 0.70475 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:04:54.722213 ops/training.py:65 2019-01-16 12:04:54.722141: step 2064, loss = 0.71736 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:04:55.490217 ops/training.py:65 2019-01-16 12:04:55.490143: step 2065, loss = 0.70192 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:04:56.257754 ops/training.py:65 2019-01-16 12:04:56.257685: step 2066, loss = 0.68276 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:04:57.025637 ops/training.py:65 2019-01-16 12:04:57.025564: step 2067, loss = 0.70562 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:04:57.791971 ops/training.py:65 2019-01-16 12:04:57.791905: step 2068, loss = 0.66505 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:04:58.555666 ops/training.py:65 2019-01-16 12:04:58.555601: step 2069, loss = 0.75102 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:04:59.319522 ops/training.py:65 2019-01-16 12:04:59.319457: step 2070, loss = 0.67764 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:05:00.084429 ops/training.py:65 2019-01-16 12:05:00.084358: step 2071, loss = 0.68531 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:05:00.848646 ops/training.py:65 2019-01-16 12:05:00.848599: step 2072, loss = 0.69306 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:05:01.613827 ops/training.py:65 2019-01-16 12:05:01.613781: step 2073, loss = 0.67111 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:05:02.377617 ops/training.py:65 2019-01-16 12:05:02.377554: step 2074, loss = 0.72097 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:05:03.145675 ops/training.py:65 2019-01-16 12:05:03.145613: step 2075, loss = 0.70966 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:05:03.912170 ops/training.py:65 2019-01-16 12:05:03.912110: step 2076, loss = 0.67510 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:05:04.677280 ops/training.py:65 2019-01-16 12:05:04.677213: step 2077, loss = 0.70153 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:05:05.441883 ops/training.py:65 2019-01-16 12:05:05.441815: step 2078, loss = 0.67557 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:05:06.205227 ops/training.py:65 2019-01-16 12:05:06.205162: step 2079, loss = 0.72182 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:05:06.973107 ops/training.py:65 2019-01-16 12:05:06.973049: step 2080, loss = 0.74146 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:05:07.740222 ops/training.py:65 2019-01-16 12:05:07.740161: step 2081, loss = 0.70028 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:05:08.506220 ops/training.py:65 2019-01-16 12:05:08.506177: step 2082, loss = 0.70367 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:05:09.272947 ops/training.py:65 2019-01-16 12:05:09.272891: step 2083, loss = 0.71463 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:05:10.036851 ops/training.py:65 2019-01-16 12:05:10.036795: step 2084, loss = 0.70795 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:05:10.802629 ops/training.py:65 2019-01-16 12:05:10.802572: step 2085, loss = 0.69661 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:05:11.570839 ops/training.py:65 2019-01-16 12:05:11.570813: step 2086, loss = 0.68038 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:05:12.337752 ops/training.py:65 2019-01-16 12:05:12.337701: step 2087, loss = 0.66918 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:05:13.103269 ops/training.py:65 2019-01-16 12:05:13.103215: step 2088, loss = 0.68849 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:05:13.867705 ops/training.py:65 2019-01-16 12:05:13.867648: step 2089, loss = 0.69977 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:05:14.631181 ops/training.py:65 2019-01-16 12:05:14.631124: step 2090, loss = 0.70624 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:05:15.395506 ops/training.py:65 2019-01-16 12:05:15.395470: step 2091, loss = 0.70763 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:05:16.160221 ops/training.py:65 2019-01-16 12:05:16.160164: step 2092, loss = 0.67884 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:05:16.923952 ops/training.py:65 2019-01-16 12:05:16.923902: step 2093, loss = 0.73047 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:05:17.686839 ops/training.py:65 2019-01-16 12:05:17.686776: step 2094, loss = 0.72083 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:05:18.450181 ops/training.py:65 2019-01-16 12:05:18.450122: step 2095, loss = 0.66226 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:05:19.213863 ops/training.py:65 2019-01-16 12:05:19.213798: step 2096, loss = 0.66251 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:05:19.982166 ops/training.py:65 2019-01-16 12:05:19.982100: step 2097, loss = 0.71702 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:05:20.750683 ops/training.py:65 2019-01-16 12:05:20.750633: step 2098, loss = 0.66671 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:05:21.520032 ops/training.py:65 2019-01-16 12:05:21.519982: step 2099, loss = 0.68448 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:05:22.285823 ops/training.py:65 2019-01-16 12:05:22.285752: step 2100, loss = 0.71517 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:05:23.052377 ops/training.py:65 2019-01-16 12:05:23.052306: step 2101, loss = 0.72772 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:05:23.819234 ops/training.py:65 2019-01-16 12:05:23.819163: step 2102, loss = 0.72727 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:05:24.586904 ops/training.py:65 2019-01-16 12:05:24.586830: step 2103, loss = 0.70442 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:05:25.355322 ops/training.py:65 2019-01-16 12:05:25.355245: step 2104, loss = 0.70209 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:05:26.120927 ops/training.py:65 2019-01-16 12:05:26.120856: step 2105, loss = 0.68645 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:05:26.885159 ops/training.py:65 2019-01-16 12:05:26.885111: step 2106, loss = 0.70098 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:05:27.648400 ops/training.py:65 2019-01-16 12:05:27.648333: step 2107, loss = 0.71722 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:05:28.412747 ops/training.py:65 2019-01-16 12:05:28.412678: step 2108, loss = 0.68845 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:05:29.176523 ops/training.py:65 2019-01-16 12:05:29.176458: step 2109, loss = 0.66388 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:05:29.940365 ops/training.py:65 2019-01-16 12:05:29.940292: step 2110, loss = 0.70468 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:05:30.707892 ops/training.py:65 2019-01-16 12:05:30.707837: step 2111, loss = 0.70144 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:05:31.475951 ops/training.py:65 2019-01-16 12:05:31.475899: step 2112, loss = 0.67676 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:05:32.244396 ops/training.py:65 2019-01-16 12:05:32.244339: step 2113, loss = 0.67266 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:05:33.011240 ops/training.py:65 2019-01-16 12:05:33.011185: step 2114, loss = 0.69983 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:05:33.777520 ops/training.py:65 2019-01-16 12:05:33.777469: step 2115, loss = 0.69990 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:05:34.545387 ops/training.py:65 2019-01-16 12:05:34.545323: step 2116, loss = 0.72457 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:05:35.313531 ops/training.py:65 2019-01-16 12:05:35.313456: step 2117, loss = 0.70141 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:05:36.079087 ops/training.py:65 2019-01-16 12:05:36.079030: step 2118, loss = 0.71484 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:05:36.844442 ops/training.py:65 2019-01-16 12:05:36.844386: step 2119, loss = 0.69595 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:05:37.609087 ops/training.py:65 2019-01-16 12:05:37.609039: step 2120, loss = 0.68942 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:05:38.373674 ops/training.py:65 2019-01-16 12:05:38.373621: step 2121, loss = 0.66316 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:05:39.137527 ops/training.py:65 2019-01-16 12:05:39.137463: step 2122, loss = 0.69734 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:05:39.901255 ops/training.py:65 2019-01-16 12:05:39.901177: step 2123, loss = 0.72981 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:05:40.665461 ops/training.py:65 2019-01-16 12:05:40.665393: step 2124, loss = 0.69867 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:05:41.429188 ops/training.py:65 2019-01-16 12:05:41.429120: step 2125, loss = 0.70036 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:05:42.192649 ops/training.py:65 2019-01-16 12:05:42.192600: step 2126, loss = 0.66190 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:05:42.960139 ops/training.py:65 2019-01-16 12:05:42.960063: step 2127, loss = 0.71684 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:05:43.728306 ops/training.py:65 2019-01-16 12:05:43.728248: step 2128, loss = 0.73575 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:05:44.495866 ops/training.py:65 2019-01-16 12:05:44.495792: step 2129, loss = 0.67695 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:05:45.261627 ops/training.py:65 2019-01-16 12:05:45.261574: step 2130, loss = 0.71665 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:05:46.028697 ops/training.py:65 2019-01-16 12:05:46.028643: step 2131, loss = 0.68359 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:05:46.797743 ops/training.py:65 2019-01-16 12:05:46.797685: step 2132, loss = 0.69354 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:05:47.565627 ops/training.py:65 2019-01-16 12:05:47.565549: step 2133, loss = 0.70488 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:05:48.333684 ops/training.py:65 2019-01-16 12:05:48.333601: step 2134, loss = 0.71962 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:05:49.099538 ops/training.py:65 2019-01-16 12:05:49.099490: step 2135, loss = 0.74368 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:05:49.864240 ops/training.py:65 2019-01-16 12:05:49.864169: step 2136, loss = 0.71738 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:05:50.629259 ops/training.py:65 2019-01-16 12:05:50.629190: step 2137, loss = 0.69725 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:05:51.392711 ops/training.py:65 2019-01-16 12:05:51.392634: step 2138, loss = 0.71584 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:05:52.156388 ops/training.py:65 2019-01-16 12:05:52.156314: step 2139, loss = 0.72691 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:05:52.920963 ops/training.py:65 2019-01-16 12:05:52.920912: step 2140, loss = 0.70496 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:05:53.686382 ops/training.py:65 2019-01-16 12:05:53.686312: step 2141, loss = 0.68172 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:05:54.453353 ops/training.py:65 2019-01-16 12:05:54.453283: step 2142, loss = 0.69068 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:05:55.221594 ops/training.py:65 2019-01-16 12:05:55.221516: step 2143, loss = 0.73395 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:05:55.988840 ops/training.py:65 2019-01-16 12:05:55.988763: step 2144, loss = 0.67105 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:05:56.753990 ops/training.py:65 2019-01-16 12:05:56.753934: step 2145, loss = 0.69009 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:05:57.520022 ops/training.py:65 2019-01-16 12:05:57.519951: step 2146, loss = 0.72856 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:05:58.283366 ops/training.py:65 2019-01-16 12:05:58.283300: step 2147, loss = 0.72654 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:05:59.048044 ops/training.py:65 2019-01-16 12:05:59.047980: step 2148, loss = 0.72659 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:05:59.815547 ops/training.py:65 2019-01-16 12:05:59.815474: step 2149, loss = 0.68192 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:06:00.583236 ops/training.py:65 2019-01-16 12:06:00.583173: step 2150, loss = 0.68061 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:06:01.351275 ops/training.py:65 2019-01-16 12:06:01.351201: step 2151, loss = 0.69624 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:06:02.118528 ops/training.py:65 2019-01-16 12:06:02.118461: step 2152, loss = 0.69808 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:06:02.884368 ops/training.py:65 2019-01-16 12:06:02.884303: step 2153, loss = 0.72283 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:06:03.648854 ops/training.py:65 2019-01-16 12:06:03.648786: step 2154, loss = 0.69405 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:06:04.413290 ops/training.py:65 2019-01-16 12:06:04.413242: step 2155, loss = 0.70460 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:06:05.177031 ops/training.py:65 2019-01-16 12:06:05.176960: step 2156, loss = 0.71103 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:06:05.941483 ops/training.py:65 2019-01-16 12:06:05.941414: step 2157, loss = 0.67321 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:06:06.705317 ops/training.py:65 2019-01-16 12:06:06.705242: step 2158, loss = 0.72823 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:06:07.468350 ops/training.py:65 2019-01-16 12:06:07.468282: step 2159, loss = 0.69149 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:06:08.231574 ops/training.py:65 2019-01-16 12:06:08.231524: step 2160, loss = 0.71011 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:06:08.996571 ops/training.py:65 2019-01-16 12:06:08.996509: step 2161, loss = 0.68783 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:06:09.760696 ops/training.py:65 2019-01-16 12:06:09.760629: step 2162, loss = 0.70173 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:06:10.524568 ops/training.py:65 2019-01-16 12:06:10.524499: step 2163, loss = 0.67209 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:06:11.287485 ops/training.py:65 2019-01-16 12:06:11.287418: step 2164, loss = 0.71621 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:06:12.051740 ops/training.py:65 2019-01-16 12:06:12.051689: step 2165, loss = 0.68555 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:06:12.816346 ops/training.py:65 2019-01-16 12:06:12.816280: step 2166, loss = 0.69989 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:06:13.580895 ops/training.py:65 2019-01-16 12:06:13.580825: step 2167, loss = 0.68671 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:06:14.344684 ops/training.py:65 2019-01-16 12:06:14.344616: step 2168, loss = 0.68896 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:06:15.110019 ops/training.py:65 2019-01-16 12:06:15.109948: step 2169, loss = 0.71205 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:06:15.874338 ops/training.py:65 2019-01-16 12:06:15.874289: step 2170, loss = 0.69802 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:06:16.638189 ops/training.py:65 2019-01-16 12:06:16.638139: step 2171, loss = 0.69499 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:06:17.402095 ops/training.py:65 2019-01-16 12:06:17.402031: step 2172, loss = 0.69736 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:06:18.169537 ops/training.py:65 2019-01-16 12:06:18.169473: step 2173, loss = 0.70555 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:06:18.940404 ops/training.py:65 2019-01-16 12:06:18.940355: step 2174, loss = 0.70333 (41.6 examples/sec; 0.770 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:06:19.708737 ops/training.py:65 2019-01-16 12:06:19.708677: step 2175, loss = 0.71242 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:06:20.477728 ops/training.py:65 2019-01-16 12:06:20.477659: step 2176, loss = 0.70943 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:06:21.246534 ops/training.py:65 2019-01-16 12:06:21.246460: step 2177, loss = 0.70015 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:06:22.014317 ops/training.py:65 2019-01-16 12:06:22.014245: step 2178, loss = 0.68794 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:06:22.782926 ops/training.py:65 2019-01-16 12:06:22.782872: step 2179, loss = 0.70052 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:06:23.551538 ops/training.py:65 2019-01-16 12:06:23.551459: step 2180, loss = 0.68482 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:06:24.317548 ops/training.py:65 2019-01-16 12:06:24.317472: step 2181, loss = 0.66539 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:06:25.080825 ops/training.py:65 2019-01-16 12:06:25.080758: step 2182, loss = 0.68207 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:06:25.844500 ops/training.py:65 2019-01-16 12:06:25.844434: step 2183, loss = 0.65158 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:06:26.609507 ops/training.py:65 2019-01-16 12:06:26.609460: step 2184, loss = 0.72832 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:06:27.374040 ops/training.py:65 2019-01-16 12:06:27.373972: step 2185, loss = 0.68984 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:06:28.138943 ops/training.py:65 2019-01-16 12:06:28.138875: step 2186, loss = 0.73306 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:06:28.903903 ops/training.py:65 2019-01-16 12:06:28.903843: step 2187, loss = 0.69719 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:06:29.667689 ops/training.py:65 2019-01-16 12:06:29.667620: step 2188, loss = 0.71184 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:06:30.436502 ops/training.py:65 2019-01-16 12:06:30.436452: step 2189, loss = 0.69231 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:06:31.204807 ops/training.py:65 2019-01-16 12:06:31.204734: step 2190, loss = 0.70178 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:06:31.973407 ops/training.py:65 2019-01-16 12:06:31.973341: step 2191, loss = 0.71002 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:06:32.740522 ops/training.py:65 2019-01-16 12:06:32.740448: step 2192, loss = 0.72566 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:06:33.510516 ops/training.py:65 2019-01-16 12:06:33.510442: step 2193, loss = 0.73851 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:06:34.279567 ops/training.py:65 2019-01-16 12:06:34.279501: step 2194, loss = 0.68393 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:06:35.046153 ops/training.py:65 2019-01-16 12:06:35.046076: step 2195, loss = 0.70777 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:06:35.814315 ops/training.py:65 2019-01-16 12:06:35.814241: step 2196, loss = 0.71680 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:06:36.581550 ops/training.py:65 2019-01-16 12:06:36.581497: step 2197, loss = 0.73092 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:06:37.345842 ops/training.py:65 2019-01-16 12:06:37.345777: step 2198, loss = 0.73621 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:06:38.110907 ops/training.py:65 2019-01-16 12:06:38.110855: step 2199, loss = 0.70667 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:06:38.875685 ops/training.py:65 2019-01-16 12:06:38.875622: step 2200, loss = 0.73866 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:06:39.640110 ops/training.py:65 2019-01-16 12:06:39.640037: step 2201, loss = 0.70783 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:06:40.404281 ops/training.py:65 2019-01-16 12:06:40.404209: step 2202, loss = 0.71578 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:06:41.167318 ops/training.py:65 2019-01-16 12:06:41.167254: step 2203, loss = 0.65857 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:06:41.930536 ops/training.py:65 2019-01-16 12:06:41.930487: step 2204, loss = 0.67679 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:06:42.693644 ops/training.py:65 2019-01-16 12:06:42.693579: step 2205, loss = 0.66471 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:06:43.461313 ops/training.py:65 2019-01-16 12:06:43.461236: step 2206, loss = 0.70467 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:06:44.228605 ops/training.py:65 2019-01-16 12:06:44.228525: step 2207, loss = 0.74391 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:06:44.997812 ops/training.py:65 2019-01-16 12:06:44.997733: step 2208, loss = 0.70465 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:06:45.765739 ops/training.py:65 2019-01-16 12:06:45.765669: step 2209, loss = 0.69618 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:06:46.531902 ops/training.py:65 2019-01-16 12:06:46.531851: step 2210, loss = 0.72149 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:06:47.296741 ops/training.py:65 2019-01-16 12:06:47.296679: step 2211, loss = 0.68796 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:06:48.061473 ops/training.py:65 2019-01-16 12:06:48.061405: step 2212, loss = 0.73098 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 12:06:48.825472 ops/training.py:65 2019-01-16 12:06:48.825411: step 2213, loss = 0.69640 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:06:49.590303 ops/training.py:65 2019-01-16 12:06:49.590249: step 2214, loss = 0.68654 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:06:50.354437 ops/training.py:65 2019-01-16 12:06:50.354368: step 2215, loss = 0.71022 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:06:51.118900 ops/training.py:65 2019-01-16 12:06:51.118831: step 2216, loss = 0.71519 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:06:51.883823 ops/training.py:65 2019-01-16 12:06:51.883759: step 2217, loss = 0.66960 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:06:52.648817 ops/training.py:65 2019-01-16 12:06:52.648760: step 2218, loss = 0.71571 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:06:53.412895 ops/training.py:65 2019-01-16 12:06:53.412846: step 2219, loss = 0.68014 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:06:54.176742 ops/training.py:65 2019-01-16 12:06:54.176672: step 2220, loss = 0.68896 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:06:54.941090 ops/training.py:65 2019-01-16 12:06:54.941024: step 2221, loss = 0.73829 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:06:55.705603 ops/training.py:65 2019-01-16 12:06:55.705537: step 2222, loss = 0.73215 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:06:56.468908 ops/training.py:65 2019-01-16 12:06:56.468860: step 2223, loss = 0.68417 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:06:57.232634 ops/training.py:65 2019-01-16 12:06:57.232568: step 2224, loss = 0.66510 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:06:57.995750 ops/training.py:65 2019-01-16 12:06:57.995685: step 2225, loss = 0.72898 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:06:58.762084 ops/training.py:65 2019-01-16 12:06:58.762024: step 2226, loss = 0.73573 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:06:59.532246 ops/training.py:65 2019-01-16 12:06:59.532170: step 2227, loss = 0.67580 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:07:00.302054 ops/training.py:65 2019-01-16 12:07:00.301990: step 2228, loss = 0.68348 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:07:01.071760 ops/training.py:65 2019-01-16 12:07:01.071683: step 2229, loss = 0.69287 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:07:01.838250 ops/training.py:65 2019-01-16 12:07:01.838195: step 2230, loss = 0.70202 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:07:02.606320 ops/training.py:65 2019-01-16 12:07:02.606262: step 2231, loss = 0.69221 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:07:03.374772 ops/training.py:65 2019-01-16 12:07:03.374703: step 2232, loss = 0.74213 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:07:04.143812 ops/training.py:65 2019-01-16 12:07:04.143742: step 2233, loss = 0.71386 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:07:04.911172 ops/training.py:65 2019-01-16 12:07:04.911096: step 2234, loss = 0.70502 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:07:05.679784 ops/training.py:65 2019-01-16 12:07:05.679727: step 2235, loss = 0.68406 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:07:06.445987 ops/training.py:65 2019-01-16 12:07:06.445934: step 2236, loss = 0.69284 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:07:07.214167 ops/training.py:65 2019-01-16 12:07:07.214113: step 2237, loss = 0.68750 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:07:07.978626 ops/training.py:65 2019-01-16 12:07:07.978578: step 2238, loss = 0.69455 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:07:08.741438 ops/training.py:65 2019-01-16 12:07:08.741386: step 2239, loss = 0.74270 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:07:09.505911 ops/training.py:65 2019-01-16 12:07:09.505838: step 2240, loss = 0.73993 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:07:10.268945 ops/training.py:65 2019-01-16 12:07:10.268876: step 2241, loss = 0.76701 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:07:11.036501 ops/training.py:65 2019-01-16 12:07:11.036428: step 2242, loss = 0.71918 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:07:11.804768 ops/training.py:65 2019-01-16 12:07:11.804691: step 2243, loss = 0.66367 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:07:12.572097 ops/training.py:65 2019-01-16 12:07:12.572026: step 2244, loss = 0.72155 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:07:13.337581 ops/training.py:65 2019-01-16 12:07:13.337514: step 2245, loss = 0.65572 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 12:07:14.102295 ops/training.py:65 2019-01-16 12:07:14.102227: step 2246, loss = 0.76855 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:07:14.870887 ops/training.py:65 2019-01-16 12:07:14.870819: step 2247, loss = 0.68629 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:07:15.638889 ops/training.py:65 2019-01-16 12:07:15.638812: step 2248, loss = 0.66609 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:07:16.407154 ops/training.py:65 2019-01-16 12:07:16.407084: step 2249, loss = 0.71425 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:07:17.171679 ops/training.py:65 2019-01-16 12:07:17.171613: step 2250, loss = 0.75242 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:07:17.936709 ops/training.py:65 2019-01-16 12:07:17.936642: step 2251, loss = 0.73744 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:07:18.700321 ops/training.py:65 2019-01-16 12:07:18.700253: step 2252, loss = 0.67397 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:07:19.463757 ops/training.py:65 2019-01-16 12:07:19.463707: step 2253, loss = 0.70239 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:07:20.228575 ops/training.py:65 2019-01-16 12:07:20.228508: step 2254, loss = 0.74431 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:07:20.993509 ops/training.py:65 2019-01-16 12:07:20.993437: step 2255, loss = 0.71625 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:07:21.760456 ops/training.py:65 2019-01-16 12:07:21.760382: step 2256, loss = 0.74095 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:07:22.528652 ops/training.py:65 2019-01-16 12:07:22.528585: step 2257, loss = 0.70673 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:07:23.296670 ops/training.py:65 2019-01-16 12:07:23.296609: step 2258, loss = 0.73394 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:07:24.063341 ops/training.py:65 2019-01-16 12:07:24.063268: step 2259, loss = 0.71547 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:07:24.831205 ops/training.py:65 2019-01-16 12:07:24.831133: step 2260, loss = 0.71963 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:07:25.597938 ops/training.py:65 2019-01-16 12:07:25.597873: step 2261, loss = 0.79578 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:07:26.365617 ops/training.py:65 2019-01-16 12:07:26.365546: step 2262, loss = 0.68488 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:07:27.134039 ops/training.py:65 2019-01-16 12:07:27.133975: step 2263, loss = 0.70544 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:07:27.904407 ops/training.py:65 2019-01-16 12:07:27.904340: step 2264, loss = 0.69806 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:07:28.673578 ops/training.py:65 2019-01-16 12:07:28.673513: step 2265, loss = 0.68900 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:07:29.441969 ops/training.py:65 2019-01-16 12:07:29.441902: step 2266, loss = 0.76293 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:07:30.210597 ops/training.py:65 2019-01-16 12:07:30.210524: step 2267, loss = 0.67761 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:07:30.979790 ops/training.py:65 2019-01-16 12:07:30.979721: step 2268, loss = 0.70121 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:07:31.746129 ops/training.py:65 2019-01-16 12:07:31.746078: step 2269, loss = 0.75291 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:07:32.514675 ops/training.py:65 2019-01-16 12:07:32.514597: step 2270, loss = 0.69729 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:07:33.283476 ops/training.py:65 2019-01-16 12:07:33.283429: step 2271, loss = 0.71289 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:07:34.051841 ops/training.py:65 2019-01-16 12:07:34.051770: step 2272, loss = 0.68993 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:07:34.820333 ops/training.py:65 2019-01-16 12:07:34.820267: step 2273, loss = 0.73353 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:07:35.587254 ops/training.py:65 2019-01-16 12:07:35.587181: step 2274, loss = 0.70667 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:07:36.355894 ops/training.py:65 2019-01-16 12:07:36.355819: step 2275, loss = 0.76143 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:07:37.124048 ops/training.py:65 2019-01-16 12:07:37.123988: step 2276, loss = 0.74959 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:07:37.891676 ops/training.py:65 2019-01-16 12:07:37.891607: step 2277, loss = 0.64715 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:07:38.657682 ops/training.py:65 2019-01-16 12:07:38.657624: step 2278, loss = 0.72018 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:07:39.424007 ops/training.py:65 2019-01-16 12:07:39.423932: step 2279, loss = 0.74554 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:07:40.188007 ops/training.py:65 2019-01-16 12:07:40.187941: step 2280, loss = 0.70803 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:07:40.952702 ops/training.py:65 2019-01-16 12:07:40.952636: step 2281, loss = 0.67542 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:07:41.721342 ops/training.py:65 2019-01-16 12:07:41.721298: step 2282, loss = 0.70483 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:07:42.491292 ops/training.py:65 2019-01-16 12:07:42.491241: step 2283, loss = 0.66776 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:07:43.259947 ops/training.py:65 2019-01-16 12:07:43.259877: step 2284, loss = 0.75471 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:07:44.028664 ops/training.py:65 2019-01-16 12:07:44.028588: step 2285, loss = 0.74442 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:07:44.796987 ops/training.py:65 2019-01-16 12:07:44.796911: step 2286, loss = 0.67786 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:07:45.565989 ops/training.py:65 2019-01-16 12:07:45.565915: step 2287, loss = 0.69985 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:07:46.335557 ops/training.py:65 2019-01-16 12:07:46.335486: step 2288, loss = 0.72875 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:07:47.104791 ops/training.py:65 2019-01-16 12:07:47.104736: step 2289, loss = 0.72990 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:07:47.871236 ops/training.py:65 2019-01-16 12:07:47.871158: step 2290, loss = 0.66953 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:07:48.639457 ops/training.py:65 2019-01-16 12:07:48.639401: step 2291, loss = 0.71488 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:07:49.407622 ops/training.py:65 2019-01-16 12:07:49.407550: step 2292, loss = 0.69666 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:07:50.174983 ops/training.py:65 2019-01-16 12:07:50.174908: step 2293, loss = 0.68149 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:07:50.943024 ops/training.py:65 2019-01-16 12:07:50.942950: step 2294, loss = 0.66518 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:07:51.710346 ops/training.py:65 2019-01-16 12:07:51.710289: step 2295, loss = 0.72169 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:07:52.476927 ops/training.py:65 2019-01-16 12:07:52.476854: step 2296, loss = 0.69215 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:07:53.243357 ops/training.py:65 2019-01-16 12:07:53.243285: step 2297, loss = 0.69283 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:07:54.008839 ops/training.py:65 2019-01-16 12:07:54.008773: step 2298, loss = 0.68811 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:07:54.773237 ops/training.py:65 2019-01-16 12:07:54.773170: step 2299, loss = 0.72556 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:07:55.538034 ops/training.py:65 2019-01-16 12:07:55.537967: step 2300, loss = 0.67291 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:07:56.302180 ops/training.py:65 2019-01-16 12:07:56.302114: step 2301, loss = 0.70574 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:07:57.066060 ops/training.py:65 2019-01-16 12:07:57.066014: step 2302, loss = 0.72069 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:07:57.830711 ops/training.py:65 2019-01-16 12:07:57.830647: step 2303, loss = 0.71008 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:07:58.595222 ops/training.py:65 2019-01-16 12:07:58.595155: step 2304, loss = 0.74868 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:07:59.359228 ops/training.py:65 2019-01-16 12:07:59.359159: step 2305, loss = 0.68404 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:08:00.123206 ops/training.py:65 2019-01-16 12:08:00.123141: step 2306, loss = 0.67317 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:08:00.887473 ops/training.py:65 2019-01-16 12:08:00.887425: step 2307, loss = 0.67973 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:08:01.651461 ops/training.py:65 2019-01-16 12:08:01.651412: step 2308, loss = 0.67991 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:08:02.415271 ops/training.py:65 2019-01-16 12:08:02.415212: step 2309, loss = 0.68312 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:08:03.178254 ops/training.py:65 2019-01-16 12:08:03.178188: step 2310, loss = 0.68162 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:08:03.942880 ops/training.py:65 2019-01-16 12:08:03.942812: step 2311, loss = 0.65430 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:08:04.710391 ops/training.py:65 2019-01-16 12:08:04.710358: step 2312, loss = 0.71234 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:08:05.479071 ops/training.py:65 2019-01-16 12:08:05.479005: step 2313, loss = 0.71341 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:08:06.247357 ops/training.py:65 2019-01-16 12:08:06.247287: step 2314, loss = 0.67998 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:08:07.014853 ops/training.py:65 2019-01-16 12:08:07.014774: step 2315, loss = 0.63543 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 12:08:07.784067 ops/training.py:65 2019-01-16 12:08:07.783991: step 2316, loss = 0.71664 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:08:08.552344 ops/training.py:65 2019-01-16 12:08:08.552287: step 2317, loss = 0.69616 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:08:09.318507 ops/training.py:65 2019-01-16 12:08:09.318437: step 2318, loss = 0.68858 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:08:10.083497 ops/training.py:65 2019-01-16 12:08:10.083425: step 2319, loss = 0.73552 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:08:10.847847 ops/training.py:65 2019-01-16 12:08:10.847775: step 2320, loss = 0.73154 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:08:11.612865 ops/training.py:65 2019-01-16 12:08:11.612798: step 2321, loss = 0.68671 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:08:12.377484 ops/training.py:65 2019-01-16 12:08:12.377430: step 2322, loss = 0.71191 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:08:13.142737 ops/training.py:65 2019-01-16 12:08:13.142670: step 2323, loss = 0.71197 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:08:13.907313 ops/training.py:65 2019-01-16 12:08:13.907244: step 2324, loss = 0.69539 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:08:14.673808 ops/training.py:65 2019-01-16 12:08:14.673734: step 2325, loss = 0.72103 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:08:15.441601 ops/training.py:65 2019-01-16 12:08:15.441529: step 2326, loss = 0.72209 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:08:16.208656 ops/training.py:65 2019-01-16 12:08:16.208588: step 2327, loss = 0.66482 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:08:16.974097 ops/training.py:65 2019-01-16 12:08:16.974049: step 2328, loss = 0.68821 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:08:17.738582 ops/training.py:65 2019-01-16 12:08:17.738516: step 2329, loss = 0.69348 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:08:18.503029 ops/training.py:65 2019-01-16 12:08:18.502962: step 2330, loss = 0.69973 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:08:19.271304 ops/training.py:65 2019-01-16 12:08:19.271252: step 2331, loss = 0.71879 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:08:20.038910 ops/training.py:65 2019-01-16 12:08:20.038847: step 2332, loss = 0.71695 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:08:20.806781 ops/training.py:65 2019-01-16 12:08:20.806704: step 2333, loss = 0.70783 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:08:21.575048 ops/training.py:65 2019-01-16 12:08:21.574989: step 2334, loss = 0.69950 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:08:22.343892 ops/training.py:65 2019-01-16 12:08:22.343815: step 2335, loss = 0.74793 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:08:23.111962 ops/training.py:65 2019-01-16 12:08:23.111888: step 2336, loss = 0.69995 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:08:23.880320 ops/training.py:65 2019-01-16 12:08:23.880249: step 2337, loss = 0.68990 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:08:24.648168 ops/training.py:65 2019-01-16 12:08:24.648103: step 2338, loss = 0.67859 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:08:25.415064 ops/training.py:65 2019-01-16 12:08:25.415008: step 2339, loss = 0.70763 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:08:26.181732 ops/training.py:65 2019-01-16 12:08:26.181676: step 2340, loss = 0.69013 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:08:26.946952 ops/training.py:65 2019-01-16 12:08:26.946898: step 2341, loss = 0.67164 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:08:27.711791 ops/training.py:65 2019-01-16 12:08:27.711744: step 2342, loss = 0.67877 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:08:28.475471 ops/training.py:65 2019-01-16 12:08:28.475401: step 2343, loss = 0.68847 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:08:29.239556 ops/training.py:65 2019-01-16 12:08:29.239492: step 2344, loss = 0.65676 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:08:30.005025 ops/training.py:65 2019-01-16 12:08:30.004959: step 2345, loss = 0.67484 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:08:30.768117 ops/training.py:65 2019-01-16 12:08:30.768070: step 2346, loss = 0.70409 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:08:31.532451 ops/training.py:65 2019-01-16 12:08:31.532403: step 2347, loss = 0.72250 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:08:32.299515 ops/training.py:65 2019-01-16 12:08:32.299455: step 2348, loss = 0.75732 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 12:08:33.068585 ops/training.py:65 2019-01-16 12:08:33.068523: step 2349, loss = 0.71974 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:08:33.837824 ops/training.py:65 2019-01-16 12:08:33.837754: step 2350, loss = 0.69934 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:08:34.606004 ops/training.py:65 2019-01-16 12:08:34.605925: step 2351, loss = 0.74532 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:08:35.374235 ops/training.py:65 2019-01-16 12:08:35.374161: step 2352, loss = 0.72556 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:08:36.142838 ops/training.py:65 2019-01-16 12:08:36.142764: step 2353, loss = 0.67795 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:08:36.910131 ops/training.py:65 2019-01-16 12:08:36.910082: step 2354, loss = 0.67162 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:08:37.677072 ops/training.py:65 2019-01-16 12:08:37.677003: step 2355, loss = 0.66303 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 12:08:38.444514 ops/training.py:65 2019-01-16 12:08:38.444457: step 2356, loss = 0.70154 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:08:39.210856 ops/training.py:65 2019-01-16 12:08:39.210787: step 2357, loss = 0.72315 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:08:39.975547 ops/training.py:65 2019-01-16 12:08:39.975478: step 2358, loss = 0.68987 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:08:40.739226 ops/training.py:65 2019-01-16 12:08:40.739158: step 2359, loss = 0.67469 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:08:41.503550 ops/training.py:65 2019-01-16 12:08:41.503485: step 2360, loss = 0.68988 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:08:42.267095 ops/training.py:65 2019-01-16 12:08:42.267046: step 2361, loss = 0.71871 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:08:43.030090 ops/training.py:65 2019-01-16 12:08:43.030019: step 2362, loss = 0.69805 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:08:43.794088 ops/training.py:65 2019-01-16 12:08:43.794014: step 2363, loss = 0.68862 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:08:44.558625 ops/training.py:65 2019-01-16 12:08:44.558558: step 2364, loss = 0.67463 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:08:45.322873 ops/training.py:65 2019-01-16 12:08:45.322804: step 2365, loss = 0.72507 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:08:46.087184 ops/training.py:65 2019-01-16 12:08:46.087135: step 2366, loss = 0.73114 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:08:46.851142 ops/training.py:65 2019-01-16 12:08:46.851092: step 2367, loss = 0.69448 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:08:47.614505 ops/training.py:65 2019-01-16 12:08:47.614441: step 2368, loss = 0.72071 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:08:48.378919 ops/training.py:65 2019-01-16 12:08:48.378855: step 2369, loss = 0.73068 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:08:49.143828 ops/training.py:65 2019-01-16 12:08:49.143759: step 2370, loss = 0.69402 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:08:49.908481 ops/training.py:65 2019-01-16 12:08:49.908434: step 2371, loss = 0.67203 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:08:50.672563 ops/training.py:65 2019-01-16 12:08:50.672504: step 2372, loss = 0.69835 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:08:51.441159 ops/training.py:65 2019-01-16 12:08:51.441089: step 2373, loss = 0.69552 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:08:52.210526 ops/training.py:65 2019-01-16 12:08:52.210456: step 2374, loss = 0.66789 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:08:52.977812 ops/training.py:65 2019-01-16 12:08:52.977741: step 2375, loss = 0.70652 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:08:53.742509 ops/training.py:65 2019-01-16 12:08:53.742462: step 2376, loss = 0.70968 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:08:54.506684 ops/training.py:65 2019-01-16 12:08:54.506622: step 2377, loss = 0.73864 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 12:08:55.274879 ops/training.py:65 2019-01-16 12:08:55.274812: step 2378, loss = 0.68286 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:08:56.043268 ops/training.py:65 2019-01-16 12:08:56.043198: step 2379, loss = 0.68297 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:08:56.812607 ops/training.py:65 2019-01-16 12:08:56.812531: step 2380, loss = 0.69940 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:08:57.579294 ops/training.py:65 2019-01-16 12:08:57.579228: step 2381, loss = 0.65719 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:08:58.343387 ops/training.py:65 2019-01-16 12:08:58.343320: step 2382, loss = 0.69741 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:08:59.107294 ops/training.py:65 2019-01-16 12:08:59.107233: step 2383, loss = 0.67300 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:08:59.872007 ops/training.py:65 2019-01-16 12:08:59.871938: step 2384, loss = 0.67335 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:09:00.637395 ops/training.py:65 2019-01-16 12:09:00.637325: step 2385, loss = 0.70959 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:09:01.401284 ops/training.py:65 2019-01-16 12:09:01.401236: step 2386, loss = 0.71798 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:09:02.164605 ops/training.py:65 2019-01-16 12:09:02.164554: step 2387, loss = 0.72139 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:09:02.929076 ops/training.py:65 2019-01-16 12:09:02.929012: step 2388, loss = 0.68256 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:09:03.693274 ops/training.py:65 2019-01-16 12:09:03.693206: step 2389, loss = 0.68018 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:09:04.458099 ops/training.py:65 2019-01-16 12:09:04.458033: step 2390, loss = 0.72854 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:09:05.222529 ops/training.py:65 2019-01-16 12:09:05.222478: step 2391, loss = 0.69989 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:09:05.989021 ops/training.py:65 2019-01-16 12:09:05.988951: step 2392, loss = 0.72287 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:09:06.756962 ops/training.py:65 2019-01-16 12:09:06.756905: step 2393, loss = 0.71505 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:09:07.524481 ops/training.py:65 2019-01-16 12:09:07.524402: step 2394, loss = 0.74542 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:09:08.292195 ops/training.py:65 2019-01-16 12:09:08.292116: step 2395, loss = 0.68519 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:09:09.058740 ops/training.py:65 2019-01-16 12:09:09.058686: step 2396, loss = 0.69429 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:09:09.823519 ops/training.py:65 2019-01-16 12:09:09.823450: step 2397, loss = 0.71088 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:09:10.587384 ops/training.py:65 2019-01-16 12:09:10.587310: step 2398, loss = 0.68400 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:09:11.355129 ops/training.py:65 2019-01-16 12:09:11.355058: step 2399, loss = 0.71027 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:09:12.123615 ops/training.py:65 2019-01-16 12:09:12.123567: step 2400, loss = 0.65653 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:09:12.891535 ops/training.py:65 2019-01-16 12:09:12.891466: step 2401, loss = 0.68900 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:09:13.659668 ops/training.py:65 2019-01-16 12:09:13.659588: step 2402, loss = 0.70037 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:09:14.426453 ops/training.py:65 2019-01-16 12:09:14.426381: step 2403, loss = 0.67257 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:09:15.191348 ops/training.py:65 2019-01-16 12:09:15.191281: step 2404, loss = 0.69096 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:09:15.955356 ops/training.py:65 2019-01-16 12:09:15.955307: step 2405, loss = 0.69415 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:09:16.719568 ops/training.py:65 2019-01-16 12:09:16.719516: step 2406, loss = 0.70517 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:09:17.484201 ops/training.py:65 2019-01-16 12:09:17.484139: step 2407, loss = 0.71063 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:09:18.249134 ops/training.py:65 2019-01-16 12:09:18.249067: step 2408, loss = 0.70642 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:09:19.013595 ops/training.py:65 2019-01-16 12:09:19.013533: step 2409, loss = 0.70755 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:09:19.777142 ops/training.py:65 2019-01-16 12:09:19.777090: step 2410, loss = 0.70227 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:09:20.541136 ops/training.py:65 2019-01-16 12:09:20.541068: step 2411, loss = 0.71151 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:09:21.304468 ops/training.py:65 2019-01-16 12:09:21.304400: step 2412, loss = 0.71125 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:09:22.067940 ops/training.py:65 2019-01-16 12:09:22.067876: step 2413, loss = 0.69499 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:09:22.831815 ops/training.py:65 2019-01-16 12:09:22.831746: step 2414, loss = 0.72424 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:09:23.596527 ops/training.py:65 2019-01-16 12:09:23.596477: step 2415, loss = 0.68478 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:09:24.360818 ops/training.py:65 2019-01-16 12:09:24.360752: step 2416, loss = 0.68293 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:09:25.126924 ops/training.py:65 2019-01-16 12:09:25.126853: step 2417, loss = 0.69450 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:09:25.895567 ops/training.py:65 2019-01-16 12:09:25.895490: step 2418, loss = 0.66775 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:09:26.665046 ops/training.py:65 2019-01-16 12:09:26.664953: step 2419, loss = 0.72000 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:09:27.434497 ops/training.py:65 2019-01-16 12:09:27.434433: step 2420, loss = 0.71169 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:09:28.204093 ops/training.py:65 2019-01-16 12:09:28.204024: step 2421, loss = 0.67944 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:09:28.971827 ops/training.py:65 2019-01-16 12:09:28.971761: step 2422, loss = 0.68192 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:09:29.738888 ops/training.py:65 2019-01-16 12:09:29.738816: step 2423, loss = 0.69406 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:09:30.506781 ops/training.py:65 2019-01-16 12:09:30.506710: step 2424, loss = 0.69035 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:09:31.274266 ops/training.py:65 2019-01-16 12:09:31.274195: step 2425, loss = 0.69118 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:09:32.041900 ops/training.py:65 2019-01-16 12:09:32.041846: step 2426, loss = 0.68899 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:09:32.808415 ops/training.py:65 2019-01-16 12:09:32.808357: step 2427, loss = 0.65880 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:09:33.576268 ops/training.py:65 2019-01-16 12:09:33.576208: step 2428, loss = 0.67893 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:09:34.344968 ops/training.py:65 2019-01-16 12:09:34.344909: step 2429, loss = 0.71882 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:09:35.112723 ops/training.py:65 2019-01-16 12:09:35.112695: step 2430, loss = 0.69153 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:09:35.878954 ops/training.py:65 2019-01-16 12:09:35.878897: step 2431, loss = 0.68837 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:09:36.644122 ops/training.py:65 2019-01-16 12:09:36.644071: step 2432, loss = 0.71125 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:09:37.408383 ops/training.py:65 2019-01-16 12:09:37.408328: step 2433, loss = 0.70645 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:09:38.172948 ops/training.py:65 2019-01-16 12:09:38.172891: step 2434, loss = 0.67780 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:09:38.939456 ops/training.py:65 2019-01-16 12:09:38.939406: step 2435, loss = 0.70542 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:09:39.706688 ops/training.py:65 2019-01-16 12:09:39.706627: step 2436, loss = 0.72202 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:09:40.473065 ops/training.py:65 2019-01-16 12:09:40.472990: step 2437, loss = 0.69321 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:09:41.240206 ops/training.py:65 2019-01-16 12:09:41.240128: step 2438, loss = 0.69708 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:09:42.008582 ops/training.py:65 2019-01-16 12:09:42.008508: step 2439, loss = 0.67115 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:09:42.774814 ops/training.py:65 2019-01-16 12:09:42.774738: step 2440, loss = 0.70590 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:09:43.539172 ops/training.py:65 2019-01-16 12:09:43.539117: step 2441, loss = 0.69318 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:09:44.303843 ops/training.py:65 2019-01-16 12:09:44.303772: step 2442, loss = 0.70881 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:09:45.069368 ops/training.py:65 2019-01-16 12:09:45.069299: step 2443, loss = 0.67517 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:09:45.833739 ops/training.py:65 2019-01-16 12:09:45.833674: step 2444, loss = 0.71110 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:09:46.597986 ops/training.py:65 2019-01-16 12:09:46.597932: step 2445, loss = 0.75181 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:09:47.363053 ops/training.py:65 2019-01-16 12:09:47.362986: step 2446, loss = 0.67668 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:09:48.126869 ops/training.py:65 2019-01-16 12:09:48.126801: step 2447, loss = 0.71109 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:09:48.891355 ops/training.py:65 2019-01-16 12:09:48.891294: step 2448, loss = 0.70362 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:09:49.655122 ops/training.py:65 2019-01-16 12:09:49.655075: step 2449, loss = 0.70053 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:09:50.419262 ops/training.py:65 2019-01-16 12:09:50.419194: step 2450, loss = 0.68444 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:09:51.184079 ops/training.py:65 2019-01-16 12:09:51.184009: step 2451, loss = 0.69366 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:09:51.948358 ops/training.py:65 2019-01-16 12:09:51.948306: step 2452, loss = 0.69918 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:09:52.713258 ops/training.py:65 2019-01-16 12:09:52.713199: step 2453, loss = 0.68251 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:09:53.477594 ops/training.py:65 2019-01-16 12:09:53.477547: step 2454, loss = 0.68166 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:09:54.241989 ops/training.py:65 2019-01-16 12:09:54.241918: step 2455, loss = 0.67169 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:09:55.005766 ops/training.py:65 2019-01-16 12:09:55.005701: step 2456, loss = 0.70096 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:09:55.770850 ops/training.py:65 2019-01-16 12:09:55.770782: step 2457, loss = 0.64334 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:09:56.537371 ops/training.py:65 2019-01-16 12:09:56.537300: step 2458, loss = 0.73177 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:09:57.305243 ops/training.py:65 2019-01-16 12:09:57.305178: step 2459, loss = 0.70515 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:09:58.073284 ops/training.py:65 2019-01-16 12:09:58.073212: step 2460, loss = 0.70559 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:09:58.840829 ops/training.py:65 2019-01-16 12:09:58.840765: step 2461, loss = 0.68617 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:09:59.605252 ops/training.py:65 2019-01-16 12:09:59.605192: step 2462, loss = 0.68833 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:10:00.369241 ops/training.py:65 2019-01-16 12:10:00.369175: step 2463, loss = 0.69659 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:10:01.133811 ops/training.py:65 2019-01-16 12:10:01.133762: step 2464, loss = 0.66352 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:10:01.898408 ops/training.py:65 2019-01-16 12:10:01.898358: step 2465, loss = 0.70016 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:10:02.663144 ops/training.py:65 2019-01-16 12:10:02.663074: step 2466, loss = 0.71825 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:10:03.427492 ops/training.py:65 2019-01-16 12:10:03.427420: step 2467, loss = 0.68809 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:10:04.191844 ops/training.py:65 2019-01-16 12:10:04.191770: step 2468, loss = 0.72581 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:10:04.956671 ops/training.py:65 2019-01-16 12:10:04.956617: step 2469, loss = 0.67145 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:10:05.721539 ops/training.py:65 2019-01-16 12:10:05.721469: step 2470, loss = 0.69840 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:10:06.486438 ops/training.py:65 2019-01-16 12:10:06.486363: step 2471, loss = 0.70455 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:10:07.251534 ops/training.py:65 2019-01-16 12:10:07.251458: step 2472, loss = 0.71287 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:10:08.014775 ops/training.py:65 2019-01-16 12:10:08.014705: step 2473, loss = 0.71246 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:10:08.779122 ops/training.py:65 2019-01-16 12:10:08.779071: step 2474, loss = 0.71428 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:10:09.544717 ops/training.py:65 2019-01-16 12:10:09.544641: step 2475, loss = 0.70041 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:10:10.309771 ops/training.py:65 2019-01-16 12:10:10.309698: step 2476, loss = 0.68699 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:10:11.073547 ops/training.py:65 2019-01-16 12:10:11.073479: step 2477, loss = 0.69893 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:10:11.837920 ops/training.py:65 2019-01-16 12:10:11.837851: step 2478, loss = 0.70165 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:10:12.603024 ops/training.py:65 2019-01-16 12:10:12.602975: step 2479, loss = 0.70576 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:10:13.368919 ops/training.py:65 2019-01-16 12:10:13.368848: step 2480, loss = 0.71166 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:10:14.132469 ops/training.py:65 2019-01-16 12:10:14.132401: step 2481, loss = 0.69368 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:10:14.896878 ops/training.py:65 2019-01-16 12:10:14.896799: step 2482, loss = 0.69183 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:10:15.661683 ops/training.py:65 2019-01-16 12:10:15.661638: step 2483, loss = 0.67929 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:10:16.425302 ops/training.py:65 2019-01-16 12:10:16.425252: step 2484, loss = 0.70903 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:10:17.190030 ops/training.py:65 2019-01-16 12:10:17.189976: step 2485, loss = 0.69734 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:10:17.954258 ops/training.py:65 2019-01-16 12:10:17.954195: step 2486, loss = 0.68536 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:10:18.721397 ops/training.py:65 2019-01-16 12:10:18.721322: step 2487, loss = 0.69657 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:10:19.489153 ops/training.py:65 2019-01-16 12:10:19.489076: step 2488, loss = 0.70094 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:10:20.255952 ops/training.py:65 2019-01-16 12:10:20.255881: step 2489, loss = 0.73638 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:10:21.020317 ops/training.py:65 2019-01-16 12:10:21.020248: step 2490, loss = 0.69382 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:10:21.784960 ops/training.py:65 2019-01-16 12:10:21.784913: step 2491, loss = 0.67407 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 12:10:22.549440 ops/training.py:65 2019-01-16 12:10:22.549373: step 2492, loss = 0.69817 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:10:23.317226 ops/training.py:65 2019-01-16 12:10:23.317184: step 2493, loss = 0.69091 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:10:24.084972 ops/training.py:65 2019-01-16 12:10:24.084896: step 2494, loss = 0.68539 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:10:24.852455 ops/training.py:65 2019-01-16 12:10:24.852376: step 2495, loss = 0.69935 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:10:25.620525 ops/training.py:65 2019-01-16 12:10:25.620454: step 2496, loss = 0.70545 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:10:26.389008 ops/training.py:65 2019-01-16 12:10:26.388929: step 2497, loss = 0.70288 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:10:27.156246 ops/training.py:65 2019-01-16 12:10:27.156199: step 2498, loss = 0.69974 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:10:27.921296 ops/training.py:65 2019-01-16 12:10:27.921227: step 2499, loss = 0.71344 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:10:28.686576 ops/training.py:65 2019-01-16 12:10:28.686508: step 2500, loss = 0.68055 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:10:29.450672 ops/training.py:65 2019-01-16 12:10:29.450603: step 2501, loss = 0.69061 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:10:30.218567 ops/training.py:65 2019-01-16 12:10:30.218492: step 2502, loss = 0.68759 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:10:30.986587 ops/training.py:65 2019-01-16 12:10:30.986517: step 2503, loss = 0.70468 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:10:31.756062 ops/training.py:65 2019-01-16 12:10:31.756007: step 2504, loss = 0.71020 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:10:32.525143 ops/training.py:65 2019-01-16 12:10:32.525069: step 2505, loss = 0.68687 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:10:33.293392 ops/training.py:65 2019-01-16 12:10:33.293319: step 2506, loss = 0.68863 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:10:34.062076 ops/training.py:65 2019-01-16 12:10:34.062006: step 2507, loss = 0.68266 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:10:34.832826 ops/training.py:65 2019-01-16 12:10:34.832770: step 2508, loss = 0.70453 (41.6 examples/sec; 0.770 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:10:35.601884 ops/training.py:65 2019-01-16 12:10:35.601813: step 2509, loss = 0.68086 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:10:36.370794 ops/training.py:65 2019-01-16 12:10:36.370724: step 2510, loss = 0.67710 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:10:37.139121 ops/training.py:65 2019-01-16 12:10:37.139052: step 2511, loss = 0.70248 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:10:37.906315 ops/training.py:65 2019-01-16 12:10:37.906243: step 2512, loss = 0.71106 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:10:38.671986 ops/training.py:65 2019-01-16 12:10:38.671931: step 2513, loss = 0.69819 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:10:39.437211 ops/training.py:65 2019-01-16 12:10:39.437142: step 2514, loss = 0.70744 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:10:40.201439 ops/training.py:65 2019-01-16 12:10:40.201372: step 2515, loss = 0.68655 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:10:40.965452 ops/training.py:65 2019-01-16 12:10:40.965380: step 2516, loss = 0.69084 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:10:41.731121 ops/training.py:65 2019-01-16 12:10:41.731052: step 2517, loss = 0.69736 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:10:42.494415 ops/training.py:65 2019-01-16 12:10:42.494363: step 2518, loss = 0.70782 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:10:43.257615 ops/training.py:65 2019-01-16 12:10:43.257546: step 2519, loss = 0.70473 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:10:44.020976 ops/training.py:65 2019-01-16 12:10:44.020906: step 2520, loss = 0.68902 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:10:44.784697 ops/training.py:65 2019-01-16 12:10:44.784624: step 2521, loss = 0.69296 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:10:45.551869 ops/training.py:65 2019-01-16 12:10:45.551802: step 2522, loss = 0.69807 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:10:46.320267 ops/training.py:65 2019-01-16 12:10:46.320199: step 2523, loss = 0.68303 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:10:47.086037 ops/training.py:65 2019-01-16 12:10:47.085989: step 2524, loss = 0.69227 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:10:47.849945 ops/training.py:65 2019-01-16 12:10:47.849879: step 2525, loss = 0.70010 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:10:48.617561 ops/training.py:65 2019-01-16 12:10:48.617491: step 2526, loss = 0.67314 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:10:49.385651 ops/training.py:65 2019-01-16 12:10:49.385582: step 2527, loss = 0.72131 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:10:50.153264 ops/training.py:65 2019-01-16 12:10:50.153192: step 2528, loss = 0.72494 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:10:50.921836 ops/training.py:65 2019-01-16 12:10:50.921757: step 2529, loss = 0.68515 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:10:51.692336 ops/training.py:65 2019-01-16 12:10:51.692262: step 2530, loss = 0.67462 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:10:52.460796 ops/training.py:65 2019-01-16 12:10:52.460719: step 2531, loss = 0.69594 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:10:53.227525 ops/training.py:65 2019-01-16 12:10:53.227450: step 2532, loss = 0.70579 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:10:53.992304 ops/training.py:65 2019-01-16 12:10:53.992255: step 2533, loss = 0.67932 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:10:54.756083 ops/training.py:65 2019-01-16 12:10:54.756017: step 2534, loss = 0.69802 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:10:55.519926 ops/training.py:65 2019-01-16 12:10:55.519852: step 2535, loss = 0.67496 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:10:56.283769 ops/training.py:65 2019-01-16 12:10:56.283693: step 2536, loss = 0.75621 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.21875
I0528 2019-01-16 12:10:57.051816 ops/training.py:65 2019-01-16 12:10:57.051742: step 2537, loss = 0.67767 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:10:57.819960 ops/training.py:65 2019-01-16 12:10:57.819881: step 2538, loss = 0.71766 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:10:58.587794 ops/training.py:65 2019-01-16 12:10:58.587719: step 2539, loss = 0.70417 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:10:59.356866 ops/training.py:65 2019-01-16 12:10:59.356800: step 2540, loss = 0.71394 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:11:00.124589 ops/training.py:65 2019-01-16 12:11:00.124522: step 2541, loss = 0.70078 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:11:00.892188 ops/training.py:65 2019-01-16 12:11:00.892122: step 2542, loss = 0.67922 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:11:01.660420 ops/training.py:65 2019-01-16 12:11:01.660358: step 2543, loss = 0.70714 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:11:02.428198 ops/training.py:65 2019-01-16 12:11:02.428122: step 2544, loss = 0.67622 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:11:03.195013 ops/training.py:65 2019-01-16 12:11:03.194937: step 2545, loss = 0.71205 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:11:03.962155 ops/training.py:65 2019-01-16 12:11:03.962100: step 2546, loss = 0.71119 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:11:04.727621 ops/training.py:65 2019-01-16 12:11:04.727580: step 2547, loss = 0.67245 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:11:05.492491 ops/training.py:65 2019-01-16 12:11:05.492430: step 2548, loss = 0.69375 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:11:06.256675 ops/training.py:65 2019-01-16 12:11:06.256624: step 2549, loss = 0.68451 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:11:07.021191 ops/training.py:65 2019-01-16 12:11:07.021115: step 2550, loss = 0.70590 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:11:07.785848 ops/training.py:65 2019-01-16 12:11:07.785775: step 2551, loss = 0.71197 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:11:08.551156 ops/training.py:65 2019-01-16 12:11:08.551097: step 2552, loss = 0.69655 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:11:09.316969 ops/training.py:65 2019-01-16 12:11:09.316906: step 2553, loss = 0.67963 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:11:10.081821 ops/training.py:65 2019-01-16 12:11:10.081746: step 2554, loss = 0.69436 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:11:10.849969 ops/training.py:65 2019-01-16 12:11:10.849900: step 2555, loss = 0.73693 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:11:11.617551 ops/training.py:65 2019-01-16 12:11:11.617475: step 2556, loss = 0.71587 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:11:12.385685 ops/training.py:65 2019-01-16 12:11:12.385618: step 2557, loss = 0.70734 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:11:13.154274 ops/training.py:65 2019-01-16 12:11:13.154198: step 2558, loss = 0.69774 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:11:13.921478 ops/training.py:65 2019-01-16 12:11:13.921401: step 2559, loss = 0.73121 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:11:14.689815 ops/training.py:65 2019-01-16 12:11:14.689742: step 2560, loss = 0.69262 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:11:15.459045 ops/training.py:65 2019-01-16 12:11:15.458967: step 2561, loss = 0.69668 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:11:16.227269 ops/training.py:65 2019-01-16 12:11:16.227203: step 2562, loss = 0.68493 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:11:16.992358 ops/training.py:65 2019-01-16 12:11:16.992305: step 2563, loss = 0.70369 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:11:17.757121 ops/training.py:65 2019-01-16 12:11:17.757058: step 2564, loss = 0.70706 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:11:18.521324 ops/training.py:65 2019-01-16 12:11:18.521255: step 2565, loss = 0.66520 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:11:19.289880 ops/training.py:65 2019-01-16 12:11:19.289819: step 2566, loss = 0.69993 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:11:20.059820 ops/training.py:65 2019-01-16 12:11:20.059751: step 2567, loss = 0.68195 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:11:20.827697 ops/training.py:65 2019-01-16 12:11:20.827636: step 2568, loss = 0.66864 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:11:21.595130 ops/training.py:65 2019-01-16 12:11:21.595076: step 2569, loss = 0.70109 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:11:22.364495 ops/training.py:65 2019-01-16 12:11:22.364440: step 2570, loss = 0.72660 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:11:23.133188 ops/training.py:65 2019-01-16 12:11:23.133137: step 2571, loss = 0.71036 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:11:23.901108 ops/training.py:65 2019-01-16 12:11:23.901041: step 2572, loss = 0.70865 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:11:24.668205 ops/training.py:65 2019-01-16 12:11:24.668144: step 2573, loss = 0.70651 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:11:25.434793 ops/training.py:65 2019-01-16 12:11:25.434736: step 2574, loss = 0.68228 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:11:26.200683 ops/training.py:65 2019-01-16 12:11:26.200634: step 2575, loss = 0.68378 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:11:26.965697 ops/training.py:65 2019-01-16 12:11:26.965625: step 2576, loss = 0.72055 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:11:27.729038 ops/training.py:65 2019-01-16 12:11:27.728986: step 2577, loss = 0.68974 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:11:28.493552 ops/training.py:65 2019-01-16 12:11:28.493482: step 2578, loss = 0.72624 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:11:29.257682 ops/training.py:65 2019-01-16 12:11:29.257615: step 2579, loss = 0.66882 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:11:30.021775 ops/training.py:65 2019-01-16 12:11:30.021709: step 2580, loss = 0.71606 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:11:30.785062 ops/training.py:65 2019-01-16 12:11:30.784995: step 2581, loss = 0.69524 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:11:31.549572 ops/training.py:65 2019-01-16 12:11:31.549524: step 2582, loss = 0.70219 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:11:32.313249 ops/training.py:65 2019-01-16 12:11:32.313200: step 2583, loss = 0.71439 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:11:33.077872 ops/training.py:65 2019-01-16 12:11:33.077808: step 2584, loss = 0.70667 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:11:33.842481 ops/training.py:65 2019-01-16 12:11:33.842411: step 2585, loss = 0.69763 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:11:34.611422 ops/training.py:65 2019-01-16 12:11:34.611349: step 2586, loss = 0.69916 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:11:35.381041 ops/training.py:65 2019-01-16 12:11:35.380987: step 2587, loss = 0.68462 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:11:36.149535 ops/training.py:65 2019-01-16 12:11:36.149464: step 2588, loss = 0.69032 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:11:36.917269 ops/training.py:65 2019-01-16 12:11:36.917209: step 2589, loss = 0.70249 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:11:37.684399 ops/training.py:65 2019-01-16 12:11:37.684338: step 2590, loss = 0.69406 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:11:38.448312 ops/training.py:65 2019-01-16 12:11:38.448248: step 2591, loss = 0.68571 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:11:39.212122 ops/training.py:65 2019-01-16 12:11:39.212060: step 2592, loss = 0.70543 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:11:39.980334 ops/training.py:65 2019-01-16 12:11:39.980263: step 2593, loss = 0.68472 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:11:40.748120 ops/training.py:65 2019-01-16 12:11:40.748047: step 2594, loss = 0.70437 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:11:41.514733 ops/training.py:65 2019-01-16 12:11:41.514662: step 2595, loss = 0.71590 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:11:42.281879 ops/training.py:65 2019-01-16 12:11:42.281808: step 2596, loss = 0.70822 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:11:43.050000 ops/training.py:65 2019-01-16 12:11:43.049917: step 2597, loss = 0.69288 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:11:43.818823 ops/training.py:65 2019-01-16 12:11:43.818750: step 2598, loss = 0.70295 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:11:44.588022 ops/training.py:65 2019-01-16 12:11:44.587953: step 2599, loss = 0.69545 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:11:45.354269 ops/training.py:65 2019-01-16 12:11:45.354193: step 2600, loss = 0.70153 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:11:46.119386 ops/training.py:65 2019-01-16 12:11:46.119319: step 2601, loss = 0.67626 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:11:46.883672 ops/training.py:65 2019-01-16 12:11:46.883629: step 2602, loss = 0.67909 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:11:47.647313 ops/training.py:65 2019-01-16 12:11:47.647251: step 2603, loss = 0.72007 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:11:48.411796 ops/training.py:65 2019-01-16 12:11:48.411725: step 2604, loss = 0.70125 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:11:49.179775 ops/training.py:65 2019-01-16 12:11:49.179716: step 2605, loss = 0.69051 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:11:49.947522 ops/training.py:65 2019-01-16 12:11:49.947459: step 2606, loss = 0.69171 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:11:50.715768 ops/training.py:65 2019-01-16 12:11:50.715694: step 2607, loss = 0.67978 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:11:51.482756 ops/training.py:65 2019-01-16 12:11:51.482686: step 2608, loss = 0.69260 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:11:52.246419 ops/training.py:65 2019-01-16 12:11:52.246341: step 2609, loss = 0.67618 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:11:53.010098 ops/training.py:65 2019-01-16 12:11:53.010029: step 2610, loss = 0.68297 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:11:53.777542 ops/training.py:65 2019-01-16 12:11:53.777500: step 2611, loss = 0.70988 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:11:54.545625 ops/training.py:65 2019-01-16 12:11:54.545552: step 2612, loss = 0.66643 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:11:55.313350 ops/training.py:65 2019-01-16 12:11:55.313280: step 2613, loss = 0.72861 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.25
I0528 2019-01-16 12:11:56.077830 ops/training.py:65 2019-01-16 12:11:56.077764: step 2614, loss = 0.69025 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:11:56.842539 ops/training.py:65 2019-01-16 12:11:56.842471: step 2615, loss = 0.68105 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:11:57.606488 ops/training.py:65 2019-01-16 12:11:57.606441: step 2616, loss = 0.68680 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:11:58.370228 ops/training.py:65 2019-01-16 12:11:58.370159: step 2617, loss = 0.68436 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:11:59.134422 ops/training.py:65 2019-01-16 12:11:59.134363: step 2618, loss = 0.69875 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:11:59.898832 ops/training.py:65 2019-01-16 12:11:59.898765: step 2619, loss = 0.70015 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:12:00.662508 ops/training.py:65 2019-01-16 12:12:00.662439: step 2620, loss = 0.67125 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:12:01.427038 ops/training.py:65 2019-01-16 12:12:01.427002: step 2621, loss = 0.68464 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:12:02.191423 ops/training.py:65 2019-01-16 12:12:02.191372: step 2622, loss = 0.70091 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:12:02.956874 ops/training.py:65 2019-01-16 12:12:02.956816: step 2623, loss = 0.69196 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:12:03.720524 ops/training.py:65 2019-01-16 12:12:03.720453: step 2624, loss = 0.66022 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:12:04.484024 ops/training.py:65 2019-01-16 12:12:04.483965: step 2625, loss = 0.69719 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:12:05.247479 ops/training.py:65 2019-01-16 12:12:05.247446: step 2626, loss = 0.71378 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:12:06.011315 ops/training.py:65 2019-01-16 12:12:06.011243: step 2627, loss = 0.70344 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:12:06.775382 ops/training.py:65 2019-01-16 12:12:06.775330: step 2628, loss = 0.72466 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:12:07.540395 ops/training.py:65 2019-01-16 12:12:07.540337: step 2629, loss = 0.70690 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:12:08.304731 ops/training.py:65 2019-01-16 12:12:08.304675: step 2630, loss = 0.69905 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:12:09.068485 ops/training.py:65 2019-01-16 12:12:09.068452: step 2631, loss = 0.70062 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:12:09.831932 ops/training.py:65 2019-01-16 12:12:09.831880: step 2632, loss = 0.71560 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:12:10.596656 ops/training.py:65 2019-01-16 12:12:10.596606: step 2633, loss = 0.70016 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:12:11.361576 ops/training.py:65 2019-01-16 12:12:11.361520: step 2634, loss = 0.69068 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:12:12.126873 ops/training.py:65 2019-01-16 12:12:12.126816: step 2635, loss = 0.69205 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:12:12.891992 ops/training.py:65 2019-01-16 12:12:12.891958: step 2636, loss = 0.71407 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:12:13.656877 ops/training.py:65 2019-01-16 12:12:13.656819: step 2637, loss = 0.72904 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:12:14.421263 ops/training.py:65 2019-01-16 12:12:14.421200: step 2638, loss = 0.70425 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:12:15.184959 ops/training.py:65 2019-01-16 12:12:15.184888: step 2639, loss = 0.70963 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:12:15.949319 ops/training.py:65 2019-01-16 12:12:15.949247: step 2640, loss = 0.70374 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:12:16.714431 ops/training.py:65 2019-01-16 12:12:16.714380: step 2641, loss = 0.70781 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:12:17.478111 ops/training.py:65 2019-01-16 12:12:17.478046: step 2642, loss = 0.69487 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:12:18.242600 ops/training.py:65 2019-01-16 12:12:18.242532: step 2643, loss = 0.71739 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:12:19.007403 ops/training.py:65 2019-01-16 12:12:19.007342: step 2644, loss = 0.68831 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:12:19.771305 ops/training.py:65 2019-01-16 12:12:19.771240: step 2645, loss = 0.67816 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:12:20.535663 ops/training.py:65 2019-01-16 12:12:20.535614: step 2646, loss = 0.67415 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:12:21.302716 ops/training.py:65 2019-01-16 12:12:21.302648: step 2647, loss = 0.70826 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:12:22.071148 ops/training.py:65 2019-01-16 12:12:22.071088: step 2648, loss = 0.72926 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:12:22.838508 ops/training.py:65 2019-01-16 12:12:22.838432: step 2649, loss = 0.70425 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:12:23.605022 ops/training.py:65 2019-01-16 12:12:23.604974: step 2650, loss = 0.68147 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:12:24.368684 ops/training.py:65 2019-01-16 12:12:24.368635: step 2651, loss = 0.69598 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:12:25.132406 ops/training.py:65 2019-01-16 12:12:25.132336: step 2652, loss = 0.69882 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:12:25.896410 ops/training.py:65 2019-01-16 12:12:25.896342: step 2653, loss = 0.70241 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:12:26.664047 ops/training.py:65 2019-01-16 12:12:26.663970: step 2654, loss = 0.69503 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:12:27.433126 ops/training.py:65 2019-01-16 12:12:27.433050: step 2655, loss = 0.67108 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:12:28.199957 ops/training.py:65 2019-01-16 12:12:28.199890: step 2656, loss = 0.68298 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:12:28.964135 ops/training.py:65 2019-01-16 12:12:28.964079: step 2657, loss = 0.69927 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:12:29.728828 ops/training.py:65 2019-01-16 12:12:29.728759: step 2658, loss = 0.68101 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:12:30.493284 ops/training.py:65 2019-01-16 12:12:30.493214: step 2659, loss = 0.70740 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:12:31.257344 ops/training.py:65 2019-01-16 12:12:31.257295: step 2660, loss = 0.69936 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:12:32.022145 ops/training.py:65 2019-01-16 12:12:32.022097: step 2661, loss = 0.70827 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:12:32.786034 ops/training.py:65 2019-01-16 12:12:32.785966: step 2662, loss = 0.68549 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:12:33.549881 ops/training.py:65 2019-01-16 12:12:33.549815: step 2663, loss = 0.68698 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:12:34.315307 ops/training.py:65 2019-01-16 12:12:34.315239: step 2664, loss = 0.70652 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:12:35.079542 ops/training.py:65 2019-01-16 12:12:35.079493: step 2665, loss = 0.68119 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:12:35.844168 ops/training.py:65 2019-01-16 12:12:35.844099: step 2666, loss = 0.70912 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:12:36.611873 ops/training.py:65 2019-01-16 12:12:36.611803: step 2667, loss = 0.70058 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:12:37.380160 ops/training.py:65 2019-01-16 12:12:37.380085: step 2668, loss = 0.68015 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:12:38.148335 ops/training.py:65 2019-01-16 12:12:38.148265: step 2669, loss = 0.68417 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:12:38.915540 ops/training.py:65 2019-01-16 12:12:38.915486: step 2670, loss = 0.69361 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:12:39.680515 ops/training.py:65 2019-01-16 12:12:39.680442: step 2671, loss = 0.70832 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:12:40.445669 ops/training.py:65 2019-01-16 12:12:40.445595: step 2672, loss = 0.67252 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:12:41.209481 ops/training.py:65 2019-01-16 12:12:41.209429: step 2673, loss = 0.69266 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:12:41.973391 ops/training.py:65 2019-01-16 12:12:41.973322: step 2674, loss = 0.68271 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:12:42.740420 ops/training.py:65 2019-01-16 12:12:42.740368: step 2675, loss = 0.68518 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:12:43.508355 ops/training.py:65 2019-01-16 12:12:43.508278: step 2676, loss = 0.67802 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:12:44.275056 ops/training.py:65 2019-01-16 12:12:44.274985: step 2677, loss = 0.69503 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:12:45.043936 ops/training.py:65 2019-01-16 12:12:45.043870: step 2678, loss = 0.69812 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:12:45.814021 ops/training.py:65 2019-01-16 12:12:45.813961: step 2679, loss = 0.69568 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:12:46.580794 ops/training.py:65 2019-01-16 12:12:46.580719: step 2680, loss = 0.67342 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:12:47.349550 ops/training.py:65 2019-01-16 12:12:47.349503: step 2681, loss = 0.69193 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:12:48.117896 ops/training.py:65 2019-01-16 12:12:48.117846: step 2682, loss = 0.70006 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:12:48.885399 ops/training.py:65 2019-01-16 12:12:48.885343: step 2683, loss = 0.68013 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:12:49.650512 ops/training.py:65 2019-01-16 12:12:49.650457: step 2684, loss = 0.72572 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:12:50.417321 ops/training.py:65 2019-01-16 12:12:50.417296: step 2685, loss = 0.66795 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:12:51.183759 ops/training.py:65 2019-01-16 12:12:51.183715: step 2686, loss = 0.69497 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:12:51.950123 ops/training.py:65 2019-01-16 12:12:51.950081: step 2687, loss = 0.67726 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:12:52.715138 ops/training.py:65 2019-01-16 12:12:52.715094: step 2688, loss = 0.68356 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:12:53.479250 ops/training.py:65 2019-01-16 12:12:53.479191: step 2689, loss = 0.68571 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:12:54.242714 ops/training.py:65 2019-01-16 12:12:54.242680: step 2690, loss = 0.70309 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:12:55.005742 ops/training.py:65 2019-01-16 12:12:55.005687: step 2691, loss = 0.71814 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:12:55.768707 ops/training.py:65 2019-01-16 12:12:55.768651: step 2692, loss = 0.71997 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:12:56.532603 ops/training.py:65 2019-01-16 12:12:56.532543: step 2693, loss = 0.69440 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:12:57.295913 ops/training.py:65 2019-01-16 12:12:57.295861: step 2694, loss = 0.69820 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:12:58.059747 ops/training.py:65 2019-01-16 12:12:58.059717: step 2695, loss = 0.70177 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:12:58.823219 ops/training.py:65 2019-01-16 12:12:58.823160: step 2696, loss = 0.71101 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:12:59.590945 ops/training.py:65 2019-01-16 12:12:59.590888: step 2697, loss = 0.70960 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:13:00.357945 ops/training.py:65 2019-01-16 12:13:00.357895: step 2698, loss = 0.69444 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:13:01.124434 ops/training.py:65 2019-01-16 12:13:01.124395: step 2699, loss = 0.70445 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:13:01.889596 ops/training.py:65 2019-01-16 12:13:01.889564: step 2700, loss = 0.71771 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:13:02.652890 ops/training.py:65 2019-01-16 12:13:02.652828: step 2701, loss = 0.71947 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:13:03.417803 ops/training.py:65 2019-01-16 12:13:03.417734: step 2702, loss = 0.68224 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:13:04.183105 ops/training.py:65 2019-01-16 12:13:04.183039: step 2703, loss = 0.70438 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:13:04.947628 ops/training.py:65 2019-01-16 12:13:04.947580: step 2704, loss = 0.68998 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:13:05.712130 ops/training.py:65 2019-01-16 12:13:05.712061: step 2705, loss = 0.67001 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:13:06.476022 ops/training.py:65 2019-01-16 12:13:06.475951: step 2706, loss = 0.69722 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:13:07.239839 ops/training.py:65 2019-01-16 12:13:07.239771: step 2707, loss = 0.70083 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:13:08.003546 ops/training.py:65 2019-01-16 12:13:08.003479: step 2708, loss = 0.72702 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:13:08.767157 ops/training.py:65 2019-01-16 12:13:08.767099: step 2709, loss = 0.69396 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:13:09.535178 ops/training.py:65 2019-01-16 12:13:09.535112: step 2710, loss = 0.68317 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:13:10.302652 ops/training.py:65 2019-01-16 12:13:10.302577: step 2711, loss = 0.70570 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:13:11.067194 ops/training.py:65 2019-01-16 12:13:11.067120: step 2712, loss = 0.72205 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:13:11.833463 ops/training.py:65 2019-01-16 12:13:11.833394: step 2713, loss = 0.72568 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:13:12.598125 ops/training.py:65 2019-01-16 12:13:12.598075: step 2714, loss = 0.69071 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:13:13.361637 ops/training.py:65 2019-01-16 12:13:13.361571: step 2715, loss = 0.72023 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:13:14.130952 ops/training.py:65 2019-01-16 12:13:14.130892: step 2716, loss = 0.67737 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:13:14.899389 ops/training.py:65 2019-01-16 12:13:14.899334: step 2717, loss = 0.69367 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:13:15.669790 ops/training.py:65 2019-01-16 12:13:15.669736: step 2718, loss = 0.69860 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:13:16.437076 ops/training.py:65 2019-01-16 12:13:16.437045: step 2719, loss = 0.68892 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:13:17.202682 ops/training.py:65 2019-01-16 12:13:17.202627: step 2720, loss = 0.71619 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:13:17.971709 ops/training.py:65 2019-01-16 12:13:17.971636: step 2721, loss = 0.69145 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:13:18.741039 ops/training.py:65 2019-01-16 12:13:18.740962: step 2722, loss = 0.70649 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:13:19.508389 ops/training.py:65 2019-01-16 12:13:19.508318: step 2723, loss = 0.68539 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:13:20.273180 ops/training.py:65 2019-01-16 12:13:20.273137: step 2724, loss = 0.71220 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:13:21.039515 ops/training.py:65 2019-01-16 12:13:21.039449: step 2725, loss = 0.70755 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:13:21.809429 ops/training.py:65 2019-01-16 12:13:21.809356: step 2726, loss = 0.68466 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:13:22.577376 ops/training.py:65 2019-01-16 12:13:22.577301: step 2727, loss = 0.71447 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:13:23.343283 ops/training.py:65 2019-01-16 12:13:23.343220: step 2728, loss = 0.72500 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:13:24.107668 ops/training.py:65 2019-01-16 12:13:24.107615: step 2729, loss = 0.69385 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:13:24.872198 ops/training.py:65 2019-01-16 12:13:24.872131: step 2730, loss = 0.67886 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:13:25.636283 ops/training.py:65 2019-01-16 12:13:25.636213: step 2731, loss = 0.71019 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:13:26.399786 ops/training.py:65 2019-01-16 12:13:26.399717: step 2732, loss = 0.71500 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:13:27.162686 ops/training.py:65 2019-01-16 12:13:27.162616: step 2733, loss = 0.68961 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:13:27.926343 ops/training.py:65 2019-01-16 12:13:27.926305: step 2734, loss = 0.69079 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:13:28.690619 ops/training.py:65 2019-01-16 12:13:28.690554: step 2735, loss = 0.70192 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:13:29.455447 ops/training.py:65 2019-01-16 12:13:29.455384: step 2736, loss = 0.70306 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:13:30.218838 ops/training.py:65 2019-01-16 12:13:30.218762: step 2737, loss = 0.69738 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:13:30.981826 ops/training.py:65 2019-01-16 12:13:30.981759: step 2738, loss = 0.71761 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:13:31.744865 ops/training.py:65 2019-01-16 12:13:31.744814: step 2739, loss = 0.65739 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:13:32.508895 ops/training.py:65 2019-01-16 12:13:32.508840: step 2740, loss = 0.68981 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:13:33.272613 ops/training.py:65 2019-01-16 12:13:33.272551: step 2741, loss = 0.69235 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:13:34.036279 ops/training.py:65 2019-01-16 12:13:34.036216: step 2742, loss = 0.67653 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:13:34.803014 ops/training.py:65 2019-01-16 12:13:34.802960: step 2743, loss = 0.67576 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:13:35.571807 ops/training.py:65 2019-01-16 12:13:35.571729: step 2744, loss = 0.70101 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:13:36.338575 ops/training.py:65 2019-01-16 12:13:36.338509: step 2745, loss = 0.70227 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:13:37.103233 ops/training.py:65 2019-01-16 12:13:37.103186: step 2746, loss = 0.69902 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:13:37.867655 ops/training.py:65 2019-01-16 12:13:37.867588: step 2747, loss = 0.70696 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:13:38.632082 ops/training.py:65 2019-01-16 12:13:38.632042: step 2748, loss = 0.68274 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:13:39.396798 ops/training.py:65 2019-01-16 12:13:39.396735: step 2749, loss = 0.71198 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:13:40.161766 ops/training.py:65 2019-01-16 12:13:40.161694: step 2750, loss = 0.72888 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:13:40.928721 ops/training.py:65 2019-01-16 12:13:40.928655: step 2751, loss = 0.72456 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:13:41.694744 ops/training.py:65 2019-01-16 12:13:41.694671: step 2752, loss = 0.69061 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:13:42.463409 ops/training.py:65 2019-01-16 12:13:42.463351: step 2753, loss = 0.69827 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:13:43.231365 ops/training.py:65 2019-01-16 12:13:43.231299: step 2754, loss = 0.71911 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:13:43.997261 ops/training.py:65 2019-01-16 12:13:43.997207: step 2755, loss = 0.69671 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:13:44.765400 ops/training.py:65 2019-01-16 12:13:44.765329: step 2756, loss = 0.69950 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:13:45.533865 ops/training.py:65 2019-01-16 12:13:45.533794: step 2757, loss = 0.72312 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 12:13:46.301398 ops/training.py:65 2019-01-16 12:13:46.301327: step 2758, loss = 0.68662 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:13:47.067039 ops/training.py:65 2019-01-16 12:13:47.066982: step 2759, loss = 0.68795 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:13:47.834389 ops/training.py:65 2019-01-16 12:13:47.834313: step 2760, loss = 0.68121 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:13:48.601605 ops/training.py:65 2019-01-16 12:13:48.601528: step 2761, loss = 0.70521 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:13:49.366854 ops/training.py:65 2019-01-16 12:13:49.366780: step 2762, loss = 0.69145 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:13:50.131538 ops/training.py:65 2019-01-16 12:13:50.131483: step 2763, loss = 0.70133 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:13:50.895880 ops/training.py:65 2019-01-16 12:13:50.895813: step 2764, loss = 0.70168 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:13:51.659827 ops/training.py:65 2019-01-16 12:13:51.659759: step 2765, loss = 0.69871 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:13:52.425391 ops/training.py:65 2019-01-16 12:13:52.425322: step 2766, loss = 0.68313 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:13:53.189112 ops/training.py:65 2019-01-16 12:13:53.189042: step 2767, loss = 0.72189 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:13:53.954421 ops/training.py:65 2019-01-16 12:13:53.954371: step 2768, loss = 0.68722 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:13:54.719636 ops/training.py:65 2019-01-16 12:13:54.719568: step 2769, loss = 0.70009 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:13:55.484940 ops/training.py:65 2019-01-16 12:13:55.484870: step 2770, loss = 0.68481 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:13:56.250272 ops/training.py:65 2019-01-16 12:13:56.250205: step 2771, loss = 0.69056 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:13:57.015052 ops/training.py:65 2019-01-16 12:13:57.014981: step 2772, loss = 0.69015 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:13:57.779326 ops/training.py:65 2019-01-16 12:13:57.779277: step 2773, loss = 0.71959 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:13:58.542540 ops/training.py:65 2019-01-16 12:13:58.542467: step 2774, loss = 0.72230 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:13:59.306365 ops/training.py:65 2019-01-16 12:13:59.306302: step 2775, loss = 0.72008 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:14:00.071308 ops/training.py:65 2019-01-16 12:14:00.071239: step 2776, loss = 0.73733 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:14:00.838167 ops/training.py:65 2019-01-16 12:14:00.838095: step 2777, loss = 0.73430 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:14:01.607006 ops/training.py:65 2019-01-16 12:14:01.606939: step 2778, loss = 0.69203 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:14:02.375415 ops/training.py:65 2019-01-16 12:14:02.375350: step 2779, loss = 0.71490 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:14:03.142962 ops/training.py:65 2019-01-16 12:14:03.142888: step 2780, loss = 0.67149 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:14:03.912169 ops/training.py:65 2019-01-16 12:14:03.912096: step 2781, loss = 0.75436 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:14:04.680937 ops/training.py:65 2019-01-16 12:14:04.680857: step 2782, loss = 0.70274 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:14:05.449403 ops/training.py:65 2019-01-16 12:14:05.449328: step 2783, loss = 0.67272 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:14:06.217681 ops/training.py:65 2019-01-16 12:14:06.217608: step 2784, loss = 0.71244 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:14:06.983315 ops/training.py:65 2019-01-16 12:14:06.983264: step 2785, loss = 0.71458 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:14:07.748311 ops/training.py:65 2019-01-16 12:14:07.748251: step 2786, loss = 0.67816 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:14:08.512816 ops/training.py:65 2019-01-16 12:14:08.512750: step 2787, loss = 0.71790 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:14:09.277124 ops/training.py:65 2019-01-16 12:14:09.277059: step 2788, loss = 0.72287 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:14:10.042623 ops/training.py:65 2019-01-16 12:14:10.042550: step 2789, loss = 0.67928 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:14:10.807734 ops/training.py:65 2019-01-16 12:14:10.807666: step 2790, loss = 0.71356 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:14:11.571915 ops/training.py:65 2019-01-16 12:14:11.571850: step 2791, loss = 0.69449 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:14:12.335194 ops/training.py:65 2019-01-16 12:14:12.335134: step 2792, loss = 0.68053 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:14:13.098710 ops/training.py:65 2019-01-16 12:14:13.098659: step 2793, loss = 0.68201 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:14:13.863783 ops/training.py:65 2019-01-16 12:14:13.863714: step 2794, loss = 0.65454 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:14:14.627667 ops/training.py:65 2019-01-16 12:14:14.627598: step 2795, loss = 0.72803 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:14:15.391703 ops/training.py:65 2019-01-16 12:14:15.391634: step 2796, loss = 0.69791 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:14:16.155512 ops/training.py:65 2019-01-16 12:14:16.155464: step 2797, loss = 0.67121 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:14:16.920700 ops/training.py:65 2019-01-16 12:14:16.920650: step 2798, loss = 0.68908 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:14:17.688321 ops/training.py:65 2019-01-16 12:14:17.688244: step 2799, loss = 0.69086 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:14:18.455637 ops/training.py:65 2019-01-16 12:14:18.455566: step 2800, loss = 0.71957 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:14:19.222281 ops/training.py:65 2019-01-16 12:14:19.222215: step 2801, loss = 0.70494 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:14:19.986652 ops/training.py:65 2019-01-16 12:14:19.986603: step 2802, loss = 0.68541 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:14:20.753294 ops/training.py:65 2019-01-16 12:14:20.753230: step 2803, loss = 0.67084 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:14:21.520476 ops/training.py:65 2019-01-16 12:14:21.520403: step 2804, loss = 0.70079 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:14:22.288006 ops/training.py:65 2019-01-16 12:14:22.287947: step 2805, loss = 0.68735 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:14:23.056988 ops/training.py:65 2019-01-16 12:14:23.056911: step 2806, loss = 0.70443 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:14:23.824775 ops/training.py:65 2019-01-16 12:14:23.824699: step 2807, loss = 0.69462 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:14:24.592373 ops/training.py:65 2019-01-16 12:14:24.592302: step 2808, loss = 0.67244 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:14:25.357018 ops/training.py:65 2019-01-16 12:14:25.356954: step 2809, loss = 0.69083 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:14:26.121864 ops/training.py:65 2019-01-16 12:14:26.121792: step 2810, loss = 0.67416 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:14:26.886788 ops/training.py:65 2019-01-16 12:14:26.886720: step 2811, loss = 0.71677 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:14:27.651715 ops/training.py:65 2019-01-16 12:14:27.651666: step 2812, loss = 0.69644 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:14:28.416950 ops/training.py:65 2019-01-16 12:14:28.416879: step 2813, loss = 0.70115 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:14:29.181582 ops/training.py:65 2019-01-16 12:14:29.181522: step 2814, loss = 0.68497 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:14:29.946359 ops/training.py:65 2019-01-16 12:14:29.946289: step 2815, loss = 0.71158 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:14:30.710760 ops/training.py:65 2019-01-16 12:14:30.710691: step 2816, loss = 0.69165 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:14:31.475770 ops/training.py:65 2019-01-16 12:14:31.475722: step 2817, loss = 0.69475 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:14:32.239781 ops/training.py:65 2019-01-16 12:14:32.239732: step 2818, loss = 0.69401 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:14:33.004225 ops/training.py:65 2019-01-16 12:14:33.004154: step 2819, loss = 0.70446 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:14:33.768468 ops/training.py:65 2019-01-16 12:14:33.768397: step 2820, loss = 0.71689 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:14:34.533141 ops/training.py:65 2019-01-16 12:14:34.533073: step 2821, loss = 0.66958 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:14:35.297774 ops/training.py:65 2019-01-16 12:14:35.297720: step 2822, loss = 0.69313 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:14:36.062212 ops/training.py:65 2019-01-16 12:14:36.062146: step 2823, loss = 0.68304 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:14:36.826870 ops/training.py:65 2019-01-16 12:14:36.826799: step 2824, loss = 0.69617 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:14:37.595511 ops/training.py:65 2019-01-16 12:14:37.595452: step 2825, loss = 0.68338 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:14:38.361853 ops/training.py:65 2019-01-16 12:14:38.361760: step 2826, loss = 0.69594 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:14:39.129501 ops/training.py:65 2019-01-16 12:14:39.129443: step 2827, loss = 0.69401 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:14:39.897592 ops/training.py:65 2019-01-16 12:14:39.897518: step 2828, loss = 0.71761 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:14:40.664243 ops/training.py:65 2019-01-16 12:14:40.664169: step 2829, loss = 0.70160 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:14:41.431218 ops/training.py:65 2019-01-16 12:14:41.431148: step 2830, loss = 0.69244 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:14:42.200037 ops/training.py:65 2019-01-16 12:14:42.199960: step 2831, loss = 0.70035 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:14:42.968017 ops/training.py:65 2019-01-16 12:14:42.967941: step 2832, loss = 0.70676 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:14:43.735010 ops/training.py:65 2019-01-16 12:14:43.734941: step 2833, loss = 0.69641 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:14:44.500699 ops/training.py:65 2019-01-16 12:14:44.500630: step 2834, loss = 0.69250 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:14:45.266044 ops/training.py:65 2019-01-16 12:14:45.265976: step 2835, loss = 0.68347 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:14:46.031348 ops/training.py:65 2019-01-16 12:14:46.031286: step 2836, loss = 0.68641 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:14:46.794984 ops/training.py:65 2019-01-16 12:14:46.794933: step 2837, loss = 0.68801 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:14:47.559404 ops/training.py:65 2019-01-16 12:14:47.559329: step 2838, loss = 0.67938 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:14:48.324218 ops/training.py:65 2019-01-16 12:14:48.324153: step 2839, loss = 0.69944 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:14:49.088241 ops/training.py:65 2019-01-16 12:14:49.088178: step 2840, loss = 0.69966 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:14:49.853465 ops/training.py:65 2019-01-16 12:14:49.853405: step 2841, loss = 0.71303 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:14:50.618102 ops/training.py:65 2019-01-16 12:14:50.618054: step 2842, loss = 0.70322 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:14:51.383207 ops/training.py:65 2019-01-16 12:14:51.383139: step 2843, loss = 0.67247 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:14:52.149734 ops/training.py:65 2019-01-16 12:14:52.149671: step 2844, loss = 0.69890 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:14:52.918443 ops/training.py:65 2019-01-16 12:14:52.918387: step 2845, loss = 0.68651 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:14:53.686536 ops/training.py:65 2019-01-16 12:14:53.686463: step 2846, loss = 0.69825 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:14:54.451315 ops/training.py:65 2019-01-16 12:14:54.451257: step 2847, loss = 0.71944 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:14:55.216099 ops/training.py:65 2019-01-16 12:14:55.216040: step 2848, loss = 0.71200 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:14:55.980673 ops/training.py:65 2019-01-16 12:14:55.980620: step 2849, loss = 0.66859 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:14:56.745007 ops/training.py:65 2019-01-16 12:14:56.744939: step 2850, loss = 0.66316 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:14:57.508476 ops/training.py:65 2019-01-16 12:14:57.508430: step 2851, loss = 0.69316 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:14:58.272893 ops/training.py:65 2019-01-16 12:14:58.272826: step 2852, loss = 0.69620 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:14:59.036812 ops/training.py:65 2019-01-16 12:14:59.036752: step 2853, loss = 0.70169 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:14:59.801946 ops/training.py:65 2019-01-16 12:14:59.801880: step 2854, loss = 0.70492 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:15:00.566594 ops/training.py:65 2019-01-16 12:15:00.566524: step 2855, loss = 0.69059 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:15:01.331016 ops/training.py:65 2019-01-16 12:15:01.330966: step 2856, loss = 0.70465 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:15:02.094859 ops/training.py:65 2019-01-16 12:15:02.094808: step 2857, loss = 0.71366 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:15:02.858347 ops/training.py:65 2019-01-16 12:15:02.858290: step 2858, loss = 0.70235 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:15:03.623517 ops/training.py:65 2019-01-16 12:15:03.623451: step 2859, loss = 0.68038 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:15:04.388141 ops/training.py:65 2019-01-16 12:15:04.388076: step 2860, loss = 0.67350 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:15:05.154343 ops/training.py:65 2019-01-16 12:15:05.154292: step 2861, loss = 0.69450 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:15:05.920605 ops/training.py:65 2019-01-16 12:15:05.920531: step 2862, loss = 0.70607 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:15:06.685941 ops/training.py:65 2019-01-16 12:15:06.685866: step 2863, loss = 0.68128 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:15:07.450177 ops/training.py:65 2019-01-16 12:15:07.450102: step 2864, loss = 0.70700 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:15:08.215068 ops/training.py:65 2019-01-16 12:15:08.214993: step 2865, loss = 0.70082 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:15:08.979788 ops/training.py:65 2019-01-16 12:15:08.979733: step 2866, loss = 0.71904 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:15:09.743682 ops/training.py:65 2019-01-16 12:15:09.743623: step 2867, loss = 0.70693 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:15:10.508393 ops/training.py:65 2019-01-16 12:15:10.508321: step 2868, loss = 0.68898 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:15:11.272405 ops/training.py:65 2019-01-16 12:15:11.272333: step 2869, loss = 0.71630 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:15:12.036730 ops/training.py:65 2019-01-16 12:15:12.036661: step 2870, loss = 0.68816 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:15:12.801650 ops/training.py:65 2019-01-16 12:15:12.801616: step 2871, loss = 0.68075 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:15:13.565788 ops/training.py:65 2019-01-16 12:15:13.565720: step 2872, loss = 0.66014 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 12:15:14.330738 ops/training.py:65 2019-01-16 12:15:14.330675: step 2873, loss = 0.67599 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:15:15.096312 ops/training.py:65 2019-01-16 12:15:15.096254: step 2874, loss = 0.69991 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:15:15.860820 ops/training.py:65 2019-01-16 12:15:15.860762: step 2875, loss = 0.68733 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:15:16.625424 ops/training.py:65 2019-01-16 12:15:16.625383: step 2876, loss = 0.68214 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:15:17.390305 ops/training.py:65 2019-01-16 12:15:17.390253: step 2877, loss = 0.70497 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:15:18.155125 ops/training.py:65 2019-01-16 12:15:18.155066: step 2878, loss = 0.67411 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:15:18.920245 ops/training.py:65 2019-01-16 12:15:18.920187: step 2879, loss = 0.71358 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:15:19.684201 ops/training.py:65 2019-01-16 12:15:19.684169: step 2880, loss = 0.69144 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:15:20.448583 ops/training.py:65 2019-01-16 12:15:20.448525: step 2881, loss = 0.69001 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:15:21.212481 ops/training.py:65 2019-01-16 12:15:21.212418: step 2882, loss = 0.70154 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:15:21.976913 ops/training.py:65 2019-01-16 12:15:21.976859: step 2883, loss = 0.68294 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:15:22.741068 ops/training.py:65 2019-01-16 12:15:22.741011: step 2884, loss = 0.70387 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:15:23.506249 ops/training.py:65 2019-01-16 12:15:23.506209: step 2885, loss = 0.68989 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:15:24.269900 ops/training.py:65 2019-01-16 12:15:24.269827: step 2886, loss = 0.69882 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:15:25.033898 ops/training.py:65 2019-01-16 12:15:25.033828: step 2887, loss = 0.68336 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:15:25.799049 ops/training.py:65 2019-01-16 12:15:25.798986: step 2888, loss = 0.68510 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:15:26.564417 ops/training.py:65 2019-01-16 12:15:26.564357: step 2889, loss = 0.67073 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:15:27.328925 ops/training.py:65 2019-01-16 12:15:27.328892: step 2890, loss = 0.70473 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:15:28.093282 ops/training.py:65 2019-01-16 12:15:28.093223: step 2891, loss = 0.69737 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:15:28.857529 ops/training.py:65 2019-01-16 12:15:28.857471: step 2892, loss = 0.67957 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:15:29.622037 ops/training.py:65 2019-01-16 12:15:29.621977: step 2893, loss = 0.68997 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:15:30.386973 ops/training.py:65 2019-01-16 12:15:30.386915: step 2894, loss = 0.67079 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:15:31.151635 ops/training.py:65 2019-01-16 12:15:31.151600: step 2895, loss = 0.69134 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:15:31.915388 ops/training.py:65 2019-01-16 12:15:31.915319: step 2896, loss = 0.68235 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:15:32.679462 ops/training.py:65 2019-01-16 12:15:32.679401: step 2897, loss = 0.68801 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:15:33.444032 ops/training.py:65 2019-01-16 12:15:33.443971: step 2898, loss = 0.69977 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:15:34.208285 ops/training.py:65 2019-01-16 12:15:34.208216: step 2899, loss = 0.67438 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:15:34.972335 ops/training.py:65 2019-01-16 12:15:34.972278: step 2900, loss = 0.68597 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:15:35.736818 ops/training.py:65 2019-01-16 12:15:35.736743: step 2901, loss = 0.67811 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:15:36.504472 ops/training.py:65 2019-01-16 12:15:36.504404: step 2902, loss = 0.68251 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:15:37.272085 ops/training.py:65 2019-01-16 12:15:37.272023: step 2903, loss = 0.68428 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:15:38.038828 ops/training.py:65 2019-01-16 12:15:38.038767: step 2904, loss = 0.68942 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:15:38.803699 ops/training.py:65 2019-01-16 12:15:38.803668: step 2905, loss = 0.70253 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:15:39.571663 ops/training.py:65 2019-01-16 12:15:39.571607: step 2906, loss = 0.68283 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:15:40.339321 ops/training.py:65 2019-01-16 12:15:40.339249: step 2907, loss = 0.68237 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:15:41.105569 ops/training.py:65 2019-01-16 12:15:41.105474: step 2908, loss = 0.70357 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:15:41.873781 ops/training.py:65 2019-01-16 12:15:41.873716: step 2909, loss = 0.70504 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:15:42.640689 ops/training.py:65 2019-01-16 12:15:42.640623: step 2910, loss = 0.68705 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:15:43.406441 ops/training.py:65 2019-01-16 12:15:43.406364: step 2911, loss = 0.68746 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:15:44.172437 ops/training.py:65 2019-01-16 12:15:44.172378: step 2912, loss = 0.71565 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:15:44.937679 ops/training.py:65 2019-01-16 12:15:44.937615: step 2913, loss = 0.68975 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:15:45.702874 ops/training.py:65 2019-01-16 12:15:45.702818: step 2914, loss = 0.68525 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:15:46.467154 ops/training.py:65 2019-01-16 12:15:46.467103: step 2915, loss = 0.70501 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:15:47.231749 ops/training.py:65 2019-01-16 12:15:47.231698: step 2916, loss = 0.69620 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:15:47.995687 ops/training.py:65 2019-01-16 12:15:47.995630: step 2917, loss = 0.71439 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:15:48.760229 ops/training.py:65 2019-01-16 12:15:48.760153: step 2918, loss = 0.68872 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:15:49.524462 ops/training.py:65 2019-01-16 12:15:49.524413: step 2919, loss = 0.67310 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:15:50.288879 ops/training.py:65 2019-01-16 12:15:50.288819: step 2920, loss = 0.69655 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:15:51.052842 ops/training.py:65 2019-01-16 12:15:51.052785: step 2921, loss = 0.67969 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:15:51.817173 ops/training.py:65 2019-01-16 12:15:51.817113: step 2922, loss = 0.70212 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:15:52.581957 ops/training.py:65 2019-01-16 12:15:52.581897: step 2923, loss = 0.71070 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:15:53.345254 ops/training.py:65 2019-01-16 12:15:53.345196: step 2924, loss = 0.71009 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:15:54.109960 ops/training.py:65 2019-01-16 12:15:54.109887: step 2925, loss = 0.70981 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:15:54.874247 ops/training.py:65 2019-01-16 12:15:54.874175: step 2926, loss = 0.70101 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:15:55.639089 ops/training.py:65 2019-01-16 12:15:55.639015: step 2927, loss = 0.68676 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:15:56.403547 ops/training.py:65 2019-01-16 12:15:56.403482: step 2928, loss = 0.69293 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:15:57.168265 ops/training.py:65 2019-01-16 12:15:57.168216: step 2929, loss = 0.70210 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:15:57.932734 ops/training.py:65 2019-01-16 12:15:57.932665: step 2930, loss = 0.68676 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:15:58.697430 ops/training.py:65 2019-01-16 12:15:58.697360: step 2931, loss = 0.66629 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:15:59.462127 ops/training.py:65 2019-01-16 12:15:59.462057: step 2932, loss = 0.70254 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:16:00.226593 ops/training.py:65 2019-01-16 12:16:00.226526: step 2933, loss = 0.70394 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:16:00.990700 ops/training.py:65 2019-01-16 12:16:00.990648: step 2934, loss = 0.68945 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:16:01.757532 ops/training.py:65 2019-01-16 12:16:01.757469: step 2935, loss = 0.67719 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:16:02.525063 ops/training.py:65 2019-01-16 12:16:02.524994: step 2936, loss = 0.68223 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:16:03.294832 ops/training.py:65 2019-01-16 12:16:03.294764: step 2937, loss = 0.68366 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:16:04.063705 ops/training.py:65 2019-01-16 12:16:04.063632: step 2938, loss = 0.68546 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:16:04.833567 ops/training.py:65 2019-01-16 12:16:04.833492: step 2939, loss = 0.71127 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:16:05.601428 ops/training.py:65 2019-01-16 12:16:05.601359: step 2940, loss = 0.70121 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:16:06.366377 ops/training.py:65 2019-01-16 12:16:06.366311: step 2941, loss = 0.68343 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:16:07.130996 ops/training.py:65 2019-01-16 12:16:07.130948: step 2942, loss = 0.69492 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:16:07.895935 ops/training.py:65 2019-01-16 12:16:07.895869: step 2943, loss = 0.71135 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:16:08.660405 ops/training.py:65 2019-01-16 12:16:08.660355: step 2944, loss = 0.69246 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:16:09.425407 ops/training.py:65 2019-01-16 12:16:09.425352: step 2945, loss = 0.68884 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:16:10.191232 ops/training.py:65 2019-01-16 12:16:10.191158: step 2946, loss = 0.70262 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:16:10.955616 ops/training.py:65 2019-01-16 12:16:10.955545: step 2947, loss = 0.68704 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:16:11.718646 ops/training.py:65 2019-01-16 12:16:11.718577: step 2948, loss = 0.69624 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:16:12.486443 ops/training.py:65 2019-01-16 12:16:12.486413: step 2949, loss = 0.70209 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:16:13.254513 ops/training.py:65 2019-01-16 12:16:13.254453: step 2950, loss = 0.70351 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:16:14.023421 ops/training.py:65 2019-01-16 12:16:14.023366: step 2951, loss = 0.70156 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:16:14.790905 ops/training.py:65 2019-01-16 12:16:14.790852: step 2952, loss = 0.69155 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:16:15.557461 ops/training.py:65 2019-01-16 12:16:15.557423: step 2953, loss = 0.70860 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:16:16.324237 ops/training.py:65 2019-01-16 12:16:16.324202: step 2954, loss = 0.68592 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:16:17.092168 ops/training.py:65 2019-01-16 12:16:17.092113: step 2955, loss = 0.70367 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:16:17.860223 ops/training.py:65 2019-01-16 12:16:17.860168: step 2956, loss = 0.69164 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:16:18.627812 ops/training.py:65 2019-01-16 12:16:18.627773: step 2957, loss = 0.69307 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:16:19.395706 ops/training.py:65 2019-01-16 12:16:19.395660: step 2958, loss = 0.69068 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:16:20.160950 ops/training.py:65 2019-01-16 12:16:20.160901: step 2959, loss = 0.69232 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:16:20.929241 ops/training.py:65 2019-01-16 12:16:20.929174: step 2960, loss = 0.69435 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:16:21.696565 ops/training.py:65 2019-01-16 12:16:21.696490: step 2961, loss = 0.69050 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:16:22.462293 ops/training.py:65 2019-01-16 12:16:22.462218: step 2962, loss = 0.67770 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:16:23.225838 ops/training.py:65 2019-01-16 12:16:23.225782: step 2963, loss = 0.67457 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:16:23.993001 ops/training.py:65 2019-01-16 12:16:23.992944: step 2964, loss = 0.71462 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:16:24.762010 ops/training.py:65 2019-01-16 12:16:24.761956: step 2965, loss = 0.71928 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:16:25.529894 ops/training.py:65 2019-01-16 12:16:25.529842: step 2966, loss = 0.69137 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:16:26.296397 ops/training.py:65 2019-01-16 12:16:26.296343: step 2967, loss = 0.70218 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:16:27.063662 ops/training.py:65 2019-01-16 12:16:27.063636: step 2968, loss = 0.68318 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:16:27.830901 ops/training.py:65 2019-01-16 12:16:27.830843: step 2969, loss = 0.71707 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:16:28.598109 ops/training.py:65 2019-01-16 12:16:28.598058: step 2970, loss = 0.72155 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 12:16:29.365371 ops/training.py:65 2019-01-16 12:16:29.365295: step 2971, loss = 0.71460 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:16:30.133616 ops/training.py:65 2019-01-16 12:16:30.133559: step 2972, loss = 0.67476 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:16:30.901466 ops/training.py:65 2019-01-16 12:16:30.901390: step 2973, loss = 0.68408 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:16:31.670340 ops/training.py:65 2019-01-16 12:16:31.670286: step 2974, loss = 0.69158 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:16:32.439520 ops/training.py:65 2019-01-16 12:16:32.439460: step 2975, loss = 0.70148 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:16:33.206082 ops/training.py:65 2019-01-16 12:16:33.206023: step 2976, loss = 0.69143 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:16:33.970595 ops/training.py:65 2019-01-16 12:16:33.970533: step 2977, loss = 0.68013 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:16:34.734654 ops/training.py:65 2019-01-16 12:16:34.734620: step 2978, loss = 0.69674 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:16:35.498831 ops/training.py:65 2019-01-16 12:16:35.498766: step 2979, loss = 0.69478 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:16:36.263422 ops/training.py:65 2019-01-16 12:16:36.263371: step 2980, loss = 0.68988 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:16:37.028508 ops/training.py:65 2019-01-16 12:16:37.028440: step 2981, loss = 0.71206 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:16:37.796161 ops/training.py:65 2019-01-16 12:16:37.796104: step 2982, loss = 0.67453 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:16:38.561400 ops/training.py:65 2019-01-16 12:16:38.561373: step 2983, loss = 0.68387 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:16:39.326051 ops/training.py:65 2019-01-16 12:16:39.325997: step 2984, loss = 0.70602 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:16:40.092147 ops/training.py:65 2019-01-16 12:16:40.092096: step 2985, loss = 0.70493 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:16:40.858344 ops/training.py:65 2019-01-16 12:16:40.858294: step 2986, loss = 0.68359 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:16:41.623047 ops/training.py:65 2019-01-16 12:16:41.622993: step 2987, loss = 0.71852 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:16:42.387381 ops/training.py:65 2019-01-16 12:16:42.387351: step 2988, loss = 0.69942 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:16:43.151550 ops/training.py:65 2019-01-16 12:16:43.151493: step 2989, loss = 0.68493 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:16:43.915808 ops/training.py:65 2019-01-16 12:16:43.915747: step 2990, loss = 0.71447 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:16:44.680758 ops/training.py:65 2019-01-16 12:16:44.680692: step 2991, loss = 0.71234 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:16:45.444710 ops/training.py:65 2019-01-16 12:16:45.444656: step 2992, loss = 0.70349 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:16:46.209269 ops/training.py:65 2019-01-16 12:16:46.209236: step 2993, loss = 0.68174 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:16:46.976186 ops/training.py:65 2019-01-16 12:16:46.976131: step 2994, loss = 0.70041 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:16:47.742747 ops/training.py:65 2019-01-16 12:16:47.742675: step 2995, loss = 0.71068 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:16:48.510530 ops/training.py:65 2019-01-16 12:16:48.510458: step 2996, loss = 0.68741 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:16:49.276617 ops/training.py:65 2019-01-16 12:16:49.276555: step 2997, loss = 0.69731 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:16:50.042006 ops/training.py:65 2019-01-16 12:16:50.041970: step 2998, loss = 0.71347 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:16:50.806245 ops/training.py:65 2019-01-16 12:16:50.806185: step 2999, loss = 0.68703 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:16:51.570639 ops/training.py:65 2019-01-16 12:16:51.570574: step 3000, loss = 0.72174 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:16:52.335260 ops/training.py:65 2019-01-16 12:16:52.335201: step 3001, loss = 0.69099 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:16:53.100368 ops/training.py:65 2019-01-16 12:16:53.100300: step 3002, loss = 0.71752 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:16:53.865410 ops/training.py:65 2019-01-16 12:16:53.865355: step 3003, loss = 0.67693 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:16:54.630212 ops/training.py:65 2019-01-16 12:16:54.630143: step 3004, loss = 0.69513 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:16:55.393872 ops/training.py:65 2019-01-16 12:16:55.393811: step 3005, loss = 0.71058 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:16:56.158393 ops/training.py:65 2019-01-16 12:16:56.158328: step 3006, loss = 0.68069 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:16:56.927440 ops/training.py:65 2019-01-16 12:16:56.927398: step 3007, loss = 0.70034 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:16:57.693938 ops/training.py:65 2019-01-16 12:16:57.693910: step 3008, loss = 0.70621 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:16:58.460395 ops/training.py:65 2019-01-16 12:16:58.460350: step 3009, loss = 0.69299 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:16:59.225916 ops/training.py:65 2019-01-16 12:16:59.225873: step 3010, loss = 0.71117 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:16:59.991128 ops/training.py:65 2019-01-16 12:16:59.991074: step 3011, loss = 0.72826 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:17:00.758442 ops/training.py:65 2019-01-16 12:17:00.758377: step 3012, loss = 0.73199 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 12:17:01.522609 ops/training.py:65 2019-01-16 12:17:01.522559: step 3013, loss = 0.67211 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:17:02.286201 ops/training.py:65 2019-01-16 12:17:02.286134: step 3014, loss = 0.68154 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:17:03.051394 ops/training.py:65 2019-01-16 12:17:03.051323: step 3015, loss = 0.67565 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:17:03.819071 ops/training.py:65 2019-01-16 12:17:03.819026: step 3016, loss = 0.67947 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:17:04.586307 ops/training.py:65 2019-01-16 12:17:04.586280: step 3017, loss = 0.70675 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:17:05.353014 ops/training.py:65 2019-01-16 12:17:05.352962: step 3018, loss = 0.68370 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:17:06.118539 ops/training.py:65 2019-01-16 12:17:06.118489: step 3019, loss = 0.67793 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:17:06.883432 ops/training.py:65 2019-01-16 12:17:06.883377: step 3020, loss = 0.66863 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:17:07.648119 ops/training.py:65 2019-01-16 12:17:07.648065: step 3021, loss = 0.71337 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:17:08.413988 ops/training.py:65 2019-01-16 12:17:08.413954: step 3022, loss = 0.72357 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:17:09.178223 ops/training.py:65 2019-01-16 12:17:09.178167: step 3023, loss = 0.68623 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:17:09.943425 ops/training.py:65 2019-01-16 12:17:09.943373: step 3024, loss = 0.68924 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:17:10.708452 ops/training.py:65 2019-01-16 12:17:10.708400: step 3025, loss = 0.72219 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:17:11.471977 ops/training.py:65 2019-01-16 12:17:11.471921: step 3026, loss = 0.72331 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:17:12.235908 ops/training.py:65 2019-01-16 12:17:12.235875: step 3027, loss = 0.69522 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:17:13.000461 ops/training.py:65 2019-01-16 12:17:13.000405: step 3028, loss = 0.68656 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:17:13.765896 ops/training.py:65 2019-01-16 12:17:13.765838: step 3029, loss = 0.72616 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 12:17:14.529356 ops/training.py:65 2019-01-16 12:17:14.529298: step 3030, loss = 0.67701 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:17:15.293564 ops/training.py:65 2019-01-16 12:17:15.293512: step 3031, loss = 0.72277 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:17:16.057974 ops/training.py:65 2019-01-16 12:17:16.057939: step 3032, loss = 0.68203 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:17:16.823010 ops/training.py:65 2019-01-16 12:17:16.822948: step 3033, loss = 0.69882 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:17:17.589142 ops/training.py:65 2019-01-16 12:17:17.589087: step 3034, loss = 0.67294 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:17:18.356707 ops/training.py:65 2019-01-16 12:17:18.356653: step 3035, loss = 0.70442 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:17:19.123488 ops/training.py:65 2019-01-16 12:17:19.123433: step 3036, loss = 0.67354 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:17:19.890882 ops/training.py:65 2019-01-16 12:17:19.890852: step 3037, loss = 0.67604 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:17:20.658612 ops/training.py:65 2019-01-16 12:17:20.658557: step 3038, loss = 0.69747 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:17:21.426217 ops/training.py:65 2019-01-16 12:17:21.426170: step 3039, loss = 0.70987 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:17:22.193247 ops/training.py:65 2019-01-16 12:17:22.193189: step 3040, loss = 0.67441 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:17:22.960999 ops/training.py:65 2019-01-16 12:17:22.960942: step 3041, loss = 0.71308 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:17:23.728134 ops/training.py:65 2019-01-16 12:17:23.728106: step 3042, loss = 0.68120 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:17:24.495380 ops/training.py:65 2019-01-16 12:17:24.495324: step 3043, loss = 0.70581 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:17:25.260622 ops/training.py:65 2019-01-16 12:17:25.260562: step 3044, loss = 0.68898 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:17:26.025114 ops/training.py:65 2019-01-16 12:17:26.025060: step 3045, loss = 0.73880 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:17:26.789299 ops/training.py:65 2019-01-16 12:17:26.789234: step 3046, loss = 0.70479 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:17:27.553693 ops/training.py:65 2019-01-16 12:17:27.553661: step 3047, loss = 0.72364 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:17:28.318032 ops/training.py:65 2019-01-16 12:17:28.317976: step 3048, loss = 0.70987 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:17:29.082275 ops/training.py:65 2019-01-16 12:17:29.082218: step 3049, loss = 0.69989 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:17:29.845836 ops/training.py:65 2019-01-16 12:17:29.845770: step 3050, loss = 0.69738 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:17:30.613708 ops/training.py:65 2019-01-16 12:17:30.613662: step 3051, loss = 0.69592 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:17:31.381082 ops/training.py:65 2019-01-16 12:17:31.381032: step 3052, loss = 0.71177 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:17:32.148915 ops/training.py:65 2019-01-16 12:17:32.148839: step 3053, loss = 0.67220 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:17:32.914886 ops/training.py:65 2019-01-16 12:17:32.914816: step 3054, loss = 0.68527 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:17:33.680746 ops/training.py:65 2019-01-16 12:17:33.680678: step 3055, loss = 0.71466 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:17:34.444201 ops/training.py:65 2019-01-16 12:17:34.444151: step 3056, loss = 0.70421 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:17:35.208755 ops/training.py:65 2019-01-16 12:17:35.208687: step 3057, loss = 0.70361 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:17:35.973503 ops/training.py:65 2019-01-16 12:17:35.973436: step 3058, loss = 0.71082 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:17:36.738061 ops/training.py:65 2019-01-16 12:17:36.737992: step 3059, loss = 0.69526 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:17:37.501659 ops/training.py:65 2019-01-16 12:17:37.501588: step 3060, loss = 0.67745 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:17:38.266262 ops/training.py:65 2019-01-16 12:17:38.266210: step 3061, loss = 0.66900 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:17:39.030565 ops/training.py:65 2019-01-16 12:17:39.030509: step 3062, loss = 0.71471 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:17:39.795649 ops/training.py:65 2019-01-16 12:17:39.795575: step 3063, loss = 0.69188 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:17:40.559807 ops/training.py:65 2019-01-16 12:17:40.559742: step 3064, loss = 0.70310 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:17:41.323965 ops/training.py:65 2019-01-16 12:17:41.323898: step 3065, loss = 0.70965 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:17:42.088769 ops/training.py:65 2019-01-16 12:17:42.088722: step 3066, loss = 0.67819 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:17:42.853358 ops/training.py:65 2019-01-16 12:17:42.853292: step 3067, loss = 0.71907 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:17:43.617882 ops/training.py:65 2019-01-16 12:17:43.617815: step 3068, loss = 0.72402 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:17:44.382252 ops/training.py:65 2019-01-16 12:17:44.382197: step 3069, loss = 0.72423 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:17:45.147279 ops/training.py:65 2019-01-16 12:17:45.147211: step 3070, loss = 0.65721 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:17:45.911083 ops/training.py:65 2019-01-16 12:17:45.911030: step 3071, loss = 0.65515 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:17:46.678590 ops/training.py:65 2019-01-16 12:17:46.678538: step 3072, loss = 0.70297 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:17:47.446066 ops/training.py:65 2019-01-16 12:17:47.445996: step 3073, loss = 0.65821 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:17:48.213563 ops/training.py:65 2019-01-16 12:17:48.213487: step 3074, loss = 0.70801 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:17:48.980653 ops/training.py:65 2019-01-16 12:17:48.980588: step 3075, loss = 0.72093 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:17:49.745617 ops/training.py:65 2019-01-16 12:17:49.745559: step 3076, loss = 0.71985 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:17:50.512597 ops/training.py:65 2019-01-16 12:17:50.512527: step 3077, loss = 0.68240 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:17:51.281264 ops/training.py:65 2019-01-16 12:17:51.281200: step 3078, loss = 0.65926 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:17:52.048848 ops/training.py:65 2019-01-16 12:17:52.048792: step 3079, loss = 0.67389 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:17:52.816254 ops/training.py:65 2019-01-16 12:17:52.816176: step 3080, loss = 0.69325 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:17:53.583340 ops/training.py:65 2019-01-16 12:17:53.583276: step 3081, loss = 0.69237 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:17:54.352704 ops/training.py:65 2019-01-16 12:17:54.352626: step 3082, loss = 0.68877 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:17:55.119381 ops/training.py:65 2019-01-16 12:17:55.119309: step 3083, loss = 0.71030 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:17:55.884172 ops/training.py:65 2019-01-16 12:17:55.884102: step 3084, loss = 0.75019 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:17:56.648939 ops/training.py:65 2019-01-16 12:17:56.648870: step 3085, loss = 0.70273 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:17:57.413810 ops/training.py:65 2019-01-16 12:17:57.413762: step 3086, loss = 0.66193 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:17:58.177668 ops/training.py:65 2019-01-16 12:17:58.177605: step 3087, loss = 0.71521 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:17:58.940446 ops/training.py:65 2019-01-16 12:17:58.940381: step 3088, loss = 0.69213 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:17:59.703744 ops/training.py:65 2019-01-16 12:17:59.703671: step 3089, loss = 0.68664 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:18:00.467462 ops/training.py:65 2019-01-16 12:18:00.467382: step 3090, loss = 0.68596 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:18:01.232303 ops/training.py:65 2019-01-16 12:18:01.232253: step 3091, loss = 0.71321 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:18:01.997647 ops/training.py:65 2019-01-16 12:18:01.997583: step 3092, loss = 0.68803 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:18:02.762026 ops/training.py:65 2019-01-16 12:18:02.761960: step 3093, loss = 0.70215 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:18:03.526641 ops/training.py:65 2019-01-16 12:18:03.526567: step 3094, loss = 0.70126 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:18:04.293415 ops/training.py:65 2019-01-16 12:18:04.293369: step 3095, loss = 0.66013 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:18:05.061692 ops/training.py:65 2019-01-16 12:18:05.061615: step 3096, loss = 0.70013 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:18:05.827561 ops/training.py:65 2019-01-16 12:18:05.827503: step 3097, loss = 0.67520 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:18:06.592736 ops/training.py:65 2019-01-16 12:18:06.592687: step 3098, loss = 0.68580 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:18:07.357157 ops/training.py:65 2019-01-16 12:18:07.357083: step 3099, loss = 0.72547 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:18:08.121815 ops/training.py:65 2019-01-16 12:18:08.121774: step 3100, loss = 0.69383 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:18:08.886139 ops/training.py:65 2019-01-16 12:18:08.886088: step 3101, loss = 0.73411 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 12:18:09.654536 ops/training.py:65 2019-01-16 12:18:09.654467: step 3102, loss = 0.71567 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:18:10.422925 ops/training.py:65 2019-01-16 12:18:10.422841: step 3103, loss = 0.72681 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:18:11.189834 ops/training.py:65 2019-01-16 12:18:11.189759: step 3104, loss = 0.68418 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:18:11.954619 ops/training.py:65 2019-01-16 12:18:11.954535: step 3105, loss = 0.71762 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:18:12.719096 ops/training.py:65 2019-01-16 12:18:12.719023: step 3106, loss = 0.70202 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:18:13.483590 ops/training.py:65 2019-01-16 12:18:13.483517: step 3107, loss = 0.67934 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:18:14.247776 ops/training.py:65 2019-01-16 12:18:14.247708: step 3108, loss = 0.68041 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:18:15.012042 ops/training.py:65 2019-01-16 12:18:15.011971: step 3109, loss = 0.68578 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:18:15.776682 ops/training.py:65 2019-01-16 12:18:15.776630: step 3110, loss = 0.66148 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:18:16.541465 ops/training.py:65 2019-01-16 12:18:16.541413: step 3111, loss = 0.67908 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:18:17.306246 ops/training.py:65 2019-01-16 12:18:17.306178: step 3112, loss = 0.70161 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:18:18.070020 ops/training.py:65 2019-01-16 12:18:18.069944: step 3113, loss = 0.73379 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:18:18.834910 ops/training.py:65 2019-01-16 12:18:18.834853: step 3114, loss = 0.72650 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:18:19.600398 ops/training.py:65 2019-01-16 12:18:19.600352: step 3115, loss = 0.71661 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:18:20.363780 ops/training.py:65 2019-01-16 12:18:20.363711: step 3116, loss = 0.68778 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:18:21.127272 ops/training.py:65 2019-01-16 12:18:21.127221: step 3117, loss = 0.68579 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:18:21.890990 ops/training.py:65 2019-01-16 12:18:21.890912: step 3118, loss = 0.70803 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:18:22.655729 ops/training.py:65 2019-01-16 12:18:22.655657: step 3119, loss = 0.69752 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:18:23.419756 ops/training.py:65 2019-01-16 12:18:23.419703: step 3120, loss = 0.68509 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:18:24.184036 ops/training.py:65 2019-01-16 12:18:24.183966: step 3121, loss = 0.68863 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:18:24.948565 ops/training.py:65 2019-01-16 12:18:24.948497: step 3122, loss = 0.69501 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:18:25.717465 ops/training.py:65 2019-01-16 12:18:25.717393: step 3123, loss = 0.67772 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:18:26.485173 ops/training.py:65 2019-01-16 12:18:26.485101: step 3124, loss = 0.67085 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:18:27.252072 ops/training.py:65 2019-01-16 12:18:27.252007: step 3125, loss = 0.70567 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:18:28.017124 ops/training.py:65 2019-01-16 12:18:28.017050: step 3126, loss = 0.70675 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:18:28.781668 ops/training.py:65 2019-01-16 12:18:28.781602: step 3127, loss = 0.69173 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:18:29.548183 ops/training.py:65 2019-01-16 12:18:29.548123: step 3128, loss = 0.69117 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:18:30.315052 ops/training.py:65 2019-01-16 12:18:30.314982: step 3129, loss = 0.69290 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:18:31.084090 ops/training.py:65 2019-01-16 12:18:31.084002: step 3130, loss = 0.69467 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:18:31.852593 ops/training.py:65 2019-01-16 12:18:31.852529: step 3131, loss = 0.68575 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:18:32.617393 ops/training.py:65 2019-01-16 12:18:32.617320: step 3132, loss = 0.70169 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:18:33.384457 ops/training.py:65 2019-01-16 12:18:33.384387: step 3133, loss = 0.67542 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:18:34.151227 ops/training.py:65 2019-01-16 12:18:34.151158: step 3134, loss = 0.68680 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:18:34.915409 ops/training.py:65 2019-01-16 12:18:34.915360: step 3135, loss = 0.66803 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:18:35.679455 ops/training.py:65 2019-01-16 12:18:35.679387: step 3136, loss = 0.69155 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:18:36.442625 ops/training.py:65 2019-01-16 12:18:36.442576: step 3137, loss = 0.67935 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:18:37.206075 ops/training.py:65 2019-01-16 12:18:37.206010: step 3138, loss = 0.68325 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:18:37.970056 ops/training.py:65 2019-01-16 12:18:37.969991: step 3139, loss = 0.66986 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:18:38.734555 ops/training.py:65 2019-01-16 12:18:38.734505: step 3140, loss = 0.70174 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:18:39.501161 ops/training.py:65 2019-01-16 12:18:39.501108: step 3141, loss = 0.71426 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:18:40.268821 ops/training.py:65 2019-01-16 12:18:40.268743: step 3142, loss = 0.71089 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:18:41.037273 ops/training.py:65 2019-01-16 12:18:41.037218: step 3143, loss = 0.70264 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:18:41.804819 ops/training.py:65 2019-01-16 12:18:41.804771: step 3144, loss = 0.67823 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:18:42.573761 ops/training.py:65 2019-01-16 12:18:42.573699: step 3145, loss = 0.72303 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:18:43.341265 ops/training.py:65 2019-01-16 12:18:43.341211: step 3146, loss = 0.69173 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:18:44.109896 ops/training.py:65 2019-01-16 12:18:44.109839: step 3147, loss = 0.69276 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:18:44.877800 ops/training.py:65 2019-01-16 12:18:44.877746: step 3148, loss = 0.69508 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:18:45.645407 ops/training.py:65 2019-01-16 12:18:45.645361: step 3149, loss = 0.70884 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:18:46.410188 ops/training.py:65 2019-01-16 12:18:46.410128: step 3150, loss = 0.68130 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:18:47.175207 ops/training.py:65 2019-01-16 12:18:47.175146: step 3151, loss = 0.71204 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:18:47.938558 ops/training.py:65 2019-01-16 12:18:47.938505: step 3152, loss = 0.68972 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:18:48.704737 ops/training.py:65 2019-01-16 12:18:48.704688: step 3153, loss = 0.70739 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:18:49.469705 ops/training.py:65 2019-01-16 12:18:49.469655: step 3154, loss = 0.69971 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:18:50.233766 ops/training.py:65 2019-01-16 12:18:50.233695: step 3155, loss = 0.69796 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:18:51.001897 ops/training.py:65 2019-01-16 12:18:51.001827: step 3156, loss = 0.69759 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:18:51.771419 ops/training.py:65 2019-01-16 12:18:51.771358: step 3157, loss = 0.70318 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:18:52.539643 ops/training.py:65 2019-01-16 12:18:52.539571: step 3158, loss = 0.68639 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:18:53.306775 ops/training.py:65 2019-01-16 12:18:53.306704: step 3159, loss = 0.68189 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:18:54.074132 ops/training.py:65 2019-01-16 12:18:54.074055: step 3160, loss = 0.68391 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:18:54.841153 ops/training.py:65 2019-01-16 12:18:54.841077: step 3161, loss = 0.67530 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:18:55.608136 ops/training.py:65 2019-01-16 12:18:55.608060: step 3162, loss = 0.69525 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:18:56.374339 ops/training.py:65 2019-01-16 12:18:56.374266: step 3163, loss = 0.70688 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:18:57.140950 ops/training.py:65 2019-01-16 12:18:57.140881: step 3164, loss = 0.71396 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:18:57.905545 ops/training.py:65 2019-01-16 12:18:57.905478: step 3165, loss = 0.70565 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:18:58.671122 ops/training.py:65 2019-01-16 12:18:58.671055: step 3166, loss = 0.69856 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:18:59.439093 ops/training.py:65 2019-01-16 12:18:59.439035: step 3167, loss = 0.68555 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:19:00.207347 ops/training.py:65 2019-01-16 12:19:00.207272: step 3168, loss = 0.68912 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:19:00.975713 ops/training.py:65 2019-01-16 12:19:00.975635: step 3169, loss = 0.70461 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:19:01.742441 ops/training.py:65 2019-01-16 12:19:01.742383: step 3170, loss = 0.69540 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:19:02.510087 ops/training.py:65 2019-01-16 12:19:02.510019: step 3171, loss = 0.70487 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:19:03.279950 ops/training.py:65 2019-01-16 12:19:03.279875: step 3172, loss = 0.68772 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:19:04.048497 ops/training.py:65 2019-01-16 12:19:04.048422: step 3173, loss = 0.69244 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:19:04.816373 ops/training.py:65 2019-01-16 12:19:04.816298: step 3174, loss = 0.71457 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:19:05.582000 ops/training.py:65 2019-01-16 12:19:05.581932: step 3175, loss = 0.69687 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:19:06.346770 ops/training.py:65 2019-01-16 12:19:06.346722: step 3176, loss = 0.69970 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:19:07.111322 ops/training.py:65 2019-01-16 12:19:07.111251: step 3177, loss = 0.72531 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:19:07.875869 ops/training.py:65 2019-01-16 12:19:07.875800: step 3178, loss = 0.69414 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:19:08.639861 ops/training.py:65 2019-01-16 12:19:08.639799: step 3179, loss = 0.68260 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:19:09.403823 ops/training.py:65 2019-01-16 12:19:09.403768: step 3180, loss = 0.71651 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:19:10.168914 ops/training.py:65 2019-01-16 12:19:10.168845: step 3181, loss = 0.67736 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:19:10.933535 ops/training.py:65 2019-01-16 12:19:10.933482: step 3182, loss = 0.67426 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:19:11.697163 ops/training.py:65 2019-01-16 12:19:11.697094: step 3183, loss = 0.71359 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:19:12.461375 ops/training.py:65 2019-01-16 12:19:12.461332: step 3184, loss = 0.71262 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:19:13.224447 ops/training.py:65 2019-01-16 12:19:13.224375: step 3185, loss = 0.68233 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:19:13.987572 ops/training.py:65 2019-01-16 12:19:13.987499: step 3186, loss = 0.69392 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:19:14.752250 ops/training.py:65 2019-01-16 12:19:14.752174: step 3187, loss = 0.68673 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:19:15.516543 ops/training.py:65 2019-01-16 12:19:15.516476: step 3188, loss = 0.69953 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:19:16.280254 ops/training.py:65 2019-01-16 12:19:16.280205: step 3189, loss = 0.67680 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:19:17.043485 ops/training.py:65 2019-01-16 12:19:17.043416: step 3190, loss = 0.69816 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:19:17.806793 ops/training.py:65 2019-01-16 12:19:17.806727: step 3191, loss = 0.70771 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:19:18.570374 ops/training.py:65 2019-01-16 12:19:18.570304: step 3192, loss = 0.68135 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:19:19.334502 ops/training.py:65 2019-01-16 12:19:19.334442: step 3193, loss = 0.72118 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:19:20.103472 ops/training.py:65 2019-01-16 12:19:20.103443: step 3194, loss = 0.70930 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:19:20.871112 ops/training.py:65 2019-01-16 12:19:20.871041: step 3195, loss = 0.70708 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:19:21.640324 ops/training.py:65 2019-01-16 12:19:21.640252: step 3196, loss = 0.68222 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:19:22.405770 ops/training.py:65 2019-01-16 12:19:22.405714: step 3197, loss = 0.68616 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:19:23.170492 ops/training.py:65 2019-01-16 12:19:23.170451: step 3198, loss = 0.70754 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:19:23.935330 ops/training.py:65 2019-01-16 12:19:23.935280: step 3199, loss = 0.67441 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:19:24.701493 ops/training.py:65 2019-01-16 12:19:24.701429: step 3200, loss = 0.70159 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:19:25.468843 ops/training.py:65 2019-01-16 12:19:25.468768: step 3201, loss = 0.72378 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:19:26.236093 ops/training.py:65 2019-01-16 12:19:26.236015: step 3202, loss = 0.70420 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:19:27.003815 ops/training.py:65 2019-01-16 12:19:27.003746: step 3203, loss = 0.66811 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:19:27.768498 ops/training.py:65 2019-01-16 12:19:27.768432: step 3204, loss = 0.70084 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:19:28.532885 ops/training.py:65 2019-01-16 12:19:28.532817: step 3205, loss = 0.68466 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:19:29.298154 ops/training.py:65 2019-01-16 12:19:29.298090: step 3206, loss = 0.68984 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:19:30.062810 ops/training.py:65 2019-01-16 12:19:30.062737: step 3207, loss = 0.71483 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.25
I0528 2019-01-16 12:19:30.827920 ops/training.py:65 2019-01-16 12:19:30.827873: step 3208, loss = 0.71363 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:19:31.592593 ops/training.py:65 2019-01-16 12:19:31.592541: step 3209, loss = 0.71473 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:19:32.357260 ops/training.py:65 2019-01-16 12:19:32.357189: step 3210, loss = 0.69415 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:19:33.121034 ops/training.py:65 2019-01-16 12:19:33.120969: step 3211, loss = 0.70509 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:19:33.885495 ops/training.py:65 2019-01-16 12:19:33.885424: step 3212, loss = 0.68775 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:19:34.649957 ops/training.py:65 2019-01-16 12:19:34.649909: step 3213, loss = 0.66674 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:19:35.414458 ops/training.py:65 2019-01-16 12:19:35.414396: step 3214, loss = 0.68292 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:19:36.179149 ops/training.py:65 2019-01-16 12:19:36.179079: step 3215, loss = 0.68335 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:19:36.943131 ops/training.py:65 2019-01-16 12:19:36.943063: step 3216, loss = 0.69317 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:19:37.707297 ops/training.py:65 2019-01-16 12:19:37.707232: step 3217, loss = 0.69610 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:19:38.472337 ops/training.py:65 2019-01-16 12:19:38.472284: step 3218, loss = 0.69420 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:19:39.236928 ops/training.py:65 2019-01-16 12:19:39.236869: step 3219, loss = 0.68997 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:19:40.000637 ops/training.py:65 2019-01-16 12:19:40.000569: step 3220, loss = 0.70127 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:19:40.764506 ops/training.py:65 2019-01-16 12:19:40.764438: step 3221, loss = 0.70818 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:19:41.528148 ops/training.py:65 2019-01-16 12:19:41.528077: step 3222, loss = 0.70481 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:19:42.291614 ops/training.py:65 2019-01-16 12:19:42.291566: step 3223, loss = 0.69774 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:19:43.057368 ops/training.py:65 2019-01-16 12:19:43.057303: step 3224, loss = 0.68729 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:19:43.824581 ops/training.py:65 2019-01-16 12:19:43.824509: step 3225, loss = 0.70913 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:19:44.591643 ops/training.py:65 2019-01-16 12:19:44.591573: step 3226, loss = 0.68883 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:19:45.360264 ops/training.py:65 2019-01-16 12:19:45.360190: step 3227, loss = 0.69196 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:19:46.127916 ops/training.py:65 2019-01-16 12:19:46.127837: step 3228, loss = 0.67868 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:19:46.893580 ops/training.py:65 2019-01-16 12:19:46.893508: step 3229, loss = 0.67104 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:19:47.659458 ops/training.py:65 2019-01-16 12:19:47.659389: step 3230, loss = 0.69958 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:19:48.424172 ops/training.py:65 2019-01-16 12:19:48.424100: step 3231, loss = 0.71542 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:19:49.188352 ops/training.py:65 2019-01-16 12:19:49.188288: step 3232, loss = 0.68538 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:19:49.952423 ops/training.py:65 2019-01-16 12:19:49.952365: step 3233, loss = 0.68102 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:19:50.716979 ops/training.py:65 2019-01-16 12:19:50.716911: step 3234, loss = 0.68991 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:19:51.479739 ops/training.py:65 2019-01-16 12:19:51.479689: step 3235, loss = 0.68122 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:19:52.243729 ops/training.py:65 2019-01-16 12:19:52.243665: step 3236, loss = 0.70017 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:19:53.007837 ops/training.py:65 2019-01-16 12:19:53.007792: step 3237, loss = 0.71332 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:19:53.772631 ops/training.py:65 2019-01-16 12:19:53.772565: step 3238, loss = 0.69823 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:19:54.536952 ops/training.py:65 2019-01-16 12:19:54.536882: step 3239, loss = 0.69420 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:19:55.305265 ops/training.py:65 2019-01-16 12:19:55.305200: step 3240, loss = 0.67917 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:19:56.074973 ops/training.py:65 2019-01-16 12:19:56.074895: step 3241, loss = 0.68855 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:19:56.845770 ops/training.py:65 2019-01-16 12:19:56.845695: step 3242, loss = 0.67692 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:19:57.613007 ops/training.py:65 2019-01-16 12:19:57.612923: step 3243, loss = 0.69370 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:19:58.379416 ops/training.py:65 2019-01-16 12:19:58.379351: step 3244, loss = 0.70437 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:19:59.144850 ops/training.py:65 2019-01-16 12:19:59.144789: step 3245, loss = 0.68639 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:19:59.908364 ops/training.py:65 2019-01-16 12:19:59.908294: step 3246, loss = 0.69760 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:20:00.672282 ops/training.py:65 2019-01-16 12:20:00.672231: step 3247, loss = 0.68032 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:20:01.437357 ops/training.py:65 2019-01-16 12:20:01.437308: step 3248, loss = 0.71024 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:20:02.206671 ops/training.py:65 2019-01-16 12:20:02.206613: step 3249, loss = 0.69040 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:20:02.974956 ops/training.py:65 2019-01-16 12:20:02.974881: step 3250, loss = 0.72030 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:20:03.742805 ops/training.py:65 2019-01-16 12:20:03.742726: step 3251, loss = 0.70445 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:20:04.511342 ops/training.py:65 2019-01-16 12:20:04.511268: step 3252, loss = 0.68204 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:20:05.277498 ops/training.py:65 2019-01-16 12:20:05.277421: step 3253, loss = 0.67361 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:20:06.041014 ops/training.py:65 2019-01-16 12:20:06.040946: step 3254, loss = 0.71337 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:20:06.804248 ops/training.py:65 2019-01-16 12:20:06.804182: step 3255, loss = 0.68647 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:20:07.570093 ops/training.py:65 2019-01-16 12:20:07.570024: step 3256, loss = 0.66763 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:20:08.337627 ops/training.py:65 2019-01-16 12:20:08.337558: step 3257, loss = 0.69376 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:20:09.105605 ops/training.py:65 2019-01-16 12:20:09.105550: step 3258, loss = 0.69956 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:20:09.873777 ops/training.py:65 2019-01-16 12:20:09.873695: step 3259, loss = 0.71188 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:20:10.638644 ops/training.py:65 2019-01-16 12:20:10.638565: step 3260, loss = 0.69464 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:20:11.403079 ops/training.py:65 2019-01-16 12:20:11.403008: step 3261, loss = 0.70236 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:20:12.167278 ops/training.py:65 2019-01-16 12:20:12.167225: step 3262, loss = 0.69813 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:20:12.932885 ops/training.py:65 2019-01-16 12:20:12.932812: step 3263, loss = 0.68210 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:20:13.698219 ops/training.py:65 2019-01-16 12:20:13.698144: step 3264, loss = 0.66863 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:20:14.463615 ops/training.py:65 2019-01-16 12:20:14.463541: step 3265, loss = 0.70162 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:20:15.226572 ops/training.py:65 2019-01-16 12:20:15.226500: step 3266, loss = 0.71412 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:20:15.990677 ops/training.py:65 2019-01-16 12:20:15.990626: step 3267, loss = 0.68079 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:20:16.757407 ops/training.py:65 2019-01-16 12:20:16.757357: step 3268, loss = 0.70460 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:20:17.525659 ops/training.py:65 2019-01-16 12:20:17.525588: step 3269, loss = 0.69694 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:20:18.293750 ops/training.py:65 2019-01-16 12:20:18.293671: step 3270, loss = 0.70700 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:20:19.060800 ops/training.py:65 2019-01-16 12:20:19.060733: step 3271, loss = 0.70686 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:20:19.826579 ops/training.py:65 2019-01-16 12:20:19.826526: step 3272, loss = 0.70369 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:20:20.589745 ops/training.py:65 2019-01-16 12:20:20.589668: step 3273, loss = 0.69269 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:20:21.352826 ops/training.py:65 2019-01-16 12:20:21.352773: step 3274, loss = 0.68628 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:20:22.116920 ops/training.py:65 2019-01-16 12:20:22.116850: step 3275, loss = 0.70568 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:20:22.880528 ops/training.py:65 2019-01-16 12:20:22.880458: step 3276, loss = 0.68856 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:20:23.645093 ops/training.py:65 2019-01-16 12:20:23.645043: step 3277, loss = 0.71329 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:20:24.408969 ops/training.py:65 2019-01-16 12:20:24.408903: step 3278, loss = 0.68609 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:20:25.173258 ops/training.py:65 2019-01-16 12:20:25.173185: step 3279, loss = 0.73730 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:20:25.937141 ops/training.py:65 2019-01-16 12:20:25.937073: step 3280, loss = 0.74001 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:20:26.703569 ops/training.py:65 2019-01-16 12:20:26.703527: step 3281, loss = 0.70240 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:20:27.471043 ops/training.py:65 2019-01-16 12:20:27.470965: step 3282, loss = 0.71539 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:20:28.239066 ops/training.py:65 2019-01-16 12:20:28.238993: step 3283, loss = 0.69719 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:20:29.003944 ops/training.py:65 2019-01-16 12:20:29.003884: step 3284, loss = 0.69085 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:20:29.771647 ops/training.py:65 2019-01-16 12:20:29.771579: step 3285, loss = 0.68587 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:20:30.540757 ops/training.py:65 2019-01-16 12:20:30.540677: step 3286, loss = 0.69454 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:20:31.307858 ops/training.py:65 2019-01-16 12:20:31.307811: step 3287, loss = 0.69353 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:20:32.072942 ops/training.py:65 2019-01-16 12:20:32.072871: step 3288, loss = 0.69963 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:20:32.837756 ops/training.py:65 2019-01-16 12:20:32.837681: step 3289, loss = 0.70001 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:20:33.602875 ops/training.py:65 2019-01-16 12:20:33.602804: step 3290, loss = 0.69298 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:20:34.366928 ops/training.py:65 2019-01-16 12:20:34.366883: step 3291, loss = 0.69916 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:20:35.130628 ops/training.py:65 2019-01-16 12:20:35.130560: step 3292, loss = 0.69183 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:20:35.894876 ops/training.py:65 2019-01-16 12:20:35.894805: step 3293, loss = 0.70537 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:20:36.660123 ops/training.py:65 2019-01-16 12:20:36.660056: step 3294, loss = 0.69795 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:20:37.424555 ops/training.py:65 2019-01-16 12:20:37.424484: step 3295, loss = 0.71215 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:20:38.189777 ops/training.py:65 2019-01-16 12:20:38.189732: step 3296, loss = 0.72485 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:20:38.954179 ops/training.py:65 2019-01-16 12:20:38.954119: step 3297, loss = 0.67181 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:20:39.718483 ops/training.py:65 2019-01-16 12:20:39.718406: step 3298, loss = 0.69570 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:20:40.486500 ops/training.py:65 2019-01-16 12:20:40.486407: step 3299, loss = 0.72335 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:20:41.255297 ops/training.py:65 2019-01-16 12:20:41.255220: step 3300, loss = 0.71572 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:20:42.024228 ops/training.py:65 2019-01-16 12:20:42.024153: step 3301, loss = 0.68660 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:20:42.791408 ops/training.py:65 2019-01-16 12:20:42.791330: step 3302, loss = 0.68498 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:20:43.557157 ops/training.py:65 2019-01-16 12:20:43.557074: step 3303, loss = 0.71126 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:20:44.323841 ops/training.py:65 2019-01-16 12:20:44.323765: step 3304, loss = 0.69129 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:20:45.090955 ops/training.py:65 2019-01-16 12:20:45.090892: step 3305, loss = 0.72614 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:20:45.859110 ops/training.py:65 2019-01-16 12:20:45.859037: step 3306, loss = 0.69720 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:20:46.627367 ops/training.py:65 2019-01-16 12:20:46.627310: step 3307, loss = 0.72752 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:20:47.392502 ops/training.py:65 2019-01-16 12:20:47.392405: step 3308, loss = 0.70603 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:20:48.157971 ops/training.py:65 2019-01-16 12:20:48.157901: step 3309, loss = 0.72161 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:20:48.922417 ops/training.py:65 2019-01-16 12:20:48.922355: step 3310, loss = 0.66180 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:20:49.686502 ops/training.py:65 2019-01-16 12:20:49.686446: step 3311, loss = 0.70473 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:20:50.450435 ops/training.py:65 2019-01-16 12:20:50.450363: step 3312, loss = 0.67566 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:20:51.216629 ops/training.py:65 2019-01-16 12:20:51.216558: step 3313, loss = 0.67338 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:20:51.985120 ops/training.py:65 2019-01-16 12:20:51.985048: step 3314, loss = 0.68204 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:20:52.753469 ops/training.py:65 2019-01-16 12:20:52.753389: step 3315, loss = 0.71806 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:20:53.520086 ops/training.py:65 2019-01-16 12:20:53.520035: step 3316, loss = 0.69857 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:20:54.283896 ops/training.py:65 2019-01-16 12:20:54.283831: step 3317, loss = 0.70975 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:20:55.048647 ops/training.py:65 2019-01-16 12:20:55.048574: step 3318, loss = 0.68169 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:20:55.813403 ops/training.py:65 2019-01-16 12:20:55.813333: step 3319, loss = 0.70564 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:20:56.578497 ops/training.py:65 2019-01-16 12:20:56.578426: step 3320, loss = 0.68706 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:20:57.345749 ops/training.py:65 2019-01-16 12:20:57.345697: step 3321, loss = 0.68985 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:20:58.114165 ops/training.py:65 2019-01-16 12:20:58.114094: step 3322, loss = 0.67326 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:20:58.882100 ops/training.py:65 2019-01-16 12:20:58.882033: step 3323, loss = 0.70605 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:20:59.646665 ops/training.py:65 2019-01-16 12:20:59.646593: step 3324, loss = 0.67544 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:21:00.410464 ops/training.py:65 2019-01-16 12:21:00.410395: step 3325, loss = 0.69077 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:21:01.174553 ops/training.py:65 2019-01-16 12:21:01.174498: step 3326, loss = 0.72390 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:21:01.937848 ops/training.py:65 2019-01-16 12:21:01.937767: step 3327, loss = 0.71608 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:21:02.701678 ops/training.py:65 2019-01-16 12:21:02.701608: step 3328, loss = 0.67797 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:21:03.465871 ops/training.py:65 2019-01-16 12:21:03.465803: step 3329, loss = 0.68894 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:21:04.230341 ops/training.py:65 2019-01-16 12:21:04.230292: step 3330, loss = 0.69112 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:21:04.994848 ops/training.py:65 2019-01-16 12:21:04.994776: step 3331, loss = 0.71051 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:21:05.763530 ops/training.py:65 2019-01-16 12:21:05.763459: step 3332, loss = 0.72284 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.21875
I0528 2019-01-16 12:21:06.533119 ops/training.py:65 2019-01-16 12:21:06.533049: step 3333, loss = 0.69634 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:21:07.302321 ops/training.py:65 2019-01-16 12:21:07.302253: step 3334, loss = 0.68113 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:21:08.067921 ops/training.py:65 2019-01-16 12:21:08.067875: step 3335, loss = 0.67942 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:21:08.832044 ops/training.py:65 2019-01-16 12:21:08.831987: step 3336, loss = 0.70435 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:21:09.599295 ops/training.py:65 2019-01-16 12:21:09.599235: step 3337, loss = 0.70721 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:21:10.368522 ops/training.py:65 2019-01-16 12:21:10.368450: step 3338, loss = 0.69029 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:21:11.134771 ops/training.py:65 2019-01-16 12:21:11.134702: step 3339, loss = 0.71379 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:21:11.900332 ops/training.py:65 2019-01-16 12:21:11.900280: step 3340, loss = 0.70834 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:21:12.667532 ops/training.py:65 2019-01-16 12:21:12.667462: step 3341, loss = 0.68414 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 12:21:13.436181 ops/training.py:65 2019-01-16 12:21:13.436110: step 3342, loss = 0.66250 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:21:14.203340 ops/training.py:65 2019-01-16 12:21:14.203269: step 3343, loss = 0.69705 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:21:14.972121 ops/training.py:65 2019-01-16 12:21:14.972051: step 3344, loss = 0.69759 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:21:15.741039 ops/training.py:65 2019-01-16 12:21:15.740977: step 3345, loss = 0.70230 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:21:16.509716 ops/training.py:65 2019-01-16 12:21:16.509659: step 3346, loss = 0.69591 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:21:17.277833 ops/training.py:65 2019-01-16 12:21:17.277759: step 3347, loss = 0.69983 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:21:18.045752 ops/training.py:65 2019-01-16 12:21:18.045676: step 3348, loss = 0.69444 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:21:18.811663 ops/training.py:65 2019-01-16 12:21:18.811602: step 3349, loss = 0.68417 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:21:19.576555 ops/training.py:65 2019-01-16 12:21:19.576500: step 3350, loss = 0.67830 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:21:20.340820 ops/training.py:65 2019-01-16 12:21:20.340752: step 3351, loss = 0.69682 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:21:21.104852 ops/training.py:65 2019-01-16 12:21:21.104785: step 3352, loss = 0.69312 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:21:21.869587 ops/training.py:65 2019-01-16 12:21:21.869519: step 3353, loss = 0.71484 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:21:22.633325 ops/training.py:65 2019-01-16 12:21:22.633259: step 3354, loss = 0.66910 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 12:21:23.398238 ops/training.py:65 2019-01-16 12:21:23.398190: step 3355, loss = 0.70516 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:21:24.162233 ops/training.py:65 2019-01-16 12:21:24.162164: step 3356, loss = 0.69342 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:21:24.927249 ops/training.py:65 2019-01-16 12:21:24.927180: step 3357, loss = 0.69236 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:21:25.691917 ops/training.py:65 2019-01-16 12:21:25.691839: step 3358, loss = 0.68930 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:21:26.455786 ops/training.py:65 2019-01-16 12:21:26.455717: step 3359, loss = 0.68116 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:21:27.220237 ops/training.py:65 2019-01-16 12:21:27.220189: step 3360, loss = 0.70255 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:21:27.984422 ops/training.py:65 2019-01-16 12:21:27.984350: step 3361, loss = 0.67840 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:21:28.748852 ops/training.py:65 2019-01-16 12:21:28.748786: step 3362, loss = 0.68107 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:21:29.514012 ops/training.py:65 2019-01-16 12:21:29.513939: step 3363, loss = 0.70006 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:21:30.279225 ops/training.py:65 2019-01-16 12:21:30.279154: step 3364, loss = 0.70377 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:21:31.044774 ops/training.py:65 2019-01-16 12:21:31.044725: step 3365, loss = 0.70341 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:21:31.810689 ops/training.py:65 2019-01-16 12:21:31.810624: step 3366, loss = 0.68907 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:21:32.575858 ops/training.py:65 2019-01-16 12:21:32.575786: step 3367, loss = 0.69126 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:21:33.342237 ops/training.py:65 2019-01-16 12:21:33.342162: step 3368, loss = 0.68878 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:21:34.110851 ops/training.py:65 2019-01-16 12:21:34.110786: step 3369, loss = 0.69587 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:21:34.879162 ops/training.py:65 2019-01-16 12:21:34.879093: step 3370, loss = 0.69864 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:21:35.647944 ops/training.py:65 2019-01-16 12:21:35.647868: step 3371, loss = 0.68210 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:21:36.416345 ops/training.py:65 2019-01-16 12:21:36.416286: step 3372, loss = 0.69473 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:21:37.183185 ops/training.py:65 2019-01-16 12:21:37.183127: step 3373, loss = 0.71013 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:21:37.948059 ops/training.py:65 2019-01-16 12:21:37.948011: step 3374, loss = 0.69971 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:21:38.714568 ops/training.py:65 2019-01-16 12:21:38.714499: step 3375, loss = 0.68749 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:21:39.482849 ops/training.py:65 2019-01-16 12:21:39.482792: step 3376, loss = 0.70862 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:21:40.250190 ops/training.py:65 2019-01-16 12:21:40.250117: step 3377, loss = 0.68441 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:21:41.015137 ops/training.py:65 2019-01-16 12:21:41.015069: step 3378, loss = 0.70937 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:21:41.779207 ops/training.py:65 2019-01-16 12:21:41.779162: step 3379, loss = 0.67438 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:21:42.542906 ops/training.py:65 2019-01-16 12:21:42.542838: step 3380, loss = 0.68613 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:21:43.305894 ops/training.py:65 2019-01-16 12:21:43.305825: step 3381, loss = 0.67890 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:21:44.069317 ops/training.py:65 2019-01-16 12:21:44.069248: step 3382, loss = 0.71394 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:21:44.832367 ops/training.py:65 2019-01-16 12:21:44.832297: step 3383, loss = 0.69177 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:21:45.596124 ops/training.py:65 2019-01-16 12:21:45.596074: step 3384, loss = 0.69186 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:21:46.359273 ops/training.py:65 2019-01-16 12:21:46.359223: step 3385, loss = 0.68168 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:21:47.122567 ops/training.py:65 2019-01-16 12:21:47.122496: step 3386, loss = 0.69108 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:21:47.888218 ops/training.py:65 2019-01-16 12:21:47.888147: step 3387, loss = 0.69883 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:21:48.655527 ops/training.py:65 2019-01-16 12:21:48.655451: step 3388, loss = 0.70051 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:21:49.423117 ops/training.py:65 2019-01-16 12:21:49.423045: step 3389, loss = 0.68651 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:21:50.190194 ops/training.py:65 2019-01-16 12:21:50.190140: step 3390, loss = 0.70522 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:21:50.958910 ops/training.py:65 2019-01-16 12:21:50.958840: step 3391, loss = 0.68394 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:21:51.728412 ops/training.py:65 2019-01-16 12:21:51.728344: step 3392, loss = 0.70841 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:21:52.496636 ops/training.py:65 2019-01-16 12:21:52.496561: step 3393, loss = 0.68433 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:21:53.260890 ops/training.py:65 2019-01-16 12:21:53.260840: step 3394, loss = 0.68577 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:21:54.025478 ops/training.py:65 2019-01-16 12:21:54.025410: step 3395, loss = 0.70973 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:21:54.790480 ops/training.py:65 2019-01-16 12:21:54.790410: step 3396, loss = 0.69132 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:21:55.558701 ops/training.py:65 2019-01-16 12:21:55.558639: step 3397, loss = 0.68934 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:21:56.326800 ops/training.py:65 2019-01-16 12:21:56.326730: step 3398, loss = 0.70011 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:21:57.094276 ops/training.py:65 2019-01-16 12:21:57.094216: step 3399, loss = 0.68571 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:21:57.860997 ops/training.py:65 2019-01-16 12:21:57.860944: step 3400, loss = 0.69370 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:21:58.626909 ops/training.py:65 2019-01-16 12:21:58.626849: step 3401, loss = 0.67846 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:21:59.391207 ops/training.py:65 2019-01-16 12:21:59.391150: step 3402, loss = 0.69468 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:22:00.155259 ops/training.py:65 2019-01-16 12:22:00.155204: step 3403, loss = 0.68871 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:22:00.919500 ops/training.py:65 2019-01-16 12:22:00.919470: step 3404, loss = 0.67996 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:22:01.683658 ops/training.py:65 2019-01-16 12:22:01.683611: step 3405, loss = 0.68223 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:22:02.448440 ops/training.py:65 2019-01-16 12:22:02.448381: step 3406, loss = 0.69244 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:22:03.212911 ops/training.py:65 2019-01-16 12:22:03.212854: step 3407, loss = 0.67753 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:22:03.977301 ops/training.py:65 2019-01-16 12:22:03.977241: step 3408, loss = 0.68259 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:22:04.741009 ops/training.py:65 2019-01-16 12:22:04.740960: step 3409, loss = 0.69885 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:22:05.504875 ops/training.py:65 2019-01-16 12:22:05.504817: step 3410, loss = 0.68846 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:22:06.270185 ops/training.py:65 2019-01-16 12:22:06.270128: step 3411, loss = 0.68727 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:22:07.033925 ops/training.py:65 2019-01-16 12:22:07.033857: step 3412, loss = 0.69302 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:22:07.797942 ops/training.py:65 2019-01-16 12:22:07.797873: step 3413, loss = 0.69384 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:22:08.565826 ops/training.py:65 2019-01-16 12:22:08.565792: step 3414, loss = 0.69422 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:22:09.334157 ops/training.py:65 2019-01-16 12:22:09.334100: step 3415, loss = 0.70917 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:22:10.102787 ops/training.py:65 2019-01-16 12:22:10.102694: step 3416, loss = 0.68375 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:22:10.872068 ops/training.py:65 2019-01-16 12:22:10.871996: step 3417, loss = 0.71638 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:22:11.639502 ops/training.py:65 2019-01-16 12:22:11.639445: step 3418, loss = 0.68959 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:22:12.407019 ops/training.py:65 2019-01-16 12:22:12.406961: step 3419, loss = 0.67863 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:22:13.173781 ops/training.py:65 2019-01-16 12:22:13.173711: step 3420, loss = 0.68969 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:22:13.941382 ops/training.py:65 2019-01-16 12:22:13.941309: step 3421, loss = 0.69538 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:22:14.708582 ops/training.py:65 2019-01-16 12:22:14.708514: step 3422, loss = 0.69728 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:22:15.475445 ops/training.py:65 2019-01-16 12:22:15.475375: step 3423, loss = 0.70894 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:22:16.243943 ops/training.py:65 2019-01-16 12:22:16.243866: step 3424, loss = 0.71751 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:22:17.012051 ops/training.py:65 2019-01-16 12:22:17.011992: step 3425, loss = 0.69358 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:22:17.781691 ops/training.py:65 2019-01-16 12:22:17.781613: step 3426, loss = 0.67852 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:22:18.549387 ops/training.py:65 2019-01-16 12:22:18.549312: step 3427, loss = 0.70258 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:22:19.314970 ops/training.py:65 2019-01-16 12:22:19.314912: step 3428, loss = 0.71219 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:22:20.079752 ops/training.py:65 2019-01-16 12:22:20.079679: step 3429, loss = 0.70756 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:22:20.847708 ops/training.py:65 2019-01-16 12:22:20.847634: step 3430, loss = 0.69735 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:22:21.616190 ops/training.py:65 2019-01-16 12:22:21.616130: step 3431, loss = 0.67616 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:22:22.383077 ops/training.py:65 2019-01-16 12:22:22.383007: step 3432, loss = 0.69364 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:22:23.149437 ops/training.py:65 2019-01-16 12:22:23.149388: step 3433, loss = 0.68932 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:22:23.913584 ops/training.py:65 2019-01-16 12:22:23.913513: step 3434, loss = 0.68712 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:22:24.678815 ops/training.py:65 2019-01-16 12:22:24.678746: step 3435, loss = 0.68444 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:22:25.443615 ops/training.py:65 2019-01-16 12:22:25.443549: step 3436, loss = 0.68460 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:22:26.208031 ops/training.py:65 2019-01-16 12:22:26.207963: step 3437, loss = 0.69120 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:22:26.972911 ops/training.py:65 2019-01-16 12:22:26.972863: step 3438, loss = 0.70721 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:22:27.737439 ops/training.py:65 2019-01-16 12:22:27.737369: step 3439, loss = 0.68534 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:22:28.502566 ops/training.py:65 2019-01-16 12:22:28.502497: step 3440, loss = 0.71135 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:22:29.266899 ops/training.py:65 2019-01-16 12:22:29.266829: step 3441, loss = 0.70226 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:22:30.031801 ops/training.py:65 2019-01-16 12:22:30.031731: step 3442, loss = 0.68380 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:22:30.795855 ops/training.py:65 2019-01-16 12:22:30.795808: step 3443, loss = 0.68281 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:22:31.560021 ops/training.py:65 2019-01-16 12:22:31.559968: step 3444, loss = 0.67817 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:22:32.324538 ops/training.py:65 2019-01-16 12:22:32.324468: step 3445, loss = 0.69785 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:22:33.088238 ops/training.py:65 2019-01-16 12:22:33.088168: step 3446, loss = 0.68523 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:22:33.852731 ops/training.py:65 2019-01-16 12:22:33.852665: step 3447, loss = 0.69845 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:22:34.617297 ops/training.py:65 2019-01-16 12:22:34.617245: step 3448, loss = 0.71948 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:22:35.380978 ops/training.py:65 2019-01-16 12:22:35.380908: step 3449, loss = 0.69137 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:22:36.145389 ops/training.py:65 2019-01-16 12:22:36.145321: step 3450, loss = 0.70376 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:22:36.909390 ops/training.py:65 2019-01-16 12:22:36.909324: step 3451, loss = 0.69285 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:22:37.673309 ops/training.py:65 2019-01-16 12:22:37.673239: step 3452, loss = 0.70338 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:22:38.437172 ops/training.py:65 2019-01-16 12:22:38.437126: step 3453, loss = 0.68655 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:22:39.200391 ops/training.py:65 2019-01-16 12:22:39.200333: step 3454, loss = 0.66926 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:22:39.969699 ops/training.py:65 2019-01-16 12:22:39.969629: step 3455, loss = 0.67438 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:22:40.737666 ops/training.py:65 2019-01-16 12:22:40.737590: step 3456, loss = 0.67968 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:22:41.503905 ops/training.py:65 2019-01-16 12:22:41.503825: step 3457, loss = 0.69863 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:22:42.268412 ops/training.py:65 2019-01-16 12:22:42.268361: step 3458, loss = 0.68487 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:22:43.032114 ops/training.py:65 2019-01-16 12:22:43.032048: step 3459, loss = 0.68432 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:22:43.795895 ops/training.py:65 2019-01-16 12:22:43.795828: step 3460, loss = 0.68522 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:22:44.560002 ops/training.py:65 2019-01-16 12:22:44.559922: step 3461, loss = 0.70799 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:22:45.323909 ops/training.py:65 2019-01-16 12:22:45.323843: step 3462, loss = 0.71324 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:22:46.087142 ops/training.py:65 2019-01-16 12:22:46.087086: step 3463, loss = 0.69726 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:22:46.850365 ops/training.py:65 2019-01-16 12:22:46.850296: step 3464, loss = 0.69924 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:22:47.614901 ops/training.py:65 2019-01-16 12:22:47.614827: step 3465, loss = 0.69217 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:22:48.379266 ops/training.py:65 2019-01-16 12:22:48.379190: step 3466, loss = 0.67349 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:22:49.143419 ops/training.py:65 2019-01-16 12:22:49.143372: step 3467, loss = 0.67768 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:22:49.907681 ops/training.py:65 2019-01-16 12:22:49.907586: step 3468, loss = 0.70592 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:22:50.674527 ops/training.py:65 2019-01-16 12:22:50.674457: step 3469, loss = 0.70547 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:22:51.442752 ops/training.py:65 2019-01-16 12:22:51.442704: step 3470, loss = 0.70109 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:22:52.209454 ops/training.py:65 2019-01-16 12:22:52.209383: step 3471, loss = 0.71526 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:22:52.974341 ops/training.py:65 2019-01-16 12:22:52.974295: step 3472, loss = 0.70043 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:22:53.739452 ops/training.py:65 2019-01-16 12:22:53.739381: step 3473, loss = 0.68627 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:22:54.503841 ops/training.py:65 2019-01-16 12:22:54.503768: step 3474, loss = 0.66879 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:22:55.268911 ops/training.py:65 2019-01-16 12:22:55.268839: step 3475, loss = 0.71074 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:22:56.033200 ops/training.py:65 2019-01-16 12:22:56.033130: step 3476, loss = 0.68431 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:22:56.799578 ops/training.py:65 2019-01-16 12:22:56.799524: step 3477, loss = 0.68932 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:22:57.568103 ops/training.py:65 2019-01-16 12:22:57.568028: step 3478, loss = 0.70312 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:22:58.335814 ops/training.py:65 2019-01-16 12:22:58.335744: step 3479, loss = 0.69236 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:22:59.102647 ops/training.py:65 2019-01-16 12:22:59.102588: step 3480, loss = 0.69849 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:22:59.867481 ops/training.py:65 2019-01-16 12:22:59.867393: step 3481, loss = 0.70179 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:23:00.634528 ops/training.py:65 2019-01-16 12:23:00.634472: step 3482, loss = 0.70095 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:23:01.403754 ops/training.py:65 2019-01-16 12:23:01.403702: step 3483, loss = 0.69279 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:23:02.171993 ops/training.py:65 2019-01-16 12:23:02.171931: step 3484, loss = 0.68337 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:23:02.938839 ops/training.py:65 2019-01-16 12:23:02.938771: step 3485, loss = 0.71031 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:23:03.702892 ops/training.py:65 2019-01-16 12:23:03.702822: step 3486, loss = 0.69670 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:23:04.467325 ops/training.py:65 2019-01-16 12:23:04.467275: step 3487, loss = 0.69292 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:23:05.231757 ops/training.py:65 2019-01-16 12:23:05.231692: step 3488, loss = 0.68857 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:23:05.995288 ops/training.py:65 2019-01-16 12:23:05.995220: step 3489, loss = 0.68599 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:23:06.759793 ops/training.py:65 2019-01-16 12:23:06.759731: step 3490, loss = 0.70159 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:23:07.524804 ops/training.py:65 2019-01-16 12:23:07.524737: step 3491, loss = 0.68367 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:23:08.288856 ops/training.py:65 2019-01-16 12:23:08.288812: step 3492, loss = 0.70550 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:23:09.053026 ops/training.py:65 2019-01-16 12:23:09.052969: step 3493, loss = 0.67997 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:23:09.816425 ops/training.py:65 2019-01-16 12:23:09.816355: step 3494, loss = 0.69983 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:23:10.580108 ops/training.py:65 2019-01-16 12:23:10.580035: step 3495, loss = 0.69879 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:23:11.344416 ops/training.py:65 2019-01-16 12:23:11.344348: step 3496, loss = 0.68928 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:23:12.108714 ops/training.py:65 2019-01-16 12:23:12.108664: step 3497, loss = 0.69971 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:23:12.872588 ops/training.py:65 2019-01-16 12:23:12.872520: step 3498, loss = 0.70228 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:23:13.637535 ops/training.py:65 2019-01-16 12:23:13.637464: step 3499, loss = 0.68321 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:23:14.401758 ops/training.py:65 2019-01-16 12:23:14.401691: step 3500, loss = 0.69242 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:23:15.165851 ops/training.py:65 2019-01-16 12:23:15.165784: step 3501, loss = 0.67882 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:23:15.929723 ops/training.py:65 2019-01-16 12:23:15.929675: step 3502, loss = 0.68325 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:23:16.693379 ops/training.py:65 2019-01-16 12:23:16.693332: step 3503, loss = 0.70556 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:23:17.457581 ops/training.py:65 2019-01-16 12:23:17.457513: step 3504, loss = 0.69449 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:23:18.221547 ops/training.py:65 2019-01-16 12:23:18.221476: step 3505, loss = 0.69241 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:23:18.985858 ops/training.py:65 2019-01-16 12:23:18.985820: step 3506, loss = 0.69358 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:23:19.752670 ops/training.py:65 2019-01-16 12:23:19.752609: step 3507, loss = 0.70029 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:23:20.517606 ops/training.py:65 2019-01-16 12:23:20.517538: step 3508, loss = 0.68338 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:23:21.282593 ops/training.py:65 2019-01-16 12:23:21.282525: step 3509, loss = 0.70235 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:23:22.046257 ops/training.py:65 2019-01-16 12:23:22.046191: step 3510, loss = 0.70428 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:23:22.814878 ops/training.py:65 2019-01-16 12:23:22.814820: step 3511, loss = 0.68253 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:23:23.585437 ops/training.py:65 2019-01-16 12:23:23.585359: step 3512, loss = 0.68190 (41.6 examples/sec; 0.770 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:23:24.355222 ops/training.py:65 2019-01-16 12:23:24.355147: step 3513, loss = 0.68159 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:23:25.122838 ops/training.py:65 2019-01-16 12:23:25.122763: step 3514, loss = 0.68462 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:23:25.887983 ops/training.py:65 2019-01-16 12:23:25.887913: step 3515, loss = 0.69766 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:23:26.652799 ops/training.py:65 2019-01-16 12:23:26.652750: step 3516, loss = 0.71784 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:23:27.418401 ops/training.py:65 2019-01-16 12:23:27.418335: step 3517, loss = 0.69700 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:23:28.187406 ops/training.py:65 2019-01-16 12:23:28.187332: step 3518, loss = 0.69223 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:23:28.954904 ops/training.py:65 2019-01-16 12:23:28.954840: step 3519, loss = 0.69714 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:23:29.723377 ops/training.py:65 2019-01-16 12:23:29.723309: step 3520, loss = 0.69148 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:23:30.491136 ops/training.py:65 2019-01-16 12:23:30.491064: step 3521, loss = 0.70135 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:23:31.259032 ops/training.py:65 2019-01-16 12:23:31.258956: step 3522, loss = 0.68974 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:23:32.027406 ops/training.py:65 2019-01-16 12:23:32.027332: step 3523, loss = 0.69441 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:23:32.794387 ops/training.py:65 2019-01-16 12:23:32.794311: step 3524, loss = 0.68869 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:23:33.562918 ops/training.py:65 2019-01-16 12:23:33.562866: step 3525, loss = 0.69047 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:23:34.329727 ops/training.py:65 2019-01-16 12:23:34.329678: step 3526, loss = 0.70239 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:23:35.093795 ops/training.py:65 2019-01-16 12:23:35.093733: step 3527, loss = 0.71832 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:23:35.858645 ops/training.py:65 2019-01-16 12:23:35.858574: step 3528, loss = 0.70186 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:23:36.624729 ops/training.py:65 2019-01-16 12:23:36.624678: step 3529, loss = 0.68897 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:23:37.389148 ops/training.py:65 2019-01-16 12:23:37.389083: step 3530, loss = 0.67459 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:23:38.153252 ops/training.py:65 2019-01-16 12:23:38.153203: step 3531, loss = 0.69077 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:23:38.919167 ops/training.py:65 2019-01-16 12:23:38.919110: step 3532, loss = 0.68979 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:23:39.683398 ops/training.py:65 2019-01-16 12:23:39.683344: step 3533, loss = 0.70162 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:23:40.448190 ops/training.py:65 2019-01-16 12:23:40.448123: step 3534, loss = 0.70856 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:23:41.212496 ops/training.py:65 2019-01-16 12:23:41.212427: step 3535, loss = 0.69326 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:23:41.975493 ops/training.py:65 2019-01-16 12:23:41.975446: step 3536, loss = 0.69810 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:23:42.738924 ops/training.py:65 2019-01-16 12:23:42.738856: step 3537, loss = 0.70406 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:23:43.503235 ops/training.py:65 2019-01-16 12:23:43.503163: step 3538, loss = 0.68334 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:23:44.266625 ops/training.py:65 2019-01-16 12:23:44.266557: step 3539, loss = 0.69088 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:23:45.030040 ops/training.py:65 2019-01-16 12:23:45.029957: step 3540, loss = 0.69948 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:23:45.793989 ops/training.py:65 2019-01-16 12:23:45.793937: step 3541, loss = 0.69527 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:23:46.557998 ops/training.py:65 2019-01-16 12:23:46.557950: step 3542, loss = 0.70231 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:23:47.322306 ops/training.py:65 2019-01-16 12:23:47.322240: step 3543, loss = 0.70415 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:23:48.086182 ops/training.py:65 2019-01-16 12:23:48.086113: step 3544, loss = 0.68202 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:23:48.850180 ops/training.py:65 2019-01-16 12:23:48.850127: step 3545, loss = 0.69146 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:23:49.616898 ops/training.py:65 2019-01-16 12:23:49.616843: step 3546, loss = 0.69826 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:23:50.384870 ops/training.py:65 2019-01-16 12:23:50.384794: step 3547, loss = 0.70261 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:23:51.152567 ops/training.py:65 2019-01-16 12:23:51.152489: step 3548, loss = 0.69865 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:23:51.920533 ops/training.py:65 2019-01-16 12:23:51.920462: step 3549, loss = 0.69011 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:23:52.687851 ops/training.py:65 2019-01-16 12:23:52.687780: step 3550, loss = 0.70182 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:23:53.455804 ops/training.py:65 2019-01-16 12:23:53.455727: step 3551, loss = 0.68761 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:23:54.222623 ops/training.py:65 2019-01-16 12:23:54.222548: step 3552, loss = 0.68839 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:23:54.988920 ops/training.py:65 2019-01-16 12:23:54.988839: step 3553, loss = 0.69869 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:23:55.758198 ops/training.py:65 2019-01-16 12:23:55.758143: step 3554, loss = 0.69933 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:23:56.527155 ops/training.py:65 2019-01-16 12:23:56.527108: step 3555, loss = 0.69993 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:23:57.293526 ops/training.py:65 2019-01-16 12:23:57.293448: step 3556, loss = 0.69153 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:23:58.058447 ops/training.py:65 2019-01-16 12:23:58.058390: step 3557, loss = 0.68448 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:23:58.822217 ops/training.py:65 2019-01-16 12:23:58.822169: step 3558, loss = 0.68738 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:23:59.587472 ops/training.py:65 2019-01-16 12:23:59.587403: step 3559, loss = 0.70334 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:24:00.351891 ops/training.py:65 2019-01-16 12:24:00.351844: step 3560, loss = 0.68846 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:24:01.116534 ops/training.py:65 2019-01-16 12:24:01.116462: step 3561, loss = 0.68134 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:24:01.880562 ops/training.py:65 2019-01-16 12:24:01.880512: step 3562, loss = 0.68654 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:24:02.645115 ops/training.py:65 2019-01-16 12:24:02.645055: step 3563, loss = 0.68924 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:24:03.409175 ops/training.py:65 2019-01-16 12:24:03.409110: step 3564, loss = 0.69266 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:24:04.173557 ops/training.py:65 2019-01-16 12:24:04.173508: step 3565, loss = 0.69774 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:24:04.937827 ops/training.py:65 2019-01-16 12:24:04.937757: step 3566, loss = 0.69343 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:24:05.700932 ops/training.py:65 2019-01-16 12:24:05.700862: step 3567, loss = 0.69618 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:24:06.465126 ops/training.py:65 2019-01-16 12:24:06.465076: step 3568, loss = 0.71310 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:24:07.230772 ops/training.py:65 2019-01-16 12:24:07.230712: step 3569, loss = 0.70685 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:24:07.995304 ops/training.py:65 2019-01-16 12:24:07.995258: step 3570, loss = 0.69256 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:24:08.758248 ops/training.py:65 2019-01-16 12:24:08.758183: step 3571, loss = 0.68727 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:24:09.522165 ops/training.py:65 2019-01-16 12:24:09.522111: step 3572, loss = 0.68805 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:24:10.285781 ops/training.py:65 2019-01-16 12:24:10.285709: step 3573, loss = 0.68991 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:24:11.050950 ops/training.py:65 2019-01-16 12:24:11.050879: step 3574, loss = 0.70419 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:24:11.813929 ops/training.py:65 2019-01-16 12:24:11.813881: step 3575, loss = 0.68294 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:24:12.580023 ops/training.py:65 2019-01-16 12:24:12.579943: step 3576, loss = 0.67898 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:24:13.343416 ops/training.py:65 2019-01-16 12:24:13.343352: step 3577, loss = 0.69132 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:24:14.106917 ops/training.py:65 2019-01-16 12:24:14.106844: step 3578, loss = 0.70224 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:24:14.870559 ops/training.py:65 2019-01-16 12:24:14.870486: step 3579, loss = 0.70702 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:24:15.634376 ops/training.py:65 2019-01-16 12:24:15.634330: step 3580, loss = 0.69695 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:24:16.398211 ops/training.py:65 2019-01-16 12:24:16.398142: step 3581, loss = 0.69230 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:24:17.165836 ops/training.py:65 2019-01-16 12:24:17.165764: step 3582, loss = 0.70546 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:24:17.933985 ops/training.py:65 2019-01-16 12:24:17.933910: step 3583, loss = 0.71389 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:24:18.701145 ops/training.py:65 2019-01-16 12:24:18.701068: step 3584, loss = 0.69726 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:24:19.467254 ops/training.py:65 2019-01-16 12:24:19.467209: step 3585, loss = 0.68478 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:24:20.231723 ops/training.py:65 2019-01-16 12:24:20.231654: step 3586, loss = 0.69352 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:24:20.995809 ops/training.py:65 2019-01-16 12:24:20.995737: step 3587, loss = 0.68417 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:24:21.759881 ops/training.py:65 2019-01-16 12:24:21.759820: step 3588, loss = 0.69721 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:24:22.523158 ops/training.py:65 2019-01-16 12:24:22.523096: step 3589, loss = 0.69818 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:24:23.287850 ops/training.py:65 2019-01-16 12:24:23.287802: step 3590, loss = 0.66733 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:24:24.052160 ops/training.py:65 2019-01-16 12:24:24.052089: step 3591, loss = 0.69935 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:24:24.819324 ops/training.py:65 2019-01-16 12:24:24.819249: step 3592, loss = 0.70119 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:24:25.588562 ops/training.py:65 2019-01-16 12:24:25.588487: step 3593, loss = 0.70440 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:24:26.356926 ops/training.py:65 2019-01-16 12:24:26.356866: step 3594, loss = 0.69351 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:24:27.124175 ops/training.py:65 2019-01-16 12:24:27.124125: step 3595, loss = 0.68699 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:24:27.889318 ops/training.py:65 2019-01-16 12:24:27.889248: step 3596, loss = 0.70579 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:24:28.652787 ops/training.py:65 2019-01-16 12:24:28.652717: step 3597, loss = 0.67539 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:24:29.416935 ops/training.py:65 2019-01-16 12:24:29.416869: step 3598, loss = 0.67961 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:24:30.181447 ops/training.py:65 2019-01-16 12:24:30.181399: step 3599, loss = 0.70525 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:24:30.947473 ops/training.py:65 2019-01-16 12:24:30.947407: step 3600, loss = 0.70431 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:24:31.715967 ops/training.py:65 2019-01-16 12:24:31.715905: step 3601, loss = 0.66514 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:24:32.483658 ops/training.py:65 2019-01-16 12:24:32.483583: step 3602, loss = 0.69243 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:24:33.248689 ops/training.py:65 2019-01-16 12:24:33.248619: step 3603, loss = 0.69535 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:24:34.012635 ops/training.py:65 2019-01-16 12:24:34.012587: step 3604, loss = 0.72462 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:24:34.776232 ops/training.py:65 2019-01-16 12:24:34.776170: step 3605, loss = 0.68992 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:24:35.540327 ops/training.py:65 2019-01-16 12:24:35.540261: step 3606, loss = 0.69610 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:24:36.304760 ops/training.py:65 2019-01-16 12:24:36.304688: step 3607, loss = 0.69990 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:24:37.068654 ops/training.py:65 2019-01-16 12:24:37.068578: step 3608, loss = 0.71016 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:24:37.833469 ops/training.py:65 2019-01-16 12:24:37.833415: step 3609, loss = 0.67532 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:24:38.598898 ops/training.py:65 2019-01-16 12:24:38.598823: step 3610, loss = 0.66682 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:24:39.362805 ops/training.py:65 2019-01-16 12:24:39.362749: step 3611, loss = 0.71512 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:24:40.127869 ops/training.py:65 2019-01-16 12:24:40.127800: step 3612, loss = 0.69996 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:24:40.893504 ops/training.py:65 2019-01-16 12:24:40.893429: step 3613, loss = 0.71172 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:24:41.657971 ops/training.py:65 2019-01-16 12:24:41.657921: step 3614, loss = 0.68425 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:24:42.422505 ops/training.py:65 2019-01-16 12:24:42.422435: step 3615, loss = 0.71271 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:24:43.187092 ops/training.py:65 2019-01-16 12:24:43.187024: step 3616, loss = 0.69299 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:24:43.952387 ops/training.py:65 2019-01-16 12:24:43.952316: step 3617, loss = 0.68965 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:24:44.716601 ops/training.py:65 2019-01-16 12:24:44.716532: step 3618, loss = 0.69099 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:24:45.480011 ops/training.py:65 2019-01-16 12:24:45.479951: step 3619, loss = 0.68331 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:24:46.242761 ops/training.py:65 2019-01-16 12:24:46.242692: step 3620, loss = 0.69571 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:24:47.007081 ops/training.py:65 2019-01-16 12:24:47.007027: step 3621, loss = 0.71686 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.25
I0528 2019-01-16 12:24:47.771687 ops/training.py:65 2019-01-16 12:24:47.771628: step 3622, loss = 0.68744 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:24:48.537693 ops/training.py:65 2019-01-16 12:24:48.537634: step 3623, loss = 0.69913 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:24:49.301543 ops/training.py:65 2019-01-16 12:24:49.301511: step 3624, loss = 0.69176 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:24:50.064655 ops/training.py:65 2019-01-16 12:24:50.064587: step 3625, loss = 0.67857 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:24:50.827969 ops/training.py:65 2019-01-16 12:24:50.827908: step 3626, loss = 0.69915 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:24:51.591899 ops/training.py:65 2019-01-16 12:24:51.591849: step 3627, loss = 0.68573 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:24:52.355907 ops/training.py:65 2019-01-16 12:24:52.355852: step 3628, loss = 0.69143 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:24:53.119238 ops/training.py:65 2019-01-16 12:24:53.119200: step 3629, loss = 0.67950 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:24:53.882508 ops/training.py:65 2019-01-16 12:24:53.882435: step 3630, loss = 0.70396 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:24:54.645549 ops/training.py:65 2019-01-16 12:24:54.645489: step 3631, loss = 0.69380 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:24:55.410643 ops/training.py:65 2019-01-16 12:24:55.410570: step 3632, loss = 0.66378 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.8125
I0528 2019-01-16 12:24:56.175318 ops/training.py:65 2019-01-16 12:24:56.175272: step 3633, loss = 0.69865 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:24:56.937988 ops/training.py:65 2019-01-16 12:24:56.937923: step 3634, loss = 0.70648 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:24:57.701863 ops/training.py:65 2019-01-16 12:24:57.701800: step 3635, loss = 0.68012 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:24:58.469735 ops/training.py:65 2019-01-16 12:24:58.469667: step 3636, loss = 0.70591 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:24:59.237073 ops/training.py:65 2019-01-16 12:24:59.237005: step 3637, loss = 0.68878 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:25:00.005165 ops/training.py:65 2019-01-16 12:25:00.005096: step 3638, loss = 0.69413 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:25:00.773389 ops/training.py:65 2019-01-16 12:25:00.773333: step 3639, loss = 0.70684 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:25:01.541946 ops/training.py:65 2019-01-16 12:25:01.541889: step 3640, loss = 0.67991 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:25:02.310299 ops/training.py:65 2019-01-16 12:25:02.310221: step 3641, loss = 0.70810 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:25:03.076475 ops/training.py:65 2019-01-16 12:25:03.076408: step 3642, loss = 0.69897 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:25:03.841967 ops/training.py:65 2019-01-16 12:25:03.841895: step 3643, loss = 0.69535 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:25:04.608009 ops/training.py:65 2019-01-16 12:25:04.607936: step 3644, loss = 0.71628 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:25:05.375299 ops/training.py:65 2019-01-16 12:25:05.375229: step 3645, loss = 0.68869 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:25:06.142768 ops/training.py:65 2019-01-16 12:25:06.142696: step 3646, loss = 0.71310 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:25:06.911279 ops/training.py:65 2019-01-16 12:25:06.911200: step 3647, loss = 0.68633 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:25:07.680812 ops/training.py:65 2019-01-16 12:25:07.680741: step 3648, loss = 0.69822 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:25:08.449975 ops/training.py:65 2019-01-16 12:25:08.449895: step 3649, loss = 0.68639 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:25:09.216256 ops/training.py:65 2019-01-16 12:25:09.216195: step 3650, loss = 0.69358 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:25:09.983926 ops/training.py:65 2019-01-16 12:25:09.983855: step 3651, loss = 0.68674 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:25:10.752085 ops/training.py:65 2019-01-16 12:25:10.752020: step 3652, loss = 0.68884 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:25:11.519723 ops/training.py:65 2019-01-16 12:25:11.519647: step 3653, loss = 0.70461 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:25:12.285406 ops/training.py:65 2019-01-16 12:25:12.285334: step 3654, loss = 0.71508 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.25
I0528 2019-01-16 12:25:13.051495 ops/training.py:65 2019-01-16 12:25:13.051427: step 3655, loss = 0.66584 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:25:13.816221 ops/training.py:65 2019-01-16 12:25:13.816153: step 3656, loss = 0.68446 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:25:14.583014 ops/training.py:65 2019-01-16 12:25:14.582945: step 3657, loss = 0.69755 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:25:15.350050 ops/training.py:65 2019-01-16 12:25:15.349966: step 3658, loss = 0.70521 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:25:16.117208 ops/training.py:65 2019-01-16 12:25:16.117135: step 3659, loss = 0.68583 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:25:16.881307 ops/training.py:65 2019-01-16 12:25:16.881256: step 3660, loss = 0.67626 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:25:17.645980 ops/training.py:65 2019-01-16 12:25:17.645922: step 3661, loss = 0.70932 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:25:18.409461 ops/training.py:65 2019-01-16 12:25:18.409393: step 3662, loss = 0.69443 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:25:19.173684 ops/training.py:65 2019-01-16 12:25:19.173641: step 3663, loss = 0.68890 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:25:19.939264 ops/training.py:65 2019-01-16 12:25:19.939196: step 3664, loss = 0.69386 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:25:20.706154 ops/training.py:65 2019-01-16 12:25:20.706083: step 3665, loss = 0.70332 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:25:21.473598 ops/training.py:65 2019-01-16 12:25:21.473526: step 3666, loss = 0.68840 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:25:22.240371 ops/training.py:65 2019-01-16 12:25:22.240299: step 3667, loss = 0.70563 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:25:23.006494 ops/training.py:65 2019-01-16 12:25:23.006446: step 3668, loss = 0.69449 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:25:23.771756 ops/training.py:65 2019-01-16 12:25:23.771690: step 3669, loss = 0.69128 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:25:24.535915 ops/training.py:65 2019-01-16 12:25:24.535854: step 3670, loss = 0.69638 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:25:25.299618 ops/training.py:65 2019-01-16 12:25:25.299553: step 3671, loss = 0.70161 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:25:26.063877 ops/training.py:65 2019-01-16 12:25:26.063810: step 3672, loss = 0.70782 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:25:26.828985 ops/training.py:65 2019-01-16 12:25:26.828938: step 3673, loss = 0.70876 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:25:27.597704 ops/training.py:65 2019-01-16 12:25:27.597633: step 3674, loss = 0.69233 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:25:28.366785 ops/training.py:65 2019-01-16 12:25:28.366722: step 3675, loss = 0.69641 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:25:29.136426 ops/training.py:65 2019-01-16 12:25:29.136362: step 3676, loss = 0.69574 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:25:29.903398 ops/training.py:65 2019-01-16 12:25:29.903326: step 3677, loss = 0.69279 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:25:30.671983 ops/training.py:65 2019-01-16 12:25:30.671925: step 3678, loss = 0.70101 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:25:31.439795 ops/training.py:65 2019-01-16 12:25:31.439721: step 3679, loss = 0.69908 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:25:32.206992 ops/training.py:65 2019-01-16 12:25:32.206924: step 3680, loss = 0.69091 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:25:32.971466 ops/training.py:65 2019-01-16 12:25:32.971397: step 3681, loss = 0.68166 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:25:33.735225 ops/training.py:65 2019-01-16 12:25:33.735158: step 3682, loss = 0.67554 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:25:34.499866 ops/training.py:65 2019-01-16 12:25:34.499816: step 3683, loss = 0.69661 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:25:35.264435 ops/training.py:65 2019-01-16 12:25:35.264368: step 3684, loss = 0.71120 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:25:36.028017 ops/training.py:65 2019-01-16 12:25:36.027953: step 3685, loss = 0.67906 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:25:36.792107 ops/training.py:65 2019-01-16 12:25:36.792042: step 3686, loss = 0.69241 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:25:37.555637 ops/training.py:65 2019-01-16 12:25:37.555588: step 3687, loss = 0.68611 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:25:38.320071 ops/training.py:65 2019-01-16 12:25:38.320002: step 3688, loss = 0.70134 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:25:39.084132 ops/training.py:65 2019-01-16 12:25:39.084074: step 3689, loss = 0.68538 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:25:39.848396 ops/training.py:65 2019-01-16 12:25:39.848328: step 3690, loss = 0.70963 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:25:40.616307 ops/training.py:65 2019-01-16 12:25:40.616252: step 3691, loss = 0.68842 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:25:41.384395 ops/training.py:65 2019-01-16 12:25:41.384340: step 3692, loss = 0.69874 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:25:42.151085 ops/training.py:65 2019-01-16 12:25:42.151013: step 3693, loss = 0.69488 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:25:42.917335 ops/training.py:65 2019-01-16 12:25:42.917241: step 3694, loss = 0.70236 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:25:43.685199 ops/training.py:65 2019-01-16 12:25:43.685131: step 3695, loss = 0.69558 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:25:44.453082 ops/training.py:65 2019-01-16 12:25:44.453020: step 3696, loss = 0.70850 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:25:45.219093 ops/training.py:65 2019-01-16 12:25:45.219022: step 3697, loss = 0.68708 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:25:45.984824 ops/training.py:65 2019-01-16 12:25:45.984754: step 3698, loss = 0.70614 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:25:46.748769 ops/training.py:65 2019-01-16 12:25:46.748719: step 3699, loss = 0.70048 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:25:47.513517 ops/training.py:65 2019-01-16 12:25:47.513454: step 3700, loss = 0.69695 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:25:48.276910 ops/training.py:65 2019-01-16 12:25:48.276842: step 3701, loss = 0.68305 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:25:49.040138 ops/training.py:65 2019-01-16 12:25:49.040094: step 3702, loss = 0.68295 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:25:49.802985 ops/training.py:65 2019-01-16 12:25:49.802916: step 3703, loss = 0.69949 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:25:50.566632 ops/training.py:65 2019-01-16 12:25:50.566564: step 3704, loss = 0.70123 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:25:51.331709 ops/training.py:65 2019-01-16 12:25:51.331641: step 3705, loss = 0.69044 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:25:52.100023 ops/training.py:65 2019-01-16 12:25:52.099954: step 3706, loss = 0.70327 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:25:52.866940 ops/training.py:65 2019-01-16 12:25:52.866908: step 3707, loss = 0.69336 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:25:53.635231 ops/training.py:65 2019-01-16 12:25:53.635168: step 3708, loss = 0.70808 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:25:54.402895 ops/training.py:65 2019-01-16 12:25:54.402815: step 3709, loss = 0.67625 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:25:55.171665 ops/training.py:65 2019-01-16 12:25:55.171603: step 3710, loss = 0.70961 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:25:55.940912 ops/training.py:65 2019-01-16 12:25:55.940843: step 3711, loss = 0.68438 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:25:56.709856 ops/training.py:65 2019-01-16 12:25:56.709779: step 3712, loss = 0.67833 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:25:57.475586 ops/training.py:65 2019-01-16 12:25:57.475518: step 3713, loss = 0.68458 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:25:58.239521 ops/training.py:65 2019-01-16 12:25:58.239453: step 3714, loss = 0.69724 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:25:59.002964 ops/training.py:65 2019-01-16 12:25:59.002907: step 3715, loss = 0.68196 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:25:59.765931 ops/training.py:65 2019-01-16 12:25:59.765867: step 3716, loss = 0.68739 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:26:00.529376 ops/training.py:65 2019-01-16 12:26:00.529327: step 3717, loss = 0.69697 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:26:01.293357 ops/training.py:65 2019-01-16 12:26:01.293289: step 3718, loss = 0.69240 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:26:02.057193 ops/training.py:65 2019-01-16 12:26:02.057132: step 3719, loss = 0.69264 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:26:02.820688 ops/training.py:65 2019-01-16 12:26:02.820635: step 3720, loss = 0.68672 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:26:03.584796 ops/training.py:65 2019-01-16 12:26:03.584726: step 3721, loss = 0.69573 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:26:04.350251 ops/training.py:65 2019-01-16 12:26:04.350181: step 3722, loss = 0.70367 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:26:05.114273 ops/training.py:65 2019-01-16 12:26:05.114223: step 3723, loss = 0.69413 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:26:05.878399 ops/training.py:65 2019-01-16 12:26:05.878320: step 3724, loss = 0.71384 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:26:06.642350 ops/training.py:65 2019-01-16 12:26:06.642287: step 3725, loss = 0.70210 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:26:07.411451 ops/training.py:65 2019-01-16 12:26:07.411377: step 3726, loss = 0.69624 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:26:08.181374 ops/training.py:65 2019-01-16 12:26:08.181302: step 3727, loss = 0.69688 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:26:08.948252 ops/training.py:65 2019-01-16 12:26:08.948181: step 3728, loss = 0.69677 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:26:09.713261 ops/training.py:65 2019-01-16 12:26:09.713208: step 3729, loss = 0.69067 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:26:10.481442 ops/training.py:65 2019-01-16 12:26:10.481371: step 3730, loss = 0.69779 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:26:11.248166 ops/training.py:65 2019-01-16 12:26:11.248093: step 3731, loss = 0.70213 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:26:12.013004 ops/training.py:65 2019-01-16 12:26:12.012928: step 3732, loss = 0.71383 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:26:12.780573 ops/training.py:65 2019-01-16 12:26:12.780496: step 3733, loss = 0.70612 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:26:13.551460 ops/training.py:65 2019-01-16 12:26:13.551385: step 3734, loss = 0.70096 (41.6 examples/sec; 0.770 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:26:14.319705 ops/training.py:65 2019-01-16 12:26:14.319631: step 3735, loss = 0.69016 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:26:15.085874 ops/training.py:65 2019-01-16 12:26:15.085803: step 3736, loss = 0.69290 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:26:15.851718 ops/training.py:65 2019-01-16 12:26:15.851666: step 3737, loss = 0.68860 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:26:16.616418 ops/training.py:65 2019-01-16 12:26:16.616375: step 3738, loss = 0.71095 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:26:17.380213 ops/training.py:65 2019-01-16 12:26:17.380160: step 3739, loss = 0.68641 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:26:18.144019 ops/training.py:65 2019-01-16 12:26:18.143967: step 3740, loss = 0.70570 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:26:18.907532 ops/training.py:65 2019-01-16 12:26:18.907484: step 3741, loss = 0.69712 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:26:19.676779 ops/training.py:65 2019-01-16 12:26:19.676723: step 3742, loss = 0.70854 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:26:20.445106 ops/training.py:65 2019-01-16 12:26:20.445033: step 3743, loss = 0.69927 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:26:21.213770 ops/training.py:65 2019-01-16 12:26:21.213705: step 3744, loss = 0.69655 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:26:21.982231 ops/training.py:65 2019-01-16 12:26:21.982184: step 3745, loss = 0.69410 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:26:22.750344 ops/training.py:65 2019-01-16 12:26:22.750272: step 3746, loss = 0.71049 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:26:23.519278 ops/training.py:65 2019-01-16 12:26:23.519207: step 3747, loss = 0.67111 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:26:24.288015 ops/training.py:65 2019-01-16 12:26:24.287940: step 3748, loss = 0.68503 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:26:25.054374 ops/training.py:65 2019-01-16 12:26:25.054316: step 3749, loss = 0.69728 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:26:25.818735 ops/training.py:65 2019-01-16 12:26:25.818684: step 3750, loss = 0.67778 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:26:26.583398 ops/training.py:65 2019-01-16 12:26:26.583343: step 3751, loss = 0.68988 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:26:27.350869 ops/training.py:65 2019-01-16 12:26:27.350808: step 3752, loss = 0.67618 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:26:28.119326 ops/training.py:65 2019-01-16 12:26:28.119253: step 3753, loss = 0.68834 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:26:28.887054 ops/training.py:65 2019-01-16 12:26:28.886993: step 3754, loss = 0.69432 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:26:29.652230 ops/training.py:65 2019-01-16 12:26:29.652179: step 3755, loss = 0.70126 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:26:30.415491 ops/training.py:65 2019-01-16 12:26:30.415437: step 3756, loss = 0.70639 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:26:31.180386 ops/training.py:65 2019-01-16 12:26:31.180333: step 3757, loss = 0.69933 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:26:31.948413 ops/training.py:65 2019-01-16 12:26:31.948352: step 3758, loss = 0.68238 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:26:32.717750 ops/training.py:65 2019-01-16 12:26:32.717694: step 3759, loss = 0.69301 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:26:33.485150 ops/training.py:65 2019-01-16 12:26:33.485077: step 3760, loss = 0.68570 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:26:34.252808 ops/training.py:65 2019-01-16 12:26:34.252739: step 3761, loss = 0.70167 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:26:35.017191 ops/training.py:65 2019-01-16 12:26:35.017138: step 3762, loss = 0.68395 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:26:35.782821 ops/training.py:65 2019-01-16 12:26:35.782766: step 3763, loss = 0.70358 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:26:36.546954 ops/training.py:65 2019-01-16 12:26:36.546897: step 3764, loss = 0.70276 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:26:37.313900 ops/training.py:65 2019-01-16 12:26:37.313843: step 3765, loss = 0.70010 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:26:38.082343 ops/training.py:65 2019-01-16 12:26:38.082272: step 3766, loss = 0.69573 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:26:38.849745 ops/training.py:65 2019-01-16 12:26:38.849686: step 3767, loss = 0.69176 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:26:39.614503 ops/training.py:65 2019-01-16 12:26:39.614449: step 3768, loss = 0.68746 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:26:40.380632 ops/training.py:65 2019-01-16 12:26:40.380578: step 3769, loss = 0.69159 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:26:41.148837 ops/training.py:65 2019-01-16 12:26:41.148771: step 3770, loss = 0.70750 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:26:41.916121 ops/training.py:65 2019-01-16 12:26:41.916047: step 3771, loss = 0.70485 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:26:42.681456 ops/training.py:65 2019-01-16 12:26:42.681385: step 3772, loss = 0.69808 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:26:43.446088 ops/training.py:65 2019-01-16 12:26:43.446027: step 3773, loss = 0.70846 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:26:44.209627 ops/training.py:65 2019-01-16 12:26:44.209567: step 3774, loss = 0.70915 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:26:44.973634 ops/training.py:65 2019-01-16 12:26:44.973576: step 3775, loss = 0.70211 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:26:45.738282 ops/training.py:65 2019-01-16 12:26:45.738227: step 3776, loss = 0.69624 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:26:46.502395 ops/training.py:65 2019-01-16 12:26:46.502344: step 3777, loss = 0.69133 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:26:47.265579 ops/training.py:65 2019-01-16 12:26:47.265521: step 3778, loss = 0.70758 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:26:48.029763 ops/training.py:65 2019-01-16 12:26:48.029691: step 3779, loss = 0.70442 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:26:48.799274 ops/training.py:65 2019-01-16 12:26:48.799216: step 3780, loss = 0.69773 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:26:49.568679 ops/training.py:65 2019-01-16 12:26:49.568604: step 3781, loss = 0.67903 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.75
I0528 2019-01-16 12:26:50.336048 ops/training.py:65 2019-01-16 12:26:50.335975: step 3782, loss = 0.68833 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:26:51.102258 ops/training.py:65 2019-01-16 12:26:51.102208: step 3783, loss = 0.69317 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:26:51.866487 ops/training.py:65 2019-01-16 12:26:51.866441: step 3784, loss = 0.69729 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:26:52.634125 ops/training.py:65 2019-01-16 12:26:52.634073: step 3785, loss = 0.70402 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:26:53.401742 ops/training.py:65 2019-01-16 12:26:53.401669: step 3786, loss = 0.68715 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:26:54.168731 ops/training.py:65 2019-01-16 12:26:54.168643: step 3787, loss = 0.67785 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:26:54.934270 ops/training.py:65 2019-01-16 12:26:54.934217: step 3788, loss = 0.69060 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:26:55.701851 ops/training.py:65 2019-01-16 12:26:55.701798: step 3789, loss = 0.70030 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:26:56.469165 ops/training.py:65 2019-01-16 12:26:56.469090: step 3790, loss = 0.70205 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:26:57.235454 ops/training.py:65 2019-01-16 12:26:57.235389: step 3791, loss = 0.67659 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:26:57.999286 ops/training.py:65 2019-01-16 12:26:57.999228: step 3792, loss = 0.70664 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:26:58.763656 ops/training.py:65 2019-01-16 12:26:58.763604: step 3793, loss = 0.69456 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:26:59.531911 ops/training.py:65 2019-01-16 12:26:59.531861: step 3794, loss = 0.68590 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:27:00.299798 ops/training.py:65 2019-01-16 12:27:00.299719: step 3795, loss = 0.69908 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:27:01.067123 ops/training.py:65 2019-01-16 12:27:01.067043: step 3796, loss = 0.70967 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:27:01.836461 ops/training.py:65 2019-01-16 12:27:01.836401: step 3797, loss = 0.67872 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 12:27:02.603623 ops/training.py:65 2019-01-16 12:27:02.603553: step 3798, loss = 0.70284 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:27:03.370323 ops/training.py:65 2019-01-16 12:27:03.370269: step 3799, loss = 0.68803 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:27:04.134106 ops/training.py:65 2019-01-16 12:27:04.134054: step 3800, loss = 0.68825 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:27:04.898129 ops/training.py:65 2019-01-16 12:27:04.898075: step 3801, loss = 0.68890 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:27:05.663158 ops/training.py:65 2019-01-16 12:27:05.663100: step 3802, loss = 0.69048 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:27:06.427217 ops/training.py:65 2019-01-16 12:27:06.427165: step 3803, loss = 0.69497 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:27:07.191838 ops/training.py:65 2019-01-16 12:27:07.191788: step 3804, loss = 0.69121 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:27:07.957228 ops/training.py:65 2019-01-16 12:27:07.957174: step 3805, loss = 0.69935 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:27:08.721791 ops/training.py:65 2019-01-16 12:27:08.721737: step 3806, loss = 0.69559 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:27:09.486169 ops/training.py:65 2019-01-16 12:27:09.486112: step 3807, loss = 0.68085 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:27:10.250640 ops/training.py:65 2019-01-16 12:27:10.250586: step 3808, loss = 0.70100 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:27:11.015625 ops/training.py:65 2019-01-16 12:27:11.015550: step 3809, loss = 0.69749 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:27:11.780593 ops/training.py:65 2019-01-16 12:27:11.780537: step 3810, loss = 0.70690 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:27:12.545181 ops/training.py:65 2019-01-16 12:27:12.545126: step 3811, loss = 0.68556 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:27:13.310406 ops/training.py:65 2019-01-16 12:27:13.310353: step 3812, loss = 0.68712 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:27:14.074274 ops/training.py:65 2019-01-16 12:27:14.074222: step 3813, loss = 0.69648 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:27:14.838266 ops/training.py:65 2019-01-16 12:27:14.838213: step 3814, loss = 0.67858 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:27:15.602583 ops/training.py:65 2019-01-16 12:27:15.602531: step 3815, loss = 0.68211 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:27:16.366689 ops/training.py:65 2019-01-16 12:27:16.366630: step 3816, loss = 0.69252 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:27:17.132044 ops/training.py:65 2019-01-16 12:27:17.131994: step 3817, loss = 0.68973 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:27:17.896581 ops/training.py:65 2019-01-16 12:27:17.896528: step 3818, loss = 0.70136 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:27:18.664547 ops/training.py:65 2019-01-16 12:27:18.664487: step 3819, loss = 0.68290 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:27:19.433846 ops/training.py:65 2019-01-16 12:27:19.433780: step 3820, loss = 0.69092 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:27:20.201818 ops/training.py:65 2019-01-16 12:27:20.201744: step 3821, loss = 0.68460 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:27:20.968292 ops/training.py:65 2019-01-16 12:27:20.968220: step 3822, loss = 0.69730 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:27:21.733971 ops/training.py:65 2019-01-16 12:27:21.733927: step 3823, loss = 0.68071 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:27:22.499625 ops/training.py:65 2019-01-16 12:27:22.499566: step 3824, loss = 0.69014 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:27:23.267078 ops/training.py:65 2019-01-16 12:27:23.267008: step 3825, loss = 0.69519 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:27:24.035562 ops/training.py:65 2019-01-16 12:27:24.035469: step 3826, loss = 0.69404 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:27:24.802988 ops/training.py:65 2019-01-16 12:27:24.802934: step 3827, loss = 0.69879 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:27:25.569657 ops/training.py:65 2019-01-16 12:27:25.569602: step 3828, loss = 0.68491 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:27:26.337614 ops/training.py:65 2019-01-16 12:27:26.337542: step 3829, loss = 0.70059 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:27:27.105030 ops/training.py:65 2019-01-16 12:27:27.104980: step 3830, loss = 0.68071 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:27:27.870534 ops/training.py:65 2019-01-16 12:27:27.870478: step 3831, loss = 0.68603 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:27:28.634544 ops/training.py:65 2019-01-16 12:27:28.634490: step 3832, loss = 0.69077 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:27:29.398214 ops/training.py:65 2019-01-16 12:27:29.398158: step 3833, loss = 0.68866 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:27:30.162182 ops/training.py:65 2019-01-16 12:27:30.162122: step 3834, loss = 0.70348 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:27:30.926235 ops/training.py:65 2019-01-16 12:27:30.926180: step 3835, loss = 0.70418 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:27:31.690357 ops/training.py:65 2019-01-16 12:27:31.690315: step 3836, loss = 0.69531 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:27:32.454417 ops/training.py:65 2019-01-16 12:27:32.454363: step 3837, loss = 0.68860 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:27:33.218131 ops/training.py:65 2019-01-16 12:27:33.218077: step 3838, loss = 0.70109 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 12:27:33.981828 ops/training.py:65 2019-01-16 12:27:33.981776: step 3839, loss = 0.69717 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:27:34.745304 ops/training.py:65 2019-01-16 12:27:34.745251: step 3840, loss = 0.69782 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:27:35.510070 ops/training.py:65 2019-01-16 12:27:35.510016: step 3841, loss = 0.69257 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:27:36.274556 ops/training.py:65 2019-01-16 12:27:36.274502: step 3842, loss = 0.69247 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:27:37.042031 ops/training.py:65 2019-01-16 12:27:37.041988: step 3843, loss = 0.69846 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:27:37.810877 ops/training.py:65 2019-01-16 12:27:37.810800: step 3844, loss = 0.69218 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:27:38.579833 ops/training.py:65 2019-01-16 12:27:38.579756: step 3845, loss = 0.68514 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:27:39.346549 ops/training.py:65 2019-01-16 12:27:39.346494: step 3846, loss = 0.70277 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:27:40.111599 ops/training.py:65 2019-01-16 12:27:40.111541: step 3847, loss = 0.69056 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:27:40.877888 ops/training.py:65 2019-01-16 12:27:40.877809: step 3848, loss = 0.69215 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:27:41.647086 ops/training.py:65 2019-01-16 12:27:41.647025: step 3849, loss = 0.69603 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:27:42.417634 ops/training.py:65 2019-01-16 12:27:42.417557: step 3850, loss = 0.69312 (41.6 examples/sec; 0.770 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:27:43.182799 ops/training.py:65 2019-01-16 12:27:43.182702: step 3851, loss = 0.69315 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:27:43.947962 ops/training.py:65 2019-01-16 12:27:43.947903: step 3852, loss = 0.70925 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:27:44.712644 ops/training.py:65 2019-01-16 12:27:44.712590: step 3853, loss = 0.70113 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:27:45.476159 ops/training.py:65 2019-01-16 12:27:45.476105: step 3854, loss = 0.70190 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:27:46.240221 ops/training.py:65 2019-01-16 12:27:46.240164: step 3855, loss = 0.69026 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:27:47.004090 ops/training.py:65 2019-01-16 12:27:47.004044: step 3856, loss = 0.70179 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:27:47.769474 ops/training.py:65 2019-01-16 12:27:47.769418: step 3857, loss = 0.69382 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:27:48.534022 ops/training.py:65 2019-01-16 12:27:48.533964: step 3858, loss = 0.68749 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:27:49.298535 ops/training.py:65 2019-01-16 12:27:49.298485: step 3859, loss = 0.69158 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:27:50.063054 ops/training.py:65 2019-01-16 12:27:50.062998: step 3860, loss = 0.70206 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:27:50.827054 ops/training.py:65 2019-01-16 12:27:50.827002: step 3861, loss = 0.69435 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:27:51.591974 ops/training.py:65 2019-01-16 12:27:51.591917: step 3862, loss = 0.70657 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:27:52.354756 ops/training.py:65 2019-01-16 12:27:52.354699: step 3863, loss = 0.68817 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:27:53.121120 ops/training.py:65 2019-01-16 12:27:53.121059: step 3864, loss = 0.69582 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:27:53.889169 ops/training.py:65 2019-01-16 12:27:53.889101: step 3865, loss = 0.69076 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:27:54.659507 ops/training.py:65 2019-01-16 12:27:54.659437: step 3866, loss = 0.69102 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:27:55.427626 ops/training.py:65 2019-01-16 12:27:55.427580: step 3867, loss = 0.69179 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:27:56.195937 ops/training.py:65 2019-01-16 12:27:56.195887: step 3868, loss = 0.69077 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:27:56.961652 ops/training.py:65 2019-01-16 12:27:56.961579: step 3869, loss = 0.71032 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:27:57.727303 ops/training.py:65 2019-01-16 12:27:57.727266: step 3870, loss = 0.67860 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:27:58.494732 ops/training.py:65 2019-01-16 12:27:58.494695: step 3871, loss = 0.70738 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:27:59.260859 ops/training.py:65 2019-01-16 12:27:59.260824: step 3872, loss = 0.68599 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:28:00.028809 ops/training.py:65 2019-01-16 12:28:00.028775: step 3873, loss = 0.69214 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:28:00.796379 ops/training.py:65 2019-01-16 12:28:00.796344: step 3874, loss = 0.67599 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:28:01.565672 ops/training.py:65 2019-01-16 12:28:01.565637: step 3875, loss = 0.68444 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:28:02.330607 ops/training.py:65 2019-01-16 12:28:02.330569: step 3876, loss = 0.70820 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:28:03.095134 ops/training.py:65 2019-01-16 12:28:03.095096: step 3877, loss = 0.69044 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:28:03.861203 ops/training.py:65 2019-01-16 12:28:03.861169: step 3878, loss = 0.68277 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:28:04.629050 ops/training.py:65 2019-01-16 12:28:04.629017: step 3879, loss = 0.68638 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:28:05.397619 ops/training.py:65 2019-01-16 12:28:05.397585: step 3880, loss = 0.69960 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:28:06.165483 ops/training.py:65 2019-01-16 12:28:06.165448: step 3881, loss = 0.69086 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:28:06.933197 ops/training.py:65 2019-01-16 12:28:06.933165: step 3882, loss = 0.69697 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:28:07.700369 ops/training.py:65 2019-01-16 12:28:07.700333: step 3883, loss = 0.69637 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:28:08.466936 ops/training.py:65 2019-01-16 12:28:08.466899: step 3884, loss = 0.69770 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:28:09.235180 ops/training.py:65 2019-01-16 12:28:09.235143: step 3885, loss = 0.69128 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:28:10.001271 ops/training.py:65 2019-01-16 12:28:10.001230: step 3886, loss = 0.70933 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:28:10.767443 ops/training.py:65 2019-01-16 12:28:10.767410: step 3887, loss = 0.70196 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:28:11.532371 ops/training.py:65 2019-01-16 12:28:11.532337: step 3888, loss = 0.69744 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:28:12.297304 ops/training.py:65 2019-01-16 12:28:12.297267: step 3889, loss = 0.69351 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:28:13.061935 ops/training.py:65 2019-01-16 12:28:13.061873: step 3890, loss = 0.69308 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:28:13.830644 ops/training.py:65 2019-01-16 12:28:13.830602: step 3891, loss = 0.69656 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:28:14.598094 ops/training.py:65 2019-01-16 12:28:14.598056: step 3892, loss = 0.68426 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:28:15.364383 ops/training.py:65 2019-01-16 12:28:15.364345: step 3893, loss = 0.68528 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:28:16.129504 ops/training.py:65 2019-01-16 12:28:16.129426: step 3894, loss = 0.69918 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:28:16.898196 ops/training.py:65 2019-01-16 12:28:16.898147: step 3895, loss = 0.69089 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:28:17.664801 ops/training.py:65 2019-01-16 12:28:17.664761: step 3896, loss = 0.70002 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:28:18.430110 ops/training.py:65 2019-01-16 12:28:18.430054: step 3897, loss = 0.68943 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:28:19.195008 ops/training.py:65 2019-01-16 12:28:19.194955: step 3898, loss = 0.69575 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:28:19.960498 ops/training.py:65 2019-01-16 12:28:19.960460: step 3899, loss = 0.68685 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:28:20.724199 ops/training.py:65 2019-01-16 12:28:20.724136: step 3900, loss = 0.69036 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:28:21.489370 ops/training.py:65 2019-01-16 12:28:21.489325: step 3901, loss = 0.70897 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 12:28:22.254503 ops/training.py:65 2019-01-16 12:28:22.254457: step 3902, loss = 0.70313 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:28:23.021018 ops/training.py:65 2019-01-16 12:28:23.020979: step 3903, loss = 0.68898 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:28:23.788442 ops/training.py:65 2019-01-16 12:28:23.788388: step 3904, loss = 0.70021 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:28:24.556182 ops/training.py:65 2019-01-16 12:28:24.556126: step 3905, loss = 0.68698 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:28:25.324133 ops/training.py:65 2019-01-16 12:28:25.324074: step 3906, loss = 0.69949 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:28:26.092173 ops/training.py:65 2019-01-16 12:28:26.092104: step 3907, loss = 0.69249 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:28:26.860238 ops/training.py:65 2019-01-16 12:28:26.860163: step 3908, loss = 0.69343 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:28:27.628276 ops/training.py:65 2019-01-16 12:28:27.628224: step 3909, loss = 0.70337 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:28:28.392920 ops/training.py:65 2019-01-16 12:28:28.392868: step 3910, loss = 0.69600 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:28:29.157594 ops/training.py:65 2019-01-16 12:28:29.157546: step 3911, loss = 0.69528 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:28:29.922692 ops/training.py:65 2019-01-16 12:28:29.922640: step 3912, loss = 0.69904 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:28:30.687283 ops/training.py:65 2019-01-16 12:28:30.687230: step 3913, loss = 0.69570 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:28:31.451616 ops/training.py:65 2019-01-16 12:28:31.451558: step 3914, loss = 0.69755 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:28:32.216414 ops/training.py:65 2019-01-16 12:28:32.216365: step 3915, loss = 0.69614 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:28:32.981166 ops/training.py:65 2019-01-16 12:28:32.981110: step 3916, loss = 0.69553 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:28:33.745239 ops/training.py:65 2019-01-16 12:28:33.745187: step 3917, loss = 0.69533 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:28:34.512355 ops/training.py:65 2019-01-16 12:28:34.512289: step 3918, loss = 0.69094 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:28:35.280135 ops/training.py:65 2019-01-16 12:28:35.280070: step 3919, loss = 0.68686 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:28:36.048094 ops/training.py:65 2019-01-16 12:28:36.048016: step 3920, loss = 0.70151 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:28:36.812614 ops/training.py:65 2019-01-16 12:28:36.812566: step 3921, loss = 0.69451 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:28:37.577014 ops/training.py:65 2019-01-16 12:28:37.576965: step 3922, loss = 0.69273 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:28:38.341393 ops/training.py:65 2019-01-16 12:28:38.341339: step 3923, loss = 0.69723 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:28:39.105197 ops/training.py:65 2019-01-16 12:28:39.105145: step 3924, loss = 0.69277 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:28:39.869815 ops/training.py:65 2019-01-16 12:28:39.869761: step 3925, loss = 0.69453 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:28:40.633778 ops/training.py:65 2019-01-16 12:28:40.633723: step 3926, loss = 0.69153 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:28:41.397905 ops/training.py:65 2019-01-16 12:28:41.397848: step 3927, loss = 0.69729 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:28:42.162141 ops/training.py:65 2019-01-16 12:28:42.162083: step 3928, loss = 0.69606 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:28:42.928817 ops/training.py:65 2019-01-16 12:28:42.928753: step 3929, loss = 0.68235 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:28:43.696436 ops/training.py:65 2019-01-16 12:28:43.696368: step 3930, loss = 0.70436 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:28:44.465303 ops/training.py:65 2019-01-16 12:28:44.465235: step 3931, loss = 0.68386 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:28:45.233337 ops/training.py:65 2019-01-16 12:28:45.233264: step 3932, loss = 0.69948 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:28:45.997985 ops/training.py:65 2019-01-16 12:28:45.997915: step 3933, loss = 0.68529 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:28:46.762986 ops/training.py:65 2019-01-16 12:28:46.762942: step 3934, loss = 0.69266 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:28:47.530132 ops/training.py:65 2019-01-16 12:28:47.530070: step 3935, loss = 0.70104 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:28:48.298039 ops/training.py:65 2019-01-16 12:28:48.297971: step 3936, loss = 0.69103 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:28:49.063583 ops/training.py:65 2019-01-16 12:28:49.063521: step 3937, loss = 0.69505 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:28:49.828872 ops/training.py:65 2019-01-16 12:28:49.828816: step 3938, loss = 0.70044 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:28:50.592326 ops/training.py:65 2019-01-16 12:28:50.592272: step 3939, loss = 0.70291 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:28:51.360208 ops/training.py:65 2019-01-16 12:28:51.360157: step 3940, loss = 0.68620 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:28:52.129401 ops/training.py:65 2019-01-16 12:28:52.129334: step 3941, loss = 0.69214 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:28:52.899839 ops/training.py:65 2019-01-16 12:28:52.899763: step 3942, loss = 0.69140 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:28:53.667956 ops/training.py:65 2019-01-16 12:28:53.667880: step 3943, loss = 0.69176 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:28:54.434257 ops/training.py:65 2019-01-16 12:28:54.434183: step 3944, loss = 0.68963 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:28:55.202016 ops/training.py:65 2019-01-16 12:28:55.201956: step 3945, loss = 0.68671 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:28:55.971409 ops/training.py:65 2019-01-16 12:28:55.971336: step 3946, loss = 0.69059 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:28:56.738860 ops/training.py:65 2019-01-16 12:28:56.738786: step 3947, loss = 0.68295 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:28:57.504939 ops/training.py:65 2019-01-16 12:28:57.504869: step 3948, loss = 0.68896 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:28:58.269855 ops/training.py:65 2019-01-16 12:28:58.269783: step 3949, loss = 0.69386 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:28:59.034871 ops/training.py:65 2019-01-16 12:28:59.034822: step 3950, loss = 0.68989 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:28:59.801886 ops/training.py:65 2019-01-16 12:28:59.801825: step 3951, loss = 0.69471 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:29:00.569222 ops/training.py:65 2019-01-16 12:29:00.569148: step 3952, loss = 0.69160 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:29:01.337191 ops/training.py:65 2019-01-16 12:29:01.337122: step 3953, loss = 0.69778 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:29:02.105094 ops/training.py:65 2019-01-16 12:29:02.105028: step 3954, loss = 0.70645 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:29:02.872080 ops/training.py:65 2019-01-16 12:29:02.871998: step 3955, loss = 0.69706 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:29:03.636970 ops/training.py:65 2019-01-16 12:29:03.636912: step 3956, loss = 0.68612 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:29:04.401804 ops/training.py:65 2019-01-16 12:29:04.401747: step 3957, loss = 0.69520 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:29:05.165996 ops/training.py:65 2019-01-16 12:29:05.165945: step 3958, loss = 0.69467 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:29:05.930443 ops/training.py:65 2019-01-16 12:29:05.930386: step 3959, loss = 0.68737 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:29:06.694204 ops/training.py:65 2019-01-16 12:29:06.694150: step 3960, loss = 0.69653 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:29:07.458139 ops/training.py:65 2019-01-16 12:29:07.458084: step 3961, loss = 0.69133 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:29:08.221663 ops/training.py:65 2019-01-16 12:29:08.221611: step 3962, loss = 0.69337 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:29:08.989360 ops/training.py:65 2019-01-16 12:29:08.989307: step 3963, loss = 0.69354 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:29:09.757615 ops/training.py:65 2019-01-16 12:29:09.757555: step 3964, loss = 0.69276 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:29:10.524049 ops/training.py:65 2019-01-16 12:29:10.523977: step 3965, loss = 0.69092 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:29:11.288374 ops/training.py:65 2019-01-16 12:29:11.288306: step 3966, loss = 0.69438 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:29:12.052362 ops/training.py:65 2019-01-16 12:29:12.052302: step 3967, loss = 0.68919 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:29:12.815224 ops/training.py:65 2019-01-16 12:29:12.815169: step 3968, loss = 0.68833 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:29:13.578525 ops/training.py:65 2019-01-16 12:29:13.578474: step 3969, loss = 0.69588 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:29:14.343533 ops/training.py:65 2019-01-16 12:29:14.343495: step 3970, loss = 0.68993 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:29:15.107779 ops/training.py:65 2019-01-16 12:29:15.107746: step 3971, loss = 0.70176 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:29:15.874690 ops/training.py:65 2019-01-16 12:29:15.874657: step 3972, loss = 0.68532 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:29:16.642637 ops/training.py:65 2019-01-16 12:29:16.642570: step 3973, loss = 0.68710 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:29:17.410584 ops/training.py:65 2019-01-16 12:29:17.410512: step 3974, loss = 0.68885 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:29:18.175493 ops/training.py:65 2019-01-16 12:29:18.175422: step 3975, loss = 0.68938 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:29:18.939868 ops/training.py:65 2019-01-16 12:29:18.939823: step 3976, loss = 0.68827 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:29:19.703949 ops/training.py:65 2019-01-16 12:29:19.703895: step 3977, loss = 0.69042 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:29:20.468359 ops/training.py:65 2019-01-16 12:29:20.468305: step 3978, loss = 0.70333 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:29:21.232058 ops/training.py:65 2019-01-16 12:29:21.231999: step 3979, loss = 0.69883 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:29:21.995986 ops/training.py:65 2019-01-16 12:29:21.995943: step 3980, loss = 0.69063 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:29:22.760400 ops/training.py:65 2019-01-16 12:29:22.760348: step 3981, loss = 0.68670 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:29:23.524678 ops/training.py:65 2019-01-16 12:29:23.524621: step 3982, loss = 0.69074 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:29:24.288895 ops/training.py:65 2019-01-16 12:29:24.288844: step 3983, loss = 0.69445 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:29:25.053257 ops/training.py:65 2019-01-16 12:29:25.053201: step 3984, loss = 0.68865 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:29:25.817198 ops/training.py:65 2019-01-16 12:29:25.817141: step 3985, loss = 0.69308 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:29:26.581549 ops/training.py:65 2019-01-16 12:29:26.581495: step 3986, loss = 0.69262 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:29:27.346032 ops/training.py:65 2019-01-16 12:29:27.345979: step 3987, loss = 0.69910 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:29:28.110750 ops/training.py:65 2019-01-16 12:29:28.110698: step 3988, loss = 0.68954 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:29:28.874614 ops/training.py:65 2019-01-16 12:29:28.874565: step 3989, loss = 0.69382 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:29:29.638605 ops/training.py:65 2019-01-16 12:29:29.638548: step 3990, loss = 0.69360 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:29:30.402287 ops/training.py:65 2019-01-16 12:29:30.402239: step 3991, loss = 0.69185 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:29:31.166121 ops/training.py:65 2019-01-16 12:29:31.166064: step 3992, loss = 0.70069 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 12:29:31.929215 ops/training.py:65 2019-01-16 12:29:31.929170: step 3993, loss = 0.69742 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:29:32.692499 ops/training.py:65 2019-01-16 12:29:32.692445: step 3994, loss = 0.69400 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:29:33.456541 ops/training.py:65 2019-01-16 12:29:33.456482: step 3995, loss = 0.69620 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:29:34.220962 ops/training.py:65 2019-01-16 12:29:34.220910: step 3996, loss = 0.68700 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:29:34.985315 ops/training.py:65 2019-01-16 12:29:34.985261: step 3997, loss = 0.68580 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:29:35.751894 ops/training.py:65 2019-01-16 12:29:35.751832: step 3998, loss = 0.68742 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:29:36.518954 ops/training.py:65 2019-01-16 12:29:36.518880: step 3999, loss = 0.70004 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:33:09.146518 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I0528 2019-01-16 12:33:09.147391 ops/training.py:41 2019-01-16 12:33:09.147346: step 4000, loss = 0.68 (0.2 examples/sec; 211.862 sec/batch) | Training accuracy = 0.6875 | Validation accuracy = 0.5152 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_11_30_14_313845
I0528 2019-01-16 12:33:09.913244 ops/training.py:65 2019-01-16 12:33:09.913189: step 4001, loss = 0.68995 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:33:10.677630 ops/training.py:65 2019-01-16 12:33:10.677558: step 4002, loss = 0.68206 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:33:11.441664 ops/training.py:65 2019-01-16 12:33:11.441592: step 4003, loss = 0.69727 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:33:12.206070 ops/training.py:65 2019-01-16 12:33:12.206002: step 4004, loss = 0.69743 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:33:12.970618 ops/training.py:65 2019-01-16 12:33:12.970569: step 4005, loss = 0.70234 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:33:13.734943 ops/training.py:65 2019-01-16 12:33:13.734879: step 4006, loss = 0.69809 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:33:14.499313 ops/training.py:65 2019-01-16 12:33:14.499239: step 4007, loss = 0.69697 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:33:15.263305 ops/training.py:65 2019-01-16 12:33:15.263239: step 4008, loss = 0.69271 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:33:16.027774 ops/training.py:65 2019-01-16 12:33:16.027701: step 4009, loss = 0.70363 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:33:16.792049 ops/training.py:65 2019-01-16 12:33:16.791999: step 4010, loss = 0.68678 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:33:17.556513 ops/training.py:65 2019-01-16 12:33:17.556441: step 4011, loss = 0.69597 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:33:18.321049 ops/training.py:65 2019-01-16 12:33:18.320982: step 4012, loss = 0.68807 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:33:19.085531 ops/training.py:65 2019-01-16 12:33:19.085483: step 4013, loss = 0.69275 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:33:19.849922 ops/training.py:65 2019-01-16 12:33:19.849860: step 4014, loss = 0.69948 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:33:20.614951 ops/training.py:65 2019-01-16 12:33:20.614918: step 4015, loss = 0.70611 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:33:21.380227 ops/training.py:65 2019-01-16 12:33:21.380166: step 4016, loss = 0.69908 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:33:22.145500 ops/training.py:65 2019-01-16 12:33:22.145439: step 4017, loss = 0.69208 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:33:22.911805 ops/training.py:65 2019-01-16 12:33:22.911746: step 4018, loss = 0.69673 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:33:23.678962 ops/training.py:65 2019-01-16 12:33:23.678904: step 4019, loss = 0.69294 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:33:24.447109 ops/training.py:65 2019-01-16 12:33:24.447083: step 4020, loss = 0.69542 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:33:25.214370 ops/training.py:65 2019-01-16 12:33:25.214312: step 4021, loss = 0.69545 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:33:25.982099 ops/training.py:65 2019-01-16 12:33:25.982020: step 4022, loss = 0.69082 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:33:26.749589 ops/training.py:65 2019-01-16 12:33:26.749536: step 4023, loss = 0.69543 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:33:27.515569 ops/training.py:65 2019-01-16 12:33:27.515502: step 4024, loss = 0.68932 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:33:28.280508 ops/training.py:65 2019-01-16 12:33:28.280469: step 4025, loss = 0.70317 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:33:29.044727 ops/training.py:65 2019-01-16 12:33:29.044672: step 4026, loss = 0.68738 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:33:29.808263 ops/training.py:65 2019-01-16 12:33:29.808201: step 4027, loss = 0.69309 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:33:30.573107 ops/training.py:65 2019-01-16 12:33:30.573048: step 4028, loss = 0.69730 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:33:31.338328 ops/training.py:65 2019-01-16 12:33:31.338269: step 4029, loss = 0.70155 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:33:32.105822 ops/training.py:65 2019-01-16 12:33:32.105796: step 4030, loss = 0.69307 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:33:32.873117 ops/training.py:65 2019-01-16 12:33:32.873054: step 4031, loss = 0.69889 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:33:33.637959 ops/training.py:65 2019-01-16 12:33:33.637899: step 4032, loss = 0.68396 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:33:34.402711 ops/training.py:65 2019-01-16 12:33:34.402649: step 4033, loss = 0.68407 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:33:35.165584 ops/training.py:65 2019-01-16 12:33:35.165520: step 4034, loss = 0.68775 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:33:35.928597 ops/training.py:65 2019-01-16 12:33:35.928529: step 4035, loss = 0.70029 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:33:36.692938 ops/training.py:65 2019-01-16 12:33:36.692876: step 4036, loss = 0.69243 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:33:37.456866 ops/training.py:65 2019-01-16 12:33:37.456806: step 4037, loss = 0.68963 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:33:38.223753 ops/training.py:65 2019-01-16 12:33:38.223695: step 4038, loss = 0.68779 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:33:38.992401 ops/training.py:65 2019-01-16 12:33:38.992363: step 4039, loss = 0.69201 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:33:39.759358 ops/training.py:65 2019-01-16 12:33:39.759315: step 4040, loss = 0.68962 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:33:40.526515 ops/training.py:65 2019-01-16 12:33:40.526473: step 4041, loss = 0.68631 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:33:41.294228 ops/training.py:65 2019-01-16 12:33:41.294191: step 4042, loss = 0.69066 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:33:42.059156 ops/training.py:65 2019-01-16 12:33:42.059105: step 4043, loss = 0.68987 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:33:42.824092 ops/training.py:65 2019-01-16 12:33:42.824057: step 4044, loss = 0.68586 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:33:43.591887 ops/training.py:65 2019-01-16 12:33:43.591828: step 4045, loss = 0.68550 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:33:44.358681 ops/training.py:65 2019-01-16 12:33:44.358616: step 4046, loss = 0.69350 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:33:45.126577 ops/training.py:65 2019-01-16 12:33:45.126517: step 4047, loss = 0.69111 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:33:45.893597 ops/training.py:65 2019-01-16 12:33:45.893526: step 4048, loss = 0.69590 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:33:46.659139 ops/training.py:65 2019-01-16 12:33:46.659081: step 4049, loss = 0.70007 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:33:47.423707 ops/training.py:65 2019-01-16 12:33:47.423638: step 4050, loss = 0.69482 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:33:48.188282 ops/training.py:65 2019-01-16 12:33:48.188232: step 4051, loss = 0.69397 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:33:48.952543 ops/training.py:65 2019-01-16 12:33:48.952483: step 4052, loss = 0.70403 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:33:49.716146 ops/training.py:65 2019-01-16 12:33:49.716089: step 4053, loss = 0.69459 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:33:50.480109 ops/training.py:65 2019-01-16 12:33:50.480073: step 4054, loss = 0.69631 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:33:51.243591 ops/training.py:65 2019-01-16 12:33:51.243535: step 4055, loss = 0.69167 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:33:52.007347 ops/training.py:65 2019-01-16 12:33:52.007286: step 4056, loss = 0.70506 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 12:33:52.771578 ops/training.py:65 2019-01-16 12:33:52.771513: step 4057, loss = 0.67916 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:33:53.535950 ops/training.py:65 2019-01-16 12:33:53.535885: step 4058, loss = 0.69506 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:33:54.300573 ops/training.py:65 2019-01-16 12:33:54.300536: step 4059, loss = 0.69369 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:33:55.068783 ops/training.py:65 2019-01-16 12:33:55.068727: step 4060, loss = 0.70902 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:33:55.836652 ops/training.py:65 2019-01-16 12:33:55.836595: step 4061, loss = 0.69336 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:33:56.603752 ops/training.py:65 2019-01-16 12:33:56.603694: step 4062, loss = 0.68688 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 12:33:57.369491 ops/training.py:65 2019-01-16 12:33:57.369426: step 4063, loss = 0.69886 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:33:58.135000 ops/training.py:65 2019-01-16 12:33:58.134945: step 4064, loss = 0.69476 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:33:58.899412 ops/training.py:65 2019-01-16 12:33:58.899347: step 4065, loss = 0.69963 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:33:59.663862 ops/training.py:65 2019-01-16 12:33:59.663802: step 4066, loss = 0.68670 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:34:00.427891 ops/training.py:65 2019-01-16 12:34:00.427831: step 4067, loss = 0.68990 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:34:01.191918 ops/training.py:65 2019-01-16 12:34:01.191847: step 4068, loss = 0.69844 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:34:01.956237 ops/training.py:65 2019-01-16 12:34:01.956170: step 4069, loss = 0.68735 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:34:02.725268 ops/training.py:65 2019-01-16 12:34:02.725205: step 4070, loss = 0.69059 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:34:03.493050 ops/training.py:65 2019-01-16 12:34:03.492983: step 4071, loss = 0.68825 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:34:04.257169 ops/training.py:65 2019-01-16 12:34:04.257097: step 4072, loss = 0.69970 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:34:05.020776 ops/training.py:65 2019-01-16 12:34:05.020706: step 4073, loss = 0.68396 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:34:05.783441 ops/training.py:65 2019-01-16 12:34:05.783389: step 4074, loss = 0.70457 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:34:06.548588 ops/training.py:65 2019-01-16 12:34:06.548529: step 4075, loss = 0.70056 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:34:07.313073 ops/training.py:65 2019-01-16 12:34:07.313025: step 4076, loss = 0.68620 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:34:08.077282 ops/training.py:65 2019-01-16 12:34:08.077227: step 4077, loss = 0.69256 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:34:08.841440 ops/training.py:65 2019-01-16 12:34:08.841385: step 4078, loss = 0.69053 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:34:09.603873 ops/training.py:65 2019-01-16 12:34:09.603844: step 4079, loss = 0.69472 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:34:10.370592 ops/training.py:65 2019-01-16 12:34:10.370531: step 4080, loss = 0.69449 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:34:11.137343 ops/training.py:65 2019-01-16 12:34:11.137293: step 4081, loss = 0.68586 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:34:11.903402 ops/training.py:65 2019-01-16 12:34:11.903346: step 4082, loss = 0.68952 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:34:12.668826 ops/training.py:65 2019-01-16 12:34:12.668786: step 4083, loss = 0.68594 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:34:13.434858 ops/training.py:65 2019-01-16 12:34:13.434827: step 4084, loss = 0.69189 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:34:14.199508 ops/training.py:65 2019-01-16 12:34:14.199452: step 4085, loss = 0.69686 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:34:14.963133 ops/training.py:65 2019-01-16 12:34:14.963060: step 4086, loss = 0.68423 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:34:15.727350 ops/training.py:65 2019-01-16 12:34:15.727287: step 4087, loss = 0.69320 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:34:16.491016 ops/training.py:65 2019-01-16 12:34:16.490954: step 4088, loss = 0.70405 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:34:17.253644 ops/training.py:65 2019-01-16 12:34:17.253573: step 4089, loss = 0.69089 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:34:18.016946 ops/training.py:65 2019-01-16 12:34:18.016873: step 4090, loss = 0.69775 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:34:18.780309 ops/training.py:65 2019-01-16 12:34:18.780237: step 4091, loss = 0.68056 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:34:19.542695 ops/training.py:65 2019-01-16 12:34:19.542625: step 4092, loss = 0.69576 (42.0 examples/sec; 0.761 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:34:20.310239 ops/training.py:65 2019-01-16 12:34:20.310207: step 4093, loss = 0.69184 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:34:21.076674 ops/training.py:65 2019-01-16 12:34:21.076622: step 4094, loss = 0.69412 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:34:21.845287 ops/training.py:65 2019-01-16 12:34:21.845230: step 4095, loss = 0.69847 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:34:22.611649 ops/training.py:65 2019-01-16 12:34:22.611574: step 4096, loss = 0.68810 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:34:23.378713 ops/training.py:65 2019-01-16 12:34:23.378649: step 4097, loss = 0.69321 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:34:24.145800 ops/training.py:65 2019-01-16 12:34:24.145766: step 4098, loss = 0.69300 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:34:24.910518 ops/training.py:65 2019-01-16 12:34:24.910453: step 4099, loss = 0.70000 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:34:25.675541 ops/training.py:65 2019-01-16 12:34:25.675482: step 4100, loss = 0.69168 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:34:26.439750 ops/training.py:65 2019-01-16 12:34:26.439696: step 4101, loss = 0.69460 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:34:27.204338 ops/training.py:65 2019-01-16 12:34:27.204279: step 4102, loss = 0.69491 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:34:27.969006 ops/training.py:65 2019-01-16 12:34:27.968960: step 4103, loss = 0.69665 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:34:28.734400 ops/training.py:65 2019-01-16 12:34:28.734340: step 4104, loss = 0.68327 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:34:29.498491 ops/training.py:65 2019-01-16 12:34:29.498434: step 4105, loss = 0.69227 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:34:30.263858 ops/training.py:65 2019-01-16 12:34:30.263817: step 4106, loss = 0.69015 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:34:31.028288 ops/training.py:65 2019-01-16 12:34:31.028247: step 4107, loss = 0.69277 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:34:31.792303 ops/training.py:65 2019-01-16 12:34:31.792247: step 4108, loss = 0.68734 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:34:32.556830 ops/training.py:65 2019-01-16 12:34:32.556766: step 4109, loss = 0.68805 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:34:33.324446 ops/training.py:65 2019-01-16 12:34:33.324398: step 4110, loss = 0.69666 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:34:34.091942 ops/training.py:65 2019-01-16 12:34:34.091878: step 4111, loss = 0.69743 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:34:34.859159 ops/training.py:65 2019-01-16 12:34:34.859082: step 4112, loss = 0.68734 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:34:35.627144 ops/training.py:65 2019-01-16 12:34:35.627101: step 4113, loss = 0.69230 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:34:36.393993 ops/training.py:65 2019-01-16 12:34:36.393922: step 4114, loss = 0.68852 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:34:37.161550 ops/training.py:65 2019-01-16 12:34:37.161494: step 4115, loss = 0.68872 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:34:37.930214 ops/training.py:65 2019-01-16 12:34:37.930155: step 4116, loss = 0.68640 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:34:38.695876 ops/training.py:65 2019-01-16 12:34:38.695828: step 4117, loss = 0.68927 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:34:39.459706 ops/training.py:65 2019-01-16 12:34:39.459650: step 4118, loss = 0.68883 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:34:40.224218 ops/training.py:65 2019-01-16 12:34:40.224166: step 4119, loss = 0.68469 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:34:40.987394 ops/training.py:65 2019-01-16 12:34:40.987321: step 4120, loss = 0.69413 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:34:41.751924 ops/training.py:65 2019-01-16 12:34:41.751856: step 4121, loss = 0.69068 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:34:42.518703 ops/training.py:65 2019-01-16 12:34:42.518643: step 4122, loss = 0.69270 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:34:43.287007 ops/training.py:65 2019-01-16 12:34:43.286935: step 4123, loss = 0.69002 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:34:44.054491 ops/training.py:65 2019-01-16 12:34:44.054418: step 4124, loss = 0.69097 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:34:44.821136 ops/training.py:65 2019-01-16 12:34:44.821063: step 4125, loss = 0.70210 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:34:45.587159 ops/training.py:65 2019-01-16 12:34:45.587092: step 4126, loss = 0.70164 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:34:46.351008 ops/training.py:65 2019-01-16 12:34:46.350967: step 4127, loss = 0.70412 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:34:47.115268 ops/training.py:65 2019-01-16 12:34:47.115216: step 4128, loss = 0.70740 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:34:47.879259 ops/training.py:65 2019-01-16 12:34:47.879190: step 4129, loss = 0.69464 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:34:48.642480 ops/training.py:65 2019-01-16 12:34:48.642412: step 4130, loss = 0.69450 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:34:49.406200 ops/training.py:65 2019-01-16 12:34:49.406128: step 4131, loss = 0.69259 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:34:50.170500 ops/training.py:65 2019-01-16 12:34:50.170444: step 4132, loss = 0.69581 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:34:50.933867 ops/training.py:65 2019-01-16 12:34:50.933796: step 4133, loss = 0.69994 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:34:51.697795 ops/training.py:65 2019-01-16 12:34:51.697727: step 4134, loss = 0.69252 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:34:52.461104 ops/training.py:65 2019-01-16 12:34:52.461032: step 4135, loss = 0.70501 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:34:53.225246 ops/training.py:65 2019-01-16 12:34:53.225180: step 4136, loss = 0.69936 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:34:53.988529 ops/training.py:65 2019-01-16 12:34:53.988485: step 4137, loss = 0.68889 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:34:54.753116 ops/training.py:65 2019-01-16 12:34:54.753048: step 4138, loss = 0.69264 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:34:55.517270 ops/training.py:65 2019-01-16 12:34:55.517197: step 4139, loss = 0.69598 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:34:56.281454 ops/training.py:65 2019-01-16 12:34:56.281363: step 4140, loss = 0.68984 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:34:57.047603 ops/training.py:65 2019-01-16 12:34:57.047535: step 4141, loss = 0.69742 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:34:57.814462 ops/training.py:65 2019-01-16 12:34:57.814398: step 4142, loss = 0.69299 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:34:58.584291 ops/training.py:65 2019-01-16 12:34:58.584236: step 4143, loss = 0.68146 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 12:34:59.350829 ops/training.py:65 2019-01-16 12:34:59.350755: step 4144, loss = 0.69022 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:35:00.115117 ops/training.py:65 2019-01-16 12:35:00.115050: step 4145, loss = 0.68791 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:35:00.881868 ops/training.py:65 2019-01-16 12:35:00.881800: step 4146, loss = 0.69586 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:35:01.648360 ops/training.py:65 2019-01-16 12:35:01.648286: step 4147, loss = 0.69816 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:35:02.417048 ops/training.py:65 2019-01-16 12:35:02.416980: step 4148, loss = 0.68766 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:35:03.185036 ops/training.py:65 2019-01-16 12:35:03.184983: step 4149, loss = 0.69467 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:35:03.952401 ops/training.py:65 2019-01-16 12:35:03.952325: step 4150, loss = 0.70080 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:35:04.717117 ops/training.py:65 2019-01-16 12:35:04.717049: step 4151, loss = 0.69712 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:35:05.481333 ops/training.py:65 2019-01-16 12:35:05.481287: step 4152, loss = 0.69557 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:35:06.245160 ops/training.py:65 2019-01-16 12:35:06.245092: step 4153, loss = 0.70317 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:35:07.008087 ops/training.py:65 2019-01-16 12:35:07.008020: step 4154, loss = 0.68961 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:35:07.777421 ops/training.py:65 2019-01-16 12:35:07.777365: step 4155, loss = 0.67832 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:35:08.546568 ops/training.py:65 2019-01-16 12:35:08.546494: step 4156, loss = 0.68986 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:35:09.313338 ops/training.py:65 2019-01-16 12:35:09.313273: step 4157, loss = 0.69336 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:35:10.078933 ops/training.py:65 2019-01-16 12:35:10.078878: step 4158, loss = 0.69189 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:35:10.843244 ops/training.py:65 2019-01-16 12:35:10.843174: step 4159, loss = 0.69263 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:35:11.607052 ops/training.py:65 2019-01-16 12:35:11.606983: step 4160, loss = 0.69391 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:35:12.370725 ops/training.py:65 2019-01-16 12:35:12.370659: step 4161, loss = 0.69155 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:35:13.134289 ops/training.py:65 2019-01-16 12:35:13.134240: step 4162, loss = 0.68753 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:35:13.898798 ops/training.py:65 2019-01-16 12:35:13.898733: step 4163, loss = 0.69906 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:35:14.663701 ops/training.py:65 2019-01-16 12:35:14.663637: step 4164, loss = 0.69644 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:35:15.432425 ops/training.py:65 2019-01-16 12:35:15.432352: step 4165, loss = 0.68844 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:35:16.200557 ops/training.py:65 2019-01-16 12:35:16.200485: step 4166, loss = 0.69961 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:35:16.969554 ops/training.py:65 2019-01-16 12:35:16.969483: step 4167, loss = 0.69270 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:35:17.736788 ops/training.py:65 2019-01-16 12:35:17.736728: step 4168, loss = 0.69513 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:35:18.503682 ops/training.py:65 2019-01-16 12:35:18.503627: step 4169, loss = 0.68740 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:35:19.268992 ops/training.py:65 2019-01-16 12:35:19.268939: step 4170, loss = 0.68688 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:35:20.034077 ops/training.py:65 2019-01-16 12:35:20.034030: step 4171, loss = 0.69858 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:35:20.798419 ops/training.py:65 2019-01-16 12:35:20.798350: step 4172, loss = 0.69659 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:35:21.562478 ops/training.py:65 2019-01-16 12:35:21.562399: step 4173, loss = 0.69663 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:35:22.325991 ops/training.py:65 2019-01-16 12:35:22.325928: step 4174, loss = 0.69545 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:35:23.090065 ops/training.py:65 2019-01-16 12:35:23.089962: step 4175, loss = 0.70015 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:35:23.855099 ops/training.py:65 2019-01-16 12:35:23.855059: step 4176, loss = 0.68411 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:35:24.619125 ops/training.py:65 2019-01-16 12:35:24.619076: step 4177, loss = 0.69091 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:35:25.383375 ops/training.py:65 2019-01-16 12:35:25.383301: step 4178, loss = 0.70523 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:35:26.147863 ops/training.py:65 2019-01-16 12:35:26.147798: step 4179, loss = 0.69299 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:35:26.911614 ops/training.py:65 2019-01-16 12:35:26.911547: step 4180, loss = 0.69203 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:35:27.675929 ops/training.py:65 2019-01-16 12:35:27.675882: step 4181, loss = 0.69573 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:35:28.439340 ops/training.py:65 2019-01-16 12:35:28.439275: step 4182, loss = 0.69917 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:35:29.202952 ops/training.py:65 2019-01-16 12:35:29.202893: step 4183, loss = 0.68266 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:35:29.968925 ops/training.py:65 2019-01-16 12:35:29.968858: step 4184, loss = 0.67950 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 12:35:30.735423 ops/training.py:65 2019-01-16 12:35:30.735351: step 4185, loss = 0.69214 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:35:31.502809 ops/training.py:65 2019-01-16 12:35:31.502746: step 4186, loss = 0.69229 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:35:32.270381 ops/training.py:65 2019-01-16 12:35:32.270306: step 4187, loss = 0.70479 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:35:33.038244 ops/training.py:65 2019-01-16 12:35:33.038170: step 4188, loss = 0.69294 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:35:33.806822 ops/training.py:65 2019-01-16 12:35:33.806763: step 4189, loss = 0.69329 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:35:34.576648 ops/training.py:65 2019-01-16 12:35:34.576575: step 4190, loss = 0.69189 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:35:35.345430 ops/training.py:65 2019-01-16 12:35:35.345358: step 4191, loss = 0.69971 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:35:36.113331 ops/training.py:65 2019-01-16 12:35:36.113253: step 4192, loss = 0.69386 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:35:36.880706 ops/training.py:65 2019-01-16 12:35:36.880634: step 4193, loss = 0.68700 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:35:37.646635 ops/training.py:65 2019-01-16 12:35:37.646573: step 4194, loss = 0.68845 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:35:38.410561 ops/training.py:65 2019-01-16 12:35:38.410492: step 4195, loss = 0.68311 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:35:39.174976 ops/training.py:65 2019-01-16 12:35:39.174934: step 4196, loss = 0.69256 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:35:39.939645 ops/training.py:65 2019-01-16 12:35:39.939587: step 4197, loss = 0.69804 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:35:40.704595 ops/training.py:65 2019-01-16 12:35:40.704528: step 4198, loss = 0.68557 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:35:41.468977 ops/training.py:65 2019-01-16 12:35:41.468905: step 4199, loss = 0.68044 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:35:42.232733 ops/training.py:65 2019-01-16 12:35:42.232662: step 4200, loss = 0.67953 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:35:42.996760 ops/training.py:65 2019-01-16 12:35:42.996706: step 4201, loss = 0.69431 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:35:43.760798 ops/training.py:65 2019-01-16 12:35:43.760731: step 4202, loss = 0.71067 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:35:44.524857 ops/training.py:65 2019-01-16 12:35:44.524795: step 4203, loss = 0.69073 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:35:45.289893 ops/training.py:65 2019-01-16 12:35:45.289826: step 4204, loss = 0.69923 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:35:46.054720 ops/training.py:65 2019-01-16 12:35:46.054651: step 4205, loss = 0.68828 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:35:46.821226 ops/training.py:65 2019-01-16 12:35:46.821154: step 4206, loss = 0.69575 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:35:47.586736 ops/training.py:65 2019-01-16 12:35:47.586671: step 4207, loss = 0.69049 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:35:48.350872 ops/training.py:65 2019-01-16 12:35:48.350823: step 4208, loss = 0.69926 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:35:49.114846 ops/training.py:65 2019-01-16 12:35:49.114784: step 4209, loss = 0.69635 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:35:49.882473 ops/training.py:65 2019-01-16 12:35:49.882405: step 4210, loss = 0.69594 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:35:50.650680 ops/training.py:65 2019-01-16 12:35:50.650602: step 4211, loss = 0.69435 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:35:51.417521 ops/training.py:65 2019-01-16 12:35:51.417446: step 4212, loss = 0.68989 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:35:52.181821 ops/training.py:65 2019-01-16 12:35:52.181770: step 4213, loss = 0.68686 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:35:52.945403 ops/training.py:65 2019-01-16 12:35:52.945343: step 4214, loss = 0.69751 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:35:53.709337 ops/training.py:65 2019-01-16 12:35:53.709269: step 4215, loss = 0.69632 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:35:54.473472 ops/training.py:65 2019-01-16 12:35:54.473425: step 4216, loss = 0.68166 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:35:55.237469 ops/training.py:65 2019-01-16 12:35:55.237398: step 4217, loss = 0.68972 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:35:56.001745 ops/training.py:65 2019-01-16 12:35:56.001675: step 4218, loss = 0.69062 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:35:56.766744 ops/training.py:65 2019-01-16 12:35:56.766672: step 4219, loss = 0.68204 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:35:57.530768 ops/training.py:65 2019-01-16 12:35:57.530723: step 4220, loss = 0.68661 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:35:58.298321 ops/training.py:65 2019-01-16 12:35:58.298255: step 4221, loss = 0.68425 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:35:59.066443 ops/training.py:65 2019-01-16 12:35:59.066385: step 4222, loss = 0.68508 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:35:59.833169 ops/training.py:65 2019-01-16 12:35:59.833098: step 4223, loss = 0.69207 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:36:00.600838 ops/training.py:65 2019-01-16 12:36:00.600766: step 4224, loss = 0.70095 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:36:01.369969 ops/training.py:65 2019-01-16 12:36:01.369897: step 4225, loss = 0.68170 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:36:02.136633 ops/training.py:65 2019-01-16 12:36:02.136564: step 4226, loss = 0.69792 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:36:02.905014 ops/training.py:65 2019-01-16 12:36:02.904943: step 4227, loss = 0.68820 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:36:03.673738 ops/training.py:65 2019-01-16 12:36:03.673667: step 4228, loss = 0.70156 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:36:04.441241 ops/training.py:65 2019-01-16 12:36:04.441184: step 4229, loss = 0.69611 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:36:05.206951 ops/training.py:65 2019-01-16 12:36:05.206889: step 4230, loss = 0.69826 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:36:05.973991 ops/training.py:65 2019-01-16 12:36:05.973927: step 4231, loss = 0.68689 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:36:06.741918 ops/training.py:65 2019-01-16 12:36:06.741841: step 4232, loss = 0.68529 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:36:07.508290 ops/training.py:65 2019-01-16 12:36:07.508213: step 4233, loss = 0.69821 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:36:08.273618 ops/training.py:65 2019-01-16 12:36:08.273552: step 4234, loss = 0.68656 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:36:09.038796 ops/training.py:65 2019-01-16 12:36:09.038753: step 4235, loss = 0.67873 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:36:09.802932 ops/training.py:65 2019-01-16 12:36:09.802866: step 4236, loss = 0.68665 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:36:10.566412 ops/training.py:65 2019-01-16 12:36:10.566350: step 4237, loss = 0.70311 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:36:11.330102 ops/training.py:65 2019-01-16 12:36:11.330033: step 4238, loss = 0.69448 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:36:12.094453 ops/training.py:65 2019-01-16 12:36:12.094384: step 4239, loss = 0.70107 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:36:12.861839 ops/training.py:65 2019-01-16 12:36:12.861800: step 4240, loss = 0.68663 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:36:13.630533 ops/training.py:65 2019-01-16 12:36:13.630463: step 4241, loss = 0.69833 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:36:14.399468 ops/training.py:65 2019-01-16 12:36:14.399399: step 4242, loss = 0.69046 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:36:15.166718 ops/training.py:65 2019-01-16 12:36:15.166645: step 4243, loss = 0.68385 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:36:15.933164 ops/training.py:65 2019-01-16 12:36:15.933089: step 4244, loss = 0.69172 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:36:16.696723 ops/training.py:65 2019-01-16 12:36:16.696671: step 4245, loss = 0.68681 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:36:17.464876 ops/training.py:65 2019-01-16 12:36:17.464785: step 4246, loss = 0.68793 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:36:18.234330 ops/training.py:65 2019-01-16 12:36:18.234282: step 4247, loss = 0.68701 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:36:19.001388 ops/training.py:65 2019-01-16 12:36:19.001325: step 4248, loss = 0.69907 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:36:19.768830 ops/training.py:65 2019-01-16 12:36:19.768754: step 4249, loss = 0.69379 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:36:20.533368 ops/training.py:65 2019-01-16 12:36:20.533320: step 4250, loss = 0.69492 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:36:21.297122 ops/training.py:65 2019-01-16 12:36:21.297055: step 4251, loss = 0.68965 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:36:22.061129 ops/training.py:65 2019-01-16 12:36:22.061062: step 4252, loss = 0.68681 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:36:22.824686 ops/training.py:65 2019-01-16 12:36:22.824621: step 4253, loss = 0.69388 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:36:23.589118 ops/training.py:65 2019-01-16 12:36:23.589051: step 4254, loss = 0.69378 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:36:24.353101 ops/training.py:65 2019-01-16 12:36:24.353054: step 4255, loss = 0.69777 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:36:25.120680 ops/training.py:65 2019-01-16 12:36:25.120613: step 4256, loss = 0.69734 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:36:25.887997 ops/training.py:65 2019-01-16 12:36:25.887918: step 4257, loss = 0.69271 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:36:26.655005 ops/training.py:65 2019-01-16 12:36:26.654933: step 4258, loss = 0.69943 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:36:27.419084 ops/training.py:65 2019-01-16 12:36:27.419014: step 4259, loss = 0.68949 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:36:28.182513 ops/training.py:65 2019-01-16 12:36:28.182466: step 4260, loss = 0.68622 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:36:28.949138 ops/training.py:65 2019-01-16 12:36:28.949078: step 4261, loss = 0.69247 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:36:29.716668 ops/training.py:65 2019-01-16 12:36:29.716599: step 4262, loss = 0.68488 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:36:30.484835 ops/training.py:65 2019-01-16 12:36:30.484766: step 4263, loss = 0.68971 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:36:31.251390 ops/training.py:65 2019-01-16 12:36:31.251319: step 4264, loss = 0.68760 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:36:32.017886 ops/training.py:65 2019-01-16 12:36:32.017817: step 4265, loss = 0.68798 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:36:32.783074 ops/training.py:65 2019-01-16 12:36:32.783009: step 4266, loss = 0.69334 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:36:33.546665 ops/training.py:65 2019-01-16 12:36:33.546603: step 4267, loss = 0.68924 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:36:34.311773 ops/training.py:65 2019-01-16 12:36:34.311711: step 4268, loss = 0.69625 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:36:35.075374 ops/training.py:65 2019-01-16 12:36:35.075327: step 4269, loss = 0.69370 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:36:35.843266 ops/training.py:65 2019-01-16 12:36:35.843199: step 4270, loss = 0.69504 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:36:36.611383 ops/training.py:65 2019-01-16 12:36:36.611305: step 4271, loss = 0.69449 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:36:37.378530 ops/training.py:65 2019-01-16 12:36:37.378472: step 4272, loss = 0.69684 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:36:38.142398 ops/training.py:65 2019-01-16 12:36:38.142335: step 4273, loss = 0.69556 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:36:38.906649 ops/training.py:65 2019-01-16 12:36:38.906607: step 4274, loss = 0.68018 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:36:39.670700 ops/training.py:65 2019-01-16 12:36:39.670632: step 4275, loss = 0.69143 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:36:40.434566 ops/training.py:65 2019-01-16 12:36:40.434511: step 4276, loss = 0.69012 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:36:41.199535 ops/training.py:65 2019-01-16 12:36:41.199467: step 4277, loss = 0.68916 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:36:41.968314 ops/training.py:65 2019-01-16 12:36:41.968240: step 4278, loss = 0.70313 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:36:42.735775 ops/training.py:65 2019-01-16 12:36:42.735705: step 4279, loss = 0.68805 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:36:43.500399 ops/training.py:65 2019-01-16 12:36:43.500328: step 4280, loss = 0.69548 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:36:44.264825 ops/training.py:65 2019-01-16 12:36:44.264760: step 4281, loss = 0.69824 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:36:45.028249 ops/training.py:65 2019-01-16 12:36:45.028181: step 4282, loss = 0.70389 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:36:45.791072 ops/training.py:65 2019-01-16 12:36:45.791004: step 4283, loss = 0.69114 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:36:46.553660 ops/training.py:65 2019-01-16 12:36:46.553608: step 4284, loss = 0.70448 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:36:47.317251 ops/training.py:65 2019-01-16 12:36:47.317184: step 4285, loss = 0.69540 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:36:48.080708 ops/training.py:65 2019-01-16 12:36:48.080640: step 4286, loss = 0.70581 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:36:48.844327 ops/training.py:65 2019-01-16 12:36:48.844262: step 4287, loss = 0.70008 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:36:49.607552 ops/training.py:65 2019-01-16 12:36:49.607488: step 4288, loss = 0.68040 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:36:50.371172 ops/training.py:65 2019-01-16 12:36:50.371127: step 4289, loss = 0.68607 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:36:51.134013 ops/training.py:65 2019-01-16 12:36:51.133948: step 4290, loss = 0.69527 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:36:51.896783 ops/training.py:65 2019-01-16 12:36:51.896710: step 4291, loss = 0.69645 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:36:52.661404 ops/training.py:65 2019-01-16 12:36:52.661339: step 4292, loss = 0.69322 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:36:53.428304 ops/training.py:65 2019-01-16 12:36:53.428233: step 4293, loss = 0.68444 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:36:54.195342 ops/training.py:65 2019-01-16 12:36:54.195274: step 4294, loss = 0.69490 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:36:54.962779 ops/training.py:65 2019-01-16 12:36:54.962707: step 4295, loss = 0.68211 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:36:55.729427 ops/training.py:65 2019-01-16 12:36:55.729334: step 4296, loss = 0.68554 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:36:56.494143 ops/training.py:65 2019-01-16 12:36:56.494073: step 4297, loss = 0.70625 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:36:57.258717 ops/training.py:65 2019-01-16 12:36:57.258650: step 4298, loss = 0.69884 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:36:58.022378 ops/training.py:65 2019-01-16 12:36:58.022329: step 4299, loss = 0.67941 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:36:58.786700 ops/training.py:65 2019-01-16 12:36:58.786631: step 4300, loss = 0.70008 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:36:59.550529 ops/training.py:65 2019-01-16 12:36:59.550462: step 4301, loss = 0.68739 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:37:00.314381 ops/training.py:65 2019-01-16 12:37:00.314315: step 4302, loss = 0.69960 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:37:01.077227 ops/training.py:65 2019-01-16 12:37:01.077161: step 4303, loss = 0.68366 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:37:01.840333 ops/training.py:65 2019-01-16 12:37:01.840280: step 4304, loss = 0.68298 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:37:02.606328 ops/training.py:65 2019-01-16 12:37:02.606255: step 4305, loss = 0.69493 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:37:03.374557 ops/training.py:65 2019-01-16 12:37:03.374500: step 4306, loss = 0.69545 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:37:04.141912 ops/training.py:65 2019-01-16 12:37:04.141831: step 4307, loss = 0.69589 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:37:04.908567 ops/training.py:65 2019-01-16 12:37:04.908495: step 4308, loss = 0.69625 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:37:05.676836 ops/training.py:65 2019-01-16 12:37:05.676768: step 4309, loss = 0.69384 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:37:06.445082 ops/training.py:65 2019-01-16 12:37:06.445011: step 4310, loss = 0.69017 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:37:07.212724 ops/training.py:65 2019-01-16 12:37:07.212665: step 4311, loss = 0.68712 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:37:07.979791 ops/training.py:65 2019-01-16 12:37:07.979721: step 4312, loss = 0.67625 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:37:08.744237 ops/training.py:65 2019-01-16 12:37:08.744190: step 4313, loss = 0.70162 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:37:09.508499 ops/training.py:65 2019-01-16 12:37:09.508442: step 4314, loss = 0.67502 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:37:10.275005 ops/training.py:65 2019-01-16 12:37:10.274954: step 4315, loss = 0.69840 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:37:11.042041 ops/training.py:65 2019-01-16 12:37:11.041969: step 4316, loss = 0.69219 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:37:11.807210 ops/training.py:65 2019-01-16 12:37:11.807141: step 4317, loss = 0.67841 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:37:12.572599 ops/training.py:65 2019-01-16 12:37:12.572553: step 4318, loss = 0.70414 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:37:13.339432 ops/training.py:65 2019-01-16 12:37:13.339359: step 4319, loss = 0.68330 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:37:14.107176 ops/training.py:65 2019-01-16 12:37:14.107101: step 4320, loss = 0.69289 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:37:14.874724 ops/training.py:65 2019-01-16 12:37:14.874654: step 4321, loss = 0.69006 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:37:15.640523 ops/training.py:65 2019-01-16 12:37:15.640455: step 4322, loss = 0.70591 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:37:16.404889 ops/training.py:65 2019-01-16 12:37:16.404833: step 4323, loss = 0.69070 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:37:17.168860 ops/training.py:65 2019-01-16 12:37:17.168789: step 4324, loss = 0.68470 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:37:17.932742 ops/training.py:65 2019-01-16 12:37:17.932674: step 4325, loss = 0.69646 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:37:18.697267 ops/training.py:65 2019-01-16 12:37:18.697196: step 4326, loss = 0.68584 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 12:37:19.461216 ops/training.py:65 2019-01-16 12:37:19.461147: step 4327, loss = 0.69281 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:37:20.224972 ops/training.py:65 2019-01-16 12:37:20.224922: step 4328, loss = 0.69545 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:37:20.988815 ops/training.py:65 2019-01-16 12:37:20.988749: step 4329, loss = 0.70432 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:37:21.753434 ops/training.py:65 2019-01-16 12:37:21.753366: step 4330, loss = 0.68586 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:37:22.519313 ops/training.py:65 2019-01-16 12:37:22.519256: step 4331, loss = 0.68617 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:37:23.288489 ops/training.py:65 2019-01-16 12:37:23.288416: step 4332, loss = 0.69142 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:37:24.055978 ops/training.py:65 2019-01-16 12:37:24.055913: step 4333, loss = 0.69641 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:37:24.824505 ops/training.py:65 2019-01-16 12:37:24.824441: step 4334, loss = 0.69594 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:37:25.591464 ops/training.py:65 2019-01-16 12:37:25.591399: step 4335, loss = 0.69126 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:37:26.363286 ops/training.py:65 2019-01-16 12:37:26.363217: step 4336, loss = 0.69131 (41.5 examples/sec; 0.770 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:37:27.134948 ops/training.py:65 2019-01-16 12:37:27.134871: step 4337, loss = 0.69824 (41.5 examples/sec; 0.771 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:37:27.902281 ops/training.py:65 2019-01-16 12:37:27.902209: step 4338, loss = 0.69350 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:37:28.670920 ops/training.py:65 2019-01-16 12:37:28.670844: step 4339, loss = 0.68449 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:37:29.439889 ops/training.py:65 2019-01-16 12:37:29.439827: step 4340, loss = 0.68705 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:37:30.206610 ops/training.py:65 2019-01-16 12:37:30.206537: step 4341, loss = 0.67929 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:37:30.973703 ops/training.py:65 2019-01-16 12:37:30.973631: step 4342, loss = 0.68351 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:37:31.738950 ops/training.py:65 2019-01-16 12:37:31.738904: step 4343, loss = 0.68528 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:37:32.502853 ops/training.py:65 2019-01-16 12:37:32.502780: step 4344, loss = 0.70410 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:37:33.267058 ops/training.py:65 2019-01-16 12:37:33.267007: step 4345, loss = 0.70235 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:37:34.032077 ops/training.py:65 2019-01-16 12:37:34.032016: step 4346, loss = 0.68496 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:37:34.795972 ops/training.py:65 2019-01-16 12:37:34.795905: step 4347, loss = 0.69356 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:37:35.560544 ops/training.py:65 2019-01-16 12:37:35.560493: step 4348, loss = 0.69268 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:37:36.324230 ops/training.py:65 2019-01-16 12:37:36.324165: step 4349, loss = 0.69469 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:37:37.087676 ops/training.py:65 2019-01-16 12:37:37.087606: step 4350, loss = 0.68798 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:37:37.851115 ops/training.py:65 2019-01-16 12:37:37.851047: step 4351, loss = 0.68940 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:37:38.614284 ops/training.py:65 2019-01-16 12:37:38.614238: step 4352, loss = 0.69971 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:37:39.378185 ops/training.py:65 2019-01-16 12:37:39.378138: step 4353, loss = 0.68925 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:37:40.142175 ops/training.py:65 2019-01-16 12:37:40.142119: step 4354, loss = 0.68049 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:37:40.906889 ops/training.py:65 2019-01-16 12:37:40.906820: step 4355, loss = 0.68276 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:37:41.670667 ops/training.py:65 2019-01-16 12:37:41.670598: step 4356, loss = 0.69686 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:37:42.434240 ops/training.py:65 2019-01-16 12:37:42.434191: step 4357, loss = 0.68521 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:37:43.198218 ops/training.py:65 2019-01-16 12:37:43.198151: step 4358, loss = 0.70032 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:37:43.962239 ops/training.py:65 2019-01-16 12:37:43.962173: step 4359, loss = 0.68822 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:37:44.725673 ops/training.py:65 2019-01-16 12:37:44.725609: step 4360, loss = 0.69091 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:37:45.489425 ops/training.py:65 2019-01-16 12:37:45.489357: step 4361, loss = 0.69877 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:37:46.253433 ops/training.py:65 2019-01-16 12:37:46.253379: step 4362, loss = 0.68407 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:37:47.021203 ops/training.py:65 2019-01-16 12:37:47.021131: step 4363, loss = 0.68957 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:37:47.789122 ops/training.py:65 2019-01-16 12:37:47.789044: step 4364, loss = 0.70102 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:37:48.555335 ops/training.py:65 2019-01-16 12:37:48.555260: step 4365, loss = 0.69778 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:37:49.319361 ops/training.py:65 2019-01-16 12:37:49.319299: step 4366, loss = 0.69074 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:37:50.083383 ops/training.py:65 2019-01-16 12:37:50.083334: step 4367, loss = 0.69074 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:37:50.847727 ops/training.py:65 2019-01-16 12:37:50.847660: step 4368, loss = 0.69070 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:37:51.611505 ops/training.py:65 2019-01-16 12:37:51.611440: step 4369, loss = 0.68020 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:37:52.375969 ops/training.py:65 2019-01-16 12:37:52.375910: step 4370, loss = 0.70452 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:37:53.140136 ops/training.py:65 2019-01-16 12:37:53.140066: step 4371, loss = 0.69174 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:37:53.903664 ops/training.py:65 2019-01-16 12:37:53.903611: step 4372, loss = 0.69979 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:37:54.667475 ops/training.py:65 2019-01-16 12:37:54.667412: step 4373, loss = 0.68675 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:37:55.431483 ops/training.py:65 2019-01-16 12:37:55.431414: step 4374, loss = 0.69225 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:37:56.194974 ops/training.py:65 2019-01-16 12:37:56.194907: step 4375, loss = 0.68715 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:37:56.958500 ops/training.py:65 2019-01-16 12:37:56.958433: step 4376, loss = 0.70827 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:37:57.722490 ops/training.py:65 2019-01-16 12:37:57.722442: step 4377, loss = 0.68537 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:37:58.487362 ops/training.py:65 2019-01-16 12:37:58.487295: step 4378, loss = 0.69642 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:37:59.251593 ops/training.py:65 2019-01-16 12:37:59.251534: step 4379, loss = 0.70156 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:38:00.016090 ops/training.py:65 2019-01-16 12:38:00.016019: step 4380, loss = 0.69432 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:38:00.780133 ops/training.py:65 2019-01-16 12:38:00.780057: step 4381, loss = 0.69165 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:38:01.545260 ops/training.py:65 2019-01-16 12:38:01.545208: step 4382, loss = 0.69199 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:38:02.308925 ops/training.py:65 2019-01-16 12:38:02.308861: step 4383, loss = 0.69202 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:38:03.073365 ops/training.py:65 2019-01-16 12:38:03.073295: step 4384, loss = 0.69526 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:38:03.838136 ops/training.py:65 2019-01-16 12:38:03.838071: step 4385, loss = 0.69553 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:38:04.602577 ops/training.py:65 2019-01-16 12:38:04.602536: step 4386, loss = 0.69741 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:38:05.366673 ops/training.py:65 2019-01-16 12:38:05.366625: step 4387, loss = 0.69107 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:38:06.131320 ops/training.py:65 2019-01-16 12:38:06.131251: step 4388, loss = 0.69601 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:38:06.894700 ops/training.py:65 2019-01-16 12:38:06.894630: step 4389, loss = 0.69513 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:38:07.659247 ops/training.py:65 2019-01-16 12:38:07.659180: step 4390, loss = 0.69422 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:38:08.423240 ops/training.py:65 2019-01-16 12:38:08.423192: step 4391, loss = 0.69350 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:38:09.186789 ops/training.py:65 2019-01-16 12:38:09.186730: step 4392, loss = 0.70494 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:38:09.949959 ops/training.py:65 2019-01-16 12:38:09.949889: step 4393, loss = 0.70030 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:38:10.713245 ops/training.py:65 2019-01-16 12:38:10.713171: step 4394, loss = 0.68722 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:38:11.478939 ops/training.py:65 2019-01-16 12:38:11.478870: step 4395, loss = 0.69907 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:38:12.243883 ops/training.py:65 2019-01-16 12:38:12.243833: step 4396, loss = 0.70032 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:38:13.007920 ops/training.py:65 2019-01-16 12:38:13.007853: step 4397, loss = 0.70053 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:38:13.772358 ops/training.py:65 2019-01-16 12:38:13.772294: step 4398, loss = 0.69130 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:38:14.536665 ops/training.py:65 2019-01-16 12:38:14.536601: step 4399, loss = 0.68807 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:38:15.300195 ops/training.py:65 2019-01-16 12:38:15.300123: step 4400, loss = 0.68545 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:38:16.064342 ops/training.py:65 2019-01-16 12:38:16.064287: step 4401, loss = 0.69667 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:38:16.830660 ops/training.py:65 2019-01-16 12:38:16.830593: step 4402, loss = 0.69207 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:38:17.594455 ops/training.py:65 2019-01-16 12:38:17.594388: step 4403, loss = 0.69165 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:38:18.358493 ops/training.py:65 2019-01-16 12:38:18.358448: step 4404, loss = 0.69222 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:38:19.122749 ops/training.py:65 2019-01-16 12:38:19.122684: step 4405, loss = 0.69883 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:38:19.886324 ops/training.py:65 2019-01-16 12:38:19.886274: step 4406, loss = 0.68581 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:38:20.650455 ops/training.py:65 2019-01-16 12:38:20.650390: step 4407, loss = 0.68439 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:38:21.413774 ops/training.py:65 2019-01-16 12:38:21.413708: step 4408, loss = 0.70165 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:38:22.177306 ops/training.py:65 2019-01-16 12:38:22.177234: step 4409, loss = 0.69096 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:38:22.940752 ops/training.py:65 2019-01-16 12:38:22.940685: step 4410, loss = 0.69238 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:38:23.705297 ops/training.py:65 2019-01-16 12:38:23.705247: step 4411, loss = 0.70259 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:38:24.470091 ops/training.py:65 2019-01-16 12:38:24.470025: step 4412, loss = 0.69271 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:38:25.234002 ops/training.py:65 2019-01-16 12:38:25.233936: step 4413, loss = 0.69523 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:38:26.000887 ops/training.py:65 2019-01-16 12:38:26.000823: step 4414, loss = 0.68805 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:38:26.768701 ops/training.py:65 2019-01-16 12:38:26.768633: step 4415, loss = 0.69910 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:38:27.535968 ops/training.py:65 2019-01-16 12:38:27.535901: step 4416, loss = 0.68823 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:38:28.301704 ops/training.py:65 2019-01-16 12:38:28.301635: step 4417, loss = 0.69767 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:38:29.065978 ops/training.py:65 2019-01-16 12:38:29.065919: step 4418, loss = 0.69929 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:38:29.831350 ops/training.py:65 2019-01-16 12:38:29.831287: step 4419, loss = 0.68563 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:38:30.598249 ops/training.py:65 2019-01-16 12:38:30.598185: step 4420, loss = 0.70640 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:38:31.365825 ops/training.py:65 2019-01-16 12:38:31.365747: step 4421, loss = 0.69353 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:38:32.132292 ops/training.py:65 2019-01-16 12:38:32.132225: step 4422, loss = 0.70696 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:38:32.897468 ops/training.py:65 2019-01-16 12:38:32.897400: step 4423, loss = 0.69236 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:38:33.660343 ops/training.py:65 2019-01-16 12:38:33.660283: step 4424, loss = 0.69263 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:38:34.423716 ops/training.py:65 2019-01-16 12:38:34.423674: step 4425, loss = 0.70428 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:38:35.188191 ops/training.py:65 2019-01-16 12:38:35.188144: step 4426, loss = 0.69527 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:38:35.952234 ops/training.py:65 2019-01-16 12:38:35.952168: step 4427, loss = 0.70233 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:38:36.716337 ops/training.py:65 2019-01-16 12:38:36.716271: step 4428, loss = 0.68485 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:38:37.480048 ops/training.py:65 2019-01-16 12:38:37.479966: step 4429, loss = 0.68849 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:38:38.248207 ops/training.py:65 2019-01-16 12:38:38.248147: step 4430, loss = 0.69307 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:38:39.015827 ops/training.py:65 2019-01-16 12:38:39.015760: step 4431, loss = 0.69679 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:38:39.784772 ops/training.py:65 2019-01-16 12:38:39.784695: step 4432, loss = 0.68767 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:38:40.552326 ops/training.py:65 2019-01-16 12:38:40.552265: step 4433, loss = 0.68431 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:38:41.320332 ops/training.py:65 2019-01-16 12:38:41.320256: step 4434, loss = 0.69297 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:38:42.088145 ops/training.py:65 2019-01-16 12:38:42.088063: step 4435, loss = 0.70159 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:38:42.853391 ops/training.py:65 2019-01-16 12:38:42.853319: step 4436, loss = 0.69004 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:38:43.618357 ops/training.py:65 2019-01-16 12:38:43.618284: step 4437, loss = 0.70041 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:38:44.382447 ops/training.py:65 2019-01-16 12:38:44.382380: step 4438, loss = 0.70451 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:38:45.147088 ops/training.py:65 2019-01-16 12:38:45.147014: step 4439, loss = 0.70077 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:38:45.911893 ops/training.py:65 2019-01-16 12:38:45.911845: step 4440, loss = 0.68021 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:38:46.678654 ops/training.py:65 2019-01-16 12:38:46.678592: step 4441, loss = 0.68542 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:38:47.446535 ops/training.py:65 2019-01-16 12:38:47.446464: step 4442, loss = 0.70224 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:38:48.213096 ops/training.py:65 2019-01-16 12:38:48.213028: step 4443, loss = 0.69075 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:38:48.978273 ops/training.py:65 2019-01-16 12:38:48.978215: step 4444, loss = 0.69402 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:38:49.745601 ops/training.py:65 2019-01-16 12:38:49.745548: step 4445, loss = 0.69701 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:38:50.512881 ops/training.py:65 2019-01-16 12:38:50.512809: step 4446, loss = 0.69200 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:38:51.279268 ops/training.py:65 2019-01-16 12:38:51.279189: step 4447, loss = 0.69431 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:38:52.046521 ops/training.py:65 2019-01-16 12:38:52.046452: step 4448, loss = 0.69960 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:38:52.811912 ops/training.py:65 2019-01-16 12:38:52.811841: step 4449, loss = 0.68975 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:38:53.577296 ops/training.py:65 2019-01-16 12:38:53.577248: step 4450, loss = 0.70564 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:38:54.341264 ops/training.py:65 2019-01-16 12:38:54.341191: step 4451, loss = 0.71116 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:38:55.106013 ops/training.py:65 2019-01-16 12:38:55.105941: step 4452, loss = 0.70028 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:38:55.869413 ops/training.py:65 2019-01-16 12:38:55.869342: step 4453, loss = 0.68929 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:38:56.633612 ops/training.py:65 2019-01-16 12:38:56.633545: step 4454, loss = 0.70458 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:38:57.397018 ops/training.py:65 2019-01-16 12:38:57.396970: step 4455, loss = 0.69624 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:38:58.160613 ops/training.py:65 2019-01-16 12:38:58.160546: step 4456, loss = 0.69406 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:38:58.923816 ops/training.py:65 2019-01-16 12:38:58.923753: step 4457, loss = 0.70728 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:38:59.687424 ops/training.py:65 2019-01-16 12:38:59.687350: step 4458, loss = 0.69009 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:39:00.452659 ops/training.py:65 2019-01-16 12:39:00.452592: step 4459, loss = 0.69337 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:39:01.216211 ops/training.py:65 2019-01-16 12:39:01.216161: step 4460, loss = 0.68828 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:39:01.979771 ops/training.py:65 2019-01-16 12:39:01.979710: step 4461, loss = 0.68452 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:39:02.743539 ops/training.py:65 2019-01-16 12:39:02.743475: step 4462, loss = 0.69426 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:39:03.509450 ops/training.py:65 2019-01-16 12:39:03.509383: step 4463, loss = 0.70004 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:39:04.276202 ops/training.py:65 2019-01-16 12:39:04.276133: step 4464, loss = 0.70135 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:39:05.045224 ops/training.py:65 2019-01-16 12:39:05.045153: step 4465, loss = 0.67961 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:39:05.813458 ops/training.py:65 2019-01-16 12:39:05.813384: step 4466, loss = 0.68035 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 12:39:06.580463 ops/training.py:65 2019-01-16 12:39:06.580385: step 4467, loss = 0.69413 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:39:07.344866 ops/training.py:65 2019-01-16 12:39:07.344816: step 4468, loss = 0.69859 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:39:08.109121 ops/training.py:65 2019-01-16 12:39:08.109073: step 4469, loss = 0.69194 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:39:08.872928 ops/training.py:65 2019-01-16 12:39:08.872872: step 4470, loss = 0.68612 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:39:09.636436 ops/training.py:65 2019-01-16 12:39:09.636371: step 4471, loss = 0.70289 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:39:10.400698 ops/training.py:65 2019-01-16 12:39:10.400643: step 4472, loss = 0.69544 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:39:11.164519 ops/training.py:65 2019-01-16 12:39:11.164458: step 4473, loss = 0.69371 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:39:11.932655 ops/training.py:65 2019-01-16 12:39:11.932614: step 4474, loss = 0.70194 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:39:12.699802 ops/training.py:65 2019-01-16 12:39:12.699727: step 4475, loss = 0.69106 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:39:13.467003 ops/training.py:65 2019-01-16 12:39:13.466933: step 4476, loss = 0.68487 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 12:39:14.232705 ops/training.py:65 2019-01-16 12:39:14.232635: step 4477, loss = 0.70161 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:39:14.996022 ops/training.py:65 2019-01-16 12:39:14.995953: step 4478, loss = 0.69418 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:39:15.759379 ops/training.py:65 2019-01-16 12:39:15.759331: step 4479, loss = 0.68557 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:39:16.523382 ops/training.py:65 2019-01-16 12:39:16.523316: step 4480, loss = 0.69933 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:39:17.286523 ops/training.py:65 2019-01-16 12:39:17.286452: step 4481, loss = 0.70223 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:39:18.050315 ops/training.py:65 2019-01-16 12:39:18.050249: step 4482, loss = 0.68949 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:39:18.817123 ops/training.py:65 2019-01-16 12:39:18.817065: step 4483, loss = 0.70548 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:39:19.584739 ops/training.py:65 2019-01-16 12:39:19.584683: step 4484, loss = 0.70219 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:39:20.352144 ops/training.py:65 2019-01-16 12:39:20.352048: step 4485, loss = 0.70064 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:39:21.121317 ops/training.py:65 2019-01-16 12:39:21.121240: step 4486, loss = 0.68018 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:39:21.889462 ops/training.py:65 2019-01-16 12:39:21.889385: step 4487, loss = 0.70109 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:39:22.656630 ops/training.py:65 2019-01-16 12:39:22.656555: step 4488, loss = 0.68494 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:39:23.422058 ops/training.py:65 2019-01-16 12:39:23.422007: step 4489, loss = 0.70029 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:39:24.186409 ops/training.py:65 2019-01-16 12:39:24.186332: step 4490, loss = 0.67526 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:39:24.950834 ops/training.py:65 2019-01-16 12:39:24.950764: step 4491, loss = 0.71113 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:39:25.715096 ops/training.py:65 2019-01-16 12:39:25.715024: step 4492, loss = 0.67446 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:39:26.480121 ops/training.py:65 2019-01-16 12:39:26.480025: step 4493, loss = 0.69581 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:39:27.244368 ops/training.py:65 2019-01-16 12:39:27.244316: step 4494, loss = 0.67238 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:39:28.008532 ops/training.py:65 2019-01-16 12:39:28.008467: step 4495, loss = 0.69346 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:39:28.772311 ops/training.py:65 2019-01-16 12:39:28.772242: step 4496, loss = 0.67899 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:39:29.535750 ops/training.py:65 2019-01-16 12:39:29.535683: step 4497, loss = 0.67757 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:39:30.299415 ops/training.py:65 2019-01-16 12:39:30.299351: step 4498, loss = 0.69853 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:39:31.063304 ops/training.py:65 2019-01-16 12:39:31.063255: step 4499, loss = 0.68848 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:39:31.826592 ops/training.py:65 2019-01-16 12:39:31.826526: step 4500, loss = 0.70123 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:39:32.590102 ops/training.py:65 2019-01-16 12:39:32.590037: step 4501, loss = 0.69072 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:39:33.353806 ops/training.py:65 2019-01-16 12:39:33.353754: step 4502, loss = 0.68850 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:39:34.118017 ops/training.py:65 2019-01-16 12:39:34.117960: step 4503, loss = 0.68753 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:39:34.881472 ops/training.py:65 2019-01-16 12:39:34.881422: step 4504, loss = 0.68928 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:39:35.644881 ops/training.py:65 2019-01-16 12:39:35.644814: step 4505, loss = 0.68726 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:39:36.408551 ops/training.py:65 2019-01-16 12:39:36.408486: step 4506, loss = 0.69094 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:39:37.173377 ops/training.py:65 2019-01-16 12:39:37.173310: step 4507, loss = 0.67837 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 12:39:37.937860 ops/training.py:65 2019-01-16 12:39:37.937815: step 4508, loss = 0.69408 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:39:38.702535 ops/training.py:65 2019-01-16 12:39:38.702466: step 4509, loss = 0.69308 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:39:39.465908 ops/training.py:65 2019-01-16 12:39:39.465845: step 4510, loss = 0.71278 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:39:40.230088 ops/training.py:65 2019-01-16 12:39:40.230031: step 4511, loss = 0.69863 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:39:40.993992 ops/training.py:65 2019-01-16 12:39:40.993924: step 4512, loss = 0.68501 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:39:41.758268 ops/training.py:65 2019-01-16 12:39:41.758220: step 4513, loss = 0.69369 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:39:42.522772 ops/training.py:65 2019-01-16 12:39:42.522704: step 4514, loss = 0.68292 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:39:43.286073 ops/training.py:65 2019-01-16 12:39:43.286008: step 4515, loss = 0.68720 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:39:44.049861 ops/training.py:65 2019-01-16 12:39:44.049788: step 4516, loss = 0.69332 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:39:44.813646 ops/training.py:65 2019-01-16 12:39:44.813583: step 4517, loss = 0.70718 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:39:45.576699 ops/training.py:65 2019-01-16 12:39:45.576647: step 4518, loss = 0.70797 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:39:46.340047 ops/training.py:65 2019-01-16 12:39:46.339980: step 4519, loss = 0.71599 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:39:47.103014 ops/training.py:65 2019-01-16 12:39:47.102949: step 4520, loss = 0.71156 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:39:47.866333 ops/training.py:65 2019-01-16 12:39:47.866264: step 4521, loss = 0.70111 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:39:48.630933 ops/training.py:65 2019-01-16 12:39:48.630862: step 4522, loss = 0.69157 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:39:49.395995 ops/training.py:65 2019-01-16 12:39:49.395947: step 4523, loss = 0.71295 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:39:50.160378 ops/training.py:65 2019-01-16 12:39:50.160311: step 4524, loss = 0.68330 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:39:50.924816 ops/training.py:65 2019-01-16 12:39:50.924749: step 4525, loss = 0.67867 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:39:51.693441 ops/training.py:65 2019-01-16 12:39:51.693373: step 4526, loss = 0.68471 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:39:52.461618 ops/training.py:65 2019-01-16 12:39:52.461539: step 4527, loss = 0.69441 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:39:53.228392 ops/training.py:65 2019-01-16 12:39:53.228324: step 4528, loss = 0.70722 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:39:53.992780 ops/training.py:65 2019-01-16 12:39:53.992717: step 4529, loss = 0.68869 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:39:54.756477 ops/training.py:65 2019-01-16 12:39:54.756410: step 4530, loss = 0.68944 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:39:55.520915 ops/training.py:65 2019-01-16 12:39:55.520854: step 4531, loss = 0.68805 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:39:56.284722 ops/training.py:65 2019-01-16 12:39:56.284670: step 4532, loss = 0.70070 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:39:57.053732 ops/training.py:65 2019-01-16 12:39:57.053677: step 4533, loss = 0.67744 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:39:57.821891 ops/training.py:65 2019-01-16 12:39:57.821815: step 4534, loss = 0.68862 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:39:58.588988 ops/training.py:65 2019-01-16 12:39:58.588914: step 4535, loss = 0.68757 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:39:59.356730 ops/training.py:65 2019-01-16 12:39:59.356657: step 4536, loss = 0.68821 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:40:00.123677 ops/training.py:65 2019-01-16 12:40:00.123609: step 4537, loss = 0.68733 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:40:00.888369 ops/training.py:65 2019-01-16 12:40:00.888320: step 4538, loss = 0.70070 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:40:01.654298 ops/training.py:65 2019-01-16 12:40:01.654229: step 4539, loss = 0.69342 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:40:02.421669 ops/training.py:65 2019-01-16 12:40:02.421595: step 4540, loss = 0.69349 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:40:03.187977 ops/training.py:65 2019-01-16 12:40:03.187904: step 4541, loss = 0.68795 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:40:03.952918 ops/training.py:65 2019-01-16 12:40:03.952850: step 4542, loss = 0.69807 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:40:04.716780 ops/training.py:65 2019-01-16 12:40:04.716730: step 4543, loss = 0.70061 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:40:05.480809 ops/training.py:65 2019-01-16 12:40:05.480731: step 4544, loss = 0.70095 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:40:06.245362 ops/training.py:65 2019-01-16 12:40:06.245280: step 4545, loss = 0.68913 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:40:07.009767 ops/training.py:65 2019-01-16 12:40:07.009697: step 4546, loss = 0.69162 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:40:07.773640 ops/training.py:65 2019-01-16 12:40:07.773596: step 4547, loss = 0.71127 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:40:08.538180 ops/training.py:65 2019-01-16 12:40:08.538123: step 4548, loss = 0.68791 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:40:09.301908 ops/training.py:65 2019-01-16 12:40:09.301846: step 4549, loss = 0.68429 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:40:10.065886 ops/training.py:65 2019-01-16 12:40:10.065814: step 4550, loss = 0.69057 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:40:10.829941 ops/training.py:65 2019-01-16 12:40:10.829867: step 4551, loss = 0.68989 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:40:11.597671 ops/training.py:65 2019-01-16 12:40:11.597619: step 4552, loss = 0.68091 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:40:12.364283 ops/training.py:65 2019-01-16 12:40:12.364209: step 4553, loss = 0.69960 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:40:13.130928 ops/training.py:65 2019-01-16 12:40:13.130855: step 4554, loss = 0.67699 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:40:13.897281 ops/training.py:65 2019-01-16 12:40:13.897209: step 4555, loss = 0.69431 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:40:14.662029 ops/training.py:65 2019-01-16 12:40:14.661959: step 4556, loss = 0.68899 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:40:15.425031 ops/training.py:65 2019-01-16 12:40:15.424982: step 4557, loss = 0.70551 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:40:16.189390 ops/training.py:65 2019-01-16 12:40:16.189320: step 4558, loss = 0.71816 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:40:16.953262 ops/training.py:65 2019-01-16 12:40:16.953196: step 4559, loss = 0.68635 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:40:17.716758 ops/training.py:65 2019-01-16 12:40:17.716689: step 4560, loss = 0.69283 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:40:18.480544 ops/training.py:65 2019-01-16 12:40:18.480481: step 4561, loss = 0.68973 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:40:19.243818 ops/training.py:65 2019-01-16 12:40:19.243775: step 4562, loss = 0.69357 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:40:20.007937 ops/training.py:65 2019-01-16 12:40:20.007870: step 4563, loss = 0.70318 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:40:20.771488 ops/training.py:65 2019-01-16 12:40:20.771421: step 4564, loss = 0.71122 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:40:21.535791 ops/training.py:65 2019-01-16 12:40:21.535722: step 4565, loss = 0.70567 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:40:22.299430 ops/training.py:65 2019-01-16 12:40:22.299361: step 4566, loss = 0.70665 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:40:23.063576 ops/training.py:65 2019-01-16 12:40:23.063531: step 4567, loss = 0.68887 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:40:23.828306 ops/training.py:65 2019-01-16 12:40:23.828245: step 4568, loss = 0.68815 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:40:24.592696 ops/training.py:65 2019-01-16 12:40:24.592628: step 4569, loss = 0.69354 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:40:25.356959 ops/training.py:65 2019-01-16 12:40:25.356889: step 4570, loss = 0.69096 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:40:26.120924 ops/training.py:65 2019-01-16 12:40:26.120836: step 4571, loss = 0.68383 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:40:26.888674 ops/training.py:65 2019-01-16 12:40:26.888618: step 4572, loss = 0.71038 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 12:40:27.655431 ops/training.py:65 2019-01-16 12:40:27.655367: step 4573, loss = 0.69472 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:40:28.422626 ops/training.py:65 2019-01-16 12:40:28.422569: step 4574, loss = 0.68302 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:40:29.191087 ops/training.py:65 2019-01-16 12:40:29.191035: step 4575, loss = 0.68577 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:40:29.958654 ops/training.py:65 2019-01-16 12:40:29.958605: step 4576, loss = 0.68580 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:40:30.725738 ops/training.py:65 2019-01-16 12:40:30.725668: step 4577, loss = 0.69329 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:40:31.493289 ops/training.py:65 2019-01-16 12:40:31.493236: step 4578, loss = 0.69148 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:40:32.256493 ops/training.py:65 2019-01-16 12:40:32.256424: step 4579, loss = 0.69157 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:40:33.019817 ops/training.py:65 2019-01-16 12:40:33.019751: step 4580, loss = 0.69676 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:40:33.783278 ops/training.py:65 2019-01-16 12:40:33.783221: step 4581, loss = 0.69586 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:40:34.547902 ops/training.py:65 2019-01-16 12:40:34.547844: step 4582, loss = 0.68507 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:40:35.310949 ops/training.py:65 2019-01-16 12:40:35.310885: step 4583, loss = 0.69145 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:40:36.074042 ops/training.py:65 2019-01-16 12:40:36.073971: step 4584, loss = 0.68826 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:40:36.838258 ops/training.py:65 2019-01-16 12:40:36.838184: step 4585, loss = 0.69411 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:40:37.602243 ops/training.py:65 2019-01-16 12:40:37.602199: step 4586, loss = 0.68314 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:40:38.366144 ops/training.py:65 2019-01-16 12:40:38.366082: step 4587, loss = 0.69005 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:40:39.130351 ops/training.py:65 2019-01-16 12:40:39.130290: step 4588, loss = 0.69331 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:40:39.900160 ops/training.py:65 2019-01-16 12:40:39.900095: step 4589, loss = 0.68148 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:40:40.668723 ops/training.py:65 2019-01-16 12:40:40.668659: step 4590, loss = 0.69894 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:40:41.436977 ops/training.py:65 2019-01-16 12:40:41.436917: step 4591, loss = 0.69558 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:40:42.204539 ops/training.py:65 2019-01-16 12:40:42.204477: step 4592, loss = 0.68829 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:40:42.971519 ops/training.py:65 2019-01-16 12:40:42.971456: step 4593, loss = 0.69201 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:40:43.737020 ops/training.py:65 2019-01-16 12:40:43.736942: step 4594, loss = 0.68915 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:40:44.502770 ops/training.py:65 2019-01-16 12:40:44.502692: step 4595, loss = 0.70136 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:40:45.267523 ops/training.py:65 2019-01-16 12:40:45.267475: step 4596, loss = 0.68791 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:40:46.034469 ops/training.py:65 2019-01-16 12:40:46.034401: step 4597, loss = 0.68017 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:40:46.802970 ops/training.py:65 2019-01-16 12:40:46.802871: step 4598, loss = 0.68891 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:40:47.570681 ops/training.py:65 2019-01-16 12:40:47.570601: step 4599, loss = 0.68530 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:40:48.338304 ops/training.py:65 2019-01-16 12:40:48.338228: step 4600, loss = 0.69287 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:40:49.107671 ops/training.py:65 2019-01-16 12:40:49.107623: step 4601, loss = 0.68964 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:40:49.874246 ops/training.py:65 2019-01-16 12:40:49.874172: step 4602, loss = 0.69791 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:40:50.641448 ops/training.py:65 2019-01-16 12:40:50.641368: step 4603, loss = 0.69437 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:40:51.407960 ops/training.py:65 2019-01-16 12:40:51.407894: step 4604, loss = 0.69260 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:40:52.172101 ops/training.py:65 2019-01-16 12:40:52.172034: step 4605, loss = 0.69245 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:40:52.936603 ops/training.py:65 2019-01-16 12:40:52.936557: step 4606, loss = 0.69526 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:40:53.702850 ops/training.py:65 2019-01-16 12:40:53.702784: step 4607, loss = 0.68813 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:40:54.471208 ops/training.py:65 2019-01-16 12:40:54.471136: step 4608, loss = 0.69671 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:40:55.237985 ops/training.py:65 2019-01-16 12:40:55.237912: step 4609, loss = 0.69588 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:40:56.004834 ops/training.py:65 2019-01-16 12:40:56.004759: step 4610, loss = 0.69784 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:40:56.769278 ops/training.py:65 2019-01-16 12:40:56.769220: step 4611, loss = 0.70347 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:40:57.535860 ops/training.py:65 2019-01-16 12:40:57.535795: step 4612, loss = 0.69700 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:40:58.303736 ops/training.py:65 2019-01-16 12:40:58.303664: step 4613, loss = 0.68735 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:40:59.072356 ops/training.py:65 2019-01-16 12:40:59.072304: step 4614, loss = 0.68914 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:40:59.839549 ops/training.py:65 2019-01-16 12:40:59.839474: step 4615, loss = 0.69797 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:41:00.605735 ops/training.py:65 2019-01-16 12:41:00.605661: step 4616, loss = 0.69796 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:41:01.371606 ops/training.py:65 2019-01-16 12:41:01.371539: step 4617, loss = 0.69147 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:41:02.134704 ops/training.py:65 2019-01-16 12:41:02.134636: step 4618, loss = 0.68816 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:41:02.898866 ops/training.py:65 2019-01-16 12:41:02.898801: step 4619, loss = 0.67832 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:41:03.661940 ops/training.py:65 2019-01-16 12:41:03.661882: step 4620, loss = 0.70108 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:41:04.430318 ops/training.py:65 2019-01-16 12:41:04.430273: step 4621, loss = 0.69329 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:41:05.199203 ops/training.py:65 2019-01-16 12:41:05.199126: step 4622, loss = 0.69502 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:41:05.966570 ops/training.py:65 2019-01-16 12:41:05.966511: step 4623, loss = 0.70298 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:41:06.733067 ops/training.py:65 2019-01-16 12:41:06.733009: step 4624, loss = 0.69873 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:41:07.497059 ops/training.py:65 2019-01-16 12:41:07.496985: step 4625, loss = 0.69440 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:41:08.261408 ops/training.py:65 2019-01-16 12:41:08.261361: step 4626, loss = 0.68579 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:41:09.025470 ops/training.py:65 2019-01-16 12:41:09.025410: step 4627, loss = 0.67927 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:41:09.789493 ops/training.py:65 2019-01-16 12:41:09.789430: step 4628, loss = 0.70638 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:41:10.553114 ops/training.py:65 2019-01-16 12:41:10.553063: step 4629, loss = 0.69366 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:41:11.320633 ops/training.py:65 2019-01-16 12:41:11.320569: step 4630, loss = 0.69397 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:41:12.088548 ops/training.py:65 2019-01-16 12:41:12.088491: step 4631, loss = 0.69036 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:41:12.853905 ops/training.py:65 2019-01-16 12:41:12.853831: step 4632, loss = 0.69741 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:41:13.617768 ops/training.py:65 2019-01-16 12:41:13.617691: step 4633, loss = 0.69300 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:41:14.382387 ops/training.py:65 2019-01-16 12:41:14.382311: step 4634, loss = 0.68939 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:41:15.150903 ops/training.py:65 2019-01-16 12:41:15.150843: step 4635, loss = 0.69389 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:41:15.917351 ops/training.py:65 2019-01-16 12:41:15.917255: step 4636, loss = 0.69117 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:41:16.686529 ops/training.py:65 2019-01-16 12:41:16.686476: step 4637, loss = 0.69753 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:41:17.453677 ops/training.py:65 2019-01-16 12:41:17.453619: step 4638, loss = 0.69970 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:41:18.222334 ops/training.py:65 2019-01-16 12:41:18.222280: step 4639, loss = 0.70659 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:41:18.990411 ops/training.py:65 2019-01-16 12:41:18.990366: step 4640, loss = 0.70267 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:41:19.754792 ops/training.py:65 2019-01-16 12:41:19.754723: step 4641, loss = 0.68683 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:41:20.518563 ops/training.py:65 2019-01-16 12:41:20.518506: step 4642, loss = 0.69356 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:41:21.287405 ops/training.py:65 2019-01-16 12:41:21.287341: step 4643, loss = 0.68710 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:41:22.053940 ops/training.py:65 2019-01-16 12:41:22.053886: step 4644, loss = 0.70237 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:41:22.819401 ops/training.py:65 2019-01-16 12:41:22.819344: step 4645, loss = 0.70468 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:41:23.584349 ops/training.py:65 2019-01-16 12:41:23.584281: step 4646, loss = 0.70412 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:41:24.349252 ops/training.py:65 2019-01-16 12:41:24.349184: step 4647, loss = 0.69069 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:41:25.117310 ops/training.py:65 2019-01-16 12:41:25.117251: step 4648, loss = 0.68909 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:41:25.883602 ops/training.py:65 2019-01-16 12:41:25.883530: step 4649, loss = 0.69505 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:41:26.649501 ops/training.py:65 2019-01-16 12:41:26.649446: step 4650, loss = 0.69356 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:41:27.413867 ops/training.py:65 2019-01-16 12:41:27.413797: step 4651, loss = 0.69481 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:41:28.178220 ops/training.py:65 2019-01-16 12:41:28.178150: step 4652, loss = 0.69102 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:41:28.941786 ops/training.py:65 2019-01-16 12:41:28.941728: step 4653, loss = 0.67750 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:41:29.706627 ops/training.py:65 2019-01-16 12:41:29.706554: step 4654, loss = 0.68627 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:41:30.470608 ops/training.py:65 2019-01-16 12:41:30.470558: step 4655, loss = 0.69304 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:41:31.234629 ops/training.py:65 2019-01-16 12:41:31.234565: step 4656, loss = 0.69217 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:41:31.998340 ops/training.py:65 2019-01-16 12:41:31.998271: step 4657, loss = 0.70602 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:41:32.762085 ops/training.py:65 2019-01-16 12:41:32.762016: step 4658, loss = 0.69055 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:41:33.529634 ops/training.py:65 2019-01-16 12:41:33.529562: step 4659, loss = 0.69535 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:41:34.296779 ops/training.py:65 2019-01-16 12:41:34.296699: step 4660, loss = 0.69498 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:41:35.063062 ops/training.py:65 2019-01-16 12:41:35.062994: step 4661, loss = 0.70846 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:41:35.828364 ops/training.py:65 2019-01-16 12:41:35.828294: step 4662, loss = 0.69060 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:41:36.593672 ops/training.py:65 2019-01-16 12:41:36.593602: step 4663, loss = 0.69459 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:41:37.357829 ops/training.py:65 2019-01-16 12:41:37.357759: step 4664, loss = 0.69272 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:41:38.121625 ops/training.py:65 2019-01-16 12:41:38.121583: step 4665, loss = 0.69196 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:41:38.886064 ops/training.py:65 2019-01-16 12:41:38.885996: step 4666, loss = 0.70150 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:41:39.649422 ops/training.py:65 2019-01-16 12:41:39.649351: step 4667, loss = 0.69583 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:41:40.413763 ops/training.py:65 2019-01-16 12:41:40.413704: step 4668, loss = 0.69448 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:41:41.177953 ops/training.py:65 2019-01-16 12:41:41.177883: step 4669, loss = 0.69412 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:41:41.942234 ops/training.py:65 2019-01-16 12:41:41.942184: step 4670, loss = 0.68747 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:41:42.705698 ops/training.py:65 2019-01-16 12:41:42.705629: step 4671, loss = 0.69632 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:41:43.471868 ops/training.py:65 2019-01-16 12:41:43.471804: step 4672, loss = 0.70149 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:41:44.239304 ops/training.py:65 2019-01-16 12:41:44.239230: step 4673, loss = 0.70062 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:41:45.006852 ops/training.py:65 2019-01-16 12:41:45.006777: step 4674, loss = 0.70013 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:41:45.770257 ops/training.py:65 2019-01-16 12:41:45.770208: step 4675, loss = 0.68659 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:41:46.534318 ops/training.py:65 2019-01-16 12:41:46.534246: step 4676, loss = 0.68843 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:41:47.299766 ops/training.py:65 2019-01-16 12:41:47.299701: step 4677, loss = 0.69802 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:41:48.063959 ops/training.py:65 2019-01-16 12:41:48.063890: step 4678, loss = 0.69596 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:41:48.830825 ops/training.py:65 2019-01-16 12:41:48.830768: step 4679, loss = 0.69493 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:41:49.597843 ops/training.py:65 2019-01-16 12:41:49.597790: step 4680, loss = 0.69546 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:41:50.364289 ops/training.py:65 2019-01-16 12:41:50.364238: step 4681, loss = 0.68184 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:41:51.130784 ops/training.py:65 2019-01-16 12:41:51.130731: step 4682, loss = 0.68757 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:41:51.897816 ops/training.py:65 2019-01-16 12:41:51.897757: step 4683, loss = 0.69833 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:41:52.662405 ops/training.py:65 2019-01-16 12:41:52.662365: step 4684, loss = 0.69750 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:41:53.425982 ops/training.py:65 2019-01-16 12:41:53.425932: step 4685, loss = 0.69684 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:41:54.190221 ops/training.py:65 2019-01-16 12:41:54.190153: step 4686, loss = 0.68721 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:41:54.953791 ops/training.py:65 2019-01-16 12:41:54.953725: step 4687, loss = 0.69324 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:41:55.717886 ops/training.py:65 2019-01-16 12:41:55.717814: step 4688, loss = 0.68639 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:41:56.482498 ops/training.py:65 2019-01-16 12:41:56.482446: step 4689, loss = 0.69590 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:41:57.246127 ops/training.py:65 2019-01-16 12:41:57.246059: step 4690, loss = 0.68399 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:41:58.010526 ops/training.py:65 2019-01-16 12:41:58.010476: step 4691, loss = 0.69602 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:41:58.779458 ops/training.py:65 2019-01-16 12:41:58.779386: step 4692, loss = 0.69857 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:41:59.547390 ops/training.py:65 2019-01-16 12:41:59.547316: step 4693, loss = 0.69714 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:42:00.314395 ops/training.py:65 2019-01-16 12:42:00.314344: step 4694, loss = 0.68430 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:42:01.079113 ops/training.py:65 2019-01-16 12:42:01.079054: step 4695, loss = 0.68935 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:42:01.847170 ops/training.py:65 2019-01-16 12:42:01.847114: step 4696, loss = 0.69648 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:42:02.615875 ops/training.py:65 2019-01-16 12:42:02.615799: step 4697, loss = 0.69790 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:42:03.384453 ops/training.py:65 2019-01-16 12:42:03.384388: step 4698, loss = 0.70422 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:42:04.151129 ops/training.py:65 2019-01-16 12:42:04.151089: step 4699, loss = 0.69410 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:42:04.915198 ops/training.py:65 2019-01-16 12:42:04.915150: step 4700, loss = 0.68969 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:42:05.679618 ops/training.py:65 2019-01-16 12:42:05.679545: step 4701, loss = 0.69250 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:42:06.446833 ops/training.py:65 2019-01-16 12:42:06.446780: step 4702, loss = 0.69516 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:42:07.214829 ops/training.py:65 2019-01-16 12:42:07.214778: step 4703, loss = 0.69816 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:42:07.982143 ops/training.py:65 2019-01-16 12:42:07.982083: step 4704, loss = 0.71110 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:42:08.751489 ops/training.py:65 2019-01-16 12:42:08.751441: step 4705, loss = 0.69109 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:42:09.519180 ops/training.py:65 2019-01-16 12:42:09.519120: step 4706, loss = 0.70323 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:42:10.286547 ops/training.py:65 2019-01-16 12:42:10.286493: step 4707, loss = 0.71112 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:42:11.052460 ops/training.py:65 2019-01-16 12:42:11.052397: step 4708, loss = 0.68047 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:42:11.820612 ops/training.py:65 2019-01-16 12:42:11.820536: step 4709, loss = 0.70800 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:42:12.584144 ops/training.py:65 2019-01-16 12:42:12.584075: step 4710, loss = 0.68010 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:42:13.348221 ops/training.py:65 2019-01-16 12:42:13.348152: step 4711, loss = 0.68213 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:42:14.111685 ops/training.py:65 2019-01-16 12:42:14.111618: step 4712, loss = 0.68280 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:42:14.874743 ops/training.py:65 2019-01-16 12:42:14.874677: step 4713, loss = 0.70257 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:42:15.639219 ops/training.py:65 2019-01-16 12:42:15.639171: step 4714, loss = 0.69224 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:42:16.402648 ops/training.py:65 2019-01-16 12:42:16.402584: step 4715, loss = 0.69854 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:42:17.166257 ops/training.py:65 2019-01-16 12:42:17.166193: step 4716, loss = 0.69765 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:42:17.934883 ops/training.py:65 2019-01-16 12:42:17.934815: step 4717, loss = 0.69065 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:42:18.703269 ops/training.py:65 2019-01-16 12:42:18.703191: step 4718, loss = 0.69984 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:42:19.471404 ops/training.py:65 2019-01-16 12:42:19.471330: step 4719, loss = 0.68395 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:42:20.238698 ops/training.py:65 2019-01-16 12:42:20.238628: step 4720, loss = 0.69568 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:42:21.002748 ops/training.py:65 2019-01-16 12:42:21.002682: step 4721, loss = 0.68551 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:42:21.766833 ops/training.py:65 2019-01-16 12:42:21.766765: step 4722, loss = 0.67785 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:42:22.530272 ops/training.py:65 2019-01-16 12:42:22.530206: step 4723, loss = 0.68285 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:42:23.293054 ops/training.py:65 2019-01-16 12:42:23.293008: step 4724, loss = 0.69191 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:42:24.057246 ops/training.py:65 2019-01-16 12:42:24.057178: step 4725, loss = 0.67951 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:42:24.821875 ops/training.py:65 2019-01-16 12:42:24.821799: step 4726, loss = 0.68323 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:42:25.586674 ops/training.py:65 2019-01-16 12:42:25.586604: step 4727, loss = 0.69447 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:42:26.350692 ops/training.py:65 2019-01-16 12:42:26.350626: step 4728, loss = 0.69008 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:42:27.113551 ops/training.py:65 2019-01-16 12:42:27.113507: step 4729, loss = 0.70196 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:42:27.876884 ops/training.py:65 2019-01-16 12:42:27.876818: step 4730, loss = 0.68978 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:42:28.641296 ops/training.py:65 2019-01-16 12:42:28.641226: step 4731, loss = 0.69423 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:42:29.405376 ops/training.py:65 2019-01-16 12:42:29.405313: step 4732, loss = 0.69756 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:42:30.168365 ops/training.py:65 2019-01-16 12:42:30.168312: step 4733, loss = 0.69285 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:42:30.931837 ops/training.py:65 2019-01-16 12:42:30.931785: step 4734, loss = 0.69781 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:42:31.697751 ops/training.py:65 2019-01-16 12:42:31.697679: step 4735, loss = 0.68911 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:42:32.465527 ops/training.py:65 2019-01-16 12:42:32.465453: step 4736, loss = 0.69398 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:42:33.234510 ops/training.py:65 2019-01-16 12:42:33.234439: step 4737, loss = 0.69617 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:42:34.001986 ops/training.py:65 2019-01-16 12:42:34.001910: step 4738, loss = 0.69093 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:42:34.767117 ops/training.py:65 2019-01-16 12:42:34.767049: step 4739, loss = 0.68455 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:42:35.530645 ops/training.py:65 2019-01-16 12:42:35.530575: step 4740, loss = 0.70614 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:42:36.295318 ops/training.py:65 2019-01-16 12:42:36.295251: step 4741, loss = 0.69947 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:42:37.059329 ops/training.py:65 2019-01-16 12:42:37.059256: step 4742, loss = 0.69933 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:42:37.823259 ops/training.py:65 2019-01-16 12:42:37.823215: step 4743, loss = 0.69543 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:42:38.587147 ops/training.py:65 2019-01-16 12:42:38.587083: step 4744, loss = 0.69797 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:42:39.350726 ops/training.py:65 2019-01-16 12:42:39.350665: step 4745, loss = 0.70455 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:42:40.114944 ops/training.py:65 2019-01-16 12:42:40.114876: step 4746, loss = 0.68193 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:42:40.878750 ops/training.py:65 2019-01-16 12:42:40.878677: step 4747, loss = 0.70811 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:42:41.642720 ops/training.py:65 2019-01-16 12:42:41.642653: step 4748, loss = 0.70086 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:42:42.410138 ops/training.py:65 2019-01-16 12:42:42.410071: step 4749, loss = 0.69904 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:42:43.177306 ops/training.py:65 2019-01-16 12:42:43.177236: step 4750, loss = 0.69693 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:42:43.944184 ops/training.py:65 2019-01-16 12:42:43.944115: step 4751, loss = 0.70542 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:42:44.710619 ops/training.py:65 2019-01-16 12:42:44.710549: step 4752, loss = 0.68154 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:42:45.475716 ops/training.py:65 2019-01-16 12:42:45.475650: step 4753, loss = 0.68005 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:42:46.239834 ops/training.py:65 2019-01-16 12:42:46.239767: step 4754, loss = 0.69002 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:42:47.008662 ops/training.py:65 2019-01-16 12:42:47.008591: step 4755, loss = 0.69274 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:42:47.777258 ops/training.py:65 2019-01-16 12:42:47.777184: step 4756, loss = 0.67643 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 12:42:48.545783 ops/training.py:65 2019-01-16 12:42:48.545710: step 4757, loss = 0.69593 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:42:49.312674 ops/training.py:65 2019-01-16 12:42:49.312607: step 4758, loss = 0.70828 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:42:50.076934 ops/training.py:65 2019-01-16 12:42:50.076867: step 4759, loss = 0.68249 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:42:50.844622 ops/training.py:65 2019-01-16 12:42:50.844548: step 4760, loss = 0.68945 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:42:51.612789 ops/training.py:65 2019-01-16 12:42:51.612713: step 4761, loss = 0.69898 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:42:52.379212 ops/training.py:65 2019-01-16 12:42:52.379140: step 4762, loss = 0.69796 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:42:53.146801 ops/training.py:65 2019-01-16 12:42:53.146751: step 4763, loss = 0.67828 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:42:53.915224 ops/training.py:65 2019-01-16 12:42:53.915162: step 4764, loss = 0.69090 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:42:54.683909 ops/training.py:65 2019-01-16 12:42:54.683846: step 4765, loss = 0.69307 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:42:55.452965 ops/training.py:65 2019-01-16 12:42:55.452904: step 4766, loss = 0.67569 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:42:56.222438 ops/training.py:65 2019-01-16 12:42:56.222393: step 4767, loss = 0.69757 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:42:56.991470 ops/training.py:65 2019-01-16 12:42:56.991399: step 4768, loss = 0.69595 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:42:57.758100 ops/training.py:65 2019-01-16 12:42:57.758039: step 4769, loss = 0.68781 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:42:58.524602 ops/training.py:65 2019-01-16 12:42:58.524538: step 4770, loss = 0.70698 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:42:59.289086 ops/training.py:65 2019-01-16 12:42:59.289020: step 4771, loss = 0.68663 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:43:00.052739 ops/training.py:65 2019-01-16 12:43:00.052674: step 4772, loss = 0.68263 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:43:00.815513 ops/training.py:65 2019-01-16 12:43:00.815460: step 4773, loss = 0.67326 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:43:01.579359 ops/training.py:65 2019-01-16 12:43:01.579283: step 4774, loss = 0.69733 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:43:02.343292 ops/training.py:65 2019-01-16 12:43:02.343221: step 4775, loss = 0.70285 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:43:03.107478 ops/training.py:65 2019-01-16 12:43:03.107411: step 4776, loss = 0.67975 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:43:03.870698 ops/training.py:65 2019-01-16 12:43:03.870606: step 4777, loss = 0.68682 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:43:04.637847 ops/training.py:65 2019-01-16 12:43:04.637803: step 4778, loss = 0.68110 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:43:05.405574 ops/training.py:65 2019-01-16 12:43:05.405501: step 4779, loss = 0.70395 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:43:06.172899 ops/training.py:65 2019-01-16 12:43:06.172842: step 4780, loss = 0.69176 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:43:06.938110 ops/training.py:65 2019-01-16 12:43:06.938043: step 4781, loss = 0.70037 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:43:07.701190 ops/training.py:65 2019-01-16 12:43:07.701133: step 4782, loss = 0.69373 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:43:08.464198 ops/training.py:65 2019-01-16 12:43:08.464138: step 4783, loss = 0.69011 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:43:09.230372 ops/training.py:65 2019-01-16 12:43:09.230312: step 4784, loss = 0.70333 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:43:09.997212 ops/training.py:65 2019-01-16 12:43:09.997122: step 4785, loss = 0.68204 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 12:43:10.764224 ops/training.py:65 2019-01-16 12:43:10.764152: step 4786, loss = 0.70420 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:43:11.532483 ops/training.py:65 2019-01-16 12:43:11.532429: step 4787, loss = 0.68486 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:43:12.300250 ops/training.py:65 2019-01-16 12:43:12.300174: step 4788, loss = 0.68861 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:43:13.065964 ops/training.py:65 2019-01-16 12:43:13.065893: step 4789, loss = 0.70870 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 12:43:13.834430 ops/training.py:65 2019-01-16 12:43:13.834378: step 4790, loss = 0.69924 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:43:14.602314 ops/training.py:65 2019-01-16 12:43:14.602252: step 4791, loss = 0.70338 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:43:15.367567 ops/training.py:65 2019-01-16 12:43:15.367503: step 4792, loss = 0.69397 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:43:16.132007 ops/training.py:65 2019-01-16 12:43:16.131938: step 4793, loss = 0.70228 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:43:16.897375 ops/training.py:65 2019-01-16 12:43:16.897306: step 4794, loss = 0.69623 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:43:17.661017 ops/training.py:65 2019-01-16 12:43:17.660944: step 4795, loss = 0.70164 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:43:18.424329 ops/training.py:65 2019-01-16 12:43:18.424255: step 4796, loss = 0.69647 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:43:19.187261 ops/training.py:65 2019-01-16 12:43:19.187217: step 4797, loss = 0.69148 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:43:19.950786 ops/training.py:65 2019-01-16 12:43:19.950715: step 4798, loss = 0.67728 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:43:20.719200 ops/training.py:65 2019-01-16 12:43:20.719136: step 4799, loss = 0.69597 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:43:21.488451 ops/training.py:65 2019-01-16 12:43:21.488404: step 4800, loss = 0.69598 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:43:22.255398 ops/training.py:65 2019-01-16 12:43:22.255321: step 4801, loss = 0.70354 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:43:23.024437 ops/training.py:65 2019-01-16 12:43:23.024383: step 4802, loss = 0.69992 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:43:23.793218 ops/training.py:65 2019-01-16 12:43:23.793141: step 4803, loss = 0.69810 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:43:24.559921 ops/training.py:65 2019-01-16 12:43:24.559844: step 4804, loss = 0.69261 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:43:25.325037 ops/training.py:65 2019-01-16 12:43:25.324983: step 4805, loss = 0.69024 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:43:26.089494 ops/training.py:65 2019-01-16 12:43:26.089424: step 4806, loss = 0.68205 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 12:43:26.853594 ops/training.py:65 2019-01-16 12:43:26.853547: step 4807, loss = 0.69723 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:43:27.617300 ops/training.py:65 2019-01-16 12:43:27.617233: step 4808, loss = 0.68644 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:43:28.381083 ops/training.py:65 2019-01-16 12:43:28.381015: step 4809, loss = 0.70178 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:43:29.144221 ops/training.py:65 2019-01-16 12:43:29.144164: step 4810, loss = 0.69697 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:43:29.908162 ops/training.py:65 2019-01-16 12:43:29.908093: step 4811, loss = 0.70313 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:43:30.672688 ops/training.py:65 2019-01-16 12:43:30.672640: step 4812, loss = 0.70305 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:43:31.437570 ops/training.py:65 2019-01-16 12:43:31.437499: step 4813, loss = 0.70255 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:43:32.201602 ops/training.py:65 2019-01-16 12:43:32.201533: step 4814, loss = 0.69951 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:43:32.965427 ops/training.py:65 2019-01-16 12:43:32.965359: step 4815, loss = 0.68608 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:43:33.731235 ops/training.py:65 2019-01-16 12:43:33.731168: step 4816, loss = 0.69887 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:43:34.498024 ops/training.py:65 2019-01-16 12:43:34.497945: step 4817, loss = 0.69589 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:43:35.264158 ops/training.py:65 2019-01-16 12:43:35.264098: step 4818, loss = 0.68924 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:43:36.029677 ops/training.py:65 2019-01-16 12:43:36.029605: step 4819, loss = 0.69534 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:43:36.794932 ops/training.py:65 2019-01-16 12:43:36.794858: step 4820, loss = 0.68672 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:43:37.559656 ops/training.py:65 2019-01-16 12:43:37.559592: step 4821, loss = 0.70305 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:43:38.323678 ops/training.py:65 2019-01-16 12:43:38.323627: step 4822, loss = 0.70040 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:43:39.088011 ops/training.py:65 2019-01-16 12:43:39.087950: step 4823, loss = 0.68990 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:43:39.851168 ops/training.py:65 2019-01-16 12:43:39.851100: step 4824, loss = 0.69979 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:43:40.614294 ops/training.py:65 2019-01-16 12:43:40.614240: step 4825, loss = 0.69471 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:43:41.378203 ops/training.py:65 2019-01-16 12:43:41.378143: step 4826, loss = 0.68303 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:43:42.142057 ops/training.py:65 2019-01-16 12:43:42.142005: step 4827, loss = 0.68619 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:43:42.905134 ops/training.py:65 2019-01-16 12:43:42.905062: step 4828, loss = 0.70529 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:43:43.669529 ops/training.py:65 2019-01-16 12:43:43.669452: step 4829, loss = 0.68725 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:43:44.434386 ops/training.py:65 2019-01-16 12:43:44.434313: step 4830, loss = 0.69003 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:43:45.197906 ops/training.py:65 2019-01-16 12:43:45.197855: step 4831, loss = 0.70012 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:43:45.961447 ops/training.py:65 2019-01-16 12:43:45.961390: step 4832, loss = 0.69125 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:43:46.725539 ops/training.py:65 2019-01-16 12:43:46.725469: step 4833, loss = 0.69345 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:43:47.489931 ops/training.py:65 2019-01-16 12:43:47.489865: step 4834, loss = 0.69395 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:43:48.253675 ops/training.py:65 2019-01-16 12:43:48.253608: step 4835, loss = 0.69732 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:43:49.017765 ops/training.py:65 2019-01-16 12:43:49.017723: step 4836, loss = 0.69284 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:43:49.785813 ops/training.py:65 2019-01-16 12:43:49.785748: step 4837, loss = 0.69012 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:43:50.554430 ops/training.py:65 2019-01-16 12:43:50.554360: step 4838, loss = 0.69572 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:43:51.323907 ops/training.py:65 2019-01-16 12:43:51.323841: step 4839, loss = 0.68820 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:43:52.091155 ops/training.py:65 2019-01-16 12:43:52.091089: step 4840, loss = 0.69589 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:43:52.857780 ops/training.py:65 2019-01-16 12:43:52.857734: step 4841, loss = 0.70377 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:43:53.624989 ops/training.py:65 2019-01-16 12:43:53.624912: step 4842, loss = 0.68997 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:43:54.391312 ops/training.py:65 2019-01-16 12:43:54.391243: step 4843, loss = 0.70194 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:43:55.156597 ops/training.py:65 2019-01-16 12:43:55.156531: step 4844, loss = 0.69234 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:43:55.921094 ops/training.py:65 2019-01-16 12:43:55.921026: step 4845, loss = 0.70425 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:43:56.684868 ops/training.py:65 2019-01-16 12:43:56.684819: step 4846, loss = 0.68343 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:43:57.448275 ops/training.py:65 2019-01-16 12:43:57.448207: step 4847, loss = 0.69953 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:43:58.211723 ops/training.py:65 2019-01-16 12:43:58.211658: step 4848, loss = 0.69258 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:43:58.975996 ops/training.py:65 2019-01-16 12:43:58.975933: step 4849, loss = 0.69059 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:43:59.739926 ops/training.py:65 2019-01-16 12:43:59.739857: step 4850, loss = 0.69413 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:44:00.504113 ops/training.py:65 2019-01-16 12:44:00.504066: step 4851, loss = 0.69519 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:44:01.267472 ops/training.py:65 2019-01-16 12:44:01.267400: step 4852, loss = 0.68713 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:44:02.031641 ops/training.py:65 2019-01-16 12:44:02.031580: step 4853, loss = 0.69202 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:44:02.796157 ops/training.py:65 2019-01-16 12:44:02.796094: step 4854, loss = 0.69557 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:44:03.564546 ops/training.py:65 2019-01-16 12:44:03.564475: step 4855, loss = 0.69072 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:44:04.332371 ops/training.py:65 2019-01-16 12:44:04.332296: step 4856, loss = 0.69362 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:44:05.099597 ops/training.py:65 2019-01-16 12:44:05.099526: step 4857, loss = 0.68924 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:44:05.864757 ops/training.py:65 2019-01-16 12:44:05.864688: step 4858, loss = 0.69990 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 12:44:06.630089 ops/training.py:65 2019-01-16 12:44:06.630024: step 4859, loss = 0.69903 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:44:07.397208 ops/training.py:65 2019-01-16 12:44:07.397138: step 4860, loss = 0.70228 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:44:08.165211 ops/training.py:65 2019-01-16 12:44:08.165153: step 4861, loss = 0.69604 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:44:08.932089 ops/training.py:65 2019-01-16 12:44:08.932034: step 4862, loss = 0.69810 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:44:09.699654 ops/training.py:65 2019-01-16 12:44:09.699590: step 4863, loss = 0.69247 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:44:10.467242 ops/training.py:65 2019-01-16 12:44:10.467185: step 4864, loss = 0.68911 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:44:11.233546 ops/training.py:65 2019-01-16 12:44:11.233488: step 4865, loss = 0.69242 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:44:11.998833 ops/training.py:65 2019-01-16 12:44:11.998757: step 4866, loss = 0.69212 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:44:12.764697 ops/training.py:65 2019-01-16 12:44:12.764628: step 4867, loss = 0.69068 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:44:13.533320 ops/training.py:65 2019-01-16 12:44:13.533243: step 4868, loss = 0.69257 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:44:14.297933 ops/training.py:65 2019-01-16 12:44:14.297859: step 4869, loss = 0.69329 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:44:15.062081 ops/training.py:65 2019-01-16 12:44:15.062015: step 4870, loss = 0.69432 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:44:15.825823 ops/training.py:65 2019-01-16 12:44:15.825773: step 4871, loss = 0.68952 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:44:16.589730 ops/training.py:65 2019-01-16 12:44:16.589660: step 4872, loss = 0.70033 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:44:17.353101 ops/training.py:65 2019-01-16 12:44:17.353030: step 4873, loss = 0.68912 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:44:18.117095 ops/training.py:65 2019-01-16 12:44:18.117027: step 4874, loss = 0.68724 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:44:18.883350 ops/training.py:65 2019-01-16 12:44:18.883289: step 4875, loss = 0.70400 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:44:19.650949 ops/training.py:65 2019-01-16 12:44:19.650871: step 4876, loss = 0.69764 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:44:20.417648 ops/training.py:65 2019-01-16 12:44:20.417593: step 4877, loss = 0.68376 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:44:21.181640 ops/training.py:65 2019-01-16 12:44:21.181574: step 4878, loss = 0.68493 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:44:21.946464 ops/training.py:65 2019-01-16 12:44:21.946397: step 4879, loss = 0.68693 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:44:22.710545 ops/training.py:65 2019-01-16 12:44:22.710505: step 4880, loss = 0.69703 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:44:23.474096 ops/training.py:65 2019-01-16 12:44:23.474028: step 4881, loss = 0.70148 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:44:24.239079 ops/training.py:65 2019-01-16 12:44:24.239009: step 4882, loss = 0.70192 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:44:25.003282 ops/training.py:65 2019-01-16 12:44:25.003216: step 4883, loss = 0.69471 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:44:25.767540 ops/training.py:65 2019-01-16 12:44:25.767470: step 4884, loss = 0.69092 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:44:26.531616 ops/training.py:65 2019-01-16 12:44:26.531565: step 4885, loss = 0.69776 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:44:27.295062 ops/training.py:65 2019-01-16 12:44:27.294998: step 4886, loss = 0.68693 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:44:28.059457 ops/training.py:65 2019-01-16 12:44:28.059392: step 4887, loss = 0.68835 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:44:28.823365 ops/training.py:65 2019-01-16 12:44:28.823295: step 4888, loss = 0.69208 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:44:29.587892 ops/training.py:65 2019-01-16 12:44:29.587827: step 4889, loss = 0.68968 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:44:30.352734 ops/training.py:65 2019-01-16 12:44:30.352685: step 4890, loss = 0.69849 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:44:31.116703 ops/training.py:65 2019-01-16 12:44:31.116637: step 4891, loss = 0.69684 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:44:31.884667 ops/training.py:65 2019-01-16 12:44:31.884599: step 4892, loss = 0.69569 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:44:32.653583 ops/training.py:65 2019-01-16 12:44:32.653510: step 4893, loss = 0.69661 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:44:33.421808 ops/training.py:65 2019-01-16 12:44:33.421737: step 4894, loss = 0.70197 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:44:34.187492 ops/training.py:65 2019-01-16 12:44:34.187443: step 4895, loss = 0.69049 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:44:34.951613 ops/training.py:65 2019-01-16 12:44:34.951543: step 4896, loss = 0.70506 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:44:35.716778 ops/training.py:65 2019-01-16 12:44:35.716708: step 4897, loss = 0.69293 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:44:36.480849 ops/training.py:65 2019-01-16 12:44:36.480775: step 4898, loss = 0.69794 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:44:37.244131 ops/training.py:65 2019-01-16 12:44:37.244066: step 4899, loss = 0.68946 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:44:38.008860 ops/training.py:65 2019-01-16 12:44:38.008816: step 4900, loss = 0.69138 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:44:38.776410 ops/training.py:65 2019-01-16 12:44:38.776346: step 4901, loss = 0.67992 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:44:39.546338 ops/training.py:65 2019-01-16 12:44:39.546271: step 4902, loss = 0.69134 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:44:40.313452 ops/training.py:65 2019-01-16 12:44:40.313392: step 4903, loss = 0.70511 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 12:44:41.079823 ops/training.py:65 2019-01-16 12:44:41.079755: step 4904, loss = 0.68996 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:44:41.846390 ops/training.py:65 2019-01-16 12:44:41.846313: step 4905, loss = 0.69689 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:44:42.610996 ops/training.py:65 2019-01-16 12:44:42.610927: step 4906, loss = 0.69205 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:44:43.375108 ops/training.py:65 2019-01-16 12:44:43.375038: step 4907, loss = 0.67713 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:44:44.140366 ops/training.py:65 2019-01-16 12:44:44.140301: step 4908, loss = 0.69678 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:44:44.904597 ops/training.py:65 2019-01-16 12:44:44.904554: step 4909, loss = 0.69567 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:44:45.668750 ops/training.py:65 2019-01-16 12:44:45.668702: step 4910, loss = 0.67697 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 12:44:46.432404 ops/training.py:65 2019-01-16 12:44:46.432338: step 4911, loss = 0.70017 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:44:47.196499 ops/training.py:65 2019-01-16 12:44:47.196429: step 4912, loss = 0.69190 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:44:47.960540 ops/training.py:65 2019-01-16 12:44:47.960469: step 4913, loss = 0.70078 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:44:48.726642 ops/training.py:65 2019-01-16 12:44:48.726587: step 4914, loss = 0.69733 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:44:49.495859 ops/training.py:65 2019-01-16 12:44:49.495784: step 4915, loss = 0.69791 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:44:50.262409 ops/training.py:65 2019-01-16 12:44:50.262341: step 4916, loss = 0.69460 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:44:51.026867 ops/training.py:65 2019-01-16 12:44:51.026800: step 4917, loss = 0.69481 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:44:51.790199 ops/training.py:65 2019-01-16 12:44:51.790131: step 4918, loss = 0.68948 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:44:52.552951 ops/training.py:65 2019-01-16 12:44:52.552902: step 4919, loss = 0.68593 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:44:53.316431 ops/training.py:65 2019-01-16 12:44:53.316357: step 4920, loss = 0.68698 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:44:54.080411 ops/training.py:65 2019-01-16 12:44:54.080340: step 4921, loss = 0.68717 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:44:54.847316 ops/training.py:65 2019-01-16 12:44:54.847248: step 4922, loss = 0.69065 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:44:55.615564 ops/training.py:65 2019-01-16 12:44:55.615492: step 4923, loss = 0.69543 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:44:56.382033 ops/training.py:65 2019-01-16 12:44:56.381982: step 4924, loss = 0.69164 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:44:57.145670 ops/training.py:65 2019-01-16 12:44:57.145600: step 4925, loss = 0.69215 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:44:57.909635 ops/training.py:65 2019-01-16 12:44:57.909562: step 4926, loss = 0.70125 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:44:58.674283 ops/training.py:65 2019-01-16 12:44:58.674213: step 4927, loss = 0.69105 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:44:59.438616 ops/training.py:65 2019-01-16 12:44:59.438549: step 4928, loss = 0.70028 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:45:00.202373 ops/training.py:65 2019-01-16 12:45:00.202322: step 4929, loss = 0.68381 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:45:00.966935 ops/training.py:65 2019-01-16 12:45:00.966853: step 4930, loss = 0.69537 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:45:01.730831 ops/training.py:65 2019-01-16 12:45:01.730763: step 4931, loss = 0.69587 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:45:02.495033 ops/training.py:65 2019-01-16 12:45:02.494965: step 4932, loss = 0.68977 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:45:03.259111 ops/training.py:65 2019-01-16 12:45:03.259041: step 4933, loss = 0.69560 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:45:04.023415 ops/training.py:65 2019-01-16 12:45:04.023360: step 4934, loss = 0.69206 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:45:04.787308 ops/training.py:65 2019-01-16 12:45:04.787237: step 4935, loss = 0.69782 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:45:05.550377 ops/training.py:65 2019-01-16 12:45:05.550310: step 4936, loss = 0.69727 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:45:06.314206 ops/training.py:65 2019-01-16 12:45:06.314141: step 4937, loss = 0.69134 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:45:07.081853 ops/training.py:65 2019-01-16 12:45:07.081787: step 4938, loss = 0.69127 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:45:07.848868 ops/training.py:65 2019-01-16 12:45:07.848817: step 4939, loss = 0.68971 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:45:08.617736 ops/training.py:65 2019-01-16 12:45:08.617662: step 4940, loss = 0.69804 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:45:09.384882 ops/training.py:65 2019-01-16 12:45:09.384813: step 4941, loss = 0.69680 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:45:10.150090 ops/training.py:65 2019-01-16 12:45:10.150024: step 4942, loss = 0.69586 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:45:10.914477 ops/training.py:65 2019-01-16 12:45:10.914405: step 4943, loss = 0.69604 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:45:11.679994 ops/training.py:65 2019-01-16 12:45:11.679917: step 4944, loss = 0.69487 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:45:12.444765 ops/training.py:65 2019-01-16 12:45:12.444696: step 4945, loss = 0.69036 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:45:13.209005 ops/training.py:65 2019-01-16 12:45:13.208940: step 4946, loss = 0.69054 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:45:13.973052 ops/training.py:65 2019-01-16 12:45:13.972986: step 4947, loss = 0.69230 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:45:14.737095 ops/training.py:65 2019-01-16 12:45:14.737042: step 4948, loss = 0.69973 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:45:15.501314 ops/training.py:65 2019-01-16 12:45:15.501264: step 4949, loss = 0.69018 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:45:16.265266 ops/training.py:65 2019-01-16 12:45:16.265199: step 4950, loss = 0.69350 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:45:17.029725 ops/training.py:65 2019-01-16 12:45:17.029658: step 4951, loss = 0.69375 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:45:17.794359 ops/training.py:65 2019-01-16 12:45:17.794297: step 4952, loss = 0.68595 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:45:18.558429 ops/training.py:65 2019-01-16 12:45:18.558384: step 4953, loss = 0.69299 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:45:19.322650 ops/training.py:65 2019-01-16 12:45:19.322591: step 4954, loss = 0.68196 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.75
I0528 2019-01-16 12:45:20.087263 ops/training.py:65 2019-01-16 12:45:20.087198: step 4955, loss = 0.69814 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 12:45:20.850876 ops/training.py:65 2019-01-16 12:45:20.850809: step 4956, loss = 0.69843 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:45:21.614679 ops/training.py:65 2019-01-16 12:45:21.614612: step 4957, loss = 0.69308 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:45:22.377934 ops/training.py:65 2019-01-16 12:45:22.377888: step 4958, loss = 0.68799 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:45:23.144739 ops/training.py:65 2019-01-16 12:45:23.144692: step 4959, loss = 0.69043 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:45:23.913009 ops/training.py:65 2019-01-16 12:45:23.912937: step 4960, loss = 0.69100 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:45:24.680669 ops/training.py:65 2019-01-16 12:45:24.680598: step 4961, loss = 0.69489 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:45:25.447820 ops/training.py:65 2019-01-16 12:45:25.447750: step 4962, loss = 0.69377 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:45:26.213786 ops/training.py:65 2019-01-16 12:45:26.213739: step 4963, loss = 0.69549 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:45:26.977913 ops/training.py:65 2019-01-16 12:45:26.977847: step 4964, loss = 0.69722 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:45:27.742372 ops/training.py:65 2019-01-16 12:45:27.742305: step 4965, loss = 0.67825 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 12:45:28.506256 ops/training.py:65 2019-01-16 12:45:28.506191: step 4966, loss = 0.70146 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:45:29.270833 ops/training.py:65 2019-01-16 12:45:29.270768: step 4967, loss = 0.68944 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:45:30.035669 ops/training.py:65 2019-01-16 12:45:30.035621: step 4968, loss = 0.68857 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:45:30.799606 ops/training.py:65 2019-01-16 12:45:30.799539: step 4969, loss = 0.69604 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:45:31.563277 ops/training.py:65 2019-01-16 12:45:31.563210: step 4970, loss = 0.69128 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:45:32.327151 ops/training.py:65 2019-01-16 12:45:32.327085: step 4971, loss = 0.69331 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:45:33.091019 ops/training.py:65 2019-01-16 12:45:33.090956: step 4972, loss = 0.69355 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:45:33.856745 ops/training.py:65 2019-01-16 12:45:33.856693: step 4973, loss = 0.68525 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:45:34.625013 ops/training.py:65 2019-01-16 12:45:34.624942: step 4974, loss = 0.69530 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:45:35.393458 ops/training.py:65 2019-01-16 12:45:35.393384: step 4975, loss = 0.69164 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:45:36.160903 ops/training.py:65 2019-01-16 12:45:36.160828: step 4976, loss = 0.68586 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:45:36.926830 ops/training.py:65 2019-01-16 12:45:36.926763: step 4977, loss = 0.69337 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:45:37.691315 ops/training.py:65 2019-01-16 12:45:37.691276: step 4978, loss = 0.69924 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:45:38.455507 ops/training.py:65 2019-01-16 12:45:38.455437: step 4979, loss = 0.68526 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:45:39.219673 ops/training.py:65 2019-01-16 12:45:39.219614: step 4980, loss = 0.69719 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:45:39.984204 ops/training.py:65 2019-01-16 12:45:39.984136: step 4981, loss = 0.69225 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:45:40.747801 ops/training.py:65 2019-01-16 12:45:40.747744: step 4982, loss = 0.68573 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:45:41.512178 ops/training.py:65 2019-01-16 12:45:41.512126: step 4983, loss = 0.69028 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:45:42.276255 ops/training.py:65 2019-01-16 12:45:42.276190: step 4984, loss = 0.69438 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:45:43.040671 ops/training.py:65 2019-01-16 12:45:43.040607: step 4985, loss = 0.69694 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:45:43.805103 ops/training.py:65 2019-01-16 12:45:43.805034: step 4986, loss = 0.69641 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:45:44.570182 ops/training.py:65 2019-01-16 12:45:44.570131: step 4987, loss = 0.69293 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:45:45.333326 ops/training.py:65 2019-01-16 12:45:45.333277: step 4988, loss = 0.69604 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:45:46.096577 ops/training.py:65 2019-01-16 12:45:46.096520: step 4989, loss = 0.69777 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:45:46.860796 ops/training.py:65 2019-01-16 12:45:46.860724: step 4990, loss = 0.68290 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.75
I0528 2019-01-16 12:45:47.624567 ops/training.py:65 2019-01-16 12:45:47.624496: step 4991, loss = 0.69267 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:45:48.388179 ops/training.py:65 2019-01-16 12:45:48.388123: step 4992, loss = 0.69793 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:45:49.151869 ops/training.py:65 2019-01-16 12:45:49.151813: step 4993, loss = 0.69552 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:45:49.920238 ops/training.py:65 2019-01-16 12:45:49.920168: step 4994, loss = 0.68841 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:45:50.688444 ops/training.py:65 2019-01-16 12:45:50.688368: step 4995, loss = 0.68750 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:45:51.457177 ops/training.py:65 2019-01-16 12:45:51.457099: step 4996, loss = 0.69431 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:45:52.224023 ops/training.py:65 2019-01-16 12:45:52.223947: step 4997, loss = 0.69795 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 12:45:52.990320 ops/training.py:65 2019-01-16 12:45:52.990263: step 4998, loss = 0.69736 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:45:53.756408 ops/training.py:65 2019-01-16 12:45:53.756350: step 4999, loss = 0.69500 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:45:54.521692 ops/training.py:65 2019-01-16 12:45:54.521636: step 5000, loss = 0.68087 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:45:55.285582 ops/training.py:65 2019-01-16 12:45:55.285517: step 5001, loss = 0.69444 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:45:56.049611 ops/training.py:65 2019-01-16 12:45:56.049563: step 5002, loss = 0.69660 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:45:56.814299 ops/training.py:65 2019-01-16 12:45:56.814232: step 5003, loss = 0.68370 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 12:45:57.581010 ops/training.py:65 2019-01-16 12:45:57.580938: step 5004, loss = 0.68704 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:45:58.348203 ops/training.py:65 2019-01-16 12:45:58.348129: step 5005, loss = 0.70026 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:45:59.117437 ops/training.py:65 2019-01-16 12:45:59.117372: step 5006, loss = 0.69518 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:45:59.885882 ops/training.py:65 2019-01-16 12:45:59.885811: step 5007, loss = 0.69743 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:46:00.654153 ops/training.py:65 2019-01-16 12:46:00.654081: step 5008, loss = 0.69079 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:46:01.422382 ops/training.py:65 2019-01-16 12:46:01.422307: step 5009, loss = 0.69128 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:46:02.190205 ops/training.py:65 2019-01-16 12:46:02.190131: step 5010, loss = 0.68979 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:46:02.957918 ops/training.py:65 2019-01-16 12:46:02.957843: step 5011, loss = 0.68187 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:46:03.725890 ops/training.py:65 2019-01-16 12:46:03.725829: step 5012, loss = 0.69070 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:46:04.491982 ops/training.py:65 2019-01-16 12:46:04.491917: step 5013, loss = 0.70127 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:46:05.259451 ops/training.py:65 2019-01-16 12:46:05.259373: step 5014, loss = 0.69298 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:46:06.026647 ops/training.py:65 2019-01-16 12:46:06.026573: step 5015, loss = 0.69236 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:46:06.793856 ops/training.py:65 2019-01-16 12:46:06.793784: step 5016, loss = 0.70135 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:46:07.559227 ops/training.py:65 2019-01-16 12:46:07.559175: step 5017, loss = 0.68343 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:46:08.323719 ops/training.py:65 2019-01-16 12:46:08.323652: step 5018, loss = 0.70211 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:46:09.088376 ops/training.py:65 2019-01-16 12:46:09.088316: step 5019, loss = 0.68574 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:46:09.855861 ops/training.py:65 2019-01-16 12:46:09.855797: step 5020, loss = 0.69604 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:46:10.624071 ops/training.py:65 2019-01-16 12:46:10.624011: step 5021, loss = 0.68638 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:46:11.391691 ops/training.py:65 2019-01-16 12:46:11.391617: step 5022, loss = 0.69714 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:46:12.156913 ops/training.py:65 2019-01-16 12:46:12.156839: step 5023, loss = 0.68985 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:46:12.920514 ops/training.py:65 2019-01-16 12:46:12.920444: step 5024, loss = 0.70467 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:46:13.684709 ops/training.py:65 2019-01-16 12:46:13.684638: step 5025, loss = 0.69912 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:46:14.449221 ops/training.py:65 2019-01-16 12:46:14.449155: step 5026, loss = 0.68449 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:46:15.212298 ops/training.py:65 2019-01-16 12:46:15.212251: step 5027, loss = 0.69842 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:46:15.976179 ops/training.py:65 2019-01-16 12:46:15.976105: step 5028, loss = 0.69927 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:46:16.739676 ops/training.py:65 2019-01-16 12:46:16.739607: step 5029, loss = 0.69357 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:46:17.503019 ops/training.py:65 2019-01-16 12:46:17.502954: step 5030, loss = 0.68857 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:46:18.267129 ops/training.py:65 2019-01-16 12:46:18.267080: step 5031, loss = 0.68990 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:46:19.031106 ops/training.py:65 2019-01-16 12:46:19.031062: step 5032, loss = 0.69382 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:46:19.794911 ops/training.py:65 2019-01-16 12:46:19.794845: step 5033, loss = 0.68372 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:46:20.558936 ops/training.py:65 2019-01-16 12:46:20.558869: step 5034, loss = 0.70095 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:46:21.322996 ops/training.py:65 2019-01-16 12:46:21.322928: step 5035, loss = 0.70886 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:46:22.087103 ops/training.py:65 2019-01-16 12:46:22.087060: step 5036, loss = 0.68587 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:46:22.850374 ops/training.py:65 2019-01-16 12:46:22.850333: step 5037, loss = 0.69138 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:46:23.617086 ops/training.py:65 2019-01-16 12:46:23.617012: step 5038, loss = 0.69474 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:46:24.384603 ops/training.py:65 2019-01-16 12:46:24.384527: step 5039, loss = 0.69340 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:46:25.151786 ops/training.py:65 2019-01-16 12:46:25.151717: step 5040, loss = 0.69460 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:46:25.916521 ops/training.py:65 2019-01-16 12:46:25.916473: step 5041, loss = 0.69347 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:46:26.682557 ops/training.py:65 2019-01-16 12:46:26.682488: step 5042, loss = 0.69405 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:46:27.451092 ops/training.py:65 2019-01-16 12:46:27.451019: step 5043, loss = 0.69189 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:46:28.217932 ops/training.py:65 2019-01-16 12:46:28.217862: step 5044, loss = 0.69762 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:46:28.984449 ops/training.py:65 2019-01-16 12:46:28.984391: step 5045, loss = 0.68722 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:46:29.747369 ops/training.py:65 2019-01-16 12:46:29.747323: step 5046, loss = 0.68913 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:46:30.511424 ops/training.py:65 2019-01-16 12:46:30.511358: step 5047, loss = 0.69449 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:46:31.274854 ops/training.py:65 2019-01-16 12:46:31.274787: step 5048, loss = 0.69630 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:46:32.038662 ops/training.py:65 2019-01-16 12:46:32.038596: step 5049, loss = 0.69105 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:46:32.802043 ops/training.py:65 2019-01-16 12:46:32.801976: step 5050, loss = 0.69150 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:46:33.566557 ops/training.py:65 2019-01-16 12:46:33.566507: step 5051, loss = 0.69126 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:46:34.331222 ops/training.py:65 2019-01-16 12:46:34.331150: step 5052, loss = 0.69628 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:46:35.098087 ops/training.py:65 2019-01-16 12:46:35.098017: step 5053, loss = 0.69104 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:46:35.866192 ops/training.py:65 2019-01-16 12:46:35.866131: step 5054, loss = 0.70079 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:46:36.633175 ops/training.py:65 2019-01-16 12:46:36.633106: step 5055, loss = 0.69641 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:46:37.401517 ops/training.py:65 2019-01-16 12:46:37.401447: step 5056, loss = 0.70050 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:46:38.168258 ops/training.py:65 2019-01-16 12:46:38.168215: step 5057, loss = 0.68484 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:46:38.932351 ops/training.py:65 2019-01-16 12:46:38.932283: step 5058, loss = 0.69280 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:46:39.697440 ops/training.py:65 2019-01-16 12:46:39.697385: step 5059, loss = 0.70371 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:46:40.462134 ops/training.py:65 2019-01-16 12:46:40.462077: step 5060, loss = 0.70015 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:46:41.226454 ops/training.py:65 2019-01-16 12:46:41.226398: step 5061, loss = 0.68717 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:46:41.992288 ops/training.py:65 2019-01-16 12:46:41.992230: step 5062, loss = 0.70146 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:46:42.757384 ops/training.py:65 2019-01-16 12:46:42.757309: step 5063, loss = 0.69641 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:46:43.522506 ops/training.py:65 2019-01-16 12:46:43.522430: step 5064, loss = 0.68453 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:46:44.286912 ops/training.py:65 2019-01-16 12:46:44.286843: step 5065, loss = 0.69666 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:46:45.051030 ops/training.py:65 2019-01-16 12:46:45.050957: step 5066, loss = 0.70323 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:46:45.815317 ops/training.py:65 2019-01-16 12:46:45.815260: step 5067, loss = 0.69040 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:46:46.580226 ops/training.py:65 2019-01-16 12:46:46.580171: step 5068, loss = 0.69864 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:46:47.345539 ops/training.py:65 2019-01-16 12:46:47.345480: step 5069, loss = 0.69823 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:46:48.108976 ops/training.py:65 2019-01-16 12:46:48.108916: step 5070, loss = 0.69509 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:46:48.875763 ops/training.py:65 2019-01-16 12:46:48.875713: step 5071, loss = 0.69227 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:46:49.643278 ops/training.py:65 2019-01-16 12:46:49.643210: step 5072, loss = 0.68906 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:46:50.410840 ops/training.py:65 2019-01-16 12:46:50.410769: step 5073, loss = 0.69691 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:46:51.179168 ops/training.py:65 2019-01-16 12:46:51.179097: step 5074, loss = 0.70402 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.21875
I0528 2019-01-16 12:46:51.946824 ops/training.py:65 2019-01-16 12:46:51.946763: step 5075, loss = 0.69340 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:46:52.711890 ops/training.py:65 2019-01-16 12:46:52.711833: step 5076, loss = 0.69439 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:46:53.476605 ops/training.py:65 2019-01-16 12:46:53.476539: step 5077, loss = 0.69693 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:46:54.241179 ops/training.py:65 2019-01-16 12:46:54.241115: step 5078, loss = 0.68495 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:46:55.005652 ops/training.py:65 2019-01-16 12:46:55.005589: step 5079, loss = 0.68649 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:46:55.769467 ops/training.py:65 2019-01-16 12:46:55.769408: step 5080, loss = 0.68978 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:46:56.533418 ops/training.py:65 2019-01-16 12:46:56.533363: step 5081, loss = 0.69519 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:46:57.297966 ops/training.py:65 2019-01-16 12:46:57.297894: step 5082, loss = 0.70054 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:46:58.062766 ops/training.py:65 2019-01-16 12:46:58.062697: step 5083, loss = 0.69691 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:46:58.827685 ops/training.py:65 2019-01-16 12:46:58.827615: step 5084, loss = 0.69541 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:46:59.591509 ops/training.py:65 2019-01-16 12:46:59.591464: step 5085, loss = 0.69253 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:47:00.355506 ops/training.py:65 2019-01-16 12:47:00.355443: step 5086, loss = 0.69112 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:47:01.119541 ops/training.py:65 2019-01-16 12:47:01.119489: step 5087, loss = 0.69869 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:47:01.888770 ops/training.py:65 2019-01-16 12:47:01.888714: step 5088, loss = 0.68997 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:47:02.656464 ops/training.py:65 2019-01-16 12:47:02.656415: step 5089, loss = 0.69173 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:47:03.423117 ops/training.py:65 2019-01-16 12:47:03.423055: step 5090, loss = 0.69629 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:47:04.187456 ops/training.py:65 2019-01-16 12:47:04.187389: step 5091, loss = 0.69947 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:47:04.953519 ops/training.py:65 2019-01-16 12:47:04.953458: step 5092, loss = 0.69564 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:47:05.722798 ops/training.py:65 2019-01-16 12:47:05.722735: step 5093, loss = 0.69408 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:47:06.489965 ops/training.py:65 2019-01-16 12:47:06.489896: step 5094, loss = 0.69631 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:47:07.256511 ops/training.py:65 2019-01-16 12:47:07.256459: step 5095, loss = 0.69425 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:47:08.023282 ops/training.py:65 2019-01-16 12:47:08.023208: step 5096, loss = 0.69940 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:47:08.788670 ops/training.py:65 2019-01-16 12:47:08.788600: step 5097, loss = 0.69786 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:47:09.555600 ops/training.py:65 2019-01-16 12:47:09.555522: step 5098, loss = 0.69531 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:47:10.323450 ops/training.py:65 2019-01-16 12:47:10.323379: step 5099, loss = 0.69861 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:47:11.087452 ops/training.py:65 2019-01-16 12:47:11.087398: step 5100, loss = 0.69815 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:47:11.855856 ops/training.py:65 2019-01-16 12:47:11.855784: step 5101, loss = 0.68837 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:47:12.623825 ops/training.py:65 2019-01-16 12:47:12.623755: step 5102, loss = 0.68493 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:47:13.389066 ops/training.py:65 2019-01-16 12:47:13.388996: step 5103, loss = 0.68781 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:47:14.153271 ops/training.py:65 2019-01-16 12:47:14.153206: step 5104, loss = 0.69585 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:47:14.916603 ops/training.py:65 2019-01-16 12:47:14.916554: step 5105, loss = 0.69380 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:47:15.680362 ops/training.py:65 2019-01-16 12:47:15.680294: step 5106, loss = 0.69217 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:47:16.444165 ops/training.py:65 2019-01-16 12:47:16.444102: step 5107, loss = 0.68735 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:47:17.208008 ops/training.py:65 2019-01-16 12:47:17.207946: step 5108, loss = 0.69526 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:47:17.971508 ops/training.py:65 2019-01-16 12:47:17.971451: step 5109, loss = 0.68899 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:47:18.735047 ops/training.py:65 2019-01-16 12:47:18.734995: step 5110, loss = 0.68835 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:47:19.498031 ops/training.py:65 2019-01-16 12:47:19.497973: step 5111, loss = 0.68600 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:47:20.261395 ops/training.py:65 2019-01-16 12:47:20.261327: step 5112, loss = 0.68402 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:47:21.024059 ops/training.py:65 2019-01-16 12:47:21.023989: step 5113, loss = 0.69226 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:47:21.791606 ops/training.py:65 2019-01-16 12:47:21.791558: step 5114, loss = 0.69632 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:47:22.558891 ops/training.py:65 2019-01-16 12:47:22.558816: step 5115, loss = 0.69680 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:47:23.326955 ops/training.py:65 2019-01-16 12:47:23.326880: step 5116, loss = 0.69950 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:47:24.094782 ops/training.py:65 2019-01-16 12:47:24.094704: step 5117, loss = 0.69966 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:47:24.861380 ops/training.py:65 2019-01-16 12:47:24.861306: step 5118, loss = 0.69069 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:47:25.627978 ops/training.py:65 2019-01-16 12:47:25.627920: step 5119, loss = 0.69194 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:47:26.392112 ops/training.py:65 2019-01-16 12:47:26.392063: step 5120, loss = 0.69071 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:47:27.155093 ops/training.py:65 2019-01-16 12:47:27.155028: step 5121, loss = 0.68096 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 12:47:27.918255 ops/training.py:65 2019-01-16 12:47:27.918190: step 5122, loss = 0.69386 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:47:28.681610 ops/training.py:65 2019-01-16 12:47:28.681541: step 5123, loss = 0.69515 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:47:29.445256 ops/training.py:65 2019-01-16 12:47:29.445193: step 5124, loss = 0.69336 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:47:30.208895 ops/training.py:65 2019-01-16 12:47:30.208846: step 5125, loss = 0.69935 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:47:30.972233 ops/training.py:65 2019-01-16 12:47:30.972182: step 5126, loss = 0.69376 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:47:31.735805 ops/training.py:65 2019-01-16 12:47:31.735742: step 5127, loss = 0.69124 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:47:32.498716 ops/training.py:65 2019-01-16 12:47:32.498651: step 5128, loss = 0.68642 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:47:33.261962 ops/training.py:65 2019-01-16 12:47:33.261899: step 5129, loss = 0.69375 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:47:34.025080 ops/training.py:65 2019-01-16 12:47:34.025026: step 5130, loss = 0.68042 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 12:47:34.793082 ops/training.py:65 2019-01-16 12:47:34.793013: step 5131, loss = 0.68663 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:47:35.560118 ops/training.py:65 2019-01-16 12:47:35.560043: step 5132, loss = 0.70056 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:47:36.328134 ops/training.py:65 2019-01-16 12:47:36.328062: step 5133, loss = 0.69394 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:47:37.095804 ops/training.py:65 2019-01-16 12:47:37.095749: step 5134, loss = 0.69420 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:47:37.864044 ops/training.py:65 2019-01-16 12:47:37.863970: step 5135, loss = 0.69178 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:47:38.632334 ops/training.py:65 2019-01-16 12:47:38.632261: step 5136, loss = 0.68979 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:47:39.399664 ops/training.py:65 2019-01-16 12:47:39.399591: step 5137, loss = 0.69364 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:47:40.166158 ops/training.py:65 2019-01-16 12:47:40.166092: step 5138, loss = 0.69564 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:47:40.932097 ops/training.py:65 2019-01-16 12:47:40.932056: step 5139, loss = 0.69563 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:47:41.697560 ops/training.py:65 2019-01-16 12:47:41.697503: step 5140, loss = 0.69368 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:47:42.460354 ops/training.py:65 2019-01-16 12:47:42.460287: step 5141, loss = 0.69556 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:47:43.223651 ops/training.py:65 2019-01-16 12:47:43.223584: step 5142, loss = 0.69028 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:47:43.987442 ops/training.py:65 2019-01-16 12:47:43.987375: step 5143, loss = 0.69455 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:47:44.754809 ops/training.py:65 2019-01-16 12:47:44.754748: step 5144, loss = 0.69077 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:47:45.521884 ops/training.py:65 2019-01-16 12:47:45.521811: step 5145, loss = 0.69232 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:47:46.288783 ops/training.py:65 2019-01-16 12:47:46.288724: step 5146, loss = 0.68926 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:47:47.055922 ops/training.py:65 2019-01-16 12:47:47.055858: step 5147, loss = 0.70020 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:47:47.822260 ops/training.py:65 2019-01-16 12:47:47.822191: step 5148, loss = 0.69556 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:47:48.587035 ops/training.py:65 2019-01-16 12:47:48.586986: step 5149, loss = 0.69092 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:47:49.351902 ops/training.py:65 2019-01-16 12:47:49.351841: step 5150, loss = 0.69612 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:47:50.115605 ops/training.py:65 2019-01-16 12:47:50.115535: step 5151, loss = 0.69481 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:47:50.878994 ops/training.py:65 2019-01-16 12:47:50.878924: step 5152, loss = 0.68815 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:47:51.641624 ops/training.py:65 2019-01-16 12:47:51.641552: step 5153, loss = 0.69419 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:47:52.404999 ops/training.py:65 2019-01-16 12:47:52.404952: step 5154, loss = 0.69405 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:47:53.169272 ops/training.py:65 2019-01-16 12:47:53.169204: step 5155, loss = 0.68823 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:47:53.933165 ops/training.py:65 2019-01-16 12:47:53.933099: step 5156, loss = 0.68825 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:47:54.700048 ops/training.py:65 2019-01-16 12:47:54.699978: step 5157, loss = 0.69238 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:47:55.466483 ops/training.py:65 2019-01-16 12:47:55.466415: step 5158, loss = 0.69749 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:47:56.232752 ops/training.py:65 2019-01-16 12:47:56.232683: step 5159, loss = 0.68821 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:47:56.998865 ops/training.py:65 2019-01-16 12:47:56.998787: step 5160, loss = 0.70216 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:47:57.766737 ops/training.py:65 2019-01-16 12:47:57.766659: step 5161, loss = 0.69375 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:47:58.534870 ops/training.py:65 2019-01-16 12:47:58.534798: step 5162, loss = 0.68962 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:47:59.303152 ops/training.py:65 2019-01-16 12:47:59.303088: step 5163, loss = 0.69298 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:48:00.070092 ops/training.py:65 2019-01-16 12:48:00.070020: step 5164, loss = 0.69813 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:48:00.834272 ops/training.py:65 2019-01-16 12:48:00.834219: step 5165, loss = 0.69431 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:48:01.597659 ops/training.py:65 2019-01-16 12:48:01.597600: step 5166, loss = 0.69877 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:48:02.365034 ops/training.py:65 2019-01-16 12:48:02.364969: step 5167, loss = 0.69656 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:48:03.132844 ops/training.py:65 2019-01-16 12:48:03.132778: step 5168, loss = 0.69385 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:48:03.901675 ops/training.py:65 2019-01-16 12:48:03.901612: step 5169, loss = 0.68316 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.78125
I0528 2019-01-16 12:48:04.670092 ops/training.py:65 2019-01-16 12:48:04.670030: step 5170, loss = 0.69632 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:48:05.438069 ops/training.py:65 2019-01-16 12:48:05.437997: step 5171, loss = 0.69898 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:48:06.205324 ops/training.py:65 2019-01-16 12:48:06.205249: step 5172, loss = 0.69408 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:48:06.970869 ops/training.py:65 2019-01-16 12:48:06.970812: step 5173, loss = 0.69346 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:48:07.734370 ops/training.py:65 2019-01-16 12:48:07.734311: step 5174, loss = 0.68334 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:48:08.498216 ops/training.py:65 2019-01-16 12:48:08.498151: step 5175, loss = 0.69445 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:48:09.261601 ops/training.py:65 2019-01-16 12:48:09.261540: step 5176, loss = 0.69652 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:48:10.025449 ops/training.py:65 2019-01-16 12:48:10.025378: step 5177, loss = 0.69477 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:48:10.789376 ops/training.py:65 2019-01-16 12:48:10.789328: step 5178, loss = 0.69622 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:48:11.555807 ops/training.py:65 2019-01-16 12:48:11.555750: step 5179, loss = 0.69459 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:48:12.319947 ops/training.py:65 2019-01-16 12:48:12.319877: step 5180, loss = 0.68787 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:48:13.089482 ops/training.py:65 2019-01-16 12:48:13.089418: step 5181, loss = 0.69192 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:48:13.857093 ops/training.py:65 2019-01-16 12:48:13.857016: step 5182, loss = 0.68753 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:48:14.624977 ops/training.py:65 2019-01-16 12:48:14.624914: step 5183, loss = 0.68985 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:48:15.392517 ops/training.py:65 2019-01-16 12:48:15.392447: step 5184, loss = 0.69754 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:48:16.159489 ops/training.py:65 2019-01-16 12:48:16.159424: step 5185, loss = 0.68964 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:48:16.925642 ops/training.py:65 2019-01-16 12:48:16.925574: step 5186, loss = 0.69013 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:48:17.690402 ops/training.py:65 2019-01-16 12:48:17.690332: step 5187, loss = 0.69067 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:48:18.454596 ops/training.py:65 2019-01-16 12:48:18.454554: step 5188, loss = 0.69507 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:48:19.218490 ops/training.py:65 2019-01-16 12:48:19.218446: step 5189, loss = 0.69488 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:48:19.984410 ops/training.py:65 2019-01-16 12:48:19.984342: step 5190, loss = 0.69162 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:48:20.752836 ops/training.py:65 2019-01-16 12:48:20.752761: step 5191, loss = 0.69301 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:48:21.518925 ops/training.py:65 2019-01-16 12:48:21.518858: step 5192, loss = 0.69379 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:48:22.283782 ops/training.py:65 2019-01-16 12:48:22.283740: step 5193, loss = 0.69324 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:48:23.047597 ops/training.py:65 2019-01-16 12:48:23.047530: step 5194, loss = 0.69049 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:48:23.811889 ops/training.py:65 2019-01-16 12:48:23.811821: step 5195, loss = 0.69346 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:48:24.575691 ops/training.py:65 2019-01-16 12:48:24.575623: step 5196, loss = 0.69236 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:48:25.339310 ops/training.py:65 2019-01-16 12:48:25.339248: step 5197, loss = 0.68703 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:48:26.102924 ops/training.py:65 2019-01-16 12:48:26.102877: step 5198, loss = 0.70171 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:48:26.869506 ops/training.py:65 2019-01-16 12:48:26.869434: step 5199, loss = 0.70105 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:48:27.636932 ops/training.py:65 2019-01-16 12:48:27.636854: step 5200, loss = 0.70745 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 12:48:28.405562 ops/training.py:65 2019-01-16 12:48:28.405483: step 5201, loss = 0.69644 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:48:29.172926 ops/training.py:65 2019-01-16 12:48:29.172863: step 5202, loss = 0.69110 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:48:29.940207 ops/training.py:65 2019-01-16 12:48:29.940135: step 5203, loss = 0.69154 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:48:30.706913 ops/training.py:65 2019-01-16 12:48:30.706838: step 5204, loss = 0.69818 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:48:31.475112 ops/training.py:65 2019-01-16 12:48:31.475020: step 5205, loss = 0.69545 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:48:32.241966 ops/training.py:65 2019-01-16 12:48:32.241889: step 5206, loss = 0.69263 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:48:33.005660 ops/training.py:65 2019-01-16 12:48:33.005592: step 5207, loss = 0.69335 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:48:33.769075 ops/training.py:65 2019-01-16 12:48:33.769026: step 5208, loss = 0.68559 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:48:34.532270 ops/training.py:65 2019-01-16 12:48:34.532195: step 5209, loss = 0.68397 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:48:35.296357 ops/training.py:65 2019-01-16 12:48:35.296293: step 5210, loss = 0.68780 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:48:36.059581 ops/training.py:65 2019-01-16 12:48:36.059513: step 5211, loss = 0.69772 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:48:36.823469 ops/training.py:65 2019-01-16 12:48:36.823418: step 5212, loss = 0.69506 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:48:37.590044 ops/training.py:65 2019-01-16 12:48:37.589999: step 5213, loss = 0.68610 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:48:38.357354 ops/training.py:65 2019-01-16 12:48:38.357283: step 5214, loss = 0.68356 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:48:39.123077 ops/training.py:65 2019-01-16 12:48:39.123026: step 5215, loss = 0.69510 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:48:39.888200 ops/training.py:65 2019-01-16 12:48:39.888151: step 5216, loss = 0.69471 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:48:40.651084 ops/training.py:65 2019-01-16 12:48:40.651042: step 5217, loss = 0.68993 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:48:41.414069 ops/training.py:65 2019-01-16 12:48:41.414010: step 5218, loss = 0.68718 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:48:42.178455 ops/training.py:65 2019-01-16 12:48:42.178384: step 5219, loss = 0.69393 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:48:42.941756 ops/training.py:65 2019-01-16 12:48:42.941681: step 5220, loss = 0.69372 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:48:43.704963 ops/training.py:65 2019-01-16 12:48:43.704892: step 5221, loss = 0.69816 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:48:44.469366 ops/training.py:65 2019-01-16 12:48:44.469300: step 5222, loss = 0.69619 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:48:45.233017 ops/training.py:65 2019-01-16 12:48:45.232971: step 5223, loss = 0.68969 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:48:45.996953 ops/training.py:65 2019-01-16 12:48:45.996902: step 5224, loss = 0.69677 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:48:46.760207 ops/training.py:65 2019-01-16 12:48:46.760145: step 5225, loss = 0.68872 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:48:47.523414 ops/training.py:65 2019-01-16 12:48:47.523348: step 5226, loss = 0.69204 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:48:48.289373 ops/training.py:65 2019-01-16 12:48:48.289327: step 5227, loss = 0.69652 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:48:49.056890 ops/training.py:65 2019-01-16 12:48:49.056823: step 5228, loss = 0.68998 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:48:49.822365 ops/training.py:65 2019-01-16 12:48:49.822294: step 5229, loss = 0.69381 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:48:50.586424 ops/training.py:65 2019-01-16 12:48:50.586356: step 5230, loss = 0.69177 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:48:51.350105 ops/training.py:65 2019-01-16 12:48:51.350031: step 5231, loss = 0.68635 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:48:52.114005 ops/training.py:65 2019-01-16 12:48:52.113964: step 5232, loss = 0.69096 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:48:52.881347 ops/training.py:65 2019-01-16 12:48:52.881289: step 5233, loss = 0.69611 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:48:53.648092 ops/training.py:65 2019-01-16 12:48:53.648015: step 5234, loss = 0.69265 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:48:54.414753 ops/training.py:65 2019-01-16 12:48:54.414672: step 5235, loss = 0.70131 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:48:55.181452 ops/training.py:65 2019-01-16 12:48:55.181382: step 5236, loss = 0.69392 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:48:55.945479 ops/training.py:65 2019-01-16 12:48:55.945433: step 5237, loss = 0.69377 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:48:56.709517 ops/training.py:65 2019-01-16 12:48:56.709450: step 5238, loss = 0.69630 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:48:57.473059 ops/training.py:65 2019-01-16 12:48:57.472991: step 5239, loss = 0.69012 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:48:58.236622 ops/training.py:65 2019-01-16 12:48:58.236556: step 5240, loss = 0.69427 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:48:59.000214 ops/training.py:65 2019-01-16 12:48:59.000158: step 5241, loss = 0.69723 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:48:59.764626 ops/training.py:65 2019-01-16 12:48:59.764579: step 5242, loss = 0.69853 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:49:00.528291 ops/training.py:65 2019-01-16 12:49:00.528222: step 5243, loss = 0.69047 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:49:01.294668 ops/training.py:65 2019-01-16 12:49:01.294619: step 5244, loss = 0.69047 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:49:02.062938 ops/training.py:65 2019-01-16 12:49:02.062872: step 5245, loss = 0.69355 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:49:02.830851 ops/training.py:65 2019-01-16 12:49:02.830778: step 5246, loss = 0.68759 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:49:03.596661 ops/training.py:65 2019-01-16 12:49:03.596591: step 5247, loss = 0.70110 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:49:04.362501 ops/training.py:65 2019-01-16 12:49:04.362431: step 5248, loss = 0.69196 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:49:05.126302 ops/training.py:65 2019-01-16 12:49:05.126232: step 5249, loss = 0.69530 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:49:05.894897 ops/training.py:65 2019-01-16 12:49:05.894826: step 5250, loss = 0.68933 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:49:06.661884 ops/training.py:65 2019-01-16 12:49:06.661832: step 5251, loss = 0.69531 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:49:07.428601 ops/training.py:65 2019-01-16 12:49:07.428567: step 5252, loss = 0.70168 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:49:08.195032 ops/training.py:65 2019-01-16 12:49:08.194980: step 5253, loss = 0.69097 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:49:08.960583 ops/training.py:65 2019-01-16 12:49:08.960526: step 5254, loss = 0.68645 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:49:09.724023 ops/training.py:65 2019-01-16 12:49:09.723972: step 5255, loss = 0.69531 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:49:10.488062 ops/training.py:65 2019-01-16 12:49:10.488006: step 5256, loss = 0.69634 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:49:11.252928 ops/training.py:65 2019-01-16 12:49:11.252876: step 5257, loss = 0.68810 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:49:12.017257 ops/training.py:65 2019-01-16 12:49:12.017197: step 5258, loss = 0.69333 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:49:12.781237 ops/training.py:65 2019-01-16 12:49:12.781177: step 5259, loss = 0.69312 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:49:13.545618 ops/training.py:65 2019-01-16 12:49:13.545556: step 5260, loss = 0.68910 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:49:14.309434 ops/training.py:65 2019-01-16 12:49:14.309376: step 5261, loss = 0.69514 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:49:15.072891 ops/training.py:65 2019-01-16 12:49:15.072862: step 5262, loss = 0.69454 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:49:15.837473 ops/training.py:65 2019-01-16 12:49:15.837421: step 5263, loss = 0.69421 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:49:16.601490 ops/training.py:65 2019-01-16 12:49:16.601435: step 5264, loss = 0.69546 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:49:17.364500 ops/training.py:65 2019-01-16 12:49:17.364448: step 5265, loss = 0.68571 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:49:18.127757 ops/training.py:65 2019-01-16 12:49:18.127701: step 5266, loss = 0.68842 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:49:18.891235 ops/training.py:65 2019-01-16 12:49:18.891189: step 5267, loss = 0.69099 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:49:19.655353 ops/training.py:65 2019-01-16 12:49:19.655294: step 5268, loss = 0.68990 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:49:20.419412 ops/training.py:65 2019-01-16 12:49:20.419356: step 5269, loss = 0.69449 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:49:21.182674 ops/training.py:65 2019-01-16 12:49:21.182614: step 5270, loss = 0.69792 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:49:21.947052 ops/training.py:65 2019-01-16 12:49:21.946998: step 5271, loss = 0.69105 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:49:22.712661 ops/training.py:65 2019-01-16 12:49:22.712624: step 5272, loss = 0.69286 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:49:23.480474 ops/training.py:65 2019-01-16 12:49:23.480401: step 5273, loss = 0.70140 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:49:24.248319 ops/training.py:65 2019-01-16 12:49:24.248248: step 5274, loss = 0.69938 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:49:25.014887 ops/training.py:65 2019-01-16 12:49:25.014817: step 5275, loss = 0.69898 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:49:25.780137 ops/training.py:65 2019-01-16 12:49:25.780091: step 5276, loss = 0.69247 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:49:26.543826 ops/training.py:65 2019-01-16 12:49:26.543776: step 5277, loss = 0.69022 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:49:27.308290 ops/training.py:65 2019-01-16 12:49:27.308221: step 5278, loss = 0.68217 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:49:28.072481 ops/training.py:65 2019-01-16 12:49:28.072413: step 5279, loss = 0.69493 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:49:28.837354 ops/training.py:65 2019-01-16 12:49:28.837286: step 5280, loss = 0.68273 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:49:29.601424 ops/training.py:65 2019-01-16 12:49:29.601380: step 5281, loss = 0.69939 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:49:30.365721 ops/training.py:65 2019-01-16 12:49:30.365656: step 5282, loss = 0.69467 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:49:31.129382 ops/training.py:65 2019-01-16 12:49:31.129330: step 5283, loss = 0.70231 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 12:49:31.893128 ops/training.py:65 2019-01-16 12:49:31.893067: step 5284, loss = 0.69264 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:49:32.657556 ops/training.py:65 2019-01-16 12:49:32.657486: step 5285, loss = 0.69163 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:49:33.421240 ops/training.py:65 2019-01-16 12:49:33.421192: step 5286, loss = 0.69641 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:49:34.185355 ops/training.py:65 2019-01-16 12:49:34.185285: step 5287, loss = 0.70105 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:49:34.950591 ops/training.py:65 2019-01-16 12:49:34.950519: step 5288, loss = 0.68566 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:49:35.718274 ops/training.py:65 2019-01-16 12:49:35.718200: step 5289, loss = 0.69770 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:49:36.483258 ops/training.py:65 2019-01-16 12:49:36.483191: step 5290, loss = 0.69508 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:49:37.246635 ops/training.py:65 2019-01-16 12:49:37.246574: step 5291, loss = 0.69123 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:49:38.010089 ops/training.py:65 2019-01-16 12:49:38.010018: step 5292, loss = 0.69330 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:49:38.777106 ops/training.py:65 2019-01-16 12:49:38.777038: step 5293, loss = 0.68388 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:49:39.545406 ops/training.py:65 2019-01-16 12:49:39.545335: step 5294, loss = 0.68823 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:49:40.313249 ops/training.py:65 2019-01-16 12:49:40.313172: step 5295, loss = 0.69589 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:49:41.080713 ops/training.py:65 2019-01-16 12:49:41.080654: step 5296, loss = 0.69175 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:49:41.847544 ops/training.py:65 2019-01-16 12:49:41.847467: step 5297, loss = 0.69881 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:49:42.613437 ops/training.py:65 2019-01-16 12:49:42.613367: step 5298, loss = 0.68967 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:49:43.378504 ops/training.py:65 2019-01-16 12:49:43.378439: step 5299, loss = 0.69274 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:49:44.143022 ops/training.py:65 2019-01-16 12:49:44.142954: step 5300, loss = 0.68561 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:49:44.907570 ops/training.py:65 2019-01-16 12:49:44.907518: step 5301, loss = 0.69234 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:49:45.672517 ops/training.py:65 2019-01-16 12:49:45.672450: step 5302, loss = 0.69716 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:49:46.437503 ops/training.py:65 2019-01-16 12:49:46.437449: step 5303, loss = 0.69451 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:49:47.202280 ops/training.py:65 2019-01-16 12:49:47.202205: step 5304, loss = 0.69084 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:49:47.966649 ops/training.py:65 2019-01-16 12:49:47.966581: step 5305, loss = 0.68515 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:49:48.731394 ops/training.py:65 2019-01-16 12:49:48.731342: step 5306, loss = 0.69087 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:49:49.495795 ops/training.py:65 2019-01-16 12:49:49.495733: step 5307, loss = 0.69390 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:49:50.259960 ops/training.py:65 2019-01-16 12:49:50.259889: step 5308, loss = 0.70227 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:49:51.024366 ops/training.py:65 2019-01-16 12:49:51.024297: step 5309, loss = 0.69150 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:49:51.788696 ops/training.py:65 2019-01-16 12:49:51.788631: step 5310, loss = 0.69543 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:49:52.552942 ops/training.py:65 2019-01-16 12:49:52.552899: step 5311, loss = 0.68827 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:49:53.317475 ops/training.py:65 2019-01-16 12:49:53.317405: step 5312, loss = 0.69237 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:49:54.082025 ops/training.py:65 2019-01-16 12:49:54.081960: step 5313, loss = 0.69260 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:49:54.851072 ops/training.py:65 2019-01-16 12:49:54.851006: step 5314, loss = 0.69310 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:49:55.619681 ops/training.py:65 2019-01-16 12:49:55.619621: step 5315, loss = 0.69664 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:49:56.386969 ops/training.py:65 2019-01-16 12:49:56.386917: step 5316, loss = 0.69366 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:49:57.154893 ops/training.py:65 2019-01-16 12:49:57.154826: step 5317, loss = 0.70098 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:49:57.923464 ops/training.py:65 2019-01-16 12:49:57.923393: step 5318, loss = 0.69265 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:49:58.692197 ops/training.py:65 2019-01-16 12:49:58.692123: step 5319, loss = 0.69419 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:49:59.461714 ops/training.py:65 2019-01-16 12:49:59.461666: step 5320, loss = 0.69880 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 12:50:00.229633 ops/training.py:65 2019-01-16 12:50:00.229555: step 5321, loss = 0.69384 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:50:00.995793 ops/training.py:65 2019-01-16 12:50:00.995745: step 5322, loss = 0.69420 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:50:01.759157 ops/training.py:65 2019-01-16 12:50:01.759089: step 5323, loss = 0.69659 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:50:02.526107 ops/training.py:65 2019-01-16 12:50:02.526046: step 5324, loss = 0.68876 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:50:03.293626 ops/training.py:65 2019-01-16 12:50:03.293564: step 5325, loss = 0.68857 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:50:04.061411 ops/training.py:65 2019-01-16 12:50:04.061347: step 5326, loss = 0.69989 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:50:04.829344 ops/training.py:65 2019-01-16 12:50:04.829282: step 5327, loss = 0.69461 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:50:05.596095 ops/training.py:65 2019-01-16 12:50:05.596039: step 5328, loss = 0.69525 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:50:06.362249 ops/training.py:65 2019-01-16 12:50:06.362193: step 5329, loss = 0.69026 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:50:07.129279 ops/training.py:65 2019-01-16 12:50:07.129232: step 5330, loss = 0.69869 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:50:07.897094 ops/training.py:65 2019-01-16 12:50:07.897030: step 5331, loss = 0.68835 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:50:08.664620 ops/training.py:65 2019-01-16 12:50:08.664566: step 5332, loss = 0.69129 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:50:09.432301 ops/training.py:65 2019-01-16 12:50:09.432250: step 5333, loss = 0.70007 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:50:10.199613 ops/training.py:65 2019-01-16 12:50:10.199557: step 5334, loss = 0.69374 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:50:10.967725 ops/training.py:65 2019-01-16 12:50:10.967663: step 5335, loss = 0.69592 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:50:11.732366 ops/training.py:65 2019-01-16 12:50:11.732292: step 5336, loss = 0.69379 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:50:12.503378 ops/training.py:65 2019-01-16 12:50:12.503303: step 5337, loss = 0.69561 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:50:13.274025 ops/training.py:65 2019-01-16 12:50:13.273963: step 5338, loss = 0.69988 (41.6 examples/sec; 0.770 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:50:14.042356 ops/training.py:65 2019-01-16 12:50:14.042293: step 5339, loss = 0.69407 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:50:14.806827 ops/training.py:65 2019-01-16 12:50:14.806751: step 5340, loss = 0.68828 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:50:15.572236 ops/training.py:65 2019-01-16 12:50:15.572180: step 5341, loss = 0.69610 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:50:16.338078 ops/training.py:65 2019-01-16 12:50:16.338004: step 5342, loss = 0.69990 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:50:17.102469 ops/training.py:65 2019-01-16 12:50:17.102405: step 5343, loss = 0.69236 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:50:17.867253 ops/training.py:65 2019-01-16 12:50:17.867180: step 5344, loss = 0.69386 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:50:18.634274 ops/training.py:65 2019-01-16 12:50:18.634221: step 5345, loss = 0.68916 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:50:19.402059 ops/training.py:65 2019-01-16 12:50:19.401977: step 5346, loss = 0.69652 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:50:20.169166 ops/training.py:65 2019-01-16 12:50:20.169088: step 5347, loss = 0.69081 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:50:20.935982 ops/training.py:65 2019-01-16 12:50:20.935907: step 5348, loss = 0.70124 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:50:21.701462 ops/training.py:65 2019-01-16 12:50:21.701388: step 5349, loss = 0.69553 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:50:22.467848 ops/training.py:65 2019-01-16 12:50:22.467804: step 5350, loss = 0.69739 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:50:23.235082 ops/training.py:65 2019-01-16 12:50:23.235022: step 5351, loss = 0.69244 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:50:24.003533 ops/training.py:65 2019-01-16 12:50:24.003466: step 5352, loss = 0.69236 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:50:24.773368 ops/training.py:65 2019-01-16 12:50:24.773296: step 5353, loss = 0.68637 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:50:25.540384 ops/training.py:65 2019-01-16 12:50:25.540307: step 5354, loss = 0.69277 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:50:26.305671 ops/training.py:65 2019-01-16 12:50:26.305588: step 5355, loss = 0.69534 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:50:27.071019 ops/training.py:65 2019-01-16 12:50:27.070930: step 5356, loss = 0.68964 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:50:27.840497 ops/training.py:65 2019-01-16 12:50:27.840426: step 5357, loss = 0.69277 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:50:28.608361 ops/training.py:65 2019-01-16 12:50:28.608286: step 5358, loss = 0.69704 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:50:29.375908 ops/training.py:65 2019-01-16 12:50:29.375835: step 5359, loss = 0.69238 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:50:30.142860 ops/training.py:65 2019-01-16 12:50:30.142804: step 5360, loss = 0.69319 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:50:30.907802 ops/training.py:65 2019-01-16 12:50:30.907754: step 5361, loss = 0.70457 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 12:50:31.672377 ops/training.py:65 2019-01-16 12:50:31.672307: step 5362, loss = 0.69187 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:50:32.437307 ops/training.py:65 2019-01-16 12:50:32.437239: step 5363, loss = 0.69840 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:50:33.202165 ops/training.py:65 2019-01-16 12:50:33.202115: step 5364, loss = 0.69841 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:50:33.966861 ops/training.py:65 2019-01-16 12:50:33.966812: step 5365, loss = 0.69888 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:50:34.731542 ops/training.py:65 2019-01-16 12:50:34.731471: step 5366, loss = 0.68805 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:50:35.495099 ops/training.py:65 2019-01-16 12:50:35.495032: step 5367, loss = 0.69495 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:50:36.258981 ops/training.py:65 2019-01-16 12:50:36.258914: step 5368, loss = 0.68899 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:50:37.025506 ops/training.py:65 2019-01-16 12:50:37.025446: step 5369, loss = 0.69679 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:50:37.794111 ops/training.py:65 2019-01-16 12:50:37.794046: step 5370, loss = 0.69673 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:50:38.563140 ops/training.py:65 2019-01-16 12:50:38.563065: step 5371, loss = 0.69293 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:50:39.330676 ops/training.py:65 2019-01-16 12:50:39.330601: step 5372, loss = 0.69359 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:50:40.097711 ops/training.py:65 2019-01-16 12:50:40.097643: step 5373, loss = 0.70110 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:50:40.861974 ops/training.py:65 2019-01-16 12:50:40.861921: step 5374, loss = 0.68712 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:50:41.626591 ops/training.py:65 2019-01-16 12:50:41.626532: step 5375, loss = 0.69978 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:50:42.392997 ops/training.py:65 2019-01-16 12:50:42.392922: step 5376, loss = 0.69416 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:50:43.160130 ops/training.py:65 2019-01-16 12:50:43.160051: step 5377, loss = 0.69375 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:50:43.925327 ops/training.py:65 2019-01-16 12:50:43.925248: step 5378, loss = 0.69361 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:50:44.691643 ops/training.py:65 2019-01-16 12:50:44.691574: step 5379, loss = 0.69947 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:50:45.455694 ops/training.py:65 2019-01-16 12:50:45.455646: step 5380, loss = 0.68938 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:50:46.219887 ops/training.py:65 2019-01-16 12:50:46.219836: step 5381, loss = 0.69424 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:50:46.984230 ops/training.py:65 2019-01-16 12:50:46.984172: step 5382, loss = 0.68822 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:50:47.748842 ops/training.py:65 2019-01-16 12:50:47.748774: step 5383, loss = 0.68445 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:50:48.515958 ops/training.py:65 2019-01-16 12:50:48.515904: step 5384, loss = 0.68354 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:50:49.282770 ops/training.py:65 2019-01-16 12:50:49.282723: step 5385, loss = 0.69578 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:50:50.050872 ops/training.py:65 2019-01-16 12:50:50.050799: step 5386, loss = 0.68721 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:50:50.819468 ops/training.py:65 2019-01-16 12:50:50.819392: step 5387, loss = 0.69458 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:50:51.587895 ops/training.py:65 2019-01-16 12:50:51.587809: step 5388, loss = 0.70168 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:50:52.355347 ops/training.py:65 2019-01-16 12:50:52.355285: step 5389, loss = 0.68149 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:50:53.124382 ops/training.py:65 2019-01-16 12:50:53.124342: step 5390, loss = 0.68466 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:50:53.893379 ops/training.py:65 2019-01-16 12:50:53.893329: step 5391, loss = 0.68640 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:50:54.662230 ops/training.py:65 2019-01-16 12:50:54.662188: step 5392, loss = 0.69022 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:50:55.429625 ops/training.py:65 2019-01-16 12:50:55.429558: step 5393, loss = 0.68994 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:50:56.196427 ops/training.py:65 2019-01-16 12:50:56.196378: step 5394, loss = 0.68612 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:50:56.964438 ops/training.py:65 2019-01-16 12:50:56.964367: step 5395, loss = 0.69085 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:50:57.733022 ops/training.py:65 2019-01-16 12:50:57.732944: step 5396, loss = 0.68938 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:50:58.500509 ops/training.py:65 2019-01-16 12:50:58.500437: step 5397, loss = 0.67172 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 12:50:59.268838 ops/training.py:65 2019-01-16 12:50:59.268771: step 5398, loss = 0.70552 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:51:00.035723 ops/training.py:65 2019-01-16 12:51:00.035668: step 5399, loss = 0.67921 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.75
I0528 2019-01-16 12:51:00.803109 ops/training.py:65 2019-01-16 12:51:00.803055: step 5400, loss = 0.69652 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:51:01.570196 ops/training.py:65 2019-01-16 12:51:01.570121: step 5401, loss = 0.69026 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:51:02.335024 ops/training.py:65 2019-01-16 12:51:02.334950: step 5402, loss = 0.69604 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:51:03.098222 ops/training.py:65 2019-01-16 12:51:03.098153: step 5403, loss = 0.69057 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:51:03.862075 ops/training.py:65 2019-01-16 12:51:03.862022: step 5404, loss = 0.68777 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:51:04.625729 ops/training.py:65 2019-01-16 12:51:04.625636: step 5405, loss = 0.69282 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:51:05.389768 ops/training.py:65 2019-01-16 12:51:05.389704: step 5406, loss = 0.68836 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:51:06.154227 ops/training.py:65 2019-01-16 12:51:06.154156: step 5407, loss = 0.69703 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:51:06.918851 ops/training.py:65 2019-01-16 12:51:06.918779: step 5408, loss = 0.70483 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:51:07.683751 ops/training.py:65 2019-01-16 12:51:07.683688: step 5409, loss = 0.69895 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:51:08.448451 ops/training.py:65 2019-01-16 12:51:08.448382: step 5410, loss = 0.69720 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:51:09.212532 ops/training.py:65 2019-01-16 12:51:09.212474: step 5411, loss = 0.68798 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:51:09.976923 ops/training.py:65 2019-01-16 12:51:09.976855: step 5412, loss = 0.69576 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:51:10.740480 ops/training.py:65 2019-01-16 12:51:10.740413: step 5413, loss = 0.70293 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:51:11.503961 ops/training.py:65 2019-01-16 12:51:11.503900: step 5414, loss = 0.69981 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:51:12.268964 ops/training.py:65 2019-01-16 12:51:12.268887: step 5415, loss = 0.71489 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 12:51:13.036403 ops/training.py:65 2019-01-16 12:51:13.036324: step 5416, loss = 0.68534 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:51:13.803480 ops/training.py:65 2019-01-16 12:51:13.803407: step 5417, loss = 0.69088 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:51:14.571555 ops/training.py:65 2019-01-16 12:51:14.571483: step 5418, loss = 0.69019 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:51:15.339747 ops/training.py:65 2019-01-16 12:51:15.339668: step 5419, loss = 0.70211 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:51:16.104793 ops/training.py:65 2019-01-16 12:51:16.104732: step 5420, loss = 0.68615 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:51:16.869366 ops/training.py:65 2019-01-16 12:51:16.869295: step 5421, loss = 0.69436 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:51:17.634083 ops/training.py:65 2019-01-16 12:51:17.634014: step 5422, loss = 0.70333 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:51:18.398180 ops/training.py:65 2019-01-16 12:51:18.398111: step 5423, loss = 0.68628 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:51:19.162494 ops/training.py:65 2019-01-16 12:51:19.162449: step 5424, loss = 0.69174 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:51:19.925905 ops/training.py:65 2019-01-16 12:51:19.925840: step 5425, loss = 0.68525 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:51:20.688919 ops/training.py:65 2019-01-16 12:51:20.688849: step 5426, loss = 0.68886 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:51:21.452242 ops/training.py:65 2019-01-16 12:51:21.452169: step 5427, loss = 0.69368 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:51:22.216308 ops/training.py:65 2019-01-16 12:51:22.216244: step 5428, loss = 0.69561 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:51:22.982667 ops/training.py:65 2019-01-16 12:51:22.982607: step 5429, loss = 0.70358 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:51:23.750505 ops/training.py:65 2019-01-16 12:51:23.750431: step 5430, loss = 0.68994 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:51:24.517108 ops/training.py:65 2019-01-16 12:51:24.517034: step 5431, loss = 0.68739 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:51:25.280754 ops/training.py:65 2019-01-16 12:51:25.280688: step 5432, loss = 0.69728 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:51:26.043802 ops/training.py:65 2019-01-16 12:51:26.043739: step 5433, loss = 0.69426 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:51:26.809733 ops/training.py:65 2019-01-16 12:51:26.809678: step 5434, loss = 0.69928 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:51:27.577142 ops/training.py:65 2019-01-16 12:51:27.577062: step 5435, loss = 0.69553 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:51:28.345105 ops/training.py:65 2019-01-16 12:51:28.345031: step 5436, loss = 0.68527 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:51:29.112046 ops/training.py:65 2019-01-16 12:51:29.111982: step 5437, loss = 0.69751 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:51:29.877001 ops/training.py:65 2019-01-16 12:51:29.876955: step 5438, loss = 0.70023 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:51:30.640722 ops/training.py:65 2019-01-16 12:51:30.640665: step 5439, loss = 0.68480 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:51:31.404433 ops/training.py:65 2019-01-16 12:51:31.404380: step 5440, loss = 0.69273 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:51:32.168906 ops/training.py:65 2019-01-16 12:51:32.168844: step 5441, loss = 0.69200 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:51:32.934088 ops/training.py:65 2019-01-16 12:51:32.934017: step 5442, loss = 0.69516 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:51:33.701769 ops/training.py:65 2019-01-16 12:51:33.701687: step 5443, loss = 0.69284 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:51:34.468830 ops/training.py:65 2019-01-16 12:51:34.468757: step 5444, loss = 0.69661 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:51:35.233671 ops/training.py:65 2019-01-16 12:51:35.233603: step 5445, loss = 0.68398 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:51:35.998673 ops/training.py:65 2019-01-16 12:51:35.998605: step 5446, loss = 0.68989 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:51:36.762974 ops/training.py:65 2019-01-16 12:51:36.762905: step 5447, loss = 0.69839 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:51:37.527266 ops/training.py:65 2019-01-16 12:51:37.527222: step 5448, loss = 0.69306 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:51:38.291890 ops/training.py:65 2019-01-16 12:51:38.291822: step 5449, loss = 0.69525 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:51:39.056376 ops/training.py:65 2019-01-16 12:51:39.056314: step 5450, loss = 0.69711 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:51:39.820339 ops/training.py:65 2019-01-16 12:51:39.820270: step 5451, loss = 0.68475 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.75
I0528 2019-01-16 12:51:40.584518 ops/training.py:65 2019-01-16 12:51:40.584449: step 5452, loss = 0.69554 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:51:41.349086 ops/training.py:65 2019-01-16 12:51:41.349032: step 5453, loss = 0.69185 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:51:42.113469 ops/training.py:65 2019-01-16 12:51:42.113399: step 5454, loss = 0.69991 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:51:42.877642 ops/training.py:65 2019-01-16 12:51:42.877573: step 5455, loss = 0.69070 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:51:43.641289 ops/training.py:65 2019-01-16 12:51:43.641222: step 5456, loss = 0.69012 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:51:44.403924 ops/training.py:65 2019-01-16 12:51:44.403856: step 5457, loss = 0.68716 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:51:45.168333 ops/training.py:65 2019-01-16 12:51:45.168292: step 5458, loss = 0.69600 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:51:45.931142 ops/training.py:65 2019-01-16 12:51:45.931088: step 5459, loss = 0.69556 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:51:46.694640 ops/training.py:65 2019-01-16 12:51:46.694586: step 5460, loss = 0.69503 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:51:47.458076 ops/training.py:65 2019-01-16 12:51:47.458006: step 5461, loss = 0.68976 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:51:48.221733 ops/training.py:65 2019-01-16 12:51:48.221660: step 5462, loss = 0.69382 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:51:48.985402 ops/training.py:65 2019-01-16 12:51:48.985357: step 5463, loss = 0.71297 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.1875
I0528 2019-01-16 12:51:49.752130 ops/training.py:65 2019-01-16 12:51:49.752062: step 5464, loss = 0.69327 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:51:50.519908 ops/training.py:65 2019-01-16 12:51:50.519835: step 5465, loss = 0.68696 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:51:51.286097 ops/training.py:65 2019-01-16 12:51:51.286023: step 5466, loss = 0.69133 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:51:52.050316 ops/training.py:65 2019-01-16 12:51:52.050261: step 5467, loss = 0.70589 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 12:51:52.813559 ops/training.py:65 2019-01-16 12:51:52.813500: step 5468, loss = 0.69445 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:51:53.577486 ops/training.py:65 2019-01-16 12:51:53.577417: step 5469, loss = 0.69887 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:51:54.340985 ops/training.py:65 2019-01-16 12:51:54.340915: step 5470, loss = 0.69778 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 12:51:55.104988 ops/training.py:65 2019-01-16 12:51:55.104918: step 5471, loss = 0.70125 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:51:55.869309 ops/training.py:65 2019-01-16 12:51:55.869249: step 5472, loss = 0.69567 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:51:56.633706 ops/training.py:65 2019-01-16 12:51:56.633657: step 5473, loss = 0.69244 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:51:57.399796 ops/training.py:65 2019-01-16 12:51:57.399722: step 5474, loss = 0.69474 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:51:58.169048 ops/training.py:65 2019-01-16 12:51:58.168973: step 5475, loss = 0.68807 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:51:58.936873 ops/training.py:65 2019-01-16 12:51:58.936799: step 5476, loss = 0.69625 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:51:59.701190 ops/training.py:65 2019-01-16 12:51:59.701147: step 5477, loss = 0.69783 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:52:00.466142 ops/training.py:65 2019-01-16 12:52:00.466094: step 5478, loss = 0.69265 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:52:01.230781 ops/training.py:65 2019-01-16 12:52:01.230732: step 5479, loss = 0.69008 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:52:01.998373 ops/training.py:65 2019-01-16 12:52:01.998310: step 5480, loss = 0.68905 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:52:02.766312 ops/training.py:65 2019-01-16 12:52:02.766244: step 5481, loss = 0.69020 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:52:03.533778 ops/training.py:65 2019-01-16 12:52:03.533732: step 5482, loss = 0.70323 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:52:04.298721 ops/training.py:65 2019-01-16 12:52:04.298671: step 5483, loss = 0.69743 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:52:05.063222 ops/training.py:65 2019-01-16 12:52:05.063148: step 5484, loss = 0.69678 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:52:05.827707 ops/training.py:65 2019-01-16 12:52:05.827636: step 5485, loss = 0.69068 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:52:06.592206 ops/training.py:65 2019-01-16 12:52:06.592137: step 5486, loss = 0.69575 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:52:07.356594 ops/training.py:65 2019-01-16 12:52:07.356554: step 5487, loss = 0.69107 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:52:08.120879 ops/training.py:65 2019-01-16 12:52:08.120809: step 5488, loss = 0.69359 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:52:08.885282 ops/training.py:65 2019-01-16 12:52:08.885212: step 5489, loss = 0.68842 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:52:09.649085 ops/training.py:65 2019-01-16 12:52:09.649011: step 5490, loss = 0.70136 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:52:10.414398 ops/training.py:65 2019-01-16 12:52:10.414333: step 5491, loss = 0.69203 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:52:11.178178 ops/training.py:65 2019-01-16 12:52:11.178122: step 5492, loss = 0.70454 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:52:11.942489 ops/training.py:65 2019-01-16 12:52:11.942410: step 5493, loss = 0.68983 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:52:12.707292 ops/training.py:65 2019-01-16 12:52:12.707218: step 5494, loss = 0.68913 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:52:13.471597 ops/training.py:65 2019-01-16 12:52:13.471529: step 5495, loss = 0.69138 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:52:14.238149 ops/training.py:65 2019-01-16 12:52:14.238076: step 5496, loss = 0.68935 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:52:15.004679 ops/training.py:65 2019-01-16 12:52:15.004603: step 5497, loss = 0.70302 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:52:15.771224 ops/training.py:65 2019-01-16 12:52:15.771159: step 5498, loss = 0.69208 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:52:16.537378 ops/training.py:65 2019-01-16 12:52:16.537322: step 5499, loss = 0.68540 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:52:17.301684 ops/training.py:65 2019-01-16 12:52:17.301630: step 5500, loss = 0.69361 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:52:18.064975 ops/training.py:65 2019-01-16 12:52:18.064922: step 5501, loss = 0.68427 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:52:18.827912 ops/training.py:65 2019-01-16 12:52:18.827863: step 5502, loss = 0.69900 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:52:19.591674 ops/training.py:65 2019-01-16 12:52:19.591613: step 5503, loss = 0.69335 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:52:20.354501 ops/training.py:65 2019-01-16 12:52:20.354427: step 5504, loss = 0.69166 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:52:21.118687 ops/training.py:65 2019-01-16 12:52:21.118619: step 5505, loss = 0.69949 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:52:21.883281 ops/training.py:65 2019-01-16 12:52:21.883229: step 5506, loss = 0.69859 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:52:22.647721 ops/training.py:65 2019-01-16 12:52:22.647661: step 5507, loss = 0.70624 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:52:23.411572 ops/training.py:65 2019-01-16 12:52:23.411508: step 5508, loss = 0.69101 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:52:24.175925 ops/training.py:65 2019-01-16 12:52:24.175858: step 5509, loss = 0.69166 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:52:24.939555 ops/training.py:65 2019-01-16 12:52:24.939487: step 5510, loss = 0.68870 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:52:25.703009 ops/training.py:65 2019-01-16 12:52:25.702945: step 5511, loss = 0.68963 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:52:26.466836 ops/training.py:65 2019-01-16 12:52:26.466785: step 5512, loss = 0.69508 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:52:27.230089 ops/training.py:65 2019-01-16 12:52:27.230019: step 5513, loss = 0.68837 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:52:27.994057 ops/training.py:65 2019-01-16 12:52:27.993988: step 5514, loss = 0.68355 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:52:28.757214 ops/training.py:65 2019-01-16 12:52:28.757145: step 5515, loss = 0.69458 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:52:29.520521 ops/training.py:65 2019-01-16 12:52:29.520469: step 5516, loss = 0.68861 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:52:30.284740 ops/training.py:65 2019-01-16 12:52:30.284697: step 5517, loss = 0.70401 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:52:31.052585 ops/training.py:65 2019-01-16 12:52:31.052514: step 5518, loss = 0.69503 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:52:31.822088 ops/training.py:65 2019-01-16 12:52:31.822007: step 5519, loss = 0.69067 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:52:32.588986 ops/training.py:65 2019-01-16 12:52:32.588914: step 5520, loss = 0.69527 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:52:33.356292 ops/training.py:65 2019-01-16 12:52:33.356229: step 5521, loss = 0.68456 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:52:34.122199 ops/training.py:65 2019-01-16 12:52:34.122150: step 5522, loss = 0.69387 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:52:34.885779 ops/training.py:65 2019-01-16 12:52:34.885712: step 5523, loss = 0.68807 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:52:35.650028 ops/training.py:65 2019-01-16 12:52:35.649957: step 5524, loss = 0.69594 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:52:36.413745 ops/training.py:65 2019-01-16 12:52:36.413684: step 5525, loss = 0.69492 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:52:37.177665 ops/training.py:65 2019-01-16 12:52:37.177623: step 5526, loss = 0.68847 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:52:37.943410 ops/training.py:65 2019-01-16 12:52:37.943358: step 5527, loss = 0.68670 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:52:38.706947 ops/training.py:65 2019-01-16 12:52:38.706876: step 5528, loss = 0.69958 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:52:39.474302 ops/training.py:65 2019-01-16 12:52:39.474235: step 5529, loss = 0.69462 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:52:40.241871 ops/training.py:65 2019-01-16 12:52:40.241800: step 5530, loss = 0.69362 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:52:41.008358 ops/training.py:65 2019-01-16 12:52:41.008300: step 5531, loss = 0.69530 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:52:41.775906 ops/training.py:65 2019-01-16 12:52:41.775847: step 5532, loss = 0.68989 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:52:42.543493 ops/training.py:65 2019-01-16 12:52:42.543420: step 5533, loss = 0.69557 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:52:43.310156 ops/training.py:65 2019-01-16 12:52:43.310080: step 5534, loss = 0.69836 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:52:44.076600 ops/training.py:65 2019-01-16 12:52:44.076523: step 5535, loss = 0.69603 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:52:44.841949 ops/training.py:65 2019-01-16 12:52:44.841873: step 5536, loss = 0.69591 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:52:45.606703 ops/training.py:65 2019-01-16 12:52:45.606645: step 5537, loss = 0.68914 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:52:46.370984 ops/training.py:65 2019-01-16 12:52:46.370915: step 5538, loss = 0.69080 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:52:47.135358 ops/training.py:65 2019-01-16 12:52:47.135286: step 5539, loss = 0.69089 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:52:47.899904 ops/training.py:65 2019-01-16 12:52:47.899835: step 5540, loss = 0.69827 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:52:48.666439 ops/training.py:65 2019-01-16 12:52:48.666385: step 5541, loss = 0.69577 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:52:49.434842 ops/training.py:65 2019-01-16 12:52:49.434767: step 5542, loss = 0.69894 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:52:50.202875 ops/training.py:65 2019-01-16 12:52:50.202792: step 5543, loss = 0.69564 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:52:50.968684 ops/training.py:65 2019-01-16 12:52:50.968614: step 5544, loss = 0.68683 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:52:51.736846 ops/training.py:65 2019-01-16 12:52:51.736785: step 5545, loss = 0.69466 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:52:52.505190 ops/training.py:65 2019-01-16 12:52:52.505110: step 5546, loss = 0.69563 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:52:53.273111 ops/training.py:65 2019-01-16 12:52:53.273035: step 5547, loss = 0.69595 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:52:54.040899 ops/training.py:65 2019-01-16 12:52:54.040821: step 5548, loss = 0.69313 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:52:54.811571 ops/training.py:65 2019-01-16 12:52:54.811499: step 5549, loss = 0.69510 (41.6 examples/sec; 0.770 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:52:55.579533 ops/training.py:65 2019-01-16 12:52:55.579482: step 5550, loss = 0.69467 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:52:56.348503 ops/training.py:65 2019-01-16 12:52:56.348441: step 5551, loss = 0.69507 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:52:57.117102 ops/training.py:65 2019-01-16 12:52:57.117019: step 5552, loss = 0.69655 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:52:57.883721 ops/training.py:65 2019-01-16 12:52:57.883650: step 5553, loss = 0.69100 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:52:58.651721 ops/training.py:65 2019-01-16 12:52:58.651641: step 5554, loss = 0.69706 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:52:59.419630 ops/training.py:65 2019-01-16 12:52:59.419560: step 5555, loss = 0.69343 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:53:00.188413 ops/training.py:65 2019-01-16 12:53:00.188354: step 5556, loss = 0.68922 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:53:00.955806 ops/training.py:65 2019-01-16 12:53:00.955746: step 5557, loss = 0.69101 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:53:01.720664 ops/training.py:65 2019-01-16 12:53:01.720589: step 5558, loss = 0.69168 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:53:02.484969 ops/training.py:65 2019-01-16 12:53:02.484898: step 5559, loss = 0.69012 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:53:03.249688 ops/training.py:65 2019-01-16 12:53:03.249627: step 5560, loss = 0.69364 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:53:04.014359 ops/training.py:65 2019-01-16 12:53:04.014311: step 5561, loss = 0.69279 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:53:04.779155 ops/training.py:65 2019-01-16 12:53:04.779085: step 5562, loss = 0.70333 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.21875
I0528 2019-01-16 12:53:05.546827 ops/training.py:65 2019-01-16 12:53:05.546753: step 5563, loss = 0.69638 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:53:06.315448 ops/training.py:65 2019-01-16 12:53:06.315380: step 5564, loss = 0.69944 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:53:07.084029 ops/training.py:65 2019-01-16 12:53:07.083967: step 5565, loss = 0.69240 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:53:07.853358 ops/training.py:65 2019-01-16 12:53:07.853282: step 5566, loss = 0.69168 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:53:08.620849 ops/training.py:65 2019-01-16 12:53:08.620755: step 5567, loss = 0.69565 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:53:09.385764 ops/training.py:65 2019-01-16 12:53:09.385703: step 5568, loss = 0.69004 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:53:10.150186 ops/training.py:65 2019-01-16 12:53:10.150116: step 5569, loss = 0.69232 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:53:10.914210 ops/training.py:65 2019-01-16 12:53:10.914154: step 5570, loss = 0.68971 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:53:11.678664 ops/training.py:65 2019-01-16 12:53:11.678607: step 5571, loss = 0.68647 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:53:12.444169 ops/training.py:65 2019-01-16 12:53:12.444095: step 5572, loss = 0.68611 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:53:13.208956 ops/training.py:65 2019-01-16 12:53:13.208883: step 5573, loss = 0.69309 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:53:13.973291 ops/training.py:65 2019-01-16 12:53:13.973220: step 5574, loss = 0.69122 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:53:14.743028 ops/training.py:65 2019-01-16 12:53:14.742971: step 5575, loss = 0.69372 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:53:15.511710 ops/training.py:65 2019-01-16 12:53:15.511638: step 5576, loss = 0.68830 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:53:16.278978 ops/training.py:65 2019-01-16 12:53:16.278906: step 5577, loss = 0.69191 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:53:17.046537 ops/training.py:65 2019-01-16 12:53:17.046472: step 5578, loss = 0.69064 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:53:17.815120 ops/training.py:65 2019-01-16 12:53:17.815044: step 5579, loss = 0.68749 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:53:18.583261 ops/training.py:65 2019-01-16 12:53:18.583190: step 5580, loss = 0.69247 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:53:19.349844 ops/training.py:65 2019-01-16 12:53:19.349790: step 5581, loss = 0.70182 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:53:20.117859 ops/training.py:65 2019-01-16 12:53:20.117785: step 5582, loss = 0.69117 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:53:20.885439 ops/training.py:65 2019-01-16 12:53:20.885371: step 5583, loss = 0.69857 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:53:21.653263 ops/training.py:65 2019-01-16 12:53:21.653193: step 5584, loss = 0.69578 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:53:22.422088 ops/training.py:65 2019-01-16 12:53:22.422015: step 5585, loss = 0.69355 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:53:23.188828 ops/training.py:65 2019-01-16 12:53:23.188765: step 5586, loss = 0.69255 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:53:23.957379 ops/training.py:65 2019-01-16 12:53:23.957303: step 5587, loss = 0.69859 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:53:24.724988 ops/training.py:65 2019-01-16 12:53:24.724894: step 5588, loss = 0.69562 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:53:25.491107 ops/training.py:65 2019-01-16 12:53:25.491057: step 5589, loss = 0.69328 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:53:26.254563 ops/training.py:65 2019-01-16 12:53:26.254518: step 5590, loss = 0.68800 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:53:27.018047 ops/training.py:65 2019-01-16 12:53:27.017994: step 5591, loss = 0.68947 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:53:27.780848 ops/training.py:65 2019-01-16 12:53:27.780775: step 5592, loss = 0.69262 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:53:28.545596 ops/training.py:65 2019-01-16 12:53:28.545525: step 5593, loss = 0.69401 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:53:29.310393 ops/training.py:65 2019-01-16 12:53:29.310340: step 5594, loss = 0.69661 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:53:30.074463 ops/training.py:65 2019-01-16 12:53:30.074424: step 5595, loss = 0.68878 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:53:30.839662 ops/training.py:65 2019-01-16 12:53:30.839597: step 5596, loss = 0.68833 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:53:31.604709 ops/training.py:65 2019-01-16 12:53:31.604640: step 5597, loss = 0.69252 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:53:32.369579 ops/training.py:65 2019-01-16 12:53:32.369485: step 5598, loss = 0.69150 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:53:33.134176 ops/training.py:65 2019-01-16 12:53:33.134113: step 5599, loss = 0.69549 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:53:33.898981 ops/training.py:65 2019-01-16 12:53:33.898933: step 5600, loss = 0.68961 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:53:34.663193 ops/training.py:65 2019-01-16 12:53:34.663123: step 5601, loss = 0.68998 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:53:35.427125 ops/training.py:65 2019-01-16 12:53:35.427056: step 5602, loss = 0.69562 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:53:36.190726 ops/training.py:65 2019-01-16 12:53:36.190678: step 5603, loss = 0.69139 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:53:36.958724 ops/training.py:65 2019-01-16 12:53:36.958659: step 5604, loss = 0.69553 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:53:37.726111 ops/training.py:65 2019-01-16 12:53:37.726031: step 5605, loss = 0.68558 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:53:38.492701 ops/training.py:65 2019-01-16 12:53:38.492636: step 5606, loss = 0.69375 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:53:39.255950 ops/training.py:65 2019-01-16 12:53:39.255886: step 5607, loss = 0.69754 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:53:40.019278 ops/training.py:65 2019-01-16 12:53:40.019204: step 5608, loss = 0.69530 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:53:40.787937 ops/training.py:65 2019-01-16 12:53:40.787885: step 5609, loss = 0.69120 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:53:41.553993 ops/training.py:65 2019-01-16 12:53:41.553930: step 5610, loss = 0.69494 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:53:42.323228 ops/training.py:65 2019-01-16 12:53:42.323151: step 5611, loss = 0.69883 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:53:43.089630 ops/training.py:65 2019-01-16 12:53:43.089553: step 5612, loss = 0.69339 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:53:43.856615 ops/training.py:65 2019-01-16 12:53:43.856537: step 5613, loss = 0.69337 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:53:44.621899 ops/training.py:65 2019-01-16 12:53:44.621844: step 5614, loss = 0.68839 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:53:45.385729 ops/training.py:65 2019-01-16 12:53:45.385685: step 5615, loss = 0.69896 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:53:46.149417 ops/training.py:65 2019-01-16 12:53:46.149364: step 5616, loss = 0.69377 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:53:46.912551 ops/training.py:65 2019-01-16 12:53:46.912477: step 5617, loss = 0.69753 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:53:47.676710 ops/training.py:65 2019-01-16 12:53:47.676648: step 5618, loss = 0.69211 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:53:48.440592 ops/training.py:65 2019-01-16 12:53:48.440549: step 5619, loss = 0.69383 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:53:49.204533 ops/training.py:65 2019-01-16 12:53:49.204484: step 5620, loss = 0.68726 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:53:49.967401 ops/training.py:65 2019-01-16 12:53:49.967328: step 5621, loss = 0.68906 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:53:50.732836 ops/training.py:65 2019-01-16 12:53:50.732771: step 5622, loss = 0.69433 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:53:51.495610 ops/training.py:65 2019-01-16 12:53:51.495547: step 5623, loss = 0.69111 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:53:52.259022 ops/training.py:65 2019-01-16 12:53:52.258975: step 5624, loss = 0.69091 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:53:53.022037 ops/training.py:65 2019-01-16 12:53:53.021984: step 5625, loss = 0.69686 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:53:53.785777 ops/training.py:65 2019-01-16 12:53:53.785710: step 5626, loss = 0.69005 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:53:54.552952 ops/training.py:65 2019-01-16 12:53:54.552877: step 5627, loss = 0.68990 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:53:55.320718 ops/training.py:65 2019-01-16 12:53:55.320654: step 5628, loss = 0.69030 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:53:56.089684 ops/training.py:65 2019-01-16 12:53:56.089621: step 5629, loss = 0.69483 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:53:56.857696 ops/training.py:65 2019-01-16 12:53:56.857642: step 5630, loss = 0.69328 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:53:57.625158 ops/training.py:65 2019-01-16 12:53:57.625073: step 5631, loss = 0.69135 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:53:58.390798 ops/training.py:65 2019-01-16 12:53:58.390724: step 5632, loss = 0.69508 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:53:59.154040 ops/training.py:65 2019-01-16 12:53:59.153979: step 5633, loss = 0.69535 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:53:59.918870 ops/training.py:65 2019-01-16 12:53:59.918798: step 5634, loss = 0.69274 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:54:00.683889 ops/training.py:65 2019-01-16 12:54:00.683828: step 5635, loss = 0.68511 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:54:01.447838 ops/training.py:65 2019-01-16 12:54:01.447761: step 5636, loss = 0.69207 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:54:02.214404 ops/training.py:65 2019-01-16 12:54:02.214340: step 5637, loss = 0.69771 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:54:02.982317 ops/training.py:65 2019-01-16 12:54:02.982241: step 5638, loss = 0.68497 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:54:03.749491 ops/training.py:65 2019-01-16 12:54:03.749433: step 5639, loss = 0.69452 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:54:04.515190 ops/training.py:65 2019-01-16 12:54:04.515135: step 5640, loss = 0.70029 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:54:05.279238 ops/training.py:65 2019-01-16 12:54:05.279171: step 5641, loss = 0.69089 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:54:06.043024 ops/training.py:65 2019-01-16 12:54:06.042947: step 5642, loss = 0.69080 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:54:06.810350 ops/training.py:65 2019-01-16 12:54:06.810300: step 5643, loss = 0.69255 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:54:07.579895 ops/training.py:65 2019-01-16 12:54:07.579861: step 5644, loss = 0.68401 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:54:08.347088 ops/training.py:65 2019-01-16 12:54:08.347028: step 5645, loss = 0.69182 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:54:09.116735 ops/training.py:65 2019-01-16 12:54:09.116668: step 5646, loss = 0.69061 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:54:09.885378 ops/training.py:65 2019-01-16 12:54:09.885315: step 5647, loss = 0.69183 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:54:10.653521 ops/training.py:65 2019-01-16 12:54:10.653446: step 5648, loss = 0.69018 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:54:11.422693 ops/training.py:65 2019-01-16 12:54:11.422631: step 5649, loss = 0.68814 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:54:12.190104 ops/training.py:65 2019-01-16 12:54:12.190022: step 5650, loss = 0.69964 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:54:12.954647 ops/training.py:65 2019-01-16 12:54:12.954571: step 5651, loss = 0.69687 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:54:13.721517 ops/training.py:65 2019-01-16 12:54:13.721439: step 5652, loss = 0.69099 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:54:14.488877 ops/training.py:65 2019-01-16 12:54:14.488801: step 5653, loss = 0.68922 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:54:15.256215 ops/training.py:65 2019-01-16 12:54:15.256157: step 5654, loss = 0.68974 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:54:16.023851 ops/training.py:65 2019-01-16 12:54:16.023773: step 5655, loss = 0.69353 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:54:16.789384 ops/training.py:65 2019-01-16 12:54:16.789308: step 5656, loss = 0.68854 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:54:17.556240 ops/training.py:65 2019-01-16 12:54:17.556160: step 5657, loss = 0.69336 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:54:18.324078 ops/training.py:65 2019-01-16 12:54:18.324007: step 5658, loss = 0.68765 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:54:19.090670 ops/training.py:65 2019-01-16 12:54:19.090608: step 5659, loss = 0.69034 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:54:19.857443 ops/training.py:65 2019-01-16 12:54:19.857371: step 5660, loss = 0.69867 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:54:20.624844 ops/training.py:65 2019-01-16 12:54:20.624765: step 5661, loss = 0.69797 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:54:21.392575 ops/training.py:65 2019-01-16 12:54:21.392507: step 5662, loss = 0.69891 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:54:22.159421 ops/training.py:65 2019-01-16 12:54:22.159349: step 5663, loss = 0.69743 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:54:22.926952 ops/training.py:65 2019-01-16 12:54:22.926872: step 5664, loss = 0.69520 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:54:23.693783 ops/training.py:65 2019-01-16 12:54:23.693707: step 5665, loss = 0.68882 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 12:54:24.459302 ops/training.py:65 2019-01-16 12:54:24.459235: step 5666, loss = 0.69145 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:54:25.224956 ops/training.py:65 2019-01-16 12:54:25.224880: step 5667, loss = 0.69202 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:54:25.992336 ops/training.py:65 2019-01-16 12:54:25.992278: step 5668, loss = 0.70526 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:54:26.759034 ops/training.py:65 2019-01-16 12:54:26.758962: step 5669, loss = 0.69506 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:54:27.527212 ops/training.py:65 2019-01-16 12:54:27.527149: step 5670, loss = 0.69596 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:54:28.293636 ops/training.py:65 2019-01-16 12:54:28.293573: step 5671, loss = 0.69296 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:54:29.059043 ops/training.py:65 2019-01-16 12:54:29.058989: step 5672, loss = 0.67739 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 12:54:29.823314 ops/training.py:65 2019-01-16 12:54:29.823257: step 5673, loss = 0.70032 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:54:30.587653 ops/training.py:65 2019-01-16 12:54:30.587580: step 5674, loss = 0.70292 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:54:31.354755 ops/training.py:65 2019-01-16 12:54:31.354682: step 5675, loss = 0.68805 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:54:32.122384 ops/training.py:65 2019-01-16 12:54:32.122303: step 5676, loss = 0.69642 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:54:32.886836 ops/training.py:65 2019-01-16 12:54:32.886757: step 5677, loss = 0.68817 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:54:33.650206 ops/training.py:65 2019-01-16 12:54:33.650139: step 5678, loss = 0.70135 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:54:34.413752 ops/training.py:65 2019-01-16 12:54:34.413693: step 5679, loss = 0.68639 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:54:35.177905 ops/training.py:65 2019-01-16 12:54:35.177831: step 5680, loss = 0.68335 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:54:35.942156 ops/training.py:65 2019-01-16 12:54:35.942079: step 5681, loss = 0.69012 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:54:36.706483 ops/training.py:65 2019-01-16 12:54:36.706409: step 5682, loss = 0.68282 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:54:37.470272 ops/training.py:65 2019-01-16 12:54:37.470209: step 5683, loss = 0.69565 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:54:38.232755 ops/training.py:65 2019-01-16 12:54:38.232703: step 5684, loss = 0.69499 (42.0 examples/sec; 0.761 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:54:38.996048 ops/training.py:65 2019-01-16 12:54:38.995987: step 5685, loss = 0.69165 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:54:39.759295 ops/training.py:65 2019-01-16 12:54:39.759215: step 5686, loss = 0.69421 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:54:40.523715 ops/training.py:65 2019-01-16 12:54:40.523609: step 5687, loss = 0.69486 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:54:41.286938 ops/training.py:65 2019-01-16 12:54:41.286854: step 5688, loss = 0.69379 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:54:42.051242 ops/training.py:65 2019-01-16 12:54:42.051179: step 5689, loss = 0.69143 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:54:42.815914 ops/training.py:65 2019-01-16 12:54:42.815829: step 5690, loss = 0.69233 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:54:43.580812 ops/training.py:65 2019-01-16 12:54:43.580743: step 5691, loss = 0.68545 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:54:44.347819 ops/training.py:65 2019-01-16 12:54:44.347744: step 5692, loss = 0.69349 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:54:45.114800 ops/training.py:65 2019-01-16 12:54:45.114721: step 5693, loss = 0.70077 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:54:45.882308 ops/training.py:65 2019-01-16 12:54:45.882226: step 5694, loss = 0.69370 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:54:46.649139 ops/training.py:65 2019-01-16 12:54:46.649057: step 5695, loss = 0.69186 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:54:47.415623 ops/training.py:65 2019-01-16 12:54:47.415547: step 5696, loss = 0.70267 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:54:48.182974 ops/training.py:65 2019-01-16 12:54:48.182902: step 5697, loss = 0.69476 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:54:48.949977 ops/training.py:65 2019-01-16 12:54:48.949902: step 5698, loss = 0.69948 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:54:49.717211 ops/training.py:65 2019-01-16 12:54:49.717161: step 5699, loss = 0.69886 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:54:50.484209 ops/training.py:65 2019-01-16 12:54:50.484130: step 5700, loss = 0.70164 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:54:51.249124 ops/training.py:65 2019-01-16 12:54:51.249074: step 5701, loss = 0.68230 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:54:52.013123 ops/training.py:65 2019-01-16 12:54:52.013052: step 5702, loss = 0.68486 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:54:52.776399 ops/training.py:65 2019-01-16 12:54:52.776331: step 5703, loss = 0.69321 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:54:53.539944 ops/training.py:65 2019-01-16 12:54:53.539892: step 5704, loss = 0.68632 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:54:54.303524 ops/training.py:65 2019-01-16 12:54:54.303456: step 5705, loss = 0.70257 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:54:55.066949 ops/training.py:65 2019-01-16 12:54:55.066872: step 5706, loss = 0.68425 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:54:55.830272 ops/training.py:65 2019-01-16 12:54:55.830204: step 5707, loss = 0.69813 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:54:56.594306 ops/training.py:65 2019-01-16 12:54:56.594252: step 5708, loss = 0.69763 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:54:57.358023 ops/training.py:65 2019-01-16 12:54:57.357952: step 5709, loss = 0.69323 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:54:58.123908 ops/training.py:65 2019-01-16 12:54:58.123835: step 5710, loss = 0.69520 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:54:58.891860 ops/training.py:65 2019-01-16 12:54:58.891782: step 5711, loss = 0.69555 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:54:59.659713 ops/training.py:65 2019-01-16 12:54:59.659635: step 5712, loss = 0.69700 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:55:00.424515 ops/training.py:65 2019-01-16 12:55:00.424470: step 5713, loss = 0.69812 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:55:01.187877 ops/training.py:65 2019-01-16 12:55:01.187807: step 5714, loss = 0.69244 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:55:01.952240 ops/training.py:65 2019-01-16 12:55:01.952172: step 5715, loss = 0.69640 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:55:02.716914 ops/training.py:65 2019-01-16 12:55:02.716851: step 5716, loss = 0.68508 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:55:03.479850 ops/training.py:65 2019-01-16 12:55:03.479792: step 5717, loss = 0.69925 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:55:04.243666 ops/training.py:65 2019-01-16 12:55:04.243616: step 5718, loss = 0.68181 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:55:05.007462 ops/training.py:65 2019-01-16 12:55:05.007389: step 5719, loss = 0.69308 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:55:05.771637 ops/training.py:65 2019-01-16 12:55:05.771562: step 5720, loss = 0.70307 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:55:06.536138 ops/training.py:65 2019-01-16 12:55:06.536062: step 5721, loss = 0.69351 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:55:07.299906 ops/training.py:65 2019-01-16 12:55:07.299846: step 5722, loss = 0.70313 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:55:08.065747 ops/training.py:65 2019-01-16 12:55:08.065692: step 5723, loss = 0.68820 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:55:08.832947 ops/training.py:65 2019-01-16 12:55:08.832868: step 5724, loss = 0.68780 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:55:09.601061 ops/training.py:65 2019-01-16 12:55:09.600986: step 5725, loss = 0.68939 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:55:10.368713 ops/training.py:65 2019-01-16 12:55:10.368633: step 5726, loss = 0.69493 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:55:11.134571 ops/training.py:65 2019-01-16 12:55:11.134522: step 5727, loss = 0.70205 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:55:11.899871 ops/training.py:65 2019-01-16 12:55:11.899795: step 5728, loss = 0.70359 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:55:12.664389 ops/training.py:65 2019-01-16 12:55:12.664315: step 5729, loss = 0.68552 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:55:13.429380 ops/training.py:65 2019-01-16 12:55:13.429309: step 5730, loss = 0.68806 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:55:14.193084 ops/training.py:65 2019-01-16 12:55:14.193014: step 5731, loss = 0.69899 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:55:14.960344 ops/training.py:65 2019-01-16 12:55:14.960276: step 5732, loss = 0.69328 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:55:15.728503 ops/training.py:65 2019-01-16 12:55:15.728445: step 5733, loss = 0.69834 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:55:16.497282 ops/training.py:65 2019-01-16 12:55:16.497212: step 5734, loss = 0.69154 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:55:17.263337 ops/training.py:65 2019-01-16 12:55:17.263278: step 5735, loss = 0.68804 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:55:18.029696 ops/training.py:65 2019-01-16 12:55:18.029645: step 5736, loss = 0.69707 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:55:18.797277 ops/training.py:65 2019-01-16 12:55:18.797227: step 5737, loss = 0.70569 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:55:19.561880 ops/training.py:65 2019-01-16 12:55:19.561814: step 5738, loss = 0.68736 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:55:20.326097 ops/training.py:65 2019-01-16 12:55:20.326028: step 5739, loss = 0.69179 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:55:21.089824 ops/training.py:65 2019-01-16 12:55:21.089756: step 5740, loss = 0.70119 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:55:21.853383 ops/training.py:65 2019-01-16 12:55:21.853316: step 5741, loss = 0.69364 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:55:22.618927 ops/training.py:65 2019-01-16 12:55:22.618874: step 5742, loss = 0.69059 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:55:23.382331 ops/training.py:65 2019-01-16 12:55:23.382277: step 5743, loss = 0.69423 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:55:24.145124 ops/training.py:65 2019-01-16 12:55:24.145053: step 5744, loss = 0.69813 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:55:24.908032 ops/training.py:65 2019-01-16 12:55:24.907956: step 5745, loss = 0.69471 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:55:25.671704 ops/training.py:65 2019-01-16 12:55:25.671639: step 5746, loss = 0.69502 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:55:26.435627 ops/training.py:65 2019-01-16 12:55:26.435585: step 5747, loss = 0.69374 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:55:27.198794 ops/training.py:65 2019-01-16 12:55:27.198743: step 5748, loss = 0.69625 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:55:27.962419 ops/training.py:65 2019-01-16 12:55:27.962343: step 5749, loss = 0.69440 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:55:28.724975 ops/training.py:65 2019-01-16 12:55:28.724909: step 5750, loss = 0.69519 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:55:29.489293 ops/training.py:65 2019-01-16 12:55:29.489231: step 5751, loss = 0.69094 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:55:30.252981 ops/training.py:65 2019-01-16 12:55:30.252937: step 5752, loss = 0.68629 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 12:55:31.019235 ops/training.py:65 2019-01-16 12:55:31.019168: step 5753, loss = 0.69217 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:55:31.785866 ops/training.py:65 2019-01-16 12:55:31.785788: step 5754, loss = 0.69606 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:55:32.553676 ops/training.py:65 2019-01-16 12:55:32.553598: step 5755, loss = 0.69212 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:55:33.320426 ops/training.py:65 2019-01-16 12:55:33.320359: step 5756, loss = 0.69091 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:55:34.086860 ops/training.py:65 2019-01-16 12:55:34.086791: step 5757, loss = 0.69368 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:55:34.851202 ops/training.py:65 2019-01-16 12:55:34.851133: step 5758, loss = 0.68662 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:55:35.615597 ops/training.py:65 2019-01-16 12:55:35.615522: step 5759, loss = 0.69297 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:55:36.378957 ops/training.py:65 2019-01-16 12:55:36.378891: step 5760, loss = 0.69008 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:55:37.142907 ops/training.py:65 2019-01-16 12:55:37.142829: step 5761, loss = 0.69430 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:55:37.906747 ops/training.py:65 2019-01-16 12:55:37.906692: step 5762, loss = 0.69254 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:55:38.670898 ops/training.py:65 2019-01-16 12:55:38.670834: step 5763, loss = 0.68908 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:55:39.434600 ops/training.py:65 2019-01-16 12:55:39.434542: step 5764, loss = 0.68903 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:55:40.199134 ops/training.py:65 2019-01-16 12:55:40.199073: step 5765, loss = 0.68646 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:55:40.963058 ops/training.py:65 2019-01-16 12:55:40.963010: step 5766, loss = 0.69374 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:55:41.727484 ops/training.py:65 2019-01-16 12:55:41.727423: step 5767, loss = 0.69217 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:55:42.491728 ops/training.py:65 2019-01-16 12:55:42.491654: step 5768, loss = 0.68682 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.75
I0528 2019-01-16 12:55:43.256001 ops/training.py:65 2019-01-16 12:55:43.255923: step 5769, loss = 0.69898 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:55:44.020599 ops/training.py:65 2019-01-16 12:55:44.020526: step 5770, loss = 0.70125 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 12:55:44.784845 ops/training.py:65 2019-01-16 12:55:44.784773: step 5771, loss = 0.69136 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:55:45.548317 ops/training.py:65 2019-01-16 12:55:45.548271: step 5772, loss = 0.69514 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:55:46.311727 ops/training.py:65 2019-01-16 12:55:46.311670: step 5773, loss = 0.69489 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:55:47.076277 ops/training.py:65 2019-01-16 12:55:47.076197: step 5774, loss = 0.70150 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 12:55:47.840453 ops/training.py:65 2019-01-16 12:55:47.840380: step 5775, loss = 0.69592 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:55:48.603292 ops/training.py:65 2019-01-16 12:55:48.603235: step 5776, loss = 0.68387 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:55:49.367009 ops/training.py:65 2019-01-16 12:55:49.366956: step 5777, loss = 0.69396 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:55:50.130994 ops/training.py:65 2019-01-16 12:55:50.130924: step 5778, loss = 0.69270 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:55:50.895578 ops/training.py:65 2019-01-16 12:55:50.895509: step 5779, loss = 0.69156 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:55:51.659309 ops/training.py:65 2019-01-16 12:55:51.659247: step 5780, loss = 0.69186 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:55:52.423175 ops/training.py:65 2019-01-16 12:55:52.423125: step 5781, loss = 0.69357 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:55:53.187955 ops/training.py:65 2019-01-16 12:55:53.187891: step 5782, loss = 0.69877 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:55:53.951704 ops/training.py:65 2019-01-16 12:55:53.951630: step 5783, loss = 0.69497 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:55:54.715671 ops/training.py:65 2019-01-16 12:55:54.715596: step 5784, loss = 0.69104 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:55:55.478436 ops/training.py:65 2019-01-16 12:55:55.478372: step 5785, loss = 0.69244 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:55:56.241794 ops/training.py:65 2019-01-16 12:55:56.241742: step 5786, loss = 0.69363 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:55:57.004917 ops/training.py:65 2019-01-16 12:55:57.004841: step 5787, loss = 0.68524 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:55:57.769359 ops/training.py:65 2019-01-16 12:55:57.769289: step 5788, loss = 0.69043 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:55:58.532252 ops/training.py:65 2019-01-16 12:55:58.532180: step 5789, loss = 0.68992 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:55:59.295824 ops/training.py:65 2019-01-16 12:55:59.295766: step 5790, loss = 0.68462 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:56:00.059172 ops/training.py:65 2019-01-16 12:56:00.059116: step 5791, loss = 0.69490 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:56:00.822468 ops/training.py:65 2019-01-16 12:56:00.822399: step 5792, loss = 0.69461 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:56:01.585476 ops/training.py:65 2019-01-16 12:56:01.585405: step 5793, loss = 0.69326 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:56:02.349208 ops/training.py:65 2019-01-16 12:56:02.349145: step 5794, loss = 0.68613 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:56:03.114301 ops/training.py:65 2019-01-16 12:56:03.114242: step 5795, loss = 0.69135 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:56:03.879580 ops/training.py:65 2019-01-16 12:56:03.879523: step 5796, loss = 0.69358 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:56:04.644413 ops/training.py:65 2019-01-16 12:56:04.644344: step 5797, loss = 0.68627 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:56:05.410159 ops/training.py:65 2019-01-16 12:56:05.410084: step 5798, loss = 0.69372 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:56:06.173777 ops/training.py:65 2019-01-16 12:56:06.173708: step 5799, loss = 0.69646 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:56:06.938145 ops/training.py:65 2019-01-16 12:56:06.938077: step 5800, loss = 0.68647 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:56:07.703655 ops/training.py:65 2019-01-16 12:56:07.703599: step 5801, loss = 0.69446 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:56:08.468254 ops/training.py:65 2019-01-16 12:56:08.468183: step 5802, loss = 0.69899 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:56:09.235284 ops/training.py:65 2019-01-16 12:56:09.235223: step 5803, loss = 0.69505 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:56:10.003252 ops/training.py:65 2019-01-16 12:56:10.003200: step 5804, loss = 0.68953 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:56:10.769783 ops/training.py:65 2019-01-16 12:56:10.769727: step 5805, loss = 0.69178 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:56:11.538392 ops/training.py:65 2019-01-16 12:56:11.538329: step 5806, loss = 0.69828 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:56:12.306222 ops/training.py:65 2019-01-16 12:56:12.306142: step 5807, loss = 0.68880 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:56:13.071422 ops/training.py:65 2019-01-16 12:56:13.071343: step 5808, loss = 0.68722 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:56:13.835329 ops/training.py:65 2019-01-16 12:56:13.835284: step 5809, loss = 0.70177 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:56:14.601440 ops/training.py:65 2019-01-16 12:56:14.601388: step 5810, loss = 0.69038 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:56:15.369673 ops/training.py:65 2019-01-16 12:56:15.369616: step 5811, loss = 0.69550 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:56:16.136656 ops/training.py:65 2019-01-16 12:56:16.136607: step 5812, loss = 0.68449 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:56:16.900709 ops/training.py:65 2019-01-16 12:56:16.900640: step 5813, loss = 0.68470 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:56:17.664860 ops/training.py:65 2019-01-16 12:56:17.664789: step 5814, loss = 0.68946 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:56:18.433602 ops/training.py:65 2019-01-16 12:56:18.433551: step 5815, loss = 0.68727 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:56:19.201822 ops/training.py:65 2019-01-16 12:56:19.201755: step 5816, loss = 0.68280 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:56:19.969645 ops/training.py:65 2019-01-16 12:56:19.969586: step 5817, loss = 0.68751 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:56:20.736788 ops/training.py:65 2019-01-16 12:56:20.736732: step 5818, loss = 0.69193 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:56:21.503832 ops/training.py:65 2019-01-16 12:56:21.503780: step 5819, loss = 0.69974 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:56:22.271967 ops/training.py:65 2019-01-16 12:56:22.271913: step 5820, loss = 0.69852 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:56:23.037111 ops/training.py:65 2019-01-16 12:56:23.037032: step 5821, loss = 0.70105 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:56:23.802487 ops/training.py:65 2019-01-16 12:56:23.802431: step 5822, loss = 0.69637 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:56:24.567163 ops/training.py:65 2019-01-16 12:56:24.567109: step 5823, loss = 0.69270 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:56:25.335598 ops/training.py:65 2019-01-16 12:56:25.335545: step 5824, loss = 0.69155 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:56:26.103320 ops/training.py:65 2019-01-16 12:56:26.103269: step 5825, loss = 0.68898 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:56:26.868125 ops/training.py:65 2019-01-16 12:56:26.868073: step 5826, loss = 0.69653 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:56:27.634016 ops/training.py:65 2019-01-16 12:56:27.633963: step 5827, loss = 0.69445 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:56:28.398794 ops/training.py:65 2019-01-16 12:56:28.398751: step 5828, loss = 0.69380 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:56:29.163458 ops/training.py:65 2019-01-16 12:56:29.163415: step 5829, loss = 0.69151 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:56:29.932217 ops/training.py:65 2019-01-16 12:56:29.932168: step 5830, loss = 0.69100 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:56:30.699796 ops/training.py:65 2019-01-16 12:56:30.699727: step 5831, loss = 0.68808 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:56:31.466255 ops/training.py:65 2019-01-16 12:56:31.466185: step 5832, loss = 0.68822 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:56:32.233188 ops/training.py:65 2019-01-16 12:56:32.233126: step 5833, loss = 0.68819 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:56:32.999868 ops/training.py:65 2019-01-16 12:56:32.999803: step 5834, loss = 0.69966 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:56:33.765168 ops/training.py:65 2019-01-16 12:56:33.765103: step 5835, loss = 0.69453 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:56:34.532404 ops/training.py:65 2019-01-16 12:56:34.532320: step 5836, loss = 0.69400 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:56:35.298431 ops/training.py:65 2019-01-16 12:56:35.298373: step 5837, loss = 0.68907 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:56:36.062585 ops/training.py:65 2019-01-16 12:56:36.062522: step 5838, loss = 0.69045 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:56:36.825337 ops/training.py:65 2019-01-16 12:56:36.825280: step 5839, loss = 0.69343 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:56:37.589541 ops/training.py:65 2019-01-16 12:56:37.589488: step 5840, loss = 0.68818 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:56:38.354115 ops/training.py:65 2019-01-16 12:56:38.354057: step 5841, loss = 0.69572 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:56:39.118307 ops/training.py:65 2019-01-16 12:56:39.118258: step 5842, loss = 0.69154 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:56:39.884054 ops/training.py:65 2019-01-16 12:56:39.883997: step 5843, loss = 0.68820 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:56:40.650489 ops/training.py:65 2019-01-16 12:56:40.650426: step 5844, loss = 0.69255 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:56:41.416981 ops/training.py:65 2019-01-16 12:56:41.416922: step 5845, loss = 0.69462 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:56:42.181334 ops/training.py:65 2019-01-16 12:56:42.181272: step 5846, loss = 0.69690 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:56:42.945696 ops/training.py:65 2019-01-16 12:56:42.945629: step 5847, loss = 0.68986 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:56:43.709350 ops/training.py:65 2019-01-16 12:56:43.709282: step 5848, loss = 0.69054 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:56:44.473376 ops/training.py:65 2019-01-16 12:56:44.473304: step 5849, loss = 0.69269 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:56:45.237305 ops/training.py:65 2019-01-16 12:56:45.237261: step 5850, loss = 0.69546 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:56:46.001268 ops/training.py:65 2019-01-16 12:56:46.001207: step 5851, loss = 0.69316 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:56:46.767001 ops/training.py:65 2019-01-16 12:56:46.766933: step 5852, loss = 0.69521 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:56:47.534944 ops/training.py:65 2019-01-16 12:56:47.534857: step 5853, loss = 0.68861 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:56:48.302203 ops/training.py:65 2019-01-16 12:56:48.302125: step 5854, loss = 0.69094 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:56:49.067388 ops/training.py:65 2019-01-16 12:56:49.067339: step 5855, loss = 0.69330 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:56:49.834703 ops/training.py:65 2019-01-16 12:56:49.834631: step 5856, loss = 0.69274 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:56:50.602674 ops/training.py:65 2019-01-16 12:56:50.602616: step 5857, loss = 0.68604 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:56:51.371392 ops/training.py:65 2019-01-16 12:56:51.371343: step 5858, loss = 0.68376 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 12:56:52.139308 ops/training.py:65 2019-01-16 12:56:52.139257: step 5859, loss = 0.68911 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:56:52.906144 ops/training.py:65 2019-01-16 12:56:52.906071: step 5860, loss = 0.68997 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:56:53.673859 ops/training.py:65 2019-01-16 12:56:53.673799: step 5861, loss = 0.69345 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:56:54.441636 ops/training.py:65 2019-01-16 12:56:54.441578: step 5862, loss = 0.69012 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:56:55.208328 ops/training.py:65 2019-01-16 12:56:55.208275: step 5863, loss = 0.69129 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:56:55.975895 ops/training.py:65 2019-01-16 12:56:55.975831: step 5864, loss = 0.68713 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:56:56.740114 ops/training.py:65 2019-01-16 12:56:56.740059: step 5865, loss = 0.69528 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:56:57.503045 ops/training.py:65 2019-01-16 12:56:57.502976: step 5866, loss = 0.69260 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:56:58.266249 ops/training.py:65 2019-01-16 12:56:58.266174: step 5867, loss = 0.68852 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:56:59.030528 ops/training.py:65 2019-01-16 12:56:59.030471: step 5868, loss = 0.68796 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:56:59.795061 ops/training.py:65 2019-01-16 12:56:59.794990: step 5869, loss = 0.69935 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:57:00.559200 ops/training.py:65 2019-01-16 12:57:00.559139: step 5870, loss = 0.69181 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:57:01.322625 ops/training.py:65 2019-01-16 12:57:01.322555: step 5871, loss = 0.69147 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:57:02.086315 ops/training.py:65 2019-01-16 12:57:02.086254: step 5872, loss = 0.69140 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:57:02.850095 ops/training.py:65 2019-01-16 12:57:02.850025: step 5873, loss = 0.69066 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:57:03.617330 ops/training.py:65 2019-01-16 12:57:03.617286: step 5874, loss = 0.69144 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:57:04.384852 ops/training.py:65 2019-01-16 12:57:04.384773: step 5875, loss = 0.69774 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:57:05.151611 ops/training.py:65 2019-01-16 12:57:05.151559: step 5876, loss = 0.68999 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:57:05.916149 ops/training.py:65 2019-01-16 12:57:05.916084: step 5877, loss = 0.69395 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:57:06.679638 ops/training.py:65 2019-01-16 12:57:06.679579: step 5878, loss = 0.68101 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:57:07.449335 ops/training.py:65 2019-01-16 12:57:07.449277: step 5879, loss = 0.68870 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:57:08.217169 ops/training.py:65 2019-01-16 12:57:08.217077: step 5880, loss = 0.68649 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:57:08.983543 ops/training.py:65 2019-01-16 12:57:08.983484: step 5881, loss = 0.69501 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:57:09.747380 ops/training.py:65 2019-01-16 12:57:09.747318: step 5882, loss = 0.68475 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:57:10.512183 ops/training.py:65 2019-01-16 12:57:10.512128: step 5883, loss = 0.69121 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:57:11.274910 ops/training.py:65 2019-01-16 12:57:11.274853: step 5884, loss = 0.69045 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:57:12.042598 ops/training.py:65 2019-01-16 12:57:12.042536: step 5885, loss = 0.69607 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:57:12.810155 ops/training.py:65 2019-01-16 12:57:12.810080: step 5886, loss = 0.69386 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:57:13.574937 ops/training.py:65 2019-01-16 12:57:13.574873: step 5887, loss = 0.69332 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:57:14.343009 ops/training.py:65 2019-01-16 12:57:14.342953: step 5888, loss = 0.69757 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:57:15.111261 ops/training.py:65 2019-01-16 12:57:15.111196: step 5889, loss = 0.69024 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:57:15.878631 ops/training.py:65 2019-01-16 12:57:15.878571: step 5890, loss = 0.69622 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:57:16.646943 ops/training.py:65 2019-01-16 12:57:16.646866: step 5891, loss = 0.68742 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 12:57:17.412557 ops/training.py:65 2019-01-16 12:57:17.412485: step 5892, loss = 0.68257 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:57:18.177351 ops/training.py:65 2019-01-16 12:57:18.177276: step 5893, loss = 0.69030 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:57:18.942153 ops/training.py:65 2019-01-16 12:57:18.942098: step 5894, loss = 0.70051 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:57:19.706435 ops/training.py:65 2019-01-16 12:57:19.706384: step 5895, loss = 0.69924 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:57:20.473104 ops/training.py:65 2019-01-16 12:57:20.473051: step 5896, loss = 0.70009 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:57:21.240150 ops/training.py:65 2019-01-16 12:57:21.240077: step 5897, loss = 0.68954 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:57:22.006225 ops/training.py:65 2019-01-16 12:57:22.006154: step 5898, loss = 0.69117 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:57:22.770068 ops/training.py:65 2019-01-16 12:57:22.770013: step 5899, loss = 0.69965 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:57:23.533705 ops/training.py:65 2019-01-16 12:57:23.533633: step 5900, loss = 0.69773 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:57:24.297067 ops/training.py:65 2019-01-16 12:57:24.296994: step 5901, loss = 0.68685 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:57:25.060381 ops/training.py:65 2019-01-16 12:57:25.060309: step 5902, loss = 0.69751 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:57:25.824125 ops/training.py:65 2019-01-16 12:57:25.824077: step 5903, loss = 0.68966 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:57:26.588840 ops/training.py:65 2019-01-16 12:57:26.588789: step 5904, loss = 0.69273 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:57:27.353461 ops/training.py:65 2019-01-16 12:57:27.353395: step 5905, loss = 0.68908 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:57:28.119360 ops/training.py:65 2019-01-16 12:57:28.119290: step 5906, loss = 0.69474 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:57:28.887721 ops/training.py:65 2019-01-16 12:57:28.887648: step 5907, loss = 0.69530 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:57:29.655466 ops/training.py:65 2019-01-16 12:57:29.655411: step 5908, loss = 0.69245 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:57:30.420878 ops/training.py:65 2019-01-16 12:57:30.420831: step 5909, loss = 0.69706 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:57:31.184409 ops/training.py:65 2019-01-16 12:57:31.184353: step 5910, loss = 0.68933 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:57:31.948172 ops/training.py:65 2019-01-16 12:57:31.948119: step 5911, loss = 0.69511 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:57:32.712199 ops/training.py:65 2019-01-16 12:57:32.712150: step 5912, loss = 0.68587 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 12:57:33.476301 ops/training.py:65 2019-01-16 12:57:33.476257: step 5913, loss = 0.68870 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:57:34.239876 ops/training.py:65 2019-01-16 12:57:34.239826: step 5914, loss = 0.69570 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:57:35.002976 ops/training.py:65 2019-01-16 12:57:35.002911: step 5915, loss = 0.68926 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:57:35.766347 ops/training.py:65 2019-01-16 12:57:35.766282: step 5916, loss = 0.69446 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:57:36.529993 ops/training.py:65 2019-01-16 12:57:36.529920: step 5917, loss = 0.70073 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 12:57:37.294321 ops/training.py:65 2019-01-16 12:57:37.294250: step 5918, loss = 0.68961 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:57:38.058401 ops/training.py:65 2019-01-16 12:57:38.058348: step 5919, loss = 0.68841 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:57:38.822619 ops/training.py:65 2019-01-16 12:57:38.822555: step 5920, loss = 0.69130 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:57:39.586623 ops/training.py:65 2019-01-16 12:57:39.586573: step 5921, loss = 0.69635 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:57:40.350155 ops/training.py:65 2019-01-16 12:57:40.350106: step 5922, loss = 0.69417 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:57:41.113854 ops/training.py:65 2019-01-16 12:57:41.113789: step 5923, loss = 0.69521 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:57:41.878158 ops/training.py:65 2019-01-16 12:57:41.878102: step 5924, loss = 0.69155 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:57:42.643199 ops/training.py:65 2019-01-16 12:57:42.643129: step 5925, loss = 0.69034 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:57:43.406739 ops/training.py:65 2019-01-16 12:57:43.406683: step 5926, loss = 0.69546 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:57:44.170411 ops/training.py:65 2019-01-16 12:57:44.170347: step 5927, loss = 0.69555 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:57:44.935593 ops/training.py:65 2019-01-16 12:57:44.935537: step 5928, loss = 0.68578 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:57:45.699057 ops/training.py:65 2019-01-16 12:57:45.699012: step 5929, loss = 0.69384 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:57:46.462491 ops/training.py:65 2019-01-16 12:57:46.462420: step 5930, loss = 0.69591 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:57:47.228517 ops/training.py:65 2019-01-16 12:57:47.228457: step 5931, loss = 0.69498 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:57:47.995443 ops/training.py:65 2019-01-16 12:57:47.995379: step 5932, loss = 0.69403 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:57:48.761345 ops/training.py:65 2019-01-16 12:57:48.761287: step 5933, loss = 0.68944 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:57:49.525968 ops/training.py:65 2019-01-16 12:57:49.525921: step 5934, loss = 0.69024 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:57:50.291006 ops/training.py:65 2019-01-16 12:57:50.290947: step 5935, loss = 0.69565 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:57:51.054883 ops/training.py:65 2019-01-16 12:57:51.054830: step 5936, loss = 0.69381 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:57:51.818473 ops/training.py:65 2019-01-16 12:57:51.818424: step 5937, loss = 0.69159 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:57:52.581511 ops/training.py:65 2019-01-16 12:57:52.581463: step 5938, loss = 0.69412 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:57:53.345322 ops/training.py:65 2019-01-16 12:57:53.345267: step 5939, loss = 0.69284 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:57:54.108916 ops/training.py:65 2019-01-16 12:57:54.108850: step 5940, loss = 0.70354 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:57:54.875011 ops/training.py:65 2019-01-16 12:57:54.874942: step 5941, loss = 0.69209 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:57:55.642347 ops/training.py:65 2019-01-16 12:57:55.642290: step 5942, loss = 0.69022 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:57:56.409056 ops/training.py:65 2019-01-16 12:57:56.408959: step 5943, loss = 0.69004 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:57:57.175114 ops/training.py:65 2019-01-16 12:57:57.175051: step 5944, loss = 0.68992 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:57:57.943767 ops/training.py:65 2019-01-16 12:57:57.943719: step 5945, loss = 0.69919 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:57:58.710383 ops/training.py:65 2019-01-16 12:57:58.710321: step 5946, loss = 0.69320 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:57:59.475020 ops/training.py:65 2019-01-16 12:57:59.474965: step 5947, loss = 0.69197 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:58:00.239167 ops/training.py:65 2019-01-16 12:58:00.239114: step 5948, loss = 0.70365 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 12:58:01.005092 ops/training.py:65 2019-01-16 12:58:01.005041: step 5949, loss = 0.69386 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:58:01.771798 ops/training.py:65 2019-01-16 12:58:01.771734: step 5950, loss = 0.69491 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:58:02.537590 ops/training.py:65 2019-01-16 12:58:02.537540: step 5951, loss = 0.68760 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:58:03.300872 ops/training.py:65 2019-01-16 12:58:03.300815: step 5952, loss = 0.69648 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:58:04.065285 ops/training.py:65 2019-01-16 12:58:04.065232: step 5953, loss = 0.69468 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:58:04.832373 ops/training.py:65 2019-01-16 12:58:04.832302: step 5954, loss = 0.68804 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:58:05.598774 ops/training.py:65 2019-01-16 12:58:05.598689: step 5955, loss = 0.69015 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:58:06.367423 ops/training.py:65 2019-01-16 12:58:06.367373: step 5956, loss = 0.68704 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:58:07.133181 ops/training.py:65 2019-01-16 12:58:07.133126: step 5957, loss = 0.69979 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:58:07.899966 ops/training.py:65 2019-01-16 12:58:07.899910: step 5958, loss = 0.69769 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:58:08.663572 ops/training.py:65 2019-01-16 12:58:08.663513: step 5959, loss = 0.69141 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:58:09.427977 ops/training.py:65 2019-01-16 12:58:09.427924: step 5960, loss = 0.69094 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:58:10.192167 ops/training.py:65 2019-01-16 12:58:10.192113: step 5961, loss = 0.69260 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:58:10.955703 ops/training.py:65 2019-01-16 12:58:10.955639: step 5962, loss = 0.69671 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:58:11.719360 ops/training.py:65 2019-01-16 12:58:11.719302: step 5963, loss = 0.70264 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 12:58:12.483584 ops/training.py:65 2019-01-16 12:58:12.483522: step 5964, loss = 0.69345 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:58:13.247225 ops/training.py:65 2019-01-16 12:58:13.247179: step 5965, loss = 0.68925 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:58:14.010285 ops/training.py:65 2019-01-16 12:58:14.010235: step 5966, loss = 0.69919 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:58:14.773970 ops/training.py:65 2019-01-16 12:58:14.773919: step 5967, loss = 0.69640 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:58:15.536795 ops/training.py:65 2019-01-16 12:58:15.536750: step 5968, loss = 0.69493 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:58:16.302858 ops/training.py:65 2019-01-16 12:58:16.302811: step 5969, loss = 0.69941 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:58:17.070348 ops/training.py:65 2019-01-16 12:58:17.070278: step 5970, loss = 0.69322 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:58:17.836708 ops/training.py:65 2019-01-16 12:58:17.836654: step 5971, loss = 0.69220 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:58:18.600108 ops/training.py:65 2019-01-16 12:58:18.600054: step 5972, loss = 0.69820 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:58:19.363833 ops/training.py:65 2019-01-16 12:58:19.363782: step 5973, loss = 0.69288 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:58:20.127056 ops/training.py:65 2019-01-16 12:58:20.126992: step 5974, loss = 0.68569 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:58:20.890933 ops/training.py:65 2019-01-16 12:58:20.890863: step 5975, loss = 0.69249 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:58:21.654151 ops/training.py:65 2019-01-16 12:58:21.654089: step 5976, loss = 0.68831 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:58:22.417419 ops/training.py:65 2019-01-16 12:58:22.417373: step 5977, loss = 0.69552 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:58:23.181169 ops/training.py:65 2019-01-16 12:58:23.181114: step 5978, loss = 0.69257 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:58:23.945171 ops/training.py:65 2019-01-16 12:58:23.945118: step 5979, loss = 0.69512 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:58:24.708542 ops/training.py:65 2019-01-16 12:58:24.708489: step 5980, loss = 0.69503 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 12:58:25.471720 ops/training.py:65 2019-01-16 12:58:25.471676: step 5981, loss = 0.69523 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:58:26.235139 ops/training.py:65 2019-01-16 12:58:26.235090: step 5982, loss = 0.69420 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:58:26.999359 ops/training.py:65 2019-01-16 12:58:26.999309: step 5983, loss = 0.69460 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:58:27.768502 ops/training.py:65 2019-01-16 12:58:27.768431: step 5984, loss = 0.68528 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:58:28.537062 ops/training.py:65 2019-01-16 12:58:28.536981: step 5985, loss = 0.69134 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:58:29.304506 ops/training.py:65 2019-01-16 12:58:29.304452: step 5986, loss = 0.68851 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 12:58:30.071885 ops/training.py:65 2019-01-16 12:58:30.071810: step 5987, loss = 0.69323 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:58:30.838834 ops/training.py:65 2019-01-16 12:58:30.838783: step 5988, loss = 0.69382 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:58:31.605803 ops/training.py:65 2019-01-16 12:58:31.605741: step 5989, loss = 0.69830 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 12:58:32.370324 ops/training.py:65 2019-01-16 12:58:32.370268: step 5990, loss = 0.69169 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:58:33.134060 ops/training.py:65 2019-01-16 12:58:33.134011: step 5991, loss = 0.69234 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:58:33.897429 ops/training.py:65 2019-01-16 12:58:33.897374: step 5992, loss = 0.69717 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 12:58:34.660316 ops/training.py:65 2019-01-16 12:58:34.660259: step 5993, loss = 0.69228 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 12:58:35.427480 ops/training.py:65 2019-01-16 12:58:35.427423: step 5994, loss = 0.69497 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 12:58:36.195593 ops/training.py:65 2019-01-16 12:58:36.195531: step 5995, loss = 0.69570 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 12:58:36.962582 ops/training.py:65 2019-01-16 12:58:36.962514: step 5996, loss = 0.68781 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 12:58:37.730553 ops/training.py:65 2019-01-16 12:58:37.730477: step 5997, loss = 0.69460 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:58:38.496776 ops/training.py:65 2019-01-16 12:58:38.496719: step 5998, loss = 0.68867 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 12:58:39.263064 ops/training.py:65 2019-01-16 12:58:39.262991: step 5999, loss = 0.68791 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:02:11.706505 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I0528 2019-01-16 13:02:11.707344 ops/training.py:41 2019-01-16 13:02:11.707299: step 6000, loss = 0.70 (0.2 examples/sec; 211.677 sec/batch) | Training accuracy = 0.4375 | Validation accuracy = 0.4891 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_11_30_14_313845
I0528 2019-01-16 13:02:12.473300 ops/training.py:65 2019-01-16 13:02:12.473227: step 6001, loss = 0.68781 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:02:13.239184 ops/training.py:65 2019-01-16 13:02:13.239106: step 6002, loss = 0.68745 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:02:14.002782 ops/training.py:65 2019-01-16 13:02:14.002732: step 6003, loss = 0.69861 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:02:14.768698 ops/training.py:65 2019-01-16 13:02:14.768635: step 6004, loss = 0.69225 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:02:15.535260 ops/training.py:65 2019-01-16 13:02:15.535192: step 6005, loss = 0.68724 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:02:16.303068 ops/training.py:65 2019-01-16 13:02:16.302999: step 6006, loss = 0.68815 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 13:02:17.070143 ops/training.py:65 2019-01-16 13:02:17.070084: step 6007, loss = 0.68435 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:02:17.836091 ops/training.py:65 2019-01-16 13:02:17.836009: step 6008, loss = 0.70025 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 13:02:18.601670 ops/training.py:65 2019-01-16 13:02:18.601618: step 6009, loss = 0.69459 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:02:19.369904 ops/training.py:65 2019-01-16 13:02:19.369857: step 6010, loss = 0.70020 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 13:02:20.137305 ops/training.py:65 2019-01-16 13:02:20.137244: step 6011, loss = 0.68857 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:02:20.904371 ops/training.py:65 2019-01-16 13:02:20.904303: step 6012, loss = 0.69600 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 13:02:21.672888 ops/training.py:65 2019-01-16 13:02:21.672813: step 6013, loss = 0.69118 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:02:22.438786 ops/training.py:65 2019-01-16 13:02:22.438733: step 6014, loss = 0.69539 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:02:23.202648 ops/training.py:65 2019-01-16 13:02:23.202599: step 6015, loss = 0.70096 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 13:02:23.965889 ops/training.py:65 2019-01-16 13:02:23.965838: step 6016, loss = 0.68751 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:02:24.731291 ops/training.py:65 2019-01-16 13:02:24.731201: step 6017, loss = 0.69933 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:02:25.499053 ops/training.py:65 2019-01-16 13:02:25.498973: step 6018, loss = 0.69320 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:02:26.266942 ops/training.py:65 2019-01-16 13:02:26.266875: step 6019, loss = 0.69005 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:02:27.033817 ops/training.py:65 2019-01-16 13:02:27.033748: step 6020, loss = 0.69229 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:02:27.801248 ops/training.py:65 2019-01-16 13:02:27.801193: step 6021, loss = 0.69715 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:02:28.568294 ops/training.py:65 2019-01-16 13:02:28.568223: step 6022, loss = 0.69651 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:02:29.336560 ops/training.py:65 2019-01-16 13:02:29.336491: step 6023, loss = 0.69183 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:02:30.103510 ops/training.py:65 2019-01-16 13:02:30.103444: step 6024, loss = 0.68860 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:02:30.871722 ops/training.py:65 2019-01-16 13:02:30.871652: step 6025, loss = 0.69901 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:02:31.637445 ops/training.py:65 2019-01-16 13:02:31.637370: step 6026, loss = 0.69623 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:02:32.401697 ops/training.py:65 2019-01-16 13:02:32.401625: step 6027, loss = 0.69253 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:02:33.166951 ops/training.py:65 2019-01-16 13:02:33.166874: step 6028, loss = 0.69230 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:02:33.931617 ops/training.py:65 2019-01-16 13:02:33.931569: step 6029, loss = 0.69612 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:02:34.694790 ops/training.py:65 2019-01-16 13:02:34.694743: step 6030, loss = 0.69390 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:02:35.457722 ops/training.py:65 2019-01-16 13:02:35.457675: step 6031, loss = 0.69329 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:02:36.221470 ops/training.py:65 2019-01-16 13:02:36.221414: step 6032, loss = 0.69047 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:02:36.989321 ops/training.py:65 2019-01-16 13:02:36.989266: step 6033, loss = 0.69495 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:02:37.757167 ops/training.py:65 2019-01-16 13:02:37.757097: step 6034, loss = 0.69456 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:02:38.523915 ops/training.py:65 2019-01-16 13:02:38.523848: step 6035, loss = 0.69669 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:02:39.289550 ops/training.py:65 2019-01-16 13:02:39.289481: step 6036, loss = 0.69194 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:02:40.054065 ops/training.py:65 2019-01-16 13:02:40.054007: step 6037, loss = 0.68159 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:02:40.819712 ops/training.py:65 2019-01-16 13:02:40.819651: step 6038, loss = 0.69449 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:02:41.584815 ops/training.py:65 2019-01-16 13:02:41.584763: step 6039, loss = 0.68784 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:02:42.348465 ops/training.py:65 2019-01-16 13:02:42.348404: step 6040, loss = 0.68808 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:02:43.114724 ops/training.py:65 2019-01-16 13:02:43.114652: step 6041, loss = 0.70233 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 13:02:43.881905 ops/training.py:65 2019-01-16 13:02:43.881830: step 6042, loss = 0.70251 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:02:44.649745 ops/training.py:65 2019-01-16 13:02:44.649674: step 6043, loss = 0.69120 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:02:45.414315 ops/training.py:65 2019-01-16 13:02:45.414240: step 6044, loss = 0.69316 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:02:46.178994 ops/training.py:65 2019-01-16 13:02:46.178939: step 6045, loss = 0.68808 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:02:46.942730 ops/training.py:65 2019-01-16 13:02:46.942671: step 6046, loss = 0.70399 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:02:47.706083 ops/training.py:65 2019-01-16 13:02:47.706025: step 6047, loss = 0.69543 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:02:48.469717 ops/training.py:65 2019-01-16 13:02:48.469658: step 6048, loss = 0.69248 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:02:49.234443 ops/training.py:65 2019-01-16 13:02:49.234391: step 6049, loss = 0.70133 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:02:49.998490 ops/training.py:65 2019-01-16 13:02:49.998432: step 6050, loss = 0.68544 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:02:50.762493 ops/training.py:65 2019-01-16 13:02:50.762437: step 6051, loss = 0.68680 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:02:51.527395 ops/training.py:65 2019-01-16 13:02:51.527343: step 6052, loss = 0.70237 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:02:52.292430 ops/training.py:65 2019-01-16 13:02:52.292378: step 6053, loss = 0.69563 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:02:53.057062 ops/training.py:65 2019-01-16 13:02:53.057009: step 6054, loss = 0.68878 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:02:53.822002 ops/training.py:65 2019-01-16 13:02:53.821954: step 6055, loss = 0.68703 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:02:54.585829 ops/training.py:65 2019-01-16 13:02:54.585774: step 6056, loss = 0.69653 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:02:55.350546 ops/training.py:65 2019-01-16 13:02:55.350496: step 6057, loss = 0.69267 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:02:56.114042 ops/training.py:65 2019-01-16 13:02:56.113991: step 6058, loss = 0.68513 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:02:56.878102 ops/training.py:65 2019-01-16 13:02:56.878051: step 6059, loss = 0.69101 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:02:57.641941 ops/training.py:65 2019-01-16 13:02:57.641888: step 6060, loss = 0.68871 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:02:58.406355 ops/training.py:65 2019-01-16 13:02:58.406303: step 6061, loss = 0.69509 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:02:59.170731 ops/training.py:65 2019-01-16 13:02:59.170682: step 6062, loss = 0.68329 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:02:59.937368 ops/training.py:65 2019-01-16 13:02:59.937314: step 6063, loss = 0.70274 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:03:00.705544 ops/training.py:65 2019-01-16 13:03:00.705460: step 6064, loss = 0.67265 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:03:01.472103 ops/training.py:65 2019-01-16 13:03:01.472030: step 6065, loss = 0.69704 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:03:02.236957 ops/training.py:65 2019-01-16 13:03:02.236911: step 6066, loss = 0.71459 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:03:03.000625 ops/training.py:65 2019-01-16 13:03:03.000572: step 6067, loss = 0.69416 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:03:03.764609 ops/training.py:65 2019-01-16 13:03:03.764549: step 6068, loss = 0.69266 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:03:04.528787 ops/training.py:65 2019-01-16 13:03:04.528734: step 6069, loss = 0.69735 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:03:05.292294 ops/training.py:65 2019-01-16 13:03:05.292239: step 6070, loss = 0.70625 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:03:06.056922 ops/training.py:65 2019-01-16 13:03:06.056867: step 6071, loss = 0.68861 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:03:06.820350 ops/training.py:65 2019-01-16 13:03:06.820299: step 6072, loss = 0.70910 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:03:07.582992 ops/training.py:65 2019-01-16 13:03:07.582941: step 6073, loss = 0.69388 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:03:08.345834 ops/training.py:65 2019-01-16 13:03:08.345783: step 6074, loss = 0.68875 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 13:03:09.112382 ops/training.py:65 2019-01-16 13:03:09.112339: step 6075, loss = 0.69049 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:03:09.878976 ops/training.py:65 2019-01-16 13:03:09.878918: step 6076, loss = 0.70727 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:03:10.645963 ops/training.py:65 2019-01-16 13:03:10.645886: step 6077, loss = 0.70003 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:03:11.413046 ops/training.py:65 2019-01-16 13:03:11.412971: step 6078, loss = 0.68177 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:03:12.178833 ops/training.py:65 2019-01-16 13:03:12.178775: step 6079, loss = 0.70131 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:03:12.944145 ops/training.py:65 2019-01-16 13:03:12.944079: step 6080, loss = 0.70261 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:03:13.708772 ops/training.py:65 2019-01-16 13:03:13.708716: step 6081, loss = 0.69502 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:03:14.473440 ops/training.py:65 2019-01-16 13:03:14.473383: step 6082, loss = 0.69814 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:03:15.236554 ops/training.py:65 2019-01-16 13:03:15.236496: step 6083, loss = 0.69151 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:03:16.000195 ops/training.py:65 2019-01-16 13:03:16.000128: step 6084, loss = 0.68480 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:03:16.763580 ops/training.py:65 2019-01-16 13:03:16.763524: step 6085, loss = 0.70714 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:03:17.527859 ops/training.py:65 2019-01-16 13:03:17.527802: step 6086, loss = 0.67898 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:03:18.292737 ops/training.py:65 2019-01-16 13:03:18.292681: step 6087, loss = 0.70516 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:03:19.056096 ops/training.py:65 2019-01-16 13:03:19.056048: step 6088, loss = 0.70942 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:03:19.822544 ops/training.py:65 2019-01-16 13:03:19.822487: step 6089, loss = 0.70174 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:03:20.590256 ops/training.py:65 2019-01-16 13:03:20.590177: step 6090, loss = 0.68203 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:03:21.359633 ops/training.py:65 2019-01-16 13:03:21.359566: step 6091, loss = 0.68792 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:03:22.128268 ops/training.py:65 2019-01-16 13:03:22.128218: step 6092, loss = 0.68966 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:03:22.895250 ops/training.py:65 2019-01-16 13:03:22.895167: step 6093, loss = 0.67720 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:03:23.661192 ops/training.py:65 2019-01-16 13:03:23.661148: step 6094, loss = 0.66779 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 13:03:24.425228 ops/training.py:65 2019-01-16 13:03:24.425176: step 6095, loss = 0.68207 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:03:25.193109 ops/training.py:65 2019-01-16 13:03:25.193048: step 6096, loss = 0.69852 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:03:25.961946 ops/training.py:65 2019-01-16 13:03:25.961865: step 6097, loss = 0.67662 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:03:26.728723 ops/training.py:65 2019-01-16 13:03:26.728662: step 6098, loss = 0.70638 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:03:27.497646 ops/training.py:65 2019-01-16 13:03:27.497568: step 6099, loss = 0.68847 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:03:28.264337 ops/training.py:65 2019-01-16 13:03:28.264267: step 6100, loss = 0.69623 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:03:29.027708 ops/training.py:65 2019-01-16 13:03:29.027655: step 6101, loss = 0.69897 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:03:29.791406 ops/training.py:65 2019-01-16 13:03:29.791350: step 6102, loss = 0.70105 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:03:30.558564 ops/training.py:65 2019-01-16 13:03:30.558495: step 6103, loss = 0.68413 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:03:31.327685 ops/training.py:65 2019-01-16 13:03:31.327618: step 6104, loss = 0.69080 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:03:32.095931 ops/training.py:65 2019-01-16 13:03:32.095862: step 6105, loss = 0.70466 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:03:32.862922 ops/training.py:65 2019-01-16 13:03:32.862847: step 6106, loss = 0.70199 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:03:33.630028 ops/training.py:65 2019-01-16 13:03:33.629943: step 6107, loss = 0.72027 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:03:34.397810 ops/training.py:65 2019-01-16 13:03:34.397735: step 6108, loss = 0.68749 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:03:35.162156 ops/training.py:65 2019-01-16 13:03:35.162103: step 6109, loss = 0.71703 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:03:35.926078 ops/training.py:65 2019-01-16 13:03:35.926022: step 6110, loss = 0.72751 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 13:03:36.689952 ops/training.py:65 2019-01-16 13:03:36.689908: step 6111, loss = 0.69955 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:03:37.453421 ops/training.py:65 2019-01-16 13:03:37.453370: step 6112, loss = 0.67701 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:03:38.217057 ops/training.py:65 2019-01-16 13:03:38.217003: step 6113, loss = 0.68801 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:03:38.981251 ops/training.py:65 2019-01-16 13:03:38.981203: step 6114, loss = 0.68504 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:03:39.749236 ops/training.py:65 2019-01-16 13:03:39.749177: step 6115, loss = 0.70853 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:03:40.515806 ops/training.py:65 2019-01-16 13:03:40.515727: step 6116, loss = 0.71652 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:03:41.282151 ops/training.py:65 2019-01-16 13:03:41.282078: step 6117, loss = 0.68245 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:03:42.049223 ops/training.py:65 2019-01-16 13:03:42.049167: step 6118, loss = 0.70847 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:03:42.817981 ops/training.py:65 2019-01-16 13:03:42.817909: step 6119, loss = 0.72565 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 13:03:43.585565 ops/training.py:65 2019-01-16 13:03:43.585494: step 6120, loss = 0.69393 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:03:44.353823 ops/training.py:65 2019-01-16 13:03:44.353751: step 6121, loss = 0.71720 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:03:45.123127 ops/training.py:65 2019-01-16 13:03:45.123059: step 6122, loss = 0.70309 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:03:45.891909 ops/training.py:65 2019-01-16 13:03:45.891833: step 6123, loss = 0.68091 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:03:46.657814 ops/training.py:65 2019-01-16 13:03:46.657740: step 6124, loss = 0.67049 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:03:47.422240 ops/training.py:65 2019-01-16 13:03:47.422182: step 6125, loss = 0.69181 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:03:48.190648 ops/training.py:65 2019-01-16 13:03:48.190599: step 6126, loss = 0.69316 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:03:48.957813 ops/training.py:65 2019-01-16 13:03:48.957726: step 6127, loss = 0.69463 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:03:49.723759 ops/training.py:65 2019-01-16 13:03:49.723691: step 6128, loss = 0.69896 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:03:50.486996 ops/training.py:65 2019-01-16 13:03:50.486927: step 6129, loss = 0.69137 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:03:51.251156 ops/training.py:65 2019-01-16 13:03:51.251097: step 6130, loss = 0.69262 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:03:52.015995 ops/training.py:65 2019-01-16 13:03:52.015944: step 6131, loss = 0.71062 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:03:52.780759 ops/training.py:65 2019-01-16 13:03:52.780708: step 6132, loss = 0.69712 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:03:53.545554 ops/training.py:65 2019-01-16 13:03:53.545498: step 6133, loss = 0.68275 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:03:54.309270 ops/training.py:65 2019-01-16 13:03:54.309217: step 6134, loss = 0.69486 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:03:55.073199 ops/training.py:65 2019-01-16 13:03:55.073142: step 6135, loss = 0.69964 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:03:55.840233 ops/training.py:65 2019-01-16 13:03:55.840171: step 6136, loss = 0.70785 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:03:56.606608 ops/training.py:65 2019-01-16 13:03:56.606537: step 6137, loss = 0.68757 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:03:57.374494 ops/training.py:65 2019-01-16 13:03:57.374415: step 6138, loss = 0.70490 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:03:58.141942 ops/training.py:65 2019-01-16 13:03:58.141889: step 6139, loss = 0.71502 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:03:58.905815 ops/training.py:65 2019-01-16 13:03:58.905761: step 6140, loss = 0.70756 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:03:59.669340 ops/training.py:65 2019-01-16 13:03:59.669283: step 6141, loss = 0.70669 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:04:00.433172 ops/training.py:65 2019-01-16 13:04:00.433116: step 6142, loss = 0.70046 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:04:01.196828 ops/training.py:65 2019-01-16 13:04:01.196772: step 6143, loss = 0.69916 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:04:01.960417 ops/training.py:65 2019-01-16 13:04:01.960365: step 6144, loss = 0.71528 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 13:04:02.725612 ops/training.py:65 2019-01-16 13:04:02.725557: step 6145, loss = 0.69369 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:04:03.492715 ops/training.py:65 2019-01-16 13:04:03.492654: step 6146, loss = 0.69498 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:04:04.260058 ops/training.py:65 2019-01-16 13:04:04.259982: step 6147, loss = 0.70259 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:04:05.026900 ops/training.py:65 2019-01-16 13:04:05.026823: step 6148, loss = 0.68316 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:04:05.792320 ops/training.py:65 2019-01-16 13:04:05.792264: step 6149, loss = 0.69260 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:04:06.556321 ops/training.py:65 2019-01-16 13:04:06.556271: step 6150, loss = 0.69203 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:04:07.321840 ops/training.py:65 2019-01-16 13:04:07.321794: step 6151, loss = 0.67497 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:04:08.089893 ops/training.py:65 2019-01-16 13:04:08.089810: step 6152, loss = 0.70480 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:04:08.857104 ops/training.py:65 2019-01-16 13:04:08.857059: step 6153, loss = 0.69303 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:04:09.620450 ops/training.py:65 2019-01-16 13:04:09.620394: step 6154, loss = 0.68455 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:04:10.384407 ops/training.py:65 2019-01-16 13:04:10.384354: step 6155, loss = 0.69191 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:04:11.149375 ops/training.py:65 2019-01-16 13:04:11.149318: step 6156, loss = 0.68582 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:04:11.913099 ops/training.py:65 2019-01-16 13:04:11.913039: step 6157, loss = 0.70313 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:04:12.679674 ops/training.py:65 2019-01-16 13:04:12.679601: step 6158, loss = 0.68273 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:04:13.446987 ops/training.py:65 2019-01-16 13:04:13.446907: step 6159, loss = 0.69415 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:04:14.215125 ops/training.py:65 2019-01-16 13:04:14.215049: step 6160, loss = 0.69217 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:04:14.982443 ops/training.py:65 2019-01-16 13:04:14.982382: step 6161, loss = 0.70564 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:04:15.749681 ops/training.py:65 2019-01-16 13:04:15.749604: step 6162, loss = 0.70635 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:04:16.515798 ops/training.py:65 2019-01-16 13:04:16.515725: step 6163, loss = 0.69314 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:04:17.281641 ops/training.py:65 2019-01-16 13:04:17.281565: step 6164, loss = 0.71772 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 13:04:18.045025 ops/training.py:65 2019-01-16 13:04:18.044973: step 6165, loss = 0.70062 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:04:18.808002 ops/training.py:65 2019-01-16 13:04:18.807943: step 6166, loss = 0.69030 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:04:19.571433 ops/training.py:65 2019-01-16 13:04:19.571375: step 6167, loss = 0.70201 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:04:20.334619 ops/training.py:65 2019-01-16 13:04:20.334566: step 6168, loss = 0.68754 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:04:21.102787 ops/training.py:65 2019-01-16 13:04:21.102731: step 6169, loss = 0.69511 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:04:21.869963 ops/training.py:65 2019-01-16 13:04:21.869890: step 6170, loss = 0.70246 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 13:04:22.636262 ops/training.py:65 2019-01-16 13:04:22.636190: step 6171, loss = 0.69055 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:04:23.400545 ops/training.py:65 2019-01-16 13:04:23.400491: step 6172, loss = 0.69711 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:04:24.164483 ops/training.py:65 2019-01-16 13:04:24.164433: step 6173, loss = 0.69999 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:04:24.928486 ops/training.py:65 2019-01-16 13:04:24.928429: step 6174, loss = 0.67905 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:04:25.695113 ops/training.py:65 2019-01-16 13:04:25.695052: step 6175, loss = 0.70731 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:04:26.461781 ops/training.py:65 2019-01-16 13:04:26.461701: step 6176, loss = 0.68745 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:04:27.227187 ops/training.py:65 2019-01-16 13:04:27.227129: step 6177, loss = 0.69987 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:04:27.991999 ops/training.py:65 2019-01-16 13:04:27.991938: step 6178, loss = 0.69534 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:04:28.758266 ops/training.py:65 2019-01-16 13:04:28.758212: step 6179, loss = 0.70433 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:04:29.524969 ops/training.py:65 2019-01-16 13:04:29.524900: step 6180, loss = 0.69692 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:04:30.293390 ops/training.py:65 2019-01-16 13:04:30.293311: step 6181, loss = 0.69763 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:04:31.060322 ops/training.py:65 2019-01-16 13:04:31.060265: step 6182, loss = 0.70128 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:04:31.824682 ops/training.py:65 2019-01-16 13:04:31.824626: step 6183, loss = 0.70090 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:04:32.588364 ops/training.py:65 2019-01-16 13:04:32.588309: step 6184, loss = 0.69330 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:04:33.352180 ops/training.py:65 2019-01-16 13:04:33.352124: step 6185, loss = 0.68564 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 13:04:34.115998 ops/training.py:65 2019-01-16 13:04:34.115945: step 6186, loss = 0.69806 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:04:34.880028 ops/training.py:65 2019-01-16 13:04:34.879959: step 6187, loss = 0.69402 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:04:35.642883 ops/training.py:65 2019-01-16 13:04:35.642827: step 6188, loss = 0.68927 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:04:36.406819 ops/training.py:65 2019-01-16 13:04:36.406760: step 6189, loss = 0.69388 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:04:37.170737 ops/training.py:65 2019-01-16 13:04:37.170688: step 6190, loss = 0.69732 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:04:37.933816 ops/training.py:65 2019-01-16 13:04:37.933764: step 6191, loss = 0.69573 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:04:38.699048 ops/training.py:65 2019-01-16 13:04:38.698995: step 6192, loss = 0.69073 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:04:39.462952 ops/training.py:65 2019-01-16 13:04:39.462902: step 6193, loss = 0.69079 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:04:40.227069 ops/training.py:65 2019-01-16 13:04:40.227016: step 6194, loss = 0.69291 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:04:40.991019 ops/training.py:65 2019-01-16 13:04:40.990961: step 6195, loss = 0.69605 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:04:41.756932 ops/training.py:65 2019-01-16 13:04:41.756875: step 6196, loss = 0.69322 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:04:42.524515 ops/training.py:65 2019-01-16 13:04:42.524453: step 6197, loss = 0.69313 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:04:43.288891 ops/training.py:65 2019-01-16 13:04:43.288809: step 6198, loss = 0.69261 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:04:44.053549 ops/training.py:65 2019-01-16 13:04:44.053506: step 6199, loss = 0.69554 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:04:44.817424 ops/training.py:65 2019-01-16 13:04:44.817377: step 6200, loss = 0.69691 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:04:45.586376 ops/training.py:65 2019-01-16 13:04:45.586332: step 6201, loss = 0.68719 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:04:46.355971 ops/training.py:65 2019-01-16 13:04:46.355895: step 6202, loss = 0.69433 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:04:47.124582 ops/training.py:65 2019-01-16 13:04:47.124501: step 6203, loss = 0.69146 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:04:47.893209 ops/training.py:65 2019-01-16 13:04:47.893132: step 6204, loss = 0.69488 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:04:48.658801 ops/training.py:65 2019-01-16 13:04:48.658745: step 6205, loss = 0.69482 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:04:49.421812 ops/training.py:65 2019-01-16 13:04:49.421758: step 6206, loss = 0.69519 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:04:50.189966 ops/training.py:65 2019-01-16 13:04:50.189906: step 6207, loss = 0.70742 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 13:04:50.956901 ops/training.py:65 2019-01-16 13:04:50.956827: step 6208, loss = 0.69155 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:04:51.724179 ops/training.py:65 2019-01-16 13:04:51.724127: step 6209, loss = 0.69566 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:04:52.492564 ops/training.py:65 2019-01-16 13:04:52.492515: step 6210, loss = 0.69294 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:04:53.260561 ops/training.py:65 2019-01-16 13:04:53.260510: step 6211, loss = 0.69500 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:04:54.026903 ops/training.py:65 2019-01-16 13:04:54.026833: step 6212, loss = 0.69506 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:04:54.793914 ops/training.py:65 2019-01-16 13:04:54.793829: step 6213, loss = 0.68791 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:04:55.560809 ops/training.py:65 2019-01-16 13:04:55.560753: step 6214, loss = 0.69083 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:04:56.327796 ops/training.py:65 2019-01-16 13:04:56.327718: step 6215, loss = 0.69457 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:04:57.095222 ops/training.py:65 2019-01-16 13:04:57.095145: step 6216, loss = 0.69882 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:04:57.860929 ops/training.py:65 2019-01-16 13:04:57.860872: step 6217, loss = 0.68901 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:04:58.625991 ops/training.py:65 2019-01-16 13:04:58.625937: step 6218, loss = 0.68979 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:04:59.390448 ops/training.py:65 2019-01-16 13:04:59.390398: step 6219, loss = 0.69390 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:05:00.155932 ops/training.py:65 2019-01-16 13:05:00.155883: step 6220, loss = 0.69270 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:05:00.920455 ops/training.py:65 2019-01-16 13:05:00.920406: step 6221, loss = 0.69296 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:05:01.684493 ops/training.py:65 2019-01-16 13:05:01.684444: step 6222, loss = 0.69063 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:05:02.448746 ops/training.py:65 2019-01-16 13:05:02.448701: step 6223, loss = 0.69051 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:05:03.213735 ops/training.py:65 2019-01-16 13:05:03.213692: step 6224, loss = 0.69132 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:05:03.981413 ops/training.py:65 2019-01-16 13:05:03.981374: step 6225, loss = 0.69572 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:05:04.749422 ops/training.py:65 2019-01-16 13:05:04.749387: step 6226, loss = 0.69453 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:05:05.516844 ops/training.py:65 2019-01-16 13:05:05.516808: step 6227, loss = 0.69290 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:05:06.282731 ops/training.py:65 2019-01-16 13:05:06.282696: step 6228, loss = 0.69561 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:05:07.047275 ops/training.py:65 2019-01-16 13:05:07.047237: step 6229, loss = 0.69754 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:05:07.810510 ops/training.py:65 2019-01-16 13:05:07.810472: step 6230, loss = 0.69376 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:05:08.575123 ops/training.py:65 2019-01-16 13:05:08.575076: step 6231, loss = 0.69347 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:05:09.340211 ops/training.py:65 2019-01-16 13:05:09.340153: step 6232, loss = 0.69341 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:05:10.106795 ops/training.py:65 2019-01-16 13:05:10.106744: step 6233, loss = 0.69530 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:05:10.875066 ops/training.py:65 2019-01-16 13:05:10.874985: step 6234, loss = 0.69870 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:05:11.642246 ops/training.py:65 2019-01-16 13:05:11.642168: step 6235, loss = 0.69176 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:05:12.407109 ops/training.py:65 2019-01-16 13:05:12.407034: step 6236, loss = 0.69115 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:05:13.172257 ops/training.py:65 2019-01-16 13:05:13.172196: step 6237, loss = 0.69352 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:05:13.937525 ops/training.py:65 2019-01-16 13:05:13.937468: step 6238, loss = 0.69134 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:05:14.702498 ops/training.py:65 2019-01-16 13:05:14.702440: step 6239, loss = 0.69358 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:05:15.467872 ops/training.py:65 2019-01-16 13:05:15.467822: step 6240, loss = 0.69965 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:05:16.235040 ops/training.py:65 2019-01-16 13:05:16.234984: step 6241, loss = 0.69425 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:05:17.002098 ops/training.py:65 2019-01-16 13:05:17.002013: step 6242, loss = 0.69789 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:05:17.771280 ops/training.py:65 2019-01-16 13:05:17.771222: step 6243, loss = 0.69949 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:05:18.538223 ops/training.py:65 2019-01-16 13:05:18.538161: step 6244, loss = 0.69600 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:05:19.305497 ops/training.py:65 2019-01-16 13:05:19.305422: step 6245, loss = 0.69646 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:05:20.075002 ops/training.py:65 2019-01-16 13:05:20.074939: step 6246, loss = 0.69364 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:05:20.841196 ops/training.py:65 2019-01-16 13:05:20.841115: step 6247, loss = 0.69694 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:05:21.606728 ops/training.py:65 2019-01-16 13:05:21.606653: step 6248, loss = 0.68690 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 13:05:22.370406 ops/training.py:65 2019-01-16 13:05:22.370356: step 6249, loss = 0.69502 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:05:23.134019 ops/training.py:65 2019-01-16 13:05:23.133960: step 6250, loss = 0.69601 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:05:23.898578 ops/training.py:65 2019-01-16 13:05:23.898526: step 6251, loss = 0.69115 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:05:24.662261 ops/training.py:65 2019-01-16 13:05:24.662204: step 6252, loss = 0.68957 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:05:25.430184 ops/training.py:65 2019-01-16 13:05:25.430141: step 6253, loss = 0.68724 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:05:26.197955 ops/training.py:65 2019-01-16 13:05:26.197892: step 6254, loss = 0.69236 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:05:26.964982 ops/training.py:65 2019-01-16 13:05:26.964900: step 6255, loss = 0.69374 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:05:27.732899 ops/training.py:65 2019-01-16 13:05:27.732828: step 6256, loss = 0.69039 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:05:28.501034 ops/training.py:65 2019-01-16 13:05:28.500953: step 6257, loss = 0.69138 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:05:29.267102 ops/training.py:65 2019-01-16 13:05:29.267050: step 6258, loss = 0.69498 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:05:30.031922 ops/training.py:65 2019-01-16 13:05:30.031877: step 6259, loss = 0.69430 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:05:30.798690 ops/training.py:65 2019-01-16 13:05:30.798629: step 6260, loss = 0.69808 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 13:05:31.566135 ops/training.py:65 2019-01-16 13:05:31.566056: step 6261, loss = 0.69520 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:05:32.332848 ops/training.py:65 2019-01-16 13:05:32.332795: step 6262, loss = 0.69026 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:05:33.097030 ops/training.py:65 2019-01-16 13:05:33.096978: step 6263, loss = 0.69067 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:05:33.860979 ops/training.py:65 2019-01-16 13:05:33.860921: step 6264, loss = 0.69389 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:05:34.625181 ops/training.py:65 2019-01-16 13:05:34.625127: step 6265, loss = 0.69449 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:05:35.389457 ops/training.py:65 2019-01-16 13:05:35.389401: step 6266, loss = 0.69682 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:05:36.153640 ops/training.py:65 2019-01-16 13:05:36.153584: step 6267, loss = 0.69164 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:05:36.916796 ops/training.py:65 2019-01-16 13:05:36.916752: step 6268, loss = 0.69286 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:05:37.680095 ops/training.py:65 2019-01-16 13:05:37.680042: step 6269, loss = 0.69199 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:05:38.442891 ops/training.py:65 2019-01-16 13:05:38.442836: step 6270, loss = 0.69441 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:05:39.210592 ops/training.py:65 2019-01-16 13:05:39.210533: step 6271, loss = 0.69177 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:05:39.978430 ops/training.py:65 2019-01-16 13:05:39.978348: step 6272, loss = 0.69407 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:05:40.745475 ops/training.py:65 2019-01-16 13:05:40.745412: step 6273, loss = 0.69136 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:05:41.513222 ops/training.py:65 2019-01-16 13:05:41.513161: step 6274, loss = 0.69713 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:05:42.281091 ops/training.py:65 2019-01-16 13:05:42.281029: step 6275, loss = 0.69456 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:05:43.048627 ops/training.py:65 2019-01-16 13:05:43.048550: step 6276, loss = 0.69638 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:05:43.816199 ops/training.py:65 2019-01-16 13:05:43.816118: step 6277, loss = 0.69389 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:05:44.582149 ops/training.py:65 2019-01-16 13:05:44.582075: step 6278, loss = 0.69327 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:05:45.346408 ops/training.py:65 2019-01-16 13:05:45.346356: step 6279, loss = 0.69153 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:05:46.114201 ops/training.py:65 2019-01-16 13:05:46.114154: step 6280, loss = 0.69407 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:05:46.882111 ops/training.py:65 2019-01-16 13:05:46.882055: step 6281, loss = 0.69198 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:05:47.649353 ops/training.py:65 2019-01-16 13:05:47.649286: step 6282, loss = 0.69654 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:05:48.416751 ops/training.py:65 2019-01-16 13:05:48.416676: step 6283, loss = 0.69760 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:05:49.184258 ops/training.py:65 2019-01-16 13:05:49.184193: step 6284, loss = 0.69198 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:05:49.952045 ops/training.py:65 2019-01-16 13:05:49.951966: step 6285, loss = 0.69674 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:05:50.717871 ops/training.py:65 2019-01-16 13:05:50.717795: step 6286, loss = 0.68964 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:05:51.482612 ops/training.py:65 2019-01-16 13:05:51.482559: step 6287, loss = 0.69640 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 13:05:52.249318 ops/training.py:65 2019-01-16 13:05:52.249268: step 6288, loss = 0.69296 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:05:53.016693 ops/training.py:65 2019-01-16 13:05:53.016640: step 6289, loss = 0.68821 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 13:05:53.785117 ops/training.py:65 2019-01-16 13:05:53.785042: step 6290, loss = 0.69412 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:05:54.554245 ops/training.py:65 2019-01-16 13:05:54.554160: step 6291, loss = 0.69132 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:05:55.323710 ops/training.py:65 2019-01-16 13:05:55.323635: step 6292, loss = 0.68993 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:05:56.091055 ops/training.py:65 2019-01-16 13:05:56.090993: step 6293, loss = 0.68614 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 13:05:56.859111 ops/training.py:65 2019-01-16 13:05:56.859051: step 6294, loss = 0.69301 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:05:57.627752 ops/training.py:65 2019-01-16 13:05:57.627704: step 6295, loss = 0.69261 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:05:58.397482 ops/training.py:65 2019-01-16 13:05:58.397415: step 6296, loss = 0.68788 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:05:59.165879 ops/training.py:65 2019-01-16 13:05:59.165809: step 6297, loss = 0.68731 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:05:59.934572 ops/training.py:65 2019-01-16 13:05:59.934512: step 6298, loss = 0.69423 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:06:00.701883 ops/training.py:65 2019-01-16 13:06:00.701825: step 6299, loss = 0.70328 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 13:06:01.466991 ops/training.py:65 2019-01-16 13:06:01.466937: step 6300, loss = 0.69168 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:06:02.234633 ops/training.py:65 2019-01-16 13:06:02.234591: step 6301, loss = 0.69166 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:06:03.002982 ops/training.py:65 2019-01-16 13:06:03.002926: step 6302, loss = 0.68498 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:06:03.772208 ops/training.py:65 2019-01-16 13:06:03.772130: step 6303, loss = 0.68494 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:06:04.540314 ops/training.py:65 2019-01-16 13:06:04.540235: step 6304, loss = 0.69695 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 13:06:05.310175 ops/training.py:65 2019-01-16 13:06:05.310116: step 6305, loss = 0.69292 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:06:06.078407 ops/training.py:65 2019-01-16 13:06:06.078326: step 6306, loss = 0.69757 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:06:06.845685 ops/training.py:65 2019-01-16 13:06:06.845631: step 6307, loss = 0.69750 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:06:07.610094 ops/training.py:65 2019-01-16 13:06:07.610041: step 6308, loss = 0.69241 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:06:08.374851 ops/training.py:65 2019-01-16 13:06:08.374795: step 6309, loss = 0.69636 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:06:09.139573 ops/training.py:65 2019-01-16 13:06:09.139524: step 6310, loss = 0.69339 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:06:09.902994 ops/training.py:65 2019-01-16 13:06:09.902933: step 6311, loss = 0.68539 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 13:06:10.667309 ops/training.py:65 2019-01-16 13:06:10.667256: step 6312, loss = 0.68967 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:06:11.433779 ops/training.py:65 2019-01-16 13:06:11.433731: step 6313, loss = 0.69258 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:06:12.203341 ops/training.py:65 2019-01-16 13:06:12.203279: step 6314, loss = 0.70035 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:06:12.970306 ops/training.py:65 2019-01-16 13:06:12.970229: step 6315, loss = 0.69315 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:06:13.738651 ops/training.py:65 2019-01-16 13:06:13.738565: step 6316, loss = 0.69387 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:06:14.505967 ops/training.py:65 2019-01-16 13:06:14.505890: step 6317, loss = 0.69356 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:06:15.269264 ops/training.py:65 2019-01-16 13:06:15.269207: step 6318, loss = 0.68936 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:06:16.032727 ops/training.py:65 2019-01-16 13:06:16.032675: step 6319, loss = 0.69374 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:06:16.796019 ops/training.py:65 2019-01-16 13:06:16.795966: step 6320, loss = 0.69080 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:06:17.559784 ops/training.py:65 2019-01-16 13:06:17.559728: step 6321, loss = 0.68925 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:06:18.323783 ops/training.py:65 2019-01-16 13:06:18.323731: step 6322, loss = 0.70136 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 13:06:19.087261 ops/training.py:65 2019-01-16 13:06:19.087210: step 6323, loss = 0.68956 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:06:19.854756 ops/training.py:65 2019-01-16 13:06:19.854697: step 6324, loss = 0.69961 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:06:20.622978 ops/training.py:65 2019-01-16 13:06:20.622899: step 6325, loss = 0.69621 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:06:21.389935 ops/training.py:65 2019-01-16 13:06:21.389876: step 6326, loss = 0.69319 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:06:22.153941 ops/training.py:65 2019-01-16 13:06:22.153893: step 6327, loss = 0.69383 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:06:22.917843 ops/training.py:65 2019-01-16 13:06:22.917787: step 6328, loss = 0.69078 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:06:23.681586 ops/training.py:65 2019-01-16 13:06:23.681534: step 6329, loss = 0.69060 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:06:24.445125 ops/training.py:65 2019-01-16 13:06:24.445074: step 6330, loss = 0.69206 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:06:25.208934 ops/training.py:65 2019-01-16 13:06:25.208882: step 6331, loss = 0.69551 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:06:25.972532 ops/training.py:65 2019-01-16 13:06:25.972479: step 6332, loss = 0.69553 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:06:26.736204 ops/training.py:65 2019-01-16 13:06:26.736150: step 6333, loss = 0.69251 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:06:27.499130 ops/training.py:65 2019-01-16 13:06:27.499077: step 6334, loss = 0.68786 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:06:28.262800 ops/training.py:65 2019-01-16 13:06:28.262744: step 6335, loss = 0.69605 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:06:29.026821 ops/training.py:65 2019-01-16 13:06:29.026765: step 6336, loss = 0.69482 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:06:29.794298 ops/training.py:65 2019-01-16 13:06:29.794241: step 6337, loss = 0.69715 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:06:30.562407 ops/training.py:65 2019-01-16 13:06:30.562338: step 6338, loss = 0.70230 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:06:31.329935 ops/training.py:65 2019-01-16 13:06:31.329864: step 6339, loss = 0.69090 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:06:32.098404 ops/training.py:65 2019-01-16 13:06:32.098345: step 6340, loss = 0.68918 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:06:32.866031 ops/training.py:65 2019-01-16 13:06:32.865956: step 6341, loss = 0.69062 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:06:33.633549 ops/training.py:65 2019-01-16 13:06:33.633478: step 6342, loss = 0.69441 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:06:34.400619 ops/training.py:65 2019-01-16 13:06:34.400538: step 6343, loss = 0.69847 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:06:35.168602 ops/training.py:65 2019-01-16 13:06:35.168532: step 6344, loss = 0.69055 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:06:35.937260 ops/training.py:65 2019-01-16 13:06:35.937185: step 6345, loss = 0.69397 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:06:36.705770 ops/training.py:65 2019-01-16 13:06:36.705692: step 6346, loss = 0.69420 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:06:37.473710 ops/training.py:65 2019-01-16 13:06:37.473653: step 6347, loss = 0.69033 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:06:38.242576 ops/training.py:65 2019-01-16 13:06:38.242473: step 6348, loss = 0.68707 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:06:39.011190 ops/training.py:65 2019-01-16 13:06:39.011117: step 6349, loss = 0.69172 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:06:39.777346 ops/training.py:65 2019-01-16 13:06:39.777285: step 6350, loss = 0.69593 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:06:40.542083 ops/training.py:65 2019-01-16 13:06:40.542028: step 6351, loss = 0.69587 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:06:41.310367 ops/training.py:65 2019-01-16 13:06:41.310309: step 6352, loss = 0.69215 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:06:42.077191 ops/training.py:65 2019-01-16 13:06:42.077131: step 6353, loss = 0.69507 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:06:42.842927 ops/training.py:65 2019-01-16 13:06:42.842850: step 6354, loss = 0.70267 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:06:43.607834 ops/training.py:65 2019-01-16 13:06:43.607772: step 6355, loss = 0.69837 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:06:44.375327 ops/training.py:65 2019-01-16 13:06:44.375268: step 6356, loss = 0.70193 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 13:06:45.142115 ops/training.py:65 2019-01-16 13:06:45.142059: step 6357, loss = 0.68857 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 13:06:45.910022 ops/training.py:65 2019-01-16 13:06:45.909932: step 6358, loss = 0.69137 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:06:46.678121 ops/training.py:65 2019-01-16 13:06:46.678044: step 6359, loss = 0.70475 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 13:06:47.445972 ops/training.py:65 2019-01-16 13:06:47.445892: step 6360, loss = 0.69700 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:06:48.212483 ops/training.py:65 2019-01-16 13:06:48.212406: step 6361, loss = 0.69003 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:06:48.976700 ops/training.py:65 2019-01-16 13:06:48.976644: step 6362, loss = 0.69344 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:06:49.740696 ops/training.py:65 2019-01-16 13:06:49.740640: step 6363, loss = 0.69126 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:06:50.504230 ops/training.py:65 2019-01-16 13:06:50.504172: step 6364, loss = 0.69534 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:06:51.268419 ops/training.py:65 2019-01-16 13:06:51.268362: step 6365, loss = 0.69917 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:06:52.032602 ops/training.py:65 2019-01-16 13:06:52.032555: step 6366, loss = 0.70209 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 13:06:52.796991 ops/training.py:65 2019-01-16 13:06:52.796933: step 6367, loss = 0.69613 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:06:53.560606 ops/training.py:65 2019-01-16 13:06:53.560553: step 6368, loss = 0.68736 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:06:54.324057 ops/training.py:65 2019-01-16 13:06:54.324005: step 6369, loss = 0.68372 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 13:06:55.090579 ops/training.py:65 2019-01-16 13:06:55.090525: step 6370, loss = 0.69472 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:06:55.857987 ops/training.py:65 2019-01-16 13:06:55.857913: step 6371, loss = 0.69515 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:06:56.625478 ops/training.py:65 2019-01-16 13:06:56.625400: step 6372, loss = 0.69261 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:06:57.392539 ops/training.py:65 2019-01-16 13:06:57.392465: step 6373, loss = 0.68738 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:06:58.156976 ops/training.py:65 2019-01-16 13:06:58.156918: step 6374, loss = 0.69055 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:06:58.920544 ops/training.py:65 2019-01-16 13:06:58.920489: step 6375, loss = 0.69445 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:06:59.684381 ops/training.py:65 2019-01-16 13:06:59.684332: step 6376, loss = 0.69848 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:07:00.447816 ops/training.py:65 2019-01-16 13:07:00.447763: step 6377, loss = 0.69008 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:07:01.211964 ops/training.py:65 2019-01-16 13:07:01.211910: step 6378, loss = 0.68861 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:07:01.976001 ops/training.py:65 2019-01-16 13:07:01.975951: step 6379, loss = 0.68545 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:07:02.739443 ops/training.py:65 2019-01-16 13:07:02.739391: step 6380, loss = 0.69940 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:07:03.503325 ops/training.py:65 2019-01-16 13:07:03.503270: step 6381, loss = 0.70617 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 13:07:04.267663 ops/training.py:65 2019-01-16 13:07:04.267610: step 6382, loss = 0.68773 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:07:05.031770 ops/training.py:65 2019-01-16 13:07:05.031717: step 6383, loss = 0.69512 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:07:05.795134 ops/training.py:65 2019-01-16 13:07:05.795083: step 6384, loss = 0.68196 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:07:06.558607 ops/training.py:65 2019-01-16 13:07:06.558549: step 6385, loss = 0.68889 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:07:07.325506 ops/training.py:65 2019-01-16 13:07:07.325459: step 6386, loss = 0.68854 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:07:08.093376 ops/training.py:65 2019-01-16 13:07:08.093302: step 6387, loss = 0.70874 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 13:07:08.860989 ops/training.py:65 2019-01-16 13:07:08.860912: step 6388, loss = 0.70325 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:07:09.626348 ops/training.py:65 2019-01-16 13:07:09.626296: step 6389, loss = 0.68460 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:07:10.390643 ops/training.py:65 2019-01-16 13:07:10.390591: step 6390, loss = 0.68706 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:07:11.156268 ops/training.py:65 2019-01-16 13:07:11.156211: step 6391, loss = 0.69678 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:07:11.923297 ops/training.py:65 2019-01-16 13:07:11.923233: step 6392, loss = 0.70503 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 13:07:12.690076 ops/training.py:65 2019-01-16 13:07:12.690011: step 6393, loss = 0.68630 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:07:13.457686 ops/training.py:65 2019-01-16 13:07:13.457608: step 6394, loss = 0.69668 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:07:14.223235 ops/training.py:65 2019-01-16 13:07:14.223159: step 6395, loss = 0.70236 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:07:14.987709 ops/training.py:65 2019-01-16 13:07:14.987664: step 6396, loss = 0.68136 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:07:15.753716 ops/training.py:65 2019-01-16 13:07:15.753661: step 6397, loss = 0.69327 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:07:16.523774 ops/training.py:65 2019-01-16 13:07:16.523694: step 6398, loss = 0.70463 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:07:17.291094 ops/training.py:65 2019-01-16 13:07:17.291018: step 6399, loss = 0.68389 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:07:18.056573 ops/training.py:65 2019-01-16 13:07:18.056520: step 6400, loss = 0.70020 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:07:18.824388 ops/training.py:65 2019-01-16 13:07:18.824310: step 6401, loss = 0.69121 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:07:19.590678 ops/training.py:65 2019-01-16 13:07:19.590623: step 6402, loss = 0.70426 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:07:20.355085 ops/training.py:65 2019-01-16 13:07:20.355034: step 6403, loss = 0.68896 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:07:21.120467 ops/training.py:65 2019-01-16 13:07:21.120414: step 6404, loss = 0.71645 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 13:07:21.884552 ops/training.py:65 2019-01-16 13:07:21.884509: step 6405, loss = 0.69696 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:07:22.648694 ops/training.py:65 2019-01-16 13:07:22.648642: step 6406, loss = 0.69723 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:07:23.412220 ops/training.py:65 2019-01-16 13:07:23.412179: step 6407, loss = 0.68719 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:07:24.175933 ops/training.py:65 2019-01-16 13:07:24.175885: step 6408, loss = 0.68743 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:07:24.940291 ops/training.py:65 2019-01-16 13:07:24.940237: step 6409, loss = 0.70221 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:07:25.703768 ops/training.py:65 2019-01-16 13:07:25.703714: step 6410, loss = 0.68919 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:07:26.467528 ops/training.py:65 2019-01-16 13:07:26.467475: step 6411, loss = 0.69763 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:07:27.231912 ops/training.py:65 2019-01-16 13:07:27.231847: step 6412, loss = 0.70017 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:07:27.996347 ops/training.py:65 2019-01-16 13:07:27.996275: step 6413, loss = 0.69897 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:07:28.763145 ops/training.py:65 2019-01-16 13:07:28.763073: step 6414, loss = 0.68560 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:07:29.531038 ops/training.py:65 2019-01-16 13:07:29.530967: step 6415, loss = 0.69827 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:07:30.298057 ops/training.py:65 2019-01-16 13:07:30.297994: step 6416, loss = 0.69815 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:07:31.064720 ops/training.py:65 2019-01-16 13:07:31.064662: step 6417, loss = 0.70285 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:07:31.830347 ops/training.py:65 2019-01-16 13:07:31.830267: step 6418, loss = 0.69197 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:07:32.595302 ops/training.py:65 2019-01-16 13:07:32.595253: step 6419, loss = 0.69741 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:07:33.358499 ops/training.py:65 2019-01-16 13:07:33.358442: step 6420, loss = 0.69483 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:07:34.122535 ops/training.py:65 2019-01-16 13:07:34.122487: step 6421, loss = 0.68440 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:07:34.886573 ops/training.py:65 2019-01-16 13:07:34.886514: step 6422, loss = 0.70005 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:07:35.651861 ops/training.py:65 2019-01-16 13:07:35.651794: step 6423, loss = 0.69894 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:07:36.416842 ops/training.py:65 2019-01-16 13:07:36.416796: step 6424, loss = 0.69577 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:07:37.180668 ops/training.py:65 2019-01-16 13:07:37.180617: step 6425, loss = 0.68887 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:07:37.944297 ops/training.py:65 2019-01-16 13:07:37.944238: step 6426, loss = 0.70362 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:07:38.711508 ops/training.py:65 2019-01-16 13:07:38.711445: step 6427, loss = 0.69543 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:07:39.478488 ops/training.py:65 2019-01-16 13:07:39.478413: step 6428, loss = 0.69761 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:07:40.244939 ops/training.py:65 2019-01-16 13:07:40.244888: step 6429, loss = 0.69554 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:07:41.010055 ops/training.py:65 2019-01-16 13:07:41.009989: step 6430, loss = 0.68832 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:07:41.776207 ops/training.py:65 2019-01-16 13:07:41.776145: step 6431, loss = 0.68953 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:07:42.541866 ops/training.py:65 2019-01-16 13:07:42.541790: step 6432, loss = 0.68563 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 13:07:43.311622 ops/training.py:65 2019-01-16 13:07:43.311550: step 6433, loss = 0.69287 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:07:44.078765 ops/training.py:65 2019-01-16 13:07:44.078702: step 6434, loss = 0.68814 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:07:44.844282 ops/training.py:65 2019-01-16 13:07:44.844217: step 6435, loss = 0.69361 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:07:45.608537 ops/training.py:65 2019-01-16 13:07:45.608465: step 6436, loss = 0.68465 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 13:07:46.373286 ops/training.py:65 2019-01-16 13:07:46.373218: step 6437, loss = 0.69102 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:07:47.137186 ops/training.py:65 2019-01-16 13:07:47.137132: step 6438, loss = 0.69818 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:07:47.902696 ops/training.py:65 2019-01-16 13:07:47.902631: step 6439, loss = 0.69382 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:07:48.669161 ops/training.py:65 2019-01-16 13:07:48.669091: step 6440, loss = 0.68944 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:07:49.435079 ops/training.py:65 2019-01-16 13:07:49.435024: step 6441, loss = 0.69194 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:07:50.199651 ops/training.py:65 2019-01-16 13:07:50.199547: step 6442, loss = 0.69131 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:07:50.966067 ops/training.py:65 2019-01-16 13:07:50.966015: step 6443, loss = 0.70036 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 13:07:51.729955 ops/training.py:65 2019-01-16 13:07:51.729909: step 6444, loss = 0.69650 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:07:52.494601 ops/training.py:65 2019-01-16 13:07:52.494553: step 6445, loss = 0.69361 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:07:53.258865 ops/training.py:65 2019-01-16 13:07:53.258804: step 6446, loss = 0.68173 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 13:07:54.022830 ops/training.py:65 2019-01-16 13:07:54.022743: step 6447, loss = 0.69617 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:07:54.787915 ops/training.py:65 2019-01-16 13:07:54.787863: step 6448, loss = 0.69472 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:07:55.553037 ops/training.py:65 2019-01-16 13:07:55.552990: step 6449, loss = 0.69040 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:07:56.317050 ops/training.py:65 2019-01-16 13:07:56.317007: step 6450, loss = 0.68295 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 13:07:57.081684 ops/training.py:65 2019-01-16 13:07:57.081620: step 6451, loss = 0.68687 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 13:07:57.846622 ops/training.py:65 2019-01-16 13:07:57.846578: step 6452, loss = 0.69565 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:07:58.610831 ops/training.py:65 2019-01-16 13:07:58.610757: step 6453, loss = 0.69514 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:07:59.375056 ops/training.py:65 2019-01-16 13:07:59.374996: step 6454, loss = 0.68614 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:08:00.138707 ops/training.py:65 2019-01-16 13:08:00.138659: step 6455, loss = 0.68865 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:08:00.902518 ops/training.py:65 2019-01-16 13:08:00.902453: step 6456, loss = 0.70210 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 13:08:01.666179 ops/training.py:65 2019-01-16 13:08:01.666134: step 6457, loss = 0.69008 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:08:02.429965 ops/training.py:65 2019-01-16 13:08:02.429904: step 6458, loss = 0.69366 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:08:03.194852 ops/training.py:65 2019-01-16 13:08:03.194781: step 6459, loss = 0.69171 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:08:03.959932 ops/training.py:65 2019-01-16 13:08:03.959860: step 6460, loss = 0.68688 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:08:04.724708 ops/training.py:65 2019-01-16 13:08:04.724641: step 6461, loss = 0.70332 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 13:08:05.488496 ops/training.py:65 2019-01-16 13:08:05.488443: step 6462, loss = 0.68992 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:08:06.255352 ops/training.py:65 2019-01-16 13:08:06.255281: step 6463, loss = 0.69844 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:08:07.023596 ops/training.py:65 2019-01-16 13:08:07.023540: step 6464, loss = 0.69340 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:08:07.791179 ops/training.py:65 2019-01-16 13:08:07.791100: step 6465, loss = 0.70141 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:08:08.559149 ops/training.py:65 2019-01-16 13:08:08.559070: step 6466, loss = 0.69893 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 13:08:09.327319 ops/training.py:65 2019-01-16 13:08:09.327248: step 6467, loss = 0.69614 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:08:10.094753 ops/training.py:65 2019-01-16 13:08:10.094693: step 6468, loss = 0.69292 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:08:10.859119 ops/training.py:65 2019-01-16 13:08:10.859058: step 6469, loss = 0.68889 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:08:11.625418 ops/training.py:65 2019-01-16 13:08:11.625358: step 6470, loss = 0.69408 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:08:12.393922 ops/training.py:65 2019-01-16 13:08:12.393851: step 6471, loss = 0.69640 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:08:13.162134 ops/training.py:65 2019-01-16 13:08:13.162068: step 6472, loss = 0.69475 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:08:13.930272 ops/training.py:65 2019-01-16 13:08:13.930197: step 6473, loss = 0.68815 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:08:14.695750 ops/training.py:65 2019-01-16 13:08:14.695675: step 6474, loss = 0.69112 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:08:15.461437 ops/training.py:65 2019-01-16 13:08:15.461366: step 6475, loss = 0.69518 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:08:16.226076 ops/training.py:65 2019-01-16 13:08:16.226011: step 6476, loss = 0.70338 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:08:16.992781 ops/training.py:65 2019-01-16 13:08:16.992725: step 6477, loss = 0.70087 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:08:17.760531 ops/training.py:65 2019-01-16 13:08:17.760471: step 6478, loss = 0.69286 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:08:18.529408 ops/training.py:65 2019-01-16 13:08:18.529329: step 6479, loss = 0.69692 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:08:19.296811 ops/training.py:65 2019-01-16 13:08:19.296740: step 6480, loss = 0.69709 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:08:20.062484 ops/training.py:65 2019-01-16 13:08:20.062418: step 6481, loss = 0.69377 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:08:20.826469 ops/training.py:65 2019-01-16 13:08:20.826415: step 6482, loss = 0.69452 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:08:21.590470 ops/training.py:65 2019-01-16 13:08:21.590405: step 6483, loss = 0.69150 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:08:22.354426 ops/training.py:65 2019-01-16 13:08:22.354359: step 6484, loss = 0.68597 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:08:23.119222 ops/training.py:65 2019-01-16 13:08:23.119158: step 6485, loss = 0.69326 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:08:23.884081 ops/training.py:65 2019-01-16 13:08:23.884018: step 6486, loss = 0.69801 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:08:24.648275 ops/training.py:65 2019-01-16 13:08:24.648226: step 6487, loss = 0.69764 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:08:25.415121 ops/training.py:65 2019-01-16 13:08:25.415048: step 6488, loss = 0.69174 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:08:26.183121 ops/training.py:65 2019-01-16 13:08:26.183040: step 6489, loss = 0.69757 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 13:08:26.949901 ops/training.py:65 2019-01-16 13:08:26.949841: step 6490, loss = 0.69058 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:08:27.717618 ops/training.py:65 2019-01-16 13:08:27.717549: step 6491, loss = 0.68841 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.71875
I0528 2019-01-16 13:08:28.485550 ops/training.py:65 2019-01-16 13:08:28.485473: step 6492, loss = 0.69292 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:08:29.251864 ops/training.py:65 2019-01-16 13:08:29.251796: step 6493, loss = 0.69768 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 13:08:30.019449 ops/training.py:65 2019-01-16 13:08:30.019399: step 6494, loss = 0.68971 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:08:30.786568 ops/training.py:65 2019-01-16 13:08:30.786509: step 6495, loss = 0.69110 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:08:31.553102 ops/training.py:65 2019-01-16 13:08:31.553051: step 6496, loss = 0.69326 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:08:32.318820 ops/training.py:65 2019-01-16 13:08:32.318763: step 6497, loss = 0.69322 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:08:33.083129 ops/training.py:65 2019-01-16 13:08:33.083057: step 6498, loss = 0.69406 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:08:33.848185 ops/training.py:65 2019-01-16 13:08:33.848115: step 6499, loss = 0.68751 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:08:34.611021 ops/training.py:65 2019-01-16 13:08:34.610948: step 6500, loss = 0.70056 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 13:08:35.374197 ops/training.py:65 2019-01-16 13:08:35.374145: step 6501, loss = 0.69035 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:08:36.142580 ops/training.py:65 2019-01-16 13:08:36.142515: step 6502, loss = 0.69523 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:08:36.912685 ops/training.py:65 2019-01-16 13:08:36.912614: step 6503, loss = 0.69329 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:08:37.680185 ops/training.py:65 2019-01-16 13:08:37.680107: step 6504, loss = 0.69380 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:08:38.446627 ops/training.py:65 2019-01-16 13:08:38.446554: step 6505, loss = 0.69620 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:08:39.211069 ops/training.py:65 2019-01-16 13:08:39.211019: step 6506, loss = 0.68757 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:08:39.978827 ops/training.py:65 2019-01-16 13:08:39.978763: step 6507, loss = 0.69962 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:08:40.746203 ops/training.py:65 2019-01-16 13:08:40.746132: step 6508, loss = 0.69194 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:08:41.515405 ops/training.py:65 2019-01-16 13:08:41.515329: step 6509, loss = 0.69679 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:08:42.283532 ops/training.py:65 2019-01-16 13:08:42.283457: step 6510, loss = 0.68672 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 13:08:43.051308 ops/training.py:65 2019-01-16 13:08:43.051233: step 6511, loss = 0.69830 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.28125
I0528 2019-01-16 13:08:43.819027 ops/training.py:65 2019-01-16 13:08:43.818946: step 6512, loss = 0.69531 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:08:44.583258 ops/training.py:65 2019-01-16 13:08:44.583198: step 6513, loss = 0.69298 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:08:45.347614 ops/training.py:65 2019-01-16 13:08:45.347548: step 6514, loss = 0.69712 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:08:46.111378 ops/training.py:65 2019-01-16 13:08:46.111307: step 6515, loss = 0.69456 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:08:46.876151 ops/training.py:65 2019-01-16 13:08:46.876103: step 6516, loss = 0.69206 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:08:47.641070 ops/training.py:65 2019-01-16 13:08:47.641004: step 6517, loss = 0.68651 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:08:48.405276 ops/training.py:65 2019-01-16 13:08:48.405208: step 6518, loss = 0.69144 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:08:49.169736 ops/training.py:65 2019-01-16 13:08:49.169675: step 6519, loss = 0.69196 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:08:49.933774 ops/training.py:65 2019-01-16 13:08:49.933708: step 6520, loss = 0.69446 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:08:50.697892 ops/training.py:65 2019-01-16 13:08:50.697844: step 6521, loss = 0.69799 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:08:51.461947 ops/training.py:65 2019-01-16 13:08:51.461876: step 6522, loss = 0.69484 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:08:52.225450 ops/training.py:65 2019-01-16 13:08:52.225398: step 6523, loss = 0.69123 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:08:52.988853 ops/training.py:65 2019-01-16 13:08:52.988791: step 6524, loss = 0.69093 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:08:53.752850 ops/training.py:65 2019-01-16 13:08:53.752779: step 6525, loss = 0.69368 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:08:54.521791 ops/training.py:65 2019-01-16 13:08:54.521729: step 6526, loss = 0.69360 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:08:55.290168 ops/training.py:65 2019-01-16 13:08:55.290091: step 6527, loss = 0.69084 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:08:56.057947 ops/training.py:65 2019-01-16 13:08:56.057887: step 6528, loss = 0.69409 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:08:56.824269 ops/training.py:65 2019-01-16 13:08:56.824218: step 6529, loss = 0.69608 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:08:57.590192 ops/training.py:65 2019-01-16 13:08:57.590123: step 6530, loss = 0.69051 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:08:58.354802 ops/training.py:65 2019-01-16 13:08:58.354751: step 6531, loss = 0.69093 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:08:59.119130 ops/training.py:65 2019-01-16 13:08:59.119073: step 6532, loss = 0.69163 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:08:59.885972 ops/training.py:65 2019-01-16 13:08:59.885900: step 6533, loss = 0.69228 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:09:00.653627 ops/training.py:65 2019-01-16 13:09:00.653574: step 6534, loss = 0.69548 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:09:01.420454 ops/training.py:65 2019-01-16 13:09:01.420399: step 6535, loss = 0.69293 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:09:02.186547 ops/training.py:65 2019-01-16 13:09:02.186487: step 6536, loss = 0.69073 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:09:02.952070 ops/training.py:65 2019-01-16 13:09:02.952009: step 6537, loss = 0.69338 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:09:03.718867 ops/training.py:65 2019-01-16 13:09:03.718790: step 6538, loss = 0.69350 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:09:04.487286 ops/training.py:65 2019-01-16 13:09:04.487209: step 6539, loss = 0.69759 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 13:09:05.255535 ops/training.py:65 2019-01-16 13:09:05.255459: step 6540, loss = 0.69385 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 13:09:06.022945 ops/training.py:65 2019-01-16 13:09:06.022865: step 6541, loss = 0.69721 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 13:09:06.787325 ops/training.py:65 2019-01-16 13:09:06.787246: step 6542, loss = 0.69368 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:09:07.551497 ops/training.py:65 2019-01-16 13:09:07.551429: step 6543, loss = 0.69126 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:09:08.315268 ops/training.py:65 2019-01-16 13:09:08.315203: step 6544, loss = 0.69337 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:09:09.079161 ops/training.py:65 2019-01-16 13:09:09.079116: step 6545, loss = 0.69157 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:09:09.843263 ops/training.py:65 2019-01-16 13:09:09.843209: step 6546, loss = 0.69063 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:09:10.606910 ops/training.py:65 2019-01-16 13:09:10.606843: step 6547, loss = 0.68914 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:09:11.372900 ops/training.py:65 2019-01-16 13:09:11.372825: step 6548, loss = 0.68970 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:09:12.140534 ops/training.py:65 2019-01-16 13:09:12.140469: step 6549, loss = 0.69232 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:09:12.907458 ops/training.py:65 2019-01-16 13:09:12.907387: step 6550, loss = 0.69348 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:09:13.677520 ops/training.py:65 2019-01-16 13:09:13.677451: step 6551, loss = 0.69481 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:09:14.447540 ops/training.py:65 2019-01-16 13:09:14.447466: step 6552, loss = 0.69067 (41.6 examples/sec; 0.769 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:09:15.215169 ops/training.py:65 2019-01-16 13:09:15.215109: step 6553, loss = 0.69411 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:09:15.979899 ops/training.py:65 2019-01-16 13:09:15.979829: step 6554, loss = 0.69307 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:09:16.744440 ops/training.py:65 2019-01-16 13:09:16.744393: step 6555, loss = 0.69243 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:09:17.508361 ops/training.py:65 2019-01-16 13:09:17.508288: step 6556, loss = 0.69014 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:09:18.274882 ops/training.py:65 2019-01-16 13:09:18.274814: step 6557, loss = 0.69469 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:09:19.039150 ops/training.py:65 2019-01-16 13:09:19.039084: step 6558, loss = 0.69084 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:09:19.803363 ops/training.py:65 2019-01-16 13:09:19.803294: step 6559, loss = 0.69109 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:09:20.566740 ops/training.py:65 2019-01-16 13:09:20.566689: step 6560, loss = 0.69875 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 13:09:21.330881 ops/training.py:65 2019-01-16 13:09:21.330816: step 6561, loss = 0.69275 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:09:22.097011 ops/training.py:65 2019-01-16 13:09:22.096952: step 6562, loss = 0.69017 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:09:22.863994 ops/training.py:65 2019-01-16 13:09:22.863916: step 6563, loss = 0.69832 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:09:23.630999 ops/training.py:65 2019-01-16 13:09:23.630944: step 6564, loss = 0.68986 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:09:24.396767 ops/training.py:65 2019-01-16 13:09:24.396718: step 6565, loss = 0.69597 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:09:25.160825 ops/training.py:65 2019-01-16 13:09:25.160760: step 6566, loss = 0.68943 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:09:25.924374 ops/training.py:65 2019-01-16 13:09:25.924303: step 6567, loss = 0.69154 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:09:26.688535 ops/training.py:65 2019-01-16 13:09:26.688468: step 6568, loss = 0.69422 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:09:27.453367 ops/training.py:65 2019-01-16 13:09:27.453297: step 6569, loss = 0.69651 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:09:28.217198 ops/training.py:65 2019-01-16 13:09:28.217152: step 6570, loss = 0.69898 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 13:09:28.981128 ops/training.py:65 2019-01-16 13:09:28.981060: step 6571, loss = 0.69041 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:09:29.744432 ops/training.py:65 2019-01-16 13:09:29.744361: step 6572, loss = 0.69301 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:09:30.512532 ops/training.py:65 2019-01-16 13:09:30.512462: step 6573, loss = 0.69604 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:09:31.280660 ops/training.py:65 2019-01-16 13:09:31.280588: step 6574, loss = 0.69118 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:09:32.049057 ops/training.py:65 2019-01-16 13:09:32.048981: step 6575, loss = 0.69775 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:09:32.815793 ops/training.py:65 2019-01-16 13:09:32.815724: step 6576, loss = 0.69293 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:09:33.580194 ops/training.py:65 2019-01-16 13:09:33.580123: step 6577, loss = 0.69267 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:09:34.345902 ops/training.py:65 2019-01-16 13:09:34.345827: step 6578, loss = 0.69515 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:09:35.110180 ops/training.py:65 2019-01-16 13:09:35.110114: step 6579, loss = 0.69354 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:09:35.875060 ops/training.py:65 2019-01-16 13:09:35.875006: step 6580, loss = 0.69307 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:09:36.639528 ops/training.py:65 2019-01-16 13:09:36.639460: step 6581, loss = 0.69148 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:09:37.405395 ops/training.py:65 2019-01-16 13:09:37.405325: step 6582, loss = 0.69775 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 13:09:38.171051 ops/training.py:65 2019-01-16 13:09:38.170986: step 6583, loss = 0.69401 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:09:38.935420 ops/training.py:65 2019-01-16 13:09:38.935354: step 6584, loss = 0.69626 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:09:39.700034 ops/training.py:65 2019-01-16 13:09:39.699983: step 6585, loss = 0.69238 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:09:40.464756 ops/training.py:65 2019-01-16 13:09:40.464668: step 6586, loss = 0.69375 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:09:41.229147 ops/training.py:65 2019-01-16 13:09:41.229078: step 6587, loss = 0.69412 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:09:41.993338 ops/training.py:65 2019-01-16 13:09:41.993271: step 6588, loss = 0.69495 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:09:42.761829 ops/training.py:65 2019-01-16 13:09:42.761775: step 6589, loss = 0.68934 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:09:43.529711 ops/training.py:65 2019-01-16 13:09:43.529633: step 6590, loss = 0.68903 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:09:44.296736 ops/training.py:65 2019-01-16 13:09:44.296661: step 6591, loss = 0.69319 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:09:45.063613 ops/training.py:65 2019-01-16 13:09:45.063563: step 6592, loss = 0.69057 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:09:45.827586 ops/training.py:65 2019-01-16 13:09:45.827526: step 6593, loss = 0.69245 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:09:46.591011 ops/training.py:65 2019-01-16 13:09:46.590965: step 6594, loss = 0.68992 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:09:47.354243 ops/training.py:65 2019-01-16 13:09:47.354168: step 6595, loss = 0.69155 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:09:48.118358 ops/training.py:65 2019-01-16 13:09:48.118259: step 6596, loss = 0.69626 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:09:48.883337 ops/training.py:65 2019-01-16 13:09:48.883264: step 6597, loss = 0.69266 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:09:49.647044 ops/training.py:65 2019-01-16 13:09:49.646975: step 6598, loss = 0.69292 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:09:50.411531 ops/training.py:65 2019-01-16 13:09:50.411481: step 6599, loss = 0.69469 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:09:51.175226 ops/training.py:65 2019-01-16 13:09:51.175159: step 6600, loss = 0.69419 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:09:51.939223 ops/training.py:65 2019-01-16 13:09:51.939152: step 6601, loss = 0.69268 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:09:52.704720 ops/training.py:65 2019-01-16 13:09:52.704628: step 6602, loss = 0.69495 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:09:53.471001 ops/training.py:65 2019-01-16 13:09:53.470965: step 6603, loss = 0.69083 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:09:54.238495 ops/training.py:65 2019-01-16 13:09:54.238468: step 6604, loss = 0.69353 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:09:55.006780 ops/training.py:65 2019-01-16 13:09:55.006733: step 6605, loss = 0.69424 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:09:55.773968 ops/training.py:65 2019-01-16 13:09:55.773929: step 6606, loss = 0.69076 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:09:56.540686 ops/training.py:65 2019-01-16 13:09:56.540650: step 6607, loss = 0.69168 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:09:57.305372 ops/training.py:65 2019-01-16 13:09:57.305336: step 6608, loss = 0.69092 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:09:58.071203 ops/training.py:65 2019-01-16 13:09:58.071176: step 6609, loss = 0.69755 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:09:58.838845 ops/training.py:65 2019-01-16 13:09:58.838810: step 6610, loss = 0.69583 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:09:59.606779 ops/training.py:65 2019-01-16 13:09:59.606747: step 6611, loss = 0.69093 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:10:00.373230 ops/training.py:65 2019-01-16 13:10:00.373200: step 6612, loss = 0.69352 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:10:01.138862 ops/training.py:65 2019-01-16 13:10:01.138827: step 6613, loss = 0.69746 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:10:01.903152 ops/training.py:65 2019-01-16 13:10:01.903124: step 6614, loss = 0.68992 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:10:02.666831 ops/training.py:65 2019-01-16 13:10:02.666789: step 6615, loss = 0.69477 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:10:03.433751 ops/training.py:65 2019-01-16 13:10:03.433691: step 6616, loss = 0.69338 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:10:04.203168 ops/training.py:65 2019-01-16 13:10:04.203114: step 6617, loss = 0.69311 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:10:04.970820 ops/training.py:65 2019-01-16 13:10:04.970775: step 6618, loss = 0.69292 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:10:05.737714 ops/training.py:65 2019-01-16 13:10:05.737686: step 6619, loss = 0.69452 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:10:06.504811 ops/training.py:65 2019-01-16 13:10:06.504732: step 6620, loss = 0.69022 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:10:07.273870 ops/training.py:65 2019-01-16 13:10:07.273798: step 6621, loss = 0.69082 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:10:08.041783 ops/training.py:65 2019-01-16 13:10:08.041691: step 6622, loss = 0.69182 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:10:08.810731 ops/training.py:65 2019-01-16 13:10:08.810616: step 6623, loss = 0.69290 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:10:09.578394 ops/training.py:65 2019-01-16 13:10:09.578361: step 6624, loss = 0.68985 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:10:10.344980 ops/training.py:65 2019-01-16 13:10:10.344947: step 6625, loss = 0.69021 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:10:11.112622 ops/training.py:65 2019-01-16 13:10:11.112590: step 6626, loss = 0.69072 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:10:11.879298 ops/training.py:65 2019-01-16 13:10:11.879263: step 6627, loss = 0.69555 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:10:12.644641 ops/training.py:65 2019-01-16 13:10:12.644601: step 6628, loss = 0.69771 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:10:13.412877 ops/training.py:65 2019-01-16 13:10:13.412845: step 6629, loss = 0.69394 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:10:14.179143 ops/training.py:65 2019-01-16 13:10:14.179099: step 6630, loss = 0.69158 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:10:14.944553 ops/training.py:65 2019-01-16 13:10:14.944512: step 6631, loss = 0.69252 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:10:15.708461 ops/training.py:65 2019-01-16 13:10:15.708424: step 6632, loss = 0.69060 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:10:16.472516 ops/training.py:65 2019-01-16 13:10:16.472486: step 6633, loss = 0.69291 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:10:17.236995 ops/training.py:65 2019-01-16 13:10:17.236966: step 6634, loss = 0.69017 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:10:18.000460 ops/training.py:65 2019-01-16 13:10:18.000409: step 6635, loss = 0.69746 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:10:18.764938 ops/training.py:65 2019-01-16 13:10:18.764876: step 6636, loss = 0.69817 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:10:19.529213 ops/training.py:65 2019-01-16 13:10:19.529161: step 6637, loss = 0.69754 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:10:20.293267 ops/training.py:65 2019-01-16 13:10:20.293239: step 6638, loss = 0.69953 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:10:21.057470 ops/training.py:65 2019-01-16 13:10:21.057414: step 6639, loss = 0.69387 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:10:21.821721 ops/training.py:65 2019-01-16 13:10:21.821672: step 6640, loss = 0.69160 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:10:22.589397 ops/training.py:65 2019-01-16 13:10:22.589346: step 6641, loss = 0.69683 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:10:23.356723 ops/training.py:65 2019-01-16 13:10:23.356672: step 6642, loss = 0.69330 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:10:24.123531 ops/training.py:65 2019-01-16 13:10:24.123503: step 6643, loss = 0.69105 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:10:24.889807 ops/training.py:65 2019-01-16 13:10:24.889760: step 6644, loss = 0.69717 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:10:25.657628 ops/training.py:65 2019-01-16 13:10:25.657593: step 6645, loss = 0.69310 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:10:26.425221 ops/training.py:65 2019-01-16 13:10:26.425188: step 6646, loss = 0.69607 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:10:27.191863 ops/training.py:65 2019-01-16 13:10:27.191828: step 6647, loss = 0.69156 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:10:27.957960 ops/training.py:65 2019-01-16 13:10:27.957932: step 6648, loss = 0.69404 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:10:28.723429 ops/training.py:65 2019-01-16 13:10:28.723373: step 6649, loss = 0.69091 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:10:29.487808 ops/training.py:65 2019-01-16 13:10:29.487762: step 6650, loss = 0.69303 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:10:30.252064 ops/training.py:65 2019-01-16 13:10:30.252023: step 6651, loss = 0.69511 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:10:31.017624 ops/training.py:65 2019-01-16 13:10:31.017591: step 6652, loss = 0.69869 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:10:31.782920 ops/training.py:65 2019-01-16 13:10:31.782893: step 6653, loss = 0.69866 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:10:32.546604 ops/training.py:65 2019-01-16 13:10:32.546575: step 6654, loss = 0.69138 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:10:33.311279 ops/training.py:65 2019-01-16 13:10:33.311247: step 6655, loss = 0.69298 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:10:34.076581 ops/training.py:65 2019-01-16 13:10:34.076549: step 6656, loss = 0.69506 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:10:34.841277 ops/training.py:65 2019-01-16 13:10:34.841246: step 6657, loss = 0.69464 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:10:35.606357 ops/training.py:65 2019-01-16 13:10:35.606332: step 6658, loss = 0.68592 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:10:36.371681 ops/training.py:65 2019-01-16 13:10:36.371649: step 6659, loss = 0.69693 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:10:37.137644 ops/training.py:65 2019-01-16 13:10:37.137614: step 6660, loss = 0.69257 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:10:37.902179 ops/training.py:65 2019-01-16 13:10:37.902148: step 6661, loss = 0.68748 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:10:38.667654 ops/training.py:65 2019-01-16 13:10:38.667613: step 6662, loss = 0.69719 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:10:39.434453 ops/training.py:65 2019-01-16 13:10:39.434341: step 6663, loss = 0.68939 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:10:40.202459 ops/training.py:65 2019-01-16 13:10:40.202400: step 6664, loss = 0.68742 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 13:10:40.967272 ops/training.py:65 2019-01-16 13:10:40.967217: step 6665, loss = 0.69301 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:10:41.735188 ops/training.py:65 2019-01-16 13:10:41.735116: step 6666, loss = 0.68788 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:10:42.501251 ops/training.py:65 2019-01-16 13:10:42.501137: step 6667, loss = 0.69125 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:10:43.267896 ops/training.py:65 2019-01-16 13:10:43.267777: step 6668, loss = 0.69495 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:10:44.035035 ops/training.py:65 2019-01-16 13:10:44.034880: step 6669, loss = 0.69813 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:10:44.801348 ops/training.py:65 2019-01-16 13:10:44.801191: step 6670, loss = 0.69881 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:10:45.569275 ops/training.py:65 2019-01-16 13:10:45.569160: step 6671, loss = 0.68916 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:10:46.337393 ops/training.py:65 2019-01-16 13:10:46.337294: step 6672, loss = 0.68652 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:10:47.105543 ops/training.py:65 2019-01-16 13:10:47.105439: step 6673, loss = 0.69861 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:10:47.872793 ops/training.py:65 2019-01-16 13:10:47.872681: step 6674, loss = 0.69233 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:10:48.638734 ops/training.py:65 2019-01-16 13:10:48.638621: step 6675, loss = 0.70019 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:10:49.403410 ops/training.py:65 2019-01-16 13:10:49.403259: step 6676, loss = 0.69231 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:10:50.169289 ops/training.py:65 2019-01-16 13:10:50.169249: step 6677, loss = 0.68422 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 13:10:50.934998 ops/training.py:65 2019-01-16 13:10:50.934971: step 6678, loss = 0.69743 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:10:51.701464 ops/training.py:65 2019-01-16 13:10:51.701425: step 6679, loss = 0.68713 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:10:52.467359 ops/training.py:65 2019-01-16 13:10:52.467323: step 6680, loss = 0.68848 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:10:53.232995 ops/training.py:65 2019-01-16 13:10:53.232884: step 6681, loss = 0.69388 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:10:53.999835 ops/training.py:65 2019-01-16 13:10:53.999681: step 6682, loss = 0.70129 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.25
I0528 2019-01-16 13:10:54.767172 ops/training.py:65 2019-01-16 13:10:54.767075: step 6683, loss = 0.69465 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:10:55.534728 ops/training.py:65 2019-01-16 13:10:55.534663: step 6684, loss = 0.69513 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:10:56.301542 ops/training.py:65 2019-01-16 13:10:56.301503: step 6685, loss = 0.69498 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:10:57.065841 ops/training.py:65 2019-01-16 13:10:57.065730: step 6686, loss = 0.69132 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:10:57.831717 ops/training.py:65 2019-01-16 13:10:57.831621: step 6687, loss = 0.69528 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:10:58.597289 ops/training.py:65 2019-01-16 13:10:58.597209: step 6688, loss = 0.69042 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:10:59.365578 ops/training.py:65 2019-01-16 13:10:59.365487: step 6689, loss = 0.69321 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:11:00.132814 ops/training.py:65 2019-01-16 13:11:00.132724: step 6690, loss = 0.69483 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:11:00.898774 ops/training.py:65 2019-01-16 13:11:00.898682: step 6691, loss = 0.69885 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:11:01.665313 ops/training.py:65 2019-01-16 13:11:01.665232: step 6692, loss = 0.69319 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:11:02.432539 ops/training.py:65 2019-01-16 13:11:02.432447: step 6693, loss = 0.69234 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:11:03.200360 ops/training.py:65 2019-01-16 13:11:03.200268: step 6694, loss = 0.68923 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:11:03.967691 ops/training.py:65 2019-01-16 13:11:03.967610: step 6695, loss = 0.69526 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:11:04.732194 ops/training.py:65 2019-01-16 13:11:04.732103: step 6696, loss = 0.69435 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:11:05.497754 ops/training.py:65 2019-01-16 13:11:05.497691: step 6697, loss = 0.69570 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:11:06.264350 ops/training.py:65 2019-01-16 13:11:06.264255: step 6698, loss = 0.68480 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 13:11:07.031978 ops/training.py:65 2019-01-16 13:11:07.031887: step 6699, loss = 0.69210 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:11:07.800303 ops/training.py:65 2019-01-16 13:11:07.800181: step 6700, loss = 0.69097 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:11:08.571323 ops/training.py:65 2019-01-16 13:11:08.571201: step 6701, loss = 0.69436 (41.6 examples/sec; 0.770 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:11:09.337944 ops/training.py:65 2019-01-16 13:11:09.337870: step 6702, loss = 0.69139 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:11:10.106020 ops/training.py:65 2019-01-16 13:11:10.105924: step 6703, loss = 0.69353 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:11:10.873616 ops/training.py:65 2019-01-16 13:11:10.873527: step 6704, loss = 0.69242 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:11:11.640975 ops/training.py:65 2019-01-16 13:11:11.640892: step 6705, loss = 0.68863 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:11:12.405256 ops/training.py:65 2019-01-16 13:11:12.405157: step 6706, loss = 0.69490 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:11:13.171914 ops/training.py:65 2019-01-16 13:11:13.171759: step 6707, loss = 0.69895 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:11:13.936302 ops/training.py:65 2019-01-16 13:11:13.936229: step 6708, loss = 0.69050 (42.0 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:11:14.699769 ops/training.py:65 2019-01-16 13:11:14.699673: step 6709, loss = 0.69400 (42.0 examples/sec; 0.762 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:11:15.465288 ops/training.py:65 2019-01-16 13:11:15.465224: step 6710, loss = 0.69695 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:11:16.231258 ops/training.py:65 2019-01-16 13:11:16.231168: step 6711, loss = 0.69343 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:11:16.998080 ops/training.py:65 2019-01-16 13:11:16.998006: step 6712, loss = 0.69614 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:11:17.763869 ops/training.py:65 2019-01-16 13:11:17.763807: step 6713, loss = 0.69414 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:11:18.530083 ops/training.py:65 2019-01-16 13:11:18.529954: step 6714, loss = 0.69646 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:11:19.297380 ops/training.py:65 2019-01-16 13:11:19.297257: step 6715, loss = 0.69055 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:11:20.064073 ops/training.py:65 2019-01-16 13:11:20.063960: step 6716, loss = 0.69059 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:11:20.830893 ops/training.py:65 2019-01-16 13:11:20.830778: step 6717, loss = 0.69556 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:11:21.596246 ops/training.py:65 2019-01-16 13:11:21.596122: step 6718, loss = 0.69679 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 13:11:22.365070 ops/training.py:65 2019-01-16 13:11:22.364937: step 6719, loss = 0.69294 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:11:23.135090 ops/training.py:65 2019-01-16 13:11:23.135008: step 6720, loss = 0.69084 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:11:23.902948 ops/training.py:65 2019-01-16 13:11:23.902877: step 6721, loss = 0.69440 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:11:24.669759 ops/training.py:65 2019-01-16 13:11:24.669653: step 6722, loss = 0.68922 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:11:25.436666 ops/training.py:65 2019-01-16 13:11:25.436558: step 6723, loss = 0.69516 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:11:26.203174 ops/training.py:65 2019-01-16 13:11:26.203060: step 6724, loss = 0.69070 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:11:26.969297 ops/training.py:65 2019-01-16 13:11:26.969187: step 6725, loss = 0.69345 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:11:27.735572 ops/training.py:65 2019-01-16 13:11:27.735450: step 6726, loss = 0.69169 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:11:28.502734 ops/training.py:65 2019-01-16 13:11:28.502623: step 6727, loss = 0.69282 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:11:29.268971 ops/training.py:65 2019-01-16 13:11:29.268855: step 6728, loss = 0.69631 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:11:30.034412 ops/training.py:65 2019-01-16 13:11:30.034304: step 6729, loss = 0.69617 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:11:30.801209 ops/training.py:65 2019-01-16 13:11:30.801101: step 6730, loss = 0.69203 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:11:31.566884 ops/training.py:65 2019-01-16 13:11:31.566771: step 6731, loss = 0.69149 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:11:32.339273 ops/training.py:65 2019-01-16 13:11:32.339167: step 6732, loss = 0.68779 (41.5 examples/sec; 0.771 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:11:33.108300 ops/training.py:65 2019-01-16 13:11:33.108169: step 6733, loss = 0.69805 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:11:33.875266 ops/training.py:65 2019-01-16 13:11:33.875155: step 6734, loss = 0.69272 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:11:34.640621 ops/training.py:65 2019-01-16 13:11:34.640564: step 6735, loss = 0.69363 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:11:35.405918 ops/training.py:65 2019-01-16 13:11:35.405797: step 6736, loss = 0.68789 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:11:36.171017 ops/training.py:65 2019-01-16 13:11:36.170904: step 6737, loss = 0.69520 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:11:36.935322 ops/training.py:65 2019-01-16 13:11:36.935199: step 6738, loss = 0.69271 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:11:37.701104 ops/training.py:65 2019-01-16 13:11:37.701009: step 6739, loss = 0.69716 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 13:11:38.467195 ops/training.py:65 2019-01-16 13:11:38.467115: step 6740, loss = 0.69747 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:11:39.235047 ops/training.py:65 2019-01-16 13:11:39.234958: step 6741, loss = 0.68943 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:11:40.004113 ops/training.py:65 2019-01-16 13:11:40.003992: step 6742, loss = 0.69710 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:11:40.772013 ops/training.py:65 2019-01-16 13:11:40.771868: step 6743, loss = 0.69475 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:11:41.538448 ops/training.py:65 2019-01-16 13:11:41.538333: step 6744, loss = 0.69739 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:11:42.306802 ops/training.py:65 2019-01-16 13:11:42.306685: step 6745, loss = 0.69768 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:11:43.076637 ops/training.py:65 2019-01-16 13:11:43.076526: step 6746, loss = 0.69393 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:11:43.844626 ops/training.py:65 2019-01-16 13:11:43.844507: step 6747, loss = 0.69824 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:11:44.611382 ops/training.py:65 2019-01-16 13:11:44.611265: step 6748, loss = 0.69382 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:11:45.377129 ops/training.py:65 2019-01-16 13:11:45.377061: step 6749, loss = 0.68964 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 13:11:46.141971 ops/training.py:65 2019-01-16 13:11:46.141856: step 6750, loss = 0.68918 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:11:46.907270 ops/training.py:65 2019-01-16 13:11:46.907172: step 6751, loss = 0.69262 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:11:47.673583 ops/training.py:65 2019-01-16 13:11:47.673447: step 6752, loss = 0.69190 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:11:48.441221 ops/training.py:65 2019-01-16 13:11:48.441095: step 6753, loss = 0.69148 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:11:49.207961 ops/training.py:65 2019-01-16 13:11:49.207855: step 6754, loss = 0.68753 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:11:49.976319 ops/training.py:65 2019-01-16 13:11:49.976203: step 6755, loss = 0.68870 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:11:50.745673 ops/training.py:65 2019-01-16 13:11:50.745551: step 6756, loss = 0.69333 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:11:51.513820 ops/training.py:65 2019-01-16 13:11:51.513705: step 6757, loss = 0.69225 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:11:52.281276 ops/training.py:65 2019-01-16 13:11:52.281159: step 6758, loss = 0.69761 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:11:53.048147 ops/training.py:65 2019-01-16 13:11:53.048042: step 6759, loss = 0.68842 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:11:53.815532 ops/training.py:65 2019-01-16 13:11:53.815415: step 6760, loss = 0.69634 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:11:54.582327 ops/training.py:65 2019-01-16 13:11:54.582210: step 6761, loss = 0.69260 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:11:55.349056 ops/training.py:65 2019-01-16 13:11:55.348937: step 6762, loss = 0.69440 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:11:56.117559 ops/training.py:65 2019-01-16 13:11:56.117457: step 6763, loss = 0.69665 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:11:56.885618 ops/training.py:65 2019-01-16 13:11:56.885512: step 6764, loss = 0.69325 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:11:57.652517 ops/training.py:65 2019-01-16 13:11:57.652418: step 6765, loss = 0.69007 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:11:58.418283 ops/training.py:65 2019-01-16 13:11:58.418173: step 6766, loss = 0.69139 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:11:59.184262 ops/training.py:65 2019-01-16 13:11:59.184148: step 6767, loss = 0.69753 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 13:11:59.949773 ops/training.py:65 2019-01-16 13:11:59.949663: step 6768, loss = 0.69614 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:12:00.715392 ops/training.py:65 2019-01-16 13:12:00.715274: step 6769, loss = 0.69296 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:12:01.479880 ops/training.py:65 2019-01-16 13:12:01.479771: step 6770, loss = 0.69672 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:12:02.244685 ops/training.py:65 2019-01-16 13:12:02.244583: step 6771, loss = 0.69433 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:12:03.009808 ops/training.py:65 2019-01-16 13:12:03.009688: step 6772, loss = 0.68998 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:12:03.777942 ops/training.py:65 2019-01-16 13:12:03.777827: step 6773, loss = 0.69089 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:12:04.544789 ops/training.py:65 2019-01-16 13:12:04.544682: step 6774, loss = 0.69340 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:12:05.313948 ops/training.py:65 2019-01-16 13:12:05.313850: step 6775, loss = 0.69056 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:12:06.082481 ops/training.py:65 2019-01-16 13:12:06.082373: step 6776, loss = 0.69440 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:12:06.849895 ops/training.py:65 2019-01-16 13:12:06.849781: step 6777, loss = 0.69226 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:12:07.615032 ops/training.py:65 2019-01-16 13:12:07.614914: step 6778, loss = 0.69992 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:12:08.382066 ops/training.py:65 2019-01-16 13:12:08.381967: step 6779, loss = 0.69804 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:12:09.147340 ops/training.py:65 2019-01-16 13:12:09.147239: step 6780, loss = 0.68869 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:12:09.915531 ops/training.py:65 2019-01-16 13:12:09.915414: step 6781, loss = 0.68676 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:12:10.683491 ops/training.py:65 2019-01-16 13:12:10.683375: step 6782, loss = 0.69425 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:12:11.452574 ops/training.py:65 2019-01-16 13:12:11.452453: step 6783, loss = 0.69421 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:12:12.220370 ops/training.py:65 2019-01-16 13:12:12.220257: step 6784, loss = 0.68643 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:12:12.986768 ops/training.py:65 2019-01-16 13:12:12.986692: step 6785, loss = 0.69039 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:12:13.752431 ops/training.py:65 2019-01-16 13:12:13.752349: step 6786, loss = 0.69651 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:12:14.518431 ops/training.py:65 2019-01-16 13:12:14.518357: step 6787, loss = 0.69069 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:12:15.284631 ops/training.py:65 2019-01-16 13:12:15.284525: step 6788, loss = 0.69880 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:12:16.050251 ops/training.py:65 2019-01-16 13:12:16.050112: step 6789, loss = 0.68483 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:12:16.814677 ops/training.py:65 2019-01-16 13:12:16.814582: step 6790, loss = 0.69157 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:12:17.580250 ops/training.py:65 2019-01-16 13:12:17.580146: step 6791, loss = 0.69592 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:12:18.345796 ops/training.py:65 2019-01-16 13:12:18.345684: step 6792, loss = 0.69881 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:12:19.110772 ops/training.py:65 2019-01-16 13:12:19.110662: step 6793, loss = 0.69217 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:12:19.876279 ops/training.py:65 2019-01-16 13:12:19.876174: step 6794, loss = 0.69791 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:12:20.642614 ops/training.py:65 2019-01-16 13:12:20.642502: step 6795, loss = 0.69953 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:12:21.408283 ops/training.py:65 2019-01-16 13:12:21.408176: step 6796, loss = 0.69536 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:12:22.174587 ops/training.py:65 2019-01-16 13:12:22.174474: step 6797, loss = 0.69986 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:12:22.939324 ops/training.py:65 2019-01-16 13:12:22.939220: step 6798, loss = 0.69129 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:12:23.704642 ops/training.py:65 2019-01-16 13:12:23.704544: step 6799, loss = 0.69164 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:12:24.470694 ops/training.py:65 2019-01-16 13:12:24.470594: step 6800, loss = 0.69959 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:12:25.237163 ops/training.py:65 2019-01-16 13:12:25.237023: step 6801, loss = 0.69619 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:12:26.002685 ops/training.py:65 2019-01-16 13:12:26.002576: step 6802, loss = 0.70257 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:12:26.768436 ops/training.py:65 2019-01-16 13:12:26.768318: step 6803, loss = 0.69315 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:12:27.535222 ops/training.py:65 2019-01-16 13:12:27.535108: step 6804, loss = 0.68852 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:12:28.303777 ops/training.py:65 2019-01-16 13:12:28.303667: step 6805, loss = 0.68997 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:12:29.072960 ops/training.py:65 2019-01-16 13:12:29.072840: step 6806, loss = 0.69991 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:12:29.840453 ops/training.py:65 2019-01-16 13:12:29.840306: step 6807, loss = 0.69957 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:12:30.606052 ops/training.py:65 2019-01-16 13:12:30.605934: step 6808, loss = 0.69237 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:12:31.371966 ops/training.py:65 2019-01-16 13:12:31.371857: step 6809, loss = 0.69624 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:12:32.137830 ops/training.py:65 2019-01-16 13:12:32.137691: step 6810, loss = 0.69310 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:12:32.904535 ops/training.py:65 2019-01-16 13:12:32.904418: step 6811, loss = 0.69321 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:12:33.674271 ops/training.py:65 2019-01-16 13:12:33.674162: step 6812, loss = 0.69373 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 13:12:34.441716 ops/training.py:65 2019-01-16 13:12:34.441601: step 6813, loss = 0.69270 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:12:35.207739 ops/training.py:65 2019-01-16 13:12:35.207638: step 6814, loss = 0.69306 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:12:35.972903 ops/training.py:65 2019-01-16 13:12:35.972832: step 6815, loss = 0.69438 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:12:36.737432 ops/training.py:65 2019-01-16 13:12:36.737340: step 6816, loss = 0.69446 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:12:37.502945 ops/training.py:65 2019-01-16 13:12:37.502848: step 6817, loss = 0.69236 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:12:38.268328 ops/training.py:65 2019-01-16 13:12:38.268241: step 6818, loss = 0.69583 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:12:39.032740 ops/training.py:65 2019-01-16 13:12:39.032656: step 6819, loss = 0.69179 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:12:39.797061 ops/training.py:65 2019-01-16 13:12:39.796985: step 6820, loss = 0.69633 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.3125
I0528 2019-01-16 13:12:40.563578 ops/training.py:65 2019-01-16 13:12:40.563521: step 6821, loss = 0.69204 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:12:41.330538 ops/training.py:65 2019-01-16 13:12:41.330435: step 6822, loss = 0.68925 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:12:42.097314 ops/training.py:65 2019-01-16 13:12:42.097204: step 6823, loss = 0.69297 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:12:42.865926 ops/training.py:65 2019-01-16 13:12:42.865822: step 6824, loss = 0.69424 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:12:43.632957 ops/training.py:65 2019-01-16 13:12:43.632857: step 6825, loss = 0.69270 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:12:44.399828 ops/training.py:65 2019-01-16 13:12:44.399716: step 6826, loss = 0.69848 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:12:45.164700 ops/training.py:65 2019-01-16 13:12:45.164595: step 6827, loss = 0.69546 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:12:45.930022 ops/training.py:65 2019-01-16 13:12:45.929907: step 6828, loss = 0.68815 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:12:46.695175 ops/training.py:65 2019-01-16 13:12:46.695065: step 6829, loss = 0.69463 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:12:47.460499 ops/training.py:65 2019-01-16 13:12:47.460394: step 6830, loss = 0.69555 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:12:48.226322 ops/training.py:65 2019-01-16 13:12:48.226201: step 6831, loss = 0.69410 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:12:48.991381 ops/training.py:65 2019-01-16 13:12:48.991272: step 6832, loss = 0.69238 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:12:49.756354 ops/training.py:65 2019-01-16 13:12:49.756245: step 6833, loss = 0.69298 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:12:50.522323 ops/training.py:65 2019-01-16 13:12:50.522219: step 6834, loss = 0.69547 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:12:51.287380 ops/training.py:65 2019-01-16 13:12:51.287268: step 6835, loss = 0.69282 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:12:52.052155 ops/training.py:65 2019-01-16 13:12:52.052042: step 6836, loss = 0.69352 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:12:52.816967 ops/training.py:65 2019-01-16 13:12:52.816854: step 6837, loss = 0.69033 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:12:53.581776 ops/training.py:65 2019-01-16 13:12:53.581664: step 6838, loss = 0.69681 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:12:54.348756 ops/training.py:65 2019-01-16 13:12:54.348643: step 6839, loss = 0.69213 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:12:55.117601 ops/training.py:65 2019-01-16 13:12:55.117490: step 6840, loss = 0.69409 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:12:55.885616 ops/training.py:65 2019-01-16 13:12:55.885525: step 6841, loss = 0.69169 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:12:56.653569 ops/training.py:65 2019-01-16 13:12:56.653474: step 6842, loss = 0.69661 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:12:57.420210 ops/training.py:65 2019-01-16 13:12:57.420111: step 6843, loss = 0.69255 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:12:58.184955 ops/training.py:65 2019-01-16 13:12:58.184842: step 6844, loss = 0.69515 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:12:58.950800 ops/training.py:65 2019-01-16 13:12:58.950694: step 6845, loss = 0.69114 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 13:12:59.717891 ops/training.py:65 2019-01-16 13:12:59.717777: step 6846, loss = 0.69271 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:13:00.486660 ops/training.py:65 2019-01-16 13:13:00.486552: step 6847, loss = 0.69522 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:13:01.256266 ops/training.py:65 2019-01-16 13:13:01.256161: step 6848, loss = 0.69394 (41.6 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:13:02.023615 ops/training.py:65 2019-01-16 13:13:02.023508: step 6849, loss = 0.69503 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:13:02.790051 ops/training.py:65 2019-01-16 13:13:02.789939: step 6850, loss = 0.68983 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:13:03.557711 ops/training.py:65 2019-01-16 13:13:03.557600: step 6851, loss = 0.69066 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:13:04.323737 ops/training.py:65 2019-01-16 13:13:04.323619: step 6852, loss = 0.69396 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:13:05.090796 ops/training.py:65 2019-01-16 13:13:05.090683: step 6853, loss = 0.69158 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:13:05.858116 ops/training.py:65 2019-01-16 13:13:05.858013: step 6854, loss = 0.69061 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:13:06.624984 ops/training.py:65 2019-01-16 13:13:06.624910: step 6855, loss = 0.69023 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:13:07.389952 ops/training.py:65 2019-01-16 13:13:07.389871: step 6856, loss = 0.69131 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:13:08.157101 ops/training.py:65 2019-01-16 13:13:08.157008: step 6857, loss = 0.69242 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:13:08.925465 ops/training.py:65 2019-01-16 13:13:08.925359: step 6858, loss = 0.69320 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:13:09.694388 ops/training.py:65 2019-01-16 13:13:09.694292: step 6859, loss = 0.68857 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 13:13:10.459996 ops/training.py:65 2019-01-16 13:13:10.459879: step 6860, loss = 0.69747 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:13:11.225121 ops/training.py:65 2019-01-16 13:13:11.225008: step 6861, loss = 0.69596 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:13:11.990251 ops/training.py:65 2019-01-16 13:13:11.990133: step 6862, loss = 0.68879 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:13:12.756254 ops/training.py:65 2019-01-16 13:13:12.756143: step 6863, loss = 0.69295 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:13:13.524570 ops/training.py:65 2019-01-16 13:13:13.524465: step 6864, loss = 0.69197 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:13:14.293637 ops/training.py:65 2019-01-16 13:13:14.293521: step 6865, loss = 0.69737 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:13:15.061866 ops/training.py:65 2019-01-16 13:13:15.061753: step 6866, loss = 0.69175 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:13:15.827849 ops/training.py:65 2019-01-16 13:13:15.827741: step 6867, loss = 0.69349 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:13:16.592870 ops/training.py:65 2019-01-16 13:13:16.592758: step 6868, loss = 0.69536 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:13:17.357724 ops/training.py:65 2019-01-16 13:13:17.357617: step 6869, loss = 0.69386 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:13:18.127143 ops/training.py:65 2019-01-16 13:13:18.127023: step 6870, loss = 0.69299 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:13:18.896069 ops/training.py:65 2019-01-16 13:13:18.895973: step 6871, loss = 0.69544 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:13:19.664456 ops/training.py:65 2019-01-16 13:13:19.664349: step 6872, loss = 0.69319 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:13:20.431640 ops/training.py:65 2019-01-16 13:13:20.431531: step 6873, loss = 0.69177 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:13:21.196336 ops/training.py:65 2019-01-16 13:13:21.196224: step 6874, loss = 0.69566 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:13:21.961496 ops/training.py:65 2019-01-16 13:13:21.961387: step 6875, loss = 0.69276 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:13:22.726833 ops/training.py:65 2019-01-16 13:13:22.726723: step 6876, loss = 0.69324 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:13:23.493554 ops/training.py:65 2019-01-16 13:13:23.493448: step 6877, loss = 0.69013 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:13:24.260922 ops/training.py:65 2019-01-16 13:13:24.260809: step 6878, loss = 0.69216 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:13:25.027026 ops/training.py:65 2019-01-16 13:13:25.026966: step 6879, loss = 0.69321 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:13:25.793126 ops/training.py:65 2019-01-16 13:13:25.793040: step 6880, loss = 0.69284 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:13:26.560254 ops/training.py:65 2019-01-16 13:13:26.560143: step 6881, loss = 0.69451 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:13:27.327087 ops/training.py:65 2019-01-16 13:13:27.326967: step 6882, loss = 0.69389 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:13:28.092400 ops/training.py:65 2019-01-16 13:13:28.092282: step 6883, loss = 0.68969 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:13:28.857999 ops/training.py:65 2019-01-16 13:13:28.857881: step 6884, loss = 0.69350 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:13:29.622447 ops/training.py:65 2019-01-16 13:13:29.622296: step 6885, loss = 0.69342 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:13:30.387668 ops/training.py:65 2019-01-16 13:13:30.387510: step 6886, loss = 0.69003 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:13:31.155940 ops/training.py:65 2019-01-16 13:13:31.155823: step 6887, loss = 0.69367 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:13:31.924107 ops/training.py:65 2019-01-16 13:13:31.924006: step 6888, loss = 0.69375 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:13:32.690463 ops/training.py:65 2019-01-16 13:13:32.690348: step 6889, loss = 0.69510 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:13:33.458468 ops/training.py:65 2019-01-16 13:13:33.458364: step 6890, loss = 0.69660 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 13:13:34.226236 ops/training.py:65 2019-01-16 13:13:34.226115: step 6891, loss = 0.69600 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:13:34.993234 ops/training.py:65 2019-01-16 13:13:34.993146: step 6892, loss = 0.69671 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:13:35.757641 ops/training.py:65 2019-01-16 13:13:35.757558: step 6893, loss = 0.70114 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:13:36.524881 ops/training.py:65 2019-01-16 13:13:36.524801: step 6894, loss = 0.69373 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:13:37.292370 ops/training.py:65 2019-01-16 13:13:37.292246: step 6895, loss = 0.69691 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:13:38.059323 ops/training.py:65 2019-01-16 13:13:38.059205: step 6896, loss = 0.70042 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.25
I0528 2019-01-16 13:13:38.823595 ops/training.py:65 2019-01-16 13:13:38.823477: step 6897, loss = 0.69278 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:13:39.588634 ops/training.py:65 2019-01-16 13:13:39.588523: step 6898, loss = 0.69517 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:13:40.353887 ops/training.py:65 2019-01-16 13:13:40.353771: step 6899, loss = 0.69909 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:13:41.118254 ops/training.py:65 2019-01-16 13:13:41.118139: step 6900, loss = 0.69402 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:13:41.883662 ops/training.py:65 2019-01-16 13:13:41.883556: step 6901, loss = 0.69228 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:13:42.649593 ops/training.py:65 2019-01-16 13:13:42.649482: step 6902, loss = 0.69247 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:13:43.419022 ops/training.py:65 2019-01-16 13:13:43.418914: step 6903, loss = 0.69835 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:13:44.186288 ops/training.py:65 2019-01-16 13:13:44.186176: step 6904, loss = 0.68982 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:13:44.951889 ops/training.py:65 2019-01-16 13:13:44.951765: step 6905, loss = 0.69254 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:13:45.717623 ops/training.py:65 2019-01-16 13:13:45.717507: step 6906, loss = 0.68006 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:13:46.484470 ops/training.py:65 2019-01-16 13:13:46.484358: step 6907, loss = 0.69391 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:13:47.250981 ops/training.py:65 2019-01-16 13:13:47.250891: step 6908, loss = 0.68594 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:13:48.017192 ops/training.py:65 2019-01-16 13:13:48.017076: step 6909, loss = 0.68991 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:13:48.783026 ops/training.py:65 2019-01-16 13:13:48.782910: step 6910, loss = 0.69219 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:13:49.548378 ops/training.py:65 2019-01-16 13:13:49.548257: step 6911, loss = 0.69579 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:13:50.313785 ops/training.py:65 2019-01-16 13:13:50.313673: step 6912, loss = 0.68392 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:13:51.078564 ops/training.py:65 2019-01-16 13:13:51.078448: step 6913, loss = 0.69660 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:13:51.843274 ops/training.py:65 2019-01-16 13:13:51.843155: step 6914, loss = 0.69400 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:13:52.611465 ops/training.py:65 2019-01-16 13:13:52.611355: step 6915, loss = 0.69152 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:13:53.379795 ops/training.py:65 2019-01-16 13:13:53.379701: step 6916, loss = 0.68927 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:13:54.148797 ops/training.py:65 2019-01-16 13:13:54.148684: step 6917, loss = 0.69484 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:13:54.917094 ops/training.py:65 2019-01-16 13:13:54.916978: step 6918, loss = 0.68330 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:13:55.685676 ops/training.py:65 2019-01-16 13:13:55.685555: step 6919, loss = 0.70157 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:13:56.451958 ops/training.py:65 2019-01-16 13:13:56.451845: step 6920, loss = 0.70638 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 13:13:57.218938 ops/training.py:65 2019-01-16 13:13:57.218837: step 6921, loss = 0.68861 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:13:57.985956 ops/training.py:65 2019-01-16 13:13:57.985852: step 6922, loss = 0.70109 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:13:58.752762 ops/training.py:65 2019-01-16 13:13:58.752655: step 6923, loss = 0.68839 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:13:59.517422 ops/training.py:65 2019-01-16 13:13:59.517312: step 6924, loss = 0.70047 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:14:00.282961 ops/training.py:65 2019-01-16 13:14:00.282859: step 6925, loss = 0.68654 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:14:01.048916 ops/training.py:65 2019-01-16 13:14:01.048808: step 6926, loss = 0.69055 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:14:01.814621 ops/training.py:65 2019-01-16 13:14:01.814508: step 6927, loss = 0.69442 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:14:02.579948 ops/training.py:65 2019-01-16 13:14:02.579845: step 6928, loss = 0.68464 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:14:03.345304 ops/training.py:65 2019-01-16 13:14:03.345191: step 6929, loss = 0.70307 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:14:04.110630 ops/training.py:65 2019-01-16 13:14:04.110517: step 6930, loss = 0.69318 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:14:04.874869 ops/training.py:65 2019-01-16 13:14:04.874764: step 6931, loss = 0.69737 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:14:05.639822 ops/training.py:65 2019-01-16 13:14:05.639713: step 6932, loss = 0.69785 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:14:06.405107 ops/training.py:65 2019-01-16 13:14:06.404993: step 6933, loss = 0.68866 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:14:07.170168 ops/training.py:65 2019-01-16 13:14:07.170055: step 6934, loss = 0.68940 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:14:07.934909 ops/training.py:65 2019-01-16 13:14:07.934794: step 6935, loss = 0.69199 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:14:08.701153 ops/training.py:65 2019-01-16 13:14:08.701041: step 6936, loss = 0.68817 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:14:09.466778 ops/training.py:65 2019-01-16 13:14:09.466666: step 6937, loss = 0.70501 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:14:10.231957 ops/training.py:65 2019-01-16 13:14:10.231850: step 6938, loss = 0.69918 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:14:10.996500 ops/training.py:65 2019-01-16 13:14:10.996385: step 6939, loss = 0.69989 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:14:11.762667 ops/training.py:65 2019-01-16 13:14:11.762555: step 6940, loss = 0.68750 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:14:12.528094 ops/training.py:65 2019-01-16 13:14:12.527987: step 6941, loss = 0.69689 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:14:13.294808 ops/training.py:65 2019-01-16 13:14:13.294703: step 6942, loss = 0.69437 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:14:14.060272 ops/training.py:65 2019-01-16 13:14:14.060159: step 6943, loss = 0.69675 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:14:14.825003 ops/training.py:65 2019-01-16 13:14:14.824889: step 6944, loss = 0.69239 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:14:15.592172 ops/training.py:65 2019-01-16 13:14:15.592055: step 6945, loss = 0.68884 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:14:16.360824 ops/training.py:65 2019-01-16 13:14:16.360713: step 6946, loss = 0.69377 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:14:17.128486 ops/training.py:65 2019-01-16 13:14:17.128403: step 6947, loss = 0.69950 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:14:17.895302 ops/training.py:65 2019-01-16 13:14:17.895194: step 6948, loss = 0.68989 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:14:18.660566 ops/training.py:65 2019-01-16 13:14:18.660467: step 6949, loss = 0.69236 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:14:19.426244 ops/training.py:65 2019-01-16 13:14:19.426133: step 6950, loss = 0.69560 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:14:20.191012 ops/training.py:65 2019-01-16 13:14:20.190903: step 6951, loss = 0.69412 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:14:20.956417 ops/training.py:65 2019-01-16 13:14:20.956316: step 6952, loss = 0.69464 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:14:21.721565 ops/training.py:65 2019-01-16 13:14:21.721454: step 6953, loss = 0.69546 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:14:22.487987 ops/training.py:65 2019-01-16 13:14:22.487882: step 6954, loss = 0.69246 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:14:23.254387 ops/training.py:65 2019-01-16 13:14:23.254289: step 6955, loss = 0.69832 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:14:24.019593 ops/training.py:65 2019-01-16 13:14:24.019491: step 6956, loss = 0.69627 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:14:24.786450 ops/training.py:65 2019-01-16 13:14:24.786361: step 6957, loss = 0.69335 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:14:25.552890 ops/training.py:65 2019-01-16 13:14:25.552777: step 6958, loss = 0.69420 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:14:26.321112 ops/training.py:65 2019-01-16 13:14:26.321013: step 6959, loss = 0.69273 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:14:27.087926 ops/training.py:65 2019-01-16 13:14:27.087826: step 6960, loss = 0.69400 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:14:27.854110 ops/training.py:65 2019-01-16 13:14:27.854025: step 6961, loss = 0.69614 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:14:28.619090 ops/training.py:65 2019-01-16 13:14:28.618983: step 6962, loss = 0.69262 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:14:29.384065 ops/training.py:65 2019-01-16 13:14:29.383953: step 6963, loss = 0.69008 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:14:30.149214 ops/training.py:65 2019-01-16 13:14:30.149109: step 6964, loss = 0.69054 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:14:30.914491 ops/training.py:65 2019-01-16 13:14:30.914386: step 6965, loss = 0.69302 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:14:31.679912 ops/training.py:65 2019-01-16 13:14:31.679800: step 6966, loss = 0.69437 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.34375
I0528 2019-01-16 13:14:32.446200 ops/training.py:65 2019-01-16 13:14:32.446091: step 6967, loss = 0.69365 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:14:33.211518 ops/training.py:65 2019-01-16 13:14:33.211405: step 6968, loss = 0.69448 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:14:33.976261 ops/training.py:65 2019-01-16 13:14:33.976158: step 6969, loss = 0.69364 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:14:34.741297 ops/training.py:65 2019-01-16 13:14:34.741189: step 6970, loss = 0.69163 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:14:35.506723 ops/training.py:65 2019-01-16 13:14:35.506608: step 6971, loss = 0.69330 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:14:36.272673 ops/training.py:65 2019-01-16 13:14:36.272565: step 6972, loss = 0.69251 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:14:37.037814 ops/training.py:65 2019-01-16 13:14:37.037702: step 6973, loss = 0.69092 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:14:37.801898 ops/training.py:65 2019-01-16 13:14:37.801789: step 6974, loss = 0.69383 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:14:38.567031 ops/training.py:65 2019-01-16 13:14:38.566916: step 6975, loss = 0.69312 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:14:39.331836 ops/training.py:65 2019-01-16 13:14:39.331719: step 6976, loss = 0.69464 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:14:40.097495 ops/training.py:65 2019-01-16 13:14:40.097380: step 6977, loss = 0.69540 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:14:40.861883 ops/training.py:65 2019-01-16 13:14:40.861764: step 6978, loss = 0.69267 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:14:41.627532 ops/training.py:65 2019-01-16 13:14:41.627418: step 6979, loss = 0.69307 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:14:42.393186 ops/training.py:65 2019-01-16 13:14:42.393086: step 6980, loss = 0.69418 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:14:43.159472 ops/training.py:65 2019-01-16 13:14:43.159367: step 6981, loss = 0.69239 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:14:43.924449 ops/training.py:65 2019-01-16 13:14:43.924338: step 6982, loss = 0.69346 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:14:44.690335 ops/training.py:65 2019-01-16 13:14:44.690222: step 6983, loss = 0.69102 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:14:45.456185 ops/training.py:65 2019-01-16 13:14:45.456040: step 6984, loss = 0.69204 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.65625
I0528 2019-01-16 13:14:46.221435 ops/training.py:65 2019-01-16 13:14:46.221323: step 6985, loss = 0.69171 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:14:46.989799 ops/training.py:65 2019-01-16 13:14:46.989699: step 6986, loss = 0.69177 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:14:47.757965 ops/training.py:65 2019-01-16 13:14:47.757846: step 6987, loss = 0.69323 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:14:48.526865 ops/training.py:65 2019-01-16 13:14:48.526767: step 6988, loss = 0.69315 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:14:49.294524 ops/training.py:65 2019-01-16 13:14:49.294419: step 6989, loss = 0.69572 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:14:50.062205 ops/training.py:65 2019-01-16 13:14:50.062086: step 6990, loss = 0.69501 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:14:50.827285 ops/training.py:65 2019-01-16 13:14:50.827179: step 6991, loss = 0.69651 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:14:51.592922 ops/training.py:65 2019-01-16 13:14:51.592810: step 6992, loss = 0.69239 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:14:52.359345 ops/training.py:65 2019-01-16 13:14:52.359231: step 6993, loss = 0.69250 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:14:53.124468 ops/training.py:65 2019-01-16 13:14:53.124365: step 6994, loss = 0.69268 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:14:53.889168 ops/training.py:65 2019-01-16 13:14:53.889069: step 6995, loss = 0.69234 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:14:54.654185 ops/training.py:65 2019-01-16 13:14:54.654091: step 6996, loss = 0.69281 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 13:14:55.420788 ops/training.py:65 2019-01-16 13:14:55.420682: step 6997, loss = 0.69387 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:14:56.186256 ops/training.py:65 2019-01-16 13:14:56.186160: step 6998, loss = 0.69250 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:14:56.951511 ops/training.py:65 2019-01-16 13:14:56.951408: step 6999, loss = 0.69278 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:14:57.716531 ops/training.py:65 2019-01-16 13:14:57.716433: step 7000, loss = 0.69616 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:14:58.482305 ops/training.py:65 2019-01-16 13:14:58.482197: step 7001, loss = 0.69310 (41.9 examples/sec; 0.765 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:14:59.249845 ops/training.py:65 2019-01-16 13:14:59.249733: step 7002, loss = 0.69530 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:15:00.014855 ops/training.py:65 2019-01-16 13:15:00.014753: step 7003, loss = 0.69444 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:15:00.780790 ops/training.py:65 2019-01-16 13:15:00.780684: step 7004, loss = 0.69318 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:15:01.546219 ops/training.py:65 2019-01-16 13:15:01.546115: step 7005, loss = 0.69334 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:15:02.313276 ops/training.py:65 2019-01-16 13:15:02.313173: step 7006, loss = 0.69503 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:15:03.082296 ops/training.py:65 2019-01-16 13:15:03.082191: step 7007, loss = 0.69192 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:15:03.850054 ops/training.py:65 2019-01-16 13:15:03.849940: step 7008, loss = 0.69391 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:15:04.618325 ops/training.py:65 2019-01-16 13:15:04.618212: step 7009, loss = 0.69172 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5625
I0528 2019-01-16 13:15:05.383663 ops/training.py:65 2019-01-16 13:15:05.383556: step 7010, loss = 0.69318 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.46875
I0528 2019-01-16 13:15:06.148605 ops/training.py:65 2019-01-16 13:15:06.148489: step 7011, loss = 0.69202 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:15:06.913704 ops/training.py:65 2019-01-16 13:15:06.913588: step 7012, loss = 0.69277 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:15:07.679062 ops/training.py:65 2019-01-16 13:15:07.678952: step 7013, loss = 0.69143 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:15:08.444265 ops/training.py:65 2019-01-16 13:15:08.444151: step 7014, loss = 0.69170 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.6875
I0528 2019-01-16 13:15:09.208590 ops/training.py:65 2019-01-16 13:15:09.208477: step 7015, loss = 0.69448 (41.9 examples/sec; 0.763 sec/batch) | Training accuracy = 0.375
I0528 2019-01-16 13:15:09.976138 ops/training.py:65 2019-01-16 13:15:09.976025: step 7016, loss = 0.69518 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.4375
I0528 2019-01-16 13:15:10.742927 ops/training.py:65 2019-01-16 13:15:10.742816: step 7017, loss = 0.69283 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:15:11.510627 ops/training.py:65 2019-01-16 13:15:11.510515: step 7018, loss = 0.69367 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:15:12.278419 ops/training.py:65 2019-01-16 13:15:12.278315: step 7019, loss = 0.69298 (41.7 examples/sec; 0.766 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:15:13.045513 ops/training.py:65 2019-01-16 13:15:13.045416: step 7020, loss = 0.69298 (41.8 examples/sec; 0.766 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:15:13.811999 ops/training.py:65 2019-01-16 13:15:13.811919: step 7021, loss = 0.69037 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:15:14.578089 ops/training.py:65 2019-01-16 13:15:14.577983: step 7022, loss = 0.69385 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.53125
I0528 2019-01-16 13:15:15.344117 ops/training.py:65 2019-01-16 13:15:15.344000: step 7023, loss = 0.69062 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.59375
I0528 2019-01-16 13:15:16.109706 ops/training.py:65 2019-01-16 13:15:16.109596: step 7024, loss = 0.69559 (41.9 examples/sec; 0.764 sec/batch) | Training accuracy = 0.40625
I0528 2019-01-16 13:15:16.877762 ops/training.py:65 2019-01-16 13:15:16.877648: step 7025, loss = 0.69027 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.625
I0528 2019-01-16 13:15:17.644207 ops/training.py:65 2019-01-16 13:15:17.644072: step 7026, loss = 0.69308 (41.8 examples/sec; 0.765 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:15:18.412193 ops/training.py:65 2019-01-16 13:15:18.412080: step 7027, loss = 0.69408 (41.7 examples/sec; 0.767 sec/batch) | Training accuracy = 0.5
I0528 2019-01-16 13:15:19.181219 ops/training.py:65 2019-01-16 13:15:19.181106: step 7028, loss = 0.69166 (41.7 examples/sec; 0.768 sec/batch) | Training accuracy = 0.59375
