I4672 2019-01-16 23:33:22.136278 ops/training.py:229 Log written to /gpfs_home/dlinsley/cluttered_nist_experiments/logs/nist_3_ix2v2_50k_2019_01_16_23_33_01_706250
I4672 2019-01-16 23:39:35.318024 ops/training.py:396 Failed to save checkpoint: global name 'db' is not defined
I4672 2019-01-16 23:39:35.319269 ops/training.py:41 2019-01-16 23:39:35.319210: step 0, loss = 0.71 (0.1 examples/sec; 364.286 sec/batch) | Training accuracy = 0.625 | Validation accuracy = 0.4951 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_23_33_01_706250
I4672 2019-01-16 23:39:36.605939 ops/training.py:65 2019-01-16 23:39:36.605794: step 1, loss = 0.91780 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:39:37.893523 ops/training.py:65 2019-01-16 23:39:37.893415: step 2, loss = 0.99944 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:39:39.174466 ops/training.py:65 2019-01-16 23:39:39.174362: step 3, loss = 0.81866 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:39:40.461199 ops/training.py:65 2019-01-16 23:39:40.461130: step 4, loss = 0.88281 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:39:41.744288 ops/training.py:65 2019-01-16 23:39:41.744188: step 5, loss = 0.95710 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-16 23:39:43.034267 ops/training.py:65 2019-01-16 23:39:43.034178: step 6, loss = 0.83496 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:39:44.322434 ops/training.py:65 2019-01-16 23:39:44.322323: step 7, loss = 1.08696 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-16 23:39:45.603562 ops/training.py:65 2019-01-16 23:39:45.603451: step 8, loss = 0.60113 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-16 23:39:46.883333 ops/training.py:65 2019-01-16 23:39:46.883218: step 9, loss = 0.78714 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:39:48.167500 ops/training.py:65 2019-01-16 23:39:48.167398: step 10, loss = 0.84488 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:39:49.458563 ops/training.py:65 2019-01-16 23:39:49.458461: step 11, loss = 0.93050 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:39:50.746569 ops/training.py:65 2019-01-16 23:39:50.746221: step 12, loss = 0.89079 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:39:52.034041 ops/training.py:65 2019-01-16 23:39:52.033933: step 13, loss = 0.60888 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:39:53.318211 ops/training.py:65 2019-01-16 23:39:53.318111: step 14, loss = 0.90918 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:39:54.606646 ops/training.py:65 2019-01-16 23:39:54.606539: step 15, loss = 0.83192 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:39:55.891307 ops/training.py:65 2019-01-16 23:39:55.891200: step 16, loss = 0.65641 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:39:57.177182 ops/training.py:65 2019-01-16 23:39:57.177077: step 17, loss = 0.73060 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-16 23:39:58.462244 ops/training.py:65 2019-01-16 23:39:58.462137: step 18, loss = 0.83899 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:39:59.750496 ops/training.py:65 2019-01-16 23:39:59.750391: step 19, loss = 1.01445 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:40:01.032327 ops/training.py:65 2019-01-16 23:40:01.032124: step 20, loss = 0.90072 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:40:02.327173 ops/training.py:65 2019-01-16 23:40:02.327084: step 21, loss = 0.79390 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-16 23:40:03.612874 ops/training.py:65 2019-01-16 23:40:03.612767: step 22, loss = 0.74678 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:40:04.904479 ops/training.py:65 2019-01-16 23:40:04.904373: step 23, loss = 0.74621 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:40:06.194490 ops/training.py:65 2019-01-16 23:40:06.194404: step 24, loss = 0.81324 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:40:07.485167 ops/training.py:65 2019-01-16 23:40:07.485092: step 25, loss = 0.84300 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:40:08.774827 ops/training.py:65 2019-01-16 23:40:08.774728: step 26, loss = 0.81597 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:40:10.061858 ops/training.py:65 2019-01-16 23:40:10.061754: step 27, loss = 0.74332 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:40:11.348067 ops/training.py:65 2019-01-16 23:40:11.347956: step 28, loss = 0.88252 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:40:12.628742 ops/training.py:65 2019-01-16 23:40:12.628634: step 29, loss = 0.74805 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:40:13.912141 ops/training.py:65 2019-01-16 23:40:13.912045: step 30, loss = 0.86818 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:40:15.200746 ops/training.py:65 2019-01-16 23:40:15.200643: step 31, loss = 0.67118 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-16 23:40:16.486116 ops/training.py:65 2019-01-16 23:40:16.486011: step 32, loss = 0.76967 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:40:17.772174 ops/training.py:65 2019-01-16 23:40:17.772079: step 33, loss = 0.89757 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:40:19.053936 ops/training.py:65 2019-01-16 23:40:19.053834: step 34, loss = 0.79316 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:40:20.338033 ops/training.py:65 2019-01-16 23:40:20.337874: step 35, loss = 0.68893 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:40:21.624549 ops/training.py:65 2019-01-16 23:40:21.624445: step 36, loss = 0.81465 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:40:22.909709 ops/training.py:65 2019-01-16 23:40:22.909603: step 37, loss = 0.78094 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:40:24.186149 ops/training.py:65 2019-01-16 23:40:24.186006: step 38, loss = 0.76679 (25.1 examples/sec; 1.275 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:40:25.470511 ops/training.py:65 2019-01-16 23:40:25.470405: step 39, loss = 1.01523 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-16 23:40:26.751862 ops/training.py:65 2019-01-16 23:40:26.751762: step 40, loss = 0.72644 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:40:28.033910 ops/training.py:65 2019-01-16 23:40:28.033800: step 41, loss = 0.58772 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-16 23:40:29.314072 ops/training.py:65 2019-01-16 23:40:29.313966: step 42, loss = 0.87536 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:40:30.597042 ops/training.py:65 2019-01-16 23:40:30.596933: step 43, loss = 0.78303 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:40:31.883833 ops/training.py:65 2019-01-16 23:40:31.883733: step 44, loss = 0.83627 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:40:33.169582 ops/training.py:65 2019-01-16 23:40:33.169485: step 45, loss = 0.79151 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:40:34.456731 ops/training.py:65 2019-01-16 23:40:34.456620: step 46, loss = 0.87801 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:40:35.741204 ops/training.py:65 2019-01-16 23:40:35.741097: step 47, loss = 0.74781 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:40:37.032087 ops/training.py:65 2019-01-16 23:40:37.031977: step 48, loss = 0.92448 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:40:38.315871 ops/training.py:65 2019-01-16 23:40:38.315805: step 49, loss = 0.84257 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:40:39.596517 ops/training.py:65 2019-01-16 23:40:39.596406: step 50, loss = 0.78486 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:40:40.883829 ops/training.py:65 2019-01-16 23:40:40.883723: step 51, loss = 0.87892 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:40:42.170791 ops/training.py:65 2019-01-16 23:40:42.170687: step 52, loss = 0.82695 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:40:43.452572 ops/training.py:65 2019-01-16 23:40:43.452472: step 53, loss = 0.77010 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:40:44.736322 ops/training.py:65 2019-01-16 23:40:44.736216: step 54, loss = 0.78683 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:40:46.021509 ops/training.py:65 2019-01-16 23:40:46.021405: step 55, loss = 0.83301 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:40:47.307365 ops/training.py:65 2019-01-16 23:40:47.307273: step 56, loss = 0.97695 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:40:48.590312 ops/training.py:65 2019-01-16 23:40:48.590208: step 57, loss = 0.76280 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:40:49.878610 ops/training.py:65 2019-01-16 23:40:49.878503: step 58, loss = 1.01545 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-16 23:40:51.163994 ops/training.py:65 2019-01-16 23:40:51.163893: step 59, loss = 0.77880 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:40:52.455667 ops/training.py:65 2019-01-16 23:40:52.455558: step 60, loss = 0.98782 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:40:53.741044 ops/training.py:65 2019-01-16 23:40:53.740978: step 61, loss = 0.84419 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:40:55.026468 ops/training.py:65 2019-01-16 23:40:55.026356: step 62, loss = 0.82334 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:40:56.320339 ops/training.py:65 2019-01-16 23:40:56.320179: step 63, loss = 0.98714 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 0.25
I4672 2019-01-16 23:40:57.608483 ops/training.py:65 2019-01-16 23:40:57.608405: step 64, loss = 0.66274 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-16 23:40:58.893177 ops/training.py:65 2019-01-16 23:40:58.893065: step 65, loss = 0.91708 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-16 23:41:00.182351 ops/training.py:65 2019-01-16 23:41:00.182241: step 66, loss = 0.91724 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:41:01.462717 ops/training.py:65 2019-01-16 23:41:01.462600: step 67, loss = 0.70296 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:41:02.745729 ops/training.py:65 2019-01-16 23:41:02.745629: step 68, loss = 0.89852 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:41:04.032269 ops/training.py:65 2019-01-16 23:41:04.032155: step 69, loss = 0.81539 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:41:05.315652 ops/training.py:65 2019-01-16 23:41:05.315548: step 70, loss = 0.85465 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:41:06.607373 ops/training.py:65 2019-01-16 23:41:06.607270: step 71, loss = 0.81522 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:41:07.897485 ops/training.py:65 2019-01-16 23:41:07.897419: step 72, loss = 0.85525 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:41:09.180272 ops/training.py:65 2019-01-16 23:41:09.180183: step 73, loss = 0.84596 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:41:10.461776 ops/training.py:65 2019-01-16 23:41:10.461664: step 74, loss = 0.94790 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:41:11.743286 ops/training.py:65 2019-01-16 23:41:11.743184: step 75, loss = 0.84624 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:41:13.023674 ops/training.py:65 2019-01-16 23:41:13.023572: step 76, loss = 0.82694 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:41:14.310747 ops/training.py:65 2019-01-16 23:41:14.310645: step 77, loss = 0.69307 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:41:15.598542 ops/training.py:65 2019-01-16 23:41:15.598437: step 78, loss = 0.91653 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:41:16.888088 ops/training.py:65 2019-01-16 23:41:16.887977: step 79, loss = 0.80183 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:41:18.170567 ops/training.py:65 2019-01-16 23:41:18.170487: step 80, loss = 0.83183 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:41:19.453468 ops/training.py:65 2019-01-16 23:41:19.453360: step 81, loss = 0.71877 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:41:20.740484 ops/training.py:65 2019-01-16 23:41:20.740373: step 82, loss = 0.83219 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:41:22.022793 ops/training.py:65 2019-01-16 23:41:22.022689: step 83, loss = 0.63273 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:41:23.311957 ops/training.py:65 2019-01-16 23:41:23.311854: step 84, loss = 0.69065 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:41:24.596108 ops/training.py:65 2019-01-16 23:41:24.595999: step 85, loss = 0.76139 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:41:25.884750 ops/training.py:65 2019-01-16 23:41:25.884638: step 86, loss = 0.78117 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:41:27.169811 ops/training.py:65 2019-01-16 23:41:27.169715: step 87, loss = 0.70308 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:41:28.452005 ops/training.py:65 2019-01-16 23:41:28.451892: step 88, loss = 0.76999 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:41:29.734832 ops/training.py:65 2019-01-16 23:41:29.734731: step 89, loss = 0.82905 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:41:31.024848 ops/training.py:65 2019-01-16 23:41:31.024741: step 90, loss = 0.88421 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:41:32.315476 ops/training.py:65 2019-01-16 23:41:32.315378: step 91, loss = 0.94925 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:41:33.604752 ops/training.py:65 2019-01-16 23:41:33.604653: step 92, loss = 0.76838 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:41:34.885913 ops/training.py:65 2019-01-16 23:41:34.885768: step 93, loss = 0.70974 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:41:36.175235 ops/training.py:65 2019-01-16 23:41:36.175127: step 94, loss = 0.81101 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:41:37.459751 ops/training.py:65 2019-01-16 23:41:37.459645: step 95, loss = 0.83094 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:41:38.743819 ops/training.py:65 2019-01-16 23:41:38.743705: step 96, loss = 0.69450 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:41:40.028070 ops/training.py:65 2019-01-16 23:41:40.027964: step 97, loss = 0.88099 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:41:41.305482 ops/training.py:65 2019-01-16 23:41:41.305383: step 98, loss = 0.86465 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:41:42.591814 ops/training.py:65 2019-01-16 23:41:42.591706: step 99, loss = 0.82352 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:41:43.873149 ops/training.py:65 2019-01-16 23:41:43.873052: step 100, loss = 0.70959 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:41:45.154104 ops/training.py:65 2019-01-16 23:41:45.153948: step 101, loss = 0.75537 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:41:46.435113 ops/training.py:65 2019-01-16 23:41:46.435013: step 102, loss = 0.72293 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:41:47.714420 ops/training.py:65 2019-01-16 23:41:47.714331: step 103, loss = 0.83719 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:41:48.998511 ops/training.py:65 2019-01-16 23:41:48.998415: step 104, loss = 0.72491 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:41:50.282273 ops/training.py:65 2019-01-16 23:41:50.282172: step 105, loss = 0.84987 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:41:51.565367 ops/training.py:65 2019-01-16 23:41:51.565260: step 106, loss = 0.83547 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:41:52.846838 ops/training.py:65 2019-01-16 23:41:52.846736: step 107, loss = 0.75397 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:41:54.124105 ops/training.py:65 2019-01-16 23:41:54.124003: step 108, loss = 0.80886 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:41:55.408339 ops/training.py:65 2019-01-16 23:41:55.408229: step 109, loss = 0.76313 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:41:56.695609 ops/training.py:65 2019-01-16 23:41:56.695522: step 110, loss = 0.82210 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:41:57.981271 ops/training.py:65 2019-01-16 23:41:57.981176: step 111, loss = 0.75974 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:41:59.266254 ops/training.py:65 2019-01-16 23:41:59.266161: step 112, loss = 0.68130 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:42:00.552562 ops/training.py:65 2019-01-16 23:42:00.552460: step 113, loss = 0.76246 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:42:01.836933 ops/training.py:65 2019-01-16 23:42:01.836784: step 114, loss = 0.66775 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:42:03.118257 ops/training.py:65 2019-01-16 23:42:03.118157: step 115, loss = 0.73830 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:42:04.398595 ops/training.py:65 2019-01-16 23:42:04.398486: step 116, loss = 0.80910 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:42:05.682818 ops/training.py:65 2019-01-16 23:42:05.682692: step 117, loss = 0.66710 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:42:06.969061 ops/training.py:65 2019-01-16 23:42:06.968928: step 118, loss = 0.82365 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:42:08.251911 ops/training.py:65 2019-01-16 23:42:08.251801: step 119, loss = 0.72455 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:42:09.536578 ops/training.py:65 2019-01-16 23:42:09.536473: step 120, loss = 0.72712 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:42:10.820945 ops/training.py:65 2019-01-16 23:42:10.820839: step 121, loss = 0.67068 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:42:12.101673 ops/training.py:65 2019-01-16 23:42:12.101562: step 122, loss = 0.82616 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:42:13.386173 ops/training.py:65 2019-01-16 23:42:13.386072: step 123, loss = 0.80569 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:42:14.671895 ops/training.py:65 2019-01-16 23:42:14.671786: step 124, loss = 0.70383 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:42:15.954649 ops/training.py:65 2019-01-16 23:42:15.954543: step 125, loss = 0.89805 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-16 23:42:17.236525 ops/training.py:65 2019-01-16 23:42:17.236431: step 126, loss = 0.72929 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:42:18.516074 ops/training.py:65 2019-01-16 23:42:18.515967: step 127, loss = 0.79897 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:42:19.798741 ops/training.py:65 2019-01-16 23:42:19.798638: step 128, loss = 0.83862 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:42:21.079109 ops/training.py:65 2019-01-16 23:42:21.079008: step 129, loss = 0.76273 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:42:22.358577 ops/training.py:65 2019-01-16 23:42:22.358489: step 130, loss = 0.72500 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:42:23.638885 ops/training.py:65 2019-01-16 23:42:23.638789: step 131, loss = 0.76564 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:42:24.921149 ops/training.py:65 2019-01-16 23:42:24.921054: step 132, loss = 0.76069 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:42:26.200941 ops/training.py:65 2019-01-16 23:42:26.200833: step 133, loss = 0.80470 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-16 23:42:27.484883 ops/training.py:65 2019-01-16 23:42:27.484769: step 134, loss = 0.90279 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-16 23:42:28.770105 ops/training.py:65 2019-01-16 23:42:28.769995: step 135, loss = 0.69933 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:42:30.057083 ops/training.py:65 2019-01-16 23:42:30.056975: step 136, loss = 0.76904 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:42:31.340500 ops/training.py:65 2019-01-16 23:42:31.340393: step 137, loss = 0.72838 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:42:32.627597 ops/training.py:65 2019-01-16 23:42:32.627500: step 138, loss = 0.74699 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:42:33.912331 ops/training.py:65 2019-01-16 23:42:33.912236: step 139, loss = 0.67412 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-16 23:42:35.204132 ops/training.py:65 2019-01-16 23:42:35.203983: step 140, loss = 0.73312 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:42:36.492183 ops/training.py:65 2019-01-16 23:42:36.492119: step 141, loss = 0.83395 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:42:37.772899 ops/training.py:65 2019-01-16 23:42:37.772788: step 142, loss = 0.84535 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:42:39.062493 ops/training.py:65 2019-01-16 23:42:39.062387: step 143, loss = 0.77680 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:42:40.348135 ops/training.py:65 2019-01-16 23:42:40.348033: step 144, loss = 0.66821 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:42:41.628528 ops/training.py:65 2019-01-16 23:42:41.628431: step 145, loss = 0.78338 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:42:42.908911 ops/training.py:65 2019-01-16 23:42:42.908809: step 146, loss = 0.65662 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:42:44.194011 ops/training.py:65 2019-01-16 23:42:44.193907: step 147, loss = 0.68041 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:42:45.475317 ops/training.py:65 2019-01-16 23:42:45.475208: step 148, loss = 0.80119 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:42:46.758617 ops/training.py:65 2019-01-16 23:42:46.758512: step 149, loss = 0.67276 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:42:48.040792 ops/training.py:65 2019-01-16 23:42:48.040695: step 150, loss = 0.67202 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:42:49.320196 ops/training.py:65 2019-01-16 23:42:49.320090: step 151, loss = 0.65949 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:42:50.604340 ops/training.py:65 2019-01-16 23:42:50.604238: step 152, loss = 0.76675 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:42:51.892357 ops/training.py:65 2019-01-16 23:42:51.892252: step 153, loss = 0.73321 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:42:53.177994 ops/training.py:65 2019-01-16 23:42:53.177899: step 154, loss = 0.87586 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:42:54.469999 ops/training.py:65 2019-01-16 23:42:54.469892: step 155, loss = 0.76083 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:42:55.751685 ops/training.py:65 2019-01-16 23:42:55.751579: step 156, loss = 0.74534 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:42:57.034383 ops/training.py:65 2019-01-16 23:42:57.034225: step 157, loss = 0.80108 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:42:58.318323 ops/training.py:65 2019-01-16 23:42:58.318213: step 158, loss = 0.76759 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:42:59.604239 ops/training.py:65 2019-01-16 23:42:59.604129: step 159, loss = 0.89514 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-16 23:43:00.882855 ops/training.py:65 2019-01-16 23:43:00.882750: step 160, loss = 0.60150 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:43:02.165677 ops/training.py:65 2019-01-16 23:43:02.165577: step 161, loss = 0.95380 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-16 23:43:03.451700 ops/training.py:65 2019-01-16 23:43:03.451597: step 162, loss = 0.73015 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:43:04.737745 ops/training.py:65 2019-01-16 23:43:04.737629: step 163, loss = 0.91660 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:43:06.028663 ops/training.py:65 2019-01-16 23:43:06.028507: step 164, loss = 0.67517 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:43:07.315315 ops/training.py:65 2019-01-16 23:43:07.315205: step 165, loss = 0.72737 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:43:08.600804 ops/training.py:65 2019-01-16 23:43:08.600697: step 166, loss = 0.88246 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:43:09.886393 ops/training.py:65 2019-01-16 23:43:09.886244: step 167, loss = 0.72655 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:43:11.174587 ops/training.py:65 2019-01-16 23:43:11.174480: step 168, loss = 0.97814 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:43:12.456251 ops/training.py:65 2019-01-16 23:43:12.456148: step 169, loss = 0.78921 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:43:13.740147 ops/training.py:65 2019-01-16 23:43:13.740052: step 170, loss = 0.71191 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:43:15.026736 ops/training.py:65 2019-01-16 23:43:15.026630: step 171, loss = 0.80072 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:43:16.318016 ops/training.py:65 2019-01-16 23:43:16.317908: step 172, loss = 0.79622 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:43:17.599057 ops/training.py:65 2019-01-16 23:43:17.598964: step 173, loss = 0.94612 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:43:18.884529 ops/training.py:65 2019-01-16 23:43:18.884423: step 174, loss = 0.73772 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:43:20.168048 ops/training.py:65 2019-01-16 23:43:20.167952: step 175, loss = 0.66888 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:43:21.450402 ops/training.py:65 2019-01-16 23:43:21.450303: step 176, loss = 0.77579 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:43:22.730532 ops/training.py:65 2019-01-16 23:43:22.730431: step 177, loss = 0.70689 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:43:24.012960 ops/training.py:65 2019-01-16 23:43:24.012864: step 178, loss = 0.70466 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:43:25.293259 ops/training.py:65 2019-01-16 23:43:25.293141: step 179, loss = 0.77344 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:43:26.574540 ops/training.py:65 2019-01-16 23:43:26.574430: step 180, loss = 0.79487 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:43:27.856386 ops/training.py:65 2019-01-16 23:43:27.856283: step 181, loss = 0.90520 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:43:29.147914 ops/training.py:65 2019-01-16 23:43:29.147815: step 182, loss = 0.73831 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:43:30.428451 ops/training.py:65 2019-01-16 23:43:30.428349: step 183, loss = 0.81021 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:43:31.721164 ops/training.py:65 2019-01-16 23:43:31.721054: step 184, loss = 0.91129 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:43:33.011320 ops/training.py:65 2019-01-16 23:43:33.011234: step 185, loss = 0.77648 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:43:34.300312 ops/training.py:65 2019-01-16 23:43:34.300210: step 186, loss = 0.73743 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:43:35.581305 ops/training.py:65 2019-01-16 23:43:35.581203: step 187, loss = 0.76649 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:43:36.859764 ops/training.py:65 2019-01-16 23:43:36.859611: step 188, loss = 1.02801 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.21875
I4672 2019-01-16 23:43:38.141074 ops/training.py:65 2019-01-16 23:43:38.140978: step 189, loss = 0.77939 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:43:39.425157 ops/training.py:65 2019-01-16 23:43:39.425050: step 190, loss = 0.75394 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:43:40.715709 ops/training.py:65 2019-01-16 23:43:40.715605: step 191, loss = 0.59190 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-16 23:43:42.003055 ops/training.py:65 2019-01-16 23:43:42.002965: step 192, loss = 0.88862 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:43:43.294437 ops/training.py:65 2019-01-16 23:43:43.294335: step 193, loss = 0.74473 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:43:44.576153 ops/training.py:65 2019-01-16 23:43:44.576093: step 194, loss = 0.93166 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-16 23:43:45.857158 ops/training.py:65 2019-01-16 23:43:45.857058: step 195, loss = 0.99415 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:43:47.141900 ops/training.py:65 2019-01-16 23:43:47.141795: step 196, loss = 0.79873 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:43:48.433101 ops/training.py:65 2019-01-16 23:43:48.433007: step 197, loss = 0.77251 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:43:49.718251 ops/training.py:65 2019-01-16 23:43:49.718134: step 198, loss = 0.74944 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:43:51.003102 ops/training.py:65 2019-01-16 23:43:51.002996: step 199, loss = 0.90342 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:43:52.287319 ops/training.py:65 2019-01-16 23:43:52.287204: step 200, loss = 0.83536 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:43:53.575240 ops/training.py:65 2019-01-16 23:43:53.575135: step 201, loss = 0.88392 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:43:54.858524 ops/training.py:65 2019-01-16 23:43:54.858423: step 202, loss = 0.71644 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:43:56.145534 ops/training.py:65 2019-01-16 23:43:56.145425: step 203, loss = 0.81271 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:43:57.429901 ops/training.py:65 2019-01-16 23:43:57.429793: step 204, loss = 0.74787 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:43:58.722178 ops/training.py:65 2019-01-16 23:43:58.722082: step 205, loss = 0.91544 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:44:00.008401 ops/training.py:65 2019-01-16 23:44:00.008296: step 206, loss = 0.90955 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:44:01.293352 ops/training.py:65 2019-01-16 23:44:01.293240: step 207, loss = 0.72774 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:44:02.581064 ops/training.py:65 2019-01-16 23:44:02.580968: step 208, loss = 0.68550 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:44:03.866313 ops/training.py:65 2019-01-16 23:44:03.866208: step 209, loss = 0.87129 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:44:05.152986 ops/training.py:65 2019-01-16 23:44:05.152880: step 210, loss = 0.91238 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:44:06.437076 ops/training.py:65 2019-01-16 23:44:06.436969: step 211, loss = 0.76533 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:44:07.718036 ops/training.py:65 2019-01-16 23:44:07.717929: step 212, loss = 0.91324 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:44:09.001557 ops/training.py:65 2019-01-16 23:44:09.001443: step 213, loss = 0.85867 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:44:10.291098 ops/training.py:65 2019-01-16 23:44:10.290980: step 214, loss = 0.82973 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:44:11.578513 ops/training.py:65 2019-01-16 23:44:11.578407: step 215, loss = 0.68818 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:44:12.859782 ops/training.py:65 2019-01-16 23:44:12.859671: step 216, loss = 0.80415 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:44:14.141135 ops/training.py:65 2019-01-16 23:44:14.141034: step 217, loss = 0.70731 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:44:15.421835 ops/training.py:65 2019-01-16 23:44:15.421723: step 218, loss = 0.72880 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:44:16.703553 ops/training.py:65 2019-01-16 23:44:16.703450: step 219, loss = 0.72334 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:44:17.987629 ops/training.py:65 2019-01-16 23:44:17.987531: step 220, loss = 0.84861 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:44:19.271828 ops/training.py:65 2019-01-16 23:44:19.271731: step 221, loss = 0.76040 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:44:20.557903 ops/training.py:65 2019-01-16 23:44:20.557799: step 222, loss = 0.72790 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:44:21.849016 ops/training.py:65 2019-01-16 23:44:21.848913: step 223, loss = 0.85026 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:44:23.130936 ops/training.py:65 2019-01-16 23:44:23.130839: step 224, loss = 0.65041 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:44:24.414408 ops/training.py:65 2019-01-16 23:44:24.414321: step 225, loss = 0.77273 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:44:25.695422 ops/training.py:65 2019-01-16 23:44:25.695320: step 226, loss = 0.72944 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:44:26.979272 ops/training.py:65 2019-01-16 23:44:26.979163: step 227, loss = 0.75348 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:44:28.267326 ops/training.py:65 2019-01-16 23:44:28.267222: step 228, loss = 0.69478 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:44:29.553604 ops/training.py:65 2019-01-16 23:44:29.553502: step 229, loss = 0.62748 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:44:30.830466 ops/training.py:65 2019-01-16 23:44:30.830358: step 230, loss = 0.73050 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:44:32.115129 ops/training.py:65 2019-01-16 23:44:32.115020: step 231, loss = 0.68281 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:44:33.402488 ops/training.py:65 2019-01-16 23:44:33.402396: step 232, loss = 0.75491 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:44:34.687380 ops/training.py:65 2019-01-16 23:44:34.687279: step 233, loss = 0.84142 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:44:35.967857 ops/training.py:65 2019-01-16 23:44:35.967747: step 234, loss = 0.79174 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:44:37.250875 ops/training.py:65 2019-01-16 23:44:37.250774: step 235, loss = 0.84784 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:44:38.530029 ops/training.py:65 2019-01-16 23:44:38.529924: step 236, loss = 0.76895 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:44:39.806725 ops/training.py:65 2019-01-16 23:44:39.806611: step 237, loss = 0.79318 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:44:41.087101 ops/training.py:65 2019-01-16 23:44:41.086992: step 238, loss = 0.70145 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:44:42.368586 ops/training.py:65 2019-01-16 23:44:42.368482: step 239, loss = 0.65189 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:44:43.651989 ops/training.py:65 2019-01-16 23:44:43.651887: step 240, loss = 0.82724 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:44:44.931199 ops/training.py:65 2019-01-16 23:44:44.931078: step 241, loss = 0.80524 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:44:46.211707 ops/training.py:65 2019-01-16 23:44:46.211592: step 242, loss = 0.83483 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-16 23:44:47.493610 ops/training.py:65 2019-01-16 23:44:47.493523: step 243, loss = 0.81115 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:44:48.772945 ops/training.py:65 2019-01-16 23:44:48.772840: step 244, loss = 0.68503 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:44:50.054201 ops/training.py:65 2019-01-16 23:44:50.054097: step 245, loss = 0.70961 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:44:51.341590 ops/training.py:65 2019-01-16 23:44:51.341480: step 246, loss = 0.75639 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:44:52.627167 ops/training.py:65 2019-01-16 23:44:52.627060: step 247, loss = 0.80445 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:44:53.914813 ops/training.py:65 2019-01-16 23:44:53.914701: step 248, loss = 0.83375 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:44:55.200374 ops/training.py:65 2019-01-16 23:44:55.200266: step 249, loss = 0.82697 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:44:56.486223 ops/training.py:65 2019-01-16 23:44:56.486117: step 250, loss = 0.64714 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:44:57.771425 ops/training.py:65 2019-01-16 23:44:57.771284: step 251, loss = 0.66848 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:44:59.056258 ops/training.py:65 2019-01-16 23:44:59.056153: step 252, loss = 0.66560 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:45:00.340120 ops/training.py:65 2019-01-16 23:45:00.340033: step 253, loss = 0.70825 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:45:01.626015 ops/training.py:65 2019-01-16 23:45:01.625912: step 254, loss = 0.83058 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:45:02.912924 ops/training.py:65 2019-01-16 23:45:02.912821: step 255, loss = 0.79707 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-16 23:45:04.196942 ops/training.py:65 2019-01-16 23:45:04.196849: step 256, loss = 0.61519 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:45:05.480980 ops/training.py:65 2019-01-16 23:45:05.480878: step 257, loss = 0.73050 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:45:06.761178 ops/training.py:65 2019-01-16 23:45:06.761085: step 258, loss = 0.79888 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:45:08.042991 ops/training.py:65 2019-01-16 23:45:08.042881: step 259, loss = 0.67799 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:45:09.327353 ops/training.py:65 2019-01-16 23:45:09.327251: step 260, loss = 0.70891 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:45:10.613994 ops/training.py:65 2019-01-16 23:45:10.613891: step 261, loss = 0.81067 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:45:11.899150 ops/training.py:65 2019-01-16 23:45:11.899041: step 262, loss = 0.74151 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:45:13.183455 ops/training.py:65 2019-01-16 23:45:13.183353: step 263, loss = 0.73891 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:45:14.471665 ops/training.py:65 2019-01-16 23:45:14.471562: step 264, loss = 0.74130 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:45:15.752038 ops/training.py:65 2019-01-16 23:45:15.751928: step 265, loss = 0.68090 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:45:17.034073 ops/training.py:65 2019-01-16 23:45:17.033970: step 266, loss = 0.67929 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:45:18.310578 ops/training.py:65 2019-01-16 23:45:18.310479: step 267, loss = 0.84290 (25.1 examples/sec; 1.275 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:45:19.595469 ops/training.py:65 2019-01-16 23:45:19.595360: step 268, loss = 0.80572 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:45:20.877947 ops/training.py:65 2019-01-16 23:45:20.877849: step 269, loss = 0.75425 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:45:22.159358 ops/training.py:65 2019-01-16 23:45:22.159250: step 270, loss = 0.72075 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:45:23.439746 ops/training.py:65 2019-01-16 23:45:23.439645: step 271, loss = 0.68697 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:45:24.720024 ops/training.py:65 2019-01-16 23:45:24.719911: step 272, loss = 0.75094 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:45:26.003284 ops/training.py:65 2019-01-16 23:45:26.003179: step 273, loss = 0.83705 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-16 23:45:27.286754 ops/training.py:65 2019-01-16 23:45:27.286651: step 274, loss = 0.73250 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:45:28.568224 ops/training.py:65 2019-01-16 23:45:28.568120: step 275, loss = 0.85723 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-16 23:45:29.849243 ops/training.py:65 2019-01-16 23:45:29.849135: step 276, loss = 0.73892 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:45:31.129811 ops/training.py:65 2019-01-16 23:45:31.129704: step 277, loss = 0.70891 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:45:32.415183 ops/training.py:65 2019-01-16 23:45:32.415085: step 278, loss = 0.72419 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:45:33.699059 ops/training.py:65 2019-01-16 23:45:33.698952: step 279, loss = 0.66110 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:45:34.981548 ops/training.py:65 2019-01-16 23:45:34.981462: step 280, loss = 0.63981 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:45:36.264548 ops/training.py:65 2019-01-16 23:45:36.264446: step 281, loss = 0.73174 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:45:37.544081 ops/training.py:65 2019-01-16 23:45:37.543981: step 282, loss = 0.71618 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:45:38.824522 ops/training.py:65 2019-01-16 23:45:38.824410: step 283, loss = 0.77830 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-16 23:45:40.103319 ops/training.py:65 2019-01-16 23:45:40.103205: step 284, loss = 0.84008 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:45:41.382719 ops/training.py:65 2019-01-16 23:45:41.382604: step 285, loss = 0.76002 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:45:42.665239 ops/training.py:65 2019-01-16 23:45:42.665136: step 286, loss = 0.75795 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:45:43.946420 ops/training.py:65 2019-01-16 23:45:43.946315: step 287, loss = 0.86090 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-16 23:45:45.227337 ops/training.py:65 2019-01-16 23:45:45.227219: step 288, loss = 0.67496 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:45:46.511215 ops/training.py:65 2019-01-16 23:45:46.511111: step 289, loss = 0.74409 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:45:47.792252 ops/training.py:65 2019-01-16 23:45:47.792159: step 290, loss = 0.74695 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:45:49.075264 ops/training.py:65 2019-01-16 23:45:49.075154: step 291, loss = 0.66647 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-16 23:45:50.356373 ops/training.py:65 2019-01-16 23:45:50.356265: step 292, loss = 0.71682 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:45:51.639404 ops/training.py:65 2019-01-16 23:45:51.639319: step 293, loss = 0.58289 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:45:52.925091 ops/training.py:65 2019-01-16 23:45:52.924982: step 294, loss = 0.78152 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:45:54.206063 ops/training.py:65 2019-01-16 23:45:54.205974: step 295, loss = 0.79211 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-16 23:45:55.487318 ops/training.py:65 2019-01-16 23:45:55.487205: step 296, loss = 0.80206 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:45:56.777640 ops/training.py:65 2019-01-16 23:45:56.777526: step 297, loss = 0.80413 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:45:58.064192 ops/training.py:65 2019-01-16 23:45:58.064094: step 298, loss = 0.74613 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:45:59.350458 ops/training.py:65 2019-01-16 23:45:59.350356: step 299, loss = 0.77423 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:46:00.637597 ops/training.py:65 2019-01-16 23:46:00.637497: step 300, loss = 0.85738 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:46:01.919144 ops/training.py:65 2019-01-16 23:46:01.919035: step 301, loss = 0.73637 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:46:03.207044 ops/training.py:65 2019-01-16 23:46:03.206948: step 302, loss = 0.88378 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:46:04.489191 ops/training.py:65 2019-01-16 23:46:04.489098: step 303, loss = 0.86029 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:46:05.774438 ops/training.py:65 2019-01-16 23:46:05.774349: step 304, loss = 0.79564 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:46:07.060260 ops/training.py:65 2019-01-16 23:46:07.060160: step 305, loss = 0.70129 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:46:08.347265 ops/training.py:65 2019-01-16 23:46:08.347164: step 306, loss = 0.67475 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:46:09.635138 ops/training.py:65 2019-01-16 23:46:09.635030: step 307, loss = 0.63851 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:46:10.925050 ops/training.py:65 2019-01-16 23:46:10.924943: step 308, loss = 0.75501 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:46:12.210554 ops/training.py:65 2019-01-16 23:46:12.210488: step 309, loss = 0.82968 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:46:13.488419 ops/training.py:65 2019-01-16 23:46:13.488309: step 310, loss = 0.77241 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:46:14.777701 ops/training.py:65 2019-01-16 23:46:14.777585: step 311, loss = 0.65083 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:46:16.060531 ops/training.py:65 2019-01-16 23:46:16.060429: step 312, loss = 0.75458 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:46:17.347608 ops/training.py:65 2019-01-16 23:46:17.347504: step 313, loss = 0.84148 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:46:18.629204 ops/training.py:65 2019-01-16 23:46:18.629108: step 314, loss = 0.71086 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:46:19.912344 ops/training.py:65 2019-01-16 23:46:19.912234: step 315, loss = 0.75198 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:46:21.195860 ops/training.py:65 2019-01-16 23:46:21.195756: step 316, loss = 0.72415 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:46:22.477013 ops/training.py:65 2019-01-16 23:46:22.476909: step 317, loss = 0.78649 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:46:23.760418 ops/training.py:65 2019-01-16 23:46:23.760327: step 318, loss = 0.75411 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:46:25.047865 ops/training.py:65 2019-01-16 23:46:25.047762: step 319, loss = 0.82170 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:46:26.329760 ops/training.py:65 2019-01-16 23:46:26.329663: step 320, loss = 0.80535 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:46:27.609250 ops/training.py:65 2019-01-16 23:46:27.609143: step 321, loss = 0.71908 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:46:28.891733 ops/training.py:65 2019-01-16 23:46:28.891623: step 322, loss = 0.65080 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:46:30.177295 ops/training.py:65 2019-01-16 23:46:30.177199: step 323, loss = 0.67046 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:46:31.463755 ops/training.py:65 2019-01-16 23:46:31.463642: step 324, loss = 0.78258 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:46:32.755431 ops/training.py:65 2019-01-16 23:46:32.755335: step 325, loss = 0.79167 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:46:34.041078 ops/training.py:65 2019-01-16 23:46:34.040996: step 326, loss = 0.74257 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:46:35.327538 ops/training.py:65 2019-01-16 23:46:35.327445: step 327, loss = 0.83303 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:46:36.619508 ops/training.py:65 2019-01-16 23:46:36.619407: step 328, loss = 0.57197 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.75
I4672 2019-01-16 23:46:37.897499 ops/training.py:65 2019-01-16 23:46:37.897396: step 329, loss = 0.69350 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:46:39.179928 ops/training.py:65 2019-01-16 23:46:39.179821: step 330, loss = 0.70162 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:46:40.463631 ops/training.py:65 2019-01-16 23:46:40.463521: step 331, loss = 0.79247 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:46:41.744636 ops/training.py:65 2019-01-16 23:46:41.744521: step 332, loss = 0.72656 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:46:43.028665 ops/training.py:65 2019-01-16 23:46:43.028566: step 333, loss = 0.65271 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-16 23:46:44.314253 ops/training.py:65 2019-01-16 23:46:44.314141: step 334, loss = 0.72182 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:46:45.603153 ops/training.py:65 2019-01-16 23:46:45.603046: step 335, loss = 0.75918 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:46:46.888137 ops/training.py:65 2019-01-16 23:46:46.888022: step 336, loss = 0.72331 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:46:48.171751 ops/training.py:65 2019-01-16 23:46:48.171654: step 337, loss = 0.86380 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-16 23:46:49.458677 ops/training.py:65 2019-01-16 23:46:49.458570: step 338, loss = 0.67378 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:46:50.740454 ops/training.py:65 2019-01-16 23:46:50.740358: step 339, loss = 0.88862 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:46:52.022457 ops/training.py:65 2019-01-16 23:46:52.022352: step 340, loss = 0.68996 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:46:53.305483 ops/training.py:65 2019-01-16 23:46:53.305381: step 341, loss = 0.75810 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:46:54.592176 ops/training.py:65 2019-01-16 23:46:54.592079: step 342, loss = 0.69068 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:46:55.874521 ops/training.py:65 2019-01-16 23:46:55.874420: step 343, loss = 0.73008 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:46:57.158211 ops/training.py:65 2019-01-16 23:46:57.158110: step 344, loss = 0.69383 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:46:58.447135 ops/training.py:65 2019-01-16 23:46:58.447033: step 345, loss = 0.80547 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:46:59.734174 ops/training.py:65 2019-01-16 23:46:59.734066: step 346, loss = 0.68649 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:47:01.019626 ops/training.py:65 2019-01-16 23:47:01.019518: step 347, loss = 0.74225 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:47:02.307907 ops/training.py:65 2019-01-16 23:47:02.307794: step 348, loss = 0.76351 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:47:03.592388 ops/training.py:65 2019-01-16 23:47:03.592294: step 349, loss = 0.71249 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:47:04.878436 ops/training.py:65 2019-01-16 23:47:04.878331: step 350, loss = 0.83419 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:47:06.160723 ops/training.py:65 2019-01-16 23:47:06.160615: step 351, loss = 0.75995 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:47:07.444275 ops/training.py:65 2019-01-16 23:47:07.444117: step 352, loss = 0.70180 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:47:08.728643 ops/training.py:65 2019-01-16 23:47:08.728548: step 353, loss = 0.72604 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:47:10.012178 ops/training.py:65 2019-01-16 23:47:10.012074: step 354, loss = 0.79427 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:47:11.294596 ops/training.py:65 2019-01-16 23:47:11.294493: step 355, loss = 0.79059 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:47:12.578011 ops/training.py:65 2019-01-16 23:47:12.577914: step 356, loss = 0.74015 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:47:13.859291 ops/training.py:65 2019-01-16 23:47:13.859184: step 357, loss = 0.71228 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:47:15.141291 ops/training.py:65 2019-01-16 23:47:15.141182: step 358, loss = 0.70342 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:47:16.421484 ops/training.py:65 2019-01-16 23:47:16.421382: step 359, loss = 0.78761 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:47:17.701164 ops/training.py:65 2019-01-16 23:47:17.701066: step 360, loss = 0.76619 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:47:18.980809 ops/training.py:65 2019-01-16 23:47:18.980711: step 361, loss = 0.72987 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:47:20.261677 ops/training.py:65 2019-01-16 23:47:20.261584: step 362, loss = 0.77764 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:47:21.541838 ops/training.py:65 2019-01-16 23:47:21.541743: step 363, loss = 0.81993 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-16 23:47:22.821824 ops/training.py:65 2019-01-16 23:47:22.821717: step 364, loss = 0.76411 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:47:24.101459 ops/training.py:65 2019-01-16 23:47:24.101305: step 365, loss = 0.75424 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:47:25.379093 ops/training.py:65 2019-01-16 23:47:25.378946: step 366, loss = 0.63985 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:47:26.665843 ops/training.py:65 2019-01-16 23:47:26.665730: step 367, loss = 0.73825 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:47:27.949368 ops/training.py:65 2019-01-16 23:47:27.949256: step 368, loss = 0.65062 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:47:29.230778 ops/training.py:65 2019-01-16 23:47:29.230682: step 369, loss = 0.72639 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:47:30.517233 ops/training.py:65 2019-01-16 23:47:30.517126: step 370, loss = 0.72873 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:47:31.802942 ops/training.py:65 2019-01-16 23:47:31.802834: step 371, loss = 0.74442 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:47:33.088743 ops/training.py:65 2019-01-16 23:47:33.088646: step 372, loss = 0.69327 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:47:34.368506 ops/training.py:65 2019-01-16 23:47:34.368401: step 373, loss = 0.68120 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:47:35.648076 ops/training.py:65 2019-01-16 23:47:35.647970: step 374, loss = 0.76423 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:47:36.931213 ops/training.py:65 2019-01-16 23:47:36.931120: step 375, loss = 0.71832 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:47:38.217184 ops/training.py:65 2019-01-16 23:47:38.217080: step 376, loss = 0.83367 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:47:39.497113 ops/training.py:65 2019-01-16 23:47:39.497022: step 377, loss = 0.76813 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:47:40.781963 ops/training.py:65 2019-01-16 23:47:40.781858: step 378, loss = 0.75132 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:47:42.066294 ops/training.py:65 2019-01-16 23:47:42.066203: step 379, loss = 0.75658 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:47:43.349362 ops/training.py:65 2019-01-16 23:47:43.349265: step 380, loss = 0.81615 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-16 23:47:44.633517 ops/training.py:65 2019-01-16 23:47:44.633425: step 381, loss = 0.76449 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:47:45.920820 ops/training.py:65 2019-01-16 23:47:45.920720: step 382, loss = 0.82049 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:47:47.200448 ops/training.py:65 2019-01-16 23:47:47.200312: step 383, loss = 0.67990 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:47:48.488040 ops/training.py:65 2019-01-16 23:47:48.487943: step 384, loss = 0.69767 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:47:49.772823 ops/training.py:65 2019-01-16 23:47:49.772725: step 385, loss = 0.79132 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:47:51.057794 ops/training.py:65 2019-01-16 23:47:51.057699: step 386, loss = 0.75311 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:47:52.339368 ops/training.py:65 2019-01-16 23:47:52.339265: step 387, loss = 0.72083 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:47:53.620284 ops/training.py:65 2019-01-16 23:47:53.620190: step 388, loss = 0.75962 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:47:54.900201 ops/training.py:65 2019-01-16 23:47:54.900108: step 389, loss = 0.78814 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:47:56.184813 ops/training.py:65 2019-01-16 23:47:56.184664: step 390, loss = 0.73324 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:47:57.473421 ops/training.py:65 2019-01-16 23:47:57.473316: step 391, loss = 0.86965 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:47:58.755789 ops/training.py:65 2019-01-16 23:47:58.755682: step 392, loss = 0.75461 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:48:00.040087 ops/training.py:65 2019-01-16 23:48:00.039968: step 393, loss = 0.88006 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-16 23:48:01.325153 ops/training.py:65 2019-01-16 23:48:01.325033: step 394, loss = 0.74287 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:48:02.612436 ops/training.py:65 2019-01-16 23:48:02.612339: step 395, loss = 0.73841 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:48:03.898258 ops/training.py:65 2019-01-16 23:48:03.898159: step 396, loss = 0.72049 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:48:05.183237 ops/training.py:65 2019-01-16 23:48:05.183139: step 397, loss = 0.79815 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:48:06.467282 ops/training.py:65 2019-01-16 23:48:06.467175: step 398, loss = 0.80158 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:48:07.752608 ops/training.py:65 2019-01-16 23:48:07.752518: step 399, loss = 0.64092 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:48:09.039248 ops/training.py:65 2019-01-16 23:48:09.039141: step 400, loss = 0.64435 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:48:10.324396 ops/training.py:65 2019-01-16 23:48:10.324286: step 401, loss = 0.72258 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:48:11.616311 ops/training.py:65 2019-01-16 23:48:11.616212: step 402, loss = 0.65410 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:48:12.907444 ops/training.py:65 2019-01-16 23:48:12.907338: step 403, loss = 0.73914 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:48:14.194254 ops/training.py:65 2019-01-16 23:48:14.194155: step 404, loss = 0.75305 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:48:15.476722 ops/training.py:65 2019-01-16 23:48:15.476614: step 405, loss = 0.66183 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:48:16.760537 ops/training.py:65 2019-01-16 23:48:16.760432: step 406, loss = 0.76648 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-16 23:48:18.041017 ops/training.py:65 2019-01-16 23:48:18.040913: step 407, loss = 0.73554 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:48:19.322279 ops/training.py:65 2019-01-16 23:48:19.322185: step 408, loss = 0.62839 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:48:20.606377 ops/training.py:65 2019-01-16 23:48:20.606277: step 409, loss = 0.71416 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:48:21.891502 ops/training.py:65 2019-01-16 23:48:21.891401: step 410, loss = 0.78291 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:48:23.176568 ops/training.py:65 2019-01-16 23:48:23.176431: step 411, loss = 0.70853 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:48:24.460013 ops/training.py:65 2019-01-16 23:48:24.459904: step 412, loss = 0.73733 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:48:25.742108 ops/training.py:65 2019-01-16 23:48:25.742015: step 413, loss = 0.74411 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:48:27.023681 ops/training.py:65 2019-01-16 23:48:27.023588: step 414, loss = 0.73626 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:48:28.304369 ops/training.py:65 2019-01-16 23:48:28.304273: step 415, loss = 0.78579 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:48:29.584051 ops/training.py:65 2019-01-16 23:48:29.583955: step 416, loss = 0.68116 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:48:30.864715 ops/training.py:65 2019-01-16 23:48:30.864618: step 417, loss = 0.78093 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:48:32.142448 ops/training.py:65 2019-01-16 23:48:32.142346: step 418, loss = 0.61392 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:48:33.425871 ops/training.py:65 2019-01-16 23:48:33.425779: step 419, loss = 0.70060 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:48:34.709965 ops/training.py:65 2019-01-16 23:48:34.709879: step 420, loss = 0.72176 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:48:35.996082 ops/training.py:65 2019-01-16 23:48:35.996001: step 421, loss = 0.70968 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:48:37.276843 ops/training.py:65 2019-01-16 23:48:37.276759: step 422, loss = 0.63667 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:48:38.555030 ops/training.py:65 2019-01-16 23:48:38.554947: step 423, loss = 0.73828 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:48:39.834741 ops/training.py:65 2019-01-16 23:48:39.834645: step 424, loss = 0.77978 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-16 23:48:41.115153 ops/training.py:65 2019-01-16 23:48:41.115056: step 425, loss = 0.69220 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:48:42.395716 ops/training.py:65 2019-01-16 23:48:42.395618: step 426, loss = 0.75842 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:48:43.676148 ops/training.py:65 2019-01-16 23:48:43.676054: step 427, loss = 0.71625 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:48:44.956081 ops/training.py:65 2019-01-16 23:48:44.955986: step 428, loss = 0.62329 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:48:46.239143 ops/training.py:65 2019-01-16 23:48:46.239050: step 429, loss = 0.74338 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:48:47.520756 ops/training.py:65 2019-01-16 23:48:47.520653: step 430, loss = 0.72906 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:48:48.802284 ops/training.py:65 2019-01-16 23:48:48.802187: step 431, loss = 0.70768 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:48:50.082044 ops/training.py:65 2019-01-16 23:48:50.081946: step 432, loss = 0.71788 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:48:51.363054 ops/training.py:65 2019-01-16 23:48:51.362951: step 433, loss = 0.68376 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:48:52.645572 ops/training.py:65 2019-01-16 23:48:52.645476: step 434, loss = 0.73687 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:48:53.926393 ops/training.py:65 2019-01-16 23:48:53.926312: step 435, loss = 0.75308 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:48:55.207323 ops/training.py:65 2019-01-16 23:48:55.207231: step 436, loss = 0.80781 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:48:56.488712 ops/training.py:65 2019-01-16 23:48:56.488617: step 437, loss = 0.63447 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:48:57.770420 ops/training.py:65 2019-01-16 23:48:57.770316: step 438, loss = 0.69546 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:48:59.050866 ops/training.py:65 2019-01-16 23:48:59.050768: step 439, loss = 0.80613 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:49:00.331634 ops/training.py:65 2019-01-16 23:49:00.331537: step 440, loss = 0.71737 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:49:01.612493 ops/training.py:65 2019-01-16 23:49:01.612391: step 441, loss = 0.71578 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:49:02.896003 ops/training.py:65 2019-01-16 23:49:02.895909: step 442, loss = 0.72887 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:49:04.178302 ops/training.py:65 2019-01-16 23:49:04.178201: step 443, loss = 0.75775 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:49:05.459745 ops/training.py:65 2019-01-16 23:49:05.459651: step 444, loss = 0.70711 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:49:06.742027 ops/training.py:65 2019-01-16 23:49:06.741942: step 445, loss = 0.78806 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:49:08.024401 ops/training.py:65 2019-01-16 23:49:08.024308: step 446, loss = 0.67285 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:49:09.306157 ops/training.py:65 2019-01-16 23:49:09.306056: step 447, loss = 0.70748 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:49:10.587023 ops/training.py:65 2019-01-16 23:49:10.586916: step 448, loss = 0.66734 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:49:11.866345 ops/training.py:65 2019-01-16 23:49:11.866252: step 449, loss = 0.76259 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:49:13.145869 ops/training.py:65 2019-01-16 23:49:13.145773: step 450, loss = 0.75825 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:49:14.425974 ops/training.py:65 2019-01-16 23:49:14.425868: step 451, loss = 0.74975 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:49:15.706628 ops/training.py:65 2019-01-16 23:49:15.706525: step 452, loss = 0.80647 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:49:16.986774 ops/training.py:65 2019-01-16 23:49:16.986669: step 453, loss = 0.68184 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:49:18.267055 ops/training.py:65 2019-01-16 23:49:18.266950: step 454, loss = 0.79452 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-16 23:49:19.547255 ops/training.py:65 2019-01-16 23:49:19.547155: step 455, loss = 0.76551 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:49:20.828073 ops/training.py:65 2019-01-16 23:49:20.827963: step 456, loss = 0.68833 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:49:22.108275 ops/training.py:65 2019-01-16 23:49:22.108176: step 457, loss = 0.68012 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:49:23.388879 ops/training.py:65 2019-01-16 23:49:23.388781: step 458, loss = 0.66544 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:49:24.667448 ops/training.py:65 2019-01-16 23:49:24.667348: step 459, loss = 0.69647 (25.0 examples/sec; 1.277 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:49:25.949247 ops/training.py:65 2019-01-16 23:49:25.949146: step 460, loss = 0.69800 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:49:27.228052 ops/training.py:65 2019-01-16 23:49:27.227959: step 461, loss = 0.73663 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:49:28.510555 ops/training.py:65 2019-01-16 23:49:28.510451: step 462, loss = 0.70128 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:49:29.795827 ops/training.py:65 2019-01-16 23:49:29.795722: step 463, loss = 0.65153 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:49:31.083057 ops/training.py:65 2019-01-16 23:49:31.082953: step 464, loss = 0.76745 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:49:32.367316 ops/training.py:65 2019-01-16 23:49:32.367232: step 465, loss = 0.77371 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:49:33.648512 ops/training.py:65 2019-01-16 23:49:33.648425: step 466, loss = 0.69123 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:49:34.930105 ops/training.py:65 2019-01-16 23:49:34.930026: step 467, loss = 0.72013 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:49:36.211194 ops/training.py:65 2019-01-16 23:49:36.211101: step 468, loss = 0.76449 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:49:37.492289 ops/training.py:65 2019-01-16 23:49:37.492211: step 469, loss = 0.83482 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:49:38.772414 ops/training.py:65 2019-01-16 23:49:38.772327: step 470, loss = 0.70337 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:49:40.056081 ops/training.py:65 2019-01-16 23:49:40.055974: step 471, loss = 0.74244 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:49:41.336469 ops/training.py:65 2019-01-16 23:49:41.336360: step 472, loss = 0.73332 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:49:42.618967 ops/training.py:65 2019-01-16 23:49:42.618880: step 473, loss = 0.73392 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:49:43.903826 ops/training.py:65 2019-01-16 23:49:43.903725: step 474, loss = 0.76948 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:49:45.188455 ops/training.py:65 2019-01-16 23:49:45.188351: step 475, loss = 0.77706 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:49:46.471381 ops/training.py:65 2019-01-16 23:49:46.471289: step 476, loss = 0.74405 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:49:47.751167 ops/training.py:65 2019-01-16 23:49:47.751074: step 477, loss = 0.76973 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:49:49.030348 ops/training.py:65 2019-01-16 23:49:49.030260: step 478, loss = 0.71333 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:49:50.311147 ops/training.py:65 2019-01-16 23:49:50.311050: step 479, loss = 0.76488 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:49:51.593069 ops/training.py:65 2019-01-16 23:49:51.592963: step 480, loss = 0.85596 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-16 23:49:52.878159 ops/training.py:65 2019-01-16 23:49:52.878054: step 481, loss = 0.72390 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:49:54.167069 ops/training.py:65 2019-01-16 23:49:54.166966: step 482, loss = 0.72972 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:49:55.455696 ops/training.py:65 2019-01-16 23:49:55.455589: step 483, loss = 0.77742 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-16 23:49:56.740498 ops/training.py:65 2019-01-16 23:49:56.740405: step 484, loss = 0.80036 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:49:58.021645 ops/training.py:65 2019-01-16 23:49:58.021549: step 485, loss = 0.79502 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:49:59.301836 ops/training.py:65 2019-01-16 23:49:59.301731: step 486, loss = 0.70051 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:50:00.584607 ops/training.py:65 2019-01-16 23:50:00.584509: step 487, loss = 0.63361 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:50:01.869873 ops/training.py:65 2019-01-16 23:50:01.869779: step 488, loss = 0.77237 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:50:03.152722 ops/training.py:65 2019-01-16 23:50:03.152629: step 489, loss = 0.68106 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:50:04.434214 ops/training.py:65 2019-01-16 23:50:04.434108: step 490, loss = 0.77272 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:50:05.715129 ops/training.py:65 2019-01-16 23:50:05.715033: step 491, loss = 0.77537 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:50:06.998134 ops/training.py:65 2019-01-16 23:50:06.998034: step 492, loss = 0.61600 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-16 23:50:08.280577 ops/training.py:65 2019-01-16 23:50:08.280473: step 493, loss = 0.75839 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:50:09.562173 ops/training.py:65 2019-01-16 23:50:09.562072: step 494, loss = 0.76616 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:50:10.846924 ops/training.py:65 2019-01-16 23:50:10.846824: step 495, loss = 0.69783 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:50:12.133128 ops/training.py:65 2019-01-16 23:50:12.133020: step 496, loss = 0.68017 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:50:13.415848 ops/training.py:65 2019-01-16 23:50:13.415750: step 497, loss = 0.73747 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:50:14.700186 ops/training.py:65 2019-01-16 23:50:14.700083: step 498, loss = 0.76492 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:50:15.981492 ops/training.py:65 2019-01-16 23:50:15.981397: step 499, loss = 0.64033 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:50:17.262372 ops/training.py:65 2019-01-16 23:50:17.262280: step 500, loss = 0.65171 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:50:18.547080 ops/training.py:65 2019-01-16 23:50:18.546991: step 501, loss = 0.70567 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:50:19.832215 ops/training.py:65 2019-01-16 23:50:19.832120: step 502, loss = 0.76158 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:50:21.114493 ops/training.py:65 2019-01-16 23:50:21.114390: step 503, loss = 0.66800 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:50:22.396459 ops/training.py:65 2019-01-16 23:50:22.396356: step 504, loss = 0.72206 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:50:23.677570 ops/training.py:65 2019-01-16 23:50:23.677475: step 505, loss = 0.75819 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:50:24.959291 ops/training.py:65 2019-01-16 23:50:24.959193: step 506, loss = 0.69341 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:50:26.243360 ops/training.py:65 2019-01-16 23:50:26.243257: step 507, loss = 0.72646 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:50:27.526821 ops/training.py:65 2019-01-16 23:50:27.526716: step 508, loss = 0.64207 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-16 23:50:28.808423 ops/training.py:65 2019-01-16 23:50:28.808320: step 509, loss = 0.65471 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-16 23:50:30.092875 ops/training.py:65 2019-01-16 23:50:30.092772: step 510, loss = 0.67445 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:50:31.373527 ops/training.py:65 2019-01-16 23:50:31.373419: step 511, loss = 0.81293 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:50:32.658208 ops/training.py:65 2019-01-16 23:50:32.658104: step 512, loss = 0.71030 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:50:33.936723 ops/training.py:65 2019-01-16 23:50:33.936621: step 513, loss = 0.71566 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:50:35.217976 ops/training.py:65 2019-01-16 23:50:35.217877: step 514, loss = 0.78038 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:50:36.497756 ops/training.py:65 2019-01-16 23:50:36.497652: step 515, loss = 0.66976 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:50:37.776703 ops/training.py:65 2019-01-16 23:50:37.776601: step 516, loss = 0.72555 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:50:39.056755 ops/training.py:65 2019-01-16 23:50:39.056651: step 517, loss = 0.78920 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:50:40.336961 ops/training.py:65 2019-01-16 23:50:40.336859: step 518, loss = 0.76588 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:50:41.617140 ops/training.py:65 2019-01-16 23:50:41.617042: step 519, loss = 0.82338 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:50:42.901857 ops/training.py:65 2019-01-16 23:50:42.901763: step 520, loss = 0.80082 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:50:44.190389 ops/training.py:65 2019-01-16 23:50:44.190282: step 521, loss = 0.79701 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:50:45.478183 ops/training.py:65 2019-01-16 23:50:45.478079: step 522, loss = 0.69701 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:50:46.763777 ops/training.py:65 2019-01-16 23:50:46.763670: step 523, loss = 0.76087 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:50:48.049862 ops/training.py:65 2019-01-16 23:50:48.049774: step 524, loss = 0.69402 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:50:49.337005 ops/training.py:65 2019-01-16 23:50:49.336895: step 525, loss = 0.71826 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:50:50.622723 ops/training.py:65 2019-01-16 23:50:50.622577: step 526, loss = 0.73878 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:50:51.910581 ops/training.py:65 2019-01-16 23:50:51.910474: step 527, loss = 0.70970 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:50:53.196969 ops/training.py:65 2019-01-16 23:50:53.196874: step 528, loss = 0.64694 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:50:54.477854 ops/training.py:65 2019-01-16 23:50:54.477753: step 529, loss = 0.74771 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:50:55.760446 ops/training.py:65 2019-01-16 23:50:55.760357: step 530, loss = 0.82132 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:50:57.044413 ops/training.py:65 2019-01-16 23:50:57.044308: step 531, loss = 0.73339 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:50:58.324657 ops/training.py:65 2019-01-16 23:50:58.324555: step 532, loss = 0.67744 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:50:59.605818 ops/training.py:65 2019-01-16 23:50:59.605727: step 533, loss = 0.71055 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:51:00.886022 ops/training.py:65 2019-01-16 23:51:00.885923: step 534, loss = 0.77551 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:51:02.165448 ops/training.py:65 2019-01-16 23:51:02.165351: step 535, loss = 0.78318 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:51:03.446126 ops/training.py:65 2019-01-16 23:51:03.446039: step 536, loss = 0.73553 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:51:04.726644 ops/training.py:65 2019-01-16 23:51:04.726549: step 537, loss = 0.70699 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:51:06.006963 ops/training.py:65 2019-01-16 23:51:06.006870: step 538, loss = 0.70566 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:51:07.287761 ops/training.py:65 2019-01-16 23:51:07.287660: step 539, loss = 0.87051 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:51:08.568806 ops/training.py:65 2019-01-16 23:51:08.568704: step 540, loss = 0.75807 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:51:09.846568 ops/training.py:65 2019-01-16 23:51:09.846464: step 541, loss = 0.74619 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:51:11.128147 ops/training.py:65 2019-01-16 23:51:11.128037: step 542, loss = 0.74387 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:51:12.410088 ops/training.py:65 2019-01-16 23:51:12.410002: step 543, loss = 0.69850 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:51:13.695321 ops/training.py:65 2019-01-16 23:51:13.695230: step 544, loss = 0.70934 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:51:14.977359 ops/training.py:65 2019-01-16 23:51:14.977258: step 545, loss = 0.77136 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:51:16.259612 ops/training.py:65 2019-01-16 23:51:16.259505: step 546, loss = 0.68563 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:51:17.542996 ops/training.py:65 2019-01-16 23:51:17.542894: step 547, loss = 0.72287 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:51:18.830299 ops/training.py:65 2019-01-16 23:51:18.830195: step 548, loss = 0.73358 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:51:20.117620 ops/training.py:65 2019-01-16 23:51:20.117521: step 549, loss = 0.66335 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:51:21.400111 ops/training.py:65 2019-01-16 23:51:21.400003: step 550, loss = 0.78469 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:51:22.687079 ops/training.py:65 2019-01-16 23:51:22.686984: step 551, loss = 0.72966 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:51:23.968716 ops/training.py:65 2019-01-16 23:51:23.968616: step 552, loss = 0.76450 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:51:25.251862 ops/training.py:65 2019-01-16 23:51:25.251769: step 553, loss = 0.66882 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:51:26.543269 ops/training.py:65 2019-01-16 23:51:26.543169: step 554, loss = 0.71066 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:51:27.829819 ops/training.py:65 2019-01-16 23:51:27.829705: step 555, loss = 0.78482 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:51:29.116008 ops/training.py:65 2019-01-16 23:51:29.115900: step 556, loss = 0.72888 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:51:30.395556 ops/training.py:65 2019-01-16 23:51:30.395455: step 557, loss = 0.83807 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:51:31.679890 ops/training.py:65 2019-01-16 23:51:31.679797: step 558, loss = 0.67507 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:51:32.961449 ops/training.py:65 2019-01-16 23:51:32.961357: step 559, loss = 0.72795 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:51:34.243095 ops/training.py:65 2019-01-16 23:51:34.243047: step 560, loss = 0.72791 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:51:35.524128 ops/training.py:65 2019-01-16 23:51:35.524042: step 561, loss = 0.78290 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:51:36.809150 ops/training.py:65 2019-01-16 23:51:36.809052: step 562, loss = 0.75064 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-16 23:51:38.094690 ops/training.py:65 2019-01-16 23:51:38.094577: step 563, loss = 0.72645 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:51:39.380467 ops/training.py:65 2019-01-16 23:51:39.380370: step 564, loss = 0.76278 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:51:40.662889 ops/training.py:65 2019-01-16 23:51:40.662786: step 565, loss = 0.72106 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:51:41.945880 ops/training.py:65 2019-01-16 23:51:41.945789: step 566, loss = 0.76155 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:51:43.231511 ops/training.py:65 2019-01-16 23:51:43.231416: step 567, loss = 0.62903 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:51:44.517684 ops/training.py:65 2019-01-16 23:51:44.517580: step 568, loss = 0.74413 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:51:45.802642 ops/training.py:65 2019-01-16 23:51:45.802535: step 569, loss = 0.65910 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:51:47.084942 ops/training.py:65 2019-01-16 23:51:47.084835: step 570, loss = 0.72427 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:51:48.371387 ops/training.py:65 2019-01-16 23:51:48.371285: step 571, loss = 0.74696 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:51:49.659144 ops/training.py:65 2019-01-16 23:51:49.659047: step 572, loss = 0.66367 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:51:50.943914 ops/training.py:65 2019-01-16 23:51:50.943778: step 573, loss = 0.79041 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-16 23:51:52.231294 ops/training.py:65 2019-01-16 23:51:52.231190: step 574, loss = 0.72385 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:51:53.521436 ops/training.py:65 2019-01-16 23:51:53.521351: step 575, loss = 0.72271 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:51:54.805835 ops/training.py:65 2019-01-16 23:51:54.805727: step 576, loss = 0.66696 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:51:56.094857 ops/training.py:65 2019-01-16 23:51:56.094752: step 577, loss = 0.67969 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:51:57.383994 ops/training.py:65 2019-01-16 23:51:57.383897: step 578, loss = 0.68000 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:51:58.667746 ops/training.py:65 2019-01-16 23:51:58.667646: step 579, loss = 0.72137 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:51:59.951234 ops/training.py:65 2019-01-16 23:51:59.951126: step 580, loss = 0.64974 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:52:01.235303 ops/training.py:65 2019-01-16 23:52:01.235196: step 581, loss = 0.69769 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:52:02.520678 ops/training.py:65 2019-01-16 23:52:02.520570: step 582, loss = 0.73138 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:52:03.803151 ops/training.py:65 2019-01-16 23:52:03.803061: step 583, loss = 0.73195 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:52:05.080664 ops/training.py:65 2019-01-16 23:52:05.080563: step 584, loss = 0.80069 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-16 23:52:06.357883 ops/training.py:65 2019-01-16 23:52:06.357752: step 585, loss = 0.73454 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:52:07.638735 ops/training.py:65 2019-01-16 23:52:07.638626: step 586, loss = 0.83747 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-16 23:52:08.919340 ops/training.py:65 2019-01-16 23:52:08.919230: step 587, loss = 0.71908 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:52:10.197565 ops/training.py:65 2019-01-16 23:52:10.197473: step 588, loss = 0.75887 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:52:11.478243 ops/training.py:65 2019-01-16 23:52:11.478131: step 589, loss = 0.70457 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:52:12.759727 ops/training.py:65 2019-01-16 23:52:12.759610: step 590, loss = 0.72423 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:52:14.041345 ops/training.py:65 2019-01-16 23:52:14.041252: step 591, loss = 0.72666 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:52:15.321683 ops/training.py:65 2019-01-16 23:52:15.321571: step 592, loss = 0.71132 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:52:16.612343 ops/training.py:65 2019-01-16 23:52:16.612247: step 593, loss = 0.70498 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:52:17.897799 ops/training.py:65 2019-01-16 23:52:17.897698: step 594, loss = 0.73147 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:52:19.180731 ops/training.py:65 2019-01-16 23:52:19.180624: step 595, loss = 0.75204 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:52:20.467790 ops/training.py:65 2019-01-16 23:52:20.467686: step 596, loss = 0.69345 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:52:21.753267 ops/training.py:65 2019-01-16 23:52:21.753157: step 597, loss = 0.71661 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:52:23.039897 ops/training.py:65 2019-01-16 23:52:23.039851: step 598, loss = 0.76460 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:52:24.323150 ops/training.py:65 2019-01-16 23:52:24.323102: step 599, loss = 0.75061 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:52:25.606659 ops/training.py:65 2019-01-16 23:52:25.606565: step 600, loss = 0.70217 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:52:26.895993 ops/training.py:65 2019-01-16 23:52:26.895884: step 601, loss = 0.69498 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:52:28.177834 ops/training.py:65 2019-01-16 23:52:28.177736: step 602, loss = 0.70092 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:52:29.462265 ops/training.py:65 2019-01-16 23:52:29.462169: step 603, loss = 0.75229 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:52:30.746853 ops/training.py:65 2019-01-16 23:52:30.746743: step 604, loss = 0.79267 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:52:32.034629 ops/training.py:65 2019-01-16 23:52:32.034524: step 605, loss = 0.74567 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:52:33.317029 ops/training.py:65 2019-01-16 23:52:33.316933: step 606, loss = 0.66363 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:52:34.598087 ops/training.py:65 2019-01-16 23:52:34.597982: step 607, loss = 0.71969 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:52:35.882195 ops/training.py:65 2019-01-16 23:52:35.882082: step 608, loss = 0.79642 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:52:37.168381 ops/training.py:65 2019-01-16 23:52:37.168274: step 609, loss = 0.66389 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:52:38.448204 ops/training.py:65 2019-01-16 23:52:38.448096: step 610, loss = 0.70059 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:52:39.731409 ops/training.py:65 2019-01-16 23:52:39.731309: step 611, loss = 0.68226 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:52:41.016443 ops/training.py:65 2019-01-16 23:52:41.016329: step 612, loss = 0.73178 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:52:42.297909 ops/training.py:65 2019-01-16 23:52:42.297808: step 613, loss = 0.73581 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:52:43.575677 ops/training.py:65 2019-01-16 23:52:43.575573: step 614, loss = 0.73175 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:52:44.856260 ops/training.py:65 2019-01-16 23:52:44.856154: step 615, loss = 0.68725 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:52:46.136477 ops/training.py:65 2019-01-16 23:52:46.136372: step 616, loss = 0.67744 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:52:47.421174 ops/training.py:65 2019-01-16 23:52:47.421069: step 617, loss = 0.69348 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:52:48.702343 ops/training.py:65 2019-01-16 23:52:48.702239: step 618, loss = 0.69366 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:52:49.987050 ops/training.py:65 2019-01-16 23:52:49.986949: step 619, loss = 0.67674 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:52:51.268562 ops/training.py:65 2019-01-16 23:52:51.268457: step 620, loss = 0.70914 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:52:52.549682 ops/training.py:65 2019-01-16 23:52:52.549579: step 621, loss = 0.70305 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:52:53.834634 ops/training.py:65 2019-01-16 23:52:53.834527: step 622, loss = 0.76828 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:52:55.116497 ops/training.py:65 2019-01-16 23:52:55.116393: step 623, loss = 0.78806 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:52:56.399566 ops/training.py:65 2019-01-16 23:52:56.399460: step 624, loss = 0.68082 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:52:57.684541 ops/training.py:65 2019-01-16 23:52:57.684445: step 625, loss = 0.72707 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:52:58.970938 ops/training.py:65 2019-01-16 23:52:58.970829: step 626, loss = 0.74438 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:53:00.253227 ops/training.py:65 2019-01-16 23:53:00.253123: step 627, loss = 0.69581 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:53:01.535230 ops/training.py:65 2019-01-16 23:53:01.535117: step 628, loss = 0.69447 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:53:02.815293 ops/training.py:65 2019-01-16 23:53:02.815187: step 629, loss = 0.79447 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:53:04.097981 ops/training.py:65 2019-01-16 23:53:04.097881: step 630, loss = 0.76729 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:53:05.379489 ops/training.py:65 2019-01-16 23:53:05.379389: step 631, loss = 0.71969 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:53:06.660555 ops/training.py:65 2019-01-16 23:53:06.660458: step 632, loss = 0.66763 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:53:07.941115 ops/training.py:65 2019-01-16 23:53:07.941015: step 633, loss = 0.73133 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:53:09.221499 ops/training.py:65 2019-01-16 23:53:09.221393: step 634, loss = 0.74771 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:53:10.503785 ops/training.py:65 2019-01-16 23:53:10.503680: step 635, loss = 0.77697 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:53:11.788006 ops/training.py:65 2019-01-16 23:53:11.787900: step 636, loss = 0.71802 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:53:13.070607 ops/training.py:65 2019-01-16 23:53:13.070504: step 637, loss = 0.75547 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:53:14.351673 ops/training.py:65 2019-01-16 23:53:14.351574: step 638, loss = 0.62976 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-16 23:53:15.633567 ops/training.py:65 2019-01-16 23:53:15.633463: step 639, loss = 0.76301 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:53:16.924792 ops/training.py:65 2019-01-16 23:53:16.924693: step 640, loss = 0.63250 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-16 23:53:18.208079 ops/training.py:65 2019-01-16 23:53:18.207986: step 641, loss = 0.74862 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:53:19.489235 ops/training.py:65 2019-01-16 23:53:19.489138: step 642, loss = 0.66721 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:53:20.770792 ops/training.py:65 2019-01-16 23:53:20.770692: step 643, loss = 0.79151 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:53:22.051900 ops/training.py:65 2019-01-16 23:53:22.051804: step 644, loss = 0.71989 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:53:23.336992 ops/training.py:65 2019-01-16 23:53:23.336886: step 645, loss = 0.73944 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:53:24.623549 ops/training.py:65 2019-01-16 23:53:24.623441: step 646, loss = 0.59050 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-16 23:53:25.906893 ops/training.py:65 2019-01-16 23:53:25.906795: step 647, loss = 0.84067 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:53:27.189040 ops/training.py:65 2019-01-16 23:53:27.188935: step 648, loss = 0.56937 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-16 23:53:28.470312 ops/training.py:65 2019-01-16 23:53:28.470209: step 649, loss = 0.69867 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:53:29.751320 ops/training.py:65 2019-01-16 23:53:29.751214: step 650, loss = 0.72463 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:53:31.031711 ops/training.py:65 2019-01-16 23:53:31.031612: step 651, loss = 0.65278 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:53:32.313240 ops/training.py:65 2019-01-16 23:53:32.313137: step 652, loss = 0.66017 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:53:33.593966 ops/training.py:65 2019-01-16 23:53:33.593872: step 653, loss = 0.84378 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:53:34.875443 ops/training.py:65 2019-01-16 23:53:34.875341: step 654, loss = 0.78080 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:53:36.156243 ops/training.py:65 2019-01-16 23:53:36.156137: step 655, loss = 0.86018 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-16 23:53:37.433806 ops/training.py:65 2019-01-16 23:53:37.433706: step 656, loss = 0.61446 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:53:38.717657 ops/training.py:65 2019-01-16 23:53:38.717555: step 657, loss = 0.67806 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:53:40.002172 ops/training.py:65 2019-01-16 23:53:40.002064: step 658, loss = 0.75122 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:53:41.282662 ops/training.py:65 2019-01-16 23:53:41.282556: step 659, loss = 0.73428 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:53:42.562970 ops/training.py:65 2019-01-16 23:53:42.562865: step 660, loss = 0.91725 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:53:43.844743 ops/training.py:65 2019-01-16 23:53:43.844641: step 661, loss = 0.68425 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:53:45.124516 ops/training.py:65 2019-01-16 23:53:45.124406: step 662, loss = 0.74498 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:53:46.404918 ops/training.py:65 2019-01-16 23:53:46.404816: step 663, loss = 0.67094 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:53:47.686514 ops/training.py:65 2019-01-16 23:53:47.686409: step 664, loss = 0.65376 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:53:48.967757 ops/training.py:65 2019-01-16 23:53:48.967649: step 665, loss = 0.71322 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:53:50.247876 ops/training.py:65 2019-01-16 23:53:50.247773: step 666, loss = 0.87776 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:53:51.535829 ops/training.py:65 2019-01-16 23:53:51.535724: step 667, loss = 0.78716 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:53:52.817912 ops/training.py:65 2019-01-16 23:53:52.817806: step 668, loss = 0.63363 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:53:54.100984 ops/training.py:65 2019-01-16 23:53:54.100880: step 669, loss = 0.70159 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:53:55.382199 ops/training.py:65 2019-01-16 23:53:55.382103: step 670, loss = 0.78288 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:53:56.663681 ops/training.py:65 2019-01-16 23:53:56.663585: step 671, loss = 0.82115 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:53:57.943793 ops/training.py:65 2019-01-16 23:53:57.943688: step 672, loss = 0.85959 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:53:59.224674 ops/training.py:65 2019-01-16 23:53:59.224577: step 673, loss = 0.76841 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:54:00.505467 ops/training.py:65 2019-01-16 23:54:00.505358: step 674, loss = 0.84701 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:54:01.785467 ops/training.py:65 2019-01-16 23:54:01.785354: step 675, loss = 0.76635 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:54:03.065603 ops/training.py:65 2019-01-16 23:54:03.065511: step 676, loss = 0.65222 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:54:04.346504 ops/training.py:65 2019-01-16 23:54:04.346407: step 677, loss = 0.95917 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.25
I4672 2019-01-16 23:54:05.626944 ops/training.py:65 2019-01-16 23:54:05.626837: step 678, loss = 0.76181 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:54:06.907888 ops/training.py:65 2019-01-16 23:54:06.907787: step 679, loss = 0.71815 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:54:08.188744 ops/training.py:65 2019-01-16 23:54:08.188646: step 680, loss = 0.65720 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:54:09.469629 ops/training.py:65 2019-01-16 23:54:09.469532: step 681, loss = 0.85628 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:54:10.750520 ops/training.py:65 2019-01-16 23:54:10.750424: step 682, loss = 0.63955 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-16 23:54:12.037170 ops/training.py:65 2019-01-16 23:54:12.037061: step 683, loss = 0.81356 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:54:13.318239 ops/training.py:65 2019-01-16 23:54:13.318146: step 684, loss = 0.83223 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-16 23:54:14.598238 ops/training.py:65 2019-01-16 23:54:14.598136: step 685, loss = 0.78766 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:54:15.882640 ops/training.py:65 2019-01-16 23:54:15.882531: step 686, loss = 0.71039 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:54:17.164147 ops/training.py:65 2019-01-16 23:54:17.164049: step 687, loss = 0.68430 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:54:18.445871 ops/training.py:65 2019-01-16 23:54:18.445780: step 688, loss = 0.67724 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:54:19.725832 ops/training.py:65 2019-01-16 23:54:19.725739: step 689, loss = 0.72635 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:54:21.007562 ops/training.py:65 2019-01-16 23:54:21.007462: step 690, loss = 0.78981 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-16 23:54:22.288905 ops/training.py:65 2019-01-16 23:54:22.288800: step 691, loss = 0.72758 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:54:23.569545 ops/training.py:65 2019-01-16 23:54:23.569467: step 692, loss = 0.77368 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:54:24.850741 ops/training.py:65 2019-01-16 23:54:24.850648: step 693, loss = 0.70479 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:54:26.131802 ops/training.py:65 2019-01-16 23:54:26.131704: step 694, loss = 0.75392 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:54:27.413552 ops/training.py:65 2019-01-16 23:54:27.413452: step 695, loss = 0.76080 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:54:28.693843 ops/training.py:65 2019-01-16 23:54:28.693754: step 696, loss = 0.71352 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-16 23:54:29.975680 ops/training.py:65 2019-01-16 23:54:29.975587: step 697, loss = 0.79942 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:54:31.255992 ops/training.py:65 2019-01-16 23:54:31.255898: step 698, loss = 0.73449 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:54:32.537361 ops/training.py:65 2019-01-16 23:54:32.537269: step 699, loss = 0.75811 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:54:33.817556 ops/training.py:65 2019-01-16 23:54:33.817472: step 700, loss = 0.74424 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:54:35.098218 ops/training.py:65 2019-01-16 23:54:35.098120: step 701, loss = 0.68721 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:54:36.378918 ops/training.py:65 2019-01-16 23:54:36.378829: step 702, loss = 0.75336 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:54:37.659933 ops/training.py:65 2019-01-16 23:54:37.659837: step 703, loss = 0.75763 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:54:38.941215 ops/training.py:65 2019-01-16 23:54:38.941121: step 704, loss = 0.77842 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-16 23:54:40.222996 ops/training.py:65 2019-01-16 23:54:40.222894: step 705, loss = 0.70041 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:54:41.504243 ops/training.py:65 2019-01-16 23:54:41.504151: step 706, loss = 0.67088 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:54:42.784661 ops/training.py:65 2019-01-16 23:54:42.784575: step 707, loss = 0.73444 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:54:44.065418 ops/training.py:65 2019-01-16 23:54:44.065325: step 708, loss = 0.71879 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:54:45.346205 ops/training.py:65 2019-01-16 23:54:45.346109: step 709, loss = 0.89545 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-16 23:54:46.627002 ops/training.py:65 2019-01-16 23:54:46.626908: step 710, loss = 0.75636 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:54:47.910623 ops/training.py:65 2019-01-16 23:54:47.910522: step 711, loss = 0.74176 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:54:49.192296 ops/training.py:65 2019-01-16 23:54:49.192200: step 712, loss = 0.74940 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:54:50.473618 ops/training.py:65 2019-01-16 23:54:50.473518: step 713, loss = 0.65331 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:54:51.754936 ops/training.py:65 2019-01-16 23:54:51.754832: step 714, loss = 0.69098 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:54:53.035579 ops/training.py:65 2019-01-16 23:54:53.035467: step 715, loss = 0.71708 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:54:54.315578 ops/training.py:65 2019-01-16 23:54:54.315476: step 716, loss = 0.69525 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:54:55.597304 ops/training.py:65 2019-01-16 23:54:55.597199: step 717, loss = 0.73018 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:54:56.876677 ops/training.py:65 2019-01-16 23:54:56.876572: step 718, loss = 0.82527 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:54:58.157632 ops/training.py:65 2019-01-16 23:54:58.157535: step 719, loss = 0.67432 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:54:59.438779 ops/training.py:65 2019-01-16 23:54:59.438673: step 720, loss = 0.76227 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:55:00.719365 ops/training.py:65 2019-01-16 23:55:00.719268: step 721, loss = 0.74357 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:55:02.001368 ops/training.py:65 2019-01-16 23:55:02.001272: step 722, loss = 0.71242 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:55:03.282650 ops/training.py:65 2019-01-16 23:55:03.282554: step 723, loss = 0.74570 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:55:04.564465 ops/training.py:65 2019-01-16 23:55:04.564360: step 724, loss = 0.75179 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:55:05.845251 ops/training.py:65 2019-01-16 23:55:05.845150: step 725, loss = 0.67816 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:55:07.126834 ops/training.py:65 2019-01-16 23:55:07.126724: step 726, loss = 0.79189 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:55:08.407539 ops/training.py:65 2019-01-16 23:55:08.407443: step 727, loss = 0.78960 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:55:09.688654 ops/training.py:65 2019-01-16 23:55:09.688558: step 728, loss = 0.81032 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:55:10.968682 ops/training.py:65 2019-01-16 23:55:10.968591: step 729, loss = 0.78042 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:55:12.249701 ops/training.py:65 2019-01-16 23:55:12.249665: step 730, loss = 0.73517 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:55:13.530088 ops/training.py:65 2019-01-16 23:55:13.530054: step 731, loss = 0.69068 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:55:14.812382 ops/training.py:65 2019-01-16 23:55:14.812352: step 732, loss = 0.75428 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:55:16.091894 ops/training.py:65 2019-01-16 23:55:16.091863: step 733, loss = 0.67962 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:55:17.371796 ops/training.py:65 2019-01-16 23:55:17.371766: step 734, loss = 0.72172 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:55:18.651759 ops/training.py:65 2019-01-16 23:55:18.651728: step 735, loss = 0.71754 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:55:19.938826 ops/training.py:65 2019-01-16 23:55:19.938792: step 736, loss = 0.84867 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:55:21.220591 ops/training.py:65 2019-01-16 23:55:21.220562: step 737, loss = 0.68338 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:55:22.501329 ops/training.py:65 2019-01-16 23:55:22.501299: step 738, loss = 0.66664 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:55:23.780588 ops/training.py:65 2019-01-16 23:55:23.780556: step 739, loss = 0.74094 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:55:25.060529 ops/training.py:65 2019-01-16 23:55:25.060500: step 740, loss = 0.69835 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:55:26.341678 ops/training.py:65 2019-01-16 23:55:26.341651: step 741, loss = 0.69358 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:55:27.622780 ops/training.py:65 2019-01-16 23:55:27.622749: step 742, loss = 0.83783 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-16 23:55:28.903936 ops/training.py:65 2019-01-16 23:55:28.903902: step 743, loss = 0.70336 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:55:30.184906 ops/training.py:65 2019-01-16 23:55:30.184876: step 744, loss = 0.73210 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:55:31.466714 ops/training.py:65 2019-01-16 23:55:31.466653: step 745, loss = 0.64835 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:55:32.748224 ops/training.py:65 2019-01-16 23:55:32.748166: step 746, loss = 0.79034 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:55:34.028416 ops/training.py:65 2019-01-16 23:55:34.028381: step 747, loss = 0.70653 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:55:35.309030 ops/training.py:65 2019-01-16 23:55:35.308998: step 748, loss = 0.63668 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:55:36.589825 ops/training.py:65 2019-01-16 23:55:36.589721: step 749, loss = 0.64876 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:55:37.876525 ops/training.py:65 2019-01-16 23:55:37.876419: step 750, loss = 0.68609 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:55:39.161377 ops/training.py:65 2019-01-16 23:55:39.161286: step 751, loss = 0.74471 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:55:40.446985 ops/training.py:65 2019-01-16 23:55:40.446878: step 752, loss = 0.73268 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:55:41.727234 ops/training.py:65 2019-01-16 23:55:41.727135: step 753, loss = 0.71297 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:55:43.008118 ops/training.py:65 2019-01-16 23:55:43.008038: step 754, loss = 0.72028 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:55:44.291802 ops/training.py:65 2019-01-16 23:55:44.291690: step 755, loss = 0.72407 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:55:45.576880 ops/training.py:65 2019-01-16 23:55:45.576775: step 756, loss = 0.71961 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:55:46.862972 ops/training.py:65 2019-01-16 23:55:46.862869: step 757, loss = 0.76337 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:55:48.150342 ops/training.py:65 2019-01-16 23:55:48.150244: step 758, loss = 0.69367 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:55:49.435687 ops/training.py:65 2019-01-16 23:55:49.435579: step 759, loss = 0.76702 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:55:50.722502 ops/training.py:65 2019-01-16 23:55:50.722393: step 760, loss = 0.69019 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:55:52.007027 ops/training.py:65 2019-01-16 23:55:52.006929: step 761, loss = 0.61686 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-16 23:55:53.298074 ops/training.py:65 2019-01-16 23:55:53.298000: step 762, loss = 0.68801 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:55:54.578411 ops/training.py:65 2019-01-16 23:55:54.578330: step 763, loss = 0.77712 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:55:55.860867 ops/training.py:65 2019-01-16 23:55:55.860749: step 764, loss = 0.78599 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:55:57.142417 ops/training.py:65 2019-01-16 23:55:57.142355: step 765, loss = 0.74336 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:55:58.426182 ops/training.py:65 2019-01-16 23:55:58.426113: step 766, loss = 0.68360 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:55:59.712747 ops/training.py:65 2019-01-16 23:55:59.712633: step 767, loss = 0.65193 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:56:01.000305 ops/training.py:65 2019-01-16 23:56:01.000205: step 768, loss = 0.79647 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:56:02.284650 ops/training.py:65 2019-01-16 23:56:02.284519: step 769, loss = 0.76044 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:56:03.570091 ops/training.py:65 2019-01-16 23:56:03.569994: step 770, loss = 0.66553 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:56:04.860759 ops/training.py:65 2019-01-16 23:56:04.860658: step 771, loss = 0.66633 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:56:06.140410 ops/training.py:65 2019-01-16 23:56:06.140305: step 772, loss = 0.65251 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:56:07.422907 ops/training.py:65 2019-01-16 23:56:07.422801: step 773, loss = 0.78250 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:56:08.703017 ops/training.py:65 2019-01-16 23:56:08.702901: step 774, loss = 0.75508 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:56:09.983408 ops/training.py:65 2019-01-16 23:56:09.983304: step 775, loss = 0.74178 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:56:11.263570 ops/training.py:65 2019-01-16 23:56:11.263464: step 776, loss = 0.68619 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:56:12.543934 ops/training.py:65 2019-01-16 23:56:12.543841: step 777, loss = 0.69640 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:56:13.825452 ops/training.py:65 2019-01-16 23:56:13.825353: step 778, loss = 0.82490 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-16 23:56:15.109358 ops/training.py:65 2019-01-16 23:56:15.109246: step 779, loss = 0.70068 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:56:16.394875 ops/training.py:65 2019-01-16 23:56:16.394769: step 780, loss = 0.73282 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:56:17.676246 ops/training.py:65 2019-01-16 23:56:17.676144: step 781, loss = 0.76254 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:56:18.960813 ops/training.py:65 2019-01-16 23:56:18.960709: step 782, loss = 0.72798 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:56:20.241573 ops/training.py:65 2019-01-16 23:56:20.241470: step 783, loss = 0.73498 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:56:21.528861 ops/training.py:65 2019-01-16 23:56:21.528758: step 784, loss = 0.72320 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:56:22.811586 ops/training.py:65 2019-01-16 23:56:22.811488: step 785, loss = 0.73451 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:56:24.092872 ops/training.py:65 2019-01-16 23:56:24.092778: step 786, loss = 0.69430 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:56:25.372919 ops/training.py:65 2019-01-16 23:56:25.372816: step 787, loss = 0.79915 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:56:26.655096 ops/training.py:65 2019-01-16 23:56:26.654993: step 788, loss = 0.71985 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:56:27.936480 ops/training.py:65 2019-01-16 23:56:27.936391: step 789, loss = 0.69570 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:56:29.222261 ops/training.py:65 2019-01-16 23:56:29.222134: step 790, loss = 0.78090 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:56:30.508730 ops/training.py:65 2019-01-16 23:56:30.508610: step 791, loss = 0.70765 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:56:31.799283 ops/training.py:65 2019-01-16 23:56:31.799158: step 792, loss = 0.72727 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:56:33.083176 ops/training.py:65 2019-01-16 23:56:33.083068: step 793, loss = 0.73961 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:56:34.361759 ops/training.py:65 2019-01-16 23:56:34.361657: step 794, loss = 0.66700 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:56:35.646175 ops/training.py:65 2019-01-16 23:56:35.646090: step 795, loss = 0.65156 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:56:36.926930 ops/training.py:65 2019-01-16 23:56:36.926828: step 796, loss = 0.67718 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:56:38.210168 ops/training.py:65 2019-01-16 23:56:38.210064: step 797, loss = 0.69787 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:56:39.494739 ops/training.py:65 2019-01-16 23:56:39.494637: step 798, loss = 0.78376 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:56:40.780319 ops/training.py:65 2019-01-16 23:56:40.780217: step 799, loss = 0.77612 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:56:42.065784 ops/training.py:65 2019-01-16 23:56:42.065668: step 800, loss = 0.75849 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:56:43.349839 ops/training.py:65 2019-01-16 23:56:43.349709: step 801, loss = 0.71018 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:56:44.641694 ops/training.py:65 2019-01-16 23:56:44.641595: step 802, loss = 0.75946 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:56:45.926552 ops/training.py:65 2019-01-16 23:56:45.926424: step 803, loss = 0.74762 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:56:47.213781 ops/training.py:65 2019-01-16 23:56:47.213606: step 804, loss = 0.83951 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:56:48.501803 ops/training.py:65 2019-01-16 23:56:48.501701: step 805, loss = 0.74915 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:56:49.783041 ops/training.py:65 2019-01-16 23:56:49.782938: step 806, loss = 0.75249 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:56:51.067328 ops/training.py:65 2019-01-16 23:56:51.067220: step 807, loss = 0.66916 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:56:52.351739 ops/training.py:65 2019-01-16 23:56:52.351655: step 808, loss = 0.70320 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:56:53.637569 ops/training.py:65 2019-01-16 23:56:53.637464: step 809, loss = 0.70126 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:56:54.925094 ops/training.py:65 2019-01-16 23:56:54.924998: step 810, loss = 0.79984 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:56:56.210177 ops/training.py:65 2019-01-16 23:56:56.210079: step 811, loss = 0.71058 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:56:57.498847 ops/training.py:65 2019-01-16 23:56:57.498739: step 812, loss = 0.66663 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:56:58.784134 ops/training.py:65 2019-01-16 23:56:58.784009: step 813, loss = 0.61416 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:57:00.066843 ops/training.py:65 2019-01-16 23:57:00.066691: step 814, loss = 0.69279 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:57:01.352512 ops/training.py:65 2019-01-16 23:57:01.352402: step 815, loss = 0.74478 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:57:02.631893 ops/training.py:65 2019-01-16 23:57:02.631801: step 816, loss = 0.67883 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:57:03.917410 ops/training.py:65 2019-01-16 23:57:03.917315: step 817, loss = 0.70058 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:57:05.201416 ops/training.py:65 2019-01-16 23:57:05.201310: step 818, loss = 0.75941 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:57:06.482946 ops/training.py:65 2019-01-16 23:57:06.482838: step 819, loss = 0.74445 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:57:07.765962 ops/training.py:65 2019-01-16 23:57:07.765878: step 820, loss = 0.71991 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:57:09.053180 ops/training.py:65 2019-01-16 23:57:09.053079: step 821, loss = 0.77203 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:57:10.338633 ops/training.py:65 2019-01-16 23:57:10.338527: step 822, loss = 0.80563 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:57:11.616705 ops/training.py:65 2019-01-16 23:57:11.616592: step 823, loss = 0.63396 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-16 23:57:12.898063 ops/training.py:65 2019-01-16 23:57:12.897937: step 824, loss = 0.70244 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:57:14.181221 ops/training.py:65 2019-01-16 23:57:14.181115: step 825, loss = 0.73536 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:57:15.469504 ops/training.py:65 2019-01-16 23:57:15.469401: step 826, loss = 0.70359 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:57:16.755810 ops/training.py:65 2019-01-16 23:57:16.755723: step 827, loss = 0.75765 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:57:18.039795 ops/training.py:65 2019-01-16 23:57:18.039692: step 828, loss = 0.71569 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:57:19.327340 ops/training.py:65 2019-01-16 23:57:19.327194: step 829, loss = 0.71253 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:57:20.615414 ops/training.py:65 2019-01-16 23:57:20.615263: step 830, loss = 0.75377 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:57:21.894251 ops/training.py:65 2019-01-16 23:57:21.894138: step 831, loss = 0.73177 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:57:23.178157 ops/training.py:65 2019-01-16 23:57:23.178060: step 832, loss = 0.72365 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:57:24.466137 ops/training.py:65 2019-01-16 23:57:24.466028: step 833, loss = 0.80234 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.25
I4672 2019-01-16 23:57:25.750215 ops/training.py:65 2019-01-16 23:57:25.750085: step 834, loss = 0.77718 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:57:27.034511 ops/training.py:65 2019-01-16 23:57:27.034408: step 835, loss = 0.68413 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:57:28.313343 ops/training.py:65 2019-01-16 23:57:28.313241: step 836, loss = 0.71825 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:57:29.597357 ops/training.py:65 2019-01-16 23:57:29.597267: step 837, loss = 0.74825 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:57:30.883519 ops/training.py:65 2019-01-16 23:57:30.883416: step 838, loss = 0.70379 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:57:32.166341 ops/training.py:65 2019-01-16 23:57:32.166170: step 839, loss = 0.68636 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:57:33.449926 ops/training.py:65 2019-01-16 23:57:33.449827: step 840, loss = 0.78330 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:57:34.740967 ops/training.py:65 2019-01-16 23:57:34.740877: step 841, loss = 0.71057 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:57:36.023217 ops/training.py:65 2019-01-16 23:57:36.023104: step 842, loss = 0.74664 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:57:37.309370 ops/training.py:65 2019-01-16 23:57:37.309264: step 843, loss = 0.68565 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:57:38.591493 ops/training.py:65 2019-01-16 23:57:38.591385: step 844, loss = 0.68934 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:57:39.873225 ops/training.py:65 2019-01-16 23:57:39.873119: step 845, loss = 0.67913 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:57:41.152993 ops/training.py:65 2019-01-16 23:57:41.152887: step 846, loss = 0.82490 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:57:42.433827 ops/training.py:65 2019-01-16 23:57:42.433715: step 847, loss = 0.78591 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-16 23:57:43.714369 ops/training.py:65 2019-01-16 23:57:43.714263: step 848, loss = 0.80930 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:57:44.994566 ops/training.py:65 2019-01-16 23:57:44.994455: step 849, loss = 0.75349 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:57:46.280184 ops/training.py:65 2019-01-16 23:57:46.280076: step 850, loss = 0.74551 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:57:47.560867 ops/training.py:65 2019-01-16 23:57:47.560766: step 851, loss = 0.63000 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:57:48.842529 ops/training.py:65 2019-01-16 23:57:48.842424: step 852, loss = 0.78163 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:57:50.131428 ops/training.py:65 2019-01-16 23:57:50.131309: step 853, loss = 0.71782 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:57:51.417638 ops/training.py:65 2019-01-16 23:57:51.417515: step 854, loss = 0.66204 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:57:52.703433 ops/training.py:65 2019-01-16 23:57:52.703330: step 855, loss = 0.73173 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:57:53.987918 ops/training.py:65 2019-01-16 23:57:53.987823: step 856, loss = 0.75879 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:57:55.274873 ops/training.py:65 2019-01-16 23:57:55.274767: step 857, loss = 0.72677 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:57:56.557508 ops/training.py:65 2019-01-16 23:57:56.557411: step 858, loss = 0.69804 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:57:57.837756 ops/training.py:65 2019-01-16 23:57:57.837649: step 859, loss = 0.75098 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:57:59.118113 ops/training.py:65 2019-01-16 23:57:59.117987: step 860, loss = 0.68358 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:58:00.399873 ops/training.py:65 2019-01-16 23:58:00.399755: step 861, loss = 0.73206 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:58:01.682761 ops/training.py:65 2019-01-16 23:58:01.682654: step 862, loss = 0.72071 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:58:02.969769 ops/training.py:65 2019-01-16 23:58:02.969674: step 863, loss = 0.80936 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.25
I4672 2019-01-16 23:58:04.260184 ops/training.py:65 2019-01-16 23:58:04.260032: step 864, loss = 0.72645 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:58:05.549986 ops/training.py:65 2019-01-16 23:58:05.549870: step 865, loss = 0.76901 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:58:06.835933 ops/training.py:65 2019-01-16 23:58:06.835832: step 866, loss = 0.68252 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:58:08.121099 ops/training.py:65 2019-01-16 23:58:08.120991: step 867, loss = 0.79450 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-16 23:58:09.406833 ops/training.py:65 2019-01-16 23:58:09.406676: step 868, loss = 0.68849 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:58:10.701315 ops/training.py:65 2019-01-16 23:58:10.701202: step 869, loss = 0.69745 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:58:11.983749 ops/training.py:65 2019-01-16 23:58:11.983649: step 870, loss = 0.63892 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:58:13.267938 ops/training.py:65 2019-01-16 23:58:13.267838: step 871, loss = 0.64949 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:58:14.553434 ops/training.py:65 2019-01-16 23:58:14.553328: step 872, loss = 0.76129 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:58:15.842867 ops/training.py:65 2019-01-16 23:58:15.842759: step 873, loss = 0.74616 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:58:17.127758 ops/training.py:65 2019-01-16 23:58:17.127723: step 874, loss = 0.57624 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-16 23:58:18.410146 ops/training.py:65 2019-01-16 23:58:18.410114: step 875, loss = 0.66070 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:58:19.696239 ops/training.py:65 2019-01-16 23:58:19.696184: step 876, loss = 0.74983 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:58:20.980650 ops/training.py:65 2019-01-16 23:58:20.980553: step 877, loss = 0.72397 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:58:22.265060 ops/training.py:65 2019-01-16 23:58:22.264958: step 878, loss = 0.73708 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:58:23.546577 ops/training.py:65 2019-01-16 23:58:23.546516: step 879, loss = 0.66823 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:58:24.825062 ops/training.py:65 2019-01-16 23:58:24.825005: step 880, loss = 0.74360 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:58:26.109789 ops/training.py:65 2019-01-16 23:58:26.109702: step 881, loss = 0.69014 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:58:27.390981 ops/training.py:65 2019-01-16 23:58:27.390899: step 882, loss = 0.73235 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:58:28.672369 ops/training.py:65 2019-01-16 23:58:28.672304: step 883, loss = 0.71690 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:58:29.957442 ops/training.py:65 2019-01-16 23:58:29.957350: step 884, loss = 0.70851 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:58:31.238840 ops/training.py:65 2019-01-16 23:58:31.238733: step 885, loss = 0.78356 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-16 23:58:32.531513 ops/training.py:65 2019-01-16 23:58:32.531402: step 886, loss = 0.71681 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:58:33.819624 ops/training.py:65 2019-01-16 23:58:33.819527: step 887, loss = 0.69093 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-16 23:58:35.105836 ops/training.py:65 2019-01-16 23:58:35.105727: step 888, loss = 0.76648 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:58:36.391443 ops/training.py:65 2019-01-16 23:58:36.391334: step 889, loss = 0.77860 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:58:37.674148 ops/training.py:65 2019-01-16 23:58:37.674070: step 890, loss = 0.76022 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:58:38.962413 ops/training.py:65 2019-01-16 23:58:38.962258: step 891, loss = 0.63926 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:58:40.247174 ops/training.py:65 2019-01-16 23:58:40.247069: step 892, loss = 0.80130 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:58:41.532231 ops/training.py:65 2019-01-16 23:58:41.532071: step 893, loss = 0.76355 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:58:42.821692 ops/training.py:65 2019-01-16 23:58:42.821575: step 894, loss = 0.71361 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:58:44.107908 ops/training.py:65 2019-01-16 23:58:44.107801: step 895, loss = 0.72074 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:58:45.395690 ops/training.py:65 2019-01-16 23:58:45.395577: step 896, loss = 0.70685 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:58:46.684291 ops/training.py:65 2019-01-16 23:58:46.684186: step 897, loss = 0.64612 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:58:47.972883 ops/training.py:65 2019-01-16 23:58:47.972779: step 898, loss = 0.72805 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:58:49.254955 ops/training.py:65 2019-01-16 23:58:49.254872: step 899, loss = 0.77995 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:58:50.542496 ops/training.py:65 2019-01-16 23:58:50.542387: step 900, loss = 0.72584 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:58:51.828713 ops/training.py:65 2019-01-16 23:58:51.828635: step 901, loss = 0.73391 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:58:53.113965 ops/training.py:65 2019-01-16 23:58:53.113862: step 902, loss = 0.66141 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:58:54.403099 ops/training.py:65 2019-01-16 23:58:54.402994: step 903, loss = 0.68569 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:58:55.685623 ops/training.py:65 2019-01-16 23:58:55.685515: step 904, loss = 0.71092 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:58:56.970785 ops/training.py:65 2019-01-16 23:58:56.970677: step 905, loss = 0.62724 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-16 23:58:58.251116 ops/training.py:65 2019-01-16 23:58:58.251007: step 906, loss = 0.71288 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:58:59.536177 ops/training.py:65 2019-01-16 23:58:59.536073: step 907, loss = 0.75938 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:59:00.817753 ops/training.py:65 2019-01-16 23:59:00.817646: step 908, loss = 0.68964 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:59:02.101389 ops/training.py:65 2019-01-16 23:59:02.101281: step 909, loss = 0.68463 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:59:03.386719 ops/training.py:65 2019-01-16 23:59:03.386621: step 910, loss = 0.74734 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:59:04.675688 ops/training.py:65 2019-01-16 23:59:04.675533: step 911, loss = 0.80560 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-16 23:59:05.963577 ops/training.py:65 2019-01-16 23:59:05.963475: step 912, loss = 0.66006 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:59:07.248776 ops/training.py:65 2019-01-16 23:59:07.248671: step 913, loss = 0.73731 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:59:08.536428 ops/training.py:65 2019-01-16 23:59:08.536320: step 914, loss = 0.73670 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:59:09.818709 ops/training.py:65 2019-01-16 23:59:09.818607: step 915, loss = 0.72841 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:59:11.105893 ops/training.py:65 2019-01-16 23:59:11.105727: step 916, loss = 0.75514 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-16 23:59:12.393093 ops/training.py:65 2019-01-16 23:59:12.392980: step 917, loss = 0.73902 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:59:13.682331 ops/training.py:65 2019-01-16 23:59:13.682227: step 918, loss = 0.75698 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:59:14.967055 ops/training.py:65 2019-01-16 23:59:14.966991: step 919, loss = 0.68278 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:59:16.251659 ops/training.py:65 2019-01-16 23:59:16.251551: step 920, loss = 0.73136 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:59:17.538354 ops/training.py:65 2019-01-16 23:59:17.538254: step 921, loss = 0.70655 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:59:18.825113 ops/training.py:65 2019-01-16 23:59:18.825015: step 922, loss = 0.76875 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:59:20.111379 ops/training.py:65 2019-01-16 23:59:20.111272: step 923, loss = 0.66912 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-16 23:59:21.398546 ops/training.py:65 2019-01-16 23:59:21.398436: step 924, loss = 0.71129 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:59:22.684353 ops/training.py:65 2019-01-16 23:59:22.684245: step 925, loss = 0.67209 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:59:23.972849 ops/training.py:65 2019-01-16 23:59:23.972742: step 926, loss = 0.72017 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:59:25.257137 ops/training.py:65 2019-01-16 23:59:25.257031: step 927, loss = 0.75968 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:59:26.542949 ops/training.py:65 2019-01-16 23:59:26.542840: step 928, loss = 0.69546 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:59:27.829945 ops/training.py:65 2019-01-16 23:59:27.829837: step 929, loss = 0.66195 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:59:29.116328 ops/training.py:65 2019-01-16 23:59:29.116224: step 930, loss = 0.77967 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:59:30.399065 ops/training.py:65 2019-01-16 23:59:30.398961: step 931, loss = 0.70254 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:59:31.689051 ops/training.py:65 2019-01-16 23:59:31.688887: step 932, loss = 0.67936 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:59:32.979829 ops/training.py:65 2019-01-16 23:59:32.979673: step 933, loss = 0.66481 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:59:34.264700 ops/training.py:65 2019-01-16 23:59:34.264629: step 934, loss = 0.76020 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:59:35.549451 ops/training.py:65 2019-01-16 23:59:35.549384: step 935, loss = 0.73011 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:59:36.837908 ops/training.py:65 2019-01-16 23:59:36.837800: step 936, loss = 0.70987 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:59:38.120820 ops/training.py:65 2019-01-16 23:59:38.120706: step 937, loss = 0.71332 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:59:39.405249 ops/training.py:65 2019-01-16 23:59:39.405141: step 938, loss = 0.71161 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:59:40.691649 ops/training.py:65 2019-01-16 23:59:40.691550: step 939, loss = 0.77199 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:59:41.979074 ops/training.py:65 2019-01-16 23:59:41.978962: step 940, loss = 0.76146 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-16 23:59:43.268573 ops/training.py:65 2019-01-16 23:59:43.268467: step 941, loss = 0.72676 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:59:44.554571 ops/training.py:65 2019-01-16 23:59:44.554503: step 942, loss = 0.67237 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:59:45.844077 ops/training.py:65 2019-01-16 23:59:45.843974: step 943, loss = 0.71121 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:59:47.135392 ops/training.py:65 2019-01-16 23:59:47.135279: step 944, loss = 0.68265 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:59:48.421303 ops/training.py:65 2019-01-16 23:59:48.421239: step 945, loss = 0.67183 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:59:49.701467 ops/training.py:65 2019-01-16 23:59:49.701356: step 946, loss = 0.66251 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-16 23:59:50.988032 ops/training.py:65 2019-01-16 23:59:50.987917: step 947, loss = 0.68581 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-16 23:59:52.275183 ops/training.py:65 2019-01-16 23:59:52.275073: step 948, loss = 0.71433 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:59:53.561095 ops/training.py:65 2019-01-16 23:59:53.560995: step 949, loss = 0.72355 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-16 23:59:54.852421 ops/training.py:65 2019-01-16 23:59:54.852321: step 950, loss = 0.68929 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-16 23:59:56.139017 ops/training.py:65 2019-01-16 23:59:56.138907: step 951, loss = 0.68867 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-16 23:59:57.422389 ops/training.py:65 2019-01-16 23:59:57.422320: step 952, loss = 0.80939 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-16 23:59:58.706804 ops/training.py:65 2019-01-16 23:59:58.706700: step 953, loss = 0.69027 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-16 23:59:59.994471 ops/training.py:65 2019-01-16 23:59:59.994362: step 954, loss = 0.72197 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:00:01.277446 ops/training.py:65 2019-01-17 00:00:01.277338: step 955, loss = 0.74244 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:00:02.562378 ops/training.py:65 2019-01-17 00:00:02.562285: step 956, loss = 0.71010 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:00:03.854807 ops/training.py:65 2019-01-17 00:00:03.854707: step 957, loss = 0.71293 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:00:05.142747 ops/training.py:65 2019-01-17 00:00:05.142682: step 958, loss = 0.68574 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:00:06.429786 ops/training.py:65 2019-01-17 00:00:06.429683: step 959, loss = 0.70817 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:00:07.722178 ops/training.py:65 2019-01-17 00:00:07.722070: step 960, loss = 0.68801 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:00:09.014593 ops/training.py:65 2019-01-17 00:00:09.014432: step 961, loss = 0.67905 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:00:10.305506 ops/training.py:65 2019-01-17 00:00:10.305440: step 962, loss = 0.71031 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:00:11.593908 ops/training.py:65 2019-01-17 00:00:11.593830: step 963, loss = 0.74443 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:00:12.877672 ops/training.py:65 2019-01-17 00:00:12.877614: step 964, loss = 0.70835 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:00:14.159317 ops/training.py:65 2019-01-17 00:00:14.159214: step 965, loss = 0.76483 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:00:15.442225 ops/training.py:65 2019-01-17 00:00:15.442117: step 966, loss = 0.71137 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:00:16.728132 ops/training.py:65 2019-01-17 00:00:16.728025: step 967, loss = 0.69254 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:00:18.015409 ops/training.py:65 2019-01-17 00:00:18.015293: step 968, loss = 0.68151 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:00:19.302939 ops/training.py:65 2019-01-17 00:00:19.302836: step 969, loss = 0.70763 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:00:20.594721 ops/training.py:65 2019-01-17 00:00:20.594609: step 970, loss = 0.69221 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:00:21.881730 ops/training.py:65 2019-01-17 00:00:21.881626: step 971, loss = 0.73586 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:00:23.163445 ops/training.py:65 2019-01-17 00:00:23.163340: step 972, loss = 0.68579 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:00:24.447280 ops/training.py:65 2019-01-17 00:00:24.447177: step 973, loss = 0.68553 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:00:25.734856 ops/training.py:65 2019-01-17 00:00:25.734746: step 974, loss = 0.66700 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:00:27.018756 ops/training.py:65 2019-01-17 00:00:27.018669: step 975, loss = 0.64438 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:00:28.302033 ops/training.py:65 2019-01-17 00:00:28.301949: step 976, loss = 0.75440 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:00:29.586004 ops/training.py:65 2019-01-17 00:00:29.585903: step 977, loss = 0.69949 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:00:30.871875 ops/training.py:65 2019-01-17 00:00:30.871765: step 978, loss = 0.68934 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:00:32.159835 ops/training.py:65 2019-01-17 00:00:32.159731: step 979, loss = 0.78251 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:00:33.442272 ops/training.py:65 2019-01-17 00:00:33.442174: step 980, loss = 0.73189 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:00:34.728634 ops/training.py:65 2019-01-17 00:00:34.728533: step 981, loss = 0.73716 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:00:36.015796 ops/training.py:65 2019-01-17 00:00:36.015687: step 982, loss = 0.74836 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:00:37.303174 ops/training.py:65 2019-01-17 00:00:37.303065: step 983, loss = 0.68816 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:00:38.596370 ops/training.py:65 2019-01-17 00:00:38.596268: step 984, loss = 0.73220 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:00:39.882428 ops/training.py:65 2019-01-17 00:00:39.882366: step 985, loss = 0.68391 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:00:41.164518 ops/training.py:65 2019-01-17 00:00:41.164420: step 986, loss = 0.68937 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:00:42.451643 ops/training.py:65 2019-01-17 00:00:42.451539: step 987, loss = 0.74379 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:00:43.734122 ops/training.py:65 2019-01-17 00:00:43.734015: step 988, loss = 0.67922 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:00:45.015474 ops/training.py:65 2019-01-17 00:00:45.015364: step 989, loss = 0.67252 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:00:46.296338 ops/training.py:65 2019-01-17 00:00:46.296229: step 990, loss = 0.77244 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:00:47.579200 ops/training.py:65 2019-01-17 00:00:47.579110: step 991, loss = 0.68003 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:00:48.863386 ops/training.py:65 2019-01-17 00:00:48.863289: step 992, loss = 0.74327 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:00:50.151576 ops/training.py:65 2019-01-17 00:00:50.151476: step 993, loss = 0.69538 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:00:51.442662 ops/training.py:65 2019-01-17 00:00:51.442521: step 994, loss = 0.75030 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:00:52.728480 ops/training.py:65 2019-01-17 00:00:52.728342: step 995, loss = 0.72034 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:00:54.011110 ops/training.py:65 2019-01-17 00:00:54.010952: step 996, loss = 0.73694 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:00:55.296807 ops/training.py:65 2019-01-17 00:00:55.296696: step 997, loss = 0.67751 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:00:56.584144 ops/training.py:65 2019-01-17 00:00:56.584038: step 998, loss = 0.73643 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:00:57.870269 ops/training.py:65 2019-01-17 00:00:57.870166: step 999, loss = 0.73126 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:00:59.160792 ops/training.py:65 2019-01-17 00:00:59.160685: step 1000, loss = 0.67606 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:01:00.451198 ops/training.py:65 2019-01-17 00:01:00.451089: step 1001, loss = 0.75933 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:01:01.737027 ops/training.py:65 2019-01-17 00:01:01.736964: step 1002, loss = 0.73959 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:01:03.024400 ops/training.py:65 2019-01-17 00:01:03.024321: step 1003, loss = 0.69538 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:01:04.309824 ops/training.py:65 2019-01-17 00:01:04.309734: step 1004, loss = 0.71927 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:01:05.595460 ops/training.py:65 2019-01-17 00:01:05.595356: step 1005, loss = 0.72305 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:01:06.881860 ops/training.py:65 2019-01-17 00:01:06.881700: step 1006, loss = 0.69400 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:01:08.167180 ops/training.py:65 2019-01-17 00:01:08.167080: step 1007, loss = 0.67338 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:01:09.457370 ops/training.py:65 2019-01-17 00:01:09.457262: step 1008, loss = 0.72603 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:01:10.743948 ops/training.py:65 2019-01-17 00:01:10.743835: step 1009, loss = 0.64751 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:01:12.030545 ops/training.py:65 2019-01-17 00:01:12.030434: step 1010, loss = 0.69538 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:01:13.314644 ops/training.py:65 2019-01-17 00:01:13.314536: step 1011, loss = 0.78224 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:01:14.602313 ops/training.py:65 2019-01-17 00:01:14.602203: step 1012, loss = 0.74670 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:01:15.888678 ops/training.py:65 2019-01-17 00:01:15.888571: step 1013, loss = 0.69672 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:01:17.176344 ops/training.py:65 2019-01-17 00:01:17.176230: step 1014, loss = 0.78303 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-17 00:01:18.457601 ops/training.py:65 2019-01-17 00:01:18.457494: step 1015, loss = 0.71250 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:01:19.739068 ops/training.py:65 2019-01-17 00:01:19.738966: step 1016, loss = 0.77559 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:01:21.021736 ops/training.py:65 2019-01-17 00:01:21.021624: step 1017, loss = 0.72130 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:01:22.306966 ops/training.py:65 2019-01-17 00:01:22.306851: step 1018, loss = 0.75234 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:01:23.594712 ops/training.py:65 2019-01-17 00:01:23.594604: step 1019, loss = 0.62892 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 00:01:24.882011 ops/training.py:65 2019-01-17 00:01:24.881905: step 1020, loss = 0.68594 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:01:26.166465 ops/training.py:65 2019-01-17 00:01:26.166354: step 1021, loss = 0.71861 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:01:27.458486 ops/training.py:65 2019-01-17 00:01:27.458389: step 1022, loss = 0.70860 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:01:28.742100 ops/training.py:65 2019-01-17 00:01:28.742013: step 1023, loss = 0.71429 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:01:30.033582 ops/training.py:65 2019-01-17 00:01:30.033474: step 1024, loss = 0.65429 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:01:31.327122 ops/training.py:65 2019-01-17 00:01:31.327011: step 1025, loss = 0.71761 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:01:32.612776 ops/training.py:65 2019-01-17 00:01:32.612669: step 1026, loss = 0.80239 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:01:33.904684 ops/training.py:65 2019-01-17 00:01:33.904582: step 1027, loss = 0.69906 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:01:35.191617 ops/training.py:65 2019-01-17 00:01:35.191461: step 1028, loss = 0.72614 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:01:36.479444 ops/training.py:65 2019-01-17 00:01:36.479286: step 1029, loss = 0.82302 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:01:37.765368 ops/training.py:65 2019-01-17 00:01:37.765260: step 1030, loss = 0.70585 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:01:39.051281 ops/training.py:65 2019-01-17 00:01:39.051176: step 1031, loss = 0.61682 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:01:40.340999 ops/training.py:65 2019-01-17 00:01:40.340897: step 1032, loss = 0.65962 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:01:41.626763 ops/training.py:65 2019-01-17 00:01:41.626663: step 1033, loss = 0.72573 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:01:42.915771 ops/training.py:65 2019-01-17 00:01:42.915663: step 1034, loss = 0.72738 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:01:44.201206 ops/training.py:65 2019-01-17 00:01:44.201100: step 1035, loss = 0.70530 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:01:45.486785 ops/training.py:65 2019-01-17 00:01:45.486676: step 1036, loss = 0.66021 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:01:46.776776 ops/training.py:65 2019-01-17 00:01:46.776669: step 1037, loss = 0.63921 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:01:48.066657 ops/training.py:65 2019-01-17 00:01:48.066496: step 1038, loss = 0.69478 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:01:49.352281 ops/training.py:65 2019-01-17 00:01:49.352220: step 1039, loss = 0.72098 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:01:50.638708 ops/training.py:65 2019-01-17 00:01:50.638603: step 1040, loss = 0.68154 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:01:51.930934 ops/training.py:65 2019-01-17 00:01:51.930821: step 1041, loss = 0.80066 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:01:53.221693 ops/training.py:65 2019-01-17 00:01:53.221607: step 1042, loss = 0.76832 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:01:54.506555 ops/training.py:65 2019-01-17 00:01:54.506472: step 1043, loss = 0.73411 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:01:55.798156 ops/training.py:65 2019-01-17 00:01:55.798044: step 1044, loss = 0.75247 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:01:57.085744 ops/training.py:65 2019-01-17 00:01:57.085635: step 1045, loss = 0.73647 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:01:58.372487 ops/training.py:65 2019-01-17 00:01:58.372371: step 1046, loss = 0.76462 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:01:59.656717 ops/training.py:65 2019-01-17 00:01:59.656615: step 1047, loss = 0.69945 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:02:00.944342 ops/training.py:65 2019-01-17 00:02:00.944178: step 1048, loss = 0.82215 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-17 00:02:02.229216 ops/training.py:65 2019-01-17 00:02:02.229111: step 1049, loss = 0.74834 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:02:03.520764 ops/training.py:65 2019-01-17 00:02:03.520668: step 1050, loss = 0.72345 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:02:04.808365 ops/training.py:65 2019-01-17 00:02:04.808254: step 1051, loss = 0.75871 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:02:06.093951 ops/training.py:65 2019-01-17 00:02:06.093844: step 1052, loss = 0.73157 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:02:07.382583 ops/training.py:65 2019-01-17 00:02:07.382471: step 1053, loss = 0.74081 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:02:08.668992 ops/training.py:65 2019-01-17 00:02:08.668887: step 1054, loss = 0.76992 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:02:09.954520 ops/training.py:65 2019-01-17 00:02:09.954362: step 1055, loss = 0.72837 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:02:11.246091 ops/training.py:65 2019-01-17 00:02:11.245987: step 1056, loss = 0.68885 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:02:12.536498 ops/training.py:65 2019-01-17 00:02:12.536435: step 1057, loss = 0.67388 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:02:13.827114 ops/training.py:65 2019-01-17 00:02:13.827008: step 1058, loss = 0.70642 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:02:15.114635 ops/training.py:65 2019-01-17 00:02:15.114526: step 1059, loss = 0.76387 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:02:16.404526 ops/training.py:65 2019-01-17 00:02:16.404451: step 1060, loss = 0.69722 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:02:17.693942 ops/training.py:65 2019-01-17 00:02:17.693875: step 1061, loss = 0.74073 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:02:18.979004 ops/training.py:65 2019-01-17 00:02:18.978933: step 1062, loss = 0.66906 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:02:20.265770 ops/training.py:65 2019-01-17 00:02:20.265656: step 1063, loss = 0.76077 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:02:21.553214 ops/training.py:65 2019-01-17 00:02:21.553073: step 1064, loss = 0.65065 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:02:22.842388 ops/training.py:65 2019-01-17 00:02:22.842278: step 1065, loss = 0.72063 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:02:24.134168 ops/training.py:65 2019-01-17 00:02:24.134063: step 1066, loss = 0.65415 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:02:25.420788 ops/training.py:65 2019-01-17 00:02:25.420632: step 1067, loss = 0.69876 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:02:26.713228 ops/training.py:65 2019-01-17 00:02:26.713123: step 1068, loss = 0.77841 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:02:28.003715 ops/training.py:65 2019-01-17 00:02:28.003648: step 1069, loss = 0.82364 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:02:29.292420 ops/training.py:65 2019-01-17 00:02:29.292326: step 1070, loss = 0.71741 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:02:30.581420 ops/training.py:65 2019-01-17 00:02:30.581336: step 1071, loss = 0.79958 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:02:31.869785 ops/training.py:65 2019-01-17 00:02:31.869715: step 1072, loss = 0.67728 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:02:33.158342 ops/training.py:65 2019-01-17 00:02:33.158268: step 1073, loss = 0.75266 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:02:34.446925 ops/training.py:65 2019-01-17 00:02:34.446857: step 1074, loss = 0.70037 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:02:35.734883 ops/training.py:65 2019-01-17 00:02:35.734817: step 1075, loss = 0.74097 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:02:37.017908 ops/training.py:65 2019-01-17 00:02:37.017831: step 1076, loss = 0.66084 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:02:38.304841 ops/training.py:65 2019-01-17 00:02:38.304729: step 1077, loss = 0.76666 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:02:39.592575 ops/training.py:65 2019-01-17 00:02:39.592464: step 1078, loss = 0.73999 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:02:40.878147 ops/training.py:65 2019-01-17 00:02:40.878045: step 1079, loss = 0.69671 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:02:42.165144 ops/training.py:65 2019-01-17 00:02:42.165042: step 1080, loss = 0.71003 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:02:43.449923 ops/training.py:65 2019-01-17 00:02:43.449824: step 1081, loss = 0.71858 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:02:44.736615 ops/training.py:65 2019-01-17 00:02:44.736512: step 1082, loss = 0.65996 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:02:46.027783 ops/training.py:65 2019-01-17 00:02:46.027623: step 1083, loss = 0.77806 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:02:47.319595 ops/training.py:65 2019-01-17 00:02:47.319512: step 1084, loss = 0.72547 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:02:48.604779 ops/training.py:65 2019-01-17 00:02:48.604718: step 1085, loss = 0.71742 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:02:49.894198 ops/training.py:65 2019-01-17 00:02:49.894090: step 1086, loss = 0.68275 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:02:51.180266 ops/training.py:65 2019-01-17 00:02:51.180197: step 1087, loss = 0.69990 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:02:52.463188 ops/training.py:65 2019-01-17 00:02:52.463074: step 1088, loss = 0.76722 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:02:53.751369 ops/training.py:65 2019-01-17 00:02:53.751266: step 1089, loss = 0.79387 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:02:55.035335 ops/training.py:65 2019-01-17 00:02:55.035179: step 1090, loss = 0.67485 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:02:56.319998 ops/training.py:65 2019-01-17 00:02:56.319838: step 1091, loss = 0.69652 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:02:57.606838 ops/training.py:65 2019-01-17 00:02:57.606730: step 1092, loss = 0.73670 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:02:58.886739 ops/training.py:65 2019-01-17 00:02:58.886583: step 1093, loss = 0.70484 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:03:00.170207 ops/training.py:65 2019-01-17 00:03:00.170097: step 1094, loss = 0.74114 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:03:01.460557 ops/training.py:65 2019-01-17 00:03:01.460399: step 1095, loss = 0.75704 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:03:02.751446 ops/training.py:65 2019-01-17 00:03:02.751382: step 1096, loss = 0.69451 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:03:04.038802 ops/training.py:65 2019-01-17 00:03:04.038703: step 1097, loss = 0.66962 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:03:05.327202 ops/training.py:65 2019-01-17 00:03:05.327142: step 1098, loss = 0.76073 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:03:06.616155 ops/training.py:65 2019-01-17 00:03:06.616069: step 1099, loss = 0.66604 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:03:07.906419 ops/training.py:65 2019-01-17 00:03:07.906333: step 1100, loss = 0.75110 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:03:09.190817 ops/training.py:65 2019-01-17 00:03:09.190748: step 1101, loss = 0.72383 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:03:10.479636 ops/training.py:65 2019-01-17 00:03:10.479479: step 1102, loss = 0.70003 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:03:11.769891 ops/training.py:65 2019-01-17 00:03:11.769784: step 1103, loss = 0.74710 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:03:13.057480 ops/training.py:65 2019-01-17 00:03:13.057411: step 1104, loss = 0.69670 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:03:14.345507 ops/training.py:65 2019-01-17 00:03:14.345429: step 1105, loss = 0.76774 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:03:15.634034 ops/training.py:65 2019-01-17 00:03:15.633962: step 1106, loss = 0.75443 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:03:16.921925 ops/training.py:65 2019-01-17 00:03:16.921828: step 1107, loss = 0.72223 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:03:18.209457 ops/training.py:65 2019-01-17 00:03:18.209369: step 1108, loss = 0.65572 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 00:03:19.498639 ops/training.py:65 2019-01-17 00:03:19.498577: step 1109, loss = 0.68410 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:03:20.786081 ops/training.py:65 2019-01-17 00:03:20.786009: step 1110, loss = 0.70898 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:03:22.074632 ops/training.py:65 2019-01-17 00:03:22.074559: step 1111, loss = 0.71472 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:03:23.365057 ops/training.py:65 2019-01-17 00:03:23.364989: step 1112, loss = 0.71648 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:03:24.653471 ops/training.py:65 2019-01-17 00:03:24.653377: step 1113, loss = 0.64601 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:03:25.942790 ops/training.py:65 2019-01-17 00:03:25.942711: step 1114, loss = 0.65826 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:03:27.231440 ops/training.py:65 2019-01-17 00:03:27.231364: step 1115, loss = 0.72386 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:03:28.520899 ops/training.py:65 2019-01-17 00:03:28.520823: step 1116, loss = 0.70348 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:03:29.810753 ops/training.py:65 2019-01-17 00:03:29.810660: step 1117, loss = 0.73358 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:03:31.100039 ops/training.py:65 2019-01-17 00:03:31.099944: step 1118, loss = 0.72084 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:03:32.390012 ops/training.py:65 2019-01-17 00:03:32.389900: step 1119, loss = 0.75380 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:03:33.679487 ops/training.py:65 2019-01-17 00:03:33.679394: step 1120, loss = 0.77724 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:03:34.969427 ops/training.py:65 2019-01-17 00:03:34.969331: step 1121, loss = 0.81243 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:03:36.258140 ops/training.py:65 2019-01-17 00:03:36.258076: step 1122, loss = 0.78178 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:03:37.542324 ops/training.py:65 2019-01-17 00:03:37.542258: step 1123, loss = 0.78398 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:03:38.829714 ops/training.py:65 2019-01-17 00:03:38.829605: step 1124, loss = 0.74609 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:03:40.118934 ops/training.py:65 2019-01-17 00:03:40.118858: step 1125, loss = 0.72627 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:03:41.408298 ops/training.py:65 2019-01-17 00:03:41.408204: step 1126, loss = 0.74397 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:03:42.697569 ops/training.py:65 2019-01-17 00:03:42.697515: step 1127, loss = 0.80370 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:03:43.981628 ops/training.py:65 2019-01-17 00:03:43.981555: step 1128, loss = 0.68143 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:03:45.270622 ops/training.py:65 2019-01-17 00:03:45.270517: step 1129, loss = 0.73739 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:03:46.561254 ops/training.py:65 2019-01-17 00:03:46.561145: step 1130, loss = 0.72327 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:03:47.851827 ops/training.py:65 2019-01-17 00:03:47.851756: step 1131, loss = 0.70430 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:03:49.135759 ops/training.py:65 2019-01-17 00:03:49.135702: step 1132, loss = 0.71105 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:03:50.424048 ops/training.py:65 2019-01-17 00:03:50.423983: step 1133, loss = 0.79023 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:03:51.712455 ops/training.py:65 2019-01-17 00:03:51.712371: step 1134, loss = 0.69343 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:03:53.002073 ops/training.py:65 2019-01-17 00:03:53.002004: step 1135, loss = 0.70570 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:03:54.290842 ops/training.py:65 2019-01-17 00:03:54.290767: step 1136, loss = 0.68721 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:03:55.580369 ops/training.py:65 2019-01-17 00:03:55.580283: step 1137, loss = 0.73057 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:03:56.868184 ops/training.py:65 2019-01-17 00:03:56.868110: step 1138, loss = 0.80098 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:03:58.155740 ops/training.py:65 2019-01-17 00:03:58.155668: step 1139, loss = 0.63246 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:03:59.443414 ops/training.py:65 2019-01-17 00:03:59.443352: step 1140, loss = 0.65038 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:04:00.731905 ops/training.py:65 2019-01-17 00:04:00.731835: step 1141, loss = 0.81117 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:04:02.021436 ops/training.py:65 2019-01-17 00:04:02.021366: step 1142, loss = 0.76173 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:04:03.310126 ops/training.py:65 2019-01-17 00:04:03.310032: step 1143, loss = 0.68139 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:04:04.599272 ops/training.py:65 2019-01-17 00:04:04.599206: step 1144, loss = 0.72922 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:04:05.886264 ops/training.py:65 2019-01-17 00:04:05.886172: step 1145, loss = 0.69140 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:04:07.176435 ops/training.py:65 2019-01-17 00:04:07.176365: step 1146, loss = 0.69888 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:04:08.464336 ops/training.py:65 2019-01-17 00:04:08.464260: step 1147, loss = 0.62389 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:04:09.749247 ops/training.py:65 2019-01-17 00:04:09.749168: step 1148, loss = 0.73103 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:04:11.041026 ops/training.py:65 2019-01-17 00:04:11.040918: step 1149, loss = 0.70999 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:04:12.331570 ops/training.py:65 2019-01-17 00:04:12.331498: step 1150, loss = 0.72665 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:04:13.619711 ops/training.py:65 2019-01-17 00:04:13.619648: step 1151, loss = 0.80593 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:04:14.909317 ops/training.py:65 2019-01-17 00:04:14.909249: step 1152, loss = 0.69186 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:04:16.198829 ops/training.py:65 2019-01-17 00:04:16.198763: step 1153, loss = 0.60857 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 00:04:17.487986 ops/training.py:65 2019-01-17 00:04:17.487920: step 1154, loss = 0.70569 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:04:18.776875 ops/training.py:65 2019-01-17 00:04:18.776807: step 1155, loss = 0.73695 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:04:20.065399 ops/training.py:65 2019-01-17 00:04:20.065335: step 1156, loss = 0.73800 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:04:21.353597 ops/training.py:65 2019-01-17 00:04:21.353534: step 1157, loss = 0.75405 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:04:22.637499 ops/training.py:65 2019-01-17 00:04:22.637443: step 1158, loss = 0.74774 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:04:23.928678 ops/training.py:65 2019-01-17 00:04:23.928574: step 1159, loss = 0.76972 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:04:25.213144 ops/training.py:65 2019-01-17 00:04:25.213034: step 1160, loss = 0.74347 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:04:26.497012 ops/training.py:65 2019-01-17 00:04:26.496903: step 1161, loss = 0.80229 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:04:27.788007 ops/training.py:65 2019-01-17 00:04:27.787852: step 1162, loss = 0.75276 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:04:29.080467 ops/training.py:65 2019-01-17 00:04:29.080399: step 1163, loss = 0.73200 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:04:30.369102 ops/training.py:65 2019-01-17 00:04:30.369030: step 1164, loss = 0.70778 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:04:31.657549 ops/training.py:65 2019-01-17 00:04:31.657468: step 1165, loss = 0.76812 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:04:32.946837 ops/training.py:65 2019-01-17 00:04:32.946759: step 1166, loss = 0.63846 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:04:34.234917 ops/training.py:65 2019-01-17 00:04:34.234848: step 1167, loss = 0.74328 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:04:35.523143 ops/training.py:65 2019-01-17 00:04:35.523057: step 1168, loss = 0.72573 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:04:36.811064 ops/training.py:65 2019-01-17 00:04:36.810984: step 1169, loss = 0.79525 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:04:38.095805 ops/training.py:65 2019-01-17 00:04:38.095737: step 1170, loss = 0.72233 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:04:39.378683 ops/training.py:65 2019-01-17 00:04:39.378575: step 1171, loss = 0.70821 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:04:40.666643 ops/training.py:65 2019-01-17 00:04:40.666481: step 1172, loss = 0.65679 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:04:41.954891 ops/training.py:65 2019-01-17 00:04:41.954789: step 1173, loss = 0.70174 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:04:43.244045 ops/training.py:65 2019-01-17 00:04:43.243950: step 1174, loss = 0.69195 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:04:44.531903 ops/training.py:65 2019-01-17 00:04:44.531839: step 1175, loss = 0.74853 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:04:45.821093 ops/training.py:65 2019-01-17 00:04:45.820991: step 1176, loss = 0.72797 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:04:47.102107 ops/training.py:65 2019-01-17 00:04:47.101990: step 1177, loss = 0.72443 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:04:48.386002 ops/training.py:65 2019-01-17 00:04:48.385910: step 1178, loss = 0.75690 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:04:49.666529 ops/training.py:65 2019-01-17 00:04:49.666441: step 1179, loss = 0.80579 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:04:50.957754 ops/training.py:65 2019-01-17 00:04:50.957651: step 1180, loss = 0.71382 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:04:52.243274 ops/training.py:65 2019-01-17 00:04:52.243205: step 1181, loss = 0.71974 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:04:53.526466 ops/training.py:65 2019-01-17 00:04:53.526367: step 1182, loss = 0.74444 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:04:54.811011 ops/training.py:65 2019-01-17 00:04:54.810913: step 1183, loss = 0.78228 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:04:56.102416 ops/training.py:65 2019-01-17 00:04:56.102320: step 1184, loss = 0.75897 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:04:57.391495 ops/training.py:65 2019-01-17 00:04:57.391408: step 1185, loss = 0.72013 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:04:58.680677 ops/training.py:65 2019-01-17 00:04:58.680578: step 1186, loss = 0.74427 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:04:59.968375 ops/training.py:65 2019-01-17 00:04:59.968283: step 1187, loss = 0.67058 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:05:01.256838 ops/training.py:65 2019-01-17 00:05:01.256766: step 1188, loss = 0.79110 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:05:02.546324 ops/training.py:65 2019-01-17 00:05:02.546264: step 1189, loss = 0.68951 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:05:03.836902 ops/training.py:65 2019-01-17 00:05:03.836826: step 1190, loss = 0.77318 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:05:05.124310 ops/training.py:65 2019-01-17 00:05:05.124227: step 1191, loss = 0.87306 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-17 00:05:06.410907 ops/training.py:65 2019-01-17 00:05:06.410835: step 1192, loss = 0.76812 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:05:07.700701 ops/training.py:65 2019-01-17 00:05:07.700617: step 1193, loss = 0.75628 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:05:08.989715 ops/training.py:65 2019-01-17 00:05:08.989635: step 1194, loss = 0.65768 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:05:10.280772 ops/training.py:65 2019-01-17 00:05:10.280652: step 1195, loss = 0.69632 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:05:11.566103 ops/training.py:65 2019-01-17 00:05:11.565992: step 1196, loss = 0.77520 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:05:12.849399 ops/training.py:65 2019-01-17 00:05:12.849342: step 1197, loss = 0.76815 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:05:14.140296 ops/training.py:65 2019-01-17 00:05:14.140198: step 1198, loss = 0.71305 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:05:15.425814 ops/training.py:65 2019-01-17 00:05:15.425744: step 1199, loss = 0.76155 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:05:16.712520 ops/training.py:65 2019-01-17 00:05:16.712434: step 1200, loss = 0.69809 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:05:17.994568 ops/training.py:65 2019-01-17 00:05:17.994519: step 1201, loss = 0.69265 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:05:19.282566 ops/training.py:65 2019-01-17 00:05:19.282496: step 1202, loss = 0.76087 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:05:20.568582 ops/training.py:65 2019-01-17 00:05:20.568525: step 1203, loss = 0.76446 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:05:21.854440 ops/training.py:65 2019-01-17 00:05:21.854362: step 1204, loss = 0.86125 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:05:23.141717 ops/training.py:65 2019-01-17 00:05:23.141622: step 1205, loss = 0.70562 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:05:24.428261 ops/training.py:65 2019-01-17 00:05:24.428194: step 1206, loss = 0.69790 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:05:25.712853 ops/training.py:65 2019-01-17 00:05:25.712787: step 1207, loss = 0.74872 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:05:26.995170 ops/training.py:65 2019-01-17 00:05:26.995066: step 1208, loss = 0.79570 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:05:28.275591 ops/training.py:65 2019-01-17 00:05:28.275537: step 1209, loss = 0.80155 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:05:29.557910 ops/training.py:65 2019-01-17 00:05:29.557853: step 1210, loss = 0.68392 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:05:30.849689 ops/training.py:65 2019-01-17 00:05:30.849642: step 1211, loss = 0.71457 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:05:32.140302 ops/training.py:65 2019-01-17 00:05:32.140199: step 1212, loss = 0.78328 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:05:33.429161 ops/training.py:65 2019-01-17 00:05:33.429075: step 1213, loss = 0.78690 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:05:34.712641 ops/training.py:65 2019-01-17 00:05:34.712548: step 1214, loss = 0.72042 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:05:35.996103 ops/training.py:65 2019-01-17 00:05:35.996048: step 1215, loss = 0.69394 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:05:37.287693 ops/training.py:65 2019-01-17 00:05:37.287645: step 1216, loss = 0.75343 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:05:38.577520 ops/training.py:65 2019-01-17 00:05:38.577445: step 1217, loss = 0.83217 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:05:39.862803 ops/training.py:65 2019-01-17 00:05:39.862728: step 1218, loss = 0.78775 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:05:41.153200 ops/training.py:65 2019-01-17 00:05:41.153088: step 1219, loss = 0.76472 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:05:42.437277 ops/training.py:65 2019-01-17 00:05:42.437173: step 1220, loss = 0.77710 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:05:43.730763 ops/training.py:65 2019-01-17 00:05:43.730662: step 1221, loss = 0.82413 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:05:45.021380 ops/training.py:65 2019-01-17 00:05:45.021304: step 1222, loss = 0.84053 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:05:46.305956 ops/training.py:65 2019-01-17 00:05:46.305891: step 1223, loss = 0.78963 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:05:47.595944 ops/training.py:65 2019-01-17 00:05:47.595839: step 1224, loss = 0.72132 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:05:48.884651 ops/training.py:65 2019-01-17 00:05:48.884584: step 1225, loss = 0.68032 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:05:50.168958 ops/training.py:65 2019-01-17 00:05:50.168886: step 1226, loss = 0.76839 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:05:51.458820 ops/training.py:65 2019-01-17 00:05:51.458718: step 1227, loss = 0.75598 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:05:52.738576 ops/training.py:65 2019-01-17 00:05:52.738466: step 1228, loss = 0.70305 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:05:54.022849 ops/training.py:65 2019-01-17 00:05:54.022752: step 1229, loss = 0.75174 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:05:55.315531 ops/training.py:65 2019-01-17 00:05:55.315433: step 1230, loss = 0.69169 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:05:56.606109 ops/training.py:65 2019-01-17 00:05:56.606004: step 1231, loss = 0.68499 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:05:57.895655 ops/training.py:65 2019-01-17 00:05:57.895584: step 1232, loss = 0.76154 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:05:59.186455 ops/training.py:65 2019-01-17 00:05:59.186384: step 1233, loss = 0.73902 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:06:00.467085 ops/training.py:65 2019-01-17 00:06:00.466935: step 1234, loss = 0.71872 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:06:01.752013 ops/training.py:65 2019-01-17 00:06:01.751905: step 1235, loss = 0.74176 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:06:03.045016 ops/training.py:65 2019-01-17 00:06:03.044914: step 1236, loss = 0.66052 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:06:04.336341 ops/training.py:65 2019-01-17 00:06:04.336269: step 1237, loss = 0.74276 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:06:05.620080 ops/training.py:65 2019-01-17 00:06:05.620027: step 1238, loss = 0.72910 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:06:06.913331 ops/training.py:65 2019-01-17 00:06:06.913229: step 1239, loss = 0.73095 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:06:08.203337 ops/training.py:65 2019-01-17 00:06:08.203251: step 1240, loss = 0.70845 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:06:09.488300 ops/training.py:65 2019-01-17 00:06:09.488231: step 1241, loss = 0.68785 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:06:10.778233 ops/training.py:65 2019-01-17 00:06:10.778131: step 1242, loss = 0.68821 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:06:12.065657 ops/training.py:65 2019-01-17 00:06:12.065511: step 1243, loss = 0.65725 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:06:13.358082 ops/training.py:65 2019-01-17 00:06:13.357980: step 1244, loss = 0.75574 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:06:14.648958 ops/training.py:65 2019-01-17 00:06:14.648856: step 1245, loss = 0.69458 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:06:15.938279 ops/training.py:65 2019-01-17 00:06:15.938173: step 1246, loss = 0.71898 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:06:17.225822 ops/training.py:65 2019-01-17 00:06:17.225720: step 1247, loss = 0.76042 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:06:18.517836 ops/training.py:65 2019-01-17 00:06:18.517732: step 1248, loss = 0.75069 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:06:19.807387 ops/training.py:65 2019-01-17 00:06:19.807274: step 1249, loss = 0.64975 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:06:21.096946 ops/training.py:65 2019-01-17 00:06:21.096862: step 1250, loss = 0.71146 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:06:22.380262 ops/training.py:65 2019-01-17 00:06:22.380201: step 1251, loss = 0.67039 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:06:23.667346 ops/training.py:65 2019-01-17 00:06:23.667253: step 1252, loss = 0.74315 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:06:24.952515 ops/training.py:65 2019-01-17 00:06:24.952454: step 1253, loss = 0.60946 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:06:26.240050 ops/training.py:65 2019-01-17 00:06:26.239890: step 1254, loss = 0.66411 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:06:27.528784 ops/training.py:65 2019-01-17 00:06:27.528722: step 1255, loss = 0.75212 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:06:28.813217 ops/training.py:65 2019-01-17 00:06:28.813161: step 1256, loss = 0.70629 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:06:30.106486 ops/training.py:65 2019-01-17 00:06:30.106418: step 1257, loss = 0.73345 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:06:31.390211 ops/training.py:65 2019-01-17 00:06:31.390141: step 1258, loss = 0.67028 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:06:32.680576 ops/training.py:65 2019-01-17 00:06:32.680472: step 1259, loss = 0.68982 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:06:33.966752 ops/training.py:65 2019-01-17 00:06:33.966655: step 1260, loss = 0.71041 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:06:35.250209 ops/training.py:65 2019-01-17 00:06:35.250104: step 1261, loss = 0.70422 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:06:36.537223 ops/training.py:65 2019-01-17 00:06:36.537119: step 1262, loss = 0.79998 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:06:37.819761 ops/training.py:65 2019-01-17 00:06:37.819663: step 1263, loss = 0.76457 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:06:39.103529 ops/training.py:65 2019-01-17 00:06:39.103425: step 1264, loss = 0.65833 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:06:40.394387 ops/training.py:65 2019-01-17 00:06:40.394287: step 1265, loss = 0.70989 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:06:41.685435 ops/training.py:65 2019-01-17 00:06:41.685353: step 1266, loss = 0.71724 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:06:42.972396 ops/training.py:65 2019-01-17 00:06:42.972330: step 1267, loss = 0.75486 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:06:44.259199 ops/training.py:65 2019-01-17 00:06:44.259090: step 1268, loss = 0.77032 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:06:45.543086 ops/training.py:65 2019-01-17 00:06:45.542983: step 1269, loss = 0.68073 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:06:46.835753 ops/training.py:65 2019-01-17 00:06:46.835649: step 1270, loss = 0.75429 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:06:48.119926 ops/training.py:65 2019-01-17 00:06:48.119817: step 1271, loss = 0.71632 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:06:49.411968 ops/training.py:65 2019-01-17 00:06:49.411878: step 1272, loss = 0.72669 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:06:50.697222 ops/training.py:65 2019-01-17 00:06:50.697131: step 1273, loss = 0.72484 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:06:51.981747 ops/training.py:65 2019-01-17 00:06:51.981644: step 1274, loss = 0.66857 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:06:53.269378 ops/training.py:65 2019-01-17 00:06:53.269276: step 1275, loss = 0.70577 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:06:54.554845 ops/training.py:65 2019-01-17 00:06:54.554744: step 1276, loss = 0.76104 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:06:55.843477 ops/training.py:65 2019-01-17 00:06:55.843369: step 1277, loss = 0.67639 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:06:57.131357 ops/training.py:65 2019-01-17 00:06:57.131249: step 1278, loss = 0.68277 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:06:58.414061 ops/training.py:65 2019-01-17 00:06:58.413960: step 1279, loss = 0.78327 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:06:59.706494 ops/training.py:65 2019-01-17 00:06:59.706387: step 1280, loss = 0.71343 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:07:00.993788 ops/training.py:65 2019-01-17 00:07:00.993693: step 1281, loss = 0.66746 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:07:02.278080 ops/training.py:65 2019-01-17 00:07:02.277989: step 1282, loss = 0.72765 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:07:03.558947 ops/training.py:65 2019-01-17 00:07:03.558845: step 1283, loss = 0.70376 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:07:04.847851 ops/training.py:65 2019-01-17 00:07:04.847759: step 1284, loss = 0.73472 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:07:06.133187 ops/training.py:65 2019-01-17 00:07:06.133082: step 1285, loss = 0.72875 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:07:07.414478 ops/training.py:65 2019-01-17 00:07:07.414378: step 1286, loss = 0.72139 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:07:08.701304 ops/training.py:65 2019-01-17 00:07:08.701192: step 1287, loss = 0.70385 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:07:09.982584 ops/training.py:65 2019-01-17 00:07:09.982481: step 1288, loss = 0.72335 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:07:11.276038 ops/training.py:65 2019-01-17 00:07:11.275932: step 1289, loss = 0.75546 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:07:12.563670 ops/training.py:65 2019-01-17 00:07:12.563578: step 1290, loss = 0.77960 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:07:13.851609 ops/training.py:65 2019-01-17 00:07:13.851500: step 1291, loss = 0.65518 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:07:15.137288 ops/training.py:65 2019-01-17 00:07:15.137189: step 1292, loss = 0.70850 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:07:16.422410 ops/training.py:65 2019-01-17 00:07:16.422301: step 1293, loss = 0.65344 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:07:17.706364 ops/training.py:65 2019-01-17 00:07:17.706263: step 1294, loss = 0.72331 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:07:18.996486 ops/training.py:65 2019-01-17 00:07:18.996386: step 1295, loss = 0.71256 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:07:20.286828 ops/training.py:65 2019-01-17 00:07:20.286722: step 1296, loss = 0.73731 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:07:21.577556 ops/training.py:65 2019-01-17 00:07:21.577454: step 1297, loss = 0.77800 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:07:22.863587 ops/training.py:65 2019-01-17 00:07:22.863515: step 1298, loss = 0.73563 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:07:24.145073 ops/training.py:65 2019-01-17 00:07:24.144972: step 1299, loss = 0.77599 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:07:25.427702 ops/training.py:65 2019-01-17 00:07:25.427597: step 1300, loss = 0.82410 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:07:26.717938 ops/training.py:65 2019-01-17 00:07:26.717832: step 1301, loss = 0.64996 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:07:28.008751 ops/training.py:65 2019-01-17 00:07:28.008666: step 1302, loss = 0.73010 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:07:29.305541 ops/training.py:65 2019-01-17 00:07:29.305399: step 1303, loss = 0.65573 (24.7 examples/sec; 1.296 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:07:30.588394 ops/training.py:65 2019-01-17 00:07:30.588287: step 1304, loss = 0.64077 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:07:31.872639 ops/training.py:65 2019-01-17 00:07:31.872537: step 1305, loss = 0.72309 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:07:33.155404 ops/training.py:65 2019-01-17 00:07:33.155345: step 1306, loss = 0.74527 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:07:34.438482 ops/training.py:65 2019-01-17 00:07:34.438390: step 1307, loss = 0.71826 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:07:35.727752 ops/training.py:65 2019-01-17 00:07:35.727652: step 1308, loss = 0.76035 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:07:37.014084 ops/training.py:65 2019-01-17 00:07:37.013981: step 1309, loss = 0.76191 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:07:38.299045 ops/training.py:65 2019-01-17 00:07:38.298935: step 1310, loss = 0.69579 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:07:39.581636 ops/training.py:65 2019-01-17 00:07:39.581535: step 1311, loss = 0.63645 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:07:40.872176 ops/training.py:65 2019-01-17 00:07:40.872077: step 1312, loss = 0.73808 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:07:42.155086 ops/training.py:65 2019-01-17 00:07:42.155020: step 1313, loss = 0.71443 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:07:43.445343 ops/training.py:65 2019-01-17 00:07:43.445250: step 1314, loss = 0.68889 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:07:44.729357 ops/training.py:65 2019-01-17 00:07:44.729298: step 1315, loss = 0.82989 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:07:46.013253 ops/training.py:65 2019-01-17 00:07:46.013145: step 1316, loss = 0.71105 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:07:47.302725 ops/training.py:65 2019-01-17 00:07:47.302614: step 1317, loss = 0.62751 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:07:48.595998 ops/training.py:65 2019-01-17 00:07:48.595898: step 1318, loss = 0.68345 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:07:49.882086 ops/training.py:65 2019-01-17 00:07:49.882002: step 1319, loss = 0.78287 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:07:51.165256 ops/training.py:65 2019-01-17 00:07:51.165146: step 1320, loss = 0.73686 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:07:52.454840 ops/training.py:65 2019-01-17 00:07:52.454733: step 1321, loss = 0.71291 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:07:53.745143 ops/training.py:65 2019-01-17 00:07:53.745034: step 1322, loss = 0.75476 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:07:55.029058 ops/training.py:65 2019-01-17 00:07:55.028956: step 1323, loss = 0.75927 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:07:56.321722 ops/training.py:65 2019-01-17 00:07:56.321621: step 1324, loss = 0.72433 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:07:57.607741 ops/training.py:65 2019-01-17 00:07:57.607708: step 1325, loss = 0.74530 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:07:58.893509 ops/training.py:65 2019-01-17 00:07:58.893414: step 1326, loss = 0.83044 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:08:00.175505 ops/training.py:65 2019-01-17 00:08:00.175404: step 1327, loss = 0.73883 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:08:01.460658 ops/training.py:65 2019-01-17 00:08:01.460591: step 1328, loss = 0.72268 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:08:02.747234 ops/training.py:65 2019-01-17 00:08:02.747184: step 1329, loss = 0.70540 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:08:04.039449 ops/training.py:65 2019-01-17 00:08:04.039394: step 1330, loss = 0.69251 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:08:05.324011 ops/training.py:65 2019-01-17 00:08:05.323958: step 1331, loss = 0.73543 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:08:06.604509 ops/training.py:65 2019-01-17 00:08:06.604450: step 1332, loss = 0.73231 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:08:07.888836 ops/training.py:65 2019-01-17 00:08:07.888760: step 1333, loss = 0.79783 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:08:09.181182 ops/training.py:65 2019-01-17 00:08:09.181083: step 1334, loss = 0.67926 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:08:10.468878 ops/training.py:65 2019-01-17 00:08:10.468778: step 1335, loss = 0.71097 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:08:11.754187 ops/training.py:65 2019-01-17 00:08:11.754092: step 1336, loss = 0.65330 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:08:13.041094 ops/training.py:65 2019-01-17 00:08:13.040999: step 1337, loss = 0.71905 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:08:14.327447 ops/training.py:65 2019-01-17 00:08:14.327347: step 1338, loss = 0.68537 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:08:15.616661 ops/training.py:65 2019-01-17 00:08:15.616564: step 1339, loss = 0.78976 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:08:16.905843 ops/training.py:65 2019-01-17 00:08:16.905729: step 1340, loss = 0.69198 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:08:18.193276 ops/training.py:65 2019-01-17 00:08:18.193175: step 1341, loss = 0.67747 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:08:19.482310 ops/training.py:65 2019-01-17 00:08:19.482220: step 1342, loss = 0.74040 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:08:20.768674 ops/training.py:65 2019-01-17 00:08:20.768575: step 1343, loss = 0.68876 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:08:22.054721 ops/training.py:65 2019-01-17 00:08:22.054615: step 1344, loss = 0.71274 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:08:23.341765 ops/training.py:65 2019-01-17 00:08:23.341666: step 1345, loss = 0.72943 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:08:24.634141 ops/training.py:65 2019-01-17 00:08:24.634004: step 1346, loss = 0.71892 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:08:25.926305 ops/training.py:65 2019-01-17 00:08:25.926162: step 1347, loss = 0.71777 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:08:27.211756 ops/training.py:65 2019-01-17 00:08:27.211658: step 1348, loss = 0.79913 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:08:28.504807 ops/training.py:65 2019-01-17 00:08:28.504710: step 1349, loss = 0.70982 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:08:29.794594 ops/training.py:65 2019-01-17 00:08:29.794491: step 1350, loss = 0.71385 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:08:31.079173 ops/training.py:65 2019-01-17 00:08:31.079054: step 1351, loss = 0.72355 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:08:32.366146 ops/training.py:65 2019-01-17 00:08:32.366038: step 1352, loss = 0.76205 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:08:33.649231 ops/training.py:65 2019-01-17 00:08:33.649129: step 1353, loss = 0.79899 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-17 00:08:34.938112 ops/training.py:65 2019-01-17 00:08:34.938018: step 1354, loss = 0.68518 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:08:36.222286 ops/training.py:65 2019-01-17 00:08:36.222152: step 1355, loss = 0.75125 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:08:37.503812 ops/training.py:65 2019-01-17 00:08:37.503712: step 1356, loss = 0.77932 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:08:38.785678 ops/training.py:65 2019-01-17 00:08:38.785521: step 1357, loss = 0.72802 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:08:40.072225 ops/training.py:65 2019-01-17 00:08:40.072117: step 1358, loss = 0.75481 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:08:41.353046 ops/training.py:65 2019-01-17 00:08:41.352955: step 1359, loss = 0.73693 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:08:42.641268 ops/training.py:65 2019-01-17 00:08:42.641169: step 1360, loss = 0.66424 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:08:43.923323 ops/training.py:65 2019-01-17 00:08:43.923222: step 1361, loss = 0.74013 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:08:45.207495 ops/training.py:65 2019-01-17 00:08:45.207392: step 1362, loss = 0.75980 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:08:46.491530 ops/training.py:65 2019-01-17 00:08:46.491416: step 1363, loss = 0.72560 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:08:47.779338 ops/training.py:65 2019-01-17 00:08:47.779190: step 1364, loss = 0.80676 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:08:49.064090 ops/training.py:65 2019-01-17 00:08:49.063997: step 1365, loss = 0.65509 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:08:50.350768 ops/training.py:65 2019-01-17 00:08:50.350666: step 1366, loss = 0.71312 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:08:51.639031 ops/training.py:65 2019-01-17 00:08:51.638945: step 1367, loss = 0.83904 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:08:52.928026 ops/training.py:65 2019-01-17 00:08:52.927920: step 1368, loss = 0.73678 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:08:54.212218 ops/training.py:65 2019-01-17 00:08:54.212160: step 1369, loss = 0.68016 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:08:55.502860 ops/training.py:65 2019-01-17 00:08:55.502794: step 1370, loss = 0.70457 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:08:56.788418 ops/training.py:65 2019-01-17 00:08:56.788342: step 1371, loss = 0.77028 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:08:58.070725 ops/training.py:65 2019-01-17 00:08:58.070625: step 1372, loss = 0.68440 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:08:59.350832 ops/training.py:65 2019-01-17 00:08:59.350727: step 1373, loss = 0.77224 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:09:00.635437 ops/training.py:65 2019-01-17 00:09:00.635334: step 1374, loss = 0.81249 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:09:01.925456 ops/training.py:65 2019-01-17 00:09:01.925355: step 1375, loss = 0.76202 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:09:03.213212 ops/training.py:65 2019-01-17 00:09:03.213116: step 1376, loss = 0.69917 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:09:04.496877 ops/training.py:65 2019-01-17 00:09:04.496789: step 1377, loss = 0.78315 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:09:05.785690 ops/training.py:65 2019-01-17 00:09:05.785580: step 1378, loss = 0.71579 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:09:07.076990 ops/training.py:65 2019-01-17 00:09:07.076886: step 1379, loss = 0.67193 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:09:08.358873 ops/training.py:65 2019-01-17 00:09:08.358769: step 1380, loss = 0.78876 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:09:09.647044 ops/training.py:65 2019-01-17 00:09:09.646942: step 1381, loss = 0.73112 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:09:10.933701 ops/training.py:65 2019-01-17 00:09:10.933597: step 1382, loss = 0.71401 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:09:12.221915 ops/training.py:65 2019-01-17 00:09:12.221811: step 1383, loss = 0.71034 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:09:13.505237 ops/training.py:65 2019-01-17 00:09:13.505131: step 1384, loss = 0.73784 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:09:14.789199 ops/training.py:65 2019-01-17 00:09:14.789097: step 1385, loss = 0.78086 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:09:16.075201 ops/training.py:65 2019-01-17 00:09:16.075102: step 1386, loss = 0.66967 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:09:17.366881 ops/training.py:65 2019-01-17 00:09:17.366780: step 1387, loss = 0.72613 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:09:18.654617 ops/training.py:65 2019-01-17 00:09:18.654510: step 1388, loss = 0.69110 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:09:19.938450 ops/training.py:65 2019-01-17 00:09:19.938356: step 1389, loss = 0.81313 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:09:21.226119 ops/training.py:65 2019-01-17 00:09:21.226017: step 1390, loss = 0.75118 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:09:22.508636 ops/training.py:65 2019-01-17 00:09:22.508537: step 1391, loss = 0.74108 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:09:23.800394 ops/training.py:65 2019-01-17 00:09:23.800288: step 1392, loss = 0.74163 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:09:25.083025 ops/training.py:65 2019-01-17 00:09:25.082917: step 1393, loss = 0.75753 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:09:26.367758 ops/training.py:65 2019-01-17 00:09:26.367651: step 1394, loss = 0.74558 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:09:27.652065 ops/training.py:65 2019-01-17 00:09:27.651959: step 1395, loss = 0.83408 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:09:28.941837 ops/training.py:65 2019-01-17 00:09:28.941714: step 1396, loss = 0.73557 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:09:30.220321 ops/training.py:65 2019-01-17 00:09:30.220221: step 1397, loss = 0.70030 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:09:31.505637 ops/training.py:65 2019-01-17 00:09:31.505538: step 1398, loss = 0.71537 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:09:32.789722 ops/training.py:65 2019-01-17 00:09:32.789623: step 1399, loss = 0.69303 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:09:34.072045 ops/training.py:65 2019-01-17 00:09:34.071959: step 1400, loss = 0.65554 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:09:35.362571 ops/training.py:65 2019-01-17 00:09:35.362466: step 1401, loss = 0.72249 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:09:36.643443 ops/training.py:65 2019-01-17 00:09:36.643290: step 1402, loss = 0.67690 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:09:37.925658 ops/training.py:65 2019-01-17 00:09:37.925499: step 1403, loss = 0.66403 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:09:39.212531 ops/training.py:65 2019-01-17 00:09:39.212430: step 1404, loss = 0.70856 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:09:40.493756 ops/training.py:65 2019-01-17 00:09:40.493609: step 1405, loss = 0.72527 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:09:41.774122 ops/training.py:65 2019-01-17 00:09:41.773965: step 1406, loss = 0.70426 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:09:43.058281 ops/training.py:65 2019-01-17 00:09:43.058184: step 1407, loss = 0.72345 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:09:44.347734 ops/training.py:65 2019-01-17 00:09:44.347634: step 1408, loss = 0.80121 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:09:45.632429 ops/training.py:65 2019-01-17 00:09:45.632324: step 1409, loss = 0.64056 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:09:46.922204 ops/training.py:65 2019-01-17 00:09:46.922096: step 1410, loss = 0.63543 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:09:48.206854 ops/training.py:65 2019-01-17 00:09:48.206751: step 1411, loss = 0.70435 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:09:49.497413 ops/training.py:65 2019-01-17 00:09:49.497316: step 1412, loss = 0.77328 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:09:50.781417 ops/training.py:65 2019-01-17 00:09:50.781318: step 1413, loss = 0.66916 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:09:52.072274 ops/training.py:65 2019-01-17 00:09:52.072173: step 1414, loss = 0.65905 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:09:53.354822 ops/training.py:65 2019-01-17 00:09:53.354717: step 1415, loss = 0.67270 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:09:54.642461 ops/training.py:65 2019-01-17 00:09:54.642360: step 1416, loss = 0.69522 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:09:55.927558 ops/training.py:65 2019-01-17 00:09:55.927470: step 1417, loss = 0.68074 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:09:57.216232 ops/training.py:65 2019-01-17 00:09:57.216127: step 1418, loss = 0.73469 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:09:58.501236 ops/training.py:65 2019-01-17 00:09:58.501090: step 1419, loss = 0.77691 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:09:59.789417 ops/training.py:65 2019-01-17 00:09:59.789322: step 1420, loss = 0.74727 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:10:01.074470 ops/training.py:65 2019-01-17 00:10:01.074364: step 1421, loss = 0.69476 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:10:02.356190 ops/training.py:65 2019-01-17 00:10:02.356103: step 1422, loss = 0.73843 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:10:03.642492 ops/training.py:65 2019-01-17 00:10:03.642387: step 1423, loss = 0.79808 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:10:04.926541 ops/training.py:65 2019-01-17 00:10:04.926453: step 1424, loss = 0.69635 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:10:06.216321 ops/training.py:65 2019-01-17 00:10:06.216199: step 1425, loss = 0.73427 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:10:07.501157 ops/training.py:65 2019-01-17 00:10:07.501056: step 1426, loss = 0.75159 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:10:08.793683 ops/training.py:65 2019-01-17 00:10:08.793574: step 1427, loss = 0.71319 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:10:10.081626 ops/training.py:65 2019-01-17 00:10:10.081513: step 1428, loss = 0.67396 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:10:11.372523 ops/training.py:65 2019-01-17 00:10:11.372421: step 1429, loss = 0.77324 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:10:12.662073 ops/training.py:65 2019-01-17 00:10:12.661918: step 1430, loss = 0.72819 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:10:13.946965 ops/training.py:65 2019-01-17 00:10:13.946862: step 1431, loss = 0.74641 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:10:15.230151 ops/training.py:65 2019-01-17 00:10:15.230051: step 1432, loss = 0.72038 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:10:16.523344 ops/training.py:65 2019-01-17 00:10:16.523190: step 1433, loss = 0.63549 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 00:10:17.815506 ops/training.py:65 2019-01-17 00:10:17.815349: step 1434, loss = 0.67208 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:10:19.101780 ops/training.py:65 2019-01-17 00:10:19.101704: step 1435, loss = 0.72141 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:10:20.386235 ops/training.py:65 2019-01-17 00:10:20.386138: step 1436, loss = 0.74171 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:10:21.671317 ops/training.py:65 2019-01-17 00:10:21.671160: step 1437, loss = 0.64581 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:10:22.958505 ops/training.py:65 2019-01-17 00:10:22.958411: step 1438, loss = 0.70223 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:10:24.239058 ops/training.py:65 2019-01-17 00:10:24.238956: step 1439, loss = 0.74415 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:10:25.528476 ops/training.py:65 2019-01-17 00:10:25.528375: step 1440, loss = 0.67048 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:10:26.811626 ops/training.py:65 2019-01-17 00:10:26.811522: step 1441, loss = 0.76460 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:10:28.104872 ops/training.py:65 2019-01-17 00:10:28.104766: step 1442, loss = 0.75156 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:10:29.393569 ops/training.py:65 2019-01-17 00:10:29.393468: step 1443, loss = 0.65539 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:10:30.678147 ops/training.py:65 2019-01-17 00:10:30.678041: step 1444, loss = 0.75314 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:10:31.959849 ops/training.py:65 2019-01-17 00:10:31.959744: step 1445, loss = 0.72343 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:10:33.249032 ops/training.py:65 2019-01-17 00:10:33.248934: step 1446, loss = 0.70246 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:10:34.534027 ops/training.py:65 2019-01-17 00:10:34.533933: step 1447, loss = 0.75981 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:10:35.817404 ops/training.py:65 2019-01-17 00:10:35.817294: step 1448, loss = 0.70247 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:10:37.101762 ops/training.py:65 2019-01-17 00:10:37.101660: step 1449, loss = 0.64329 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:10:38.395268 ops/training.py:65 2019-01-17 00:10:38.395164: step 1450, loss = 0.66741 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:10:39.684173 ops/training.py:65 2019-01-17 00:10:39.684115: step 1451, loss = 0.68992 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:10:40.968782 ops/training.py:65 2019-01-17 00:10:40.968725: step 1452, loss = 0.73011 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:10:42.250076 ops/training.py:65 2019-01-17 00:10:42.249962: step 1453, loss = 0.77729 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-17 00:10:43.530375 ops/training.py:65 2019-01-17 00:10:43.530312: step 1454, loss = 0.71405 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:10:44.814380 ops/training.py:65 2019-01-17 00:10:44.814282: step 1455, loss = 0.67635 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:10:46.100589 ops/training.py:65 2019-01-17 00:10:46.100480: step 1456, loss = 0.79290 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:10:47.390580 ops/training.py:65 2019-01-17 00:10:47.390473: step 1457, loss = 0.72258 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:10:48.672017 ops/training.py:65 2019-01-17 00:10:48.671920: step 1458, loss = 0.72250 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:10:49.955622 ops/training.py:65 2019-01-17 00:10:49.955489: step 1459, loss = 0.71981 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:10:51.242258 ops/training.py:65 2019-01-17 00:10:51.242156: step 1460, loss = 0.71448 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:10:52.526045 ops/training.py:65 2019-01-17 00:10:52.525954: step 1461, loss = 0.69213 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:10:53.816878 ops/training.py:65 2019-01-17 00:10:53.816738: step 1462, loss = 0.73382 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:10:55.100501 ops/training.py:65 2019-01-17 00:10:55.100401: step 1463, loss = 0.80535 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:10:56.392363 ops/training.py:65 2019-01-17 00:10:56.392208: step 1464, loss = 0.66421 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:10:57.682977 ops/training.py:65 2019-01-17 00:10:57.682898: step 1465, loss = 0.74119 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:10:58.967136 ops/training.py:65 2019-01-17 00:10:58.967069: step 1466, loss = 0.79191 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:11:00.259450 ops/training.py:65 2019-01-17 00:11:00.259341: step 1467, loss = 0.70219 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:11:01.538637 ops/training.py:65 2019-01-17 00:11:01.538472: step 1468, loss = 0.73809 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:11:02.828489 ops/training.py:65 2019-01-17 00:11:02.828383: step 1469, loss = 0.69227 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:11:04.108727 ops/training.py:65 2019-01-17 00:11:04.108614: step 1470, loss = 0.68365 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:11:05.392000 ops/training.py:65 2019-01-17 00:11:05.391909: step 1471, loss = 0.76919 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:11:06.682674 ops/training.py:65 2019-01-17 00:11:06.682562: step 1472, loss = 0.68277 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:11:07.974612 ops/training.py:65 2019-01-17 00:11:07.974504: step 1473, loss = 0.77122 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:11:09.257896 ops/training.py:65 2019-01-17 00:11:09.257786: step 1474, loss = 0.69910 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:11:10.541371 ops/training.py:65 2019-01-17 00:11:10.541271: step 1475, loss = 0.70145 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:11:11.834829 ops/training.py:65 2019-01-17 00:11:11.834728: step 1476, loss = 0.62616 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:11:13.124006 ops/training.py:65 2019-01-17 00:11:13.123899: step 1477, loss = 0.75126 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:11:14.415432 ops/training.py:65 2019-01-17 00:11:14.415274: step 1478, loss = 0.78030 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:11:15.707131 ops/training.py:65 2019-01-17 00:11:15.706979: step 1479, loss = 0.79098 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:11:16.998034 ops/training.py:65 2019-01-17 00:11:16.997947: step 1480, loss = 0.78461 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:11:18.283806 ops/training.py:65 2019-01-17 00:11:18.283731: step 1481, loss = 0.70711 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:11:19.566516 ops/training.py:65 2019-01-17 00:11:19.566418: step 1482, loss = 0.65826 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:11:20.858867 ops/training.py:65 2019-01-17 00:11:20.858764: step 1483, loss = 0.72992 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:11:22.145771 ops/training.py:65 2019-01-17 00:11:22.145621: step 1484, loss = 0.74298 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:11:23.425762 ops/training.py:65 2019-01-17 00:11:23.425665: step 1485, loss = 0.60570 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 00:11:24.719157 ops/training.py:65 2019-01-17 00:11:24.719055: step 1486, loss = 0.70205 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:11:26.010132 ops/training.py:65 2019-01-17 00:11:26.010034: step 1487, loss = 0.69430 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:11:27.301979 ops/training.py:65 2019-01-17 00:11:27.301897: step 1488, loss = 0.73326 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:11:28.591499 ops/training.py:65 2019-01-17 00:11:28.591391: step 1489, loss = 0.68367 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:11:29.882849 ops/training.py:65 2019-01-17 00:11:29.882739: step 1490, loss = 0.72410 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:11:31.169320 ops/training.py:65 2019-01-17 00:11:31.169170: step 1491, loss = 0.71011 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:11:32.460363 ops/training.py:65 2019-01-17 00:11:32.460255: step 1492, loss = 0.75481 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:11:33.749762 ops/training.py:65 2019-01-17 00:11:33.749618: step 1493, loss = 0.74625 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:11:35.037703 ops/training.py:65 2019-01-17 00:11:35.037608: step 1494, loss = 0.64530 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:11:36.326937 ops/training.py:65 2019-01-17 00:11:36.326834: step 1495, loss = 0.77615 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.21875
I4672 2019-01-17 00:11:37.616709 ops/training.py:65 2019-01-17 00:11:37.616610: step 1496, loss = 0.68845 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:11:38.906188 ops/training.py:65 2019-01-17 00:11:38.906031: step 1497, loss = 0.73121 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:11:40.190429 ops/training.py:65 2019-01-17 00:11:40.190273: step 1498, loss = 0.78135 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:11:41.471881 ops/training.py:65 2019-01-17 00:11:41.471771: step 1499, loss = 0.71309 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:11:42.755994 ops/training.py:65 2019-01-17 00:11:42.755837: step 1500, loss = 0.69954 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:11:44.038937 ops/training.py:65 2019-01-17 00:11:44.038831: step 1501, loss = 0.70111 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:11:45.325066 ops/training.py:65 2019-01-17 00:11:45.324962: step 1502, loss = 0.71908 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:11:46.606511 ops/training.py:65 2019-01-17 00:11:46.606378: step 1503, loss = 0.68848 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:11:47.895596 ops/training.py:65 2019-01-17 00:11:47.895457: step 1504, loss = 0.71501 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:11:49.181230 ops/training.py:65 2019-01-17 00:11:49.181081: step 1505, loss = 0.71751 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:11:50.467705 ops/training.py:65 2019-01-17 00:11:50.467607: step 1506, loss = 0.70310 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:11:51.748964 ops/training.py:65 2019-01-17 00:11:51.748912: step 1507, loss = 0.70826 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:11:53.030654 ops/training.py:65 2019-01-17 00:11:53.030584: step 1508, loss = 0.61680 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:11:54.315891 ops/training.py:65 2019-01-17 00:11:54.315796: step 1509, loss = 0.71715 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:11:55.605137 ops/training.py:65 2019-01-17 00:11:55.605046: step 1510, loss = 0.72059 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:11:56.885613 ops/training.py:65 2019-01-17 00:11:56.885521: step 1511, loss = 0.70053 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:11:58.170705 ops/training.py:65 2019-01-17 00:11:58.170620: step 1512, loss = 0.72184 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:11:59.456541 ops/training.py:65 2019-01-17 00:11:59.456468: step 1513, loss = 0.65177 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:12:00.739286 ops/training.py:65 2019-01-17 00:12:00.739254: step 1514, loss = 0.72458 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:12:02.030835 ops/training.py:65 2019-01-17 00:12:02.030805: step 1515, loss = 0.65787 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:12:03.314272 ops/training.py:65 2019-01-17 00:12:03.314237: step 1516, loss = 0.71240 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:12:04.605144 ops/training.py:65 2019-01-17 00:12:04.605113: step 1517, loss = 0.72673 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:12:05.895695 ops/training.py:65 2019-01-17 00:12:05.895645: step 1518, loss = 0.72488 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:12:07.183058 ops/training.py:65 2019-01-17 00:12:07.182985: step 1519, loss = 0.66810 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:12:08.466548 ops/training.py:65 2019-01-17 00:12:08.466514: step 1520, loss = 0.78385 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:12:09.759217 ops/training.py:65 2019-01-17 00:12:09.759111: step 1521, loss = 0.70398 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:12:11.047374 ops/training.py:65 2019-01-17 00:12:11.047279: step 1522, loss = 0.69726 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:12:12.331520 ops/training.py:65 2019-01-17 00:12:12.331450: step 1523, loss = 0.71258 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:12:13.622965 ops/training.py:65 2019-01-17 00:12:13.622879: step 1524, loss = 0.73147 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:12:14.911322 ops/training.py:65 2019-01-17 00:12:14.911234: step 1525, loss = 0.78513 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:12:16.196983 ops/training.py:65 2019-01-17 00:12:16.196909: step 1526, loss = 0.79501 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:12:17.480802 ops/training.py:65 2019-01-17 00:12:17.480652: step 1527, loss = 0.73467 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:12:18.771059 ops/training.py:65 2019-01-17 00:12:18.770952: step 1528, loss = 0.68101 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:12:20.056088 ops/training.py:65 2019-01-17 00:12:20.055989: step 1529, loss = 0.69446 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:12:21.340126 ops/training.py:65 2019-01-17 00:12:21.340015: step 1530, loss = 0.67591 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:12:22.620874 ops/training.py:65 2019-01-17 00:12:22.620774: step 1531, loss = 0.65965 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:12:23.911898 ops/training.py:65 2019-01-17 00:12:23.911791: step 1532, loss = 0.67639 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:12:25.203777 ops/training.py:65 2019-01-17 00:12:25.203627: step 1533, loss = 0.68961 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:12:26.491335 ops/training.py:65 2019-01-17 00:12:26.491229: step 1534, loss = 0.74843 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:12:27.774514 ops/training.py:65 2019-01-17 00:12:27.774406: step 1535, loss = 0.71839 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:12:29.061690 ops/training.py:65 2019-01-17 00:12:29.061589: step 1536, loss = 0.75174 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:12:30.346767 ops/training.py:65 2019-01-17 00:12:30.346672: step 1537, loss = 0.71334 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:12:31.639038 ops/training.py:65 2019-01-17 00:12:31.638940: step 1538, loss = 0.70602 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:12:32.927330 ops/training.py:65 2019-01-17 00:12:32.927244: step 1539, loss = 0.71621 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:12:34.218200 ops/training.py:65 2019-01-17 00:12:34.218052: step 1540, loss = 0.76412 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:12:35.510416 ops/training.py:65 2019-01-17 00:12:35.510326: step 1541, loss = 0.78555 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:12:36.801400 ops/training.py:65 2019-01-17 00:12:36.801303: step 1542, loss = 0.77696 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:12:38.087012 ops/training.py:65 2019-01-17 00:12:38.086941: step 1543, loss = 0.70599 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:12:39.377527 ops/training.py:65 2019-01-17 00:12:39.377386: step 1544, loss = 0.66317 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:12:40.668108 ops/training.py:65 2019-01-17 00:12:40.668007: step 1545, loss = 0.71772 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:12:41.953215 ops/training.py:65 2019-01-17 00:12:41.953110: step 1546, loss = 0.71226 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:12:43.234087 ops/training.py:65 2019-01-17 00:12:43.233989: step 1547, loss = 0.67664 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:12:44.517087 ops/training.py:65 2019-01-17 00:12:44.516981: step 1548, loss = 0.69467 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:12:45.807608 ops/training.py:65 2019-01-17 00:12:45.807471: step 1549, loss = 0.78791 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:12:47.092536 ops/training.py:65 2019-01-17 00:12:47.092440: step 1550, loss = 0.62634 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:12:48.382645 ops/training.py:65 2019-01-17 00:12:48.382538: step 1551, loss = 0.72907 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:12:49.671698 ops/training.py:65 2019-01-17 00:12:49.671618: step 1552, loss = 0.80221 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:12:50.958235 ops/training.py:65 2019-01-17 00:12:50.958168: step 1553, loss = 0.67432 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:12:52.247123 ops/training.py:65 2019-01-17 00:12:52.247047: step 1554, loss = 0.76449 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:12:53.536323 ops/training.py:65 2019-01-17 00:12:53.536250: step 1555, loss = 0.69921 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:12:54.823722 ops/training.py:65 2019-01-17 00:12:54.823625: step 1556, loss = 0.80985 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:12:56.111012 ops/training.py:65 2019-01-17 00:12:56.110974: step 1557, loss = 0.72421 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:12:57.394916 ops/training.py:65 2019-01-17 00:12:57.394876: step 1558, loss = 0.76581 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:12:58.684395 ops/training.py:65 2019-01-17 00:12:58.684354: step 1559, loss = 0.75561 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:12:59.972437 ops/training.py:65 2019-01-17 00:12:59.972352: step 1560, loss = 0.63657 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:13:01.256284 ops/training.py:65 2019-01-17 00:13:01.256215: step 1561, loss = 0.70424 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:13:02.541683 ops/training.py:65 2019-01-17 00:13:02.541581: step 1562, loss = 0.72949 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:13:03.827677 ops/training.py:65 2019-01-17 00:13:03.827570: step 1563, loss = 0.76320 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:13:05.108801 ops/training.py:65 2019-01-17 00:13:05.108728: step 1564, loss = 0.73902 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:13:06.387658 ops/training.py:65 2019-01-17 00:13:06.387610: step 1565, loss = 0.74553 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:13:07.672079 ops/training.py:65 2019-01-17 00:13:07.672005: step 1566, loss = 0.71873 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:13:08.999556 ops/training.py:65 2019-01-17 00:13:08.999465: step 1567, loss = 0.69195 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:13:10.283518 ops/training.py:65 2019-01-17 00:13:10.283445: step 1568, loss = 0.75501 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:13:11.573293 ops/training.py:65 2019-01-17 00:13:11.573186: step 1569, loss = 0.81950 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:13:12.856648 ops/training.py:65 2019-01-17 00:13:12.856543: step 1570, loss = 0.73861 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:13:14.145282 ops/training.py:65 2019-01-17 00:13:14.145191: step 1571, loss = 0.66955 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:13:15.433434 ops/training.py:65 2019-01-17 00:13:15.433334: step 1572, loss = 0.74274 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:13:16.716211 ops/training.py:65 2019-01-17 00:13:16.716145: step 1573, loss = 0.72480 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:13:17.994625 ops/training.py:65 2019-01-17 00:13:17.994546: step 1574, loss = 0.71552 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:13:19.276158 ops/training.py:65 2019-01-17 00:13:19.276095: step 1575, loss = 0.76672 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:13:20.559178 ops/training.py:65 2019-01-17 00:13:20.559140: step 1576, loss = 0.75811 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:13:21.852853 ops/training.py:65 2019-01-17 00:13:21.852806: step 1577, loss = 0.75043 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:13:23.145782 ops/training.py:65 2019-01-17 00:13:23.145711: step 1578, loss = 0.67255 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:13:28.515157 ops/training.py:65 2019-01-17 00:13:28.515078: step 1579, loss = 0.74400 (24.6 examples/sec; 1.299 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:13:29.797398 ops/training.py:65 2019-01-17 00:13:29.797297: step 1580, loss = 0.75664 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:13:31.076436 ops/training.py:65 2019-01-17 00:13:31.076331: step 1581, loss = 0.67919 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:13:32.361002 ops/training.py:65 2019-01-17 00:13:32.360889: step 1582, loss = 0.74801 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:13:33.648903 ops/training.py:65 2019-01-17 00:13:33.648796: step 1583, loss = 0.77358 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:13:34.929487 ops/training.py:65 2019-01-17 00:13:34.929390: step 1584, loss = 0.66826 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:13:36.212194 ops/training.py:65 2019-01-17 00:13:36.212089: step 1585, loss = 0.67451 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:13:37.491314 ops/training.py:65 2019-01-17 00:13:37.491203: step 1586, loss = 0.64271 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:13:38.774623 ops/training.py:65 2019-01-17 00:13:38.774519: step 1587, loss = 0.75446 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:13:40.055683 ops/training.py:65 2019-01-17 00:13:40.055571: step 1588, loss = 0.70773 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:13:41.341615 ops/training.py:65 2019-01-17 00:13:41.341504: step 1589, loss = 0.64327 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:13:42.623678 ops/training.py:65 2019-01-17 00:13:42.623571: step 1590, loss = 0.71316 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:13:43.913725 ops/training.py:65 2019-01-17 00:13:43.913628: step 1591, loss = 0.70310 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:13:45.199578 ops/training.py:65 2019-01-17 00:13:45.199475: step 1592, loss = 0.72533 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:13:46.489534 ops/training.py:65 2019-01-17 00:13:46.489428: step 1593, loss = 0.77865 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:13:47.776213 ops/training.py:65 2019-01-17 00:13:47.776099: step 1594, loss = 0.75350 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:13:49.062144 ops/training.py:65 2019-01-17 00:13:49.062020: step 1595, loss = 0.69857 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:13:50.353745 ops/training.py:65 2019-01-17 00:13:50.353651: step 1596, loss = 0.71479 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:13:51.642650 ops/training.py:65 2019-01-17 00:13:51.642553: step 1597, loss = 0.79286 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:13:52.932314 ops/training.py:65 2019-01-17 00:13:52.932224: step 1598, loss = 0.66340 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:13:54.219638 ops/training.py:65 2019-01-17 00:13:54.219533: step 1599, loss = 0.66385 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:13:55.504695 ops/training.py:65 2019-01-17 00:13:55.504602: step 1600, loss = 0.67444 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:13:56.788588 ops/training.py:65 2019-01-17 00:13:56.788491: step 1601, loss = 0.68090 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:13:58.074640 ops/training.py:65 2019-01-17 00:13:58.074541: step 1602, loss = 0.69238 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:13:59.364689 ops/training.py:65 2019-01-17 00:13:59.364581: step 1603, loss = 0.71952 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:14:00.645953 ops/training.py:65 2019-01-17 00:14:00.645889: step 1604, loss = 0.72445 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:14:01.930981 ops/training.py:65 2019-01-17 00:14:01.930876: step 1605, loss = 0.67513 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:14:03.215464 ops/training.py:65 2019-01-17 00:14:03.215370: step 1606, loss = 0.65904 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:14:04.500777 ops/training.py:65 2019-01-17 00:14:04.500676: step 1607, loss = 0.72381 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:14:05.789388 ops/training.py:65 2019-01-17 00:14:05.789278: step 1608, loss = 0.73506 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:14:07.079339 ops/training.py:65 2019-01-17 00:14:07.079234: step 1609, loss = 0.71891 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:14:08.366275 ops/training.py:65 2019-01-17 00:14:08.366176: step 1610, loss = 0.73226 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:14:09.649647 ops/training.py:65 2019-01-17 00:14:09.649538: step 1611, loss = 0.79452 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:14:10.937393 ops/training.py:65 2019-01-17 00:14:10.937293: step 1612, loss = 0.69678 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:14:12.221487 ops/training.py:65 2019-01-17 00:14:12.221380: step 1613, loss = 0.78137 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-17 00:14:13.513390 ops/training.py:65 2019-01-17 00:14:13.513284: step 1614, loss = 0.80620 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:14:14.797801 ops/training.py:65 2019-01-17 00:14:14.797701: step 1615, loss = 0.76052 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:14:16.078484 ops/training.py:65 2019-01-17 00:14:16.078371: step 1616, loss = 0.71645 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:14:17.371281 ops/training.py:65 2019-01-17 00:14:17.371128: step 1617, loss = 0.77682 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:14:18.660223 ops/training.py:65 2019-01-17 00:14:18.660122: step 1618, loss = 0.72573 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:14:19.947306 ops/training.py:65 2019-01-17 00:14:19.947244: step 1619, loss = 0.69093 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:14:21.235487 ops/training.py:65 2019-01-17 00:14:21.235379: step 1620, loss = 0.65751 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:14:22.521299 ops/training.py:65 2019-01-17 00:14:22.521191: step 1621, loss = 0.70969 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:14:23.804953 ops/training.py:65 2019-01-17 00:14:23.804846: step 1622, loss = 0.67019 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:14:25.091256 ops/training.py:65 2019-01-17 00:14:25.091149: step 1623, loss = 0.70240 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:14:26.376376 ops/training.py:65 2019-01-17 00:14:26.376272: step 1624, loss = 0.73687 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:14:27.664602 ops/training.py:65 2019-01-17 00:14:27.664500: step 1625, loss = 0.71384 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:14:28.948317 ops/training.py:65 2019-01-17 00:14:28.948215: step 1626, loss = 0.68617 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:14:30.235746 ops/training.py:65 2019-01-17 00:14:30.235642: step 1627, loss = 0.69454 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:14:31.519599 ops/training.py:65 2019-01-17 00:14:31.519488: step 1628, loss = 0.74692 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:14:32.805735 ops/training.py:65 2019-01-17 00:14:32.805631: step 1629, loss = 0.73558 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:14:34.090305 ops/training.py:65 2019-01-17 00:14:34.090197: step 1630, loss = 0.76743 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:14:35.377911 ops/training.py:65 2019-01-17 00:14:35.377816: step 1631, loss = 0.73049 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:14:36.662499 ops/training.py:65 2019-01-17 00:14:36.662395: step 1632, loss = 0.66082 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:14:37.945580 ops/training.py:65 2019-01-17 00:14:37.945482: step 1633, loss = 0.68630 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:14:39.238713 ops/training.py:65 2019-01-17 00:14:39.238559: step 1634, loss = 0.72524 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:14:40.525195 ops/training.py:65 2019-01-17 00:14:40.525092: step 1635, loss = 0.74724 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:14:41.808205 ops/training.py:65 2019-01-17 00:14:41.808095: step 1636, loss = 0.73727 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:14:43.093148 ops/training.py:65 2019-01-17 00:14:43.093052: step 1637, loss = 0.79572 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:14:44.382231 ops/training.py:65 2019-01-17 00:14:44.382123: step 1638, loss = 0.64968 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:14:45.665802 ops/training.py:65 2019-01-17 00:14:45.665739: step 1639, loss = 0.72319 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:14:46.950349 ops/training.py:65 2019-01-17 00:14:46.950240: step 1640, loss = 0.71150 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:14:48.242288 ops/training.py:65 2019-01-17 00:14:48.242180: step 1641, loss = 0.75884 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:14:49.527778 ops/training.py:65 2019-01-17 00:14:49.527682: step 1642, loss = 0.70793 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:14:50.816555 ops/training.py:65 2019-01-17 00:14:50.816447: step 1643, loss = 0.64863 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:14:52.100502 ops/training.py:65 2019-01-17 00:14:52.100398: step 1644, loss = 0.71265 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:14:53.388234 ops/training.py:65 2019-01-17 00:14:53.388138: step 1645, loss = 0.73740 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:14:54.671633 ops/training.py:65 2019-01-17 00:14:54.671526: step 1646, loss = 0.76052 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:14:55.963705 ops/training.py:65 2019-01-17 00:14:55.963595: step 1647, loss = 0.72698 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:14:57.253595 ops/training.py:65 2019-01-17 00:14:57.253514: step 1648, loss = 0.81299 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:14:58.537754 ops/training.py:65 2019-01-17 00:14:58.537685: step 1649, loss = 0.84809 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:14:59.828180 ops/training.py:65 2019-01-17 00:14:59.828095: step 1650, loss = 0.71412 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:15:01.112203 ops/training.py:65 2019-01-17 00:15:01.112128: step 1651, loss = 0.75827 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:15:02.396630 ops/training.py:65 2019-01-17 00:15:02.396547: step 1652, loss = 0.72444 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:15:03.683928 ops/training.py:65 2019-01-17 00:15:03.683823: step 1653, loss = 0.80716 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:15:04.964439 ops/training.py:65 2019-01-17 00:15:04.964346: step 1654, loss = 0.74249 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:15:06.254618 ops/training.py:65 2019-01-17 00:15:06.254461: step 1655, loss = 0.71945 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:15:07.544777 ops/training.py:65 2019-01-17 00:15:07.544637: step 1656, loss = 0.73772 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:15:08.835720 ops/training.py:65 2019-01-17 00:15:08.835611: step 1657, loss = 0.77032 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:15:10.121132 ops/training.py:65 2019-01-17 00:15:10.121056: step 1658, loss = 0.73160 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:15:11.402116 ops/training.py:65 2019-01-17 00:15:11.402017: step 1659, loss = 0.68190 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:15:12.689377 ops/training.py:65 2019-01-17 00:15:12.689274: step 1660, loss = 0.63572 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 00:15:13.971702 ops/training.py:65 2019-01-17 00:15:13.971569: step 1661, loss = 0.67524 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:15:15.255276 ops/training.py:65 2019-01-17 00:15:15.255176: step 1662, loss = 0.72274 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:15:16.538994 ops/training.py:65 2019-01-17 00:15:16.538885: step 1663, loss = 0.69214 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:15:17.823179 ops/training.py:65 2019-01-17 00:15:17.823071: step 1664, loss = 0.73843 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:15:19.107655 ops/training.py:65 2019-01-17 00:15:19.107551: step 1665, loss = 0.72873 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:15:20.397942 ops/training.py:65 2019-01-17 00:15:20.397854: step 1666, loss = 0.74729 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:15:21.679560 ops/training.py:65 2019-01-17 00:15:21.679460: step 1667, loss = 0.72841 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:15:22.962852 ops/training.py:65 2019-01-17 00:15:22.962745: step 1668, loss = 0.67963 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 00:15:24.256248 ops/training.py:65 2019-01-17 00:15:24.256105: step 1669, loss = 0.69124 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:15:25.549682 ops/training.py:65 2019-01-17 00:15:25.549579: step 1670, loss = 0.71195 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:15:26.838489 ops/training.py:65 2019-01-17 00:15:26.838392: step 1671, loss = 0.69473 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:15:28.126232 ops/training.py:65 2019-01-17 00:15:28.126144: step 1672, loss = 0.79975 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:15:29.409099 ops/training.py:65 2019-01-17 00:15:29.408950: step 1673, loss = 0.78026 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:15:30.701952 ops/training.py:65 2019-01-17 00:15:30.701854: step 1674, loss = 0.74175 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:15:31.991906 ops/training.py:65 2019-01-17 00:15:31.991805: step 1675, loss = 0.76926 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:15:33.283616 ops/training.py:65 2019-01-17 00:15:33.283519: step 1676, loss = 0.70885 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:15:34.572710 ops/training.py:65 2019-01-17 00:15:34.572616: step 1677, loss = 0.68090 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:15:35.862530 ops/training.py:65 2019-01-17 00:15:35.862423: step 1678, loss = 0.72546 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:15:37.151657 ops/training.py:65 2019-01-17 00:15:37.151554: step 1679, loss = 0.80601 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:15:38.432576 ops/training.py:65 2019-01-17 00:15:38.432508: step 1680, loss = 0.77910 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:15:39.713255 ops/training.py:65 2019-01-17 00:15:39.713187: step 1681, loss = 0.74023 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:15:40.996763 ops/training.py:65 2019-01-17 00:15:40.996696: step 1682, loss = 0.78484 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:15:42.286903 ops/training.py:65 2019-01-17 00:15:42.286805: step 1683, loss = 0.74451 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:15:43.576616 ops/training.py:65 2019-01-17 00:15:43.576520: step 1684, loss = 0.68947 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:15:44.863569 ops/training.py:65 2019-01-17 00:15:44.863462: step 1685, loss = 0.72338 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:15:46.147681 ops/training.py:65 2019-01-17 00:15:46.147572: step 1686, loss = 0.74584 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:15:47.433935 ops/training.py:65 2019-01-17 00:15:47.433780: step 1687, loss = 0.71983 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:15:48.714999 ops/training.py:65 2019-01-17 00:15:48.714892: step 1688, loss = 0.70018 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:15:50.006059 ops/training.py:65 2019-01-17 00:15:50.005961: step 1689, loss = 0.72181 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:15:51.292124 ops/training.py:65 2019-01-17 00:15:51.292019: step 1690, loss = 0.79140 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:15:52.583131 ops/training.py:65 2019-01-17 00:15:52.583022: step 1691, loss = 0.67340 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:15:53.867127 ops/training.py:65 2019-01-17 00:15:53.867049: step 1692, loss = 0.71717 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:15:55.154547 ops/training.py:65 2019-01-17 00:15:55.154438: step 1693, loss = 0.65436 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 00:15:56.438828 ops/training.py:65 2019-01-17 00:15:56.438721: step 1694, loss = 0.68527 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:15:57.721672 ops/training.py:65 2019-01-17 00:15:57.721564: step 1695, loss = 0.69952 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:15:59.003486 ops/training.py:65 2019-01-17 00:15:59.003380: step 1696, loss = 0.65446 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:16:00.282921 ops/training.py:65 2019-01-17 00:16:00.282766: step 1697, loss = 0.69023 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:16:01.563072 ops/training.py:65 2019-01-17 00:16:01.562964: step 1698, loss = 0.73590 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:16:02.842223 ops/training.py:65 2019-01-17 00:16:02.842077: step 1699, loss = 0.73188 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:16:04.126427 ops/training.py:65 2019-01-17 00:16:04.126328: step 1700, loss = 0.72085 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:16:05.414658 ops/training.py:65 2019-01-17 00:16:05.414559: step 1701, loss = 0.72408 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:16:06.704417 ops/training.py:65 2019-01-17 00:16:06.704317: step 1702, loss = 0.77146 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:16:07.989225 ops/training.py:65 2019-01-17 00:16:07.989121: step 1703, loss = 0.74017 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:16:09.277437 ops/training.py:65 2019-01-17 00:16:09.277331: step 1704, loss = 0.75580 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:16:10.563229 ops/training.py:65 2019-01-17 00:16:10.563128: step 1705, loss = 0.63295 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:16:11.847598 ops/training.py:65 2019-01-17 00:16:11.847449: step 1706, loss = 0.73515 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:16:13.131747 ops/training.py:65 2019-01-17 00:16:13.131643: step 1707, loss = 0.71541 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:16:14.416228 ops/training.py:65 2019-01-17 00:16:14.416120: step 1708, loss = 0.68304 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:16:15.706130 ops/training.py:65 2019-01-17 00:16:15.705972: step 1709, loss = 0.70924 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:16:16.992946 ops/training.py:65 2019-01-17 00:16:16.992837: step 1710, loss = 0.66940 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:16:18.279367 ops/training.py:65 2019-01-17 00:16:18.279266: step 1711, loss = 0.72992 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:16:19.563027 ops/training.py:65 2019-01-17 00:16:19.562937: step 1712, loss = 0.69628 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:16:20.855880 ops/training.py:65 2019-01-17 00:16:20.855771: step 1713, loss = 0.78077 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:16:22.139719 ops/training.py:65 2019-01-17 00:16:22.139649: step 1714, loss = 0.70482 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:16:23.428552 ops/training.py:65 2019-01-17 00:16:23.428483: step 1715, loss = 0.66420 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:16:24.713339 ops/training.py:65 2019-01-17 00:16:24.713241: step 1716, loss = 0.70247 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:16:25.998247 ops/training.py:65 2019-01-17 00:16:25.998165: step 1717, loss = 0.68555 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:16:27.279648 ops/training.py:65 2019-01-17 00:16:27.279545: step 1718, loss = 0.71756 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:16:28.567233 ops/training.py:65 2019-01-17 00:16:28.567127: step 1719, loss = 0.69588 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:16:29.856317 ops/training.py:65 2019-01-17 00:16:29.856213: step 1720, loss = 0.71029 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:16:31.141602 ops/training.py:65 2019-01-17 00:16:31.141501: step 1721, loss = 0.71876 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:16:32.429868 ops/training.py:65 2019-01-17 00:16:32.429759: step 1722, loss = 0.72569 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:16:33.713411 ops/training.py:65 2019-01-17 00:16:33.713304: step 1723, loss = 0.73560 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:16:34.997927 ops/training.py:65 2019-01-17 00:16:34.997829: step 1724, loss = 0.71887 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:16:36.279297 ops/training.py:65 2019-01-17 00:16:36.279190: step 1725, loss = 0.71210 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:16:37.559836 ops/training.py:65 2019-01-17 00:16:37.559731: step 1726, loss = 0.79062 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:16:38.841069 ops/training.py:65 2019-01-17 00:16:38.840959: step 1727, loss = 0.73937 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:16:40.121948 ops/training.py:65 2019-01-17 00:16:40.121839: step 1728, loss = 0.67116 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:16:41.406423 ops/training.py:65 2019-01-17 00:16:41.406320: step 1729, loss = 0.66604 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:16:42.690819 ops/training.py:65 2019-01-17 00:16:42.690717: step 1730, loss = 0.67451 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:16:43.971726 ops/training.py:65 2019-01-17 00:16:43.971628: step 1731, loss = 0.75029 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:16:45.256171 ops/training.py:65 2019-01-17 00:16:45.256063: step 1732, loss = 0.73495 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:16:46.547193 ops/training.py:65 2019-01-17 00:16:46.547089: step 1733, loss = 0.71793 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:16:47.832587 ops/training.py:65 2019-01-17 00:16:47.832477: step 1734, loss = 0.70240 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:16:49.116863 ops/training.py:65 2019-01-17 00:16:49.116753: step 1735, loss = 0.75466 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:16:50.401189 ops/training.py:65 2019-01-17 00:16:50.401089: step 1736, loss = 0.72654 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:16:51.688174 ops/training.py:65 2019-01-17 00:16:51.688068: step 1737, loss = 0.67549 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:16:52.969158 ops/training.py:65 2019-01-17 00:16:52.969049: step 1738, loss = 0.81952 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:16:54.252690 ops/training.py:65 2019-01-17 00:16:54.252551: step 1739, loss = 0.67564 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:16:55.532272 ops/training.py:65 2019-01-17 00:16:55.532172: step 1740, loss = 0.69742 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:16:56.814819 ops/training.py:65 2019-01-17 00:16:56.814721: step 1741, loss = 0.72075 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:16:58.099871 ops/training.py:65 2019-01-17 00:16:58.099776: step 1742, loss = 0.70727 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:16:59.388566 ops/training.py:65 2019-01-17 00:16:59.388458: step 1743, loss = 0.65266 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:17:00.672590 ops/training.py:65 2019-01-17 00:17:00.672479: step 1744, loss = 0.71577 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:17:01.958056 ops/training.py:65 2019-01-17 00:17:01.957949: step 1745, loss = 0.68925 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:17:03.243204 ops/training.py:65 2019-01-17 00:17:03.243104: step 1746, loss = 0.70469 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:17:04.527950 ops/training.py:65 2019-01-17 00:17:04.527841: step 1747, loss = 0.71317 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:17:05.813968 ops/training.py:65 2019-01-17 00:17:05.813825: step 1748, loss = 0.65203 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:17:07.096215 ops/training.py:65 2019-01-17 00:17:07.096106: step 1749, loss = 0.75892 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:17:08.379720 ops/training.py:65 2019-01-17 00:17:08.379562: step 1750, loss = 0.73128 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:17:09.659894 ops/training.py:65 2019-01-17 00:17:09.659801: step 1751, loss = 0.78656 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:17:10.941193 ops/training.py:65 2019-01-17 00:17:10.941098: step 1752, loss = 0.74955 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:17:12.222185 ops/training.py:65 2019-01-17 00:17:12.222090: step 1753, loss = 0.79876 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:17:13.502731 ops/training.py:65 2019-01-17 00:17:13.502630: step 1754, loss = 0.67609 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:17:14.787622 ops/training.py:65 2019-01-17 00:17:14.787512: step 1755, loss = 0.72366 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:17:16.068316 ops/training.py:65 2019-01-17 00:17:16.068207: step 1756, loss = 0.77674 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:17:17.346090 ops/training.py:65 2019-01-17 00:17:17.345992: step 1757, loss = 0.75656 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:17:18.623208 ops/training.py:65 2019-01-17 00:17:18.623098: step 1758, loss = 0.65763 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:17:19.911723 ops/training.py:65 2019-01-17 00:17:19.911641: step 1759, loss = 0.72061 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:17:21.201528 ops/training.py:65 2019-01-17 00:17:21.201424: step 1760, loss = 0.76197 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:17:22.485366 ops/training.py:65 2019-01-17 00:17:22.485245: step 1761, loss = 0.70869 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:17:23.766219 ops/training.py:65 2019-01-17 00:17:23.766120: step 1762, loss = 0.73873 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:17:25.047161 ops/training.py:65 2019-01-17 00:17:25.047060: step 1763, loss = 0.80645 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:17:26.330217 ops/training.py:65 2019-01-17 00:17:26.330121: step 1764, loss = 0.70259 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:17:27.615599 ops/training.py:65 2019-01-17 00:17:27.615500: step 1765, loss = 0.69665 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:17:28.902161 ops/training.py:65 2019-01-17 00:17:28.902060: step 1766, loss = 0.68585 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:17:30.188040 ops/training.py:65 2019-01-17 00:17:30.187934: step 1767, loss = 0.67322 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:17:31.476305 ops/training.py:65 2019-01-17 00:17:31.476193: step 1768, loss = 0.73538 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:17:32.756548 ops/training.py:65 2019-01-17 00:17:32.756448: step 1769, loss = 0.74863 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:17:34.039814 ops/training.py:65 2019-01-17 00:17:34.039740: step 1770, loss = 0.76688 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:17:35.326600 ops/training.py:65 2019-01-17 00:17:35.326505: step 1771, loss = 0.68250 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:17:36.604189 ops/training.py:65 2019-01-17 00:17:36.604082: step 1772, loss = 0.74639 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:17:37.891045 ops/training.py:65 2019-01-17 00:17:37.890946: step 1773, loss = 0.75987 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:17:39.173670 ops/training.py:65 2019-01-17 00:17:39.173573: step 1774, loss = 0.80134 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:17:40.464764 ops/training.py:65 2019-01-17 00:17:40.464662: step 1775, loss = 0.73348 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:17:41.753981 ops/training.py:65 2019-01-17 00:17:41.753882: step 1776, loss = 0.76098 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:17:43.038668 ops/training.py:65 2019-01-17 00:17:43.038563: step 1777, loss = 0.65898 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:17:44.328498 ops/training.py:65 2019-01-17 00:17:44.328396: step 1778, loss = 0.66495 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:17:45.613043 ops/training.py:65 2019-01-17 00:17:45.612938: step 1779, loss = 0.79319 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:17:46.896831 ops/training.py:65 2019-01-17 00:17:46.896720: step 1780, loss = 0.62940 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:17:48.183236 ops/training.py:65 2019-01-17 00:17:48.183131: step 1781, loss = 0.72683 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:17:49.471112 ops/training.py:65 2019-01-17 00:17:49.471009: step 1782, loss = 0.67299 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:17:50.753591 ops/training.py:65 2019-01-17 00:17:50.753500: step 1783, loss = 0.65690 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:17:52.037496 ops/training.py:65 2019-01-17 00:17:52.037395: step 1784, loss = 0.77564 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:17:53.322928 ops/training.py:65 2019-01-17 00:17:53.322828: step 1785, loss = 0.74339 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:17:54.612830 ops/training.py:65 2019-01-17 00:17:54.612726: step 1786, loss = 0.75029 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:17:55.898104 ops/training.py:65 2019-01-17 00:17:55.898005: step 1787, loss = 0.75275 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:17:57.181959 ops/training.py:65 2019-01-17 00:17:57.181858: step 1788, loss = 0.70753 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:17:58.466235 ops/training.py:65 2019-01-17 00:17:58.466122: step 1789, loss = 0.67633 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:17:59.751722 ops/training.py:65 2019-01-17 00:17:59.751621: step 1790, loss = 0.64308 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:18:01.036975 ops/training.py:65 2019-01-17 00:18:01.036873: step 1791, loss = 0.64920 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 00:18:02.318848 ops/training.py:65 2019-01-17 00:18:02.318749: step 1792, loss = 0.80190 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.25
I4672 2019-01-17 00:18:03.596580 ops/training.py:65 2019-01-17 00:18:03.596469: step 1793, loss = 0.67629 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:18:04.874660 ops/training.py:65 2019-01-17 00:18:04.874569: step 1794, loss = 0.66662 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:18:06.153283 ops/training.py:65 2019-01-17 00:18:06.153177: step 1795, loss = 0.72652 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:18:07.433432 ops/training.py:65 2019-01-17 00:18:07.433326: step 1796, loss = 0.74075 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:18:08.711867 ops/training.py:65 2019-01-17 00:18:08.711726: step 1797, loss = 0.70081 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:18:10.004189 ops/training.py:65 2019-01-17 00:18:10.004082: step 1798, loss = 0.70362 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:18:11.289264 ops/training.py:65 2019-01-17 00:18:11.289155: step 1799, loss = 0.74541 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:18:12.582591 ops/training.py:65 2019-01-17 00:18:12.582488: step 1800, loss = 0.70550 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:18:13.864708 ops/training.py:65 2019-01-17 00:18:13.864545: step 1801, loss = 0.70974 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:18:15.149888 ops/training.py:65 2019-01-17 00:18:15.149778: step 1802, loss = 0.73154 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:18:16.435845 ops/training.py:65 2019-01-17 00:18:16.435743: step 1803, loss = 0.72731 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:18:17.721715 ops/training.py:65 2019-01-17 00:18:17.721615: step 1804, loss = 0.77699 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:18:19.007515 ops/training.py:65 2019-01-17 00:18:19.007411: step 1805, loss = 0.70545 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:18:20.288362 ops/training.py:65 2019-01-17 00:18:20.288267: step 1806, loss = 0.69283 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:18:21.569343 ops/training.py:65 2019-01-17 00:18:21.569241: step 1807, loss = 0.74127 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:18:22.858257 ops/training.py:65 2019-01-17 00:18:22.858156: step 1808, loss = 0.74639 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:18:24.143015 ops/training.py:65 2019-01-17 00:18:24.142910: step 1809, loss = 0.67339 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:18:25.424028 ops/training.py:65 2019-01-17 00:18:25.423904: step 1810, loss = 0.76744 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:18:26.700130 ops/training.py:65 2019-01-17 00:18:26.700022: step 1811, loss = 0.73400 (25.1 examples/sec; 1.275 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:18:27.983439 ops/training.py:65 2019-01-17 00:18:27.983338: step 1812, loss = 0.73039 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:18:29.270493 ops/training.py:65 2019-01-17 00:18:29.270368: step 1813, loss = 0.68832 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:18:30.558721 ops/training.py:65 2019-01-17 00:18:30.558620: step 1814, loss = 0.72027 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:18:31.851406 ops/training.py:65 2019-01-17 00:18:31.851294: step 1815, loss = 0.74092 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:18:33.149735 ops/training.py:65 2019-01-17 00:18:33.149651: step 1816, loss = 0.78132 (24.7 examples/sec; 1.297 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:18:34.435770 ops/training.py:65 2019-01-17 00:18:34.435666: step 1817, loss = 0.76015 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:18:35.722531 ops/training.py:65 2019-01-17 00:18:35.722456: step 1818, loss = 0.77552 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:18:37.003157 ops/training.py:65 2019-01-17 00:18:37.003057: step 1819, loss = 0.68672 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:18:38.284035 ops/training.py:65 2019-01-17 00:18:38.283888: step 1820, loss = 0.71523 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:18:39.561257 ops/training.py:65 2019-01-17 00:18:39.561208: step 1821, loss = 0.70324 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:18:40.840191 ops/training.py:65 2019-01-17 00:18:40.840145: step 1822, loss = 0.71536 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:18:42.115384 ops/training.py:65 2019-01-17 00:18:42.115347: step 1823, loss = 0.71675 (25.1 examples/sec; 1.274 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:18:43.398484 ops/training.py:65 2019-01-17 00:18:43.398393: step 1824, loss = 0.65819 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:18:44.683608 ops/training.py:65 2019-01-17 00:18:44.683550: step 1825, loss = 0.72406 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:18:45.963777 ops/training.py:65 2019-01-17 00:18:45.963726: step 1826, loss = 0.72009 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:18:47.246620 ops/training.py:65 2019-01-17 00:18:47.246526: step 1827, loss = 0.77225 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:18:48.531184 ops/training.py:65 2019-01-17 00:18:48.531078: step 1828, loss = 0.65528 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:18:49.818557 ops/training.py:65 2019-01-17 00:18:49.818520: step 1829, loss = 0.69915 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:18:51.100191 ops/training.py:65 2019-01-17 00:18:51.100133: step 1830, loss = 0.65439 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:18:52.384609 ops/training.py:65 2019-01-17 00:18:52.384561: step 1831, loss = 0.69329 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:18:53.671410 ops/training.py:65 2019-01-17 00:18:53.671323: step 1832, loss = 0.72098 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:18:54.956428 ops/training.py:65 2019-01-17 00:18:54.956382: step 1833, loss = 0.69549 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:18:56.246247 ops/training.py:65 2019-01-17 00:18:56.246209: step 1834, loss = 0.77959 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:18:57.532839 ops/training.py:65 2019-01-17 00:18:57.532785: step 1835, loss = 0.67232 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:18:58.818079 ops/training.py:65 2019-01-17 00:18:58.818031: step 1836, loss = 0.66075 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:19:00.104505 ops/training.py:65 2019-01-17 00:19:00.104471: step 1837, loss = 0.70531 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:19:01.389693 ops/training.py:65 2019-01-17 00:19:01.389660: step 1838, loss = 0.67514 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:19:02.675969 ops/training.py:65 2019-01-17 00:19:02.675939: step 1839, loss = 0.72993 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:19:03.961895 ops/training.py:65 2019-01-17 00:19:03.961864: step 1840, loss = 0.65450 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:19:05.244045 ops/training.py:65 2019-01-17 00:19:05.244014: step 1841, loss = 0.73499 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:19:06.532150 ops/training.py:65 2019-01-17 00:19:06.532118: step 1842, loss = 0.68872 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:19:07.817795 ops/training.py:65 2019-01-17 00:19:07.817765: step 1843, loss = 0.67971 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:19:09.102135 ops/training.py:65 2019-01-17 00:19:09.102103: step 1844, loss = 0.69411 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:19:10.383215 ops/training.py:65 2019-01-17 00:19:10.383185: step 1845, loss = 0.64027 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:19:11.664254 ops/training.py:65 2019-01-17 00:19:11.664224: step 1846, loss = 0.67642 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:19:12.947875 ops/training.py:65 2019-01-17 00:19:12.947843: step 1847, loss = 0.67454 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:19:14.234473 ops/training.py:65 2019-01-17 00:19:14.234441: step 1848, loss = 0.67320 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:19:15.521810 ops/training.py:65 2019-01-17 00:19:15.521780: step 1849, loss = 0.68951 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:19:16.802822 ops/training.py:65 2019-01-17 00:19:16.802773: step 1850, loss = 0.71217 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:19:18.087902 ops/training.py:65 2019-01-17 00:19:18.087852: step 1851, loss = 0.70321 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:19:19.369202 ops/training.py:65 2019-01-17 00:19:19.369166: step 1852, loss = 0.68348 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:19:20.648583 ops/training.py:65 2019-01-17 00:19:20.648552: step 1853, loss = 0.71272 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:19:21.927851 ops/training.py:65 2019-01-17 00:19:21.927823: step 1854, loss = 0.69030 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:19:23.207677 ops/training.py:65 2019-01-17 00:19:23.207645: step 1855, loss = 0.72716 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:19:24.487971 ops/training.py:65 2019-01-17 00:19:24.487918: step 1856, loss = 0.68380 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:19:25.771742 ops/training.py:65 2019-01-17 00:19:25.771680: step 1857, loss = 0.76062 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:19:27.051069 ops/training.py:65 2019-01-17 00:19:27.051040: step 1858, loss = 0.70831 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:19:28.330275 ops/training.py:65 2019-01-17 00:19:28.330244: step 1859, loss = 0.72902 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:19:29.616553 ops/training.py:65 2019-01-17 00:19:29.616524: step 1860, loss = 0.67941 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:19:30.898924 ops/training.py:65 2019-01-17 00:19:30.898894: step 1861, loss = 0.73472 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:19:32.181800 ops/training.py:65 2019-01-17 00:19:32.181769: step 1862, loss = 0.67961 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:19:33.467189 ops/training.py:65 2019-01-17 00:19:33.467159: step 1863, loss = 0.70603 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:19:34.752893 ops/training.py:65 2019-01-17 00:19:34.752863: step 1864, loss = 0.72931 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:19:36.032220 ops/training.py:65 2019-01-17 00:19:36.032190: step 1865, loss = 0.75945 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:19:37.313532 ops/training.py:65 2019-01-17 00:19:37.313503: step 1866, loss = 0.70892 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:19:38.598922 ops/training.py:65 2019-01-17 00:19:38.598889: step 1867, loss = 0.70692 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:19:39.886328 ops/training.py:65 2019-01-17 00:19:39.886297: step 1868, loss = 0.67866 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:19:41.171455 ops/training.py:65 2019-01-17 00:19:41.171414: step 1869, loss = 0.70002 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:19:42.457087 ops/training.py:65 2019-01-17 00:19:42.457036: step 1870, loss = 0.68781 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:19:43.741560 ops/training.py:65 2019-01-17 00:19:43.741477: step 1871, loss = 0.67921 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:19:45.027186 ops/training.py:65 2019-01-17 00:19:45.027077: step 1872, loss = 0.76068 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:19:46.309024 ops/training.py:65 2019-01-17 00:19:46.308978: step 1873, loss = 0.69883 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:19:47.593373 ops/training.py:65 2019-01-17 00:19:47.593337: step 1874, loss = 0.66304 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:19:48.873617 ops/training.py:65 2019-01-17 00:19:48.873584: step 1875, loss = 0.76472 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:19:50.158166 ops/training.py:65 2019-01-17 00:19:50.158136: step 1876, loss = 0.70951 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:19:51.442224 ops/training.py:65 2019-01-17 00:19:51.442193: step 1877, loss = 0.73886 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:19:52.728857 ops/training.py:65 2019-01-17 00:19:52.728826: step 1878, loss = 0.72416 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:19:54.011638 ops/training.py:65 2019-01-17 00:19:54.011606: step 1879, loss = 0.72892 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:19:55.298743 ops/training.py:65 2019-01-17 00:19:55.298712: step 1880, loss = 0.68344 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:19:56.584020 ops/training.py:65 2019-01-17 00:19:56.583992: step 1881, loss = 0.72605 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:19:57.862929 ops/training.py:65 2019-01-17 00:19:57.862898: step 1882, loss = 0.76488 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:19:59.145049 ops/training.py:65 2019-01-17 00:19:59.145017: step 1883, loss = 0.67495 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:20:00.428921 ops/training.py:65 2019-01-17 00:20:00.428889: step 1884, loss = 0.63331 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:20:01.716674 ops/training.py:65 2019-01-17 00:20:01.716645: step 1885, loss = 0.77755 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-17 00:20:03.001650 ops/training.py:65 2019-01-17 00:20:03.001618: step 1886, loss = 0.67143 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:20:04.284197 ops/training.py:65 2019-01-17 00:20:04.284168: step 1887, loss = 0.76145 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:20:05.564955 ops/training.py:65 2019-01-17 00:20:05.564925: step 1888, loss = 0.69057 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:20:06.843446 ops/training.py:65 2019-01-17 00:20:06.843416: step 1889, loss = 0.70630 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:20:08.125070 ops/training.py:65 2019-01-17 00:20:08.125040: step 1890, loss = 0.70937 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:20:09.410649 ops/training.py:65 2019-01-17 00:20:09.410617: step 1891, loss = 0.74594 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:20:10.692528 ops/training.py:65 2019-01-17 00:20:10.692490: step 1892, loss = 0.71653 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:20:11.972786 ops/training.py:65 2019-01-17 00:20:11.972758: step 1893, loss = 0.71577 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:20:13.251513 ops/training.py:65 2019-01-17 00:20:13.251453: step 1894, loss = 0.67324 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:20:14.531594 ops/training.py:65 2019-01-17 00:20:14.531540: step 1895, loss = 0.76319 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:20:15.810397 ops/training.py:65 2019-01-17 00:20:15.810341: step 1896, loss = 0.72603 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:20:17.089645 ops/training.py:65 2019-01-17 00:20:17.089610: step 1897, loss = 0.82044 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:20:18.369798 ops/training.py:65 2019-01-17 00:20:18.369753: step 1898, loss = 0.73653 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:20:19.650371 ops/training.py:65 2019-01-17 00:20:19.650319: step 1899, loss = 0.73402 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:20:20.933026 ops/training.py:65 2019-01-17 00:20:20.932953: step 1900, loss = 0.67857 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:20:22.218470 ops/training.py:65 2019-01-17 00:20:22.218370: step 1901, loss = 0.70435 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:20:23.501468 ops/training.py:65 2019-01-17 00:20:23.501410: step 1902, loss = 0.71078 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:20:24.784351 ops/training.py:65 2019-01-17 00:20:24.784297: step 1903, loss = 0.66351 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:20:26.073399 ops/training.py:65 2019-01-17 00:20:26.073301: step 1904, loss = 0.76339 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:20:27.358286 ops/training.py:65 2019-01-17 00:20:27.358175: step 1905, loss = 0.69807 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:20:28.640471 ops/training.py:65 2019-01-17 00:20:28.640362: step 1906, loss = 0.69635 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:20:29.920225 ops/training.py:65 2019-01-17 00:20:29.920105: step 1907, loss = 0.67511 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:20:31.204773 ops/training.py:65 2019-01-17 00:20:31.204657: step 1908, loss = 0.67468 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:20:32.495806 ops/training.py:65 2019-01-17 00:20:32.495695: step 1909, loss = 0.71006 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:20:33.776020 ops/training.py:65 2019-01-17 00:20:33.775912: step 1910, loss = 0.70121 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:20:35.062000 ops/training.py:65 2019-01-17 00:20:35.061888: step 1911, loss = 0.70271 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:20:36.347160 ops/training.py:65 2019-01-17 00:20:36.347043: step 1912, loss = 0.74768 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:20:37.629356 ops/training.py:65 2019-01-17 00:20:37.629249: step 1913, loss = 0.70386 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:20:38.914881 ops/training.py:65 2019-01-17 00:20:38.914762: step 1914, loss = 0.68050 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:20:40.199705 ops/training.py:65 2019-01-17 00:20:40.199597: step 1915, loss = 0.63877 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:20:41.484974 ops/training.py:65 2019-01-17 00:20:41.484860: step 1916, loss = 0.70141 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:20:42.768064 ops/training.py:65 2019-01-17 00:20:42.767950: step 1917, loss = 0.74449 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:20:44.047823 ops/training.py:65 2019-01-17 00:20:44.047706: step 1918, loss = 0.69025 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:20:45.328143 ops/training.py:65 2019-01-17 00:20:45.328035: step 1919, loss = 0.69685 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:20:46.606383 ops/training.py:65 2019-01-17 00:20:46.606273: step 1920, loss = 0.76129 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:20:47.889838 ops/training.py:65 2019-01-17 00:20:47.889726: step 1921, loss = 0.76868 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:20:49.171091 ops/training.py:65 2019-01-17 00:20:49.170983: step 1922, loss = 0.67552 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:20:50.450490 ops/training.py:65 2019-01-17 00:20:50.450394: step 1923, loss = 0.82471 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:20:51.731142 ops/training.py:65 2019-01-17 00:20:51.731033: step 1924, loss = 0.76768 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:20:53.011052 ops/training.py:65 2019-01-17 00:20:53.010949: step 1925, loss = 0.72592 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:20:54.293915 ops/training.py:65 2019-01-17 00:20:54.293805: step 1926, loss = 0.76007 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:20:55.580406 ops/training.py:65 2019-01-17 00:20:55.580294: step 1927, loss = 0.74173 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:20:56.867009 ops/training.py:65 2019-01-17 00:20:56.866897: step 1928, loss = 0.66585 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:20:58.154971 ops/training.py:65 2019-01-17 00:20:58.154854: step 1929, loss = 0.70464 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:20:59.452170 ops/training.py:65 2019-01-17 00:20:59.452038: step 1930, loss = 0.70699 (24.7 examples/sec; 1.296 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:21:00.739245 ops/training.py:65 2019-01-17 00:21:00.739128: step 1931, loss = 0.71189 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:21:02.026764 ops/training.py:65 2019-01-17 00:21:02.026654: step 1932, loss = 0.69827 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:21:03.312616 ops/training.py:65 2019-01-17 00:21:03.312480: step 1933, loss = 0.72658 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:21:04.596733 ops/training.py:65 2019-01-17 00:21:04.596623: step 1934, loss = 0.64218 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:21:05.877196 ops/training.py:65 2019-01-17 00:21:05.877050: step 1935, loss = 0.65052 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:21:07.160601 ops/training.py:65 2019-01-17 00:21:07.160490: step 1936, loss = 0.71985 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:21:08.444691 ops/training.py:65 2019-01-17 00:21:08.444581: step 1937, loss = 0.71853 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:21:09.729510 ops/training.py:65 2019-01-17 00:21:09.729399: step 1938, loss = 0.78103 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:21:11.019987 ops/training.py:65 2019-01-17 00:21:11.019861: step 1939, loss = 0.71985 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:21:12.308438 ops/training.py:65 2019-01-17 00:21:12.308351: step 1940, loss = 0.64868 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 00:21:13.591384 ops/training.py:65 2019-01-17 00:21:13.591317: step 1941, loss = 0.65680 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 00:21:14.873203 ops/training.py:65 2019-01-17 00:21:14.873095: step 1942, loss = 0.78762 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:21:16.163423 ops/training.py:65 2019-01-17 00:21:16.163305: step 1943, loss = 0.73093 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:21:17.445367 ops/training.py:65 2019-01-17 00:21:17.445250: step 1944, loss = 0.72989 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:21:18.729365 ops/training.py:65 2019-01-17 00:21:18.729254: step 1945, loss = 0.66731 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:21:20.005935 ops/training.py:65 2019-01-17 00:21:20.005826: step 1946, loss = 0.75432 (25.1 examples/sec; 1.275 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:21:21.288407 ops/training.py:65 2019-01-17 00:21:21.288251: step 1947, loss = 0.74157 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:21:22.574175 ops/training.py:65 2019-01-17 00:21:22.574072: step 1948, loss = 0.70324 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:21:23.859379 ops/training.py:65 2019-01-17 00:21:23.859269: step 1949, loss = 0.61946 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:21:25.146539 ops/training.py:65 2019-01-17 00:21:25.146371: step 1950, loss = 0.75012 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:21:26.429916 ops/training.py:65 2019-01-17 00:21:26.429802: step 1951, loss = 0.67156 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:21:27.714578 ops/training.py:65 2019-01-17 00:21:27.714466: step 1952, loss = 0.70921 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:21:28.995493 ops/training.py:65 2019-01-17 00:21:28.995383: step 1953, loss = 0.68423 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:21:30.280554 ops/training.py:65 2019-01-17 00:21:30.280444: step 1954, loss = 0.74574 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:21:31.571924 ops/training.py:65 2019-01-17 00:21:31.571818: step 1955, loss = 0.64195 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 00:21:32.856723 ops/training.py:65 2019-01-17 00:21:32.856649: step 1956, loss = 0.66619 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:21:34.141950 ops/training.py:65 2019-01-17 00:21:34.141808: step 1957, loss = 0.75978 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:21:35.426397 ops/training.py:65 2019-01-17 00:21:35.426293: step 1958, loss = 0.69644 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:21:36.706409 ops/training.py:65 2019-01-17 00:21:36.706301: step 1959, loss = 0.74754 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:21:37.993791 ops/training.py:65 2019-01-17 00:21:37.993675: step 1960, loss = 0.76831 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:21:39.275225 ops/training.py:65 2019-01-17 00:21:39.275116: step 1961, loss = 0.74932 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:21:40.559350 ops/training.py:65 2019-01-17 00:21:40.559239: step 1962, loss = 0.71527 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:21:41.839082 ops/training.py:65 2019-01-17 00:21:41.838967: step 1963, loss = 0.75825 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:21:43.118108 ops/training.py:65 2019-01-17 00:21:43.117993: step 1964, loss = 0.67258 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:21:44.400896 ops/training.py:65 2019-01-17 00:21:44.400792: step 1965, loss = 0.77638 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:21:45.680257 ops/training.py:65 2019-01-17 00:21:45.680141: step 1966, loss = 0.69850 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:21:46.964035 ops/training.py:65 2019-01-17 00:21:46.963936: step 1967, loss = 0.72433 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:21:48.250579 ops/training.py:65 2019-01-17 00:21:48.250474: step 1968, loss = 0.68911 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:21:49.539985 ops/training.py:65 2019-01-17 00:21:49.539858: step 1969, loss = 0.73601 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:21:50.826078 ops/training.py:65 2019-01-17 00:21:50.825950: step 1970, loss = 0.80662 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:21:52.111647 ops/training.py:65 2019-01-17 00:21:52.111546: step 1971, loss = 0.73466 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:21:53.396414 ops/training.py:65 2019-01-17 00:21:53.396253: step 1972, loss = 0.75493 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:21:54.683691 ops/training.py:65 2019-01-17 00:21:54.683580: step 1973, loss = 0.67961 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:21:55.965565 ops/training.py:65 2019-01-17 00:21:55.965481: step 1974, loss = 0.63399 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:21:57.253918 ops/training.py:65 2019-01-17 00:21:57.253808: step 1975, loss = 0.74655 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:21:58.539730 ops/training.py:65 2019-01-17 00:21:58.539622: step 1976, loss = 0.68438 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:21:59.824415 ops/training.py:65 2019-01-17 00:21:59.824305: step 1977, loss = 0.68630 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:22:01.112096 ops/training.py:65 2019-01-17 00:22:01.111987: step 1978, loss = 0.72624 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:22:02.401681 ops/training.py:65 2019-01-17 00:22:02.401578: step 1979, loss = 0.72230 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:22:03.686605 ops/training.py:65 2019-01-17 00:22:03.686497: step 1980, loss = 0.76415 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:22:04.973384 ops/training.py:65 2019-01-17 00:22:04.973287: step 1981, loss = 0.69574 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:22:06.252153 ops/training.py:65 2019-01-17 00:22:06.252042: step 1982, loss = 0.67912 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:22:07.532454 ops/training.py:65 2019-01-17 00:22:07.532345: step 1983, loss = 0.72684 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:22:08.819843 ops/training.py:65 2019-01-17 00:22:08.819731: step 1984, loss = 0.69110 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:22:10.106231 ops/training.py:65 2019-01-17 00:22:10.106121: step 1985, loss = 0.68996 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:22:11.394688 ops/training.py:65 2019-01-17 00:22:11.394577: step 1986, loss = 0.67661 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:22:12.680162 ops/training.py:65 2019-01-17 00:22:12.680056: step 1987, loss = 0.76202 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:22:13.969066 ops/training.py:65 2019-01-17 00:22:13.968960: step 1988, loss = 0.69539 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:22:15.256382 ops/training.py:65 2019-01-17 00:22:15.256270: step 1989, loss = 0.79516 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:22:16.537985 ops/training.py:65 2019-01-17 00:22:16.537878: step 1990, loss = 0.74968 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:22:17.820448 ops/training.py:65 2019-01-17 00:22:17.820335: step 1991, loss = 0.67850 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:22:19.104238 ops/training.py:65 2019-01-17 00:22:19.104153: step 1992, loss = 0.71703 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:22:20.387151 ops/training.py:65 2019-01-17 00:22:20.387007: step 1993, loss = 0.72158 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:22:21.678450 ops/training.py:65 2019-01-17 00:22:21.678350: step 1994, loss = 0.70358 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:22:22.970136 ops/training.py:65 2019-01-17 00:22:22.970039: step 1995, loss = 0.65001 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:22:24.255952 ops/training.py:65 2019-01-17 00:22:24.255874: step 1996, loss = 0.70917 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:22:25.541113 ops/training.py:65 2019-01-17 00:22:25.541006: step 1997, loss = 0.70986 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:22:26.821801 ops/training.py:65 2019-01-17 00:22:26.821690: step 1998, loss = 0.71918 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:22:28.100622 ops/training.py:65 2019-01-17 00:22:28.100520: step 1999, loss = 0.65955 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:28:32.218253 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I4672 2019-01-17 00:28:32.219485 ops/training.py:41 2019-01-17 00:28:32.219298: step 2000, loss = 0.75 (0.1 examples/sec; 362.838 sec/batch) | Training accuracy = 0.5 | Validation accuracy = 0.5087 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_23_33_01_706250
I4672 2019-01-17 00:28:33.507221 ops/training.py:65 2019-01-17 00:28:33.507116: step 2001, loss = 0.66252 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:28:34.788490 ops/training.py:65 2019-01-17 00:28:34.788371: step 2002, loss = 0.71898 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:28:36.100124 ops/training.py:65 2019-01-17 00:28:36.100017: step 2003, loss = 0.73679 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:28:37.384595 ops/training.py:65 2019-01-17 00:28:37.384445: step 2004, loss = 0.78802 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:28:38.669635 ops/training.py:65 2019-01-17 00:28:38.669518: step 2005, loss = 0.66293 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:28:39.955585 ops/training.py:65 2019-01-17 00:28:39.955487: step 2006, loss = 0.75823 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:28:41.235073 ops/training.py:65 2019-01-17 00:28:41.234982: step 2007, loss = 0.69815 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:28:42.524580 ops/training.py:65 2019-01-17 00:28:42.524505: step 2008, loss = 0.76567 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:28:43.813455 ops/training.py:65 2019-01-17 00:28:43.813377: step 2009, loss = 0.68808 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:28:45.098219 ops/training.py:65 2019-01-17 00:28:45.098155: step 2010, loss = 0.73971 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:28:46.383248 ops/training.py:65 2019-01-17 00:28:46.383149: step 2011, loss = 0.70228 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:28:47.667015 ops/training.py:65 2019-01-17 00:28:47.666928: step 2012, loss = 0.72163 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:28:48.957747 ops/training.py:65 2019-01-17 00:28:48.957628: step 2013, loss = 0.67424 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:28:50.244477 ops/training.py:65 2019-01-17 00:28:50.244406: step 2014, loss = 0.68157 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:28:51.528923 ops/training.py:65 2019-01-17 00:28:51.528822: step 2015, loss = 0.78315 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:28:52.815986 ops/training.py:65 2019-01-17 00:28:52.815904: step 2016, loss = 0.75553 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:28:54.100760 ops/training.py:65 2019-01-17 00:28:54.100657: step 2017, loss = 0.75502 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:28:55.386838 ops/training.py:65 2019-01-17 00:28:55.386724: step 2018, loss = 0.72587 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:28:56.670383 ops/training.py:65 2019-01-17 00:28:56.670351: step 2019, loss = 0.71951 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:28:57.959849 ops/training.py:65 2019-01-17 00:28:57.959814: step 2020, loss = 0.80210 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:28:59.245772 ops/training.py:65 2019-01-17 00:28:59.245686: step 2021, loss = 0.73785 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:29:00.536321 ops/training.py:65 2019-01-17 00:29:00.536271: step 2022, loss = 0.71143 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:29:01.817486 ops/training.py:65 2019-01-17 00:29:01.817375: step 2023, loss = 0.73054 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:29:03.102937 ops/training.py:65 2019-01-17 00:29:03.102833: step 2024, loss = 0.77566 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:29:04.385561 ops/training.py:65 2019-01-17 00:29:04.385454: step 2025, loss = 0.76848 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:29:05.676857 ops/training.py:65 2019-01-17 00:29:05.676750: step 2026, loss = 0.76111 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:29:06.964971 ops/training.py:65 2019-01-17 00:29:06.964900: step 2027, loss = 0.79716 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:29:08.248876 ops/training.py:65 2019-01-17 00:29:08.248759: step 2028, loss = 0.71221 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:29:09.541854 ops/training.py:65 2019-01-17 00:29:09.541748: step 2029, loss = 0.71347 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:29:10.832754 ops/training.py:65 2019-01-17 00:29:10.832639: step 2030, loss = 0.81003 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:29:12.126554 ops/training.py:65 2019-01-17 00:29:12.126466: step 2031, loss = 0.72761 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:29:13.414115 ops/training.py:65 2019-01-17 00:29:13.414032: step 2032, loss = 0.80418 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:29:14.695424 ops/training.py:65 2019-01-17 00:29:14.695303: step 2033, loss = 0.80854 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:29:15.986883 ops/training.py:65 2019-01-17 00:29:15.986734: step 2034, loss = 0.70063 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:29:17.278238 ops/training.py:65 2019-01-17 00:29:17.278120: step 2035, loss = 0.78663 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:29:18.569862 ops/training.py:65 2019-01-17 00:29:18.569773: step 2036, loss = 0.77800 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:29:19.855729 ops/training.py:65 2019-01-17 00:29:19.855653: step 2037, loss = 0.68185 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:29:21.146655 ops/training.py:65 2019-01-17 00:29:21.146523: step 2038, loss = 0.75418 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:29:22.434480 ops/training.py:65 2019-01-17 00:29:22.434404: step 2039, loss = 0.69359 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:29:23.718183 ops/training.py:65 2019-01-17 00:29:23.718083: step 2040, loss = 0.80495 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:29:25.006019 ops/training.py:65 2019-01-17 00:29:25.005907: step 2041, loss = 0.74592 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:29:26.290626 ops/training.py:65 2019-01-17 00:29:26.290475: step 2042, loss = 0.75779 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:29:27.572504 ops/training.py:65 2019-01-17 00:29:27.572391: step 2043, loss = 0.68598 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:29:28.864180 ops/training.py:65 2019-01-17 00:29:28.864077: step 2044, loss = 0.67348 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:29:30.150699 ops/training.py:65 2019-01-17 00:29:30.150632: step 2045, loss = 0.70129 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:29:31.434346 ops/training.py:65 2019-01-17 00:29:31.434235: step 2046, loss = 0.68976 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:29:32.727731 ops/training.py:65 2019-01-17 00:29:32.727626: step 2047, loss = 0.71748 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:29:34.019097 ops/training.py:65 2019-01-17 00:29:34.018992: step 2048, loss = 0.74179 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:29:35.306487 ops/training.py:65 2019-01-17 00:29:35.306399: step 2049, loss = 0.66147 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:29:36.592006 ops/training.py:65 2019-01-17 00:29:36.591902: step 2050, loss = 0.74434 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:29:37.883102 ops/training.py:65 2019-01-17 00:29:37.882998: step 2051, loss = 0.58433 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 00:29:39.167817 ops/training.py:65 2019-01-17 00:29:39.167740: step 2052, loss = 0.75007 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:29:40.448107 ops/training.py:65 2019-01-17 00:29:40.448001: step 2053, loss = 0.78176 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:29:41.738564 ops/training.py:65 2019-01-17 00:29:41.738449: step 2054, loss = 0.75737 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:29:43.029223 ops/training.py:65 2019-01-17 00:29:43.029108: step 2055, loss = 0.66121 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:29:44.319528 ops/training.py:65 2019-01-17 00:29:44.319434: step 2056, loss = 0.66711 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:29:45.605846 ops/training.py:65 2019-01-17 00:29:45.605782: step 2057, loss = 0.67061 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:29:46.889982 ops/training.py:65 2019-01-17 00:29:46.889865: step 2058, loss = 0.70193 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:29:48.170894 ops/training.py:65 2019-01-17 00:29:48.170779: step 2059, loss = 0.64865 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:29:49.453040 ops/training.py:65 2019-01-17 00:29:49.452928: step 2060, loss = 0.75951 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:29:50.740926 ops/training.py:65 2019-01-17 00:29:50.740829: step 2061, loss = 0.62697 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:29:52.034099 ops/training.py:65 2019-01-17 00:29:52.033985: step 2062, loss = 0.75147 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:29:53.325882 ops/training.py:65 2019-01-17 00:29:53.325769: step 2063, loss = 0.73505 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:29:54.614629 ops/training.py:65 2019-01-17 00:29:54.614543: step 2064, loss = 0.72860 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:29:55.899559 ops/training.py:65 2019-01-17 00:29:55.899452: step 2065, loss = 0.76542 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:29:57.188005 ops/training.py:65 2019-01-17 00:29:57.187886: step 2066, loss = 0.76590 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:29:58.473244 ops/training.py:65 2019-01-17 00:29:58.473147: step 2067, loss = 0.68467 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:29:59.764456 ops/training.py:65 2019-01-17 00:29:59.764346: step 2068, loss = 0.66152 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:30:01.053650 ops/training.py:65 2019-01-17 00:30:01.053541: step 2069, loss = 0.74843 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:30:02.339258 ops/training.py:65 2019-01-17 00:30:02.339171: step 2070, loss = 0.74166 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:30:03.629991 ops/training.py:65 2019-01-17 00:30:03.629894: step 2071, loss = 0.72831 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:30:04.913372 ops/training.py:65 2019-01-17 00:30:04.913292: step 2072, loss = 0.68290 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:30:06.197768 ops/training.py:65 2019-01-17 00:30:06.197670: step 2073, loss = 0.73912 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:30:07.487086 ops/training.py:65 2019-01-17 00:30:07.486971: step 2074, loss = 0.73924 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:30:08.774587 ops/training.py:65 2019-01-17 00:30:08.774467: step 2075, loss = 0.73576 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:30:10.058474 ops/training.py:65 2019-01-17 00:30:10.058368: step 2076, loss = 0.67656 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:30:11.345000 ops/training.py:65 2019-01-17 00:30:11.344896: step 2077, loss = 0.67688 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:30:12.629254 ops/training.py:65 2019-01-17 00:30:12.629139: step 2078, loss = 0.71380 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:30:13.920425 ops/training.py:65 2019-01-17 00:30:13.920321: step 2079, loss = 0.72209 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:30:15.204250 ops/training.py:65 2019-01-17 00:30:15.204179: step 2080, loss = 0.70099 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:30:16.489323 ops/training.py:65 2019-01-17 00:30:16.489208: step 2081, loss = 0.73075 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:30:17.774165 ops/training.py:65 2019-01-17 00:30:17.774049: step 2082, loss = 0.72512 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:30:19.060896 ops/training.py:65 2019-01-17 00:30:19.060790: step 2083, loss = 0.69937 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:30:20.346160 ops/training.py:65 2019-01-17 00:30:20.346049: step 2084, loss = 0.77150 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:30:21.637255 ops/training.py:65 2019-01-17 00:30:21.637158: step 2085, loss = 0.71303 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:30:22.928465 ops/training.py:65 2019-01-17 00:30:22.928362: step 2086, loss = 0.64230 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:30:24.215060 ops/training.py:65 2019-01-17 00:30:24.214987: step 2087, loss = 0.76545 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:30:25.504672 ops/training.py:65 2019-01-17 00:30:25.504576: step 2088, loss = 0.72088 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:30:26.794449 ops/training.py:65 2019-01-17 00:30:26.794379: step 2089, loss = 0.69968 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:30:28.084109 ops/training.py:65 2019-01-17 00:30:28.084027: step 2090, loss = 0.66465 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:30:29.366849 ops/training.py:65 2019-01-17 00:30:29.366784: step 2091, loss = 0.73361 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:30:30.653116 ops/training.py:65 2019-01-17 00:30:30.653037: step 2092, loss = 0.70982 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:30:31.938626 ops/training.py:65 2019-01-17 00:30:31.938535: step 2093, loss = 0.81772 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:30:33.223743 ops/training.py:65 2019-01-17 00:30:33.223636: step 2094, loss = 0.78451 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:30:34.505092 ops/training.py:65 2019-01-17 00:30:34.504981: step 2095, loss = 0.69165 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:30:35.789312 ops/training.py:65 2019-01-17 00:30:35.789208: step 2096, loss = 0.70114 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:30:37.068015 ops/training.py:65 2019-01-17 00:30:37.067910: step 2097, loss = 0.67070 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:30:38.359457 ops/training.py:65 2019-01-17 00:30:38.359350: step 2098, loss = 0.72340 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:30:39.642211 ops/training.py:65 2019-01-17 00:30:39.642178: step 2099, loss = 0.77598 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:30:40.922682 ops/training.py:65 2019-01-17 00:30:40.922628: step 2100, loss = 0.62221 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 00:30:42.198594 ops/training.py:65 2019-01-17 00:30:42.198532: step 2101, loss = 0.77274 (25.1 examples/sec; 1.275 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:30:43.479838 ops/training.py:65 2019-01-17 00:30:43.479735: step 2102, loss = 0.71254 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:30:44.764607 ops/training.py:65 2019-01-17 00:30:44.764496: step 2103, loss = 0.71318 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:30:46.050013 ops/training.py:65 2019-01-17 00:30:46.049980: step 2104, loss = 0.71094 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:30:47.340472 ops/training.py:65 2019-01-17 00:30:47.340440: step 2105, loss = 0.72565 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:30:48.634266 ops/training.py:65 2019-01-17 00:30:48.634225: step 2106, loss = 0.71347 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:30:49.922547 ops/training.py:65 2019-01-17 00:30:49.922513: step 2107, loss = 0.63563 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:30:51.208897 ops/training.py:65 2019-01-17 00:30:51.208865: step 2108, loss = 0.66393 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:30:52.494747 ops/training.py:65 2019-01-17 00:30:52.494670: step 2109, loss = 0.72829 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:30:53.780209 ops/training.py:65 2019-01-17 00:30:53.780098: step 2110, loss = 0.75146 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:30:55.063246 ops/training.py:65 2019-01-17 00:30:55.063133: step 2111, loss = 0.79125 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:30:56.355823 ops/training.py:65 2019-01-17 00:30:56.355728: step 2112, loss = 0.64110 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:30:57.643353 ops/training.py:65 2019-01-17 00:30:57.643280: step 2113, loss = 0.71199 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:30:58.926947 ops/training.py:65 2019-01-17 00:30:58.926888: step 2114, loss = 0.65010 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:31:00.209085 ops/training.py:65 2019-01-17 00:31:00.209054: step 2115, loss = 0.72912 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:31:01.497557 ops/training.py:65 2019-01-17 00:31:01.497495: step 2116, loss = 0.69401 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:31:02.782677 ops/training.py:65 2019-01-17 00:31:02.782645: step 2117, loss = 0.74734 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:31:04.066867 ops/training.py:65 2019-01-17 00:31:04.066816: step 2118, loss = 0.69759 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:31:05.355754 ops/training.py:65 2019-01-17 00:31:05.355725: step 2119, loss = 0.69028 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:31:06.647039 ops/training.py:65 2019-01-17 00:31:06.647009: step 2120, loss = 0.74858 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:31:07.938395 ops/training.py:65 2019-01-17 00:31:07.938365: step 2121, loss = 0.68793 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:31:09.229837 ops/training.py:65 2019-01-17 00:31:09.229808: step 2122, loss = 0.66698 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:31:10.513474 ops/training.py:65 2019-01-17 00:31:10.513444: step 2123, loss = 0.67215 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:31:11.801475 ops/training.py:65 2019-01-17 00:31:11.801444: step 2124, loss = 0.64746 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 00:31:13.085988 ops/training.py:65 2019-01-17 00:31:13.085896: step 2125, loss = 0.70372 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:31:14.375293 ops/training.py:65 2019-01-17 00:31:14.375186: step 2126, loss = 0.67856 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:31:15.663902 ops/training.py:65 2019-01-17 00:31:15.663826: step 2127, loss = 0.66122 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 00:31:16.955014 ops/training.py:65 2019-01-17 00:31:16.954923: step 2128, loss = 0.68301 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:31:18.246581 ops/training.py:65 2019-01-17 00:31:18.246477: step 2129, loss = 0.68945 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:31:19.533269 ops/training.py:65 2019-01-17 00:31:19.533186: step 2130, loss = 0.75168 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:31:20.814825 ops/training.py:65 2019-01-17 00:31:20.814764: step 2131, loss = 0.75233 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:31:22.108485 ops/training.py:65 2019-01-17 00:31:22.108379: step 2132, loss = 0.69869 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:31:23.399952 ops/training.py:65 2019-01-17 00:31:23.399867: step 2133, loss = 0.68726 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:31:24.687270 ops/training.py:65 2019-01-17 00:31:24.687195: step 2134, loss = 0.65642 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:31:25.970333 ops/training.py:65 2019-01-17 00:31:25.970271: step 2135, loss = 0.67537 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:31:27.261653 ops/training.py:65 2019-01-17 00:31:27.261489: step 2136, loss = 0.73121 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:31:28.552989 ops/training.py:65 2019-01-17 00:31:28.552836: step 2137, loss = 0.70267 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:31:29.839677 ops/training.py:65 2019-01-17 00:31:29.839569: step 2138, loss = 0.68170 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:31:31.132395 ops/training.py:65 2019-01-17 00:31:31.132286: step 2139, loss = 0.70864 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:31:32.419019 ops/training.py:65 2019-01-17 00:31:32.418907: step 2140, loss = 0.73921 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:31:33.704625 ops/training.py:65 2019-01-17 00:31:33.704520: step 2141, loss = 0.70359 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:31:34.996651 ops/training.py:65 2019-01-17 00:31:34.996544: step 2142, loss = 0.68555 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:31:36.287716 ops/training.py:65 2019-01-17 00:31:36.287598: step 2143, loss = 0.69481 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:31:37.579522 ops/training.py:65 2019-01-17 00:31:37.579436: step 2144, loss = 0.80613 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:31:38.865528 ops/training.py:65 2019-01-17 00:31:38.865453: step 2145, loss = 0.71725 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:31:40.147464 ops/training.py:65 2019-01-17 00:31:40.147382: step 2146, loss = 0.67538 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:31:41.431415 ops/training.py:65 2019-01-17 00:31:41.431300: step 2147, loss = 0.66986 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:31:42.720628 ops/training.py:65 2019-01-17 00:31:42.720463: step 2148, loss = 0.70104 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:31:44.012781 ops/training.py:65 2019-01-17 00:31:44.012696: step 2149, loss = 0.67208 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:31:45.302681 ops/training.py:65 2019-01-17 00:31:45.302605: step 2150, loss = 0.67871 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:31:46.592671 ops/training.py:65 2019-01-17 00:31:46.592598: step 2151, loss = 0.71485 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:31:47.883095 ops/training.py:65 2019-01-17 00:31:47.883004: step 2152, loss = 0.75730 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:31:49.169828 ops/training.py:65 2019-01-17 00:31:49.169753: step 2153, loss = 0.72405 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:31:50.448852 ops/training.py:65 2019-01-17 00:31:50.448753: step 2154, loss = 0.66657 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:31:51.743014 ops/training.py:65 2019-01-17 00:31:51.742909: step 2155, loss = 0.69665 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:31:53.030028 ops/training.py:65 2019-01-17 00:31:53.029960: step 2156, loss = 0.73971 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:31:54.314013 ops/training.py:65 2019-01-17 00:31:54.313911: step 2157, loss = 0.76886 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:31:55.601976 ops/training.py:65 2019-01-17 00:31:55.601868: step 2158, loss = 0.71322 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:31:56.889128 ops/training.py:65 2019-01-17 00:31:56.889005: step 2159, loss = 0.68879 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:31:58.177661 ops/training.py:65 2019-01-17 00:31:58.177559: step 2160, loss = 0.76791 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:31:59.464294 ops/training.py:65 2019-01-17 00:31:59.464177: step 2161, loss = 0.62430 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 00:32:00.750925 ops/training.py:65 2019-01-17 00:32:00.750820: step 2162, loss = 0.68335 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:32:02.033830 ops/training.py:65 2019-01-17 00:32:02.033711: step 2163, loss = 0.73561 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:32:03.321355 ops/training.py:65 2019-01-17 00:32:03.321243: step 2164, loss = 0.74064 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:32:04.605723 ops/training.py:65 2019-01-17 00:32:04.605618: step 2165, loss = 0.70946 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:32:05.893091 ops/training.py:65 2019-01-17 00:32:05.892991: step 2166, loss = 0.68294 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:32:07.178806 ops/training.py:65 2019-01-17 00:32:07.178695: step 2167, loss = 0.74413 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:32:08.467898 ops/training.py:65 2019-01-17 00:32:08.467790: step 2168, loss = 0.71854 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:32:09.754728 ops/training.py:65 2019-01-17 00:32:09.754622: step 2169, loss = 0.73391 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:32:11.040164 ops/training.py:65 2019-01-17 00:32:11.040065: step 2170, loss = 0.74328 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:32:12.327878 ops/training.py:65 2019-01-17 00:32:12.327723: step 2171, loss = 0.66333 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:32:13.614058 ops/training.py:65 2019-01-17 00:32:13.613966: step 2172, loss = 0.77698 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.25
I4672 2019-01-17 00:32:14.900166 ops/training.py:65 2019-01-17 00:32:14.900069: step 2173, loss = 0.66898 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:32:16.185620 ops/training.py:65 2019-01-17 00:32:16.185558: step 2174, loss = 0.69276 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:32:17.468273 ops/training.py:65 2019-01-17 00:32:17.468236: step 2175, loss = 0.71862 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:32:18.747447 ops/training.py:65 2019-01-17 00:32:18.747405: step 2176, loss = 0.68728 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:32:20.030844 ops/training.py:65 2019-01-17 00:32:20.030776: step 2177, loss = 0.74487 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:32:21.316767 ops/training.py:65 2019-01-17 00:32:21.316673: step 2178, loss = 0.73521 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:32:22.607745 ops/training.py:65 2019-01-17 00:32:22.607665: step 2179, loss = 0.72778 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:32:23.897428 ops/training.py:65 2019-01-17 00:32:23.897335: step 2180, loss = 0.77536 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:32:25.183996 ops/training.py:65 2019-01-17 00:32:25.183923: step 2181, loss = 0.66384 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:32:26.466269 ops/training.py:65 2019-01-17 00:32:26.466113: step 2182, loss = 0.77896 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:32:27.754834 ops/training.py:65 2019-01-17 00:32:27.754722: step 2183, loss = 0.66963 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:32:29.047598 ops/training.py:65 2019-01-17 00:32:29.047444: step 2184, loss = 0.65077 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:32:30.346392 ops/training.py:65 2019-01-17 00:32:30.346300: step 2185, loss = 0.67058 (24.7 examples/sec; 1.297 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:32:31.637818 ops/training.py:65 2019-01-17 00:32:31.637699: step 2186, loss = 0.74185 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:32:32.930390 ops/training.py:65 2019-01-17 00:32:32.930279: step 2187, loss = 0.74089 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:32:34.220618 ops/training.py:65 2019-01-17 00:32:34.220533: step 2188, loss = 0.70164 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:32:35.510160 ops/training.py:65 2019-01-17 00:32:35.510069: step 2189, loss = 0.74375 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:32:36.789313 ops/training.py:65 2019-01-17 00:32:36.789249: step 2190, loss = 0.75048 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:32:38.077481 ops/training.py:65 2019-01-17 00:32:38.077372: step 2191, loss = 0.67128 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:32:39.367590 ops/training.py:65 2019-01-17 00:32:39.367506: step 2192, loss = 0.75930 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:32:40.657172 ops/training.py:65 2019-01-17 00:32:40.657091: step 2193, loss = 0.79750 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:32:41.944167 ops/training.py:65 2019-01-17 00:32:41.944065: step 2194, loss = 0.70590 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:32:43.228232 ops/training.py:65 2019-01-17 00:32:43.228126: step 2195, loss = 0.72536 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:32:44.518651 ops/training.py:65 2019-01-17 00:32:44.518541: step 2196, loss = 0.73586 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:32:45.808723 ops/training.py:65 2019-01-17 00:32:45.808644: step 2197, loss = 0.73714 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:32:47.100970 ops/training.py:65 2019-01-17 00:32:47.100887: step 2198, loss = 0.69524 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:32:48.388386 ops/training.py:65 2019-01-17 00:32:48.388273: step 2199, loss = 0.76189 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:32:49.686142 ops/training.py:65 2019-01-17 00:32:49.686039: step 2200, loss = 0.74945 (24.7 examples/sec; 1.296 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:32:50.972392 ops/training.py:65 2019-01-17 00:32:50.972319: step 2201, loss = 0.71650 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:32:52.257998 ops/training.py:65 2019-01-17 00:32:52.257889: step 2202, loss = 0.72038 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:32:53.550552 ops/training.py:65 2019-01-17 00:32:53.550453: step 2203, loss = 0.71609 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:32:54.836954 ops/training.py:65 2019-01-17 00:32:54.836871: step 2204, loss = 0.62674 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:32:56.124465 ops/training.py:65 2019-01-17 00:32:56.124360: step 2205, loss = 0.65879 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:32:57.415918 ops/training.py:65 2019-01-17 00:32:57.415823: step 2206, loss = 0.76051 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:32:58.699851 ops/training.py:65 2019-01-17 00:32:58.699751: step 2207, loss = 0.71041 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:32:59.987560 ops/training.py:65 2019-01-17 00:32:59.987449: step 2208, loss = 0.77403 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:33:01.267987 ops/training.py:65 2019-01-17 00:33:01.267881: step 2209, loss = 0.72940 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:33:02.550160 ops/training.py:65 2019-01-17 00:33:02.550051: step 2210, loss = 0.66457 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:33:03.837493 ops/training.py:65 2019-01-17 00:33:03.837390: step 2211, loss = 0.73686 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:33:05.122304 ops/training.py:65 2019-01-17 00:33:05.122209: step 2212, loss = 0.71518 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:33:06.413948 ops/training.py:65 2019-01-17 00:33:06.413855: step 2213, loss = 0.76074 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:33:07.700129 ops/training.py:65 2019-01-17 00:33:07.700030: step 2214, loss = 0.68538 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:33:08.990461 ops/training.py:65 2019-01-17 00:33:08.990365: step 2215, loss = 0.72988 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:33:10.281255 ops/training.py:65 2019-01-17 00:33:10.281169: step 2216, loss = 0.76163 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:33:11.564416 ops/training.py:65 2019-01-17 00:33:11.564340: step 2217, loss = 0.67783 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:33:12.853505 ops/training.py:65 2019-01-17 00:33:12.853424: step 2218, loss = 0.71056 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:33:14.138655 ops/training.py:65 2019-01-17 00:33:14.138575: step 2219, loss = 0.73255 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:33:15.428619 ops/training.py:65 2019-01-17 00:33:15.428505: step 2220, loss = 0.69544 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:33:16.717160 ops/training.py:65 2019-01-17 00:33:16.717080: step 2221, loss = 0.73784 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:33:18.000768 ops/training.py:65 2019-01-17 00:33:18.000703: step 2222, loss = 0.73364 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:33:19.296001 ops/training.py:65 2019-01-17 00:33:19.295894: step 2223, loss = 0.77605 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:33:20.580910 ops/training.py:65 2019-01-17 00:33:20.580805: step 2224, loss = 0.73879 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:33:21.864741 ops/training.py:65 2019-01-17 00:33:21.864600: step 2225, loss = 0.69763 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:33:23.153740 ops/training.py:65 2019-01-17 00:33:23.153634: step 2226, loss = 0.75340 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:33:24.438664 ops/training.py:65 2019-01-17 00:33:24.438559: step 2227, loss = 0.69520 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:33:25.729201 ops/training.py:65 2019-01-17 00:33:25.729041: step 2228, loss = 0.75463 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:33:27.015822 ops/training.py:65 2019-01-17 00:33:27.015744: step 2229, loss = 0.72986 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:33:28.294384 ops/training.py:65 2019-01-17 00:33:28.294273: step 2230, loss = 0.67671 (25.0 examples/sec; 1.277 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:33:29.585105 ops/training.py:65 2019-01-17 00:33:29.584997: step 2231, loss = 0.71097 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:33:30.875665 ops/training.py:65 2019-01-17 00:33:30.875563: step 2232, loss = 0.74222 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:33:32.162377 ops/training.py:65 2019-01-17 00:33:32.162305: step 2233, loss = 0.70241 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:33:33.443443 ops/training.py:65 2019-01-17 00:33:33.443343: step 2234, loss = 0.72632 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:33:34.736104 ops/training.py:65 2019-01-17 00:33:34.735950: step 2235, loss = 0.67662 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:33:36.026308 ops/training.py:65 2019-01-17 00:33:36.026236: step 2236, loss = 0.73259 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:33:37.314416 ops/training.py:65 2019-01-17 00:33:37.314307: step 2237, loss = 0.71614 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:33:38.604493 ops/training.py:65 2019-01-17 00:33:38.604391: step 2238, loss = 0.70432 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:33:39.891554 ops/training.py:65 2019-01-17 00:33:39.891478: step 2239, loss = 0.70421 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:33:41.176536 ops/training.py:65 2019-01-17 00:33:41.176425: step 2240, loss = 0.76101 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:33:42.464257 ops/training.py:65 2019-01-17 00:33:42.464146: step 2241, loss = 0.62950 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:33:43.748811 ops/training.py:65 2019-01-17 00:33:43.748705: step 2242, loss = 0.65364 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:33:45.031571 ops/training.py:65 2019-01-17 00:33:45.031459: step 2243, loss = 0.70725 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:33:46.319356 ops/training.py:65 2019-01-17 00:33:46.319255: step 2244, loss = 0.78500 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:33:47.601873 ops/training.py:65 2019-01-17 00:33:47.601764: step 2245, loss = 0.75666 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:33:48.895209 ops/training.py:65 2019-01-17 00:33:48.895105: step 2246, loss = 0.65160 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:33:50.186764 ops/training.py:65 2019-01-17 00:33:50.186685: step 2247, loss = 0.64372 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:33:51.474673 ops/training.py:65 2019-01-17 00:33:51.474605: step 2248, loss = 0.68293 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:33:52.760455 ops/training.py:65 2019-01-17 00:33:52.760354: step 2249, loss = 0.72135 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:33:54.044680 ops/training.py:65 2019-01-17 00:33:54.044578: step 2250, loss = 0.69536 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:33:55.328189 ops/training.py:65 2019-01-17 00:33:55.328078: step 2251, loss = 0.67485 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:33:56.613249 ops/training.py:65 2019-01-17 00:33:56.613095: step 2252, loss = 0.69427 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:33:57.895267 ops/training.py:65 2019-01-17 00:33:57.895155: step 2253, loss = 0.77771 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:33:59.179454 ops/training.py:65 2019-01-17 00:33:59.179352: step 2254, loss = 0.70943 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:34:00.466997 ops/training.py:65 2019-01-17 00:34:00.466885: step 2255, loss = 0.72308 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:34:01.752943 ops/training.py:65 2019-01-17 00:34:01.752871: step 2256, loss = 0.63789 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:34:03.038287 ops/training.py:65 2019-01-17 00:34:03.038184: step 2257, loss = 0.75621 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:34:04.321996 ops/training.py:65 2019-01-17 00:34:04.321893: step 2258, loss = 0.70614 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:34:05.610927 ops/training.py:65 2019-01-17 00:34:05.610825: step 2259, loss = 0.68852 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:34:06.899098 ops/training.py:65 2019-01-17 00:34:06.899004: step 2260, loss = 0.69149 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:34:08.186061 ops/training.py:65 2019-01-17 00:34:08.185990: step 2261, loss = 0.66241 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:34:09.469325 ops/training.py:65 2019-01-17 00:34:09.469223: step 2262, loss = 0.75808 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:34:10.757214 ops/training.py:65 2019-01-17 00:34:10.757112: step 2263, loss = 0.76596 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:34:12.043915 ops/training.py:65 2019-01-17 00:34:12.043842: step 2264, loss = 0.68486 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:34:13.327223 ops/training.py:65 2019-01-17 00:34:13.327122: step 2265, loss = 0.72822 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:34:14.609144 ops/training.py:65 2019-01-17 00:34:14.609046: step 2266, loss = 0.70499 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:34:15.894122 ops/training.py:65 2019-01-17 00:34:15.894014: step 2267, loss = 0.63031 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:34:17.180589 ops/training.py:65 2019-01-17 00:34:17.180491: step 2268, loss = 0.74815 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:34:18.471161 ops/training.py:65 2019-01-17 00:34:18.471049: step 2269, loss = 0.79531 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.25
I4672 2019-01-17 00:34:19.763567 ops/training.py:65 2019-01-17 00:34:19.763425: step 2270, loss = 0.67405 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:34:21.049545 ops/training.py:65 2019-01-17 00:34:21.049474: step 2271, loss = 0.71468 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:34:22.340383 ops/training.py:65 2019-01-17 00:34:22.340308: step 2272, loss = 0.71034 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:34:23.623950 ops/training.py:65 2019-01-17 00:34:23.623880: step 2273, loss = 0.73476 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:34:24.915188 ops/training.py:65 2019-01-17 00:34:24.915081: step 2274, loss = 0.64141 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 00:34:26.201260 ops/training.py:65 2019-01-17 00:34:26.201158: step 2275, loss = 0.71482 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:34:27.486372 ops/training.py:65 2019-01-17 00:34:27.486276: step 2276, loss = 0.69218 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:34:28.773271 ops/training.py:65 2019-01-17 00:34:28.773169: step 2277, loss = 0.66331 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:34:30.060945 ops/training.py:65 2019-01-17 00:34:30.060846: step 2278, loss = 0.76780 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:34:31.345371 ops/training.py:65 2019-01-17 00:34:31.345267: step 2279, loss = 0.72527 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:34:32.629851 ops/training.py:65 2019-01-17 00:34:32.629736: step 2280, loss = 0.79021 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-17 00:34:33.914204 ops/training.py:65 2019-01-17 00:34:33.914106: step 2281, loss = 0.66844 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:34:35.196933 ops/training.py:65 2019-01-17 00:34:35.196827: step 2282, loss = 0.68801 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:34:36.483237 ops/training.py:65 2019-01-17 00:34:36.483136: step 2283, loss = 0.69300 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:34:37.768909 ops/training.py:65 2019-01-17 00:34:37.768830: step 2284, loss = 0.72330 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:34:39.053585 ops/training.py:65 2019-01-17 00:34:39.053542: step 2285, loss = 0.70365 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:34:40.338838 ops/training.py:65 2019-01-17 00:34:40.338798: step 2286, loss = 0.66054 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:34:41.623629 ops/training.py:65 2019-01-17 00:34:41.623548: step 2287, loss = 0.69123 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:34:42.904141 ops/training.py:65 2019-01-17 00:34:42.904054: step 2288, loss = 0.71143 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:34:44.192601 ops/training.py:65 2019-01-17 00:34:44.192511: step 2289, loss = 0.71397 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:34:45.475768 ops/training.py:65 2019-01-17 00:34:45.475692: step 2290, loss = 0.65615 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:34:46.755059 ops/training.py:65 2019-01-17 00:34:46.754947: step 2291, loss = 0.74622 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:34:48.039029 ops/training.py:65 2019-01-17 00:34:48.038939: step 2292, loss = 0.77624 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:34:49.325810 ops/training.py:65 2019-01-17 00:34:49.325699: step 2293, loss = 0.67303 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:34:50.612135 ops/training.py:65 2019-01-17 00:34:50.612028: step 2294, loss = 0.70830 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:34:51.893801 ops/training.py:65 2019-01-17 00:34:51.893747: step 2295, loss = 0.74306 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:34:53.179317 ops/training.py:65 2019-01-17 00:34:53.179228: step 2296, loss = 0.71879 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:34:54.463850 ops/training.py:65 2019-01-17 00:34:54.463763: step 2297, loss = 0.71657 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:34:55.745524 ops/training.py:65 2019-01-17 00:34:55.745412: step 2298, loss = 0.72633 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:34:57.030852 ops/training.py:65 2019-01-17 00:34:57.030696: step 2299, loss = 0.73675 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:34:58.313034 ops/training.py:65 2019-01-17 00:34:58.312932: step 2300, loss = 0.66507 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:34:59.593900 ops/training.py:65 2019-01-17 00:34:59.593789: step 2301, loss = 0.68803 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:35:00.877376 ops/training.py:65 2019-01-17 00:35:00.877271: step 2302, loss = 0.72091 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:35:02.163901 ops/training.py:65 2019-01-17 00:35:02.163792: step 2303, loss = 0.68980 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:35:03.449960 ops/training.py:65 2019-01-17 00:35:03.449860: step 2304, loss = 0.63268 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:35:04.736080 ops/training.py:65 2019-01-17 00:35:04.735973: step 2305, loss = 0.71836 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:35:06.021041 ops/training.py:65 2019-01-17 00:35:06.020947: step 2306, loss = 0.67684 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:35:07.309905 ops/training.py:65 2019-01-17 00:35:07.309796: step 2307, loss = 0.69481 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:35:08.595057 ops/training.py:65 2019-01-17 00:35:08.594954: step 2308, loss = 0.67278 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:35:09.882205 ops/training.py:65 2019-01-17 00:35:09.882094: step 2309, loss = 0.72735 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-17 00:35:11.164463 ops/training.py:65 2019-01-17 00:35:11.164362: step 2310, loss = 0.66909 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:35:12.445687 ops/training.py:65 2019-01-17 00:35:12.445581: step 2311, loss = 0.75809 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:35:13.737036 ops/training.py:65 2019-01-17 00:35:13.736929: step 2312, loss = 0.72675 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:35:15.021638 ops/training.py:65 2019-01-17 00:35:15.021531: step 2313, loss = 0.67575 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:35:16.309920 ops/training.py:65 2019-01-17 00:35:16.309820: step 2314, loss = 0.72034 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:35:17.596965 ops/training.py:65 2019-01-17 00:35:17.596857: step 2315, loss = 0.71772 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:35:18.887662 ops/training.py:65 2019-01-17 00:35:18.887568: step 2316, loss = 0.69705 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:35:20.173154 ops/training.py:65 2019-01-17 00:35:20.173052: step 2317, loss = 0.70240 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:35:21.464808 ops/training.py:65 2019-01-17 00:35:21.464716: step 2318, loss = 0.72553 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:35:22.755289 ops/training.py:65 2019-01-17 00:35:22.755213: step 2319, loss = 0.71567 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:35:24.038086 ops/training.py:65 2019-01-17 00:35:24.038014: step 2320, loss = 0.71225 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:35:25.322608 ops/training.py:65 2019-01-17 00:35:25.322452: step 2321, loss = 0.68197 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:35:26.611954 ops/training.py:65 2019-01-17 00:35:26.611853: step 2322, loss = 0.66543 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:35:27.899416 ops/training.py:65 2019-01-17 00:35:27.899306: step 2323, loss = 0.68495 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:35:29.181279 ops/training.py:65 2019-01-17 00:35:29.181182: step 2324, loss = 0.73605 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:35:30.461911 ops/training.py:65 2019-01-17 00:35:30.461814: step 2325, loss = 0.71970 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:35:31.743339 ops/training.py:65 2019-01-17 00:35:31.743235: step 2326, loss = 0.68214 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:35:33.029606 ops/training.py:65 2019-01-17 00:35:33.029507: step 2327, loss = 0.72562 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:35:34.315102 ops/training.py:65 2019-01-17 00:35:34.314996: step 2328, loss = 0.67462 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:35:35.603960 ops/training.py:65 2019-01-17 00:35:35.603851: step 2329, loss = 0.73128 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:35:36.888501 ops/training.py:65 2019-01-17 00:35:36.888400: step 2330, loss = 0.70139 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:35:38.173218 ops/training.py:65 2019-01-17 00:35:38.173119: step 2331, loss = 0.65485 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:35:39.460624 ops/training.py:65 2019-01-17 00:35:39.460513: step 2332, loss = 0.69106 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:35:40.744984 ops/training.py:65 2019-01-17 00:35:40.744876: step 2333, loss = 0.66921 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:35:42.033115 ops/training.py:65 2019-01-17 00:35:42.033009: step 2334, loss = 0.70563 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:35:43.315946 ops/training.py:65 2019-01-17 00:35:43.315846: step 2335, loss = 0.71061 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:35:44.605397 ops/training.py:65 2019-01-17 00:35:44.605298: step 2336, loss = 0.65697 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:35:45.892201 ops/training.py:65 2019-01-17 00:35:45.892124: step 2337, loss = 0.73112 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:35:47.175830 ops/training.py:65 2019-01-17 00:35:47.175720: step 2338, loss = 0.69074 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:35:48.466946 ops/training.py:65 2019-01-17 00:35:48.466835: step 2339, loss = 0.70289 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:35:49.760224 ops/training.py:65 2019-01-17 00:35:49.760145: step 2340, loss = 0.69355 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:35:51.043400 ops/training.py:65 2019-01-17 00:35:51.043335: step 2341, loss = 0.74865 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:35:52.334967 ops/training.py:65 2019-01-17 00:35:52.334870: step 2342, loss = 0.74502 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:35:53.625879 ops/training.py:65 2019-01-17 00:35:53.625793: step 2343, loss = 0.73179 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:35:54.908797 ops/training.py:65 2019-01-17 00:35:54.908737: step 2344, loss = 0.69500 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:35:56.193343 ops/training.py:65 2019-01-17 00:35:56.193194: step 2345, loss = 0.71368 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:35:57.486893 ops/training.py:65 2019-01-17 00:35:57.486796: step 2346, loss = 0.65251 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:35:58.772165 ops/training.py:65 2019-01-17 00:35:58.772089: step 2347, loss = 0.72422 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:36:00.064107 ops/training.py:65 2019-01-17 00:36:00.063996: step 2348, loss = 0.69204 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:36:01.353773 ops/training.py:65 2019-01-17 00:36:01.353689: step 2349, loss = 0.71303 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:36:02.637384 ops/training.py:65 2019-01-17 00:36:02.637323: step 2350, loss = 0.65700 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:36:03.935552 ops/training.py:65 2019-01-17 00:36:03.935443: step 2351, loss = 0.73075 (24.7 examples/sec; 1.297 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:36:05.226292 ops/training.py:65 2019-01-17 00:36:05.226208: step 2352, loss = 0.69238 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:36:06.515908 ops/training.py:65 2019-01-17 00:36:06.515830: step 2353, loss = 0.72038 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:36:07.806173 ops/training.py:65 2019-01-17 00:36:07.806091: step 2354, loss = 0.64142 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:36:09.095930 ops/training.py:65 2019-01-17 00:36:09.095813: step 2355, loss = 0.68103 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:36:10.380816 ops/training.py:65 2019-01-17 00:36:10.380746: step 2356, loss = 0.72500 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:36:11.663714 ops/training.py:65 2019-01-17 00:36:11.663602: step 2357, loss = 0.69420 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:36:12.952292 ops/training.py:65 2019-01-17 00:36:12.952187: step 2358, loss = 0.70723 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:36:14.236099 ops/training.py:65 2019-01-17 00:36:14.236002: step 2359, loss = 0.70062 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:36:15.525907 ops/training.py:65 2019-01-17 00:36:15.525806: step 2360, loss = 0.68289 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:36:16.813911 ops/training.py:65 2019-01-17 00:36:16.813813: step 2361, loss = 0.68672 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:36:18.098911 ops/training.py:65 2019-01-17 00:36:18.098816: step 2362, loss = 0.69055 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:36:19.386908 ops/training.py:65 2019-01-17 00:36:19.386809: step 2363, loss = 0.68732 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:36:20.677824 ops/training.py:65 2019-01-17 00:36:20.677722: step 2364, loss = 0.71561 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:36:21.969333 ops/training.py:65 2019-01-17 00:36:21.969237: step 2365, loss = 0.71552 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:36:23.261491 ops/training.py:65 2019-01-17 00:36:23.261409: step 2366, loss = 0.69307 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:36:24.550013 ops/training.py:65 2019-01-17 00:36:24.549930: step 2367, loss = 0.77399 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:36:25.838699 ops/training.py:65 2019-01-17 00:36:25.838617: step 2368, loss = 0.72528 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:36:27.124403 ops/training.py:65 2019-01-17 00:36:27.124336: step 2369, loss = 0.72860 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:36:28.411132 ops/training.py:65 2019-01-17 00:36:28.411028: step 2370, loss = 0.68026 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:36:29.696637 ops/training.py:65 2019-01-17 00:36:29.696526: step 2371, loss = 0.75014 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:36:30.982965 ops/training.py:65 2019-01-17 00:36:30.982851: step 2372, loss = 0.67956 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:36:32.267876 ops/training.py:65 2019-01-17 00:36:32.267768: step 2373, loss = 0.73102 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:36:33.555713 ops/training.py:65 2019-01-17 00:36:33.555606: step 2374, loss = 0.68295 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:36:34.843767 ops/training.py:65 2019-01-17 00:36:34.843652: step 2375, loss = 0.64620 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:36:36.125142 ops/training.py:65 2019-01-17 00:36:36.125005: step 2376, loss = 0.62738 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 00:36:37.412380 ops/training.py:65 2019-01-17 00:36:37.412267: step 2377, loss = 0.69866 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:36:38.693737 ops/training.py:65 2019-01-17 00:36:38.693624: step 2378, loss = 0.70174 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:36:39.978165 ops/training.py:65 2019-01-17 00:36:39.978003: step 2379, loss = 0.72571 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:36:41.270026 ops/training.py:65 2019-01-17 00:36:41.269911: step 2380, loss = 0.69888 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:36:42.557083 ops/training.py:65 2019-01-17 00:36:42.557014: step 2381, loss = 0.72559 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:36:43.842728 ops/training.py:65 2019-01-17 00:36:43.842638: step 2382, loss = 0.62199 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:36:45.134822 ops/training.py:65 2019-01-17 00:36:45.134712: step 2383, loss = 0.73154 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:36:46.420490 ops/training.py:65 2019-01-17 00:36:46.420415: step 2384, loss = 0.68925 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:36:47.711837 ops/training.py:65 2019-01-17 00:36:47.711732: step 2385, loss = 0.66977 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:36:49.003371 ops/training.py:65 2019-01-17 00:36:49.003299: step 2386, loss = 0.76743 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:36:50.286652 ops/training.py:65 2019-01-17 00:36:50.286582: step 2387, loss = 0.70585 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:36:51.570826 ops/training.py:65 2019-01-17 00:36:51.570732: step 2388, loss = 0.63015 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 00:36:52.860649 ops/training.py:65 2019-01-17 00:36:52.860539: step 2389, loss = 0.68023 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:36:54.146835 ops/training.py:65 2019-01-17 00:36:54.146752: step 2390, loss = 0.70603 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:36:55.432708 ops/training.py:65 2019-01-17 00:36:55.432594: step 2391, loss = 0.75207 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:36:56.717354 ops/training.py:65 2019-01-17 00:36:56.717209: step 2392, loss = 0.68679 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:36:58.003963 ops/training.py:65 2019-01-17 00:36:58.003852: step 2393, loss = 0.76125 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:36:59.289283 ops/training.py:65 2019-01-17 00:36:59.289174: step 2394, loss = 0.68929 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:37:00.576600 ops/training.py:65 2019-01-17 00:37:00.576487: step 2395, loss = 0.74998 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:37:01.858504 ops/training.py:65 2019-01-17 00:37:01.858394: step 2396, loss = 0.67250 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:37:03.149767 ops/training.py:65 2019-01-17 00:37:03.149672: step 2397, loss = 0.74826 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:37:04.431818 ops/training.py:65 2019-01-17 00:37:04.431709: step 2398, loss = 0.70955 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:37:05.716485 ops/training.py:65 2019-01-17 00:37:05.716380: step 2399, loss = 0.70104 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:37:06.994006 ops/training.py:65 2019-01-17 00:37:06.993903: step 2400, loss = 0.72155 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:37:08.274005 ops/training.py:65 2019-01-17 00:37:08.273895: step 2401, loss = 0.71658 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:37:09.557340 ops/training.py:65 2019-01-17 00:37:09.557242: step 2402, loss = 0.68928 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:37:10.844595 ops/training.py:65 2019-01-17 00:37:10.844491: step 2403, loss = 0.68313 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:37:12.129594 ops/training.py:65 2019-01-17 00:37:12.129487: step 2404, loss = 0.68469 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:37:13.414543 ops/training.py:65 2019-01-17 00:37:13.414393: step 2405, loss = 0.70073 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:37:14.701126 ops/training.py:65 2019-01-17 00:37:14.701022: step 2406, loss = 0.70253 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:37:15.983465 ops/training.py:65 2019-01-17 00:37:15.983360: step 2407, loss = 0.72389 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:37:17.268705 ops/training.py:65 2019-01-17 00:37:17.268600: step 2408, loss = 0.70242 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:37:18.561239 ops/training.py:65 2019-01-17 00:37:18.561127: step 2409, loss = 0.70877 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:37:19.842720 ops/training.py:65 2019-01-17 00:37:19.842615: step 2410, loss = 0.72031 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:37:21.126064 ops/training.py:65 2019-01-17 00:37:21.125964: step 2411, loss = 0.64792 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:37:22.418520 ops/training.py:65 2019-01-17 00:37:22.418429: step 2412, loss = 0.68372 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:37:23.710187 ops/training.py:65 2019-01-17 00:37:23.710102: step 2413, loss = 0.67633 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:37:24.997904 ops/training.py:65 2019-01-17 00:37:24.997831: step 2414, loss = 0.72842 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:37:26.288852 ops/training.py:65 2019-01-17 00:37:26.288768: step 2415, loss = 0.70401 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:37:27.578965 ops/training.py:65 2019-01-17 00:37:27.578874: step 2416, loss = 0.74221 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:37:28.868642 ops/training.py:65 2019-01-17 00:37:28.868526: step 2417, loss = 0.74538 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:37:30.156821 ops/training.py:65 2019-01-17 00:37:30.156709: step 2418, loss = 0.69791 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:37:31.447737 ops/training.py:65 2019-01-17 00:37:31.447652: step 2419, loss = 0.72776 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:37:32.736285 ops/training.py:65 2019-01-17 00:37:32.736199: step 2420, loss = 0.69997 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:37:34.026078 ops/training.py:65 2019-01-17 00:37:34.025989: step 2421, loss = 0.68661 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:37:35.316287 ops/training.py:65 2019-01-17 00:37:35.316206: step 2422, loss = 0.68356 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:37:36.600352 ops/training.py:65 2019-01-17 00:37:36.600283: step 2423, loss = 0.61766 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 00:37:37.881890 ops/training.py:65 2019-01-17 00:37:37.881782: step 2424, loss = 0.69810 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:37:39.169648 ops/training.py:65 2019-01-17 00:37:39.169548: step 2425, loss = 0.70552 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:37:40.462972 ops/training.py:65 2019-01-17 00:37:40.462821: step 2426, loss = 0.71881 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:37:41.747123 ops/training.py:65 2019-01-17 00:37:41.747045: step 2427, loss = 0.74883 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:37:43.026845 ops/training.py:65 2019-01-17 00:37:43.026745: step 2428, loss = 0.73239 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:37:44.313329 ops/training.py:65 2019-01-17 00:37:44.313262: step 2429, loss = 0.76504 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:37:45.596834 ops/training.py:65 2019-01-17 00:37:45.596732: step 2430, loss = 0.70063 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:37:46.890846 ops/training.py:65 2019-01-17 00:37:46.890743: step 2431, loss = 0.72050 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:37:48.184601 ops/training.py:65 2019-01-17 00:37:48.184521: step 2432, loss = 0.70525 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:37:49.475853 ops/training.py:65 2019-01-17 00:37:49.475779: step 2433, loss = 0.71788 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:37:50.757661 ops/training.py:65 2019-01-17 00:37:50.757585: step 2434, loss = 0.72484 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:37:52.040807 ops/training.py:65 2019-01-17 00:37:52.040712: step 2435, loss = 0.74220 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:37:53.332589 ops/training.py:65 2019-01-17 00:37:53.332487: step 2436, loss = 0.69910 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:37:54.622843 ops/training.py:65 2019-01-17 00:37:54.622769: step 2437, loss = 0.71058 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:37:55.912312 ops/training.py:65 2019-01-17 00:37:55.912201: step 2438, loss = 0.72318 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:37:57.195691 ops/training.py:65 2019-01-17 00:37:57.195625: step 2439, loss = 0.73691 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:37:58.487758 ops/training.py:65 2019-01-17 00:37:58.487649: step 2440, loss = 0.70775 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:37:59.779214 ops/training.py:65 2019-01-17 00:37:59.779130: step 2441, loss = 0.64360 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:38:01.069106 ops/training.py:65 2019-01-17 00:38:01.069024: step 2442, loss = 0.73628 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:38:02.360133 ops/training.py:65 2019-01-17 00:38:02.360049: step 2443, loss = 0.70680 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:38:03.642326 ops/training.py:65 2019-01-17 00:38:03.642224: step 2444, loss = 0.68359 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:38:04.930546 ops/training.py:65 2019-01-17 00:38:04.930443: step 2445, loss = 0.66143 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:38:06.213127 ops/training.py:65 2019-01-17 00:38:06.213047: step 2446, loss = 0.69587 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:38:07.504544 ops/training.py:65 2019-01-17 00:38:07.504444: step 2447, loss = 0.64616 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:38:08.782170 ops/training.py:65 2019-01-17 00:38:08.782096: step 2448, loss = 0.75721 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:38:10.063084 ops/training.py:65 2019-01-17 00:38:10.062985: step 2449, loss = 0.65693 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:38:11.354717 ops/training.py:65 2019-01-17 00:38:11.354563: step 2450, loss = 0.66181 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:38:12.640311 ops/training.py:65 2019-01-17 00:38:12.640236: step 2451, loss = 0.68737 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:38:13.924090 ops/training.py:65 2019-01-17 00:38:13.923988: step 2452, loss = 0.73111 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:38:15.215037 ops/training.py:65 2019-01-17 00:38:15.214931: step 2453, loss = 0.68763 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:38:16.494889 ops/training.py:65 2019-01-17 00:38:16.494783: step 2454, loss = 0.65334 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 00:38:17.782783 ops/training.py:65 2019-01-17 00:38:17.782640: step 2455, loss = 0.69941 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:38:19.067924 ops/training.py:65 2019-01-17 00:38:19.067820: step 2456, loss = 0.70335 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:38:20.359384 ops/training.py:65 2019-01-17 00:38:20.359283: step 2457, loss = 0.69888 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:38:21.651454 ops/training.py:65 2019-01-17 00:38:21.651356: step 2458, loss = 0.73303 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:38:22.944014 ops/training.py:65 2019-01-17 00:38:22.943942: step 2459, loss = 0.77319 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.25
I4672 2019-01-17 00:38:24.230748 ops/training.py:65 2019-01-17 00:38:24.230680: step 2460, loss = 0.61173 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 00:38:25.522212 ops/training.py:65 2019-01-17 00:38:25.522100: step 2461, loss = 0.74863 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:38:26.807502 ops/training.py:65 2019-01-17 00:38:26.807440: step 2462, loss = 0.72806 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:38:28.091919 ops/training.py:65 2019-01-17 00:38:28.091810: step 2463, loss = 0.72514 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:38:29.375314 ops/training.py:65 2019-01-17 00:38:29.375157: step 2464, loss = 0.66177 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:38:30.661707 ops/training.py:65 2019-01-17 00:38:30.661601: step 2465, loss = 0.70475 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:38:31.950827 ops/training.py:65 2019-01-17 00:38:31.950691: step 2466, loss = 0.73132 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:38:33.235716 ops/training.py:65 2019-01-17 00:38:33.235639: step 2467, loss = 0.71542 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:38:34.522325 ops/training.py:65 2019-01-17 00:38:34.522224: step 2468, loss = 0.73292 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:38:35.804005 ops/training.py:65 2019-01-17 00:38:35.803857: step 2469, loss = 0.71144 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:38:37.095793 ops/training.py:65 2019-01-17 00:38:37.095703: step 2470, loss = 0.72422 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:38:38.386176 ops/training.py:65 2019-01-17 00:38:38.386069: step 2471, loss = 0.70388 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:38:39.672738 ops/training.py:65 2019-01-17 00:38:39.672659: step 2472, loss = 0.73631 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:38:40.956728 ops/training.py:65 2019-01-17 00:38:40.956613: step 2473, loss = 0.73650 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:38:42.244577 ops/training.py:65 2019-01-17 00:38:42.244475: step 2474, loss = 0.71182 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:38:43.530562 ops/training.py:65 2019-01-17 00:38:43.530469: step 2475, loss = 0.70308 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:38:44.822551 ops/training.py:65 2019-01-17 00:38:44.822441: step 2476, loss = 0.67359 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:38:46.113334 ops/training.py:65 2019-01-17 00:38:46.113226: step 2477, loss = 0.66561 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:38:47.404428 ops/training.py:65 2019-01-17 00:38:47.404356: step 2478, loss = 0.73397 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:38:48.694907 ops/training.py:65 2019-01-17 00:38:48.694827: step 2479, loss = 0.76982 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:38:49.985575 ops/training.py:65 2019-01-17 00:38:49.985506: step 2480, loss = 0.72779 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:38:51.275056 ops/training.py:65 2019-01-17 00:38:51.274976: step 2481, loss = 0.78952 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:38:52.565198 ops/training.py:65 2019-01-17 00:38:52.565099: step 2482, loss = 0.74282 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:38:53.855640 ops/training.py:65 2019-01-17 00:38:53.855555: step 2483, loss = 0.75628 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:38:55.144588 ops/training.py:65 2019-01-17 00:38:55.144498: step 2484, loss = 0.68939 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:38:56.430236 ops/training.py:65 2019-01-17 00:38:56.430167: step 2485, loss = 0.76093 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:38:57.719134 ops/training.py:65 2019-01-17 00:38:57.719003: step 2486, loss = 0.63689 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:38:59.009524 ops/training.py:65 2019-01-17 00:38:59.009424: step 2487, loss = 0.67518 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:39:00.299942 ops/training.py:65 2019-01-17 00:39:00.299835: step 2488, loss = 0.71901 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:39:01.584524 ops/training.py:65 2019-01-17 00:39:01.584460: step 2489, loss = 0.75016 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:39:02.871156 ops/training.py:65 2019-01-17 00:39:02.871041: step 2490, loss = 0.73061 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:39:04.162742 ops/training.py:65 2019-01-17 00:39:04.162632: step 2491, loss = 0.84227 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.25
I4672 2019-01-17 00:39:05.452219 ops/training.py:65 2019-01-17 00:39:05.452135: step 2492, loss = 0.76172 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:39:06.741818 ops/training.py:65 2019-01-17 00:39:06.741745: step 2493, loss = 0.69447 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:39:08.032350 ops/training.py:65 2019-01-17 00:39:08.032269: step 2494, loss = 0.64393 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:39:09.318149 ops/training.py:65 2019-01-17 00:39:09.318072: step 2495, loss = 0.79532 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:39:10.604866 ops/training.py:65 2019-01-17 00:39:10.604761: step 2496, loss = 0.75910 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:39:11.886644 ops/training.py:65 2019-01-17 00:39:11.886543: step 2497, loss = 0.77432 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:39:13.171482 ops/training.py:65 2019-01-17 00:39:13.171348: step 2498, loss = 0.74346 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:39:14.463845 ops/training.py:65 2019-01-17 00:39:14.463736: step 2499, loss = 0.76045 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:39:15.749169 ops/training.py:65 2019-01-17 00:39:15.749101: step 2500, loss = 0.68341 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:39:17.035803 ops/training.py:65 2019-01-17 00:39:17.035693: step 2501, loss = 0.73582 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:39:18.317698 ops/training.py:65 2019-01-17 00:39:18.317599: step 2502, loss = 0.80895 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:39:19.598962 ops/training.py:65 2019-01-17 00:39:19.598855: step 2503, loss = 0.69248 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:39:20.889741 ops/training.py:65 2019-01-17 00:39:20.889602: step 2504, loss = 0.65993 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:39:22.176001 ops/training.py:65 2019-01-17 00:39:22.175919: step 2505, loss = 0.67184 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:39:23.461450 ops/training.py:65 2019-01-17 00:39:23.461360: step 2506, loss = 0.69507 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:39:24.752016 ops/training.py:65 2019-01-17 00:39:24.751907: step 2507, loss = 0.70012 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:39:26.034452 ops/training.py:65 2019-01-17 00:39:26.034348: step 2508, loss = 0.73467 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:39:27.315095 ops/training.py:65 2019-01-17 00:39:27.315056: step 2509, loss = 0.72183 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:39:28.599985 ops/training.py:65 2019-01-17 00:39:28.599875: step 2510, loss = 0.71290 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:39:29.885939 ops/training.py:65 2019-01-17 00:39:29.885897: step 2511, loss = 0.76838 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:39:31.173689 ops/training.py:65 2019-01-17 00:39:31.173655: step 2512, loss = 0.80598 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-17 00:39:32.459473 ops/training.py:65 2019-01-17 00:39:32.459440: step 2513, loss = 0.71618 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:39:33.745911 ops/training.py:65 2019-01-17 00:39:33.745845: step 2514, loss = 0.70362 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:39:35.031981 ops/training.py:65 2019-01-17 00:39:35.031902: step 2515, loss = 0.69016 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:39:36.321487 ops/training.py:65 2019-01-17 00:39:36.321400: step 2516, loss = 0.80617 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-17 00:39:37.609165 ops/training.py:65 2019-01-17 00:39:37.609088: step 2517, loss = 0.70216 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:39:38.890098 ops/training.py:65 2019-01-17 00:39:38.890065: step 2518, loss = 0.69732 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:39:40.174375 ops/training.py:65 2019-01-17 00:39:40.174318: step 2519, loss = 0.73522 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:39:41.461438 ops/training.py:65 2019-01-17 00:39:41.461399: step 2520, loss = 0.71529 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:39:42.748448 ops/training.py:65 2019-01-17 00:39:42.748409: step 2521, loss = 0.74037 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:39:44.035381 ops/training.py:65 2019-01-17 00:39:44.035351: step 2522, loss = 0.65400 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:39:45.321971 ops/training.py:65 2019-01-17 00:39:45.321939: step 2523, loss = 0.72215 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:39:46.607121 ops/training.py:65 2019-01-17 00:39:46.607013: step 2524, loss = 0.76423 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:39:47.886166 ops/training.py:65 2019-01-17 00:39:47.886052: step 2525, loss = 0.70904 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:39:49.179135 ops/training.py:65 2019-01-17 00:39:49.179028: step 2526, loss = 0.70785 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:39:50.470559 ops/training.py:65 2019-01-17 00:39:50.470459: step 2527, loss = 0.72722 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:39:51.755927 ops/training.py:65 2019-01-17 00:39:51.755825: step 2528, loss = 0.66478 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:39:53.040460 ops/training.py:65 2019-01-17 00:39:53.040391: step 2529, loss = 0.72643 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:39:54.324048 ops/training.py:65 2019-01-17 00:39:54.323940: step 2530, loss = 0.66274 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:39:55.611143 ops/training.py:65 2019-01-17 00:39:55.611028: step 2531, loss = 0.68364 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:39:56.896606 ops/training.py:65 2019-01-17 00:39:56.896502: step 2532, loss = 0.67117 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:39:58.183582 ops/training.py:65 2019-01-17 00:39:58.183435: step 2533, loss = 0.72161 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:39:59.469301 ops/training.py:65 2019-01-17 00:39:59.469196: step 2534, loss = 0.70647 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:40:00.751861 ops/training.py:65 2019-01-17 00:40:00.751749: step 2535, loss = 0.74020 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:40:02.044493 ops/training.py:65 2019-01-17 00:40:02.044394: step 2536, loss = 0.66925 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:40:03.330435 ops/training.py:65 2019-01-17 00:40:03.330368: step 2537, loss = 0.71274 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:40:04.607862 ops/training.py:65 2019-01-17 00:40:04.607753: step 2538, loss = 0.75229 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:40:05.892048 ops/training.py:65 2019-01-17 00:40:05.891897: step 2539, loss = 0.76018 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:40:07.183557 ops/training.py:65 2019-01-17 00:40:07.183452: step 2540, loss = 0.75216 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:40:08.474805 ops/training.py:65 2019-01-17 00:40:08.474694: step 2541, loss = 0.66736 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:40:09.763630 ops/training.py:65 2019-01-17 00:40:09.763557: step 2542, loss = 0.75197 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:40:11.053296 ops/training.py:65 2019-01-17 00:40:11.053216: step 2543, loss = 0.76702 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:40:12.343452 ops/training.py:65 2019-01-17 00:40:12.343368: step 2544, loss = 0.69478 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:40:13.633822 ops/training.py:65 2019-01-17 00:40:13.633734: step 2545, loss = 0.74095 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:40:14.921938 ops/training.py:65 2019-01-17 00:40:14.921851: step 2546, loss = 0.72023 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:40:16.206678 ops/training.py:65 2019-01-17 00:40:16.206602: step 2547, loss = 0.70630 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:40:17.487031 ops/training.py:65 2019-01-17 00:40:17.486924: step 2548, loss = 0.66205 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:40:18.778373 ops/training.py:65 2019-01-17 00:40:18.778274: step 2549, loss = 0.66691 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:40:20.069392 ops/training.py:65 2019-01-17 00:40:20.069306: step 2550, loss = 0.68157 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:40:21.357712 ops/training.py:65 2019-01-17 00:40:21.357626: step 2551, loss = 0.75779 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:40:22.643190 ops/training.py:65 2019-01-17 00:40:22.643120: step 2552, loss = 0.76628 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:40:23.926413 ops/training.py:65 2019-01-17 00:40:23.926306: step 2553, loss = 0.70302 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:40:25.206684 ops/training.py:65 2019-01-17 00:40:25.206571: step 2554, loss = 0.73353 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:40:26.489955 ops/training.py:65 2019-01-17 00:40:26.489857: step 2555, loss = 0.67100 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:40:27.778704 ops/training.py:65 2019-01-17 00:40:27.778597: step 2556, loss = 0.69298 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:40:29.064833 ops/training.py:65 2019-01-17 00:40:29.064761: step 2557, loss = 0.76327 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:40:30.350373 ops/training.py:65 2019-01-17 00:40:30.350258: step 2558, loss = 0.69415 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:40:31.631179 ops/training.py:65 2019-01-17 00:40:31.631068: step 2559, loss = 0.67358 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:40:32.921346 ops/training.py:65 2019-01-17 00:40:32.921237: step 2560, loss = 0.70453 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:40:34.211532 ops/training.py:65 2019-01-17 00:40:34.211434: step 2561, loss = 0.72264 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:40:35.503981 ops/training.py:65 2019-01-17 00:40:35.503882: step 2562, loss = 0.66672 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:40:36.794027 ops/training.py:65 2019-01-17 00:40:36.793922: step 2563, loss = 0.69932 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:40:38.083230 ops/training.py:65 2019-01-17 00:40:38.083165: step 2564, loss = 0.71078 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:40:39.372355 ops/training.py:65 2019-01-17 00:40:39.372269: step 2565, loss = 0.79128 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:40:40.656828 ops/training.py:65 2019-01-17 00:40:40.656757: step 2566, loss = 0.68175 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:40:41.940034 ops/training.py:65 2019-01-17 00:40:41.939889: step 2567, loss = 0.68510 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:40:43.223771 ops/training.py:65 2019-01-17 00:40:43.223678: step 2568, loss = 0.69330 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:40:44.512775 ops/training.py:65 2019-01-17 00:40:44.512662: step 2569, loss = 0.74067 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:40:45.796118 ops/training.py:65 2019-01-17 00:40:45.796009: step 2570, loss = 0.68911 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:40:47.079755 ops/training.py:65 2019-01-17 00:40:47.079656: step 2571, loss = 0.68628 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:40:48.368454 ops/training.py:65 2019-01-17 00:40:48.368345: step 2572, loss = 0.70997 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:40:49.652571 ops/training.py:65 2019-01-17 00:40:49.652472: step 2573, loss = 0.72830 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:40:50.939070 ops/training.py:65 2019-01-17 00:40:50.938968: step 2574, loss = 0.74183 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:40:52.223274 ops/training.py:65 2019-01-17 00:40:52.223145: step 2575, loss = 0.68304 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:40:53.515885 ops/training.py:65 2019-01-17 00:40:53.515777: step 2576, loss = 0.67570 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:40:54.801869 ops/training.py:65 2019-01-17 00:40:54.801796: step 2577, loss = 0.67824 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:40:56.087406 ops/training.py:65 2019-01-17 00:40:56.087307: step 2578, loss = 0.74472 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:40:57.377748 ops/training.py:65 2019-01-17 00:40:57.377652: step 2579, loss = 0.70184 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:40:58.663726 ops/training.py:65 2019-01-17 00:40:58.663633: step 2580, loss = 0.78013 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:40:59.950686 ops/training.py:65 2019-01-17 00:40:59.950581: step 2581, loss = 0.84760 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.15625
I4672 2019-01-17 00:41:01.235725 ops/training.py:65 2019-01-17 00:41:01.235628: step 2582, loss = 0.69439 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:41:02.516918 ops/training.py:65 2019-01-17 00:41:02.516866: step 2583, loss = 0.67181 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:41:03.801827 ops/training.py:65 2019-01-17 00:41:03.801733: step 2584, loss = 0.71882 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:41:05.085864 ops/training.py:65 2019-01-17 00:41:05.085727: step 2585, loss = 0.73254 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:41:06.369766 ops/training.py:65 2019-01-17 00:41:06.369641: step 2586, loss = 0.61672 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 00:41:07.650099 ops/training.py:65 2019-01-17 00:41:07.649998: step 2587, loss = 0.73241 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:41:08.930466 ops/training.py:65 2019-01-17 00:41:08.930395: step 2588, loss = 0.69851 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:41:10.215409 ops/training.py:65 2019-01-17 00:41:10.215303: step 2589, loss = 0.73528 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:41:11.500996 ops/training.py:65 2019-01-17 00:41:11.500887: step 2590, loss = 0.68409 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:41:12.782193 ops/training.py:65 2019-01-17 00:41:12.782117: step 2591, loss = 0.69800 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:41:14.068203 ops/training.py:65 2019-01-17 00:41:14.068104: step 2592, loss = 0.68633 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:41:15.353456 ops/training.py:65 2019-01-17 00:41:15.353370: step 2593, loss = 0.68897 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:41:16.639571 ops/training.py:65 2019-01-17 00:41:16.639462: step 2594, loss = 0.76221 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:41:17.920638 ops/training.py:65 2019-01-17 00:41:17.920485: step 2595, loss = 0.73865 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:41:19.199512 ops/training.py:65 2019-01-17 00:41:19.199397: step 2596, loss = 0.72416 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:41:20.487627 ops/training.py:65 2019-01-17 00:41:20.487520: step 2597, loss = 0.70259 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:41:21.777070 ops/training.py:65 2019-01-17 00:41:21.776971: step 2598, loss = 0.66615 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:41:23.058459 ops/training.py:65 2019-01-17 00:41:23.058389: step 2599, loss = 0.67605 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:41:24.345810 ops/training.py:65 2019-01-17 00:41:24.345705: step 2600, loss = 0.72202 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:41:25.630566 ops/training.py:65 2019-01-17 00:41:25.630472: step 2601, loss = 0.70301 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:41:26.913855 ops/training.py:65 2019-01-17 00:41:26.913756: step 2602, loss = 0.70625 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:41:28.196749 ops/training.py:65 2019-01-17 00:41:28.196678: step 2603, loss = 0.70312 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:41:29.479228 ops/training.py:65 2019-01-17 00:41:29.479126: step 2604, loss = 0.68856 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:41:30.770375 ops/training.py:65 2019-01-17 00:41:30.770260: step 2605, loss = 0.71436 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:41:32.055453 ops/training.py:65 2019-01-17 00:41:32.055386: step 2606, loss = 0.66434 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:41:33.347628 ops/training.py:65 2019-01-17 00:41:33.347484: step 2607, loss = 0.69713 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:41:34.637706 ops/training.py:65 2019-01-17 00:41:34.637588: step 2608, loss = 0.69739 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:41:35.928668 ops/training.py:65 2019-01-17 00:41:35.928590: step 2609, loss = 0.70111 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:41:37.217959 ops/training.py:65 2019-01-17 00:41:37.217873: step 2610, loss = 0.73285 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:41:38.506353 ops/training.py:65 2019-01-17 00:41:38.506267: step 2611, loss = 0.71668 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:41:39.787392 ops/training.py:65 2019-01-17 00:41:39.787323: step 2612, loss = 0.73246 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:41:41.078095 ops/training.py:65 2019-01-17 00:41:41.077948: step 2613, loss = 0.67904 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:41:42.365868 ops/training.py:65 2019-01-17 00:41:42.365801: step 2614, loss = 0.70097 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:41:43.647170 ops/training.py:65 2019-01-17 00:41:43.647057: step 2615, loss = 0.72174 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:41:44.936009 ops/training.py:65 2019-01-17 00:41:44.935899: step 2616, loss = 0.73650 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:41:46.220378 ops/training.py:65 2019-01-17 00:41:46.220300: step 2617, loss = 0.72422 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:41:47.511398 ops/training.py:65 2019-01-17 00:41:47.511287: step 2618, loss = 0.68920 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:41:48.802490 ops/training.py:65 2019-01-17 00:41:48.802419: step 2619, loss = 0.69152 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:41:50.087308 ops/training.py:65 2019-01-17 00:41:50.087240: step 2620, loss = 0.71749 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:41:51.369952 ops/training.py:65 2019-01-17 00:41:51.369818: step 2621, loss = 0.69885 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:41:52.664024 ops/training.py:65 2019-01-17 00:41:52.663876: step 2622, loss = 0.69755 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:41:53.955553 ops/training.py:65 2019-01-17 00:41:53.955479: step 2623, loss = 0.72027 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:41:55.241179 ops/training.py:65 2019-01-17 00:41:55.241104: step 2624, loss = 0.67824 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:41:56.527498 ops/training.py:65 2019-01-17 00:41:56.527386: step 2625, loss = 0.72156 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:41:57.812697 ops/training.py:65 2019-01-17 00:41:57.812588: step 2626, loss = 0.64833 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:41:59.100267 ops/training.py:65 2019-01-17 00:41:59.100157: step 2627, loss = 0.69375 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:42:00.385603 ops/training.py:65 2019-01-17 00:42:00.385533: step 2628, loss = 0.68309 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:42:01.672283 ops/training.py:65 2019-01-17 00:42:01.672119: step 2629, loss = 0.65794 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:42:02.958009 ops/training.py:65 2019-01-17 00:42:02.957941: step 2630, loss = 0.70908 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:42:04.243127 ops/training.py:65 2019-01-17 00:42:04.243017: step 2631, loss = 0.74036 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:42:05.528532 ops/training.py:65 2019-01-17 00:42:05.528424: step 2632, loss = 0.70249 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:42:06.814626 ops/training.py:65 2019-01-17 00:42:06.814522: step 2633, loss = 0.73483 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:42:08.097876 ops/training.py:65 2019-01-17 00:42:08.097719: step 2634, loss = 0.74153 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:42:09.380075 ops/training.py:65 2019-01-17 00:42:09.379940: step 2635, loss = 0.72680 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:42:10.666826 ops/training.py:65 2019-01-17 00:42:10.666716: step 2636, loss = 0.67716 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:42:11.949762 ops/training.py:65 2019-01-17 00:42:11.949601: step 2637, loss = 0.74866 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:42:13.233790 ops/training.py:65 2019-01-17 00:42:13.233649: step 2638, loss = 0.69489 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:42:14.519849 ops/training.py:65 2019-01-17 00:42:14.519737: step 2639, loss = 0.69697 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:42:15.803365 ops/training.py:65 2019-01-17 00:42:15.803257: step 2640, loss = 0.68322 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:42:17.087950 ops/training.py:65 2019-01-17 00:42:17.087836: step 2641, loss = 0.66841 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:42:18.370057 ops/training.py:65 2019-01-17 00:42:18.369955: step 2642, loss = 0.76213 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:42:19.646551 ops/training.py:65 2019-01-17 00:42:19.646445: step 2643, loss = 0.68833 (25.1 examples/sec; 1.275 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:42:20.926866 ops/training.py:65 2019-01-17 00:42:20.926754: step 2644, loss = 0.73777 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:42:22.217582 ops/training.py:65 2019-01-17 00:42:22.217440: step 2645, loss = 0.72947 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:42:23.503956 ops/training.py:65 2019-01-17 00:42:23.503888: step 2646, loss = 0.69347 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:42:24.792673 ops/training.py:65 2019-01-17 00:42:24.792575: step 2647, loss = 0.72662 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:42:26.076643 ops/training.py:65 2019-01-17 00:42:26.076544: step 2648, loss = 0.71086 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:42:27.362496 ops/training.py:65 2019-01-17 00:42:27.362394: step 2649, loss = 0.71088 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:42:28.651987 ops/training.py:65 2019-01-17 00:42:28.651880: step 2650, loss = 0.64699 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:42:29.939843 ops/training.py:65 2019-01-17 00:42:29.939772: step 2651, loss = 0.71275 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:42:31.224565 ops/training.py:65 2019-01-17 00:42:31.224497: step 2652, loss = 0.69535 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:42:32.509361 ops/training.py:65 2019-01-17 00:42:32.509255: step 2653, loss = 0.68827 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:42:33.792861 ops/training.py:65 2019-01-17 00:42:33.792760: step 2654, loss = 0.67152 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:42:35.075338 ops/training.py:65 2019-01-17 00:42:35.075181: step 2655, loss = 0.80359 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:42:36.357984 ops/training.py:65 2019-01-17 00:42:36.357880: step 2656, loss = 0.71475 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:42:37.643901 ops/training.py:65 2019-01-17 00:42:37.643794: step 2657, loss = 0.70597 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:42:38.931726 ops/training.py:65 2019-01-17 00:42:38.931618: step 2658, loss = 0.70762 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:42:40.218857 ops/training.py:65 2019-01-17 00:42:40.218739: step 2659, loss = 0.68416 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:42:41.501628 ops/training.py:65 2019-01-17 00:42:41.501472: step 2660, loss = 0.70884 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:42:42.793474 ops/training.py:65 2019-01-17 00:42:42.793367: step 2661, loss = 0.67608 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:42:44.078124 ops/training.py:65 2019-01-17 00:42:44.078018: step 2662, loss = 0.69094 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:42:45.365728 ops/training.py:65 2019-01-17 00:42:45.365615: step 2663, loss = 0.72792 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:42:46.657781 ops/training.py:65 2019-01-17 00:42:46.657681: step 2664, loss = 0.68371 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:42:47.940233 ops/training.py:65 2019-01-17 00:42:47.940122: step 2665, loss = 0.67583 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:42:49.220787 ops/training.py:65 2019-01-17 00:42:49.220686: step 2666, loss = 0.70015 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:42:50.506265 ops/training.py:65 2019-01-17 00:42:50.506157: step 2667, loss = 0.71880 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:42:51.790459 ops/training.py:65 2019-01-17 00:42:51.790358: step 2668, loss = 0.71900 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:42:53.070358 ops/training.py:65 2019-01-17 00:42:53.070262: step 2669, loss = 0.66550 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:42:54.354049 ops/training.py:65 2019-01-17 00:42:54.353962: step 2670, loss = 0.72341 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:42:55.637067 ops/training.py:65 2019-01-17 00:42:55.636977: step 2671, loss = 0.70992 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:42:56.921900 ops/training.py:65 2019-01-17 00:42:56.921785: step 2672, loss = 0.70289 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:42:58.204964 ops/training.py:65 2019-01-17 00:42:58.204853: step 2673, loss = 0.75842 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:42:59.491086 ops/training.py:65 2019-01-17 00:42:59.490984: step 2674, loss = 0.67810 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:43:00.778651 ops/training.py:65 2019-01-17 00:43:00.778539: step 2675, loss = 0.70382 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:43:02.063846 ops/training.py:65 2019-01-17 00:43:02.063745: step 2676, loss = 0.69398 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:43:03.348678 ops/training.py:65 2019-01-17 00:43:03.348580: step 2677, loss = 0.72995 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:43:04.635999 ops/training.py:65 2019-01-17 00:43:04.635882: step 2678, loss = 0.72747 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:43:05.927796 ops/training.py:65 2019-01-17 00:43:05.927689: step 2679, loss = 0.70880 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:43:07.218239 ops/training.py:65 2019-01-17 00:43:07.218137: step 2680, loss = 0.74964 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:43:08.503410 ops/training.py:65 2019-01-17 00:43:08.503300: step 2681, loss = 0.66856 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:43:09.787488 ops/training.py:65 2019-01-17 00:43:09.787386: step 2682, loss = 0.70810 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:43:11.074371 ops/training.py:65 2019-01-17 00:43:11.074259: step 2683, loss = 0.71226 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:43:12.360775 ops/training.py:65 2019-01-17 00:43:12.360661: step 2684, loss = 0.69897 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:43:13.651164 ops/training.py:65 2019-01-17 00:43:13.651055: step 2685, loss = 0.67241 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:43:14.935813 ops/training.py:65 2019-01-17 00:43:14.935741: step 2686, loss = 0.66837 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:43:16.215788 ops/training.py:65 2019-01-17 00:43:16.215682: step 2687, loss = 0.70451 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:43:17.500052 ops/training.py:65 2019-01-17 00:43:17.499949: step 2688, loss = 0.72447 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:43:18.784359 ops/training.py:65 2019-01-17 00:43:18.784203: step 2689, loss = 0.74685 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:43:20.069900 ops/training.py:65 2019-01-17 00:43:20.069790: step 2690, loss = 0.70713 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:43:21.355841 ops/training.py:65 2019-01-17 00:43:21.355737: step 2691, loss = 0.72227 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:43:22.644074 ops/training.py:65 2019-01-17 00:43:22.643973: step 2692, loss = 0.65499 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:43:23.931728 ops/training.py:65 2019-01-17 00:43:23.931615: step 2693, loss = 0.70064 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:43:25.219483 ops/training.py:65 2019-01-17 00:43:25.219370: step 2694, loss = 0.69026 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:43:26.504326 ops/training.py:65 2019-01-17 00:43:26.504170: step 2695, loss = 0.74975 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:43:27.786254 ops/training.py:65 2019-01-17 00:43:27.786143: step 2696, loss = 0.72622 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:43:29.073445 ops/training.py:65 2019-01-17 00:43:29.073337: step 2697, loss = 0.71935 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:43:30.359580 ops/training.py:65 2019-01-17 00:43:30.359419: step 2698, loss = 0.70410 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:43:31.651220 ops/training.py:65 2019-01-17 00:43:31.651119: step 2699, loss = 0.68094 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:43:32.941846 ops/training.py:65 2019-01-17 00:43:32.941779: step 2700, loss = 0.72134 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:43:34.226318 ops/training.py:65 2019-01-17 00:43:34.226245: step 2701, loss = 0.67344 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:43:35.508482 ops/training.py:65 2019-01-17 00:43:35.508374: step 2702, loss = 0.72367 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:43:36.794493 ops/training.py:65 2019-01-17 00:43:36.794393: step 2703, loss = 0.73295 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:43:38.078710 ops/training.py:65 2019-01-17 00:43:38.078601: step 2704, loss = 0.71040 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:43:39.367449 ops/training.py:65 2019-01-17 00:43:39.367335: step 2705, loss = 0.72975 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:43:40.652612 ops/training.py:65 2019-01-17 00:43:40.652508: step 2706, loss = 0.73409 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:43:41.934585 ops/training.py:65 2019-01-17 00:43:41.934480: step 2707, loss = 0.71895 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:43:43.221254 ops/training.py:65 2019-01-17 00:43:43.221153: step 2708, loss = 0.71401 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:43:44.506088 ops/training.py:65 2019-01-17 00:43:44.505977: step 2709, loss = 0.71547 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:43:45.791034 ops/training.py:65 2019-01-17 00:43:45.790928: step 2710, loss = 0.66958 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:43:47.077130 ops/training.py:65 2019-01-17 00:43:47.077024: step 2711, loss = 0.72959 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:43:48.364197 ops/training.py:65 2019-01-17 00:43:48.364094: step 2712, loss = 0.68812 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:43:49.653325 ops/training.py:65 2019-01-17 00:43:49.653228: step 2713, loss = 0.68784 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:43:50.937222 ops/training.py:65 2019-01-17 00:43:50.937080: step 2714, loss = 0.71130 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:43:52.226595 ops/training.py:65 2019-01-17 00:43:52.226507: step 2715, loss = 0.67807 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:43:53.510586 ops/training.py:65 2019-01-17 00:43:53.510509: step 2716, loss = 0.72638 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:43:54.792549 ops/training.py:65 2019-01-17 00:43:54.792442: step 2717, loss = 0.68689 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:43:56.084606 ops/training.py:65 2019-01-17 00:43:56.084496: step 2718, loss = 0.72742 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:43:57.366323 ops/training.py:65 2019-01-17 00:43:57.366214: step 2719, loss = 0.71236 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:43:58.653092 ops/training.py:65 2019-01-17 00:43:58.652984: step 2720, loss = 0.73752 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:43:59.934554 ops/training.py:65 2019-01-17 00:43:59.934447: step 2721, loss = 0.70657 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:44:01.219712 ops/training.py:65 2019-01-17 00:44:01.219602: step 2722, loss = 0.75581 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:44:02.504399 ops/training.py:65 2019-01-17 00:44:02.504246: step 2723, loss = 0.69635 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:44:03.791681 ops/training.py:65 2019-01-17 00:44:03.791575: step 2724, loss = 0.69860 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:44:05.077781 ops/training.py:65 2019-01-17 00:44:05.077671: step 2725, loss = 0.71242 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:44:06.369334 ops/training.py:65 2019-01-17 00:44:06.369176: step 2726, loss = 0.69995 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:44:07.659184 ops/training.py:65 2019-01-17 00:44:07.659081: step 2727, loss = 0.67924 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:44:08.944201 ops/training.py:65 2019-01-17 00:44:08.944132: step 2728, loss = 0.67609 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:44:10.229437 ops/training.py:65 2019-01-17 00:44:10.229334: step 2729, loss = 0.71749 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:44:11.515017 ops/training.py:65 2019-01-17 00:44:11.514917: step 2730, loss = 0.68393 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 00:44:12.800117 ops/training.py:65 2019-01-17 00:44:12.799978: step 2731, loss = 0.68709 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:44:14.085943 ops/training.py:65 2019-01-17 00:44:14.085841: step 2732, loss = 0.62711 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:44:15.370860 ops/training.py:65 2019-01-17 00:44:15.370756: step 2733, loss = 0.65726 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 00:44:16.657372 ops/training.py:65 2019-01-17 00:44:16.657263: step 2734, loss = 0.76099 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-17 00:44:17.948753 ops/training.py:65 2019-01-17 00:44:17.948669: step 2735, loss = 0.73023 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:44:19.236376 ops/training.py:65 2019-01-17 00:44:19.236292: step 2736, loss = 0.71519 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:44:20.520138 ops/training.py:65 2019-01-17 00:44:20.520082: step 2737, loss = 0.72459 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:44:21.800398 ops/training.py:65 2019-01-17 00:44:21.800305: step 2738, loss = 0.72198 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:44:23.084984 ops/training.py:65 2019-01-17 00:44:23.084890: step 2739, loss = 0.66067 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:44:24.370691 ops/training.py:65 2019-01-17 00:44:24.370585: step 2740, loss = 0.68372 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:44:25.658788 ops/training.py:65 2019-01-17 00:44:25.658638: step 2741, loss = 0.67630 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:44:26.938835 ops/training.py:65 2019-01-17 00:44:26.938723: step 2742, loss = 0.70360 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:44:28.220892 ops/training.py:65 2019-01-17 00:44:28.220784: step 2743, loss = 0.70658 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:44:29.517969 ops/training.py:65 2019-01-17 00:44:29.517861: step 2744, loss = 0.70470 (24.7 examples/sec; 1.296 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:44:30.808482 ops/training.py:65 2019-01-17 00:44:30.808382: step 2745, loss = 0.72345 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:44:32.094349 ops/training.py:65 2019-01-17 00:44:32.094284: step 2746, loss = 0.72400 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:44:33.377471 ops/training.py:65 2019-01-17 00:44:33.377376: step 2747, loss = 0.71900 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:44:34.665467 ops/training.py:65 2019-01-17 00:44:34.665356: step 2748, loss = 0.72170 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:44:35.956511 ops/training.py:65 2019-01-17 00:44:35.956400: step 2749, loss = 0.71866 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:44:37.246497 ops/training.py:65 2019-01-17 00:44:37.246407: step 2750, loss = 0.73975 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:44:38.530430 ops/training.py:65 2019-01-17 00:44:38.530360: step 2751, loss = 0.71383 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:44:39.817356 ops/training.py:65 2019-01-17 00:44:39.817245: step 2752, loss = 0.71668 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:44:41.105850 ops/training.py:65 2019-01-17 00:44:41.105744: step 2753, loss = 0.75839 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:44:42.393611 ops/training.py:65 2019-01-17 00:44:42.393497: step 2754, loss = 0.73562 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:44:43.677772 ops/training.py:65 2019-01-17 00:44:43.677670: step 2755, loss = 0.64500 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:44:44.966540 ops/training.py:65 2019-01-17 00:44:44.966434: step 2756, loss = 0.74092 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:44:46.252957 ops/training.py:65 2019-01-17 00:44:46.252893: step 2757, loss = 0.72720 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:44:47.533551 ops/training.py:65 2019-01-17 00:44:47.533443: step 2758, loss = 0.65260 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:44:48.821669 ops/training.py:65 2019-01-17 00:44:48.821558: step 2759, loss = 0.77741 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:44:50.106339 ops/training.py:65 2019-01-17 00:44:50.106197: step 2760, loss = 0.73104 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:44:51.393434 ops/training.py:65 2019-01-17 00:44:51.393275: step 2761, loss = 0.71693 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:44:52.678075 ops/training.py:65 2019-01-17 00:44:52.677973: step 2762, loss = 0.78618 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:44:53.962736 ops/training.py:65 2019-01-17 00:44:53.962633: step 2763, loss = 0.70427 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:44:55.247626 ops/training.py:65 2019-01-17 00:44:55.247522: step 2764, loss = 0.69976 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:44:56.535967 ops/training.py:65 2019-01-17 00:44:56.535857: step 2765, loss = 0.76655 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:44:57.816136 ops/training.py:65 2019-01-17 00:44:57.816028: step 2766, loss = 0.76269 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:44:59.100065 ops/training.py:65 2019-01-17 00:44:59.099948: step 2767, loss = 0.72698 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:45:00.389198 ops/training.py:65 2019-01-17 00:45:00.389089: step 2768, loss = 0.75267 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:45:01.672360 ops/training.py:65 2019-01-17 00:45:01.672298: step 2769, loss = 0.74189 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:45:02.962482 ops/training.py:65 2019-01-17 00:45:02.962374: step 2770, loss = 0.72049 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:45:04.248589 ops/training.py:65 2019-01-17 00:45:04.248508: step 2771, loss = 0.69441 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:45:05.534062 ops/training.py:65 2019-01-17 00:45:05.533958: step 2772, loss = 0.72047 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:45:06.824798 ops/training.py:65 2019-01-17 00:45:06.824700: step 2773, loss = 0.70897 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:45:08.115151 ops/training.py:65 2019-01-17 00:45:08.115041: step 2774, loss = 0.64619 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:45:09.400317 ops/training.py:65 2019-01-17 00:45:09.400252: step 2775, loss = 0.73259 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:45:10.682071 ops/training.py:65 2019-01-17 00:45:10.681966: step 2776, loss = 0.73288 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:45:11.969034 ops/training.py:65 2019-01-17 00:45:11.968894: step 2777, loss = 0.70910 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:45:13.249687 ops/training.py:65 2019-01-17 00:45:13.249594: step 2778, loss = 0.63410 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 00:45:14.532894 ops/training.py:65 2019-01-17 00:45:14.532744: step 2779, loss = 0.69862 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:45:15.825326 ops/training.py:65 2019-01-17 00:45:15.825225: step 2780, loss = 0.77654 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:45:17.113422 ops/training.py:65 2019-01-17 00:45:17.113319: step 2781, loss = 0.64458 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:45:18.394713 ops/training.py:65 2019-01-17 00:45:18.394606: step 2782, loss = 0.69319 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:45:19.679489 ops/training.py:65 2019-01-17 00:45:19.679336: step 2783, loss = 0.73180 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:45:20.968875 ops/training.py:65 2019-01-17 00:45:20.968760: step 2784, loss = 0.69161 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:45:22.256785 ops/training.py:65 2019-01-17 00:45:22.256683: step 2785, loss = 0.72163 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:45:23.540665 ops/training.py:65 2019-01-17 00:45:23.540557: step 2786, loss = 0.74312 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:45:24.831432 ops/training.py:65 2019-01-17 00:45:24.831323: step 2787, loss = 0.65570 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:45:26.119115 ops/training.py:65 2019-01-17 00:45:26.119046: step 2788, loss = 0.76836 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:45:27.403950 ops/training.py:65 2019-01-17 00:45:27.403846: step 2789, loss = 0.69928 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:45:28.695194 ops/training.py:65 2019-01-17 00:45:28.695093: step 2790, loss = 0.68343 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:45:29.982210 ops/training.py:65 2019-01-17 00:45:29.982111: step 2791, loss = 0.69557 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:45:31.265141 ops/training.py:65 2019-01-17 00:45:31.265030: step 2792, loss = 0.77038 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:45:32.549114 ops/training.py:65 2019-01-17 00:45:32.548952: step 2793, loss = 0.70383 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:45:33.835891 ops/training.py:65 2019-01-17 00:45:33.835788: step 2794, loss = 0.72339 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:45:35.125461 ops/training.py:65 2019-01-17 00:45:35.125353: step 2795, loss = 0.66611 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:45:36.406269 ops/training.py:65 2019-01-17 00:45:36.406108: step 2796, loss = 0.81042 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:45:37.687409 ops/training.py:65 2019-01-17 00:45:37.687313: step 2797, loss = 0.72294 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:45:38.973279 ops/training.py:65 2019-01-17 00:45:38.973166: step 2798, loss = 0.69570 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:45:40.264081 ops/training.py:65 2019-01-17 00:45:40.263983: step 2799, loss = 0.67543 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:45:41.545987 ops/training.py:65 2019-01-17 00:45:41.545874: step 2800, loss = 0.77876 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:45:42.826324 ops/training.py:65 2019-01-17 00:45:42.826216: step 2801, loss = 0.70830 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:45:44.118816 ops/training.py:65 2019-01-17 00:45:44.118707: step 2802, loss = 0.72424 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:45:45.409858 ops/training.py:65 2019-01-17 00:45:45.409757: step 2803, loss = 0.75238 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:45:46.700997 ops/training.py:65 2019-01-17 00:45:46.700894: step 2804, loss = 0.81860 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:45:47.981558 ops/training.py:65 2019-01-17 00:45:47.981486: step 2805, loss = 0.69578 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:45:49.264671 ops/training.py:65 2019-01-17 00:45:49.264572: step 2806, loss = 0.74525 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:45:50.557229 ops/training.py:65 2019-01-17 00:45:50.557132: step 2807, loss = 0.76935 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:45:51.843900 ops/training.py:65 2019-01-17 00:45:51.843800: step 2808, loss = 0.71941 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:45:53.125401 ops/training.py:65 2019-01-17 00:45:53.125311: step 2809, loss = 0.79254 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:45:54.416477 ops/training.py:65 2019-01-17 00:45:54.416367: step 2810, loss = 0.84426 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-17 00:45:55.696603 ops/training.py:65 2019-01-17 00:45:55.696497: step 2811, loss = 0.70362 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:45:56.980284 ops/training.py:65 2019-01-17 00:45:56.980139: step 2812, loss = 0.70463 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:45:58.266833 ops/training.py:65 2019-01-17 00:45:58.266733: step 2813, loss = 0.70732 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:45:59.550055 ops/training.py:65 2019-01-17 00:45:59.549941: step 2814, loss = 0.65028 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:46:00.840877 ops/training.py:65 2019-01-17 00:46:00.840742: step 2815, loss = 0.71282 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:46:02.124631 ops/training.py:65 2019-01-17 00:46:02.124565: step 2816, loss = 0.68905 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:46:03.410989 ops/training.py:65 2019-01-17 00:46:03.410880: step 2817, loss = 0.70329 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:46:04.694677 ops/training.py:65 2019-01-17 00:46:04.694523: step 2818, loss = 0.71364 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:46:05.981782 ops/training.py:65 2019-01-17 00:46:05.981677: step 2819, loss = 0.70267 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:46:07.266979 ops/training.py:65 2019-01-17 00:46:07.266882: step 2820, loss = 0.77195 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:46:08.556752 ops/training.py:65 2019-01-17 00:46:08.556595: step 2821, loss = 0.70577 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:46:09.837983 ops/training.py:65 2019-01-17 00:46:09.837907: step 2822, loss = 0.72203 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:46:11.123864 ops/training.py:65 2019-01-17 00:46:11.123755: step 2823, loss = 0.75050 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:46:12.407423 ops/training.py:65 2019-01-17 00:46:12.407319: step 2824, loss = 0.69157 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:46:13.693413 ops/training.py:65 2019-01-17 00:46:13.693316: step 2825, loss = 0.64163 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:46:14.981539 ops/training.py:65 2019-01-17 00:46:14.981425: step 2826, loss = 0.72422 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:46:16.266852 ops/training.py:65 2019-01-17 00:46:16.266755: step 2827, loss = 0.71916 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:46:17.550131 ops/training.py:65 2019-01-17 00:46:17.550032: step 2828, loss = 0.71791 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:46:18.830936 ops/training.py:65 2019-01-17 00:46:18.830866: step 2829, loss = 0.66059 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:46:20.111127 ops/training.py:65 2019-01-17 00:46:20.111063: step 2830, loss = 0.65586 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:46:21.388887 ops/training.py:65 2019-01-17 00:46:21.388838: step 2831, loss = 0.71130 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:46:22.671346 ops/training.py:65 2019-01-17 00:46:22.671314: step 2832, loss = 0.68637 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:46:23.951313 ops/training.py:65 2019-01-17 00:46:23.951280: step 2833, loss = 0.73564 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:46:25.230269 ops/training.py:65 2019-01-17 00:46:25.230237: step 2834, loss = 0.66374 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:46:26.511756 ops/training.py:65 2019-01-17 00:46:26.511684: step 2835, loss = 0.69273 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:46:27.794080 ops/training.py:65 2019-01-17 00:46:27.793985: step 2836, loss = 0.66322 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:46:29.085914 ops/training.py:65 2019-01-17 00:46:29.085823: step 2837, loss = 0.70966 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:46:30.377016 ops/training.py:65 2019-01-17 00:46:30.376929: step 2838, loss = 0.64968 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:46:31.658826 ops/training.py:65 2019-01-17 00:46:31.658742: step 2839, loss = 0.69419 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:46:32.940221 ops/training.py:65 2019-01-17 00:46:32.940114: step 2840, loss = 0.66741 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:46:34.223193 ops/training.py:65 2019-01-17 00:46:34.223094: step 2841, loss = 0.68574 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:46:35.506927 ops/training.py:65 2019-01-17 00:46:35.506820: step 2842, loss = 0.72239 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:46:36.799153 ops/training.py:65 2019-01-17 00:46:36.799051: step 2843, loss = 0.72314 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:46:38.086916 ops/training.py:65 2019-01-17 00:46:38.086834: step 2844, loss = 0.70901 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:46:39.371028 ops/training.py:65 2019-01-17 00:46:39.370927: step 2845, loss = 0.73807 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:46:40.652315 ops/training.py:65 2019-01-17 00:46:40.652211: step 2846, loss = 0.71451 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:46:41.944149 ops/training.py:65 2019-01-17 00:46:41.944039: step 2847, loss = 0.69927 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:46:43.234290 ops/training.py:65 2019-01-17 00:46:43.234153: step 2848, loss = 0.70753 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:46:44.526068 ops/training.py:65 2019-01-17 00:46:44.525966: step 2849, loss = 0.67686 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:46:45.816947 ops/training.py:65 2019-01-17 00:46:45.816868: step 2850, loss = 0.67898 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:46:47.108071 ops/training.py:65 2019-01-17 00:46:47.107986: step 2851, loss = 0.68230 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:46:48.398485 ops/training.py:65 2019-01-17 00:46:48.398398: step 2852, loss = 0.70054 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:46:49.684493 ops/training.py:65 2019-01-17 00:46:49.684412: step 2853, loss = 0.71381 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:46:50.973039 ops/training.py:65 2019-01-17 00:46:50.972934: step 2854, loss = 0.73863 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:46:52.263676 ops/training.py:65 2019-01-17 00:46:52.263561: step 2855, loss = 0.71274 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:46:53.549125 ops/training.py:65 2019-01-17 00:46:53.549024: step 2856, loss = 0.75044 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:46:54.832105 ops/training.py:65 2019-01-17 00:46:54.831992: step 2857, loss = 0.70669 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:46:56.115143 ops/training.py:65 2019-01-17 00:46:56.115039: step 2858, loss = 0.69723 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:46:57.406869 ops/training.py:65 2019-01-17 00:46:57.406764: step 2859, loss = 0.80741 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-17 00:46:58.698249 ops/training.py:65 2019-01-17 00:46:58.698168: step 2860, loss = 0.75883 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:46:59.989362 ops/training.py:65 2019-01-17 00:46:59.989278: step 2861, loss = 0.66792 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 00:47:01.274462 ops/training.py:65 2019-01-17 00:47:01.274397: step 2862, loss = 0.66426 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:47:02.559097 ops/training.py:65 2019-01-17 00:47:02.559016: step 2863, loss = 0.71217 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:47:03.849642 ops/training.py:65 2019-01-17 00:47:03.849516: step 2864, loss = 0.68635 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:47:05.138223 ops/training.py:65 2019-01-17 00:47:05.138082: step 2865, loss = 0.67194 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:47:06.428540 ops/training.py:65 2019-01-17 00:47:06.428452: step 2866, loss = 0.68144 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:47:07.719321 ops/training.py:65 2019-01-17 00:47:07.719234: step 2867, loss = 0.70242 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:47:09.007376 ops/training.py:65 2019-01-17 00:47:09.007298: step 2868, loss = 0.73283 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:47:10.295886 ops/training.py:65 2019-01-17 00:47:10.295812: step 2869, loss = 0.69506 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:47:11.585159 ops/training.py:65 2019-01-17 00:47:11.585073: step 2870, loss = 0.70539 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:47:12.867460 ops/training.py:65 2019-01-17 00:47:12.867394: step 2871, loss = 0.71656 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:47:14.155643 ops/training.py:65 2019-01-17 00:47:14.155543: step 2872, loss = 0.71292 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:47:15.442788 ops/training.py:65 2019-01-17 00:47:15.442675: step 2873, loss = 0.69875 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:47:16.727242 ops/training.py:65 2019-01-17 00:47:16.727130: step 2874, loss = 0.68115 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:47:18.017495 ops/training.py:65 2019-01-17 00:47:18.017386: step 2875, loss = 0.74044 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:47:19.302874 ops/training.py:65 2019-01-17 00:47:19.302772: step 2876, loss = 0.64181 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:47:20.593925 ops/training.py:65 2019-01-17 00:47:20.593815: step 2877, loss = 0.68738 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:47:21.877489 ops/training.py:65 2019-01-17 00:47:21.877407: step 2878, loss = 0.68528 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:47:23.165765 ops/training.py:65 2019-01-17 00:47:23.165662: step 2879, loss = 0.69770 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:47:24.448825 ops/training.py:65 2019-01-17 00:47:24.448727: step 2880, loss = 0.69215 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:47:25.735439 ops/training.py:65 2019-01-17 00:47:25.735331: step 2881, loss = 0.68515 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:47:27.020827 ops/training.py:65 2019-01-17 00:47:27.020722: step 2882, loss = 0.74678 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:47:28.302922 ops/training.py:65 2019-01-17 00:47:28.302822: step 2883, loss = 0.64755 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:47:29.585981 ops/training.py:65 2019-01-17 00:47:29.585885: step 2884, loss = 0.70604 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:47:30.876750 ops/training.py:65 2019-01-17 00:47:30.876654: step 2885, loss = 0.69328 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:47:32.166845 ops/training.py:65 2019-01-17 00:47:32.166775: step 2886, loss = 0.69208 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:47:33.450925 ops/training.py:65 2019-01-17 00:47:33.450852: step 2887, loss = 0.75501 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:47:34.735984 ops/training.py:65 2019-01-17 00:47:34.735910: step 2888, loss = 0.67943 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:47:36.019119 ops/training.py:65 2019-01-17 00:47:36.019010: step 2889, loss = 0.66413 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:47:37.311483 ops/training.py:65 2019-01-17 00:47:37.311383: step 2890, loss = 0.68662 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:47:38.602621 ops/training.py:65 2019-01-17 00:47:38.602535: step 2891, loss = 0.66651 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:47:39.892768 ops/training.py:65 2019-01-17 00:47:39.892691: step 2892, loss = 0.69443 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:47:41.176162 ops/training.py:65 2019-01-17 00:47:41.176095: step 2893, loss = 0.74706 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-17 00:47:42.470322 ops/training.py:65 2019-01-17 00:47:42.470214: step 2894, loss = 0.72082 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:47:43.759401 ops/training.py:65 2019-01-17 00:47:43.759292: step 2895, loss = 0.70848 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:47:45.039835 ops/training.py:65 2019-01-17 00:47:45.039771: step 2896, loss = 0.74018 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:47:46.324042 ops/training.py:65 2019-01-17 00:47:46.323885: step 2897, loss = 0.67835 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:47:47.604093 ops/training.py:65 2019-01-17 00:47:47.603934: step 2898, loss = 0.66153 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:47:48.895730 ops/training.py:65 2019-01-17 00:47:48.895624: step 2899, loss = 0.73465 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:47:50.185689 ops/training.py:65 2019-01-17 00:47:50.185587: step 2900, loss = 0.67307 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:47:51.476880 ops/training.py:65 2019-01-17 00:47:51.476798: step 2901, loss = 0.72276 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:47:52.760068 ops/training.py:65 2019-01-17 00:47:52.760002: step 2902, loss = 0.70081 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:47:54.052191 ops/training.py:65 2019-01-17 00:47:54.052083: step 2903, loss = 0.72867 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:47:55.339053 ops/training.py:65 2019-01-17 00:47:55.338975: step 2904, loss = 0.70493 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:47:56.622324 ops/training.py:65 2019-01-17 00:47:56.622221: step 2905, loss = 0.69547 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:47:57.904528 ops/training.py:65 2019-01-17 00:47:57.904375: step 2906, loss = 0.68751 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:47:59.197576 ops/training.py:65 2019-01-17 00:47:59.197475: step 2907, loss = 0.70483 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:48:00.481223 ops/training.py:65 2019-01-17 00:48:00.481123: step 2908, loss = 0.69748 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:48:01.772595 ops/training.py:65 2019-01-17 00:48:01.772498: step 2909, loss = 0.74370 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:48:03.060921 ops/training.py:65 2019-01-17 00:48:03.060822: step 2910, loss = 0.73396 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:48:04.351562 ops/training.py:65 2019-01-17 00:48:04.351478: step 2911, loss = 0.70485 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:48:05.641030 ops/training.py:65 2019-01-17 00:48:05.640949: step 2912, loss = 0.71735 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:48:06.925381 ops/training.py:65 2019-01-17 00:48:06.925276: step 2913, loss = 0.74230 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:48:08.208369 ops/training.py:65 2019-01-17 00:48:08.208259: step 2914, loss = 0.71112 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:48:09.500798 ops/training.py:65 2019-01-17 00:48:09.500637: step 2915, loss = 0.73494 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:48:10.792244 ops/training.py:65 2019-01-17 00:48:10.792163: step 2916, loss = 0.66343 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:48:12.083190 ops/training.py:65 2019-01-17 00:48:12.083102: step 2917, loss = 0.68149 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:48:13.368431 ops/training.py:65 2019-01-17 00:48:13.368326: step 2918, loss = 0.67892 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:48:14.648862 ops/training.py:65 2019-01-17 00:48:14.648748: step 2919, loss = 0.71325 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:48:15.936062 ops/training.py:65 2019-01-17 00:48:15.935957: step 2920, loss = 0.75242 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:48:17.220765 ops/training.py:65 2019-01-17 00:48:17.220656: step 2921, loss = 0.71945 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:48:18.512612 ops/training.py:65 2019-01-17 00:48:18.512512: step 2922, loss = 0.69841 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:48:19.797735 ops/training.py:65 2019-01-17 00:48:19.797665: step 2923, loss = 0.70340 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:48:21.080538 ops/training.py:65 2019-01-17 00:48:21.080430: step 2924, loss = 0.73768 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:48:22.371035 ops/training.py:65 2019-01-17 00:48:22.370939: step 2925, loss = 0.72677 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:48:23.660511 ops/training.py:65 2019-01-17 00:48:23.660409: step 2926, loss = 0.69136 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:48:24.950696 ops/training.py:65 2019-01-17 00:48:24.950598: step 2927, loss = 0.70805 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:48:26.229191 ops/training.py:65 2019-01-17 00:48:26.229103: step 2928, loss = 0.68687 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:48:27.520462 ops/training.py:65 2019-01-17 00:48:27.520351: step 2929, loss = 0.72625 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:48:28.806194 ops/training.py:65 2019-01-17 00:48:28.806083: step 2930, loss = 0.70647 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:48:30.090292 ops/training.py:65 2019-01-17 00:48:30.090187: step 2931, loss = 0.72473 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:48:31.377071 ops/training.py:65 2019-01-17 00:48:31.376977: step 2932, loss = 0.70799 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:48:32.667354 ops/training.py:65 2019-01-17 00:48:32.667240: step 2933, loss = 0.73461 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:48:33.957954 ops/training.py:65 2019-01-17 00:48:33.957858: step 2934, loss = 0.65676 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 00:48:35.244065 ops/training.py:65 2019-01-17 00:48:35.243957: step 2935, loss = 0.67903 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:48:36.528532 ops/training.py:65 2019-01-17 00:48:36.528382: step 2936, loss = 0.70410 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:48:37.816056 ops/training.py:65 2019-01-17 00:48:37.815952: step 2937, loss = 0.72378 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:48:39.096472 ops/training.py:65 2019-01-17 00:48:39.096363: step 2938, loss = 0.70811 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:48:40.380465 ops/training.py:65 2019-01-17 00:48:40.380376: step 2939, loss = 0.71610 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:48:41.664651 ops/training.py:65 2019-01-17 00:48:41.664540: step 2940, loss = 0.70713 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:48:42.945769 ops/training.py:65 2019-01-17 00:48:42.945665: step 2941, loss = 0.70039 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:48:44.226673 ops/training.py:65 2019-01-17 00:48:44.226528: step 2942, loss = 0.71139 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:48:45.510080 ops/training.py:65 2019-01-17 00:48:45.509967: step 2943, loss = 0.68182 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:48:46.801554 ops/training.py:65 2019-01-17 00:48:46.801449: step 2944, loss = 0.73960 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:48:48.092573 ops/training.py:65 2019-01-17 00:48:48.092490: step 2945, loss = 0.69311 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:48:49.377820 ops/training.py:65 2019-01-17 00:48:49.377754: step 2946, loss = 0.70665 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:48:50.664105 ops/training.py:65 2019-01-17 00:48:50.664000: step 2947, loss = 0.72835 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:48:51.945282 ops/training.py:65 2019-01-17 00:48:51.945185: step 2948, loss = 0.75370 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:48:53.225038 ops/training.py:65 2019-01-17 00:48:53.224943: step 2949, loss = 0.69810 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:48:54.505856 ops/training.py:65 2019-01-17 00:48:54.505751: step 2950, loss = 0.67813 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:48:55.786021 ops/training.py:65 2019-01-17 00:48:55.785911: step 2951, loss = 0.72071 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:48:57.071997 ops/training.py:65 2019-01-17 00:48:57.071904: step 2952, loss = 0.73201 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:48:58.356092 ops/training.py:65 2019-01-17 00:48:58.355951: step 2953, loss = 0.70070 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:48:59.645994 ops/training.py:65 2019-01-17 00:48:59.645885: step 2954, loss = 0.73748 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:49:00.926649 ops/training.py:65 2019-01-17 00:49:00.926550: step 2955, loss = 0.68208 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:49:02.211535 ops/training.py:65 2019-01-17 00:49:02.211431: step 2956, loss = 0.68329 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:49:03.503167 ops/training.py:65 2019-01-17 00:49:03.503067: step 2957, loss = 0.69708 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:49:04.799680 ops/training.py:65 2019-01-17 00:49:04.799571: step 2958, loss = 0.72026 (24.7 examples/sec; 1.295 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:49:06.083898 ops/training.py:65 2019-01-17 00:49:06.083833: step 2959, loss = 0.72008 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:49:07.364554 ops/training.py:65 2019-01-17 00:49:07.364451: step 2960, loss = 0.71742 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:49:08.648727 ops/training.py:65 2019-01-17 00:49:08.648582: step 2961, loss = 0.70787 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:49:09.940816 ops/training.py:65 2019-01-17 00:49:09.940712: step 2962, loss = 0.67442 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:49:11.231010 ops/training.py:65 2019-01-17 00:49:11.230932: step 2963, loss = 0.67496 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:49:12.516572 ops/training.py:65 2019-01-17 00:49:12.516479: step 2964, loss = 0.66578 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:49:13.803975 ops/training.py:65 2019-01-17 00:49:13.803831: step 2965, loss = 0.64839 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:49:15.090168 ops/training.py:65 2019-01-17 00:49:15.090059: step 2966, loss = 0.76750 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:49:16.373830 ops/training.py:65 2019-01-17 00:49:16.373717: step 2967, loss = 0.72158 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:49:17.664852 ops/training.py:65 2019-01-17 00:49:17.664745: step 2968, loss = 0.70293 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:49:18.953037 ops/training.py:65 2019-01-17 00:49:18.952959: step 2969, loss = 0.69909 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:49:20.238021 ops/training.py:65 2019-01-17 00:49:20.237867: step 2970, loss = 0.70844 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:49:21.522150 ops/training.py:65 2019-01-17 00:49:21.522046: step 2971, loss = 0.69211 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:49:22.812841 ops/training.py:65 2019-01-17 00:49:22.812737: step 2972, loss = 0.76804 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:49:24.105505 ops/training.py:65 2019-01-17 00:49:24.105398: step 2973, loss = 0.71917 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:49:25.395992 ops/training.py:65 2019-01-17 00:49:25.395912: step 2974, loss = 0.66639 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:49:26.685279 ops/training.py:65 2019-01-17 00:49:26.685198: step 2975, loss = 0.69230 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:49:27.968182 ops/training.py:65 2019-01-17 00:49:27.968117: step 2976, loss = 0.70146 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:49:29.260171 ops/training.py:65 2019-01-17 00:49:29.260011: step 2977, loss = 0.66637 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:49:30.547108 ops/training.py:65 2019-01-17 00:49:30.547037: step 2978, loss = 0.68304 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:49:31.827744 ops/training.py:65 2019-01-17 00:49:31.827635: step 2979, loss = 0.67472 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:49:33.115916 ops/training.py:65 2019-01-17 00:49:33.115812: step 2980, loss = 0.69254 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:49:34.400325 ops/training.py:65 2019-01-17 00:49:34.400217: step 2981, loss = 0.70446 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:49:35.683877 ops/training.py:65 2019-01-17 00:49:35.683761: step 2982, loss = 0.66474 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:49:36.968609 ops/training.py:65 2019-01-17 00:49:36.968505: step 2983, loss = 0.68140 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:49:38.250329 ops/training.py:65 2019-01-17 00:49:38.250221: step 2984, loss = 0.71824 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:49:39.534089 ops/training.py:65 2019-01-17 00:49:39.533984: step 2985, loss = 0.69387 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:49:40.821358 ops/training.py:65 2019-01-17 00:49:40.821248: step 2986, loss = 0.69526 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:49:42.102225 ops/training.py:65 2019-01-17 00:49:42.102114: step 2987, loss = 0.65594 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:49:43.385421 ops/training.py:65 2019-01-17 00:49:43.385307: step 2988, loss = 0.72085 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:49:44.667656 ops/training.py:65 2019-01-17 00:49:44.667552: step 2989, loss = 0.66925 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:49:45.959922 ops/training.py:65 2019-01-17 00:49:45.959813: step 2990, loss = 0.65285 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:49:47.245008 ops/training.py:65 2019-01-17 00:49:47.244902: step 2991, loss = 0.69106 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:49:48.536579 ops/training.py:65 2019-01-17 00:49:48.536467: step 2992, loss = 0.70522 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:49:49.821864 ops/training.py:65 2019-01-17 00:49:49.821762: step 2993, loss = 0.70125 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:49:51.112084 ops/training.py:65 2019-01-17 00:49:51.111975: step 2994, loss = 0.70451 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:49:52.398697 ops/training.py:65 2019-01-17 00:49:52.398625: step 2995, loss = 0.68804 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:49:53.678756 ops/training.py:65 2019-01-17 00:49:53.678652: step 2996, loss = 0.71819 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:49:54.963565 ops/training.py:65 2019-01-17 00:49:54.963456: step 2997, loss = 0.73601 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:49:56.254066 ops/training.py:65 2019-01-17 00:49:56.253956: step 2998, loss = 0.68617 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:49:57.538051 ops/training.py:65 2019-01-17 00:49:57.537958: step 2999, loss = 0.67365 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:49:58.828343 ops/training.py:65 2019-01-17 00:49:58.828236: step 3000, loss = 0.73814 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:50:00.117406 ops/training.py:65 2019-01-17 00:50:00.117317: step 3001, loss = 0.70409 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:50:01.405365 ops/training.py:65 2019-01-17 00:50:01.405272: step 3002, loss = 0.68979 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:50:02.686750 ops/training.py:65 2019-01-17 00:50:02.686637: step 3003, loss = 0.72071 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:50:03.970001 ops/training.py:65 2019-01-17 00:50:03.969884: step 3004, loss = 0.71255 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:50:05.259158 ops/training.py:65 2019-01-17 00:50:05.259053: step 3005, loss = 0.70977 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:50:06.542489 ops/training.py:65 2019-01-17 00:50:06.542353: step 3006, loss = 0.72901 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:50:07.831297 ops/training.py:65 2019-01-17 00:50:07.831205: step 3007, loss = 0.74281 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:50:09.112290 ops/training.py:65 2019-01-17 00:50:09.112188: step 3008, loss = 0.66928 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:50:10.402116 ops/training.py:65 2019-01-17 00:50:10.402007: step 3009, loss = 0.71043 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:50:11.688279 ops/training.py:65 2019-01-17 00:50:11.688173: step 3010, loss = 0.72435 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:50:12.973382 ops/training.py:65 2019-01-17 00:50:12.973279: step 3011, loss = 0.66599 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:50:14.261365 ops/training.py:65 2019-01-17 00:50:14.261258: step 3012, loss = 0.70243 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:50:15.547529 ops/training.py:65 2019-01-17 00:50:15.547457: step 3013, loss = 0.68891 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:50:16.830909 ops/training.py:65 2019-01-17 00:50:16.830760: step 3014, loss = 0.70058 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:50:18.124439 ops/training.py:65 2019-01-17 00:50:18.124332: step 3015, loss = 0.65866 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:50:19.411675 ops/training.py:65 2019-01-17 00:50:19.411599: step 3016, loss = 0.73164 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:50:20.700700 ops/training.py:65 2019-01-17 00:50:20.700628: step 3017, loss = 0.69627 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:50:21.989947 ops/training.py:65 2019-01-17 00:50:21.989875: step 3018, loss = 0.63004 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 00:50:23.273854 ops/training.py:65 2019-01-17 00:50:23.273751: step 3019, loss = 0.72645 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:50:24.558481 ops/training.py:65 2019-01-17 00:50:24.558345: step 3020, loss = 0.67673 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:50:25.850672 ops/training.py:65 2019-01-17 00:50:25.850569: step 3021, loss = 0.68155 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:50:27.139369 ops/training.py:65 2019-01-17 00:50:27.139268: step 3022, loss = 0.72856 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:50:28.428046 ops/training.py:65 2019-01-17 00:50:28.427942: step 3023, loss = 0.65753 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:50:29.714784 ops/training.py:65 2019-01-17 00:50:29.714703: step 3024, loss = 0.69238 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:50:30.997644 ops/training.py:65 2019-01-17 00:50:30.997539: step 3025, loss = 0.71605 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:50:32.287069 ops/training.py:65 2019-01-17 00:50:32.286965: step 3026, loss = 0.72253 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:50:33.578112 ops/training.py:65 2019-01-17 00:50:33.578011: step 3027, loss = 0.73138 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:50:34.862474 ops/training.py:65 2019-01-17 00:50:34.862360: step 3028, loss = 0.71188 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:50:36.145385 ops/training.py:65 2019-01-17 00:50:36.145221: step 3029, loss = 0.69940 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:50:37.432545 ops/training.py:65 2019-01-17 00:50:37.432452: step 3030, loss = 0.69101 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:50:38.721462 ops/training.py:65 2019-01-17 00:50:38.721354: step 3031, loss = 0.66963 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:50:40.006650 ops/training.py:65 2019-01-17 00:50:40.006548: step 3032, loss = 0.74985 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:50:41.291021 ops/training.py:65 2019-01-17 00:50:41.290923: step 3033, loss = 0.66658 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:50:42.573298 ops/training.py:65 2019-01-17 00:50:42.573195: step 3034, loss = 0.67221 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:50:43.857079 ops/training.py:65 2019-01-17 00:50:43.856975: step 3035, loss = 0.72409 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:50:45.148458 ops/training.py:65 2019-01-17 00:50:45.148308: step 3036, loss = 0.71441 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:50:46.439537 ops/training.py:65 2019-01-17 00:50:46.439466: step 3037, loss = 0.68580 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:50:47.721350 ops/training.py:65 2019-01-17 00:50:47.721271: step 3038, loss = 0.73729 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:50:49.005729 ops/training.py:65 2019-01-17 00:50:49.005624: step 3039, loss = 0.65713 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:50:50.297305 ops/training.py:65 2019-01-17 00:50:50.297200: step 3040, loss = 0.68038 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:50:51.583629 ops/training.py:65 2019-01-17 00:50:51.583564: step 3041, loss = 0.69559 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:50:52.867462 ops/training.py:65 2019-01-17 00:50:52.867378: step 3042, loss = 0.69387 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:50:54.154595 ops/training.py:65 2019-01-17 00:50:54.154498: step 3043, loss = 0.67232 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:50:55.437461 ops/training.py:65 2019-01-17 00:50:55.437361: step 3044, loss = 0.71278 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:50:56.720729 ops/training.py:65 2019-01-17 00:50:56.720622: step 3045, loss = 0.65786 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:50:58.010256 ops/training.py:65 2019-01-17 00:50:58.010148: step 3046, loss = 0.66325 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:50:59.289603 ops/training.py:65 2019-01-17 00:50:59.289493: step 3047, loss = 0.66180 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:51:00.572351 ops/training.py:65 2019-01-17 00:51:00.572242: step 3048, loss = 0.65023 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:51:01.860017 ops/training.py:65 2019-01-17 00:51:01.859892: step 3049, loss = 0.75060 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:51:03.144885 ops/training.py:65 2019-01-17 00:51:03.144785: step 3050, loss = 0.73527 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:51:04.438505 ops/training.py:65 2019-01-17 00:51:04.438403: step 3051, loss = 0.68966 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:51:05.723314 ops/training.py:65 2019-01-17 00:51:05.723210: step 3052, loss = 0.68710 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:51:07.002921 ops/training.py:65 2019-01-17 00:51:07.002815: step 3053, loss = 0.66609 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:51:08.288147 ops/training.py:65 2019-01-17 00:51:08.288054: step 3054, loss = 0.72219 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:51:09.578126 ops/training.py:65 2019-01-17 00:51:09.578030: step 3055, loss = 0.67735 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:51:10.861808 ops/training.py:65 2019-01-17 00:51:10.861710: step 3056, loss = 0.68970 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:51:12.145767 ops/training.py:65 2019-01-17 00:51:12.145673: step 3057, loss = 0.70264 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:51:13.438098 ops/training.py:65 2019-01-17 00:51:13.437992: step 3058, loss = 0.70573 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:51:14.722953 ops/training.py:65 2019-01-17 00:51:14.722841: step 3059, loss = 0.68747 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:51:16.003092 ops/training.py:65 2019-01-17 00:51:16.002986: step 3060, loss = 0.69133 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:51:17.293389 ops/training.py:65 2019-01-17 00:51:17.293286: step 3061, loss = 0.68373 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:51:18.580582 ops/training.py:65 2019-01-17 00:51:18.580480: step 3062, loss = 0.68438 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:51:19.867274 ops/training.py:65 2019-01-17 00:51:19.867169: step 3063, loss = 0.68847 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:51:21.158740 ops/training.py:65 2019-01-17 00:51:21.158631: step 3064, loss = 0.68615 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:51:22.448972 ops/training.py:65 2019-01-17 00:51:22.448875: step 3065, loss = 0.64307 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:51:23.736316 ops/training.py:65 2019-01-17 00:51:23.736214: step 3066, loss = 0.75485 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:51:25.020788 ops/training.py:65 2019-01-17 00:51:25.020662: step 3067, loss = 0.67249 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:51:26.302523 ops/training.py:65 2019-01-17 00:51:26.302418: step 3068, loss = 0.71927 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:51:27.592504 ops/training.py:65 2019-01-17 00:51:27.592399: step 3069, loss = 0.70569 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:51:28.877015 ops/training.py:65 2019-01-17 00:51:28.876922: step 3070, loss = 0.67681 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:51:30.164489 ops/training.py:65 2019-01-17 00:51:30.164385: step 3071, loss = 0.72192 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:51:31.448911 ops/training.py:65 2019-01-17 00:51:31.448798: step 3072, loss = 0.72703 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:51:32.739592 ops/training.py:65 2019-01-17 00:51:32.739482: step 3073, loss = 0.66304 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:51:34.019162 ops/training.py:65 2019-01-17 00:51:34.019056: step 3074, loss = 0.71669 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:51:35.298990 ops/training.py:65 2019-01-17 00:51:35.298883: step 3075, loss = 0.69624 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:51:36.592289 ops/training.py:65 2019-01-17 00:51:36.592181: step 3076, loss = 0.69911 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:51:37.883026 ops/training.py:65 2019-01-17 00:51:37.882938: step 3077, loss = 0.71330 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:51:39.172124 ops/training.py:65 2019-01-17 00:51:39.172050: step 3078, loss = 0.73943 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:51:40.457258 ops/training.py:65 2019-01-17 00:51:40.457150: step 3079, loss = 0.63839 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:51:41.738732 ops/training.py:65 2019-01-17 00:51:41.738627: step 3080, loss = 0.70877 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:51:43.023600 ops/training.py:65 2019-01-17 00:51:43.023494: step 3081, loss = 0.64946 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 00:51:44.303956 ops/training.py:65 2019-01-17 00:51:44.303850: step 3082, loss = 0.72975 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:51:45.590964 ops/training.py:65 2019-01-17 00:51:45.590857: step 3083, loss = 0.75352 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:51:46.876828 ops/training.py:65 2019-01-17 00:51:46.876720: step 3084, loss = 0.71232 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:51:48.163778 ops/training.py:65 2019-01-17 00:51:48.163668: step 3085, loss = 0.63606 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:51:49.454072 ops/training.py:65 2019-01-17 00:51:49.453968: step 3086, loss = 0.68158 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:51:50.738694 ops/training.py:65 2019-01-17 00:51:50.738556: step 3087, loss = 0.67997 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:51:52.024809 ops/training.py:65 2019-01-17 00:51:52.024694: step 3088, loss = 0.72976 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:51:53.301394 ops/training.py:65 2019-01-17 00:51:53.301294: step 3089, loss = 0.65048 (25.1 examples/sec; 1.275 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:51:54.585590 ops/training.py:65 2019-01-17 00:51:54.585474: step 3090, loss = 0.75245 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:51:55.871164 ops/training.py:65 2019-01-17 00:51:55.871061: step 3091, loss = 0.70421 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:51:57.154641 ops/training.py:65 2019-01-17 00:51:57.154549: step 3092, loss = 0.72353 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:51:58.440167 ops/training.py:65 2019-01-17 00:51:58.440063: step 3093, loss = 0.69797 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:51:59.726585 ops/training.py:65 2019-01-17 00:51:59.726477: step 3094, loss = 0.71327 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:52:01.010792 ops/training.py:65 2019-01-17 00:52:01.010686: step 3095, loss = 0.69717 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:52:02.293968 ops/training.py:65 2019-01-17 00:52:02.293861: step 3096, loss = 0.69743 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:52:03.578604 ops/training.py:65 2019-01-17 00:52:03.578502: step 3097, loss = 0.70187 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:52:04.864387 ops/training.py:65 2019-01-17 00:52:04.864275: step 3098, loss = 0.70935 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:52:06.145798 ops/training.py:65 2019-01-17 00:52:06.145697: step 3099, loss = 0.65835 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 00:52:07.430292 ops/training.py:65 2019-01-17 00:52:07.430202: step 3100, loss = 0.71406 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:52:08.717313 ops/training.py:65 2019-01-17 00:52:08.717207: step 3101, loss = 0.74097 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:52:10.007182 ops/training.py:65 2019-01-17 00:52:10.007067: step 3102, loss = 0.69009 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:52:11.294092 ops/training.py:65 2019-01-17 00:52:11.293984: step 3103, loss = 0.72006 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:52:12.579948 ops/training.py:65 2019-01-17 00:52:12.579844: step 3104, loss = 0.77092 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:52:13.861435 ops/training.py:65 2019-01-17 00:52:13.861334: step 3105, loss = 0.71224 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:52:15.140720 ops/training.py:65 2019-01-17 00:52:15.140610: step 3106, loss = 0.69078 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:52:16.431153 ops/training.py:65 2019-01-17 00:52:16.431048: step 3107, loss = 0.73034 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:52:17.714877 ops/training.py:65 2019-01-17 00:52:17.714770: step 3108, loss = 0.74229 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:52:19.004489 ops/training.py:65 2019-01-17 00:52:19.004392: step 3109, loss = 0.67552 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 00:52:20.290439 ops/training.py:65 2019-01-17 00:52:20.290335: step 3110, loss = 0.70983 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:52:21.573167 ops/training.py:65 2019-01-17 00:52:21.573063: step 3111, loss = 0.69926 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:52:22.854737 ops/training.py:65 2019-01-17 00:52:22.854639: step 3112, loss = 0.72938 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:52:24.138836 ops/training.py:65 2019-01-17 00:52:24.138743: step 3113, loss = 0.66584 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:52:25.423927 ops/training.py:65 2019-01-17 00:52:25.423829: step 3114, loss = 0.66537 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:52:26.708525 ops/training.py:65 2019-01-17 00:52:26.708390: step 3115, loss = 0.71267 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:52:27.998113 ops/training.py:65 2019-01-17 00:52:27.998016: step 3116, loss = 0.69071 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:52:29.284023 ops/training.py:65 2019-01-17 00:52:29.283921: step 3117, loss = 0.69851 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:52:30.572229 ops/training.py:65 2019-01-17 00:52:30.572130: step 3118, loss = 0.72877 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:52:31.854708 ops/training.py:65 2019-01-17 00:52:31.854601: step 3119, loss = 0.70437 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:52:33.139101 ops/training.py:65 2019-01-17 00:52:33.138954: step 3120, loss = 0.69540 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:52:34.430179 ops/training.py:65 2019-01-17 00:52:34.430078: step 3121, loss = 0.70892 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:52:35.719840 ops/training.py:65 2019-01-17 00:52:35.719714: step 3122, loss = 0.68136 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:52:37.009074 ops/training.py:65 2019-01-17 00:52:37.009000: step 3123, loss = 0.68153 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:52:38.298970 ops/training.py:65 2019-01-17 00:52:38.298901: step 3124, loss = 0.70487 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:52:39.579597 ops/training.py:65 2019-01-17 00:52:39.579485: step 3125, loss = 0.69310 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:52:40.863358 ops/training.py:65 2019-01-17 00:52:40.863248: step 3126, loss = 0.73269 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:52:42.149345 ops/training.py:65 2019-01-17 00:52:42.149239: step 3127, loss = 0.69512 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:52:43.434991 ops/training.py:65 2019-01-17 00:52:43.434892: step 3128, loss = 0.68878 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:52:44.720316 ops/training.py:65 2019-01-17 00:52:44.720209: step 3129, loss = 0.68838 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:52:46.002725 ops/training.py:65 2019-01-17 00:52:46.002612: step 3130, loss = 0.64709 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:52:47.293511 ops/training.py:65 2019-01-17 00:52:47.293399: step 3131, loss = 0.67860 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:52:48.578777 ops/training.py:65 2019-01-17 00:52:48.578673: step 3132, loss = 0.67595 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:52:49.860244 ops/training.py:65 2019-01-17 00:52:49.860144: step 3133, loss = 0.76919 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:52:51.144085 ops/training.py:65 2019-01-17 00:52:51.143985: step 3134, loss = 0.67203 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:52:52.424193 ops/training.py:65 2019-01-17 00:52:52.424094: step 3135, loss = 0.66253 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:52:53.708657 ops/training.py:65 2019-01-17 00:52:53.708553: step 3136, loss = 0.71605 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:52:54.999822 ops/training.py:65 2019-01-17 00:52:54.999729: step 3137, loss = 0.67263 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:52:56.290772 ops/training.py:65 2019-01-17 00:52:56.290669: step 3138, loss = 0.72650 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:52:57.575972 ops/training.py:65 2019-01-17 00:52:57.575890: step 3139, loss = 0.67366 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:52:58.855363 ops/training.py:65 2019-01-17 00:52:58.855258: step 3140, loss = 0.67424 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:53:00.144593 ops/training.py:65 2019-01-17 00:53:00.144489: step 3141, loss = 0.63980 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:53:01.430248 ops/training.py:65 2019-01-17 00:53:01.430173: step 3142, loss = 0.71732 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:53:02.714946 ops/training.py:65 2019-01-17 00:53:02.714879: step 3143, loss = 0.66627 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:53:04.007039 ops/training.py:65 2019-01-17 00:53:04.006893: step 3144, loss = 0.72138 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:53:05.293355 ops/training.py:65 2019-01-17 00:53:05.293285: step 3145, loss = 0.69989 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:53:06.578082 ops/training.py:65 2019-01-17 00:53:06.577978: step 3146, loss = 0.66749 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:53:07.866462 ops/training.py:65 2019-01-17 00:53:07.866354: step 3147, loss = 0.71951 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:53:09.143531 ops/training.py:65 2019-01-17 00:53:09.143415: step 3148, loss = 0.72082 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:53:10.427786 ops/training.py:65 2019-01-17 00:53:10.427677: step 3149, loss = 0.67753 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:53:11.713737 ops/training.py:65 2019-01-17 00:53:11.713626: step 3150, loss = 0.71511 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:53:12.995144 ops/training.py:65 2019-01-17 00:53:12.995039: step 3151, loss = 0.72055 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:53:14.285313 ops/training.py:65 2019-01-17 00:53:14.285198: step 3152, loss = 0.71138 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:53:15.573118 ops/training.py:65 2019-01-17 00:53:15.573008: step 3153, loss = 0.70919 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:53:16.857779 ops/training.py:65 2019-01-17 00:53:16.857674: step 3154, loss = 0.66379 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:53:18.144905 ops/training.py:65 2019-01-17 00:53:18.144797: step 3155, loss = 0.64676 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:53:19.426283 ops/training.py:65 2019-01-17 00:53:19.426171: step 3156, loss = 0.72824 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:53:20.720875 ops/training.py:65 2019-01-17 00:53:20.720717: step 3157, loss = 0.68346 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:53:22.004736 ops/training.py:65 2019-01-17 00:53:22.004631: step 3158, loss = 0.66049 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:53:23.292075 ops/training.py:65 2019-01-17 00:53:23.291977: step 3159, loss = 0.66088 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:53:24.573827 ops/training.py:65 2019-01-17 00:53:24.573714: step 3160, loss = 0.71383 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:53:25.858246 ops/training.py:65 2019-01-17 00:53:25.858134: step 3161, loss = 0.69364 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:53:27.146099 ops/training.py:65 2019-01-17 00:53:27.145992: step 3162, loss = 0.76514 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:53:28.435919 ops/training.py:65 2019-01-17 00:53:28.435809: step 3163, loss = 0.67782 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:53:29.727862 ops/training.py:65 2019-01-17 00:53:29.727778: step 3164, loss = 0.77723 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:53:31.014769 ops/training.py:65 2019-01-17 00:53:31.014699: step 3165, loss = 0.76734 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:53:32.303130 ops/training.py:65 2019-01-17 00:53:32.302973: step 3166, loss = 0.75292 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:53:33.591162 ops/training.py:65 2019-01-17 00:53:33.591018: step 3167, loss = 0.67355 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:53:34.877289 ops/training.py:65 2019-01-17 00:53:34.877202: step 3168, loss = 0.69197 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:53:36.162716 ops/training.py:65 2019-01-17 00:53:36.162608: step 3169, loss = 0.71304 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:53:37.456249 ops/training.py:65 2019-01-17 00:53:37.456154: step 3170, loss = 0.64809 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 00:53:38.745325 ops/training.py:65 2019-01-17 00:53:38.745245: step 3171, loss = 0.73413 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:53:40.026063 ops/training.py:65 2019-01-17 00:53:40.025995: step 3172, loss = 0.68178 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:53:41.310185 ops/training.py:65 2019-01-17 00:53:41.310089: step 3173, loss = 0.73958 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:53:42.602350 ops/training.py:65 2019-01-17 00:53:42.602247: step 3174, loss = 0.66623 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:53:43.891279 ops/training.py:65 2019-01-17 00:53:43.891181: step 3175, loss = 0.75859 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:53:45.181280 ops/training.py:65 2019-01-17 00:53:45.181184: step 3176, loss = 0.70463 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:53:46.468210 ops/training.py:65 2019-01-17 00:53:46.468135: step 3177, loss = 0.69827 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:53:47.752130 ops/training.py:65 2019-01-17 00:53:47.752033: step 3178, loss = 0.69265 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:53:49.036303 ops/training.py:65 2019-01-17 00:53:49.036191: step 3179, loss = 0.67620 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:53:50.328020 ops/training.py:65 2019-01-17 00:53:50.327912: step 3180, loss = 0.70513 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:53:51.612856 ops/training.py:65 2019-01-17 00:53:51.612787: step 3181, loss = 0.71551 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:53:52.904754 ops/training.py:65 2019-01-17 00:53:52.904651: step 3182, loss = 0.68595 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:53:54.196536 ops/training.py:65 2019-01-17 00:53:54.196458: step 3183, loss = 0.69209 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:53:55.484863 ops/training.py:65 2019-01-17 00:53:55.484783: step 3184, loss = 0.69152 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:53:56.771747 ops/training.py:65 2019-01-17 00:53:56.771662: step 3185, loss = 0.73852 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:53:58.060943 ops/training.py:65 2019-01-17 00:53:58.060870: step 3186, loss = 0.64505 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:53:59.350995 ops/training.py:65 2019-01-17 00:53:59.350882: step 3187, loss = 0.69849 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:54:00.640756 ops/training.py:65 2019-01-17 00:54:00.640672: step 3188, loss = 0.66661 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:54:01.930958 ops/training.py:65 2019-01-17 00:54:01.930874: step 3189, loss = 0.74611 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:54:03.215178 ops/training.py:65 2019-01-17 00:54:03.215101: step 3190, loss = 0.71062 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:54:04.499311 ops/training.py:65 2019-01-17 00:54:04.499212: step 3191, loss = 0.74090 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:54:05.790316 ops/training.py:65 2019-01-17 00:54:05.790204: step 3192, loss = 0.66608 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:54:07.080331 ops/training.py:65 2019-01-17 00:54:07.080254: step 3193, loss = 0.66815 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:54:08.367536 ops/training.py:65 2019-01-17 00:54:08.367468: step 3194, loss = 0.70072 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:54:09.651402 ops/training.py:65 2019-01-17 00:54:09.651289: step 3195, loss = 0.68106 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:54:10.943826 ops/training.py:65 2019-01-17 00:54:10.943715: step 3196, loss = 0.68285 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:54:12.229952 ops/training.py:65 2019-01-17 00:54:12.229888: step 3197, loss = 0.72494 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:54:13.515570 ops/training.py:65 2019-01-17 00:54:13.515465: step 3198, loss = 0.70395 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:54:14.800431 ops/training.py:65 2019-01-17 00:54:14.800328: step 3199, loss = 0.69150 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:54:16.093143 ops/training.py:65 2019-01-17 00:54:16.093038: step 3200, loss = 0.71004 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:54:17.373408 ops/training.py:65 2019-01-17 00:54:17.373344: step 3201, loss = 0.70659 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:54:18.663269 ops/training.py:65 2019-01-17 00:54:18.663162: step 3202, loss = 0.71597 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:54:19.951593 ops/training.py:65 2019-01-17 00:54:19.951484: step 3203, loss = 0.66214 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:54:21.241467 ops/training.py:65 2019-01-17 00:54:21.241313: step 3204, loss = 0.66750 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:54:22.532068 ops/training.py:65 2019-01-17 00:54:22.531994: step 3205, loss = 0.72583 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:54:23.816912 ops/training.py:65 2019-01-17 00:54:23.816834: step 3206, loss = 0.70571 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:54:25.106780 ops/training.py:65 2019-01-17 00:54:25.106701: step 3207, loss = 0.70693 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:54:26.396375 ops/training.py:65 2019-01-17 00:54:26.396264: step 3208, loss = 0.74518 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:54:27.687847 ops/training.py:65 2019-01-17 00:54:27.687767: step 3209, loss = 0.68376 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:54:28.978050 ops/training.py:65 2019-01-17 00:54:28.977978: step 3210, loss = 0.72962 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:54:30.267798 ops/training.py:65 2019-01-17 00:54:30.267717: step 3211, loss = 0.69048 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:54:31.556734 ops/training.py:65 2019-01-17 00:54:31.556650: step 3212, loss = 0.69226 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:54:32.845508 ops/training.py:65 2019-01-17 00:54:32.845422: step 3213, loss = 0.72710 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:54:34.135467 ops/training.py:65 2019-01-17 00:54:34.135374: step 3214, loss = 0.72808 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:54:35.421534 ops/training.py:65 2019-01-17 00:54:35.421458: step 3215, loss = 0.65803 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:54:36.701093 ops/training.py:65 2019-01-17 00:54:36.700984: step 3216, loss = 0.69264 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:54:37.993456 ops/training.py:65 2019-01-17 00:54:37.993363: step 3217, loss = 0.71404 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:54:39.285826 ops/training.py:65 2019-01-17 00:54:39.285742: step 3218, loss = 0.70315 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:54:40.568488 ops/training.py:65 2019-01-17 00:54:40.568428: step 3219, loss = 0.66805 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:54:41.855989 ops/training.py:65 2019-01-17 00:54:41.855877: step 3220, loss = 0.72553 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:54:43.139214 ops/training.py:65 2019-01-17 00:54:43.139113: step 3221, loss = 0.69603 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:54:44.430614 ops/training.py:65 2019-01-17 00:54:44.430503: step 3222, loss = 0.67542 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:54:45.720426 ops/training.py:65 2019-01-17 00:54:45.720307: step 3223, loss = 0.68248 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:54:47.010651 ops/training.py:65 2019-01-17 00:54:47.010534: step 3224, loss = 0.67239 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:54:48.300564 ops/training.py:65 2019-01-17 00:54:48.300445: step 3225, loss = 0.67746 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:54:49.590127 ops/training.py:65 2019-01-17 00:54:49.590054: step 3226, loss = 0.68133 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:54:50.875349 ops/training.py:65 2019-01-17 00:54:50.875284: step 3227, loss = 0.74714 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:54:52.159899 ops/training.py:65 2019-01-17 00:54:52.159802: step 3228, loss = 0.67109 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:54:53.450986 ops/training.py:65 2019-01-17 00:54:53.450894: step 3229, loss = 0.72741 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:54:54.739041 ops/training.py:65 2019-01-17 00:54:54.738963: step 3230, loss = 0.69414 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:54:56.026925 ops/training.py:65 2019-01-17 00:54:56.026840: step 3231, loss = 0.73517 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:54:57.316152 ops/training.py:65 2019-01-17 00:54:57.316074: step 3232, loss = 0.73132 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:54:58.606336 ops/training.py:65 2019-01-17 00:54:58.606262: step 3233, loss = 0.69550 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:54:59.892780 ops/training.py:65 2019-01-17 00:54:59.892672: step 3234, loss = 0.68310 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:55:01.182837 ops/training.py:65 2019-01-17 00:55:01.182729: step 3235, loss = 0.64131 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:55:02.473041 ops/training.py:65 2019-01-17 00:55:02.472961: step 3236, loss = 0.68372 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:55:03.763259 ops/training.py:65 2019-01-17 00:55:03.763180: step 3237, loss = 0.69848 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:55:05.052350 ops/training.py:65 2019-01-17 00:55:05.052256: step 3238, loss = 0.72413 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:55:06.336047 ops/training.py:65 2019-01-17 00:55:06.335962: step 3239, loss = 0.72163 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:55:07.628168 ops/training.py:65 2019-01-17 00:55:07.628071: step 3240, loss = 0.64636 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:55:08.916129 ops/training.py:65 2019-01-17 00:55:08.916056: step 3241, loss = 0.72498 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:55:10.202065 ops/training.py:65 2019-01-17 00:55:10.201959: step 3242, loss = 0.73496 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:55:11.495303 ops/training.py:65 2019-01-17 00:55:11.495195: step 3243, loss = 0.68848 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:55:12.787612 ops/training.py:65 2019-01-17 00:55:12.787503: step 3244, loss = 0.69623 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:55:14.078863 ops/training.py:65 2019-01-17 00:55:14.078783: step 3245, loss = 0.66588 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:55:15.368126 ops/training.py:65 2019-01-17 00:55:15.368047: step 3246, loss = 0.72407 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:55:16.651599 ops/training.py:65 2019-01-17 00:55:16.651532: step 3247, loss = 0.74538 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:55:17.943181 ops/training.py:65 2019-01-17 00:55:17.943073: step 3248, loss = 0.67270 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:55:19.235540 ops/training.py:65 2019-01-17 00:55:19.235454: step 3249, loss = 0.76404 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:55:20.516114 ops/training.py:65 2019-01-17 00:55:20.516046: step 3250, loss = 0.71978 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:55:21.800153 ops/training.py:65 2019-01-17 00:55:21.800041: step 3251, loss = 0.73887 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:55:23.091481 ops/training.py:65 2019-01-17 00:55:23.091383: step 3252, loss = 0.76217 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-17 00:55:24.378297 ops/training.py:65 2019-01-17 00:55:24.378216: step 3253, loss = 0.72848 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:55:25.660645 ops/training.py:65 2019-01-17 00:55:25.660543: step 3254, loss = 0.71897 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:55:26.949537 ops/training.py:65 2019-01-17 00:55:26.949431: step 3255, loss = 0.67747 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:55:28.231444 ops/training.py:65 2019-01-17 00:55:28.231337: step 3256, loss = 0.66452 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:55:29.519003 ops/training.py:65 2019-01-17 00:55:29.518898: step 3257, loss = 0.68348 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:55:30.806475 ops/training.py:65 2019-01-17 00:55:30.806381: step 3258, loss = 0.70499 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:55:32.086432 ops/training.py:65 2019-01-17 00:55:32.086320: step 3259, loss = 0.68823 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:55:33.374147 ops/training.py:65 2019-01-17 00:55:33.374038: step 3260, loss = 0.70731 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:55:34.659248 ops/training.py:65 2019-01-17 00:55:34.659119: step 3261, loss = 0.70640 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:55:35.950066 ops/training.py:65 2019-01-17 00:55:35.949960: step 3262, loss = 0.71979 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:55:37.239782 ops/training.py:65 2019-01-17 00:55:37.239707: step 3263, loss = 0.67765 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:55:38.527634 ops/training.py:65 2019-01-17 00:55:38.527566: step 3264, loss = 0.77979 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:55:39.810728 ops/training.py:65 2019-01-17 00:55:39.810622: step 3265, loss = 0.69752 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:55:41.088459 ops/training.py:65 2019-01-17 00:55:41.088357: step 3266, loss = 0.70144 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:55:42.371087 ops/training.py:65 2019-01-17 00:55:42.370983: step 3267, loss = 0.71288 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:55:43.658090 ops/training.py:65 2019-01-17 00:55:43.657989: step 3268, loss = 0.72425 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:55:44.949161 ops/training.py:65 2019-01-17 00:55:44.949003: step 3269, loss = 0.68536 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:55:46.233372 ops/training.py:65 2019-01-17 00:55:46.233304: step 3270, loss = 0.66581 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:55:47.519581 ops/training.py:65 2019-01-17 00:55:47.519509: step 3271, loss = 0.72209 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:55:48.807015 ops/training.py:65 2019-01-17 00:55:48.806929: step 3272, loss = 0.72801 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:55:50.090305 ops/training.py:65 2019-01-17 00:55:50.090240: step 3273, loss = 0.69815 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:55:51.369625 ops/training.py:65 2019-01-17 00:55:51.369535: step 3274, loss = 0.66564 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:55:52.653626 ops/training.py:65 2019-01-17 00:55:52.653537: step 3275, loss = 0.75040 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:55:53.940745 ops/training.py:65 2019-01-17 00:55:53.940641: step 3276, loss = 0.70573 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:55:55.230919 ops/training.py:65 2019-01-17 00:55:55.230814: step 3277, loss = 0.69449 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:55:56.521295 ops/training.py:65 2019-01-17 00:55:56.521186: step 3278, loss = 0.72373 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:55:57.811329 ops/training.py:65 2019-01-17 00:55:57.811244: step 3279, loss = 0.75250 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:55:59.100056 ops/training.py:65 2019-01-17 00:55:59.099961: step 3280, loss = 0.72086 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:56:00.386336 ops/training.py:65 2019-01-17 00:56:00.386257: step 3281, loss = 0.66889 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:56:01.675396 ops/training.py:65 2019-01-17 00:56:01.675313: step 3282, loss = 0.69242 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:56:02.965261 ops/training.py:65 2019-01-17 00:56:02.965185: step 3283, loss = 0.72062 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:56:04.254436 ops/training.py:65 2019-01-17 00:56:04.254327: step 3284, loss = 0.72752 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:56:05.543020 ops/training.py:65 2019-01-17 00:56:05.542931: step 3285, loss = 0.70452 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:56:06.826723 ops/training.py:65 2019-01-17 00:56:06.826643: step 3286, loss = 0.70719 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:56:08.119636 ops/training.py:65 2019-01-17 00:56:08.119539: step 3287, loss = 0.71252 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:56:09.410883 ops/training.py:65 2019-01-17 00:56:09.410773: step 3288, loss = 0.70631 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:56:10.701147 ops/training.py:65 2019-01-17 00:56:10.701069: step 3289, loss = 0.75742 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:56:11.991850 ops/training.py:65 2019-01-17 00:56:11.991773: step 3290, loss = 0.72427 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:56:13.281318 ops/training.py:65 2019-01-17 00:56:13.281236: step 3291, loss = 0.64834 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:56:14.570416 ops/training.py:65 2019-01-17 00:56:14.570311: step 3292, loss = 0.69495 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:56:15.859690 ops/training.py:65 2019-01-17 00:56:15.859612: step 3293, loss = 0.68682 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:56:17.145093 ops/training.py:65 2019-01-17 00:56:17.145018: step 3294, loss = 0.66511 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:56:18.428365 ops/training.py:65 2019-01-17 00:56:18.428293: step 3295, loss = 0.67947 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:56:19.716342 ops/training.py:65 2019-01-17 00:56:19.716240: step 3296, loss = 0.71659 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:56:21.001263 ops/training.py:65 2019-01-17 00:56:21.001101: step 3297, loss = 0.66367 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:56:22.290756 ops/training.py:65 2019-01-17 00:56:22.290643: step 3298, loss = 0.74702 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:56:23.571642 ops/training.py:65 2019-01-17 00:56:23.571516: step 3299, loss = 0.72371 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:56:24.856527 ops/training.py:65 2019-01-17 00:56:24.856422: step 3300, loss = 0.67846 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:56:26.148037 ops/training.py:65 2019-01-17 00:56:26.147932: step 3301, loss = 0.68638 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:56:27.429208 ops/training.py:65 2019-01-17 00:56:27.429141: step 3302, loss = 0.73222 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:56:28.713591 ops/training.py:65 2019-01-17 00:56:28.713481: step 3303, loss = 0.71318 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:56:30.001351 ops/training.py:65 2019-01-17 00:56:30.001245: step 3304, loss = 0.68049 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:56:31.285440 ops/training.py:65 2019-01-17 00:56:31.285337: step 3305, loss = 0.76835 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:56:32.574249 ops/training.py:65 2019-01-17 00:56:32.574139: step 3306, loss = 0.67877 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:56:33.860181 ops/training.py:65 2019-01-17 00:56:33.860065: step 3307, loss = 0.70006 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:56:35.150678 ops/training.py:65 2019-01-17 00:56:35.150576: step 3308, loss = 0.70761 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:56:36.441325 ops/training.py:65 2019-01-17 00:56:36.441240: step 3309, loss = 0.72065 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:56:37.731637 ops/training.py:65 2019-01-17 00:56:37.731551: step 3310, loss = 0.73536 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:56:39.020899 ops/training.py:65 2019-01-17 00:56:39.020818: step 3311, loss = 0.66386 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:56:40.308375 ops/training.py:65 2019-01-17 00:56:40.308289: step 3312, loss = 0.76668 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:56:41.593254 ops/training.py:65 2019-01-17 00:56:41.593185: step 3313, loss = 0.72413 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:56:42.878195 ops/training.py:65 2019-01-17 00:56:42.878119: step 3314, loss = 0.67715 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:56:44.164901 ops/training.py:65 2019-01-17 00:56:44.164828: step 3315, loss = 0.70579 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:56:45.448151 ops/training.py:65 2019-01-17 00:56:45.448042: step 3316, loss = 0.72563 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:56:46.739478 ops/training.py:65 2019-01-17 00:56:46.739326: step 3317, loss = 0.76128 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-17 00:56:48.032453 ops/training.py:65 2019-01-17 00:56:48.032361: step 3318, loss = 0.65546 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:56:49.320884 ops/training.py:65 2019-01-17 00:56:49.320805: step 3319, loss = 0.70913 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:56:50.610048 ops/training.py:65 2019-01-17 00:56:50.609964: step 3320, loss = 0.67118 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:56:51.899116 ops/training.py:65 2019-01-17 00:56:51.899030: step 3321, loss = 0.69944 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:56:53.179669 ops/training.py:65 2019-01-17 00:56:53.179606: step 3322, loss = 0.71902 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:56:54.467885 ops/training.py:65 2019-01-17 00:56:54.467780: step 3323, loss = 0.69566 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:56:55.758216 ops/training.py:65 2019-01-17 00:56:55.758103: step 3324, loss = 0.68413 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:56:57.042073 ops/training.py:65 2019-01-17 00:56:57.041964: step 3325, loss = 0.69247 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:56:58.340530 ops/training.py:65 2019-01-17 00:56:58.340368: step 3326, loss = 0.71097 (24.7 examples/sec; 1.297 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:56:59.633338 ops/training.py:65 2019-01-17 00:56:59.633255: step 3327, loss = 0.72043 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:57:00.916694 ops/training.py:65 2019-01-17 00:57:00.916621: step 3328, loss = 0.70724 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:57:02.204784 ops/training.py:65 2019-01-17 00:57:02.204667: step 3329, loss = 0.71120 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:57:03.494310 ops/training.py:65 2019-01-17 00:57:03.494226: step 3330, loss = 0.75088 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:57:04.779101 ops/training.py:65 2019-01-17 00:57:04.779022: step 3331, loss = 0.66748 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:57:06.068193 ops/training.py:65 2019-01-17 00:57:06.068117: step 3332, loss = 0.66944 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:57:07.357933 ops/training.py:65 2019-01-17 00:57:07.357847: step 3333, loss = 0.75156 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:57:08.644410 ops/training.py:65 2019-01-17 00:57:08.644325: step 3334, loss = 0.73150 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:57:09.926127 ops/training.py:65 2019-01-17 00:57:09.926055: step 3335, loss = 0.76569 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:57:11.218850 ops/training.py:65 2019-01-17 00:57:11.218740: step 3336, loss = 0.66163 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:57:12.511268 ops/training.py:65 2019-01-17 00:57:12.511193: step 3337, loss = 0.66507 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:57:13.800598 ops/training.py:65 2019-01-17 00:57:13.800488: step 3338, loss = 0.64189 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:57:15.090655 ops/training.py:65 2019-01-17 00:57:15.090577: step 3339, loss = 0.70700 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:57:16.373804 ops/training.py:65 2019-01-17 00:57:16.373741: step 3340, loss = 0.68494 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:57:17.664811 ops/training.py:65 2019-01-17 00:57:17.664654: step 3341, loss = 0.71598 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:57:18.956848 ops/training.py:65 2019-01-17 00:57:18.956766: step 3342, loss = 0.75877 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:57:20.247124 ops/training.py:65 2019-01-17 00:57:20.247043: step 3343, loss = 0.71109 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:57:21.532537 ops/training.py:65 2019-01-17 00:57:21.532463: step 3344, loss = 0.67040 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:57:22.817856 ops/training.py:65 2019-01-17 00:57:22.817783: step 3345, loss = 0.70568 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:57:24.107038 ops/training.py:65 2019-01-17 00:57:24.106933: step 3346, loss = 0.71136 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:57:25.392542 ops/training.py:65 2019-01-17 00:57:25.392430: step 3347, loss = 0.67170 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:57:26.675603 ops/training.py:65 2019-01-17 00:57:26.675495: step 3348, loss = 0.68291 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:57:27.968134 ops/training.py:65 2019-01-17 00:57:27.968027: step 3349, loss = 0.73952 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:57:29.260280 ops/training.py:65 2019-01-17 00:57:29.260176: step 3350, loss = 0.68926 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:57:30.545012 ops/training.py:65 2019-01-17 00:57:30.544903: step 3351, loss = 0.68752 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:57:31.824612 ops/training.py:65 2019-01-17 00:57:31.824449: step 3352, loss = 0.73834 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:57:33.115998 ops/training.py:65 2019-01-17 00:57:33.115845: step 3353, loss = 0.69359 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:57:34.402565 ops/training.py:65 2019-01-17 00:57:34.402462: step 3354, loss = 0.63425 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:57:35.688680 ops/training.py:65 2019-01-17 00:57:35.688571: step 3355, loss = 0.68325 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:57:36.972464 ops/training.py:65 2019-01-17 00:57:36.972356: step 3356, loss = 0.74479 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:57:38.262841 ops/training.py:65 2019-01-17 00:57:38.262746: step 3357, loss = 0.71795 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:57:39.549145 ops/training.py:65 2019-01-17 00:57:39.549071: step 3358, loss = 0.72553 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:57:40.830480 ops/training.py:65 2019-01-17 00:57:40.830374: step 3359, loss = 0.73448 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:57:42.111048 ops/training.py:65 2019-01-17 00:57:42.110950: step 3360, loss = 0.69579 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:57:43.397427 ops/training.py:65 2019-01-17 00:57:43.397316: step 3361, loss = 0.63886 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 00:57:44.682593 ops/training.py:65 2019-01-17 00:57:44.682498: step 3362, loss = 0.63288 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 00:57:45.965771 ops/training.py:65 2019-01-17 00:57:45.965670: step 3363, loss = 0.69626 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:57:47.249459 ops/training.py:65 2019-01-17 00:57:47.249350: step 3364, loss = 0.73047 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:57:48.543289 ops/training.py:65 2019-01-17 00:57:48.543146: step 3365, loss = 0.70169 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:57:49.834650 ops/training.py:65 2019-01-17 00:57:49.834570: step 3366, loss = 0.67966 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:57:51.123869 ops/training.py:65 2019-01-17 00:57:51.123791: step 3367, loss = 0.71776 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:57:52.409458 ops/training.py:65 2019-01-17 00:57:52.409389: step 3368, loss = 0.68279 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:57:53.692929 ops/training.py:65 2019-01-17 00:57:53.692804: step 3369, loss = 0.72378 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:57:54.992702 ops/training.py:65 2019-01-17 00:57:54.992549: step 3370, loss = 0.73237 (24.6 examples/sec; 1.298 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:57:56.276648 ops/training.py:65 2019-01-17 00:57:56.276582: step 3371, loss = 0.66049 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:57:57.558500 ops/training.py:65 2019-01-17 00:57:57.558396: step 3372, loss = 0.72307 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:57:58.846012 ops/training.py:65 2019-01-17 00:57:58.845905: step 3373, loss = 0.70283 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:58:00.134082 ops/training.py:65 2019-01-17 00:58:00.134007: step 3374, loss = 0.67741 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:58:01.416672 ops/training.py:65 2019-01-17 00:58:01.416566: step 3375, loss = 0.69089 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:58:02.705327 ops/training.py:65 2019-01-17 00:58:02.705226: step 3376, loss = 0.72215 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:58:03.997054 ops/training.py:65 2019-01-17 00:58:03.996910: step 3377, loss = 0.70671 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:58:05.287476 ops/training.py:65 2019-01-17 00:58:05.287376: step 3378, loss = 0.71118 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:58:06.577231 ops/training.py:65 2019-01-17 00:58:06.577151: step 3379, loss = 0.70038 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:58:07.867021 ops/training.py:65 2019-01-17 00:58:07.866902: step 3380, loss = 0.75013 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 00:58:09.157123 ops/training.py:65 2019-01-17 00:58:09.157018: step 3381, loss = 0.69631 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:58:10.443177 ops/training.py:65 2019-01-17 00:58:10.443098: step 3382, loss = 0.70389 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:58:11.725887 ops/training.py:65 2019-01-17 00:58:11.725780: step 3383, loss = 0.61752 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 00:58:13.018230 ops/training.py:65 2019-01-17 00:58:13.018126: step 3384, loss = 0.74359 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:58:14.311055 ops/training.py:65 2019-01-17 00:58:14.310936: step 3385, loss = 0.75403 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.25
I4672 2019-01-17 00:58:15.596817 ops/training.py:65 2019-01-17 00:58:15.596736: step 3386, loss = 0.70959 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:58:16.881193 ops/training.py:65 2019-01-17 00:58:16.881091: step 3387, loss = 0.70695 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:58:18.173232 ops/training.py:65 2019-01-17 00:58:18.173130: step 3388, loss = 0.72398 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:58:19.456737 ops/training.py:65 2019-01-17 00:58:19.456655: step 3389, loss = 0.67795 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:58:20.742157 ops/training.py:65 2019-01-17 00:58:20.742051: step 3390, loss = 0.72807 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:58:22.026480 ops/training.py:65 2019-01-17 00:58:22.026374: step 3391, loss = 0.74268 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:58:23.306882 ops/training.py:65 2019-01-17 00:58:23.306781: step 3392, loss = 0.74805 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:58:24.599467 ops/training.py:65 2019-01-17 00:58:24.599360: step 3393, loss = 0.68887 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:58:25.891195 ops/training.py:65 2019-01-17 00:58:25.891086: step 3394, loss = 0.66227 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:58:27.181790 ops/training.py:65 2019-01-17 00:58:27.181710: step 3395, loss = 0.73108 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:58:28.466865 ops/training.py:65 2019-01-17 00:58:28.466788: step 3396, loss = 0.70562 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:58:29.756025 ops/training.py:65 2019-01-17 00:58:29.755918: step 3397, loss = 0.71465 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:58:31.046015 ops/training.py:65 2019-01-17 00:58:31.045904: step 3398, loss = 0.73278 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:58:32.332794 ops/training.py:65 2019-01-17 00:58:32.332719: step 3399, loss = 0.61801 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 00:58:33.613594 ops/training.py:65 2019-01-17 00:58:33.613528: step 3400, loss = 0.72357 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:58:34.898705 ops/training.py:65 2019-01-17 00:58:34.898595: step 3401, loss = 0.65896 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:58:36.184251 ops/training.py:65 2019-01-17 00:58:36.184148: step 3402, loss = 0.69313 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:58:37.468380 ops/training.py:65 2019-01-17 00:58:37.468279: step 3403, loss = 0.68570 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:58:38.760279 ops/training.py:65 2019-01-17 00:58:38.760180: step 3404, loss = 0.78359 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:58:40.051792 ops/training.py:65 2019-01-17 00:58:40.051725: step 3405, loss = 0.71200 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:58:41.336510 ops/training.py:65 2019-01-17 00:58:41.336402: step 3406, loss = 0.71626 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:58:42.620679 ops/training.py:65 2019-01-17 00:58:42.620570: step 3407, loss = 0.69844 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:58:43.913103 ops/training.py:65 2019-01-17 00:58:43.912990: step 3408, loss = 0.73897 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:58:45.205695 ops/training.py:65 2019-01-17 00:58:45.205586: step 3409, loss = 0.68372 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:58:46.486365 ops/training.py:65 2019-01-17 00:58:46.486292: step 3410, loss = 0.67907 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:58:47.772794 ops/training.py:65 2019-01-17 00:58:47.772681: step 3411, loss = 0.65497 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:58:49.058838 ops/training.py:65 2019-01-17 00:58:49.058726: step 3412, loss = 0.68288 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:58:50.343231 ops/training.py:65 2019-01-17 00:58:50.343124: step 3413, loss = 0.72878 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:58:51.630247 ops/training.py:65 2019-01-17 00:58:51.630145: step 3414, loss = 0.66079 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:58:52.915165 ops/training.py:65 2019-01-17 00:58:52.915063: step 3415, loss = 0.66585 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:58:54.199157 ops/training.py:65 2019-01-17 00:58:54.199057: step 3416, loss = 0.65386 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:58:55.480200 ops/training.py:65 2019-01-17 00:58:55.480044: step 3417, loss = 0.69781 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:58:56.771033 ops/training.py:65 2019-01-17 00:58:56.770922: step 3418, loss = 0.69395 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:58:58.058082 ops/training.py:65 2019-01-17 00:58:58.058015: step 3419, loss = 0.74726 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:58:59.343245 ops/training.py:65 2019-01-17 00:58:59.343135: step 3420, loss = 0.70870 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:59:00.633906 ops/training.py:65 2019-01-17 00:59:00.633791: step 3421, loss = 0.72309 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:59:01.918464 ops/training.py:65 2019-01-17 00:59:01.918388: step 3422, loss = 0.71249 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:59:03.206337 ops/training.py:65 2019-01-17 00:59:03.206224: step 3423, loss = 0.74780 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:59:04.489177 ops/training.py:65 2019-01-17 00:59:04.489063: step 3424, loss = 0.71755 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:59:05.772947 ops/training.py:65 2019-01-17 00:59:05.772833: step 3425, loss = 0.65599 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:59:07.059315 ops/training.py:65 2019-01-17 00:59:07.059197: step 3426, loss = 0.74228 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:59:08.341114 ops/training.py:65 2019-01-17 00:59:08.341009: step 3427, loss = 0.70149 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:59:09.630857 ops/training.py:65 2019-01-17 00:59:09.630749: step 3428, loss = 0.74674 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:59:10.916967 ops/training.py:65 2019-01-17 00:59:10.916857: step 3429, loss = 0.71028 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:59:12.202111 ops/training.py:65 2019-01-17 00:59:12.201967: step 3430, loss = 0.65490 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 00:59:13.489105 ops/training.py:65 2019-01-17 00:59:13.488995: step 3431, loss = 0.68418 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:59:14.775378 ops/training.py:65 2019-01-17 00:59:14.775275: step 3432, loss = 0.76179 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:59:16.059962 ops/training.py:65 2019-01-17 00:59:16.059849: step 3433, loss = 0.69411 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:59:17.346023 ops/training.py:65 2019-01-17 00:59:17.345921: step 3434, loss = 0.70921 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:59:18.627699 ops/training.py:65 2019-01-17 00:59:18.627590: step 3435, loss = 0.74888 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:59:19.917493 ops/training.py:65 2019-01-17 00:59:19.917384: step 3436, loss = 0.82375 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:59:21.199646 ops/training.py:65 2019-01-17 00:59:21.199536: step 3437, loss = 0.69061 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:59:22.480736 ops/training.py:65 2019-01-17 00:59:22.480621: step 3438, loss = 0.79592 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:59:23.764515 ops/training.py:65 2019-01-17 00:59:23.764414: step 3439, loss = 0.79778 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:59:25.046509 ops/training.py:65 2019-01-17 00:59:25.046402: step 3440, loss = 0.65020 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:59:26.327636 ops/training.py:65 2019-01-17 00:59:26.327526: step 3441, loss = 0.76717 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:59:27.613115 ops/training.py:65 2019-01-17 00:59:27.612996: step 3442, loss = 0.73974 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:59:28.905088 ops/training.py:65 2019-01-17 00:59:28.904927: step 3443, loss = 0.65142 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 00:59:30.187175 ops/training.py:65 2019-01-17 00:59:30.187065: step 3444, loss = 0.69509 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:59:31.475011 ops/training.py:65 2019-01-17 00:59:31.474846: step 3445, loss = 0.74924 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 00:59:32.762247 ops/training.py:65 2019-01-17 00:59:32.762142: step 3446, loss = 0.65712 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:59:34.042812 ops/training.py:65 2019-01-17 00:59:34.042658: step 3447, loss = 0.68524 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:59:35.332048 ops/training.py:65 2019-01-17 00:59:35.331887: step 3448, loss = 0.76944 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 00:59:36.618712 ops/training.py:65 2019-01-17 00:59:36.618616: step 3449, loss = 0.74037 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:59:37.902781 ops/training.py:65 2019-01-17 00:59:37.902684: step 3450, loss = 0.72252 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:59:39.189705 ops/training.py:65 2019-01-17 00:59:39.189596: step 3451, loss = 0.72047 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 00:59:40.477648 ops/training.py:65 2019-01-17 00:59:40.477540: step 3452, loss = 0.71068 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:59:41.762543 ops/training.py:65 2019-01-17 00:59:41.762442: step 3453, loss = 0.70465 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:59:43.044598 ops/training.py:65 2019-01-17 00:59:43.044484: step 3454, loss = 0.74463 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 00:59:44.322744 ops/training.py:65 2019-01-17 00:59:44.322639: step 3455, loss = 0.66893 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:59:45.614412 ops/training.py:65 2019-01-17 00:59:45.614311: step 3456, loss = 0.73592 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:59:46.899076 ops/training.py:65 2019-01-17 00:59:46.898967: step 3457, loss = 0.69824 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:59:48.183816 ops/training.py:65 2019-01-17 00:59:48.183710: step 3458, loss = 0.66459 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 00:59:49.469841 ops/training.py:65 2019-01-17 00:59:49.469733: step 3459, loss = 0.71829 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:59:50.759784 ops/training.py:65 2019-01-17 00:59:50.759625: step 3460, loss = 0.72005 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 00:59:52.044922 ops/training.py:65 2019-01-17 00:59:52.044813: step 3461, loss = 0.62818 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 00:59:53.336006 ops/training.py:65 2019-01-17 00:59:53.335871: step 3462, loss = 0.66551 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 00:59:54.626669 ops/training.py:65 2019-01-17 00:59:54.626601: step 3463, loss = 0.68732 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:59:55.910248 ops/training.py:65 2019-01-17 00:59:55.910138: step 3464, loss = 0.69458 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 00:59:57.194467 ops/training.py:65 2019-01-17 00:59:57.194312: step 3465, loss = 0.68585 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 00:59:58.483144 ops/training.py:65 2019-01-17 00:59:58.482979: step 3466, loss = 0.69152 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 00:59:59.766734 ops/training.py:65 2019-01-17 00:59:59.766628: step 3467, loss = 0.70090 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:00:01.056685 ops/training.py:65 2019-01-17 01:00:01.056586: step 3468, loss = 0.69234 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:00:02.337941 ops/training.py:65 2019-01-17 01:00:02.337910: step 3469, loss = 0.68723 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:00:03.616133 ops/training.py:65 2019-01-17 01:00:03.616051: step 3470, loss = 0.69279 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:00:04.900153 ops/training.py:65 2019-01-17 01:00:04.900066: step 3471, loss = 0.69358 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:00:06.188852 ops/training.py:65 2019-01-17 01:00:06.188690: step 3472, loss = 0.70922 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:00:07.481910 ops/training.py:65 2019-01-17 01:00:07.481817: step 3473, loss = 0.73284 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:00:08.766302 ops/training.py:65 2019-01-17 01:00:08.766221: step 3474, loss = 0.71918 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:00:10.053640 ops/training.py:65 2019-01-17 01:00:10.053528: step 3475, loss = 0.69430 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:00:11.337969 ops/training.py:65 2019-01-17 01:00:11.337860: step 3476, loss = 0.72595 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:00:12.630697 ops/training.py:65 2019-01-17 01:00:12.630589: step 3477, loss = 0.70104 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:00:13.916934 ops/training.py:65 2019-01-17 01:00:13.916853: step 3478, loss = 0.74559 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:00:15.202197 ops/training.py:65 2019-01-17 01:00:15.202086: step 3479, loss = 0.72763 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:00:16.489313 ops/training.py:65 2019-01-17 01:00:16.489202: step 3480, loss = 0.67329 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:00:17.774060 ops/training.py:65 2019-01-17 01:00:17.773958: step 3481, loss = 0.69648 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:00:19.051011 ops/training.py:65 2019-01-17 01:00:19.050902: step 3482, loss = 0.70820 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:00:20.329755 ops/training.py:65 2019-01-17 01:00:20.329652: step 3483, loss = 0.71716 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:00:21.614140 ops/training.py:65 2019-01-17 01:00:21.614028: step 3484, loss = 0.71696 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:00:22.900438 ops/training.py:65 2019-01-17 01:00:22.900341: step 3485, loss = 0.66943 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:00:24.186639 ops/training.py:65 2019-01-17 01:00:24.186542: step 3486, loss = 0.78695 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:00:25.463662 ops/training.py:65 2019-01-17 01:00:25.463563: step 3487, loss = 0.68337 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:00:26.753278 ops/training.py:65 2019-01-17 01:00:26.753176: step 3488, loss = 0.69671 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:00:28.039651 ops/training.py:65 2019-01-17 01:00:28.039546: step 3489, loss = 0.69528 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:00:29.324710 ops/training.py:65 2019-01-17 01:00:29.324600: step 3490, loss = 0.71806 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:00:30.603494 ops/training.py:65 2019-01-17 01:00:30.603381: step 3491, loss = 0.67829 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:00:31.888674 ops/training.py:65 2019-01-17 01:00:31.888565: step 3492, loss = 0.77077 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:00:33.170450 ops/training.py:65 2019-01-17 01:00:33.170344: step 3493, loss = 0.65643 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:00:34.454675 ops/training.py:65 2019-01-17 01:00:34.454567: step 3494, loss = 0.68128 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:00:35.735931 ops/training.py:65 2019-01-17 01:00:35.735823: step 3495, loss = 0.69317 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:00:37.019111 ops/training.py:65 2019-01-17 01:00:37.019002: step 3496, loss = 0.72512 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:00:38.305546 ops/training.py:65 2019-01-17 01:00:38.305448: step 3497, loss = 0.69672 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:00:39.590334 ops/training.py:65 2019-01-17 01:00:39.590227: step 3498, loss = 0.66972 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:00:40.877728 ops/training.py:65 2019-01-17 01:00:40.877630: step 3499, loss = 0.71095 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:00:42.164196 ops/training.py:65 2019-01-17 01:00:42.164092: step 3500, loss = 0.73750 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:00:43.450654 ops/training.py:65 2019-01-17 01:00:43.450547: step 3501, loss = 0.70588 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:00:44.734309 ops/training.py:65 2019-01-17 01:00:44.734212: step 3502, loss = 0.67907 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:00:46.018367 ops/training.py:65 2019-01-17 01:00:46.018268: step 3503, loss = 0.68839 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:00:47.310896 ops/training.py:65 2019-01-17 01:00:47.310786: step 3504, loss = 0.64926 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:00:48.595368 ops/training.py:65 2019-01-17 01:00:48.595260: step 3505, loss = 0.72795 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:00:49.878936 ops/training.py:65 2019-01-17 01:00:49.878795: step 3506, loss = 0.69603 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:00:51.162625 ops/training.py:65 2019-01-17 01:00:51.162522: step 3507, loss = 0.70697 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:00:52.443180 ops/training.py:65 2019-01-17 01:00:52.443074: step 3508, loss = 0.67945 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:00:53.734210 ops/training.py:65 2019-01-17 01:00:53.734074: step 3509, loss = 0.66026 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:00:55.017783 ops/training.py:65 2019-01-17 01:00:55.017675: step 3510, loss = 0.72277 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:00:56.300496 ops/training.py:65 2019-01-17 01:00:56.300392: step 3511, loss = 0.72192 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:00:57.587530 ops/training.py:65 2019-01-17 01:00:57.587412: step 3512, loss = 0.68608 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:00:58.871189 ops/training.py:65 2019-01-17 01:00:58.871083: step 3513, loss = 0.66822 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:01:00.160053 ops/training.py:65 2019-01-17 01:01:00.159935: step 3514, loss = 0.67070 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:01:01.444554 ops/training.py:65 2019-01-17 01:01:01.444455: step 3515, loss = 0.71970 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:01:02.729494 ops/training.py:65 2019-01-17 01:01:02.729386: step 3516, loss = 0.72627 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:01:04.017515 ops/training.py:65 2019-01-17 01:01:04.017412: step 3517, loss = 0.73142 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:01:05.301469 ops/training.py:65 2019-01-17 01:01:05.301359: step 3518, loss = 0.68348 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:01:06.593921 ops/training.py:65 2019-01-17 01:01:06.593809: step 3519, loss = 0.69613 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:01:07.877569 ops/training.py:65 2019-01-17 01:01:07.877505: step 3520, loss = 0.68165 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:01:09.166873 ops/training.py:65 2019-01-17 01:01:09.166761: step 3521, loss = 0.72843 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:01:10.453346 ops/training.py:65 2019-01-17 01:01:10.453237: step 3522, loss = 0.69459 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:01:11.734252 ops/training.py:65 2019-01-17 01:01:11.734147: step 3523, loss = 0.70066 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:01:13.017567 ops/training.py:65 2019-01-17 01:01:13.017464: step 3524, loss = 0.67709 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:01:14.297155 ops/training.py:65 2019-01-17 01:01:14.297043: step 3525, loss = 0.71305 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:01:15.586170 ops/training.py:65 2019-01-17 01:01:15.586059: step 3526, loss = 0.69759 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:01:16.878881 ops/training.py:65 2019-01-17 01:01:16.878798: step 3527, loss = 0.69717 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:01:18.164108 ops/training.py:65 2019-01-17 01:01:18.164038: step 3528, loss = 0.68770 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:01:19.447756 ops/training.py:65 2019-01-17 01:01:19.447643: step 3529, loss = 0.71817 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:01:20.738884 ops/training.py:65 2019-01-17 01:01:20.738725: step 3530, loss = 0.69578 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:01:22.021072 ops/training.py:65 2019-01-17 01:01:22.021009: step 3531, loss = 0.64298 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:01:23.300970 ops/training.py:65 2019-01-17 01:01:23.300832: step 3532, loss = 0.67295 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:01:24.588622 ops/training.py:65 2019-01-17 01:01:24.588509: step 3533, loss = 0.71695 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:01:25.880068 ops/training.py:65 2019-01-17 01:01:25.879953: step 3534, loss = 0.72009 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:01:27.163810 ops/training.py:65 2019-01-17 01:01:27.163701: step 3535, loss = 0.68443 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:01:28.454903 ops/training.py:65 2019-01-17 01:01:28.454797: step 3536, loss = 0.69096 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:01:29.742499 ops/training.py:65 2019-01-17 01:01:29.742396: step 3537, loss = 0.68305 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:01:31.026462 ops/training.py:65 2019-01-17 01:01:31.026353: step 3538, loss = 0.67404 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:01:32.319469 ops/training.py:65 2019-01-17 01:01:32.319364: step 3539, loss = 0.70357 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:01:33.611330 ops/training.py:65 2019-01-17 01:01:33.611226: step 3540, loss = 0.68531 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:01:34.897729 ops/training.py:65 2019-01-17 01:01:34.897614: step 3541, loss = 0.69698 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:01:36.189299 ops/training.py:65 2019-01-17 01:01:36.189191: step 3542, loss = 0.70476 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:01:37.480471 ops/training.py:65 2019-01-17 01:01:37.480403: step 3543, loss = 0.71216 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:01:38.769587 ops/training.py:65 2019-01-17 01:01:38.769512: step 3544, loss = 0.71491 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:01:40.054168 ops/training.py:65 2019-01-17 01:01:40.054095: step 3545, loss = 0.74239 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:01:41.337826 ops/training.py:65 2019-01-17 01:01:41.337758: step 3546, loss = 0.69150 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:01:42.624423 ops/training.py:65 2019-01-17 01:01:42.624311: step 3547, loss = 0.71299 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:01:43.909491 ops/training.py:65 2019-01-17 01:01:43.909387: step 3548, loss = 0.73722 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:01:45.199161 ops/training.py:65 2019-01-17 01:01:45.199052: step 3549, loss = 0.66588 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:01:46.483733 ops/training.py:65 2019-01-17 01:01:46.483625: step 3550, loss = 0.74345 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:01:47.775048 ops/training.py:65 2019-01-17 01:01:47.774946: step 3551, loss = 0.74291 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:01:49.059710 ops/training.py:65 2019-01-17 01:01:49.059610: step 3552, loss = 0.69286 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:01:50.351340 ops/training.py:65 2019-01-17 01:01:50.351232: step 3553, loss = 0.70899 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:01:51.637449 ops/training.py:65 2019-01-17 01:01:51.637386: step 3554, loss = 0.68401 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:01:52.920973 ops/training.py:65 2019-01-17 01:01:52.920876: step 3555, loss = 0.72129 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:01:54.204268 ops/training.py:65 2019-01-17 01:01:54.204162: step 3556, loss = 0.70694 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:01:55.490103 ops/training.py:65 2019-01-17 01:01:55.489991: step 3557, loss = 0.67285 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:01:56.775246 ops/training.py:65 2019-01-17 01:01:56.775106: step 3558, loss = 0.66477 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:01:58.057245 ops/training.py:65 2019-01-17 01:01:58.057143: step 3559, loss = 0.71177 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:01:59.336978 ops/training.py:65 2019-01-17 01:01:59.336870: step 3560, loss = 0.69387 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:02:00.619515 ops/training.py:65 2019-01-17 01:02:00.619357: step 3561, loss = 0.72137 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:02:01.911155 ops/training.py:65 2019-01-17 01:02:01.911001: step 3562, loss = 0.68287 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:02:03.202971 ops/training.py:65 2019-01-17 01:02:03.202894: step 3563, loss = 0.70438 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:02:04.488571 ops/training.py:65 2019-01-17 01:02:04.488500: step 3564, loss = 0.66849 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:02:05.775011 ops/training.py:65 2019-01-17 01:02:05.774892: step 3565, loss = 0.64263 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:02:07.066791 ops/training.py:65 2019-01-17 01:02:07.066686: step 3566, loss = 0.70004 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:02:08.358081 ops/training.py:65 2019-01-17 01:02:08.357985: step 3567, loss = 0.69950 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:02:09.644567 ops/training.py:65 2019-01-17 01:02:09.644454: step 3568, loss = 0.72640 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:02:10.933532 ops/training.py:65 2019-01-17 01:02:10.933423: step 3569, loss = 0.70482 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:02:12.219817 ops/training.py:65 2019-01-17 01:02:12.219697: step 3570, loss = 0.70186 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:02:13.503629 ops/training.py:65 2019-01-17 01:02:13.503474: step 3571, loss = 0.70859 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:02:14.792170 ops/training.py:65 2019-01-17 01:02:14.792069: step 3572, loss = 0.70201 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:02:16.077353 ops/training.py:65 2019-01-17 01:02:16.077250: step 3573, loss = 0.68244 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:02:17.364550 ops/training.py:65 2019-01-17 01:02:17.364439: step 3574, loss = 0.68093 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:02:18.649569 ops/training.py:65 2019-01-17 01:02:18.649459: step 3575, loss = 0.70810 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:02:19.941146 ops/training.py:65 2019-01-17 01:02:19.941037: step 3576, loss = 0.68463 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:02:21.230323 ops/training.py:65 2019-01-17 01:02:21.230257: step 3577, loss = 0.73427 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:02:22.513105 ops/training.py:65 2019-01-17 01:02:22.513040: step 3578, loss = 0.74209 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:02:23.799844 ops/training.py:65 2019-01-17 01:02:23.799738: step 3579, loss = 0.66302 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:02:25.086997 ops/training.py:65 2019-01-17 01:02:25.086885: step 3580, loss = 0.68843 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:02:26.375387 ops/training.py:65 2019-01-17 01:02:26.375278: step 3581, loss = 0.68053 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:02:27.656619 ops/training.py:65 2019-01-17 01:02:27.656503: step 3582, loss = 0.72650 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:02:28.944374 ops/training.py:65 2019-01-17 01:02:28.944262: step 3583, loss = 0.68090 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:02:30.231076 ops/training.py:65 2019-01-17 01:02:30.230971: step 3584, loss = 0.66295 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:02:31.520064 ops/training.py:65 2019-01-17 01:02:31.519949: step 3585, loss = 0.70429 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:02:32.805874 ops/training.py:65 2019-01-17 01:02:32.805759: step 3586, loss = 0.71791 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:02:34.087650 ops/training.py:65 2019-01-17 01:02:34.087542: step 3587, loss = 0.72399 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:02:35.381175 ops/training.py:65 2019-01-17 01:02:35.381063: step 3588, loss = 0.72486 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:02:36.661530 ops/training.py:65 2019-01-17 01:02:36.661467: step 3589, loss = 0.64805 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 01:02:37.948385 ops/training.py:65 2019-01-17 01:02:37.948282: step 3590, loss = 0.69161 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:02:39.232160 ops/training.py:65 2019-01-17 01:02:39.232061: step 3591, loss = 0.70061 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:02:40.515813 ops/training.py:65 2019-01-17 01:02:40.515719: step 3592, loss = 0.69261 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:02:41.800390 ops/training.py:65 2019-01-17 01:02:41.800289: step 3593, loss = 0.66814 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:02:43.089525 ops/training.py:65 2019-01-17 01:02:43.089423: step 3594, loss = 0.69862 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:02:44.371317 ops/training.py:65 2019-01-17 01:02:44.371209: step 3595, loss = 0.71439 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:02:45.655614 ops/training.py:65 2019-01-17 01:02:45.655520: step 3596, loss = 0.66300 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:02:46.942638 ops/training.py:65 2019-01-17 01:02:46.942531: step 3597, loss = 0.72872 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:02:48.228192 ops/training.py:65 2019-01-17 01:02:48.228092: step 3598, loss = 0.74165 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:02:49.519844 ops/training.py:65 2019-01-17 01:02:49.519737: step 3599, loss = 0.72145 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:02:50.805600 ops/training.py:65 2019-01-17 01:02:50.805496: step 3600, loss = 0.67940 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:02:52.093802 ops/training.py:65 2019-01-17 01:02:52.093730: step 3601, loss = 0.66663 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:02:53.383373 ops/training.py:65 2019-01-17 01:02:53.383288: step 3602, loss = 0.69541 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:02:54.665747 ops/training.py:65 2019-01-17 01:02:54.665669: step 3603, loss = 0.69889 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:02:55.946660 ops/training.py:65 2019-01-17 01:02:55.946556: step 3604, loss = 0.70712 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:02:57.223832 ops/training.py:65 2019-01-17 01:02:57.223728: step 3605, loss = 0.67028 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:02:58.509809 ops/training.py:65 2019-01-17 01:02:58.509703: step 3606, loss = 0.71532 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:02:59.793133 ops/training.py:65 2019-01-17 01:02:59.793030: step 3607, loss = 0.66958 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:03:01.073981 ops/training.py:65 2019-01-17 01:03:01.073879: step 3608, loss = 0.65617 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 01:03:02.354549 ops/training.py:65 2019-01-17 01:03:02.354434: step 3609, loss = 0.66154 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:03:03.641313 ops/training.py:65 2019-01-17 01:03:03.641211: step 3610, loss = 0.67973 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:03:04.925932 ops/training.py:65 2019-01-17 01:03:04.925838: step 3611, loss = 0.67844 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:03:06.210684 ops/training.py:65 2019-01-17 01:03:06.210618: step 3612, loss = 0.71162 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:03:07.500434 ops/training.py:65 2019-01-17 01:03:07.500320: step 3613, loss = 0.66772 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:03:08.785988 ops/training.py:65 2019-01-17 01:03:08.785923: step 3614, loss = 0.71046 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:03:10.071122 ops/training.py:65 2019-01-17 01:03:10.071038: step 3615, loss = 0.67983 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:03:11.361559 ops/training.py:65 2019-01-17 01:03:11.361455: step 3616, loss = 0.67180 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:03:12.646951 ops/training.py:65 2019-01-17 01:03:12.646866: step 3617, loss = 0.71587 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:03:13.929211 ops/training.py:65 2019-01-17 01:03:13.929111: step 3618, loss = 0.69470 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:03:15.212824 ops/training.py:65 2019-01-17 01:03:15.212714: step 3619, loss = 0.66368 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:03:16.501401 ops/training.py:65 2019-01-17 01:03:16.501296: step 3620, loss = 0.66095 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:03:17.793225 ops/training.py:65 2019-01-17 01:03:17.793149: step 3621, loss = 0.72977 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:03:19.081506 ops/training.py:65 2019-01-17 01:03:19.081436: step 3622, loss = 0.67693 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:03:20.371451 ops/training.py:65 2019-01-17 01:03:20.371371: step 3623, loss = 0.70947 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:03:21.656225 ops/training.py:65 2019-01-17 01:03:21.656153: step 3624, loss = 0.72495 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:03:22.935547 ops/training.py:65 2019-01-17 01:03:22.935453: step 3625, loss = 0.68054 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:03:24.215857 ops/training.py:65 2019-01-17 01:03:24.215762: step 3626, loss = 0.70363 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:03:25.503848 ops/training.py:65 2019-01-17 01:03:25.503743: step 3627, loss = 0.69199 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:03:26.795730 ops/training.py:65 2019-01-17 01:03:26.795621: step 3628, loss = 0.67201 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:03:28.082446 ops/training.py:65 2019-01-17 01:03:28.082338: step 3629, loss = 0.71833 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:03:29.365599 ops/training.py:65 2019-01-17 01:03:29.365489: step 3630, loss = 0.69328 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:03:30.657594 ops/training.py:65 2019-01-17 01:03:30.657437: step 3631, loss = 0.68046 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:03:31.944939 ops/training.py:65 2019-01-17 01:03:31.944785: step 3632, loss = 0.62416 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:03:33.231094 ops/training.py:65 2019-01-17 01:03:33.230988: step 3633, loss = 0.70493 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:03:34.520332 ops/training.py:65 2019-01-17 01:03:34.520225: step 3634, loss = 0.66990 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:03:35.802208 ops/training.py:65 2019-01-17 01:03:35.802098: step 3635, loss = 0.72024 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:03:37.092970 ops/training.py:65 2019-01-17 01:03:37.092875: step 3636, loss = 0.68963 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:03:38.381073 ops/training.py:65 2019-01-17 01:03:38.380942: step 3637, loss = 0.69974 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:03:39.673014 ops/training.py:65 2019-01-17 01:03:39.672900: step 3638, loss = 0.69648 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:03:40.960229 ops/training.py:65 2019-01-17 01:03:40.960121: step 3639, loss = 0.71137 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:03:42.246459 ops/training.py:65 2019-01-17 01:03:42.246379: step 3640, loss = 0.68710 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:03:43.534986 ops/training.py:65 2019-01-17 01:03:43.534877: step 3641, loss = 0.70711 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:03:44.820417 ops/training.py:65 2019-01-17 01:03:44.820304: step 3642, loss = 0.67268 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:03:46.110994 ops/training.py:65 2019-01-17 01:03:46.110886: step 3643, loss = 0.69902 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:03:47.399730 ops/training.py:65 2019-01-17 01:03:47.399649: step 3644, loss = 0.75520 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:03:48.689226 ops/training.py:65 2019-01-17 01:03:48.689150: step 3645, loss = 0.66942 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:03:49.978505 ops/training.py:65 2019-01-17 01:03:49.978426: step 3646, loss = 0.72816 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:03:51.268937 ops/training.py:65 2019-01-17 01:03:51.268853: step 3647, loss = 0.68345 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:03:52.556711 ops/training.py:65 2019-01-17 01:03:52.556622: step 3648, loss = 0.69462 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:03:53.842076 ops/training.py:65 2019-01-17 01:03:53.842008: step 3649, loss = 0.67267 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:03:55.130756 ops/training.py:65 2019-01-17 01:03:55.130672: step 3650, loss = 0.71619 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:03:56.419682 ops/training.py:65 2019-01-17 01:03:56.419605: step 3651, loss = 0.68220 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:03:57.704454 ops/training.py:65 2019-01-17 01:03:57.704382: step 3652, loss = 0.73294 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:03:58.992729 ops/training.py:65 2019-01-17 01:03:58.992628: step 3653, loss = 0.68545 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:04:00.277923 ops/training.py:65 2019-01-17 01:04:00.277815: step 3654, loss = 0.73976 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:04:01.563661 ops/training.py:65 2019-01-17 01:04:01.563565: step 3655, loss = 0.65208 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:04:02.853929 ops/training.py:65 2019-01-17 01:04:02.853820: step 3656, loss = 0.68865 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:04:04.144093 ops/training.py:65 2019-01-17 01:04:04.143991: step 3657, loss = 0.74416 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:04:05.434559 ops/training.py:65 2019-01-17 01:04:05.434458: step 3658, loss = 0.72744 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:04:06.723643 ops/training.py:65 2019-01-17 01:04:06.723538: step 3659, loss = 0.71423 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:04:08.010045 ops/training.py:65 2019-01-17 01:04:08.009978: step 3660, loss = 0.69330 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:04:09.295642 ops/training.py:65 2019-01-17 01:04:09.295532: step 3661, loss = 0.70948 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:04:10.587454 ops/training.py:65 2019-01-17 01:04:10.587310: step 3662, loss = 0.69848 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:04:11.867619 ops/training.py:65 2019-01-17 01:04:11.867552: step 3663, loss = 0.73676 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:04:13.146452 ops/training.py:65 2019-01-17 01:04:13.146345: step 3664, loss = 0.65205 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 01:04:14.428151 ops/training.py:65 2019-01-17 01:04:14.428040: step 3665, loss = 0.67731 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:04:15.716616 ops/training.py:65 2019-01-17 01:04:15.716502: step 3666, loss = 0.74644 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:04:16.998346 ops/training.py:65 2019-01-17 01:04:16.998234: step 3667, loss = 0.73801 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:04:18.285359 ops/training.py:65 2019-01-17 01:04:18.285249: step 3668, loss = 0.73334 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:04:19.565260 ops/training.py:65 2019-01-17 01:04:19.565150: step 3669, loss = 0.74489 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:04:20.851620 ops/training.py:65 2019-01-17 01:04:20.851468: step 3670, loss = 0.71392 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:04:22.138495 ops/training.py:65 2019-01-17 01:04:22.138394: step 3671, loss = 0.65407 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:04:23.423677 ops/training.py:65 2019-01-17 01:04:23.423577: step 3672, loss = 0.74271 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:04:24.713885 ops/training.py:65 2019-01-17 01:04:24.713782: step 3673, loss = 0.68661 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:04:26.004310 ops/training.py:65 2019-01-17 01:04:26.004170: step 3674, loss = 0.73297 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:04:27.288985 ops/training.py:65 2019-01-17 01:04:27.288914: step 3675, loss = 0.69575 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:04:28.573162 ops/training.py:65 2019-01-17 01:04:28.573068: step 3676, loss = 0.73084 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:04:29.859424 ops/training.py:65 2019-01-17 01:04:29.859315: step 3677, loss = 0.69126 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:04:31.142850 ops/training.py:65 2019-01-17 01:04:31.142757: step 3678, loss = 0.66512 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:04:32.435568 ops/training.py:65 2019-01-17 01:04:32.435498: step 3679, loss = 0.70505 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:04:33.718408 ops/training.py:65 2019-01-17 01:04:33.718332: step 3680, loss = 0.71711 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:04:35.004964 ops/training.py:65 2019-01-17 01:04:35.004882: step 3681, loss = 0.67337 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:04:36.288390 ops/training.py:65 2019-01-17 01:04:36.288314: step 3682, loss = 0.66319 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:04:37.580836 ops/training.py:65 2019-01-17 01:04:37.580682: step 3683, loss = 0.68720 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:04:38.867122 ops/training.py:65 2019-01-17 01:04:38.867050: step 3684, loss = 0.68033 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:04:40.150902 ops/training.py:65 2019-01-17 01:04:40.150801: step 3685, loss = 0.72497 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:04:41.435005 ops/training.py:65 2019-01-17 01:04:41.434914: step 3686, loss = 0.73193 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:04:42.721389 ops/training.py:65 2019-01-17 01:04:42.721288: step 3687, loss = 0.67268 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:04:44.013497 ops/training.py:65 2019-01-17 01:04:44.013393: step 3688, loss = 0.68846 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:04:45.294597 ops/training.py:65 2019-01-17 01:04:45.294541: step 3689, loss = 0.77893 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:04:46.585236 ops/training.py:65 2019-01-17 01:04:46.585169: step 3690, loss = 0.67602 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:04:47.870129 ops/training.py:65 2019-01-17 01:04:47.870058: step 3691, loss = 0.71312 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:04:49.154076 ops/training.py:65 2019-01-17 01:04:49.154007: step 3692, loss = 0.71317 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:04:50.435395 ops/training.py:65 2019-01-17 01:04:50.435334: step 3693, loss = 0.70419 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:04:51.719029 ops/training.py:65 2019-01-17 01:04:51.718967: step 3694, loss = 0.67897 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:04:53.001351 ops/training.py:65 2019-01-17 01:04:53.001304: step 3695, loss = 0.73929 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:04:54.287058 ops/training.py:65 2019-01-17 01:04:54.287027: step 3696, loss = 0.72523 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:04:55.569469 ops/training.py:65 2019-01-17 01:04:55.569419: step 3697, loss = 0.70893 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:04:56.849833 ops/training.py:65 2019-01-17 01:04:56.849794: step 3698, loss = 0.67607 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:04:58.132904 ops/training.py:65 2019-01-17 01:04:58.132873: step 3699, loss = 0.74913 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:04:59.424931 ops/training.py:65 2019-01-17 01:04:59.424825: step 3700, loss = 0.70369 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:05:00.713314 ops/training.py:65 2019-01-17 01:05:00.713202: step 3701, loss = 0.69088 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:05:02.002594 ops/training.py:65 2019-01-17 01:05:02.002502: step 3702, loss = 0.67899 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:05:03.292820 ops/training.py:65 2019-01-17 01:05:03.292744: step 3703, loss = 0.67086 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:05:04.581814 ops/training.py:65 2019-01-17 01:05:04.581702: step 3704, loss = 0.74434 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:05:05.871569 ops/training.py:65 2019-01-17 01:05:05.871470: step 3705, loss = 0.69645 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:05:07.162099 ops/training.py:65 2019-01-17 01:05:07.162016: step 3706, loss = 0.75642 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:05:08.450865 ops/training.py:65 2019-01-17 01:05:08.450782: step 3707, loss = 0.71325 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:05:09.740594 ops/training.py:65 2019-01-17 01:05:09.740508: step 3708, loss = 0.65422 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:05:11.030682 ops/training.py:65 2019-01-17 01:05:11.030596: step 3709, loss = 0.69622 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:05:12.319630 ops/training.py:65 2019-01-17 01:05:12.319563: step 3710, loss = 0.68403 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:05:13.607130 ops/training.py:65 2019-01-17 01:05:13.607058: step 3711, loss = 0.70132 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:05:14.896853 ops/training.py:65 2019-01-17 01:05:14.896773: step 3712, loss = 0.72520 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:05:16.186214 ops/training.py:65 2019-01-17 01:05:16.186122: step 3713, loss = 0.71878 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:05:17.476752 ops/training.py:65 2019-01-17 01:05:17.476660: step 3714, loss = 0.69828 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:05:18.764891 ops/training.py:65 2019-01-17 01:05:18.764804: step 3715, loss = 0.65386 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:05:20.054433 ops/training.py:65 2019-01-17 01:05:20.054359: step 3716, loss = 0.70460 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:05:21.338314 ops/training.py:65 2019-01-17 01:05:21.338238: step 3717, loss = 0.74068 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:05:22.635377 ops/training.py:65 2019-01-17 01:05:22.635217: step 3718, loss = 0.67900 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:05:23.922007 ops/training.py:65 2019-01-17 01:05:23.921932: step 3719, loss = 0.64744 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:05:25.211062 ops/training.py:65 2019-01-17 01:05:25.210979: step 3720, loss = 0.74024 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:05:26.498320 ops/training.py:65 2019-01-17 01:05:26.498251: step 3721, loss = 0.72496 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:05:27.783361 ops/training.py:65 2019-01-17 01:05:27.783253: step 3722, loss = 0.67466 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:05:29.069429 ops/training.py:65 2019-01-17 01:05:29.069285: step 3723, loss = 0.70076 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:05:30.357632 ops/training.py:65 2019-01-17 01:05:30.357530: step 3724, loss = 0.71846 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:05:31.648958 ops/training.py:65 2019-01-17 01:05:31.648848: step 3725, loss = 0.72753 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:05:32.936622 ops/training.py:65 2019-01-17 01:05:32.936514: step 3726, loss = 0.66090 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:05:34.225099 ops/training.py:65 2019-01-17 01:05:34.224991: step 3727, loss = 0.72706 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:05:35.512232 ops/training.py:65 2019-01-17 01:05:35.512125: step 3728, loss = 0.69234 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:05:36.800329 ops/training.py:65 2019-01-17 01:05:36.800177: step 3729, loss = 0.70627 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:05:38.087156 ops/training.py:65 2019-01-17 01:05:38.087034: step 3730, loss = 0.69203 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:05:39.374289 ops/training.py:65 2019-01-17 01:05:39.374179: step 3731, loss = 0.70606 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:05:40.655164 ops/training.py:65 2019-01-17 01:05:40.655046: step 3732, loss = 0.75994 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:05:41.939193 ops/training.py:65 2019-01-17 01:05:41.939093: step 3733, loss = 0.68444 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:05:43.227742 ops/training.py:65 2019-01-17 01:05:43.227636: step 3734, loss = 0.70151 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:05:44.512023 ops/training.py:65 2019-01-17 01:05:44.511924: step 3735, loss = 0.75738 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:05:45.799043 ops/training.py:65 2019-01-17 01:05:45.798937: step 3736, loss = 0.69393 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:05:47.084262 ops/training.py:65 2019-01-17 01:05:47.084159: step 3737, loss = 0.67899 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:05:48.383912 ops/training.py:65 2019-01-17 01:05:48.383803: step 3738, loss = 0.71805 (24.6 examples/sec; 1.298 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:05:49.677395 ops/training.py:65 2019-01-17 01:05:49.677289: step 3739, loss = 0.72217 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:05:50.967513 ops/training.py:65 2019-01-17 01:05:50.967407: step 3740, loss = 0.68580 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:05:52.248754 ops/training.py:65 2019-01-17 01:05:52.248685: step 3741, loss = 0.66091 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:05:53.535915 ops/training.py:65 2019-01-17 01:05:53.535817: step 3742, loss = 0.68324 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:05:54.827266 ops/training.py:65 2019-01-17 01:05:54.827161: step 3743, loss = 0.68869 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:05:56.114979 ops/training.py:65 2019-01-17 01:05:56.114864: step 3744, loss = 0.72263 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:05:57.405560 ops/training.py:65 2019-01-17 01:05:57.405456: step 3745, loss = 0.72088 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:05:58.695163 ops/training.py:65 2019-01-17 01:05:58.695048: step 3746, loss = 0.71016 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:05:59.981794 ops/training.py:65 2019-01-17 01:05:59.981708: step 3747, loss = 0.69309 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:06:01.270489 ops/training.py:65 2019-01-17 01:06:01.270385: step 3748, loss = 0.67201 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:06:02.556469 ops/training.py:65 2019-01-17 01:06:02.556401: step 3749, loss = 0.67336 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:06:03.842492 ops/training.py:65 2019-01-17 01:06:03.842390: step 3750, loss = 0.70801 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:06:05.127117 ops/training.py:65 2019-01-17 01:06:05.127007: step 3751, loss = 0.68061 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:06:06.421023 ops/training.py:65 2019-01-17 01:06:06.420914: step 3752, loss = 0.65115 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:06:07.711122 ops/training.py:65 2019-01-17 01:06:07.711043: step 3753, loss = 0.68580 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:06:08.996419 ops/training.py:65 2019-01-17 01:06:08.996347: step 3754, loss = 0.72937 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:06:10.280199 ops/training.py:65 2019-01-17 01:06:10.280094: step 3755, loss = 0.64025 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:06:11.567274 ops/training.py:65 2019-01-17 01:06:11.567158: step 3756, loss = 0.67819 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:06:12.857746 ops/training.py:65 2019-01-17 01:06:12.857647: step 3757, loss = 0.68840 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:06:14.144043 ops/training.py:65 2019-01-17 01:06:14.143976: step 3758, loss = 0.73602 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:06:15.428256 ops/training.py:65 2019-01-17 01:06:15.428171: step 3759, loss = 0.73943 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:06:16.720096 ops/training.py:65 2019-01-17 01:06:16.719988: step 3760, loss = 0.69404 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:06:18.012636 ops/training.py:65 2019-01-17 01:06:18.012558: step 3761, loss = 0.69808 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:06:19.293915 ops/training.py:65 2019-01-17 01:06:19.293840: step 3762, loss = 0.73274 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:06:20.573812 ops/training.py:65 2019-01-17 01:06:20.573660: step 3763, loss = 0.68569 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:06:21.855092 ops/training.py:65 2019-01-17 01:06:21.854982: step 3764, loss = 0.74993 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:06:23.147035 ops/training.py:65 2019-01-17 01:06:23.146936: step 3765, loss = 0.66305 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:06:24.429450 ops/training.py:65 2019-01-17 01:06:24.429295: step 3766, loss = 0.67308 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:06:25.710047 ops/training.py:65 2019-01-17 01:06:25.709930: step 3767, loss = 0.68790 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:06:27.002183 ops/training.py:65 2019-01-17 01:06:27.002084: step 3768, loss = 0.74422 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:06:28.293889 ops/training.py:65 2019-01-17 01:06:28.293768: step 3769, loss = 0.71450 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:06:29.580734 ops/training.py:65 2019-01-17 01:06:29.580667: step 3770, loss = 0.69069 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:06:30.864005 ops/training.py:65 2019-01-17 01:06:30.863901: step 3771, loss = 0.72166 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:06:32.151803 ops/training.py:65 2019-01-17 01:06:32.151696: step 3772, loss = 0.68346 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:06:33.440143 ops/training.py:65 2019-01-17 01:06:33.440049: step 3773, loss = 0.71061 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:06:34.723693 ops/training.py:65 2019-01-17 01:06:34.723588: step 3774, loss = 0.74552 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:06:36.016084 ops/training.py:65 2019-01-17 01:06:36.015922: step 3775, loss = 0.71948 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:06:37.307304 ops/training.py:65 2019-01-17 01:06:37.307197: step 3776, loss = 0.71486 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:06:38.592974 ops/training.py:65 2019-01-17 01:06:38.592896: step 3777, loss = 0.68660 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:06:39.881836 ops/training.py:65 2019-01-17 01:06:39.881728: step 3778, loss = 0.70896 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:06:41.172997 ops/training.py:65 2019-01-17 01:06:41.172897: step 3779, loss = 0.71049 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:06:42.458294 ops/training.py:65 2019-01-17 01:06:42.458211: step 3780, loss = 0.68091 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:06:43.747610 ops/training.py:65 2019-01-17 01:06:43.747527: step 3781, loss = 0.64375 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:06:45.034723 ops/training.py:65 2019-01-17 01:06:45.034649: step 3782, loss = 0.69919 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:06:46.324564 ops/training.py:65 2019-01-17 01:06:46.324420: step 3783, loss = 0.65123 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:06:47.609529 ops/training.py:65 2019-01-17 01:06:47.609427: step 3784, loss = 0.68792 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:06:48.897060 ops/training.py:65 2019-01-17 01:06:48.896955: step 3785, loss = 0.67847 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:06:50.181922 ops/training.py:65 2019-01-17 01:06:50.181817: step 3786, loss = 0.75338 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:06:51.469453 ops/training.py:65 2019-01-17 01:06:51.469332: step 3787, loss = 0.74640 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:06:52.753132 ops/training.py:65 2019-01-17 01:06:52.753023: step 3788, loss = 0.75111 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:06:54.041328 ops/training.py:65 2019-01-17 01:06:54.041237: step 3789, loss = 0.70208 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:06:55.326312 ops/training.py:65 2019-01-17 01:06:55.326212: step 3790, loss = 0.75114 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:06:56.618265 ops/training.py:65 2019-01-17 01:06:56.618104: step 3791, loss = 0.72789 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:06:57.905218 ops/training.py:65 2019-01-17 01:06:57.905101: step 3792, loss = 0.72614 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:06:59.189293 ops/training.py:65 2019-01-17 01:06:59.189194: step 3793, loss = 0.69799 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:07:00.473471 ops/training.py:65 2019-01-17 01:07:00.473315: step 3794, loss = 0.75390 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:07:01.757946 ops/training.py:65 2019-01-17 01:07:01.757838: step 3795, loss = 0.71814 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:07:03.044400 ops/training.py:65 2019-01-17 01:07:03.044242: step 3796, loss = 0.67782 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:07:04.331063 ops/training.py:65 2019-01-17 01:07:04.330915: step 3797, loss = 0.76299 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:07:05.620714 ops/training.py:65 2019-01-17 01:07:05.620601: step 3798, loss = 0.72361 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:07:06.909912 ops/training.py:65 2019-01-17 01:07:06.909838: step 3799, loss = 0.73532 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:07:08.197403 ops/training.py:65 2019-01-17 01:07:08.197327: step 3800, loss = 0.69063 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:07:09.483140 ops/training.py:65 2019-01-17 01:07:09.483065: step 3801, loss = 0.73701 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:07:10.774313 ops/training.py:65 2019-01-17 01:07:10.774152: step 3802, loss = 0.69804 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:07:12.066792 ops/training.py:65 2019-01-17 01:07:12.066673: step 3803, loss = 0.69188 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:07:13.357073 ops/training.py:65 2019-01-17 01:07:13.356997: step 3804, loss = 0.73497 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:07:14.640762 ops/training.py:65 2019-01-17 01:07:14.640672: step 3805, loss = 0.68024 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:07:15.930996 ops/training.py:65 2019-01-17 01:07:15.930841: step 3806, loss = 0.73170 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:07:17.217842 ops/training.py:65 2019-01-17 01:07:17.217762: step 3807, loss = 0.71236 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:07:18.501836 ops/training.py:65 2019-01-17 01:07:18.501722: step 3808, loss = 0.67391 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:07:19.792834 ops/training.py:65 2019-01-17 01:07:19.792728: step 3809, loss = 0.67019 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:07:21.081505 ops/training.py:65 2019-01-17 01:07:21.081427: step 3810, loss = 0.71060 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:07:22.370657 ops/training.py:65 2019-01-17 01:07:22.370567: step 3811, loss = 0.73690 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:07:23.657007 ops/training.py:65 2019-01-17 01:07:23.656921: step 3812, loss = 0.71154 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:07:24.938327 ops/training.py:65 2019-01-17 01:07:24.938265: step 3813, loss = 0.72024 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:07:26.229494 ops/training.py:65 2019-01-17 01:07:26.229386: step 3814, loss = 0.69208 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:07:27.520791 ops/training.py:65 2019-01-17 01:07:27.520701: step 3815, loss = 0.67700 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:07:28.810772 ops/training.py:65 2019-01-17 01:07:28.810696: step 3816, loss = 0.73302 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:07:30.092814 ops/training.py:65 2019-01-17 01:07:30.092735: step 3817, loss = 0.75725 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:07:31.379436 ops/training.py:65 2019-01-17 01:07:31.379363: step 3818, loss = 0.70312 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:07:32.664105 ops/training.py:65 2019-01-17 01:07:32.663999: step 3819, loss = 0.72984 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:07:33.955977 ops/training.py:65 2019-01-17 01:07:33.955870: step 3820, loss = 0.72980 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:07:35.244895 ops/training.py:65 2019-01-17 01:07:35.244786: step 3821, loss = 0.69277 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:07:36.537119 ops/training.py:65 2019-01-17 01:07:36.537033: step 3822, loss = 0.68947 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:07:37.827543 ops/training.py:65 2019-01-17 01:07:37.827465: step 3823, loss = 0.68845 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:07:39.118318 ops/training.py:65 2019-01-17 01:07:39.118237: step 3824, loss = 0.76663 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:07:40.406186 ops/training.py:65 2019-01-17 01:07:40.406098: step 3825, loss = 0.72243 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:07:41.695334 ops/training.py:65 2019-01-17 01:07:41.695261: step 3826, loss = 0.69787 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:07:42.979821 ops/training.py:65 2019-01-17 01:07:42.979743: step 3827, loss = 0.73280 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:07:44.260817 ops/training.py:65 2019-01-17 01:07:44.260712: step 3828, loss = 0.66696 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:07:45.543864 ops/training.py:65 2019-01-17 01:07:45.543756: step 3829, loss = 0.69527 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:07:46.831830 ops/training.py:65 2019-01-17 01:07:46.831727: step 3830, loss = 0.74790 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:07:48.117003 ops/training.py:65 2019-01-17 01:07:48.116858: step 3831, loss = 0.71084 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:07:49.409399 ops/training.py:65 2019-01-17 01:07:49.409289: step 3832, loss = 0.67144 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:07:50.694333 ops/training.py:65 2019-01-17 01:07:50.694252: step 3833, loss = 0.71363 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:07:51.987356 ops/training.py:65 2019-01-17 01:07:51.987199: step 3834, loss = 0.67900 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:07:53.279524 ops/training.py:65 2019-01-17 01:07:53.279429: step 3835, loss = 0.68519 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:07:54.564173 ops/training.py:65 2019-01-17 01:07:54.564096: step 3836, loss = 0.68880 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:07:55.852113 ops/training.py:65 2019-01-17 01:07:55.852005: step 3837, loss = 0.70109 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:07:57.138688 ops/training.py:65 2019-01-17 01:07:57.138620: step 3838, loss = 0.66513 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:07:58.422933 ops/training.py:65 2019-01-17 01:07:58.422848: step 3839, loss = 0.72846 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:07:59.715529 ops/training.py:65 2019-01-17 01:07:59.715423: step 3840, loss = 0.71608 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:08:01.002749 ops/training.py:65 2019-01-17 01:08:01.002641: step 3841, loss = 0.72110 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:08:02.286905 ops/training.py:65 2019-01-17 01:08:02.286769: step 3842, loss = 0.68120 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:08:03.578896 ops/training.py:65 2019-01-17 01:08:03.578788: step 3843, loss = 0.73572 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:08:04.862781 ops/training.py:65 2019-01-17 01:08:04.862671: step 3844, loss = 0.71010 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:08:06.149885 ops/training.py:65 2019-01-17 01:08:06.149780: step 3845, loss = 0.67844 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:08:07.430267 ops/training.py:65 2019-01-17 01:08:07.430157: step 3846, loss = 0.69851 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:08:08.722090 ops/training.py:65 2019-01-17 01:08:08.721996: step 3847, loss = 0.74994 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:08:10.012662 ops/training.py:65 2019-01-17 01:08:10.012568: step 3848, loss = 0.73222 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:08:11.302525 ops/training.py:65 2019-01-17 01:08:11.302418: step 3849, loss = 0.72081 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:08:12.593413 ops/training.py:65 2019-01-17 01:08:12.593338: step 3850, loss = 0.71368 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:08:13.876425 ops/training.py:65 2019-01-17 01:08:13.876358: step 3851, loss = 0.66532 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:08:15.159193 ops/training.py:65 2019-01-17 01:08:15.159081: step 3852, loss = 0.72807 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:08:16.453679 ops/training.py:65 2019-01-17 01:08:16.453569: step 3853, loss = 0.67565 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:08:17.745935 ops/training.py:65 2019-01-17 01:08:17.745823: step 3854, loss = 0.71467 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:08:19.037066 ops/training.py:65 2019-01-17 01:08:19.036956: step 3855, loss = 0.74916 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:08:20.327328 ops/training.py:65 2019-01-17 01:08:20.327223: step 3856, loss = 0.74480 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:08:21.617388 ops/training.py:65 2019-01-17 01:08:21.617311: step 3857, loss = 0.69343 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:08:22.906780 ops/training.py:65 2019-01-17 01:08:22.906702: step 3858, loss = 0.65193 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:08:24.191380 ops/training.py:65 2019-01-17 01:08:24.191306: step 3859, loss = 0.66440 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:08:25.480177 ops/training.py:65 2019-01-17 01:08:25.480074: step 3860, loss = 0.74641 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:08:26.766119 ops/training.py:65 2019-01-17 01:08:26.766048: step 3861, loss = 0.74127 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:08:28.049217 ops/training.py:65 2019-01-17 01:08:28.049108: step 3862, loss = 0.73315 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:08:29.335943 ops/training.py:65 2019-01-17 01:08:29.335844: step 3863, loss = 0.67350 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:08:30.620618 ops/training.py:65 2019-01-17 01:08:30.620519: step 3864, loss = 0.76880 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:08:31.905744 ops/training.py:65 2019-01-17 01:08:31.905670: step 3865, loss = 0.75140 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:08:33.190143 ops/training.py:65 2019-01-17 01:08:33.190109: step 3866, loss = 0.65483 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:08:34.474816 ops/training.py:65 2019-01-17 01:08:34.474784: step 3867, loss = 0.72365 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:08:35.766664 ops/training.py:65 2019-01-17 01:08:35.766584: step 3868, loss = 0.75223 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:08:37.055990 ops/training.py:65 2019-01-17 01:08:37.055900: step 3869, loss = 0.65870 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:08:38.339702 ops/training.py:65 2019-01-17 01:08:38.339643: step 3870, loss = 0.68499 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:08:39.621926 ops/training.py:65 2019-01-17 01:08:39.621894: step 3871, loss = 0.69023 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:08:40.913239 ops/training.py:65 2019-01-17 01:08:40.913209: step 3872, loss = 0.68377 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:08:42.197914 ops/training.py:65 2019-01-17 01:08:42.197871: step 3873, loss = 0.76248 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:08:43.486544 ops/training.py:65 2019-01-17 01:08:43.486500: step 3874, loss = 0.67726 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:08:44.769696 ops/training.py:65 2019-01-17 01:08:44.769661: step 3875, loss = 0.68444 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:08:46.058153 ops/training.py:65 2019-01-17 01:08:46.058110: step 3876, loss = 0.75521 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:08:47.342962 ops/training.py:65 2019-01-17 01:08:47.342888: step 3877, loss = 0.70015 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:08:48.632492 ops/training.py:65 2019-01-17 01:08:48.632417: step 3878, loss = 0.72013 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:08:49.920686 ops/training.py:65 2019-01-17 01:08:49.920651: step 3879, loss = 0.69686 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:08:51.204833 ops/training.py:65 2019-01-17 01:08:51.204803: step 3880, loss = 0.74451 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:08:52.487573 ops/training.py:65 2019-01-17 01:08:52.487526: step 3881, loss = 0.66179 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:08:53.776017 ops/training.py:65 2019-01-17 01:08:53.775979: step 3882, loss = 0.67259 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:08:55.061450 ops/training.py:65 2019-01-17 01:08:55.061412: step 3883, loss = 0.64520 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:08:56.343683 ops/training.py:65 2019-01-17 01:08:56.343586: step 3884, loss = 0.69912 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:08:57.635060 ops/training.py:65 2019-01-17 01:08:57.634952: step 3885, loss = 0.74328 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:08:58.924098 ops/training.py:65 2019-01-17 01:08:58.924006: step 3886, loss = 0.76180 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:09:00.209813 ops/training.py:65 2019-01-17 01:09:00.209745: step 3887, loss = 0.68174 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:09:01.493847 ops/training.py:65 2019-01-17 01:09:01.493746: step 3888, loss = 0.74713 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:09:02.784720 ops/training.py:65 2019-01-17 01:09:02.784617: step 3889, loss = 0.67280 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:09:04.075188 ops/training.py:65 2019-01-17 01:09:04.075104: step 3890, loss = 0.73948 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:09:05.365739 ops/training.py:65 2019-01-17 01:09:05.365661: step 3891, loss = 0.70580 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:09:06.652190 ops/training.py:65 2019-01-17 01:09:06.652118: step 3892, loss = 0.78794 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:09:07.935484 ops/training.py:65 2019-01-17 01:09:07.935330: step 3893, loss = 0.63933 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:09:09.224492 ops/training.py:65 2019-01-17 01:09:09.224355: step 3894, loss = 0.67189 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:09:10.517343 ops/training.py:65 2019-01-17 01:09:10.517187: step 3895, loss = 0.66598 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:09:11.809153 ops/training.py:65 2019-01-17 01:09:11.809051: step 3896, loss = 0.70346 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:09:13.100859 ops/training.py:65 2019-01-17 01:09:13.100778: step 3897, loss = 0.71057 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:09:14.391417 ops/training.py:65 2019-01-17 01:09:14.391339: step 3898, loss = 0.66793 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:09:15.681380 ops/training.py:65 2019-01-17 01:09:15.681292: step 3899, loss = 0.72730 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:09:16.970696 ops/training.py:65 2019-01-17 01:09:16.970611: step 3900, loss = 0.76797 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:09:18.257797 ops/training.py:65 2019-01-17 01:09:18.257714: step 3901, loss = 0.71106 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:09:19.547385 ops/training.py:65 2019-01-17 01:09:19.547305: step 3902, loss = 0.71613 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:09:20.836801 ops/training.py:65 2019-01-17 01:09:20.836697: step 3903, loss = 0.71284 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:09:22.127626 ops/training.py:65 2019-01-17 01:09:22.127543: step 3904, loss = 0.68335 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:09:23.417627 ops/training.py:65 2019-01-17 01:09:23.417548: step 3905, loss = 0.69381 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:09:24.706180 ops/training.py:65 2019-01-17 01:09:24.706065: step 3906, loss = 0.70475 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:09:25.992738 ops/training.py:65 2019-01-17 01:09:25.992653: step 3907, loss = 0.67808 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:09:27.279826 ops/training.py:65 2019-01-17 01:09:27.279714: step 3908, loss = 0.71354 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:09:28.570200 ops/training.py:65 2019-01-17 01:09:28.570088: step 3909, loss = 0.67769 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:09:29.861776 ops/training.py:65 2019-01-17 01:09:29.861658: step 3910, loss = 0.65475 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:09:31.150463 ops/training.py:65 2019-01-17 01:09:31.150382: step 3911, loss = 0.68436 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:09:32.440094 ops/training.py:65 2019-01-17 01:09:32.439969: step 3912, loss = 0.68888 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:09:33.725834 ops/training.py:65 2019-01-17 01:09:33.725744: step 3913, loss = 0.69398 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:09:35.017224 ops/training.py:65 2019-01-17 01:09:35.017112: step 3914, loss = 0.72669 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:09:36.306115 ops/training.py:65 2019-01-17 01:09:36.306025: step 3915, loss = 0.74216 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:09:37.595078 ops/training.py:65 2019-01-17 01:09:37.594992: step 3916, loss = 0.66056 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:09:38.885032 ops/training.py:65 2019-01-17 01:09:38.884951: step 3917, loss = 0.68692 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:09:40.170878 ops/training.py:65 2019-01-17 01:09:40.170767: step 3918, loss = 0.70203 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:09:41.461255 ops/training.py:65 2019-01-17 01:09:41.461138: step 3919, loss = 0.75179 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:09:42.750693 ops/training.py:65 2019-01-17 01:09:42.750594: step 3920, loss = 0.68736 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:09:44.037010 ops/training.py:65 2019-01-17 01:09:44.036922: step 3921, loss = 0.77314 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:09:45.326602 ops/training.py:65 2019-01-17 01:09:45.326529: step 3922, loss = 0.70568 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:09:46.612978 ops/training.py:65 2019-01-17 01:09:46.612906: step 3923, loss = 0.75171 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:09:47.896740 ops/training.py:65 2019-01-17 01:09:47.896633: step 3924, loss = 0.73437 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:09:49.181205 ops/training.py:65 2019-01-17 01:09:49.181111: step 3925, loss = 0.67727 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:09:50.464931 ops/training.py:65 2019-01-17 01:09:50.464777: step 3926, loss = 0.71655 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:09:51.757093 ops/training.py:65 2019-01-17 01:09:51.756986: step 3927, loss = 0.74390 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:09:53.043867 ops/training.py:65 2019-01-17 01:09:53.043791: step 3928, loss = 0.71881 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:09:54.333909 ops/training.py:65 2019-01-17 01:09:54.333828: step 3929, loss = 0.70821 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:09:55.623426 ops/training.py:65 2019-01-17 01:09:55.623347: step 3930, loss = 0.70611 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:09:56.907603 ops/training.py:65 2019-01-17 01:09:56.907530: step 3931, loss = 0.64632 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:09:58.201420 ops/training.py:65 2019-01-17 01:09:58.201314: step 3932, loss = 0.69967 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:09:59.486387 ops/training.py:65 2019-01-17 01:09:59.486279: step 3933, loss = 0.61550 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 01:10:00.775068 ops/training.py:65 2019-01-17 01:10:00.774965: step 3934, loss = 0.68599 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:10:02.059476 ops/training.py:65 2019-01-17 01:10:02.059379: step 3935, loss = 0.65173 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:10:03.342591 ops/training.py:65 2019-01-17 01:10:03.342491: step 3936, loss = 0.78026 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:10:04.635688 ops/training.py:65 2019-01-17 01:10:04.635586: step 3937, loss = 0.73972 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:10:05.925864 ops/training.py:65 2019-01-17 01:10:05.925780: step 3938, loss = 0.71667 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:10:07.215492 ops/training.py:65 2019-01-17 01:10:07.215411: step 3939, loss = 0.74084 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:10:08.505163 ops/training.py:65 2019-01-17 01:10:08.505079: step 3940, loss = 0.66602 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:10:09.795853 ops/training.py:65 2019-01-17 01:10:09.795740: step 3941, loss = 0.74546 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:10:11.076461 ops/training.py:65 2019-01-17 01:10:11.076392: step 3942, loss = 0.73616 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:10:12.369781 ops/training.py:65 2019-01-17 01:10:12.369674: step 3943, loss = 0.74131 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:10:13.662204 ops/training.py:65 2019-01-17 01:10:13.662115: step 3944, loss = 0.64602 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:10:14.952217 ops/training.py:65 2019-01-17 01:10:14.952141: step 3945, loss = 0.69395 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:10:16.235742 ops/training.py:65 2019-01-17 01:10:16.235674: step 3946, loss = 0.65684 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:10:17.520670 ops/training.py:65 2019-01-17 01:10:17.520561: step 3947, loss = 0.70756 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:10:18.809571 ops/training.py:65 2019-01-17 01:10:18.809466: step 3948, loss = 0.70381 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:10:20.096411 ops/training.py:65 2019-01-17 01:10:20.096305: step 3949, loss = 0.69894 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:10:21.377571 ops/training.py:65 2019-01-17 01:10:21.377419: step 3950, loss = 0.72274 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:10:22.656511 ops/training.py:65 2019-01-17 01:10:22.656398: step 3951, loss = 0.65789 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:10:23.944974 ops/training.py:65 2019-01-17 01:10:23.944874: step 3952, loss = 0.69586 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:10:25.224608 ops/training.py:65 2019-01-17 01:10:25.224493: step 3953, loss = 0.72606 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:10:26.507743 ops/training.py:65 2019-01-17 01:10:26.507596: step 3954, loss = 0.74503 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:10:27.795756 ops/training.py:65 2019-01-17 01:10:27.795643: step 3955, loss = 0.70717 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:10:29.083712 ops/training.py:65 2019-01-17 01:10:29.083641: step 3956, loss = 0.65108 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:10:30.367278 ops/training.py:65 2019-01-17 01:10:30.367126: step 3957, loss = 0.69332 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:10:31.654778 ops/training.py:65 2019-01-17 01:10:31.654667: step 3958, loss = 0.70953 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:10:32.942804 ops/training.py:65 2019-01-17 01:10:32.942686: step 3959, loss = 0.71046 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:10:34.233863 ops/training.py:65 2019-01-17 01:10:34.233773: step 3960, loss = 0.75193 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:10:35.523907 ops/training.py:65 2019-01-17 01:10:35.523778: step 3961, loss = 0.67532 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:10:36.810312 ops/training.py:65 2019-01-17 01:10:36.810230: step 3962, loss = 0.72979 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:10:38.089499 ops/training.py:65 2019-01-17 01:10:38.089406: step 3963, loss = 0.65536 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:10:39.369387 ops/training.py:65 2019-01-17 01:10:39.369247: step 3964, loss = 0.69390 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:10:40.659820 ops/training.py:65 2019-01-17 01:10:40.659716: step 3965, loss = 0.68542 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:10:41.950503 ops/training.py:65 2019-01-17 01:10:41.950432: step 3966, loss = 0.76089 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-17 01:10:43.240260 ops/training.py:65 2019-01-17 01:10:43.240185: step 3967, loss = 0.78192 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:10:44.529651 ops/training.py:65 2019-01-17 01:10:44.529565: step 3968, loss = 0.71301 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:10:45.814360 ops/training.py:65 2019-01-17 01:10:45.814294: step 3969, loss = 0.70204 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:10:47.097390 ops/training.py:65 2019-01-17 01:10:47.097281: step 3970, loss = 0.67429 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:10:48.389684 ops/training.py:65 2019-01-17 01:10:48.389577: step 3971, loss = 0.68454 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:10:49.676602 ops/training.py:65 2019-01-17 01:10:49.676496: step 3972, loss = 0.72251 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:10:50.961154 ops/training.py:65 2019-01-17 01:10:50.960995: step 3973, loss = 0.74314 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:10:52.245767 ops/training.py:65 2019-01-17 01:10:52.245668: step 3974, loss = 0.66430 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:10:53.533734 ops/training.py:65 2019-01-17 01:10:53.533642: step 3975, loss = 0.72117 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:10:54.814877 ops/training.py:65 2019-01-17 01:10:54.814779: step 3976, loss = 0.63785 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:10:56.101569 ops/training.py:65 2019-01-17 01:10:56.101467: step 3977, loss = 0.72038 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:10:57.386635 ops/training.py:65 2019-01-17 01:10:57.386529: step 3978, loss = 0.65582 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:10:58.678544 ops/training.py:65 2019-01-17 01:10:58.678447: step 3979, loss = 0.67184 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:10:59.956621 ops/training.py:65 2019-01-17 01:10:59.956550: step 3980, loss = 0.71810 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:11:01.244461 ops/training.py:65 2019-01-17 01:11:01.244357: step 3981, loss = 0.69519 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:11:02.529389 ops/training.py:65 2019-01-17 01:11:02.529282: step 3982, loss = 0.72305 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:11:03.820837 ops/training.py:65 2019-01-17 01:11:03.820741: step 3983, loss = 0.71608 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:11:05.102111 ops/training.py:65 2019-01-17 01:11:05.102001: step 3984, loss = 0.69683 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:11:06.387989 ops/training.py:65 2019-01-17 01:11:06.387889: step 3985, loss = 0.68978 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:11:07.681117 ops/training.py:65 2019-01-17 01:11:07.681042: step 3986, loss = 0.69320 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:11:08.969574 ops/training.py:65 2019-01-17 01:11:08.969503: step 3987, loss = 0.66790 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:11:10.248903 ops/training.py:65 2019-01-17 01:11:10.248830: step 3988, loss = 0.72003 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:11:11.532539 ops/training.py:65 2019-01-17 01:11:11.532384: step 3989, loss = 0.66196 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:11:12.819573 ops/training.py:65 2019-01-17 01:11:12.819466: step 3990, loss = 0.71189 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:11:14.104765 ops/training.py:65 2019-01-17 01:11:14.104696: step 3991, loss = 0.74041 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:11:15.394715 ops/training.py:65 2019-01-17 01:11:15.394642: step 3992, loss = 0.63805 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:11:16.678492 ops/training.py:65 2019-01-17 01:11:16.678418: step 3993, loss = 0.70817 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:11:17.966341 ops/training.py:65 2019-01-17 01:11:17.966245: step 3994, loss = 0.68593 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:11:19.251696 ops/training.py:65 2019-01-17 01:11:19.251587: step 3995, loss = 0.65479 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:11:20.534965 ops/training.py:65 2019-01-17 01:11:20.534870: step 3996, loss = 0.70713 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:11:21.825958 ops/training.py:65 2019-01-17 01:11:21.825852: step 3997, loss = 0.65712 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:11:23.111389 ops/training.py:65 2019-01-17 01:11:23.111286: step 3998, loss = 0.65091 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:11:24.399469 ops/training.py:65 2019-01-17 01:11:24.399387: step 3999, loss = 0.69088 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:17:29.633192 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I4672 2019-01-17 01:17:29.634154 ops/training.py:41 2019-01-17 01:17:29.634100: step 4000, loss = 0.71 (0.1 examples/sec; 363.951 sec/batch) | Training accuracy = 0.5 | Validation accuracy = 0.50285 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_23_33_01_706250
I4672 2019-01-17 01:17:30.918171 ops/training.py:65 2019-01-17 01:17:30.918071: step 4001, loss = 0.70703 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:17:32.203883 ops/training.py:65 2019-01-17 01:17:32.203785: step 4002, loss = 0.71281 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:17:33.488135 ops/training.py:65 2019-01-17 01:17:33.488040: step 4003, loss = 0.67555 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:17:34.774867 ops/training.py:65 2019-01-17 01:17:34.774753: step 4004, loss = 0.68064 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:17:36.064162 ops/training.py:65 2019-01-17 01:17:36.064058: step 4005, loss = 0.68972 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:17:37.355605 ops/training.py:65 2019-01-17 01:17:37.355522: step 4006, loss = 0.71193 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:17:38.646063 ops/training.py:65 2019-01-17 01:17:38.645990: step 4007, loss = 0.71514 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:17:39.933802 ops/training.py:65 2019-01-17 01:17:39.933727: step 4008, loss = 0.67929 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:17:41.223622 ops/training.py:65 2019-01-17 01:17:41.223549: step 4009, loss = 0.71722 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:17:42.513187 ops/training.py:65 2019-01-17 01:17:42.513118: step 4010, loss = 0.68165 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:17:43.800432 ops/training.py:65 2019-01-17 01:17:43.800366: step 4011, loss = 0.64104 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:17:45.084985 ops/training.py:65 2019-01-17 01:17:45.084916: step 4012, loss = 0.68258 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:17:46.367963 ops/training.py:65 2019-01-17 01:17:46.367893: step 4013, loss = 0.69921 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:17:47.659647 ops/training.py:65 2019-01-17 01:17:47.659541: step 4014, loss = 0.70248 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:17:48.947455 ops/training.py:65 2019-01-17 01:17:48.947387: step 4015, loss = 0.69886 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:17:50.224101 ops/training.py:65 2019-01-17 01:17:50.223994: step 4016, loss = 0.73962 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:17:51.508082 ops/training.py:65 2019-01-17 01:17:51.507973: step 4017, loss = 0.70001 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:17:52.790795 ops/training.py:65 2019-01-17 01:17:52.790683: step 4018, loss = 0.73138 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:17:54.078248 ops/training.py:65 2019-01-17 01:17:54.078162: step 4019, loss = 0.68806 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:17:55.362631 ops/training.py:65 2019-01-17 01:17:55.362521: step 4020, loss = 0.69413 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:17:56.650034 ops/training.py:65 2019-01-17 01:17:56.649908: step 4021, loss = 0.68489 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:17:57.935117 ops/training.py:65 2019-01-17 01:17:57.935013: step 4022, loss = 0.69934 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:17:59.228541 ops/training.py:65 2019-01-17 01:17:59.228433: step 4023, loss = 0.70799 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:18:00.519462 ops/training.py:65 2019-01-17 01:18:00.519384: step 4024, loss = 0.70103 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:18:01.803614 ops/training.py:65 2019-01-17 01:18:01.803539: step 4025, loss = 0.68216 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:18:03.085330 ops/training.py:65 2019-01-17 01:18:03.085225: step 4026, loss = 0.67592 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:18:04.372854 ops/training.py:65 2019-01-17 01:18:04.372712: step 4027, loss = 0.67822 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:18:05.662084 ops/training.py:65 2019-01-17 01:18:05.661982: step 4028, loss = 0.70847 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:18:06.953087 ops/training.py:65 2019-01-17 01:18:06.953012: step 4029, loss = 0.66325 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:18:08.242714 ops/training.py:65 2019-01-17 01:18:08.242635: step 4030, loss = 0.71246 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:18:09.531610 ops/training.py:65 2019-01-17 01:18:09.531534: step 4031, loss = 0.65727 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:18:10.819619 ops/training.py:65 2019-01-17 01:18:10.819532: step 4032, loss = 0.74188 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:18:12.106847 ops/training.py:65 2019-01-17 01:18:12.106778: step 4033, loss = 0.72934 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:18:13.392159 ops/training.py:65 2019-01-17 01:18:13.392087: step 4034, loss = 0.68586 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:18:14.681375 ops/training.py:65 2019-01-17 01:18:14.681292: step 4035, loss = 0.69326 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:18:15.969007 ops/training.py:65 2019-01-17 01:18:15.968921: step 4036, loss = 0.71140 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:18:17.250814 ops/training.py:65 2019-01-17 01:18:17.250743: step 4037, loss = 0.72037 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:18:18.536249 ops/training.py:65 2019-01-17 01:18:18.536147: step 4038, loss = 0.67920 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:18:19.827006 ops/training.py:65 2019-01-17 01:18:19.826902: step 4039, loss = 0.73722 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:18:21.117166 ops/training.py:65 2019-01-17 01:18:21.117072: step 4040, loss = 0.70589 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:18:22.402391 ops/training.py:65 2019-01-17 01:18:22.402315: step 4041, loss = 0.70627 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:18:23.687905 ops/training.py:65 2019-01-17 01:18:23.687808: step 4042, loss = 0.68535 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:18:24.972509 ops/training.py:65 2019-01-17 01:18:24.972410: step 4043, loss = 0.67637 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:18:26.252359 ops/training.py:65 2019-01-17 01:18:26.252251: step 4044, loss = 0.68108 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:18:27.537275 ops/training.py:65 2019-01-17 01:18:27.537168: step 4045, loss = 0.66133 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:18:28.823371 ops/training.py:65 2019-01-17 01:18:28.823265: step 4046, loss = 0.70325 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:18:30.108578 ops/training.py:65 2019-01-17 01:18:30.108472: step 4047, loss = 0.66440 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:18:31.389482 ops/training.py:65 2019-01-17 01:18:31.389336: step 4048, loss = 0.74639 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:18:32.676564 ops/training.py:65 2019-01-17 01:18:32.676461: step 4049, loss = 0.67614 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:18:33.959565 ops/training.py:65 2019-01-17 01:18:33.959465: step 4050, loss = 0.67340 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:18:35.244021 ops/training.py:65 2019-01-17 01:18:35.243887: step 4051, loss = 0.70587 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:18:36.534357 ops/training.py:65 2019-01-17 01:18:36.534253: step 4052, loss = 0.74885 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:18:37.822030 ops/training.py:65 2019-01-17 01:18:37.821948: step 4053, loss = 0.69860 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:18:39.108539 ops/training.py:65 2019-01-17 01:18:39.108450: step 4054, loss = 0.67789 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:18:40.394683 ops/training.py:65 2019-01-17 01:18:40.394613: step 4055, loss = 0.72505 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:18:41.682928 ops/training.py:65 2019-01-17 01:18:41.682836: step 4056, loss = 0.72548 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:18:42.971756 ops/training.py:65 2019-01-17 01:18:42.971676: step 4057, loss = 0.70541 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:18:44.259826 ops/training.py:65 2019-01-17 01:18:44.259742: step 4058, loss = 0.70534 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:18:45.544079 ops/training.py:65 2019-01-17 01:18:45.544009: step 4059, loss = 0.71983 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:18:46.829183 ops/training.py:65 2019-01-17 01:18:46.829083: step 4060, loss = 0.70379 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:18:48.110475 ops/training.py:65 2019-01-17 01:18:48.110339: step 4061, loss = 0.71646 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:18:49.401480 ops/training.py:65 2019-01-17 01:18:49.401323: step 4062, loss = 0.69607 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:18:50.688023 ops/training.py:65 2019-01-17 01:18:50.687950: step 4063, loss = 0.67868 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:18:51.977582 ops/training.py:65 2019-01-17 01:18:51.977468: step 4064, loss = 0.67998 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:18:53.264073 ops/training.py:65 2019-01-17 01:18:53.263992: step 4065, loss = 0.69417 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:18:54.547041 ops/training.py:65 2019-01-17 01:18:54.546942: step 4066, loss = 0.70087 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:18:55.836265 ops/training.py:65 2019-01-17 01:18:55.836158: step 4067, loss = 0.71282 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:18:57.125463 ops/training.py:65 2019-01-17 01:18:57.125362: step 4068, loss = 0.67397 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:18:58.407862 ops/training.py:65 2019-01-17 01:18:58.407806: step 4069, loss = 0.67304 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:18:59.699319 ops/training.py:65 2019-01-17 01:18:59.699282: step 4070, loss = 0.70870 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:19:00.987140 ops/training.py:65 2019-01-17 01:19:00.987068: step 4071, loss = 0.68618 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:19:02.276310 ops/training.py:65 2019-01-17 01:19:02.276248: step 4072, loss = 0.68356 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:19:03.566968 ops/training.py:65 2019-01-17 01:19:03.566937: step 4073, loss = 0.70600 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:19:04.854269 ops/training.py:65 2019-01-17 01:19:04.854221: step 4074, loss = 0.70846 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:19:06.143771 ops/training.py:65 2019-01-17 01:19:06.143723: step 4075, loss = 0.70554 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:19:07.431813 ops/training.py:65 2019-01-17 01:19:07.431762: step 4076, loss = 0.72444 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:19:08.721169 ops/training.py:65 2019-01-17 01:19:08.721080: step 4077, loss = 0.63836 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:19:10.009753 ops/training.py:65 2019-01-17 01:19:10.009706: step 4078, loss = 0.64958 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 01:19:11.298284 ops/training.py:65 2019-01-17 01:19:11.298240: step 4079, loss = 0.72495 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:19:12.583205 ops/training.py:65 2019-01-17 01:19:12.583155: step 4080, loss = 0.69877 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:19:13.871711 ops/training.py:65 2019-01-17 01:19:13.871677: step 4081, loss = 0.69234 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:19:15.160745 ops/training.py:65 2019-01-17 01:19:15.160698: step 4082, loss = 0.70907 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:19:16.448967 ops/training.py:65 2019-01-17 01:19:16.448878: step 4083, loss = 0.68846 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:19:17.733076 ops/training.py:65 2019-01-17 01:19:17.733011: step 4084, loss = 0.65867 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:19:19.015989 ops/training.py:65 2019-01-17 01:19:19.015924: step 4085, loss = 0.65887 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:19:20.306071 ops/training.py:65 2019-01-17 01:19:20.305991: step 4086, loss = 0.67339 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:19:21.591089 ops/training.py:65 2019-01-17 01:19:21.591023: step 4087, loss = 0.67027 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:19:22.874094 ops/training.py:65 2019-01-17 01:19:22.873992: step 4088, loss = 0.72631 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:19:24.164055 ops/training.py:65 2019-01-17 01:19:24.163928: step 4089, loss = 0.71978 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:19:25.454312 ops/training.py:65 2019-01-17 01:19:25.454226: step 4090, loss = 0.66406 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:19:26.745172 ops/training.py:65 2019-01-17 01:19:26.745090: step 4091, loss = 0.70135 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:19:28.034078 ops/training.py:65 2019-01-17 01:19:28.033997: step 4092, loss = 0.67019 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:19:29.323763 ops/training.py:65 2019-01-17 01:19:29.323651: step 4093, loss = 0.72557 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:19:30.612391 ops/training.py:65 2019-01-17 01:19:30.612304: step 4094, loss = 0.73224 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:19:31.901796 ops/training.py:65 2019-01-17 01:19:31.901716: step 4095, loss = 0.68747 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:19:33.186550 ops/training.py:65 2019-01-17 01:19:33.186469: step 4096, loss = 0.68498 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:19:34.475928 ops/training.py:65 2019-01-17 01:19:34.475845: step 4097, loss = 0.69336 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:19:35.766262 ops/training.py:65 2019-01-17 01:19:35.766185: step 4098, loss = 0.74017 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:19:37.051056 ops/training.py:65 2019-01-17 01:19:37.050981: step 4099, loss = 0.67716 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:19:38.332901 ops/training.py:65 2019-01-17 01:19:38.332789: step 4100, loss = 0.67881 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:19:39.622614 ops/training.py:65 2019-01-17 01:19:39.622521: step 4101, loss = 0.65391 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:19:40.911423 ops/training.py:65 2019-01-17 01:19:40.911346: step 4102, loss = 0.68213 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:19:42.199991 ops/training.py:65 2019-01-17 01:19:42.199900: step 4103, loss = 0.68679 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:19:43.489136 ops/training.py:65 2019-01-17 01:19:43.489049: step 4104, loss = 0.70728 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:19:44.773181 ops/training.py:65 2019-01-17 01:19:44.773107: step 4105, loss = 0.70625 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:19:46.056909 ops/training.py:65 2019-01-17 01:19:46.056803: step 4106, loss = 0.67667 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:19:47.342251 ops/training.py:65 2019-01-17 01:19:47.342138: step 4107, loss = 0.68395 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:19:48.627499 ops/training.py:65 2019-01-17 01:19:48.627395: step 4108, loss = 0.66921 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:19:49.911779 ops/training.py:65 2019-01-17 01:19:49.911677: step 4109, loss = 0.68465 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:19:51.202745 ops/training.py:65 2019-01-17 01:19:51.202648: step 4110, loss = 0.68536 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:19:52.490183 ops/training.py:65 2019-01-17 01:19:52.490107: step 4111, loss = 0.67977 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:19:53.772992 ops/training.py:65 2019-01-17 01:19:53.772885: step 4112, loss = 0.65398 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:19:55.056961 ops/training.py:65 2019-01-17 01:19:55.056865: step 4113, loss = 0.71887 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:19:56.345233 ops/training.py:65 2019-01-17 01:19:56.345129: step 4114, loss = 0.70114 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:19:57.630042 ops/training.py:65 2019-01-17 01:19:57.629926: step 4115, loss = 0.68448 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:19:58.914324 ops/training.py:65 2019-01-17 01:19:58.914221: step 4116, loss = 0.70817 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:20:00.202434 ops/training.py:65 2019-01-17 01:20:00.202336: step 4117, loss = 0.67436 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:20:01.487630 ops/training.py:65 2019-01-17 01:20:01.487549: step 4118, loss = 0.68381 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:20:02.773188 ops/training.py:65 2019-01-17 01:20:02.773085: step 4119, loss = 0.72125 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:20:04.055490 ops/training.py:65 2019-01-17 01:20:04.055393: step 4120, loss = 0.65919 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:20:05.345166 ops/training.py:65 2019-01-17 01:20:05.345060: step 4121, loss = 0.69444 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:20:06.628431 ops/training.py:65 2019-01-17 01:20:06.628323: step 4122, loss = 0.67891 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:20:07.924289 ops/training.py:65 2019-01-17 01:20:07.924184: step 4123, loss = 0.68036 (24.7 examples/sec; 1.295 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:20:09.208322 ops/training.py:65 2019-01-17 01:20:09.208251: step 4124, loss = 0.71310 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:20:10.494286 ops/training.py:65 2019-01-17 01:20:10.494214: step 4125, loss = 0.69921 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:20:11.774359 ops/training.py:65 2019-01-17 01:20:11.774252: step 4126, loss = 0.68593 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:20:13.061577 ops/training.py:65 2019-01-17 01:20:13.061473: step 4127, loss = 0.69237 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:20:14.345821 ops/training.py:65 2019-01-17 01:20:14.345714: step 4128, loss = 0.69719 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:20:15.637202 ops/training.py:65 2019-01-17 01:20:15.637096: step 4129, loss = 0.67666 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:20:16.926741 ops/training.py:65 2019-01-17 01:20:16.926661: step 4130, loss = 0.76407 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:20:18.215892 ops/training.py:65 2019-01-17 01:20:18.215817: step 4131, loss = 0.68456 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:20:19.499617 ops/training.py:65 2019-01-17 01:20:19.499548: step 4132, loss = 0.70781 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:20:20.782898 ops/training.py:65 2019-01-17 01:20:20.782828: step 4133, loss = 0.69239 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:20:22.069023 ops/training.py:65 2019-01-17 01:20:22.068918: step 4134, loss = 0.72773 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:20:23.349306 ops/training.py:65 2019-01-17 01:20:23.349201: step 4135, loss = 0.70588 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:20:24.630691 ops/training.py:65 2019-01-17 01:20:24.630616: step 4136, loss = 0.74004 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:20:25.915088 ops/training.py:65 2019-01-17 01:20:25.914978: step 4137, loss = 0.69991 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:20:27.196088 ops/training.py:65 2019-01-17 01:20:27.195981: step 4138, loss = 0.69017 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:20:28.476836 ops/training.py:65 2019-01-17 01:20:28.476724: step 4139, loss = 0.68509 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:20:29.753410 ops/training.py:65 2019-01-17 01:20:29.753296: step 4140, loss = 0.72405 (25.1 examples/sec; 1.275 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:20:31.035651 ops/training.py:65 2019-01-17 01:20:31.035542: step 4141, loss = 0.69947 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:20:32.324423 ops/training.py:65 2019-01-17 01:20:32.324319: step 4142, loss = 0.72429 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:20:33.611764 ops/training.py:65 2019-01-17 01:20:33.611678: step 4143, loss = 0.72509 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:20:34.895780 ops/training.py:65 2019-01-17 01:20:34.895684: step 4144, loss = 0.68137 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:20:36.188167 ops/training.py:65 2019-01-17 01:20:36.188066: step 4145, loss = 0.65750 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:20:37.469381 ops/training.py:65 2019-01-17 01:20:37.469305: step 4146, loss = 0.69407 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:20:38.759786 ops/training.py:65 2019-01-17 01:20:38.759679: step 4147, loss = 0.68385 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:20:40.049195 ops/training.py:65 2019-01-17 01:20:40.049100: step 4148, loss = 0.67229 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:20:41.334054 ops/training.py:65 2019-01-17 01:20:41.333976: step 4149, loss = 0.66515 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:20:42.617787 ops/training.py:65 2019-01-17 01:20:42.617631: step 4150, loss = 0.70665 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:20:43.909744 ops/training.py:65 2019-01-17 01:20:43.909601: step 4151, loss = 0.67350 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:20:45.196122 ops/training.py:65 2019-01-17 01:20:45.196015: step 4152, loss = 0.67869 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:20:46.484820 ops/training.py:65 2019-01-17 01:20:46.484708: step 4153, loss = 0.72068 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:20:47.770891 ops/training.py:65 2019-01-17 01:20:47.770784: step 4154, loss = 0.71207 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:20:49.055004 ops/training.py:65 2019-01-17 01:20:49.054902: step 4155, loss = 0.68356 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:20:50.340026 ops/training.py:65 2019-01-17 01:20:50.339919: step 4156, loss = 0.68699 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:20:51.623776 ops/training.py:65 2019-01-17 01:20:51.623640: step 4157, loss = 0.69003 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:20:52.910509 ops/training.py:65 2019-01-17 01:20:52.910412: step 4158, loss = 0.68645 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:20:54.199019 ops/training.py:65 2019-01-17 01:20:54.198881: step 4159, loss = 0.72641 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:20:55.483399 ops/training.py:65 2019-01-17 01:20:55.483291: step 4160, loss = 0.72568 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:20:56.773450 ops/training.py:65 2019-01-17 01:20:56.773344: step 4161, loss = 0.70955 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:20:58.057557 ops/training.py:65 2019-01-17 01:20:58.057453: step 4162, loss = 0.71965 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:20:59.338502 ops/training.py:65 2019-01-17 01:20:59.338391: step 4163, loss = 0.69892 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:21:00.627741 ops/training.py:65 2019-01-17 01:21:00.627640: step 4164, loss = 0.69171 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:21:01.911998 ops/training.py:65 2019-01-17 01:21:01.911901: step 4165, loss = 0.68814 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:21:03.192765 ops/training.py:65 2019-01-17 01:21:03.192680: step 4166, loss = 0.63449 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:21:04.474478 ops/training.py:65 2019-01-17 01:21:04.474378: step 4167, loss = 0.67781 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:21:05.757787 ops/training.py:65 2019-01-17 01:21:05.757750: step 4168, loss = 0.75550 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:21:07.046631 ops/training.py:65 2019-01-17 01:21:07.046597: step 4169, loss = 0.71312 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:21:08.329367 ops/training.py:65 2019-01-17 01:21:08.329307: step 4170, loss = 0.73381 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:21:09.612404 ops/training.py:65 2019-01-17 01:21:09.612304: step 4171, loss = 0.70101 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:21:10.894361 ops/training.py:65 2019-01-17 01:21:10.894269: step 4172, loss = 0.69238 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:21:12.179023 ops/training.py:65 2019-01-17 01:21:12.178968: step 4173, loss = 0.75625 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:21:13.461725 ops/training.py:65 2019-01-17 01:21:13.461690: step 4174, loss = 0.70997 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:21:14.750319 ops/training.py:65 2019-01-17 01:21:14.750286: step 4175, loss = 0.77256 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.25
I4672 2019-01-17 01:21:16.034809 ops/training.py:65 2019-01-17 01:21:16.034774: step 4176, loss = 0.72472 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:21:17.319119 ops/training.py:65 2019-01-17 01:21:17.319078: step 4177, loss = 0.69105 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:21:18.603256 ops/training.py:65 2019-01-17 01:21:18.603222: step 4178, loss = 0.74458 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:21:19.889347 ops/training.py:65 2019-01-17 01:21:19.889277: step 4179, loss = 0.70008 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:21:21.179001 ops/training.py:65 2019-01-17 01:21:21.178950: step 4180, loss = 0.68230 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:21:22.463608 ops/training.py:65 2019-01-17 01:21:22.463540: step 4181, loss = 0.67888 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:21:23.754865 ops/training.py:65 2019-01-17 01:21:23.754791: step 4182, loss = 0.68700 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:21:25.036940 ops/training.py:65 2019-01-17 01:21:25.036902: step 4183, loss = 0.68680 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:21:26.318205 ops/training.py:65 2019-01-17 01:21:26.318171: step 4184, loss = 0.66590 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:21:27.598881 ops/training.py:65 2019-01-17 01:21:27.598816: step 4185, loss = 0.68348 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:21:28.882982 ops/training.py:65 2019-01-17 01:21:28.882950: step 4186, loss = 0.70894 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:21:30.166009 ops/training.py:65 2019-01-17 01:21:30.165975: step 4187, loss = 0.66466 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:21:31.450271 ops/training.py:65 2019-01-17 01:21:31.450164: step 4188, loss = 0.71771 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:21:32.730690 ops/training.py:65 2019-01-17 01:21:32.730656: step 4189, loss = 0.74793 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:21:34.009411 ops/training.py:65 2019-01-17 01:21:34.009376: step 4190, loss = 0.70480 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:21:35.286862 ops/training.py:65 2019-01-17 01:21:35.286813: step 4191, loss = 0.70410 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:21:36.572313 ops/training.py:65 2019-01-17 01:21:36.572274: step 4192, loss = 0.72288 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:21:37.857214 ops/training.py:65 2019-01-17 01:21:37.857116: step 4193, loss = 0.73875 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:21:39.143617 ops/training.py:65 2019-01-17 01:21:39.143512: step 4194, loss = 0.67672 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:21:40.423913 ops/training.py:65 2019-01-17 01:21:40.423819: step 4195, loss = 0.69395 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:21:41.704482 ops/training.py:65 2019-01-17 01:21:41.704374: step 4196, loss = 0.67879 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:21:42.987744 ops/training.py:65 2019-01-17 01:21:42.987641: step 4197, loss = 0.72386 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:21:44.305959 ops/training.py:65 2019-01-17 01:21:44.305858: step 4198, loss = 0.66940 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:21:45.587268 ops/training.py:65 2019-01-17 01:21:45.587158: step 4199, loss = 0.69855 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:21:46.867506 ops/training.py:65 2019-01-17 01:21:46.867401: step 4200, loss = 0.68471 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:21:48.153625 ops/training.py:65 2019-01-17 01:21:48.153519: step 4201, loss = 0.69876 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:21:49.439551 ops/training.py:65 2019-01-17 01:21:49.439452: step 4202, loss = 0.70928 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:21:50.725120 ops/training.py:65 2019-01-17 01:21:50.724983: step 4203, loss = 0.69819 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:21:52.011945 ops/training.py:65 2019-01-17 01:21:52.011842: step 4204, loss = 0.70891 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:21:53.296572 ops/training.py:65 2019-01-17 01:21:53.296496: step 4205, loss = 0.77149 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:21:54.584867 ops/training.py:65 2019-01-17 01:21:54.584809: step 4206, loss = 0.72686 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:21:55.872540 ops/training.py:65 2019-01-17 01:21:55.872446: step 4207, loss = 0.70851 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:21:57.160133 ops/training.py:65 2019-01-17 01:21:57.160056: step 4208, loss = 0.68965 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:21:58.441374 ops/training.py:65 2019-01-17 01:21:58.441326: step 4209, loss = 0.66901 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:21:59.727458 ops/training.py:65 2019-01-17 01:21:59.727381: step 4210, loss = 0.72387 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:22:01.008753 ops/training.py:65 2019-01-17 01:22:01.008688: step 4211, loss = 0.67918 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:22:02.289396 ops/training.py:65 2019-01-17 01:22:02.289334: step 4212, loss = 0.72089 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:22:03.565926 ops/training.py:65 2019-01-17 01:22:03.565889: step 4213, loss = 0.70167 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:22:04.846123 ops/training.py:65 2019-01-17 01:22:04.846070: step 4214, loss = 0.68049 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:22:06.126460 ops/training.py:65 2019-01-17 01:22:06.126388: step 4215, loss = 0.69553 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:22:07.408530 ops/training.py:65 2019-01-17 01:22:07.408448: step 4216, loss = 0.71056 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:22:08.693880 ops/training.py:65 2019-01-17 01:22:08.693798: step 4217, loss = 0.70608 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:22:09.975124 ops/training.py:65 2019-01-17 01:22:09.975065: step 4218, loss = 0.68544 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:22:11.256186 ops/training.py:65 2019-01-17 01:22:11.256116: step 4219, loss = 0.68497 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:22:12.538925 ops/training.py:65 2019-01-17 01:22:12.538851: step 4220, loss = 0.68084 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:22:13.828905 ops/training.py:65 2019-01-17 01:22:13.828825: step 4221, loss = 0.69048 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:22:15.110073 ops/training.py:65 2019-01-17 01:22:15.110000: step 4222, loss = 0.72930 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:22:16.386210 ops/training.py:65 2019-01-17 01:22:16.386122: step 4223, loss = 0.68894 (25.1 examples/sec; 1.275 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:22:17.667621 ops/training.py:65 2019-01-17 01:22:17.667547: step 4224, loss = 0.66695 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:22:18.945446 ops/training.py:65 2019-01-17 01:22:18.945379: step 4225, loss = 0.72982 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:22:20.225540 ops/training.py:65 2019-01-17 01:22:20.225489: step 4226, loss = 0.69725 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:22:21.507827 ops/training.py:65 2019-01-17 01:22:21.507752: step 4227, loss = 0.69110 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:22:22.793711 ops/training.py:65 2019-01-17 01:22:22.793600: step 4228, loss = 0.69737 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:22:24.075336 ops/training.py:65 2019-01-17 01:22:24.075229: step 4229, loss = 0.68407 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:22:25.358552 ops/training.py:65 2019-01-17 01:22:25.358454: step 4230, loss = 0.69328 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:22:26.643408 ops/training.py:65 2019-01-17 01:22:26.643305: step 4231, loss = 0.65515 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:22:27.928704 ops/training.py:65 2019-01-17 01:22:27.928591: step 4232, loss = 0.75023 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:22:29.210965 ops/training.py:65 2019-01-17 01:22:29.210865: step 4233, loss = 0.66907 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:22:30.500392 ops/training.py:65 2019-01-17 01:22:30.500278: step 4234, loss = 0.68196 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:22:31.786271 ops/training.py:65 2019-01-17 01:22:31.786157: step 4235, loss = 0.64930 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 01:22:33.072789 ops/training.py:65 2019-01-17 01:22:33.072692: step 4236, loss = 0.69894 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:22:34.353663 ops/training.py:65 2019-01-17 01:22:34.353555: step 4237, loss = 0.71530 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:22:35.640606 ops/training.py:65 2019-01-17 01:22:35.640497: step 4238, loss = 0.69094 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:22:36.925469 ops/training.py:65 2019-01-17 01:22:36.925365: step 4239, loss = 0.72166 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:22:38.210758 ops/training.py:65 2019-01-17 01:22:38.210652: step 4240, loss = 0.69718 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:22:39.496678 ops/training.py:65 2019-01-17 01:22:39.496581: step 4241, loss = 0.68247 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:22:40.781904 ops/training.py:65 2019-01-17 01:22:40.781797: step 4242, loss = 0.73094 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:22:42.072951 ops/training.py:65 2019-01-17 01:22:42.072845: step 4243, loss = 0.76020 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-17 01:22:43.353870 ops/training.py:65 2019-01-17 01:22:43.353787: step 4244, loss = 0.66354 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:22:44.636973 ops/training.py:65 2019-01-17 01:22:44.636866: step 4245, loss = 0.75723 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:22:45.926573 ops/training.py:65 2019-01-17 01:22:45.926466: step 4246, loss = 0.70847 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:22:47.211575 ops/training.py:65 2019-01-17 01:22:47.211468: step 4247, loss = 0.66135 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:22:48.494632 ops/training.py:65 2019-01-17 01:22:48.494527: step 4248, loss = 0.68126 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:22:49.778396 ops/training.py:65 2019-01-17 01:22:49.778291: step 4249, loss = 0.74675 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:22:51.061542 ops/training.py:65 2019-01-17 01:22:51.061446: step 4250, loss = 0.72857 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:22:52.341424 ops/training.py:65 2019-01-17 01:22:52.341356: step 4251, loss = 0.69314 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:22:53.624497 ops/training.py:65 2019-01-17 01:22:53.624397: step 4252, loss = 0.68688 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:22:54.908430 ops/training.py:65 2019-01-17 01:22:54.908329: step 4253, loss = 0.70349 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:22:56.193838 ops/training.py:65 2019-01-17 01:22:56.193730: step 4254, loss = 0.66723 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:22:57.481529 ops/training.py:65 2019-01-17 01:22:57.481419: step 4255, loss = 0.69333 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:22:58.767117 ops/training.py:65 2019-01-17 01:22:58.767014: step 4256, loss = 0.68900 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:23:00.052685 ops/training.py:65 2019-01-17 01:23:00.052584: step 4257, loss = 0.74320 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:23:01.336097 ops/training.py:65 2019-01-17 01:23:01.335991: step 4258, loss = 0.72000 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:23:02.620143 ops/training.py:65 2019-01-17 01:23:02.620040: step 4259, loss = 0.63800 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:23:03.909688 ops/training.py:65 2019-01-17 01:23:03.909548: step 4260, loss = 0.75772 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:23:05.195366 ops/training.py:65 2019-01-17 01:23:05.195257: step 4261, loss = 0.74940 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:23:06.476133 ops/training.py:65 2019-01-17 01:23:06.476022: step 4262, loss = 0.69462 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:23:07.760062 ops/training.py:65 2019-01-17 01:23:07.759906: step 4263, loss = 0.68345 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:23:09.050822 ops/training.py:65 2019-01-17 01:23:09.050713: step 4264, loss = 0.69595 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:23:10.336126 ops/training.py:65 2019-01-17 01:23:10.336024: step 4265, loss = 0.72951 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:23:11.620707 ops/training.py:65 2019-01-17 01:23:11.620568: step 4266, loss = 0.66511 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:23:12.907584 ops/training.py:65 2019-01-17 01:23:12.907480: step 4267, loss = 0.72674 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:23:14.188784 ops/training.py:65 2019-01-17 01:23:14.188677: step 4268, loss = 0.65122 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:23:15.471380 ops/training.py:65 2019-01-17 01:23:15.471278: step 4269, loss = 0.71989 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:23:16.757606 ops/training.py:65 2019-01-17 01:23:16.757500: step 4270, loss = 0.68322 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:23:18.043541 ops/training.py:65 2019-01-17 01:23:18.043436: step 4271, loss = 0.68125 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:23:19.325507 ops/training.py:65 2019-01-17 01:23:19.325401: step 4272, loss = 0.69998 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:23:20.608784 ops/training.py:65 2019-01-17 01:23:20.608638: step 4273, loss = 0.70094 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:23:21.898646 ops/training.py:65 2019-01-17 01:23:21.898550: step 4274, loss = 0.69871 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:23:23.186774 ops/training.py:65 2019-01-17 01:23:23.186702: step 4275, loss = 0.67385 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:23:24.471742 ops/training.py:65 2019-01-17 01:23:24.471609: step 4276, loss = 0.70521 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:23:25.756268 ops/training.py:65 2019-01-17 01:23:25.756170: step 4277, loss = 0.71513 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:23:27.045846 ops/training.py:65 2019-01-17 01:23:27.045742: step 4278, loss = 0.72416 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:23:28.335006 ops/training.py:65 2019-01-17 01:23:28.334902: step 4279, loss = 0.70358 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:23:29.623972 ops/training.py:65 2019-01-17 01:23:29.623884: step 4280, loss = 0.72578 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:23:30.908507 ops/training.py:65 2019-01-17 01:23:30.908434: step 4281, loss = 0.74372 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:23:32.191632 ops/training.py:65 2019-01-17 01:23:32.191523: step 4282, loss = 0.69915 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:23:33.483050 ops/training.py:65 2019-01-17 01:23:33.482951: step 4283, loss = 0.74605 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:23:34.770161 ops/training.py:65 2019-01-17 01:23:34.770058: step 4284, loss = 0.67426 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:23:36.054764 ops/training.py:65 2019-01-17 01:23:36.054663: step 4285, loss = 0.68928 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:23:37.336448 ops/training.py:65 2019-01-17 01:23:37.336340: step 4286, loss = 0.67312 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:23:38.618897 ops/training.py:65 2019-01-17 01:23:38.618786: step 4287, loss = 0.70068 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:23:39.905680 ops/training.py:65 2019-01-17 01:23:39.905579: step 4288, loss = 0.69818 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:23:41.190752 ops/training.py:65 2019-01-17 01:23:41.190648: step 4289, loss = 0.70439 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:23:42.472890 ops/training.py:65 2019-01-17 01:23:42.472781: step 4290, loss = 0.67382 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:23:43.757014 ops/training.py:65 2019-01-17 01:23:43.756911: step 4291, loss = 0.73885 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:23:45.036693 ops/training.py:65 2019-01-17 01:23:45.036583: step 4292, loss = 0.65804 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:23:46.319959 ops/training.py:65 2019-01-17 01:23:46.319854: step 4293, loss = 0.69616 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:23:47.605924 ops/training.py:65 2019-01-17 01:23:47.605821: step 4294, loss = 0.66011 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:23:48.890718 ops/training.py:65 2019-01-17 01:23:48.890613: step 4295, loss = 0.67690 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:23:50.177454 ops/training.py:65 2019-01-17 01:23:50.177357: step 4296, loss = 0.74122 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:23:51.461907 ops/training.py:65 2019-01-17 01:23:51.461799: step 4297, loss = 0.70021 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:23:52.739707 ops/training.py:65 2019-01-17 01:23:52.739598: step 4298, loss = 0.67624 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:23:54.020000 ops/training.py:65 2019-01-17 01:23:54.019882: step 4299, loss = 0.65568 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:23:55.297896 ops/training.py:65 2019-01-17 01:23:55.297795: step 4300, loss = 0.71807 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:23:56.581355 ops/training.py:65 2019-01-17 01:23:56.581250: step 4301, loss = 0.69154 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:23:57.868009 ops/training.py:65 2019-01-17 01:23:57.867905: step 4302, loss = 0.68655 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:23:59.149430 ops/training.py:65 2019-01-17 01:23:59.149316: step 4303, loss = 0.68338 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:24:00.432946 ops/training.py:65 2019-01-17 01:24:00.432855: step 4304, loss = 0.69182 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:24:01.726075 ops/training.py:65 2019-01-17 01:24:01.725970: step 4305, loss = 0.68886 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:24:03.007688 ops/training.py:65 2019-01-17 01:24:03.007583: step 4306, loss = 0.70826 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:24:04.299015 ops/training.py:65 2019-01-17 01:24:04.298911: step 4307, loss = 0.68972 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:24:05.582596 ops/training.py:65 2019-01-17 01:24:05.582504: step 4308, loss = 0.67856 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:24:06.863563 ops/training.py:65 2019-01-17 01:24:06.863458: step 4309, loss = 0.71764 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:24:08.147055 ops/training.py:65 2019-01-17 01:24:08.146927: step 4310, loss = 0.70684 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:24:09.434050 ops/training.py:65 2019-01-17 01:24:09.433956: step 4311, loss = 0.73499 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:24:10.717995 ops/training.py:65 2019-01-17 01:24:10.717892: step 4312, loss = 0.67407 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:24:12.006669 ops/training.py:65 2019-01-17 01:24:12.006563: step 4313, loss = 0.63690 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 01:24:13.292607 ops/training.py:65 2019-01-17 01:24:13.292537: step 4314, loss = 0.68123 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:24:14.574991 ops/training.py:65 2019-01-17 01:24:14.574896: step 4315, loss = 0.73538 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:24:15.858275 ops/training.py:65 2019-01-17 01:24:15.858177: step 4316, loss = 0.68582 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:24:17.148428 ops/training.py:65 2019-01-17 01:24:17.148333: step 4317, loss = 0.67297 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:24:18.434324 ops/training.py:65 2019-01-17 01:24:18.434246: step 4318, loss = 0.71335 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:24:19.719128 ops/training.py:65 2019-01-17 01:24:19.719021: step 4319, loss = 0.70684 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:24:21.004476 ops/training.py:65 2019-01-17 01:24:21.004374: step 4320, loss = 0.69371 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:24:22.292753 ops/training.py:65 2019-01-17 01:24:22.292658: step 4321, loss = 0.72185 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:24:23.576950 ops/training.py:65 2019-01-17 01:24:23.576846: step 4322, loss = 0.72994 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:24:24.868648 ops/training.py:65 2019-01-17 01:24:24.868551: step 4323, loss = 0.71928 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:24:26.158358 ops/training.py:65 2019-01-17 01:24:26.158279: step 4324, loss = 0.70251 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:24:27.445603 ops/training.py:65 2019-01-17 01:24:27.445521: step 4325, loss = 0.71648 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:24:28.733605 ops/training.py:65 2019-01-17 01:24:28.733520: step 4326, loss = 0.68008 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:24:30.021932 ops/training.py:65 2019-01-17 01:24:30.021850: step 4327, loss = 0.68069 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:24:31.308466 ops/training.py:65 2019-01-17 01:24:31.308391: step 4328, loss = 0.69519 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:24:32.591344 ops/training.py:65 2019-01-17 01:24:32.591252: step 4329, loss = 0.68118 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:24:33.875352 ops/training.py:65 2019-01-17 01:24:33.875257: step 4330, loss = 0.66031 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:24:35.165031 ops/training.py:65 2019-01-17 01:24:35.164920: step 4331, loss = 0.71367 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:24:36.452816 ops/training.py:65 2019-01-17 01:24:36.452714: step 4332, loss = 0.66500 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:24:37.736792 ops/training.py:65 2019-01-17 01:24:37.736688: step 4333, loss = 0.66622 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:24:39.026705 ops/training.py:65 2019-01-17 01:24:39.026603: step 4334, loss = 0.69642 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:24:40.309704 ops/training.py:65 2019-01-17 01:24:40.309630: step 4335, loss = 0.69438 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:24:41.593971 ops/training.py:65 2019-01-17 01:24:41.593905: step 4336, loss = 0.66369 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:24:42.877545 ops/training.py:65 2019-01-17 01:24:42.877435: step 4337, loss = 0.75144 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:24:44.162196 ops/training.py:65 2019-01-17 01:24:44.162090: step 4338, loss = 0.71729 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:24:45.454669 ops/training.py:65 2019-01-17 01:24:45.454556: step 4339, loss = 0.67875 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:24:46.742767 ops/training.py:65 2019-01-17 01:24:46.742685: step 4340, loss = 0.73206 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:24:48.026927 ops/training.py:65 2019-01-17 01:24:48.026853: step 4341, loss = 0.67273 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:24:49.313229 ops/training.py:65 2019-01-17 01:24:49.313122: step 4342, loss = 0.65758 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:24:50.601819 ops/training.py:65 2019-01-17 01:24:50.601718: step 4343, loss = 0.67708 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:24:51.887765 ops/training.py:65 2019-01-17 01:24:51.887661: step 4344, loss = 0.72329 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:24:53.174324 ops/training.py:65 2019-01-17 01:24:53.174224: step 4345, loss = 0.75542 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-17 01:24:54.459016 ops/training.py:65 2019-01-17 01:24:54.458917: step 4346, loss = 0.70127 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:24:55.744712 ops/training.py:65 2019-01-17 01:24:55.744605: step 4347, loss = 0.70044 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:24:57.028903 ops/training.py:65 2019-01-17 01:24:57.028807: step 4348, loss = 0.67180 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:24:58.314504 ops/training.py:65 2019-01-17 01:24:58.314397: step 4349, loss = 0.67202 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:24:59.600303 ops/training.py:65 2019-01-17 01:24:59.600202: step 4350, loss = 0.71387 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:25:00.887376 ops/training.py:65 2019-01-17 01:25:00.887275: step 4351, loss = 0.67998 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:25:02.171130 ops/training.py:65 2019-01-17 01:25:02.171032: step 4352, loss = 0.69432 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:25:03.458872 ops/training.py:65 2019-01-17 01:25:03.458770: step 4353, loss = 0.71592 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:25:04.743674 ops/training.py:65 2019-01-17 01:25:04.743573: step 4354, loss = 0.70365 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:25:06.035228 ops/training.py:65 2019-01-17 01:25:06.035116: step 4355, loss = 0.67761 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:25:07.322051 ops/training.py:65 2019-01-17 01:25:07.321979: step 4356, loss = 0.69354 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:25:08.606667 ops/training.py:65 2019-01-17 01:25:08.606561: step 4357, loss = 0.64062 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 01:25:09.894072 ops/training.py:65 2019-01-17 01:25:09.893977: step 4358, loss = 0.71426 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:25:11.184877 ops/training.py:65 2019-01-17 01:25:11.184772: step 4359, loss = 0.71748 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:25:12.473946 ops/training.py:65 2019-01-17 01:25:12.473866: step 4360, loss = 0.68658 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:25:13.754586 ops/training.py:65 2019-01-17 01:25:13.754506: step 4361, loss = 0.68047 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:25:15.039843 ops/training.py:65 2019-01-17 01:25:15.039732: step 4362, loss = 0.72657 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:25:16.330241 ops/training.py:65 2019-01-17 01:25:16.330132: step 4363, loss = 0.70077 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:25:17.620693 ops/training.py:65 2019-01-17 01:25:17.620605: step 4364, loss = 0.65978 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:25:18.907658 ops/training.py:65 2019-01-17 01:25:18.907557: step 4365, loss = 0.65349 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:25:20.195193 ops/training.py:65 2019-01-17 01:25:20.195082: step 4366, loss = 0.71034 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:25:21.476413 ops/training.py:65 2019-01-17 01:25:21.476303: step 4367, loss = 0.67818 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:25:22.759324 ops/training.py:65 2019-01-17 01:25:22.759215: step 4368, loss = 0.70693 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:25:24.042435 ops/training.py:65 2019-01-17 01:25:24.042331: step 4369, loss = 0.67349 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:25:25.324407 ops/training.py:65 2019-01-17 01:25:25.324304: step 4370, loss = 0.72456 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:25:26.608567 ops/training.py:65 2019-01-17 01:25:26.608460: step 4371, loss = 0.70431 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:25:27.889381 ops/training.py:65 2019-01-17 01:25:27.889279: step 4372, loss = 0.74337 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:25:29.174100 ops/training.py:65 2019-01-17 01:25:29.173998: step 4373, loss = 0.70245 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:25:30.461372 ops/training.py:65 2019-01-17 01:25:30.461266: step 4374, loss = 0.70569 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:25:31.744260 ops/training.py:65 2019-01-17 01:25:31.744151: step 4375, loss = 0.73607 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:25:33.030506 ops/training.py:65 2019-01-17 01:25:33.030403: step 4376, loss = 0.70027 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:25:34.312860 ops/training.py:65 2019-01-17 01:25:34.312752: step 4377, loss = 0.67793 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:25:35.596690 ops/training.py:65 2019-01-17 01:25:35.596580: step 4378, loss = 0.68466 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:25:36.880269 ops/training.py:65 2019-01-17 01:25:36.880161: step 4379, loss = 0.71675 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:25:38.165357 ops/training.py:65 2019-01-17 01:25:38.165246: step 4380, loss = 0.70449 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:25:39.446597 ops/training.py:65 2019-01-17 01:25:39.446483: step 4381, loss = 0.69891 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:25:40.737498 ops/training.py:65 2019-01-17 01:25:40.737398: step 4382, loss = 0.69333 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:25:42.027032 ops/training.py:65 2019-01-17 01:25:42.026925: step 4383, loss = 0.69134 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:25:43.310712 ops/training.py:65 2019-01-17 01:25:43.310608: step 4384, loss = 0.67427 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:25:44.591092 ops/training.py:65 2019-01-17 01:25:44.590983: step 4385, loss = 0.69290 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:25:45.874109 ops/training.py:65 2019-01-17 01:25:45.874002: step 4386, loss = 0.67971 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:25:47.163354 ops/training.py:65 2019-01-17 01:25:47.163252: step 4387, loss = 0.68950 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:25:48.449753 ops/training.py:65 2019-01-17 01:25:48.449668: step 4388, loss = 0.69080 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:25:49.733408 ops/training.py:65 2019-01-17 01:25:49.733311: step 4389, loss = 0.68489 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:25:51.020879 ops/training.py:65 2019-01-17 01:25:51.020766: step 4390, loss = 0.72022 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:25:52.304651 ops/training.py:65 2019-01-17 01:25:52.304548: step 4391, loss = 0.70740 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:25:53.586725 ops/training.py:65 2019-01-17 01:25:53.586624: step 4392, loss = 0.72396 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:25:54.876116 ops/training.py:65 2019-01-17 01:25:54.876017: step 4393, loss = 0.67378 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:25:56.162313 ops/training.py:65 2019-01-17 01:25:56.162209: step 4394, loss = 0.68821 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:25:57.446449 ops/training.py:65 2019-01-17 01:25:57.446349: step 4395, loss = 0.69920 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:25:58.729131 ops/training.py:65 2019-01-17 01:25:58.728978: step 4396, loss = 0.69706 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:26:00.008583 ops/training.py:65 2019-01-17 01:26:00.008474: step 4397, loss = 0.72797 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:26:01.290868 ops/training.py:65 2019-01-17 01:26:01.290756: step 4398, loss = 0.69041 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:26:02.574956 ops/training.py:65 2019-01-17 01:26:02.574844: step 4399, loss = 0.69177 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:26:03.860156 ops/training.py:65 2019-01-17 01:26:03.860060: step 4400, loss = 0.69993 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:26:05.149373 ops/training.py:65 2019-01-17 01:26:05.149271: step 4401, loss = 0.66302 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:26:06.430428 ops/training.py:65 2019-01-17 01:26:06.430326: step 4402, loss = 0.74460 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:26:07.720921 ops/training.py:65 2019-01-17 01:26:07.720812: step 4403, loss = 0.72209 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:26:09.002582 ops/training.py:65 2019-01-17 01:26:09.002509: step 4404, loss = 0.73847 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:26:10.287073 ops/training.py:65 2019-01-17 01:26:10.286977: step 4405, loss = 0.67888 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:26:11.570813 ops/training.py:65 2019-01-17 01:26:11.570711: step 4406, loss = 0.68369 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:26:12.857818 ops/training.py:65 2019-01-17 01:26:12.857710: step 4407, loss = 0.67428 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:26:14.142286 ops/training.py:65 2019-01-17 01:26:14.142181: step 4408, loss = 0.70096 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:26:15.428526 ops/training.py:65 2019-01-17 01:26:15.428417: step 4409, loss = 0.70057 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:26:16.712573 ops/training.py:65 2019-01-17 01:26:16.712463: step 4410, loss = 0.72286 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:26:17.993418 ops/training.py:65 2019-01-17 01:26:17.993308: step 4411, loss = 0.69138 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:26:19.276742 ops/training.py:65 2019-01-17 01:26:19.276597: step 4412, loss = 0.71347 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:26:20.561153 ops/training.py:65 2019-01-17 01:26:20.561039: step 4413, loss = 0.70163 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:26:21.842546 ops/training.py:65 2019-01-17 01:26:21.842441: step 4414, loss = 0.71895 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:26:23.127856 ops/training.py:65 2019-01-17 01:26:23.127754: step 4415, loss = 0.72441 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:26:24.418065 ops/training.py:65 2019-01-17 01:26:24.417955: step 4416, loss = 0.68020 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:26:25.699641 ops/training.py:65 2019-01-17 01:26:25.699572: step 4417, loss = 0.68715 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:26:26.984171 ops/training.py:65 2019-01-17 01:26:26.984059: step 4418, loss = 0.68562 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:26:28.275919 ops/training.py:65 2019-01-17 01:26:28.275814: step 4419, loss = 0.70162 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:26:29.563933 ops/training.py:65 2019-01-17 01:26:29.563870: step 4420, loss = 0.69162 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:26:30.847976 ops/training.py:65 2019-01-17 01:26:30.847863: step 4421, loss = 0.71106 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:26:32.138878 ops/training.py:65 2019-01-17 01:26:32.138766: step 4422, loss = 0.71023 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:26:33.424658 ops/training.py:65 2019-01-17 01:26:33.424584: step 4423, loss = 0.72180 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:26:34.708537 ops/training.py:65 2019-01-17 01:26:34.708441: step 4424, loss = 0.67099 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:26:35.994997 ops/training.py:65 2019-01-17 01:26:35.994892: step 4425, loss = 0.72272 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:26:37.279852 ops/training.py:65 2019-01-17 01:26:37.279746: step 4426, loss = 0.72563 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:26:38.563308 ops/training.py:65 2019-01-17 01:26:38.563213: step 4427, loss = 0.73521 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:26:39.849931 ops/training.py:65 2019-01-17 01:26:39.849834: step 4428, loss = 0.70684 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:26:41.135160 ops/training.py:65 2019-01-17 01:26:41.135056: step 4429, loss = 0.71180 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:26:42.413231 ops/training.py:65 2019-01-17 01:26:42.413122: step 4430, loss = 0.74623 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:26:43.692195 ops/training.py:65 2019-01-17 01:26:43.692083: step 4431, loss = 0.70816 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:26:44.974331 ops/training.py:65 2019-01-17 01:26:44.974230: step 4432, loss = 0.72154 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:26:46.252506 ops/training.py:65 2019-01-17 01:26:46.252391: step 4433, loss = 0.74652 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:26:47.531455 ops/training.py:65 2019-01-17 01:26:47.531344: step 4434, loss = 0.66816 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:26:48.812984 ops/training.py:65 2019-01-17 01:26:48.812874: step 4435, loss = 0.70879 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:26:50.100351 ops/training.py:65 2019-01-17 01:26:50.100252: step 4436, loss = 0.71902 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:26:51.386266 ops/training.py:65 2019-01-17 01:26:51.386156: step 4437, loss = 0.65898 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:26:52.677527 ops/training.py:65 2019-01-17 01:26:52.677420: step 4438, loss = 0.72165 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:26:53.969767 ops/training.py:65 2019-01-17 01:26:53.969657: step 4439, loss = 0.68465 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:26:55.251133 ops/training.py:65 2019-01-17 01:26:55.251039: step 4440, loss = 0.73555 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:26:56.535065 ops/training.py:65 2019-01-17 01:26:56.534968: step 4441, loss = 0.69972 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:26:57.825228 ops/training.py:65 2019-01-17 01:26:57.825132: step 4442, loss = 0.62834 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 01:26:59.114448 ops/training.py:65 2019-01-17 01:26:59.114348: step 4443, loss = 0.63245 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:27:00.404189 ops/training.py:65 2019-01-17 01:27:00.404105: step 4444, loss = 0.69807 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:27:01.687554 ops/training.py:65 2019-01-17 01:27:01.687484: step 4445, loss = 0.71466 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:27:02.970255 ops/training.py:65 2019-01-17 01:27:02.970159: step 4446, loss = 0.70221 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:27:04.254704 ops/training.py:65 2019-01-17 01:27:04.254606: step 4447, loss = 0.67897 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:27:05.540282 ops/training.py:65 2019-01-17 01:27:05.540185: step 4448, loss = 0.68282 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:27:06.819368 ops/training.py:65 2019-01-17 01:27:06.819259: step 4449, loss = 0.66102 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:27:08.101351 ops/training.py:65 2019-01-17 01:27:08.101240: step 4450, loss = 0.74444 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:27:09.390430 ops/training.py:65 2019-01-17 01:27:09.390321: step 4451, loss = 0.70269 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:27:10.675017 ops/training.py:65 2019-01-17 01:27:10.674950: step 4452, loss = 0.71654 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:27:11.964018 ops/training.py:65 2019-01-17 01:27:11.963907: step 4453, loss = 0.68789 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:27:13.251528 ops/training.py:65 2019-01-17 01:27:13.251445: step 4454, loss = 0.67612 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:27:14.536466 ops/training.py:65 2019-01-17 01:27:14.536386: step 4455, loss = 0.73623 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:27:15.821780 ops/training.py:65 2019-01-17 01:27:15.821698: step 4456, loss = 0.64634 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:27:17.106090 ops/training.py:65 2019-01-17 01:27:17.105999: step 4457, loss = 0.71593 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:27:18.391526 ops/training.py:65 2019-01-17 01:27:18.391418: step 4458, loss = 0.67967 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:27:19.675002 ops/training.py:65 2019-01-17 01:27:19.674896: step 4459, loss = 0.70485 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:27:20.962190 ops/training.py:65 2019-01-17 01:27:20.962082: step 4460, loss = 0.73820 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:27:22.247364 ops/training.py:65 2019-01-17 01:27:22.247257: step 4461, loss = 0.69302 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:27:23.531426 ops/training.py:65 2019-01-17 01:27:23.531332: step 4462, loss = 0.68870 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:27:24.822348 ops/training.py:65 2019-01-17 01:27:24.822251: step 4463, loss = 0.66464 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:27:26.110575 ops/training.py:65 2019-01-17 01:27:26.110461: step 4464, loss = 0.70978 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:27:27.395067 ops/training.py:65 2019-01-17 01:27:27.394977: step 4465, loss = 0.68653 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:27:28.679642 ops/training.py:65 2019-01-17 01:27:28.679533: step 4466, loss = 0.68558 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:27:29.959070 ops/training.py:65 2019-01-17 01:27:29.958969: step 4467, loss = 0.69635 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:27:31.249470 ops/training.py:65 2019-01-17 01:27:31.249357: step 4468, loss = 0.71183 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:27:32.538507 ops/training.py:65 2019-01-17 01:27:32.538415: step 4469, loss = 0.68868 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:27:33.827711 ops/training.py:65 2019-01-17 01:27:33.827626: step 4470, loss = 0.71050 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:27:35.110722 ops/training.py:65 2019-01-17 01:27:35.110619: step 4471, loss = 0.66128 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 01:27:36.395720 ops/training.py:65 2019-01-17 01:27:36.395612: step 4472, loss = 0.69828 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:27:37.679621 ops/training.py:65 2019-01-17 01:27:37.679513: step 4473, loss = 0.68478 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:27:38.969771 ops/training.py:65 2019-01-17 01:27:38.969672: step 4474, loss = 0.70659 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:27:40.254468 ops/training.py:65 2019-01-17 01:27:40.254400: step 4475, loss = 0.70151 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:27:41.537594 ops/training.py:65 2019-01-17 01:27:41.537492: step 4476, loss = 0.73028 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:27:42.828779 ops/training.py:65 2019-01-17 01:27:42.828676: step 4477, loss = 0.70942 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:27:44.119615 ops/training.py:65 2019-01-17 01:27:44.119523: step 4478, loss = 0.72594 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:27:45.408734 ops/training.py:65 2019-01-17 01:27:45.408659: step 4479, loss = 0.74741 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-17 01:27:46.692231 ops/training.py:65 2019-01-17 01:27:46.692153: step 4480, loss = 0.74763 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:27:47.982673 ops/training.py:65 2019-01-17 01:27:47.982581: step 4481, loss = 0.63779 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 01:27:49.263885 ops/training.py:65 2019-01-17 01:27:49.263803: step 4482, loss = 0.66734 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:27:50.546489 ops/training.py:65 2019-01-17 01:27:50.546380: step 4483, loss = 0.72762 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:27:51.838520 ops/training.py:65 2019-01-17 01:27:51.838411: step 4484, loss = 0.69880 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:27:53.127878 ops/training.py:65 2019-01-17 01:27:53.127774: step 4485, loss = 0.67907 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:27:54.413226 ops/training.py:65 2019-01-17 01:27:54.413147: step 4486, loss = 0.70535 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:27:55.697761 ops/training.py:65 2019-01-17 01:27:55.697669: step 4487, loss = 0.71878 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:27:56.984223 ops/training.py:65 2019-01-17 01:27:56.984107: step 4488, loss = 0.71762 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:27:58.269072 ops/training.py:65 2019-01-17 01:27:58.268970: step 4489, loss = 0.68468 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:27:59.551742 ops/training.py:65 2019-01-17 01:27:59.551643: step 4490, loss = 0.73948 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:28:00.842402 ops/training.py:65 2019-01-17 01:28:00.842295: step 4491, loss = 0.67265 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:28:02.129297 ops/training.py:65 2019-01-17 01:28:02.129210: step 4492, loss = 0.68588 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:28:03.412421 ops/training.py:65 2019-01-17 01:28:03.412322: step 4493, loss = 0.72330 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:28:04.697978 ops/training.py:65 2019-01-17 01:28:04.697843: step 4494, loss = 0.72120 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:28:05.984211 ops/training.py:65 2019-01-17 01:28:05.984099: step 4495, loss = 0.63594 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:28:07.265222 ops/training.py:65 2019-01-17 01:28:07.265114: step 4496, loss = 0.70012 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:28:08.549182 ops/training.py:65 2019-01-17 01:28:08.549075: step 4497, loss = 0.70883 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:28:09.838990 ops/training.py:65 2019-01-17 01:28:09.838898: step 4498, loss = 0.65047 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 01:28:11.120314 ops/training.py:65 2019-01-17 01:28:11.120223: step 4499, loss = 0.70003 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:28:12.405615 ops/training.py:65 2019-01-17 01:28:12.405503: step 4500, loss = 0.68928 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:28:13.687045 ops/training.py:65 2019-01-17 01:28:13.686942: step 4501, loss = 0.69321 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:28:14.973949 ops/training.py:65 2019-01-17 01:28:14.973840: step 4502, loss = 0.69354 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:28:16.256473 ops/training.py:65 2019-01-17 01:28:16.256365: step 4503, loss = 0.71647 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:28:17.539288 ops/training.py:65 2019-01-17 01:28:17.539181: step 4504, loss = 0.70513 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:28:18.821368 ops/training.py:65 2019-01-17 01:28:18.821264: step 4505, loss = 0.63762 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 01:28:20.104828 ops/training.py:65 2019-01-17 01:28:20.104735: step 4506, loss = 0.67915 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:28:21.393549 ops/training.py:65 2019-01-17 01:28:21.393452: step 4507, loss = 0.68427 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:28:22.682570 ops/training.py:65 2019-01-17 01:28:22.682487: step 4508, loss = 0.72034 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:28:23.965832 ops/training.py:65 2019-01-17 01:28:23.965760: step 4509, loss = 0.67556 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:28:25.250605 ops/training.py:65 2019-01-17 01:28:25.250508: step 4510, loss = 0.69607 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:28:26.536222 ops/training.py:65 2019-01-17 01:28:26.536121: step 4511, loss = 0.68817 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:28:27.816428 ops/training.py:65 2019-01-17 01:28:27.816316: step 4512, loss = 0.70204 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:28:29.096309 ops/training.py:65 2019-01-17 01:28:29.096206: step 4513, loss = 0.69990 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:28:30.378820 ops/training.py:65 2019-01-17 01:28:30.378712: step 4514, loss = 0.68460 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:28:31.657975 ops/training.py:65 2019-01-17 01:28:31.657862: step 4515, loss = 0.64961 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:28:32.942614 ops/training.py:65 2019-01-17 01:28:32.942506: step 4516, loss = 0.69396 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:28:34.226046 ops/training.py:65 2019-01-17 01:28:34.225913: step 4517, loss = 0.68929 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:28:35.509994 ops/training.py:65 2019-01-17 01:28:35.509893: step 4518, loss = 0.68396 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:28:36.790047 ops/training.py:65 2019-01-17 01:28:36.789946: step 4519, loss = 0.70829 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:28:38.072872 ops/training.py:65 2019-01-17 01:28:38.072758: step 4520, loss = 0.68524 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:28:39.354004 ops/training.py:65 2019-01-17 01:28:39.353891: step 4521, loss = 0.67965 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:28:40.634147 ops/training.py:65 2019-01-17 01:28:40.634047: step 4522, loss = 0.71810 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:28:41.918816 ops/training.py:65 2019-01-17 01:28:41.918708: step 4523, loss = 0.69372 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:28:43.204310 ops/training.py:65 2019-01-17 01:28:43.204220: step 4524, loss = 0.66999 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:28:44.493707 ops/training.py:65 2019-01-17 01:28:44.493611: step 4525, loss = 0.70384 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:28:45.784033 ops/training.py:65 2019-01-17 01:28:45.783929: step 4526, loss = 0.69917 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:28:47.069245 ops/training.py:65 2019-01-17 01:28:47.069174: step 4527, loss = 0.70078 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:28:48.348782 ops/training.py:65 2019-01-17 01:28:48.348674: step 4528, loss = 0.67700 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:28:49.628386 ops/training.py:65 2019-01-17 01:28:49.628282: step 4529, loss = 0.67378 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:28:50.908769 ops/training.py:65 2019-01-17 01:28:50.908657: step 4530, loss = 0.68108 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:28:52.190573 ops/training.py:65 2019-01-17 01:28:52.190456: step 4531, loss = 0.67660 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:28:53.475845 ops/training.py:65 2019-01-17 01:28:53.475744: step 4532, loss = 0.68814 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:28:54.761087 ops/training.py:65 2019-01-17 01:28:54.760989: step 4533, loss = 0.69873 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:28:56.039274 ops/training.py:65 2019-01-17 01:28:56.039163: step 4534, loss = 0.66571 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 01:28:57.322679 ops/training.py:65 2019-01-17 01:28:57.322568: step 4535, loss = 0.66426 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 01:28:58.607596 ops/training.py:65 2019-01-17 01:28:58.607497: step 4536, loss = 0.66443 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:28:59.899115 ops/training.py:65 2019-01-17 01:28:59.899013: step 4537, loss = 0.68364 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:29:01.186380 ops/training.py:65 2019-01-17 01:29:01.186310: step 4538, loss = 0.68838 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:29:02.466737 ops/training.py:65 2019-01-17 01:29:02.466624: step 4539, loss = 0.68624 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:29:03.751545 ops/training.py:65 2019-01-17 01:29:03.751452: step 4540, loss = 0.66068 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:29:05.037760 ops/training.py:65 2019-01-17 01:29:05.037657: step 4541, loss = 0.68436 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:29:06.315601 ops/training.py:65 2019-01-17 01:29:06.315487: step 4542, loss = 0.73368 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:29:07.599599 ops/training.py:65 2019-01-17 01:29:07.599488: step 4543, loss = 0.74385 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:29:08.882859 ops/training.py:65 2019-01-17 01:29:08.882754: step 4544, loss = 0.64884 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:29:10.171579 ops/training.py:65 2019-01-17 01:29:10.171482: step 4545, loss = 0.72280 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:29:11.457581 ops/training.py:65 2019-01-17 01:29:11.457517: step 4546, loss = 0.67716 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:29:12.738454 ops/training.py:65 2019-01-17 01:29:12.738348: step 4547, loss = 0.70400 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:29:14.015654 ops/training.py:65 2019-01-17 01:29:14.015545: step 4548, loss = 0.67590 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:29:15.298428 ops/training.py:65 2019-01-17 01:29:15.298317: step 4549, loss = 0.67336 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:29:16.585085 ops/training.py:65 2019-01-17 01:29:16.584980: step 4550, loss = 0.72696 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:29:17.870535 ops/training.py:65 2019-01-17 01:29:17.870426: step 4551, loss = 0.71098 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:29:19.152264 ops/training.py:65 2019-01-17 01:29:19.152148: step 4552, loss = 0.73068 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:29:20.433246 ops/training.py:65 2019-01-17 01:29:20.433131: step 4553, loss = 0.69548 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:29:21.714288 ops/training.py:65 2019-01-17 01:29:21.714178: step 4554, loss = 0.70539 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:29:22.992923 ops/training.py:65 2019-01-17 01:29:22.992810: step 4555, loss = 0.69283 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:29:24.275939 ops/training.py:65 2019-01-17 01:29:24.275841: step 4556, loss = 0.71081 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:29:25.559054 ops/training.py:65 2019-01-17 01:29:25.558956: step 4557, loss = 0.66368 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:29:26.848890 ops/training.py:65 2019-01-17 01:29:26.848791: step 4558, loss = 0.72740 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:29:28.131992 ops/training.py:65 2019-01-17 01:29:28.131890: step 4559, loss = 0.70991 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:29:29.419609 ops/training.py:65 2019-01-17 01:29:29.419498: step 4560, loss = 0.65445 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:29:30.704806 ops/training.py:65 2019-01-17 01:29:30.704708: step 4561, loss = 0.69596 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:29:31.989900 ops/training.py:65 2019-01-17 01:29:31.989795: step 4562, loss = 0.67399 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:29:33.277683 ops/training.py:65 2019-01-17 01:29:33.277577: step 4563, loss = 0.69536 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:29:34.561086 ops/training.py:65 2019-01-17 01:29:34.560943: step 4564, loss = 0.64929 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:29:35.841687 ops/training.py:65 2019-01-17 01:29:35.841579: step 4565, loss = 0.68473 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:29:37.121866 ops/training.py:65 2019-01-17 01:29:37.121756: step 4566, loss = 0.71836 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:29:38.410570 ops/training.py:65 2019-01-17 01:29:38.410463: step 4567, loss = 0.68791 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:29:39.698393 ops/training.py:65 2019-01-17 01:29:39.698299: step 4568, loss = 0.67294 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:29:40.978371 ops/training.py:65 2019-01-17 01:29:40.978266: step 4569, loss = 0.70299 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:29:42.258941 ops/training.py:65 2019-01-17 01:29:42.258829: step 4570, loss = 0.69007 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:29:43.544114 ops/training.py:65 2019-01-17 01:29:43.544008: step 4571, loss = 0.71150 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:29:44.829651 ops/training.py:65 2019-01-17 01:29:44.829563: step 4572, loss = 0.68023 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:29:46.117650 ops/training.py:65 2019-01-17 01:29:46.117539: step 4573, loss = 0.72282 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:29:47.398514 ops/training.py:65 2019-01-17 01:29:47.398409: step 4574, loss = 0.71351 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:29:48.683934 ops/training.py:65 2019-01-17 01:29:48.683828: step 4575, loss = 0.69080 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:29:49.971876 ops/training.py:65 2019-01-17 01:29:49.971772: step 4576, loss = 0.65545 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:29:51.253582 ops/training.py:65 2019-01-17 01:29:51.253504: step 4577, loss = 0.69549 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:29:52.537767 ops/training.py:65 2019-01-17 01:29:52.537670: step 4578, loss = 0.69962 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:29:53.827570 ops/training.py:65 2019-01-17 01:29:53.827469: step 4579, loss = 0.69524 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:29:55.116556 ops/training.py:65 2019-01-17 01:29:55.116465: step 4580, loss = 0.71623 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:29:56.406217 ops/training.py:65 2019-01-17 01:29:56.406131: step 4581, loss = 0.64701 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 01:29:57.694604 ops/training.py:65 2019-01-17 01:29:57.694506: step 4582, loss = 0.68321 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:29:58.978684 ops/training.py:65 2019-01-17 01:29:58.978600: step 4583, loss = 0.65502 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:30:00.263929 ops/training.py:65 2019-01-17 01:30:00.263853: step 4584, loss = 0.63878 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 01:30:01.549630 ops/training.py:65 2019-01-17 01:30:01.549564: step 4585, loss = 0.68058 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:30:02.829198 ops/training.py:65 2019-01-17 01:30:02.829099: step 4586, loss = 0.67674 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:30:04.114887 ops/training.py:65 2019-01-17 01:30:04.114790: step 4587, loss = 0.67629 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:30:05.400084 ops/training.py:65 2019-01-17 01:30:05.399965: step 4588, loss = 0.68009 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:30:06.686911 ops/training.py:65 2019-01-17 01:30:06.686799: step 4589, loss = 0.74793 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:30:07.971833 ops/training.py:65 2019-01-17 01:30:07.971722: step 4590, loss = 0.70380 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:30:09.251338 ops/training.py:65 2019-01-17 01:30:09.251224: step 4591, loss = 0.68058 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:30:10.533879 ops/training.py:65 2019-01-17 01:30:10.533776: step 4592, loss = 0.67735 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:30:11.821272 ops/training.py:65 2019-01-17 01:30:11.821156: step 4593, loss = 0.69629 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:30:13.107053 ops/training.py:65 2019-01-17 01:30:13.106968: step 4594, loss = 0.70344 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:30:14.397287 ops/training.py:65 2019-01-17 01:30:14.397190: step 4595, loss = 0.79470 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:30:15.677787 ops/training.py:65 2019-01-17 01:30:15.677724: step 4596, loss = 0.70166 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:30:16.961268 ops/training.py:65 2019-01-17 01:30:16.961160: step 4597, loss = 0.71835 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:30:18.248844 ops/training.py:65 2019-01-17 01:30:18.248732: step 4598, loss = 0.71018 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:30:19.529349 ops/training.py:65 2019-01-17 01:30:19.529236: step 4599, loss = 0.74072 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:30:20.813792 ops/training.py:65 2019-01-17 01:30:20.813682: step 4600, loss = 0.71016 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:30:22.101871 ops/training.py:65 2019-01-17 01:30:22.101761: step 4601, loss = 0.71288 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:30:23.388948 ops/training.py:65 2019-01-17 01:30:23.388845: step 4602, loss = 0.64655 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:30:24.672093 ops/training.py:65 2019-01-17 01:30:24.671985: step 4603, loss = 0.77594 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:30:25.954767 ops/training.py:65 2019-01-17 01:30:25.954632: step 4604, loss = 0.73335 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:30:27.241509 ops/training.py:65 2019-01-17 01:30:27.241395: step 4605, loss = 0.75182 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:30:28.525015 ops/training.py:65 2019-01-17 01:30:28.524910: step 4606, loss = 0.69266 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:30:29.813618 ops/training.py:65 2019-01-17 01:30:29.813506: step 4607, loss = 0.69592 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:30:31.097362 ops/training.py:65 2019-01-17 01:30:31.097258: step 4608, loss = 0.71158 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:30:32.377459 ops/training.py:65 2019-01-17 01:30:32.377350: step 4609, loss = 0.72028 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:30:33.661750 ops/training.py:65 2019-01-17 01:30:33.661651: step 4610, loss = 0.68029 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:30:34.944019 ops/training.py:65 2019-01-17 01:30:34.943903: step 4611, loss = 0.75934 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:30:36.230059 ops/training.py:65 2019-01-17 01:30:36.229941: step 4612, loss = 0.62516 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:30:37.514599 ops/training.py:65 2019-01-17 01:30:37.514491: step 4613, loss = 0.68335 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:30:38.804137 ops/training.py:65 2019-01-17 01:30:38.804025: step 4614, loss = 0.66045 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:30:40.088155 ops/training.py:65 2019-01-17 01:30:40.088074: step 4615, loss = 0.70860 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:30:41.378951 ops/training.py:65 2019-01-17 01:30:41.378844: step 4616, loss = 0.71518 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:30:42.662152 ops/training.py:65 2019-01-17 01:30:42.662042: step 4617, loss = 0.67891 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:30:43.945949 ops/training.py:65 2019-01-17 01:30:43.945856: step 4618, loss = 0.71137 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:30:45.236829 ops/training.py:65 2019-01-17 01:30:45.236723: step 4619, loss = 0.76578 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:30:46.524077 ops/training.py:65 2019-01-17 01:30:46.524010: step 4620, loss = 0.65505 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:30:47.806116 ops/training.py:65 2019-01-17 01:30:47.806052: step 4621, loss = 0.70535 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:30:49.087112 ops/training.py:65 2019-01-17 01:30:49.087009: step 4622, loss = 0.72114 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:30:50.374177 ops/training.py:65 2019-01-17 01:30:50.374066: step 4623, loss = 0.71894 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:30:51.658150 ops/training.py:65 2019-01-17 01:30:51.658048: step 4624, loss = 0.68036 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:30:52.939638 ops/training.py:65 2019-01-17 01:30:52.939528: step 4625, loss = 0.68819 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:30:54.216819 ops/training.py:65 2019-01-17 01:30:54.216710: step 4626, loss = 0.67060 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:30:55.498387 ops/training.py:65 2019-01-17 01:30:55.498297: step 4627, loss = 0.68954 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:30:56.782388 ops/training.py:65 2019-01-17 01:30:56.782290: step 4628, loss = 0.69066 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:30:58.068581 ops/training.py:65 2019-01-17 01:30:58.068481: step 4629, loss = 0.70461 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:30:59.355043 ops/training.py:65 2019-01-17 01:30:59.354931: step 4630, loss = 0.71930 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:31:00.642367 ops/training.py:65 2019-01-17 01:31:00.642258: step 4631, loss = 0.68874 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:31:01.926803 ops/training.py:65 2019-01-17 01:31:01.926699: step 4632, loss = 0.70089 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:31:03.212994 ops/training.py:65 2019-01-17 01:31:03.212891: step 4633, loss = 0.68217 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:31:04.498992 ops/training.py:65 2019-01-17 01:31:04.498876: step 4634, loss = 0.70210 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:31:05.780888 ops/training.py:65 2019-01-17 01:31:05.780783: step 4635, loss = 0.71106 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:31:07.067199 ops/training.py:65 2019-01-17 01:31:07.067096: step 4636, loss = 0.69438 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:31:08.355668 ops/training.py:65 2019-01-17 01:31:08.355556: step 4637, loss = 0.70312 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:31:09.640588 ops/training.py:65 2019-01-17 01:31:09.640488: step 4638, loss = 0.68085 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:31:10.930341 ops/training.py:65 2019-01-17 01:31:10.930242: step 4639, loss = 0.67803 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:31:12.218751 ops/training.py:65 2019-01-17 01:31:12.218689: step 4640, loss = 0.71415 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:31:13.506557 ops/training.py:65 2019-01-17 01:31:13.506486: step 4641, loss = 0.69189 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:31:14.789685 ops/training.py:65 2019-01-17 01:31:14.789611: step 4642, loss = 0.67954 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:31:16.075571 ops/training.py:65 2019-01-17 01:31:16.075503: step 4643, loss = 0.66835 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:31:17.365183 ops/training.py:65 2019-01-17 01:31:17.365114: step 4644, loss = 0.70424 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:31:18.650360 ops/training.py:65 2019-01-17 01:31:18.650257: step 4645, loss = 0.69730 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:31:19.937539 ops/training.py:65 2019-01-17 01:31:19.937426: step 4646, loss = 0.72503 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:31:21.222199 ops/training.py:65 2019-01-17 01:31:21.222091: step 4647, loss = 0.69935 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:31:22.513755 ops/training.py:65 2019-01-17 01:31:22.513596: step 4648, loss = 0.69648 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:31:23.803352 ops/training.py:65 2019-01-17 01:31:23.803265: step 4649, loss = 0.69575 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:31:25.086555 ops/training.py:65 2019-01-17 01:31:25.086413: step 4650, loss = 0.67578 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 01:31:26.370585 ops/training.py:65 2019-01-17 01:31:26.370475: step 4651, loss = 0.67726 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:31:27.660066 ops/training.py:65 2019-01-17 01:31:27.659945: step 4652, loss = 0.72146 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:31:28.949361 ops/training.py:65 2019-01-17 01:31:28.949201: step 4653, loss = 0.68861 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:31:30.239611 ops/training.py:65 2019-01-17 01:31:30.239469: step 4654, loss = 0.69663 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:31:31.524229 ops/training.py:65 2019-01-17 01:31:31.524145: step 4655, loss = 0.72001 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:31:32.805082 ops/training.py:65 2019-01-17 01:31:32.804989: step 4656, loss = 0.67872 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:31:34.087670 ops/training.py:65 2019-01-17 01:31:34.087566: step 4657, loss = 0.73397 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:31:35.368137 ops/training.py:65 2019-01-17 01:31:35.368075: step 4658, loss = 0.67844 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:31:36.649622 ops/training.py:65 2019-01-17 01:31:36.649590: step 4659, loss = 0.68223 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:31:37.932596 ops/training.py:65 2019-01-17 01:31:37.932524: step 4660, loss = 0.69159 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:31:39.214549 ops/training.py:65 2019-01-17 01:31:39.214475: step 4661, loss = 0.71515 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:31:40.498335 ops/training.py:65 2019-01-17 01:31:40.498241: step 4662, loss = 0.66616 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:31:41.782947 ops/training.py:65 2019-01-17 01:31:41.782841: step 4663, loss = 0.68388 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:31:43.067562 ops/training.py:65 2019-01-17 01:31:43.067465: step 4664, loss = 0.71863 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:31:44.347061 ops/training.py:65 2019-01-17 01:31:44.346993: step 4665, loss = 0.69149 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:31:45.630871 ops/training.py:65 2019-01-17 01:31:45.630764: step 4666, loss = 0.71989 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:31:46.915524 ops/training.py:65 2019-01-17 01:31:46.915429: step 4667, loss = 0.72299 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:31:48.198264 ops/training.py:65 2019-01-17 01:31:48.198186: step 4668, loss = 0.71609 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:31:49.479694 ops/training.py:65 2019-01-17 01:31:49.479585: step 4669, loss = 0.69573 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:31:50.768246 ops/training.py:65 2019-01-17 01:31:50.768134: step 4670, loss = 0.71235 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:31:52.058030 ops/training.py:65 2019-01-17 01:31:52.057922: step 4671, loss = 0.66367 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:31:53.342802 ops/training.py:65 2019-01-17 01:31:53.342701: step 4672, loss = 0.71536 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:31:54.626643 ops/training.py:65 2019-01-17 01:31:54.626533: step 4673, loss = 0.66357 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:31:55.912799 ops/training.py:65 2019-01-17 01:31:55.912693: step 4674, loss = 0.71691 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:31:57.194665 ops/training.py:65 2019-01-17 01:31:57.194561: step 4675, loss = 0.65924 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:31:58.475305 ops/training.py:65 2019-01-17 01:31:58.475237: step 4676, loss = 0.73635 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:31:59.757556 ops/training.py:65 2019-01-17 01:31:59.757452: step 4677, loss = 0.68658 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:32:01.037407 ops/training.py:65 2019-01-17 01:32:01.037305: step 4678, loss = 0.68098 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:32:02.318561 ops/training.py:65 2019-01-17 01:32:02.318477: step 4679, loss = 0.68172 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:32:03.600729 ops/training.py:65 2019-01-17 01:32:03.600632: step 4680, loss = 0.65566 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:32:04.891467 ops/training.py:65 2019-01-17 01:32:04.891356: step 4681, loss = 0.67267 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:32:06.172813 ops/training.py:65 2019-01-17 01:32:06.172750: step 4682, loss = 0.65955 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:32:07.453116 ops/training.py:65 2019-01-17 01:32:07.453062: step 4683, loss = 0.64480 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:32:08.736746 ops/training.py:65 2019-01-17 01:32:08.736635: step 4684, loss = 0.72485 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:32:10.019311 ops/training.py:65 2019-01-17 01:32:10.019208: step 4685, loss = 0.79226 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:32:11.305680 ops/training.py:65 2019-01-17 01:32:11.305572: step 4686, loss = 0.68962 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:32:12.592624 ops/training.py:65 2019-01-17 01:32:12.592528: step 4687, loss = 0.74962 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:32:13.877414 ops/training.py:65 2019-01-17 01:32:13.877274: step 4688, loss = 0.72523 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:32:15.164283 ops/training.py:65 2019-01-17 01:32:15.164185: step 4689, loss = 0.71702 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:32:16.445461 ops/training.py:65 2019-01-17 01:32:16.445365: step 4690, loss = 0.68849 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:32:17.731903 ops/training.py:65 2019-01-17 01:32:17.731795: step 4691, loss = 0.74508 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:32:19.017345 ops/training.py:65 2019-01-17 01:32:19.017243: step 4692, loss = 0.67553 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:32:20.301910 ops/training.py:65 2019-01-17 01:32:20.301806: step 4693, loss = 0.69107 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:32:21.582483 ops/training.py:65 2019-01-17 01:32:21.582394: step 4694, loss = 0.75738 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:32:22.862361 ops/training.py:65 2019-01-17 01:32:22.862287: step 4695, loss = 0.74510 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:32:24.148466 ops/training.py:65 2019-01-17 01:32:24.148430: step 4696, loss = 0.75112 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:32:25.428747 ops/training.py:65 2019-01-17 01:32:25.428617: step 4697, loss = 0.70003 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:32:26.712770 ops/training.py:65 2019-01-17 01:32:26.712661: step 4698, loss = 0.73312 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:32:27.998793 ops/training.py:65 2019-01-17 01:32:27.998688: step 4699, loss = 0.72323 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:32:29.283407 ops/training.py:65 2019-01-17 01:32:29.283250: step 4700, loss = 0.69726 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:32:30.573518 ops/training.py:65 2019-01-17 01:32:30.573366: step 4701, loss = 0.66012 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:32:31.860454 ops/training.py:65 2019-01-17 01:32:31.860343: step 4702, loss = 0.71910 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:32:33.142754 ops/training.py:65 2019-01-17 01:32:33.142658: step 4703, loss = 0.70677 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:32:34.426162 ops/training.py:65 2019-01-17 01:32:34.426053: step 4704, loss = 0.63280 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 01:32:35.707775 ops/training.py:65 2019-01-17 01:32:35.707662: step 4705, loss = 0.70061 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:32:36.993866 ops/training.py:65 2019-01-17 01:32:36.993755: step 4706, loss = 0.73345 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:32:38.276821 ops/training.py:65 2019-01-17 01:32:38.276712: step 4707, loss = 0.65792 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:32:39.560977 ops/training.py:65 2019-01-17 01:32:39.560917: step 4708, loss = 0.70295 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:32:40.847321 ops/training.py:65 2019-01-17 01:32:40.847183: step 4709, loss = 0.71006 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:32:42.137572 ops/training.py:65 2019-01-17 01:32:42.137417: step 4710, loss = 0.71813 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:32:43.421084 ops/training.py:65 2019-01-17 01:32:43.420975: step 4711, loss = 0.69315 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:32:44.706098 ops/training.py:65 2019-01-17 01:32:44.705985: step 4712, loss = 0.69603 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:32:45.993538 ops/training.py:65 2019-01-17 01:32:45.993428: step 4713, loss = 0.70956 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:32:47.282912 ops/training.py:65 2019-01-17 01:32:47.282804: step 4714, loss = 0.68373 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:32:48.571775 ops/training.py:65 2019-01-17 01:32:48.571619: step 4715, loss = 0.69142 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:32:49.861166 ops/training.py:65 2019-01-17 01:32:49.861081: step 4716, loss = 0.68890 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:32:51.144489 ops/training.py:65 2019-01-17 01:32:51.144425: step 4717, loss = 0.68275 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:32:52.431081 ops/training.py:65 2019-01-17 01:32:52.430973: step 4718, loss = 0.72818 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:32:53.714813 ops/training.py:65 2019-01-17 01:32:53.714775: step 4719, loss = 0.70959 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:32:54.995769 ops/training.py:65 2019-01-17 01:32:54.995686: step 4720, loss = 0.67911 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:32:56.276067 ops/training.py:65 2019-01-17 01:32:56.275924: step 4721, loss = 0.63034 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:32:57.566200 ops/training.py:65 2019-01-17 01:32:57.566087: step 4722, loss = 0.68300 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:32:58.850484 ops/training.py:65 2019-01-17 01:32:58.850395: step 4723, loss = 0.70753 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:33:00.136276 ops/training.py:65 2019-01-17 01:33:00.136131: step 4724, loss = 0.67946 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:33:01.424353 ops/training.py:65 2019-01-17 01:33:01.424244: step 4725, loss = 0.66864 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:33:02.705592 ops/training.py:65 2019-01-17 01:33:02.705490: step 4726, loss = 0.73396 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:33:03.991886 ops/training.py:65 2019-01-17 01:33:03.991784: step 4727, loss = 0.71897 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:33:05.279080 ops/training.py:65 2019-01-17 01:33:05.278963: step 4728, loss = 0.69987 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:33:06.563648 ops/training.py:65 2019-01-17 01:33:06.563552: step 4729, loss = 0.66667 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:33:07.842761 ops/training.py:65 2019-01-17 01:33:07.842689: step 4730, loss = 0.69025 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:33:09.125257 ops/training.py:65 2019-01-17 01:33:09.125143: step 4731, loss = 0.66678 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 01:33:10.406964 ops/training.py:65 2019-01-17 01:33:10.406862: step 4732, loss = 0.69038 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:33:11.688153 ops/training.py:65 2019-01-17 01:33:11.688081: step 4733, loss = 0.73736 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:33:12.970003 ops/training.py:65 2019-01-17 01:33:12.969890: step 4734, loss = 0.69425 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:33:14.252180 ops/training.py:65 2019-01-17 01:33:14.252080: step 4735, loss = 0.68299 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:33:15.537263 ops/training.py:65 2019-01-17 01:33:15.537148: step 4736, loss = 0.69195 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:33:16.822174 ops/training.py:65 2019-01-17 01:33:16.822073: step 4737, loss = 0.70788 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:33:18.108455 ops/training.py:65 2019-01-17 01:33:18.108341: step 4738, loss = 0.70621 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:33:19.393336 ops/training.py:65 2019-01-17 01:33:19.393239: step 4739, loss = 0.71224 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:33:20.683407 ops/training.py:65 2019-01-17 01:33:20.683261: step 4740, loss = 0.73563 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:33:21.968489 ops/training.py:65 2019-01-17 01:33:21.968385: step 4741, loss = 0.68922 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:33:23.252109 ops/training.py:65 2019-01-17 01:33:23.252008: step 4742, loss = 0.64463 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 01:33:24.538084 ops/training.py:65 2019-01-17 01:33:24.537987: step 4743, loss = 0.69687 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:33:25.827291 ops/training.py:65 2019-01-17 01:33:25.827189: step 4744, loss = 0.70071 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:33:27.116677 ops/training.py:65 2019-01-17 01:33:27.116568: step 4745, loss = 0.66985 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:33:28.400887 ops/training.py:65 2019-01-17 01:33:28.400774: step 4746, loss = 0.69584 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:33:29.698080 ops/training.py:65 2019-01-17 01:33:29.697966: step 4747, loss = 0.70983 (24.7 examples/sec; 1.296 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:33:30.983071 ops/training.py:65 2019-01-17 01:33:30.983002: step 4748, loss = 0.68141 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:33:32.267856 ops/training.py:65 2019-01-17 01:33:32.267792: step 4749, loss = 0.70115 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:33:33.548321 ops/training.py:65 2019-01-17 01:33:33.548244: step 4750, loss = 0.70958 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:33:34.829079 ops/training.py:65 2019-01-17 01:33:34.829011: step 4751, loss = 0.73400 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:33:36.112138 ops/training.py:65 2019-01-17 01:33:36.112030: step 4752, loss = 0.71738 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:33:37.396310 ops/training.py:65 2019-01-17 01:33:37.396197: step 4753, loss = 0.66933 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:33:38.682878 ops/training.py:65 2019-01-17 01:33:38.682767: step 4754, loss = 0.69013 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:33:39.967982 ops/training.py:65 2019-01-17 01:33:39.967871: step 4755, loss = 0.66861 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:33:41.252062 ops/training.py:65 2019-01-17 01:33:41.251919: step 4756, loss = 0.70246 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:33:42.539979 ops/training.py:65 2019-01-17 01:33:42.539870: step 4757, loss = 0.70181 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:33:43.821288 ops/training.py:65 2019-01-17 01:33:43.821222: step 4758, loss = 0.67481 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:33:45.104548 ops/training.py:65 2019-01-17 01:33:45.104439: step 4759, loss = 0.68262 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:33:46.388801 ops/training.py:65 2019-01-17 01:33:46.388643: step 4760, loss = 0.71227 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:33:47.675800 ops/training.py:65 2019-01-17 01:33:47.675688: step 4761, loss = 0.67936 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:33:48.961435 ops/training.py:65 2019-01-17 01:33:48.961326: step 4762, loss = 0.72503 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:33:50.243989 ops/training.py:65 2019-01-17 01:33:50.243933: step 4763, loss = 0.65655 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:33:51.530497 ops/training.py:65 2019-01-17 01:33:51.530386: step 4764, loss = 0.68312 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:33:52.811348 ops/training.py:65 2019-01-17 01:33:52.811250: step 4765, loss = 0.67351 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:33:54.088839 ops/training.py:65 2019-01-17 01:33:54.088759: step 4766, loss = 0.70247 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:33:55.368754 ops/training.py:65 2019-01-17 01:33:55.368683: step 4767, loss = 0.68581 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:33:56.650980 ops/training.py:65 2019-01-17 01:33:56.650871: step 4768, loss = 0.71283 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:33:57.934396 ops/training.py:65 2019-01-17 01:33:57.934284: step 4769, loss = 0.70216 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:33:59.216149 ops/training.py:65 2019-01-17 01:33:59.216047: step 4770, loss = 0.71382 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:34:00.497096 ops/training.py:65 2019-01-17 01:34:00.497005: step 4771, loss = 0.72131 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:34:01.778140 ops/training.py:65 2019-01-17 01:34:01.778054: step 4772, loss = 0.74308 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:34:03.060756 ops/training.py:65 2019-01-17 01:34:03.060723: step 4773, loss = 0.74068 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:34:04.342540 ops/training.py:65 2019-01-17 01:34:04.342446: step 4774, loss = 0.70700 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:34:05.623363 ops/training.py:65 2019-01-17 01:34:05.623336: step 4775, loss = 0.66058 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:34:06.903449 ops/training.py:65 2019-01-17 01:34:06.903420: step 4776, loss = 0.74298 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:34:08.186660 ops/training.py:65 2019-01-17 01:34:08.186631: step 4777, loss = 0.68101 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:34:09.471399 ops/training.py:65 2019-01-17 01:34:09.471293: step 4778, loss = 0.73030 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:34:10.756446 ops/training.py:65 2019-01-17 01:34:10.756356: step 4779, loss = 0.68082 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:34:12.042425 ops/training.py:65 2019-01-17 01:34:12.042325: step 4780, loss = 0.69136 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:34:13.324072 ops/training.py:65 2019-01-17 01:34:13.323990: step 4781, loss = 0.73656 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:34:14.607163 ops/training.py:65 2019-01-17 01:34:14.607055: step 4782, loss = 0.70272 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:34:15.891745 ops/training.py:65 2019-01-17 01:34:15.891643: step 4783, loss = 0.69179 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:34:17.179876 ops/training.py:65 2019-01-17 01:34:17.179781: step 4784, loss = 0.66528 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:34:18.467338 ops/training.py:65 2019-01-17 01:34:18.467238: step 4785, loss = 0.76912 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:34:19.752899 ops/training.py:65 2019-01-17 01:34:19.752802: step 4786, loss = 0.64626 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:34:21.033175 ops/training.py:65 2019-01-17 01:34:21.033078: step 4787, loss = 0.74516 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:34:22.314375 ops/training.py:65 2019-01-17 01:34:22.314300: step 4788, loss = 0.71159 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:34:23.593798 ops/training.py:65 2019-01-17 01:34:23.593719: step 4789, loss = 0.72125 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:34:24.879735 ops/training.py:65 2019-01-17 01:34:24.879703: step 4790, loss = 0.71839 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:34:26.160676 ops/training.py:65 2019-01-17 01:34:26.160638: step 4791, loss = 0.76708 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:34:27.447089 ops/training.py:65 2019-01-17 01:34:27.447059: step 4792, loss = 0.66987 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:34:28.722597 ops/training.py:65 2019-01-17 01:34:28.722553: step 4793, loss = 0.72927 (25.1 examples/sec; 1.275 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:34:30.001377 ops/training.py:65 2019-01-17 01:34:30.001300: step 4794, loss = 0.68785 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:34:31.289670 ops/training.py:65 2019-01-17 01:34:31.289567: step 4795, loss = 0.70550 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:34:32.574663 ops/training.py:65 2019-01-17 01:34:32.574505: step 4796, loss = 0.68575 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:34:33.856312 ops/training.py:65 2019-01-17 01:34:33.856216: step 4797, loss = 0.71623 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:34:35.135494 ops/training.py:65 2019-01-17 01:34:35.135406: step 4798, loss = 0.68279 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:34:36.416019 ops/training.py:65 2019-01-17 01:34:36.415934: step 4799, loss = 0.69855 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:34:37.695678 ops/training.py:65 2019-01-17 01:34:37.695625: step 4800, loss = 0.72635 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:34:38.979316 ops/training.py:65 2019-01-17 01:34:38.979215: step 4801, loss = 0.67626 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:34:40.260930 ops/training.py:65 2019-01-17 01:34:40.260878: step 4802, loss = 0.71611 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:34:41.538086 ops/training.py:65 2019-01-17 01:34:41.538029: step 4803, loss = 0.67834 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:34:42.817755 ops/training.py:65 2019-01-17 01:34:42.817697: step 4804, loss = 0.63101 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 01:34:44.098732 ops/training.py:65 2019-01-17 01:34:44.098635: step 4805, loss = 0.70171 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:34:45.383763 ops/training.py:65 2019-01-17 01:34:45.383654: step 4806, loss = 0.68559 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:34:46.663385 ops/training.py:65 2019-01-17 01:34:46.663321: step 4807, loss = 0.73350 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:34:47.944964 ops/training.py:65 2019-01-17 01:34:47.944864: step 4808, loss = 0.69650 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:34:49.225952 ops/training.py:65 2019-01-17 01:34:49.225886: step 4809, loss = 0.73084 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:34:50.507784 ops/training.py:65 2019-01-17 01:34:50.507743: step 4810, loss = 0.67120 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:34:51.789512 ops/training.py:65 2019-01-17 01:34:51.789457: step 4811, loss = 0.68513 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:34:53.071339 ops/training.py:65 2019-01-17 01:34:53.071303: step 4812, loss = 0.70495 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:34:54.354304 ops/training.py:65 2019-01-17 01:34:54.354204: step 4813, loss = 0.72473 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:34:55.640528 ops/training.py:65 2019-01-17 01:34:55.640438: step 4814, loss = 0.71657 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:34:56.922952 ops/training.py:65 2019-01-17 01:34:56.922869: step 4815, loss = 0.67475 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:34:58.208834 ops/training.py:65 2019-01-17 01:34:58.208723: step 4816, loss = 0.69525 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:34:59.491377 ops/training.py:65 2019-01-17 01:34:59.491260: step 4817, loss = 0.71647 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:35:00.773334 ops/training.py:65 2019-01-17 01:35:00.773241: step 4818, loss = 0.65298 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:35:02.056887 ops/training.py:65 2019-01-17 01:35:02.056778: step 4819, loss = 0.75478 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.25
I4672 2019-01-17 01:35:03.335962 ops/training.py:65 2019-01-17 01:35:03.335883: step 4820, loss = 0.68970 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:35:04.615487 ops/training.py:65 2019-01-17 01:35:04.615393: step 4821, loss = 0.72465 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:35:05.897557 ops/training.py:65 2019-01-17 01:35:05.897475: step 4822, loss = 0.70104 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:35:07.183283 ops/training.py:65 2019-01-17 01:35:07.183190: step 4823, loss = 0.72883 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:35:08.463677 ops/training.py:65 2019-01-17 01:35:08.463630: step 4824, loss = 0.72083 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:35:09.747686 ops/training.py:65 2019-01-17 01:35:09.747585: step 4825, loss = 0.69590 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:35:11.031170 ops/training.py:65 2019-01-17 01:35:11.031142: step 4826, loss = 0.65493 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:35:12.312051 ops/training.py:65 2019-01-17 01:35:12.311964: step 4827, loss = 0.67707 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:35:13.592250 ops/training.py:65 2019-01-17 01:35:13.592157: step 4828, loss = 0.69569 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:35:14.871920 ops/training.py:65 2019-01-17 01:35:14.871824: step 4829, loss = 0.68691 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:35:16.152704 ops/training.py:65 2019-01-17 01:35:16.152610: step 4830, loss = 0.70298 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:35:17.430214 ops/training.py:65 2019-01-17 01:35:17.430123: step 4831, loss = 0.69673 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:35:18.710465 ops/training.py:65 2019-01-17 01:35:18.710360: step 4832, loss = 0.66771 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:35:19.989934 ops/training.py:65 2019-01-17 01:35:19.989852: step 4833, loss = 0.68022 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:35:21.268520 ops/training.py:65 2019-01-17 01:35:21.268439: step 4834, loss = 0.67117 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:35:22.555042 ops/training.py:65 2019-01-17 01:35:22.554936: step 4835, loss = 0.69928 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:35:23.838578 ops/training.py:65 2019-01-17 01:35:23.838479: step 4836, loss = 0.72650 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:35:25.125932 ops/training.py:65 2019-01-17 01:35:25.125854: step 4837, loss = 0.70735 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:35:26.412407 ops/training.py:65 2019-01-17 01:35:26.412323: step 4838, loss = 0.71405 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:35:27.697239 ops/training.py:65 2019-01-17 01:35:27.697136: step 4839, loss = 0.65928 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:35:28.990109 ops/training.py:65 2019-01-17 01:35:28.989995: step 4840, loss = 0.71350 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:35:30.272948 ops/training.py:65 2019-01-17 01:35:30.272844: step 4841, loss = 0.68833 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:35:31.553756 ops/training.py:65 2019-01-17 01:35:31.553671: step 4842, loss = 0.68923 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:35:32.834392 ops/training.py:65 2019-01-17 01:35:32.834302: step 4843, loss = 0.70832 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:35:34.114206 ops/training.py:65 2019-01-17 01:35:34.114112: step 4844, loss = 0.71062 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:35:35.398627 ops/training.py:65 2019-01-17 01:35:35.398521: step 4845, loss = 0.69786 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:35:36.680106 ops/training.py:65 2019-01-17 01:35:36.680001: step 4846, loss = 0.69369 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:35:37.964566 ops/training.py:65 2019-01-17 01:35:37.964494: step 4847, loss = 0.70492 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:35:39.243325 ops/training.py:65 2019-01-17 01:35:39.243226: step 4848, loss = 0.67580 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:35:40.524687 ops/training.py:65 2019-01-17 01:35:40.524587: step 4849, loss = 0.65982 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:35:41.805085 ops/training.py:65 2019-01-17 01:35:41.805005: step 4850, loss = 0.68051 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:35:43.090377 ops/training.py:65 2019-01-17 01:35:43.090278: step 4851, loss = 0.66156 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 01:35:44.369278 ops/training.py:65 2019-01-17 01:35:44.369178: step 4852, loss = 0.69491 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:35:45.650028 ops/training.py:65 2019-01-17 01:35:45.649922: step 4853, loss = 0.69139 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:35:46.932655 ops/training.py:65 2019-01-17 01:35:46.932565: step 4854, loss = 0.66527 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:35:48.214825 ops/training.py:65 2019-01-17 01:35:48.214726: step 4855, loss = 0.67968 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:35:49.500126 ops/training.py:65 2019-01-17 01:35:49.500034: step 4856, loss = 0.68143 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:35:50.785427 ops/training.py:65 2019-01-17 01:35:50.785315: step 4857, loss = 0.70737 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:35:52.069741 ops/training.py:65 2019-01-17 01:35:52.069640: step 4858, loss = 0.69143 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:35:53.354946 ops/training.py:65 2019-01-17 01:35:53.354866: step 4859, loss = 0.69456 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:35:54.639801 ops/training.py:65 2019-01-17 01:35:54.639705: step 4860, loss = 0.71623 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:35:55.926155 ops/training.py:65 2019-01-17 01:35:55.926055: step 4861, loss = 0.68485 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:35:57.206098 ops/training.py:65 2019-01-17 01:35:57.206006: step 4862, loss = 0.69252 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:35:58.486277 ops/training.py:65 2019-01-17 01:35:58.486204: step 4863, loss = 0.71360 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:35:59.769269 ops/training.py:65 2019-01-17 01:35:59.769176: step 4864, loss = 0.71481 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:36:01.054766 ops/training.py:65 2019-01-17 01:36:01.054665: step 4865, loss = 0.70164 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:36:02.338930 ops/training.py:65 2019-01-17 01:36:02.338835: step 4866, loss = 0.71383 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:36:03.623201 ops/training.py:65 2019-01-17 01:36:03.623078: step 4867, loss = 0.68048 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:36:04.910687 ops/training.py:65 2019-01-17 01:36:04.910584: step 4868, loss = 0.71566 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:36:06.192440 ops/training.py:65 2019-01-17 01:36:06.192332: step 4869, loss = 0.66671 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:36:07.475823 ops/training.py:65 2019-01-17 01:36:07.475724: step 4870, loss = 0.69527 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:36:08.768691 ops/training.py:65 2019-01-17 01:36:08.768564: step 4871, loss = 0.69714 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:36:10.050619 ops/training.py:65 2019-01-17 01:36:10.050515: step 4872, loss = 0.70888 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:36:11.327129 ops/training.py:65 2019-01-17 01:36:11.327041: step 4873, loss = 0.68487 (25.1 examples/sec; 1.275 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:36:12.609999 ops/training.py:65 2019-01-17 01:36:12.609916: step 4874, loss = 0.68858 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:36:13.894721 ops/training.py:65 2019-01-17 01:36:13.894646: step 4875, loss = 0.72235 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:36:15.174207 ops/training.py:65 2019-01-17 01:36:15.174095: step 4876, loss = 0.70919 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:36:16.454679 ops/training.py:65 2019-01-17 01:36:16.454567: step 4877, loss = 0.66469 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:36:17.738189 ops/training.py:65 2019-01-17 01:36:17.738078: step 4878, loss = 0.70891 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:36:19.023712 ops/training.py:65 2019-01-17 01:36:19.023610: step 4879, loss = 0.68855 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:36:20.306430 ops/training.py:65 2019-01-17 01:36:20.306348: step 4880, loss = 0.67693 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:36:21.586765 ops/training.py:65 2019-01-17 01:36:21.586675: step 4881, loss = 0.68360 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:36:22.865872 ops/training.py:65 2019-01-17 01:36:22.865792: step 4882, loss = 0.70817 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:36:24.141325 ops/training.py:65 2019-01-17 01:36:24.141224: step 4883, loss = 0.71165 (25.1 examples/sec; 1.274 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:36:25.421416 ops/training.py:65 2019-01-17 01:36:25.421321: step 4884, loss = 0.69983 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:36:26.704486 ops/training.py:65 2019-01-17 01:36:26.704405: step 4885, loss = 0.65468 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 01:36:27.988011 ops/training.py:65 2019-01-17 01:36:27.987915: step 4886, loss = 0.65123 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:36:29.275016 ops/training.py:65 2019-01-17 01:36:29.274899: step 4887, loss = 0.69913 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:36:30.552781 ops/training.py:65 2019-01-17 01:36:30.552679: step 4888, loss = 0.71488 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:36:31.834119 ops/training.py:65 2019-01-17 01:36:31.834014: step 4889, loss = 0.70698 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:36:33.119748 ops/training.py:65 2019-01-17 01:36:33.119644: step 4890, loss = 0.70726 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:36:34.401828 ops/training.py:65 2019-01-17 01:36:34.401751: step 4891, loss = 0.70387 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:36:35.691890 ops/training.py:65 2019-01-17 01:36:35.691745: step 4892, loss = 0.65914 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 01:36:36.976112 ops/training.py:65 2019-01-17 01:36:36.975995: step 4893, loss = 0.73242 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:36:38.261661 ops/training.py:65 2019-01-17 01:36:38.261562: step 4894, loss = 0.66236 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:36:39.544160 ops/training.py:65 2019-01-17 01:36:39.544092: step 4895, loss = 0.71805 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:36:40.823856 ops/training.py:65 2019-01-17 01:36:40.823763: step 4896, loss = 0.69948 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:36:42.105351 ops/training.py:65 2019-01-17 01:36:42.105255: step 4897, loss = 0.69828 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:36:43.386400 ops/training.py:65 2019-01-17 01:36:43.386300: step 4898, loss = 0.66968 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:36:44.670193 ops/training.py:65 2019-01-17 01:36:44.670082: step 4899, loss = 0.71717 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:36:45.953616 ops/training.py:65 2019-01-17 01:36:45.953503: step 4900, loss = 0.73783 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:36:47.237482 ops/training.py:65 2019-01-17 01:36:47.237369: step 4901, loss = 0.72070 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:36:48.519778 ops/training.py:65 2019-01-17 01:36:48.519681: step 4902, loss = 0.67739 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:36:49.804514 ops/training.py:65 2019-01-17 01:36:49.804402: step 4903, loss = 0.70183 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:36:51.087161 ops/training.py:65 2019-01-17 01:36:51.087054: step 4904, loss = 0.70594 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:36:52.367728 ops/training.py:65 2019-01-17 01:36:52.367616: step 4905, loss = 0.72613 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:36:53.652105 ops/training.py:65 2019-01-17 01:36:53.652022: step 4906, loss = 0.71442 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:36:54.936851 ops/training.py:65 2019-01-17 01:36:54.936748: step 4907, loss = 0.69939 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:36:56.221221 ops/training.py:65 2019-01-17 01:36:56.221138: step 4908, loss = 0.65745 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:36:57.507794 ops/training.py:65 2019-01-17 01:36:57.507690: step 4909, loss = 0.70362 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:36:58.789638 ops/training.py:65 2019-01-17 01:36:58.789530: step 4910, loss = 0.67835 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:37:00.069457 ops/training.py:65 2019-01-17 01:37:00.069284: step 4911, loss = 0.69255 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:37:01.353317 ops/training.py:65 2019-01-17 01:37:01.353189: step 4912, loss = 0.73539 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:37:02.637174 ops/training.py:65 2019-01-17 01:37:02.637081: step 4913, loss = 0.67923 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:37:03.919634 ops/training.py:65 2019-01-17 01:37:03.919540: step 4914, loss = 0.69796 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:37:05.204868 ops/training.py:65 2019-01-17 01:37:05.204767: step 4915, loss = 0.70065 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:37:06.482675 ops/training.py:65 2019-01-17 01:37:06.482570: step 4916, loss = 0.66126 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:37:07.766399 ops/training.py:65 2019-01-17 01:37:07.766316: step 4917, loss = 0.71410 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:37:09.055981 ops/training.py:65 2019-01-17 01:37:09.055877: step 4918, loss = 0.73219 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:37:10.339722 ops/training.py:65 2019-01-17 01:37:10.339639: step 4919, loss = 0.67542 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:37:11.630033 ops/training.py:65 2019-01-17 01:37:11.629921: step 4920, loss = 0.71369 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:37:12.910831 ops/training.py:65 2019-01-17 01:37:12.910750: step 4921, loss = 0.68938 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:37:14.195128 ops/training.py:65 2019-01-17 01:37:14.195032: step 4922, loss = 0.72642 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:37:15.486067 ops/training.py:65 2019-01-17 01:37:15.485961: step 4923, loss = 0.72991 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:37:16.776689 ops/training.py:65 2019-01-17 01:37:16.776628: step 4924, loss = 0.69984 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:37:18.062063 ops/training.py:65 2019-01-17 01:37:18.061949: step 4925, loss = 0.66816 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:37:19.346438 ops/training.py:65 2019-01-17 01:37:19.346324: step 4926, loss = 0.70515 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:37:20.633281 ops/training.py:65 2019-01-17 01:37:20.633178: step 4927, loss = 0.67873 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:37:21.919562 ops/training.py:65 2019-01-17 01:37:21.919448: step 4928, loss = 0.66969 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:37:23.205574 ops/training.py:65 2019-01-17 01:37:23.205469: step 4929, loss = 0.66943 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:37:24.485959 ops/training.py:65 2019-01-17 01:37:24.485859: step 4930, loss = 0.67039 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:37:25.772848 ops/training.py:65 2019-01-17 01:37:25.772755: step 4931, loss = 0.68383 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:37:27.054898 ops/training.py:65 2019-01-17 01:37:27.054788: step 4932, loss = 0.68188 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:37:28.339921 ops/training.py:65 2019-01-17 01:37:28.339820: step 4933, loss = 0.68373 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:37:29.619894 ops/training.py:65 2019-01-17 01:37:29.619795: step 4934, loss = 0.70814 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:37:30.903290 ops/training.py:65 2019-01-17 01:37:30.903184: step 4935, loss = 0.71005 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:37:32.189306 ops/training.py:65 2019-01-17 01:37:32.189195: step 4936, loss = 0.65251 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 01:37:33.472845 ops/training.py:65 2019-01-17 01:37:33.472752: step 4937, loss = 0.68827 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:37:34.756895 ops/training.py:65 2019-01-17 01:37:34.756786: step 4938, loss = 0.67475 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:37:36.038531 ops/training.py:65 2019-01-17 01:37:36.038430: step 4939, loss = 0.71424 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:37:37.322222 ops/training.py:65 2019-01-17 01:37:37.322114: step 4940, loss = 0.71013 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:37:38.604880 ops/training.py:65 2019-01-17 01:37:38.604776: step 4941, loss = 0.67956 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:37:39.888850 ops/training.py:65 2019-01-17 01:37:39.888748: step 4942, loss = 0.71594 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:37:41.174452 ops/training.py:65 2019-01-17 01:37:41.174351: step 4943, loss = 0.72470 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:37:42.452521 ops/training.py:65 2019-01-17 01:37:42.452418: step 4944, loss = 0.71977 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:37:43.739357 ops/training.py:65 2019-01-17 01:37:43.739261: step 4945, loss = 0.71159 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:37:45.024390 ops/training.py:65 2019-01-17 01:37:45.024290: step 4946, loss = 0.73318 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:37:46.311676 ops/training.py:65 2019-01-17 01:37:46.311533: step 4947, loss = 0.71221 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:37:47.597630 ops/training.py:65 2019-01-17 01:37:47.597532: step 4948, loss = 0.71650 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:37:48.885941 ops/training.py:65 2019-01-17 01:37:48.885838: step 4949, loss = 0.68798 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:37:50.174121 ops/training.py:65 2019-01-17 01:37:50.174045: step 4950, loss = 0.74646 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:37:51.462738 ops/training.py:65 2019-01-17 01:37:51.462641: step 4951, loss = 0.70930 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:37:52.747060 ops/training.py:65 2019-01-17 01:37:52.746961: step 4952, loss = 0.67199 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:37:54.029130 ops/training.py:65 2019-01-17 01:37:54.029028: step 4953, loss = 0.70172 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:37:55.307326 ops/training.py:65 2019-01-17 01:37:55.307219: step 4954, loss = 0.71360 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:37:56.593731 ops/training.py:65 2019-01-17 01:37:56.593637: step 4955, loss = 0.70191 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:37:57.873410 ops/training.py:65 2019-01-17 01:37:57.873316: step 4956, loss = 0.69374 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:37:59.159763 ops/training.py:65 2019-01-17 01:37:59.159653: step 4957, loss = 0.73268 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:38:00.441539 ops/training.py:65 2019-01-17 01:38:00.441435: step 4958, loss = 0.67718 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:38:01.727266 ops/training.py:65 2019-01-17 01:38:01.727174: step 4959, loss = 0.69021 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:38:03.009023 ops/training.py:65 2019-01-17 01:38:03.008923: step 4960, loss = 0.69819 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:38:04.293958 ops/training.py:65 2019-01-17 01:38:04.293847: step 4961, loss = 0.73210 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:38:05.577182 ops/training.py:65 2019-01-17 01:38:05.577077: step 4962, loss = 0.73350 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:38:06.858471 ops/training.py:65 2019-01-17 01:38:06.858374: step 4963, loss = 0.72519 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:38:08.138900 ops/training.py:65 2019-01-17 01:38:08.138797: step 4964, loss = 0.67156 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:38:09.424533 ops/training.py:65 2019-01-17 01:38:09.424428: step 4965, loss = 0.72404 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:38:10.710653 ops/training.py:65 2019-01-17 01:38:10.710554: step 4966, loss = 0.68558 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:38:11.994665 ops/training.py:65 2019-01-17 01:38:11.994556: step 4967, loss = 0.69713 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:38:13.281793 ops/training.py:65 2019-01-17 01:38:13.281695: step 4968, loss = 0.66095 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:38:14.562799 ops/training.py:65 2019-01-17 01:38:14.562692: step 4969, loss = 0.70981 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:38:15.847758 ops/training.py:65 2019-01-17 01:38:15.847647: step 4970, loss = 0.70104 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:38:17.132663 ops/training.py:65 2019-01-17 01:38:17.132559: step 4971, loss = 0.66681 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:38:18.418920 ops/training.py:65 2019-01-17 01:38:18.418812: step 4972, loss = 0.66985 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:38:19.709656 ops/training.py:65 2019-01-17 01:38:19.709558: step 4973, loss = 0.68761 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:38:20.994330 ops/training.py:65 2019-01-17 01:38:20.994265: step 4974, loss = 0.73316 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:38:22.278122 ops/training.py:65 2019-01-17 01:38:22.278022: step 4975, loss = 0.67723 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:38:23.563859 ops/training.py:65 2019-01-17 01:38:23.563759: step 4976, loss = 0.71888 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:38:24.846842 ops/training.py:65 2019-01-17 01:38:24.846753: step 4977, loss = 0.71456 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:38:26.135812 ops/training.py:65 2019-01-17 01:38:26.135711: step 4978, loss = 0.70858 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:38:27.422425 ops/training.py:65 2019-01-17 01:38:27.422345: step 4979, loss = 0.69418 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:38:28.706971 ops/training.py:65 2019-01-17 01:38:28.706864: step 4980, loss = 0.69114 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:38:29.990658 ops/training.py:65 2019-01-17 01:38:29.990556: step 4981, loss = 0.70943 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:38:31.280564 ops/training.py:65 2019-01-17 01:38:31.280455: step 4982, loss = 0.72495 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:38:32.562536 ops/training.py:65 2019-01-17 01:38:32.562433: step 4983, loss = 0.72737 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:38:33.854328 ops/training.py:65 2019-01-17 01:38:33.854238: step 4984, loss = 0.72808 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:38:35.144779 ops/training.py:65 2019-01-17 01:38:35.144705: step 4985, loss = 0.72742 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:38:36.429275 ops/training.py:65 2019-01-17 01:38:36.429192: step 4986, loss = 0.68553 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:38:37.713359 ops/training.py:65 2019-01-17 01:38:37.713249: step 4987, loss = 0.68133 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:38:39.002891 ops/training.py:65 2019-01-17 01:38:39.002780: step 4988, loss = 0.71858 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:38:40.288638 ops/training.py:65 2019-01-17 01:38:40.288569: step 4989, loss = 0.67182 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:38:41.572719 ops/training.py:65 2019-01-17 01:38:41.572614: step 4990, loss = 0.68265 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:38:42.854001 ops/training.py:65 2019-01-17 01:38:42.853891: step 4991, loss = 0.68009 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:38:44.136900 ops/training.py:65 2019-01-17 01:38:44.136801: step 4992, loss = 0.68952 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:38:45.422861 ops/training.py:65 2019-01-17 01:38:45.422755: step 4993, loss = 0.68731 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:38:46.703679 ops/training.py:65 2019-01-17 01:38:46.703568: step 4994, loss = 0.69591 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:38:47.991350 ops/training.py:65 2019-01-17 01:38:47.991247: step 4995, loss = 0.69541 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:38:49.271557 ops/training.py:65 2019-01-17 01:38:49.271409: step 4996, loss = 0.66079 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:38:50.555202 ops/training.py:65 2019-01-17 01:38:50.555096: step 4997, loss = 0.71551 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:38:51.845489 ops/training.py:65 2019-01-17 01:38:51.845381: step 4998, loss = 0.67978 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:38:53.129872 ops/training.py:65 2019-01-17 01:38:53.129773: step 4999, loss = 0.72640 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:38:54.414545 ops/training.py:65 2019-01-17 01:38:54.414445: step 5000, loss = 0.71293 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:38:55.702164 ops/training.py:65 2019-01-17 01:38:55.702125: step 5001, loss = 0.67184 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:38:56.993375 ops/training.py:65 2019-01-17 01:38:56.993341: step 5002, loss = 0.71452 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:38:58.277392 ops/training.py:65 2019-01-17 01:38:58.277349: step 5003, loss = 0.69576 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:38:59.558516 ops/training.py:65 2019-01-17 01:38:59.558479: step 5004, loss = 0.70936 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:39:00.843738 ops/training.py:65 2019-01-17 01:39:00.843688: step 5005, loss = 0.68045 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:39:02.134541 ops/training.py:65 2019-01-17 01:39:02.134502: step 5006, loss = 0.69079 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:39:03.420581 ops/training.py:65 2019-01-17 01:39:03.420519: step 5007, loss = 0.72320 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:39:04.704511 ops/training.py:65 2019-01-17 01:39:04.704462: step 5008, loss = 0.70342 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:39:05.980944 ops/training.py:65 2019-01-17 01:39:05.980869: step 5009, loss = 0.69068 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:39:07.262819 ops/training.py:65 2019-01-17 01:39:07.262758: step 5010, loss = 0.68654 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:39:08.548512 ops/training.py:65 2019-01-17 01:39:08.548470: step 5011, loss = 0.70930 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:39:09.838730 ops/training.py:65 2019-01-17 01:39:09.838662: step 5012, loss = 0.68470 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:39:11.125561 ops/training.py:65 2019-01-17 01:39:11.125501: step 5013, loss = 0.67291 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:39:12.410916 ops/training.py:65 2019-01-17 01:39:12.410836: step 5014, loss = 0.72767 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:39:13.701692 ops/training.py:65 2019-01-17 01:39:13.701597: step 5015, loss = 0.72046 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:39:14.989673 ops/training.py:65 2019-01-17 01:39:14.989583: step 5016, loss = 0.69881 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:39:16.276730 ops/training.py:65 2019-01-17 01:39:16.276641: step 5017, loss = 0.71423 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:39:17.564582 ops/training.py:65 2019-01-17 01:39:17.564501: step 5018, loss = 0.69549 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:39:18.851984 ops/training.py:65 2019-01-17 01:39:18.851889: step 5019, loss = 0.67612 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:39:20.131474 ops/training.py:65 2019-01-17 01:39:20.131387: step 5020, loss = 0.70577 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:39:21.424226 ops/training.py:65 2019-01-17 01:39:21.424082: step 5021, loss = 0.67032 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:39:22.709201 ops/training.py:65 2019-01-17 01:39:22.709087: step 5022, loss = 0.65521 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 01:39:23.990213 ops/training.py:65 2019-01-17 01:39:23.990112: step 5023, loss = 0.65807 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:39:25.279686 ops/training.py:65 2019-01-17 01:39:25.279573: step 5024, loss = 0.69358 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:39:26.568383 ops/training.py:65 2019-01-17 01:39:26.568258: step 5025, loss = 0.70692 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:39:27.854293 ops/training.py:65 2019-01-17 01:39:27.854196: step 5026, loss = 0.66258 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:39:29.139045 ops/training.py:65 2019-01-17 01:39:29.138934: step 5027, loss = 0.68746 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:39:30.423786 ops/training.py:65 2019-01-17 01:39:30.423680: step 5028, loss = 0.69103 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:39:31.708086 ops/training.py:65 2019-01-17 01:39:31.707974: step 5029, loss = 0.73587 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:39:32.994217 ops/training.py:65 2019-01-17 01:39:32.994115: step 5030, loss = 0.69041 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:39:34.288574 ops/training.py:65 2019-01-17 01:39:34.288468: step 5031, loss = 0.67531 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:39:35.577645 ops/training.py:65 2019-01-17 01:39:35.577544: step 5032, loss = 0.67281 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:39:36.867401 ops/training.py:65 2019-01-17 01:39:36.867300: step 5033, loss = 0.68525 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:39:38.153160 ops/training.py:65 2019-01-17 01:39:38.153054: step 5034, loss = 0.69258 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:39:39.436733 ops/training.py:65 2019-01-17 01:39:39.436628: step 5035, loss = 0.70271 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:39:40.724087 ops/training.py:65 2019-01-17 01:39:40.723993: step 5036, loss = 0.73158 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:39:42.007004 ops/training.py:65 2019-01-17 01:39:42.006896: step 5037, loss = 0.68335 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:39:43.292715 ops/training.py:65 2019-01-17 01:39:43.292624: step 5038, loss = 0.70970 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:39:44.583038 ops/training.py:65 2019-01-17 01:39:44.582934: step 5039, loss = 0.68594 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:39:45.869688 ops/training.py:65 2019-01-17 01:39:45.869597: step 5040, loss = 0.70533 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:39:47.159470 ops/training.py:65 2019-01-17 01:39:47.159383: step 5041, loss = 0.70617 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:39:48.449503 ops/training.py:65 2019-01-17 01:39:48.449414: step 5042, loss = 0.66936 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:39:49.733565 ops/training.py:65 2019-01-17 01:39:49.733488: step 5043, loss = 0.71100 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:39:51.025054 ops/training.py:65 2019-01-17 01:39:51.024957: step 5044, loss = 0.67472 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:39:52.309626 ops/training.py:65 2019-01-17 01:39:52.309562: step 5045, loss = 0.70673 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:39:53.590775 ops/training.py:65 2019-01-17 01:39:53.590679: step 5046, loss = 0.70367 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:39:54.873982 ops/training.py:65 2019-01-17 01:39:54.873875: step 5047, loss = 0.68547 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:39:56.154753 ops/training.py:65 2019-01-17 01:39:56.154650: step 5048, loss = 0.70742 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:39:57.440532 ops/training.py:65 2019-01-17 01:39:57.440423: step 5049, loss = 0.67919 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:39:58.722481 ops/training.py:65 2019-01-17 01:39:58.722398: step 5050, loss = 0.67940 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:40:00.009177 ops/training.py:65 2019-01-17 01:40:00.009084: step 5051, loss = 0.72299 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:40:01.289992 ops/training.py:65 2019-01-17 01:40:01.289887: step 5052, loss = 0.70148 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:40:02.569329 ops/training.py:65 2019-01-17 01:40:02.569241: step 5053, loss = 0.72582 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:40:03.853447 ops/training.py:65 2019-01-17 01:40:03.853346: step 5054, loss = 0.72010 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:40:05.139211 ops/training.py:65 2019-01-17 01:40:05.139106: step 5055, loss = 0.72700 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:40:06.425662 ops/training.py:65 2019-01-17 01:40:06.425558: step 5056, loss = 0.70854 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:40:07.707484 ops/training.py:65 2019-01-17 01:40:07.707374: step 5057, loss = 0.67999 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:40:08.995338 ops/training.py:65 2019-01-17 01:40:08.995231: step 5058, loss = 0.70280 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:40:10.276996 ops/training.py:65 2019-01-17 01:40:10.276884: step 5059, loss = 0.66888 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:40:11.558968 ops/training.py:65 2019-01-17 01:40:11.558868: step 5060, loss = 0.68784 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:40:12.845675 ops/training.py:65 2019-01-17 01:40:12.845566: step 5061, loss = 0.71441 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:40:14.133240 ops/training.py:65 2019-01-17 01:40:14.133121: step 5062, loss = 0.68085 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:40:15.417371 ops/training.py:65 2019-01-17 01:40:15.417269: step 5063, loss = 0.72927 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:40:16.694484 ops/training.py:65 2019-01-17 01:40:16.694344: step 5064, loss = 0.69167 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:40:17.981920 ops/training.py:65 2019-01-17 01:40:17.981821: step 5065, loss = 0.70636 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:40:19.272212 ops/training.py:65 2019-01-17 01:40:19.272057: step 5066, loss = 0.68444 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:40:20.558410 ops/training.py:65 2019-01-17 01:40:20.558337: step 5067, loss = 0.70330 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:40:21.838999 ops/training.py:65 2019-01-17 01:40:21.838848: step 5068, loss = 0.66377 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:40:23.127710 ops/training.py:65 2019-01-17 01:40:23.127613: step 5069, loss = 0.71336 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:40:24.407806 ops/training.py:65 2019-01-17 01:40:24.407710: step 5070, loss = 0.68257 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:40:25.691147 ops/training.py:65 2019-01-17 01:40:25.691057: step 5071, loss = 0.72348 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:40:26.976368 ops/training.py:65 2019-01-17 01:40:26.976271: step 5072, loss = 0.67797 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:40:28.262360 ops/training.py:65 2019-01-17 01:40:28.262251: step 5073, loss = 0.73725 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:40:29.543159 ops/training.py:65 2019-01-17 01:40:29.543056: step 5074, loss = 0.72700 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:40:30.821878 ops/training.py:65 2019-01-17 01:40:30.821778: step 5075, loss = 0.70633 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:40:32.104820 ops/training.py:65 2019-01-17 01:40:32.104717: step 5076, loss = 0.71388 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:40:33.394089 ops/training.py:65 2019-01-17 01:40:33.394005: step 5077, loss = 0.69530 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:40:34.680575 ops/training.py:65 2019-01-17 01:40:34.680509: step 5078, loss = 0.65472 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:40:35.963570 ops/training.py:65 2019-01-17 01:40:35.963469: step 5079, loss = 0.67443 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:40:37.244368 ops/training.py:65 2019-01-17 01:40:37.244270: step 5080, loss = 0.72028 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:40:38.526008 ops/training.py:65 2019-01-17 01:40:38.525913: step 5081, loss = 0.74428 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:40:39.806065 ops/training.py:65 2019-01-17 01:40:39.805969: step 5082, loss = 0.69371 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:40:41.089504 ops/training.py:65 2019-01-17 01:40:41.089387: step 5083, loss = 0.69905 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:40:42.367257 ops/training.py:65 2019-01-17 01:40:42.367149: step 5084, loss = 0.68931 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:40:43.660294 ops/training.py:65 2019-01-17 01:40:43.660191: step 5085, loss = 0.67907 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:40:44.943810 ops/training.py:65 2019-01-17 01:40:44.943697: step 5086, loss = 0.68056 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:40:46.229219 ops/training.py:65 2019-01-17 01:40:46.229111: step 5087, loss = 0.73033 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:40:47.516672 ops/training.py:65 2019-01-17 01:40:47.516567: step 5088, loss = 0.73522 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:40:48.801444 ops/training.py:65 2019-01-17 01:40:48.801334: step 5089, loss = 0.68591 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:40:50.077747 ops/training.py:65 2019-01-17 01:40:50.077643: step 5090, loss = 0.72444 (25.1 examples/sec; 1.275 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:40:51.367062 ops/training.py:65 2019-01-17 01:40:51.366958: step 5091, loss = 0.74767 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:40:52.653070 ops/training.py:65 2019-01-17 01:40:52.652973: step 5092, loss = 0.72802 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:40:53.938480 ops/training.py:65 2019-01-17 01:40:53.938378: step 5093, loss = 0.66609 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:40:55.229880 ops/training.py:65 2019-01-17 01:40:55.229785: step 5094, loss = 0.68263 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:40:56.514713 ops/training.py:65 2019-01-17 01:40:56.514644: step 5095, loss = 0.74209 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:40:57.804161 ops/training.py:65 2019-01-17 01:40:57.804065: step 5096, loss = 0.66510 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:40:59.094352 ops/training.py:65 2019-01-17 01:40:59.094277: step 5097, loss = 0.75237 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:41:00.382286 ops/training.py:65 2019-01-17 01:41:00.382218: step 5098, loss = 0.67590 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:41:01.668134 ops/training.py:65 2019-01-17 01:41:01.668070: step 5099, loss = 0.71594 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:41:02.950340 ops/training.py:65 2019-01-17 01:41:02.950235: step 5100, loss = 0.66204 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:41:04.235162 ops/training.py:65 2019-01-17 01:41:04.235035: step 5101, loss = 0.67738 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:41:05.523911 ops/training.py:65 2019-01-17 01:41:05.523749: step 5102, loss = 0.69252 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:41:06.810440 ops/training.py:65 2019-01-17 01:41:06.810337: step 5103, loss = 0.67320 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:41:08.098329 ops/training.py:65 2019-01-17 01:41:08.098218: step 5104, loss = 0.67656 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:41:09.383343 ops/training.py:65 2019-01-17 01:41:09.383236: step 5105, loss = 0.72163 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:41:10.670216 ops/training.py:65 2019-01-17 01:41:10.670123: step 5106, loss = 0.67745 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:41:11.958465 ops/training.py:65 2019-01-17 01:41:11.958357: step 5107, loss = 0.71600 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:41:13.241569 ops/training.py:65 2019-01-17 01:41:13.241470: step 5108, loss = 0.66020 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:41:14.526539 ops/training.py:65 2019-01-17 01:41:14.526435: step 5109, loss = 0.69037 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:41:15.811329 ops/training.py:65 2019-01-17 01:41:15.811224: step 5110, loss = 0.65733 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:41:17.097496 ops/training.py:65 2019-01-17 01:41:17.097399: step 5111, loss = 0.67696 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:41:18.387642 ops/training.py:65 2019-01-17 01:41:18.387487: step 5112, loss = 0.69827 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:41:19.671552 ops/training.py:65 2019-01-17 01:41:19.671486: step 5113, loss = 0.67228 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:41:20.953999 ops/training.py:65 2019-01-17 01:41:20.953844: step 5114, loss = 0.67772 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:41:22.236743 ops/training.py:65 2019-01-17 01:41:22.236635: step 5115, loss = 0.70098 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:41:23.523744 ops/training.py:65 2019-01-17 01:41:23.523644: step 5116, loss = 0.68331 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:41:24.809881 ops/training.py:65 2019-01-17 01:41:24.809785: step 5117, loss = 0.71870 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:41:26.101487 ops/training.py:65 2019-01-17 01:41:26.101395: step 5118, loss = 0.67457 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:41:27.387627 ops/training.py:65 2019-01-17 01:41:27.387551: step 5119, loss = 0.68037 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:41:28.668517 ops/training.py:65 2019-01-17 01:41:28.668415: step 5120, loss = 0.71451 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:41:29.956406 ops/training.py:65 2019-01-17 01:41:29.956304: step 5121, loss = 0.69128 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:41:31.240990 ops/training.py:65 2019-01-17 01:41:31.240877: step 5122, loss = 0.66706 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:41:32.527165 ops/training.py:65 2019-01-17 01:41:32.527032: step 5123, loss = 0.68305 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:41:33.820198 ops/training.py:65 2019-01-17 01:41:33.820103: step 5124, loss = 0.67352 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:41:35.106511 ops/training.py:65 2019-01-17 01:41:35.106437: step 5125, loss = 0.72387 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:41:36.389382 ops/training.py:65 2019-01-17 01:41:36.389282: step 5126, loss = 0.70598 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:41:37.676563 ops/training.py:65 2019-01-17 01:41:37.676461: step 5127, loss = 0.70167 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:41:38.967736 ops/training.py:65 2019-01-17 01:41:38.967576: step 5128, loss = 0.73313 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:41:40.258733 ops/training.py:65 2019-01-17 01:41:40.258645: step 5129, loss = 0.66973 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:41:41.542933 ops/training.py:65 2019-01-17 01:41:41.542862: step 5130, loss = 0.67809 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:41:42.828315 ops/training.py:65 2019-01-17 01:41:42.828213: step 5131, loss = 0.70441 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:41:44.114679 ops/training.py:65 2019-01-17 01:41:44.114570: step 5132, loss = 0.70325 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:41:45.396128 ops/training.py:65 2019-01-17 01:41:45.396028: step 5133, loss = 0.67039 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:41:46.687848 ops/training.py:65 2019-01-17 01:41:46.687737: step 5134, loss = 0.73577 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:41:47.972779 ops/training.py:65 2019-01-17 01:41:47.972697: step 5135, loss = 0.68737 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:41:49.257715 ops/training.py:65 2019-01-17 01:41:49.257614: step 5136, loss = 0.69817 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:41:50.541343 ops/training.py:65 2019-01-17 01:41:50.541235: step 5137, loss = 0.72902 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:41:51.827234 ops/training.py:65 2019-01-17 01:41:51.827127: step 5138, loss = 0.67534 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:41:53.110009 ops/training.py:65 2019-01-17 01:41:53.109906: step 5139, loss = 0.71675 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:41:54.386607 ops/training.py:65 2019-01-17 01:41:54.386444: step 5140, loss = 0.68359 (25.1 examples/sec; 1.275 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:41:55.670654 ops/training.py:65 2019-01-17 01:41:55.670556: step 5141, loss = 0.70431 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:41:56.961956 ops/training.py:65 2019-01-17 01:41:56.961838: step 5142, loss = 0.71330 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:41:58.247736 ops/training.py:65 2019-01-17 01:41:58.247660: step 5143, loss = 0.70714 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:41:59.529224 ops/training.py:65 2019-01-17 01:41:59.529067: step 5144, loss = 0.67080 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:42:00.817252 ops/training.py:65 2019-01-17 01:42:00.817148: step 5145, loss = 0.69452 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:42:02.109438 ops/training.py:65 2019-01-17 01:42:02.109337: step 5146, loss = 0.70419 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:42:03.396248 ops/training.py:65 2019-01-17 01:42:03.396182: step 5147, loss = 0.68259 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:42:04.681033 ops/training.py:65 2019-01-17 01:42:04.680922: step 5148, loss = 0.74319 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:42:05.971745 ops/training.py:65 2019-01-17 01:42:05.971586: step 5149, loss = 0.70657 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:42:07.261997 ops/training.py:65 2019-01-17 01:42:07.261900: step 5150, loss = 0.71942 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:42:08.550859 ops/training.py:65 2019-01-17 01:42:08.550776: step 5151, loss = 0.73312 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:42:09.836090 ops/training.py:65 2019-01-17 01:42:09.836019: step 5152, loss = 0.66006 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:42:11.125451 ops/training.py:65 2019-01-17 01:42:11.125353: step 5153, loss = 0.69752 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:42:12.408532 ops/training.py:65 2019-01-17 01:42:12.408450: step 5154, loss = 0.65558 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:42:13.696714 ops/training.py:65 2019-01-17 01:42:13.696614: step 5155, loss = 0.69562 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:42:14.980872 ops/training.py:65 2019-01-17 01:42:14.980768: step 5156, loss = 0.66850 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:42:16.267008 ops/training.py:65 2019-01-17 01:42:16.266848: step 5157, loss = 0.71350 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:42:17.558281 ops/training.py:65 2019-01-17 01:42:17.558176: step 5158, loss = 0.69422 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:42:18.847835 ops/training.py:65 2019-01-17 01:42:18.847732: step 5159, loss = 0.70432 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:42:20.134380 ops/training.py:65 2019-01-17 01:42:20.134307: step 5160, loss = 0.67922 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:42:21.416309 ops/training.py:65 2019-01-17 01:42:21.416198: step 5161, loss = 0.69089 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:42:22.706173 ops/training.py:65 2019-01-17 01:42:22.706022: step 5162, loss = 0.70945 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:42:23.990713 ops/training.py:65 2019-01-17 01:42:23.990641: step 5163, loss = 0.70808 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:42:25.273662 ops/training.py:65 2019-01-17 01:42:25.273559: step 5164, loss = 0.73226 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:42:26.561469 ops/training.py:65 2019-01-17 01:42:26.561375: step 5165, loss = 0.68368 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:42:27.841015 ops/training.py:65 2019-01-17 01:42:27.840909: step 5166, loss = 0.68989 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:42:29.124770 ops/training.py:65 2019-01-17 01:42:29.124669: step 5167, loss = 0.76518 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:42:30.413775 ops/training.py:65 2019-01-17 01:42:30.413675: step 5168, loss = 0.67241 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:42:31.693752 ops/training.py:65 2019-01-17 01:42:31.693646: step 5169, loss = 0.65006 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:42:32.977554 ops/training.py:65 2019-01-17 01:42:32.977451: step 5170, loss = 0.76042 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.21875
I4672 2019-01-17 01:42:34.266242 ops/training.py:65 2019-01-17 01:42:34.266131: step 5171, loss = 0.70707 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:42:35.546117 ops/training.py:65 2019-01-17 01:42:35.546005: step 5172, loss = 0.68989 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:42:36.833127 ops/training.py:65 2019-01-17 01:42:36.833019: step 5173, loss = 0.65395 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:42:38.118772 ops/training.py:65 2019-01-17 01:42:38.118664: step 5174, loss = 0.68580 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:42:39.405881 ops/training.py:65 2019-01-17 01:42:39.405773: step 5175, loss = 0.69372 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:42:40.690036 ops/training.py:65 2019-01-17 01:42:40.689931: step 5176, loss = 0.69612 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:42:41.981911 ops/training.py:65 2019-01-17 01:42:41.981816: step 5177, loss = 0.69761 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:42:43.267496 ops/training.py:65 2019-01-17 01:42:43.267427: step 5178, loss = 0.71435 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:42:44.554268 ops/training.py:65 2019-01-17 01:42:44.554157: step 5179, loss = 0.72688 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:42:45.838774 ops/training.py:65 2019-01-17 01:42:45.838702: step 5180, loss = 0.70097 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:42:47.123034 ops/training.py:65 2019-01-17 01:42:47.122922: step 5181, loss = 0.68681 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:42:48.411107 ops/training.py:65 2019-01-17 01:42:48.411003: step 5182, loss = 0.68517 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:42:49.695180 ops/training.py:65 2019-01-17 01:42:49.695075: step 5183, loss = 0.65085 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:42:50.984524 ops/training.py:65 2019-01-17 01:42:50.984419: step 5184, loss = 0.70838 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:42:52.269995 ops/training.py:65 2019-01-17 01:42:52.269888: step 5185, loss = 0.69514 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:42:53.557058 ops/training.py:65 2019-01-17 01:42:53.556963: step 5186, loss = 0.70559 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:42:54.837534 ops/training.py:65 2019-01-17 01:42:54.837424: step 5187, loss = 0.70074 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:42:56.125179 ops/training.py:65 2019-01-17 01:42:56.125087: step 5188, loss = 0.68098 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:42:57.409745 ops/training.py:65 2019-01-17 01:42:57.409645: step 5189, loss = 0.71913 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:42:58.698961 ops/training.py:65 2019-01-17 01:42:58.698850: step 5190, loss = 0.69245 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:42:59.989060 ops/training.py:65 2019-01-17 01:42:59.988982: step 5191, loss = 0.67287 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:43:01.278249 ops/training.py:65 2019-01-17 01:43:01.278178: step 5192, loss = 0.70435 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:43:02.563195 ops/training.py:65 2019-01-17 01:43:02.563123: step 5193, loss = 0.71153 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:43:03.843898 ops/training.py:65 2019-01-17 01:43:03.843792: step 5194, loss = 0.70682 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:43:05.131245 ops/training.py:65 2019-01-17 01:43:05.131135: step 5195, loss = 0.72477 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:43:06.416005 ops/training.py:65 2019-01-17 01:43:06.415901: step 5196, loss = 0.70279 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:43:07.695727 ops/training.py:65 2019-01-17 01:43:07.695618: step 5197, loss = 0.67196 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:43:08.978503 ops/training.py:65 2019-01-17 01:43:08.978406: step 5198, loss = 0.68317 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:43:10.263984 ops/training.py:65 2019-01-17 01:43:10.263871: step 5199, loss = 0.70129 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:43:11.546418 ops/training.py:65 2019-01-17 01:43:11.546323: step 5200, loss = 0.71168 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:43:12.827813 ops/training.py:65 2019-01-17 01:43:12.827714: step 5201, loss = 0.71176 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:43:14.115808 ops/training.py:65 2019-01-17 01:43:14.115696: step 5202, loss = 0.68673 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:43:15.400276 ops/training.py:65 2019-01-17 01:43:15.400179: step 5203, loss = 0.68964 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:43:16.684610 ops/training.py:65 2019-01-17 01:43:16.684502: step 5204, loss = 0.69910 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:43:17.975431 ops/training.py:65 2019-01-17 01:43:17.975330: step 5205, loss = 0.68837 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:43:19.259323 ops/training.py:65 2019-01-17 01:43:19.259265: step 5206, loss = 0.64813 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 01:43:20.544956 ops/training.py:65 2019-01-17 01:43:20.544859: step 5207, loss = 0.68586 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:43:21.831101 ops/training.py:65 2019-01-17 01:43:21.830958: step 5208, loss = 0.69341 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:43:23.118633 ops/training.py:65 2019-01-17 01:43:23.118534: step 5209, loss = 0.67538 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:43:24.397695 ops/training.py:65 2019-01-17 01:43:24.397588: step 5210, loss = 0.67101 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:43:25.685370 ops/training.py:65 2019-01-17 01:43:25.685261: step 5211, loss = 0.70260 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:43:26.968994 ops/training.py:65 2019-01-17 01:43:26.968892: step 5212, loss = 0.69023 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:43:28.255459 ops/training.py:65 2019-01-17 01:43:28.255362: step 5213, loss = 0.67127 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:43:29.541563 ops/training.py:65 2019-01-17 01:43:29.541465: step 5214, loss = 0.72353 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:43:30.826034 ops/training.py:65 2019-01-17 01:43:30.825927: step 5215, loss = 0.67790 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:43:32.114603 ops/training.py:65 2019-01-17 01:43:32.114493: step 5216, loss = 0.69255 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:43:33.399056 ops/training.py:65 2019-01-17 01:43:33.398962: step 5217, loss = 0.70736 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:43:34.686229 ops/training.py:65 2019-01-17 01:43:34.686121: step 5218, loss = 0.69831 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:43:35.966822 ops/training.py:65 2019-01-17 01:43:35.966726: step 5219, loss = 0.66419 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:43:37.250130 ops/training.py:65 2019-01-17 01:43:37.250022: step 5220, loss = 0.69735 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:43:38.534581 ops/training.py:65 2019-01-17 01:43:38.534473: step 5221, loss = 0.67741 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:43:39.819862 ops/training.py:65 2019-01-17 01:43:39.819759: step 5222, loss = 0.68402 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:43:41.110432 ops/training.py:65 2019-01-17 01:43:41.110338: step 5223, loss = 0.72237 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:43:42.400056 ops/training.py:65 2019-01-17 01:43:42.399989: step 5224, loss = 0.70397 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:43:43.684522 ops/training.py:65 2019-01-17 01:43:43.684455: step 5225, loss = 0.68549 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:43:44.965383 ops/training.py:65 2019-01-17 01:43:44.965352: step 5226, loss = 0.68774 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:43:46.250357 ops/training.py:65 2019-01-17 01:43:46.250326: step 5227, loss = 0.70442 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:43:47.539710 ops/training.py:65 2019-01-17 01:43:47.539679: step 5228, loss = 0.68371 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:43:48.827417 ops/training.py:65 2019-01-17 01:43:48.827356: step 5229, loss = 0.68822 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:43:50.112611 ops/training.py:65 2019-01-17 01:43:50.112572: step 5230, loss = 0.70023 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:43:51.397016 ops/training.py:65 2019-01-17 01:43:51.396937: step 5231, loss = 0.70841 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:43:52.681347 ops/training.py:65 2019-01-17 01:43:52.681241: step 5232, loss = 0.69976 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:43:53.967515 ops/training.py:65 2019-01-17 01:43:53.967431: step 5233, loss = 0.69387 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:43:55.250211 ops/training.py:65 2019-01-17 01:43:55.250137: step 5234, loss = 0.68649 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:43:56.538377 ops/training.py:65 2019-01-17 01:43:56.538303: step 5235, loss = 0.68843 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:43:57.826659 ops/training.py:65 2019-01-17 01:43:57.826568: step 5236, loss = 0.70894 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:43:59.110010 ops/training.py:65 2019-01-17 01:43:59.109899: step 5237, loss = 0.70709 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:44:00.396544 ops/training.py:65 2019-01-17 01:44:00.396446: step 5238, loss = 0.72784 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:44:01.687153 ops/training.py:65 2019-01-17 01:44:01.687061: step 5239, loss = 0.68611 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:44:02.969278 ops/training.py:65 2019-01-17 01:44:02.969175: step 5240, loss = 0.69402 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:44:04.255613 ops/training.py:65 2019-01-17 01:44:04.255527: step 5241, loss = 0.68954 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:44:05.547370 ops/training.py:65 2019-01-17 01:44:05.547279: step 5242, loss = 0.67648 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:44:06.837108 ops/training.py:65 2019-01-17 01:44:06.837030: step 5243, loss = 0.75287 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:44:08.122005 ops/training.py:65 2019-01-17 01:44:08.121922: step 5244, loss = 0.67223 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:44:09.410648 ops/training.py:65 2019-01-17 01:44:09.410579: step 5245, loss = 0.71462 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:44:10.698209 ops/training.py:65 2019-01-17 01:44:10.698128: step 5246, loss = 0.67304 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:44:11.980230 ops/training.py:65 2019-01-17 01:44:11.980158: step 5247, loss = 0.69940 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:44:13.260896 ops/training.py:65 2019-01-17 01:44:13.260814: step 5248, loss = 0.74078 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:44:14.546444 ops/training.py:65 2019-01-17 01:44:14.546400: step 5249, loss = 0.69008 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:44:15.830523 ops/training.py:65 2019-01-17 01:44:15.830491: step 5250, loss = 0.70853 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:44:17.121334 ops/training.py:65 2019-01-17 01:44:17.121299: step 5251, loss = 0.75264 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:44:18.405790 ops/training.py:65 2019-01-17 01:44:18.405707: step 5252, loss = 0.67395 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:44:19.697678 ops/training.py:65 2019-01-17 01:44:19.697610: step 5253, loss = 0.73755 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:44:20.985512 ops/training.py:65 2019-01-17 01:44:20.985476: step 5254, loss = 0.74284 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:44:22.275329 ops/training.py:65 2019-01-17 01:44:22.275245: step 5255, loss = 0.66802 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:44:23.563854 ops/training.py:65 2019-01-17 01:44:23.563775: step 5256, loss = 0.70720 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:44:24.852861 ops/training.py:65 2019-01-17 01:44:24.852784: step 5257, loss = 0.76600 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:44:26.141438 ops/training.py:65 2019-01-17 01:44:26.141345: step 5258, loss = 0.71962 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:44:27.428227 ops/training.py:65 2019-01-17 01:44:27.428150: step 5259, loss = 0.71363 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:44:28.712857 ops/training.py:65 2019-01-17 01:44:28.712809: step 5260, loss = 0.74300 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:44:29.992523 ops/training.py:65 2019-01-17 01:44:29.992483: step 5261, loss = 0.71745 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:44:31.282128 ops/training.py:65 2019-01-17 01:44:31.282056: step 5262, loss = 0.71430 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:44:32.568669 ops/training.py:65 2019-01-17 01:44:32.568588: step 5263, loss = 0.66160 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:44:33.852157 ops/training.py:65 2019-01-17 01:44:33.852080: step 5264, loss = 0.73838 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:44:35.137688 ops/training.py:65 2019-01-17 01:44:35.137573: step 5265, loss = 0.69676 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:44:36.419806 ops/training.py:65 2019-01-17 01:44:36.419652: step 5266, loss = 0.69996 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:44:37.704495 ops/training.py:65 2019-01-17 01:44:37.704391: step 5267, loss = 0.72363 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:44:38.985868 ops/training.py:65 2019-01-17 01:44:38.985767: step 5268, loss = 0.66081 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:44:40.272681 ops/training.py:65 2019-01-17 01:44:40.272578: step 5269, loss = 0.77328 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:44:41.558141 ops/training.py:65 2019-01-17 01:44:41.558070: step 5270, loss = 0.68811 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:44:42.842490 ops/training.py:65 2019-01-17 01:44:42.842388: step 5271, loss = 0.70839 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:44:44.126093 ops/training.py:65 2019-01-17 01:44:44.125991: step 5272, loss = 0.70871 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:44:45.413910 ops/training.py:65 2019-01-17 01:44:45.413807: step 5273, loss = 0.71938 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:44:46.698306 ops/training.py:65 2019-01-17 01:44:46.698226: step 5274, loss = 0.66900 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:44:47.981978 ops/training.py:65 2019-01-17 01:44:47.981894: step 5275, loss = 0.71798 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:44:49.269597 ops/training.py:65 2019-01-17 01:44:49.269543: step 5276, loss = 0.70565 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:44:50.559731 ops/training.py:65 2019-01-17 01:44:50.559696: step 5277, loss = 0.73585 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:44:51.843306 ops/training.py:65 2019-01-17 01:44:51.843273: step 5278, loss = 0.71594 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:44:53.130481 ops/training.py:65 2019-01-17 01:44:53.130447: step 5279, loss = 0.70820 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:44:54.413306 ops/training.py:65 2019-01-17 01:44:54.413276: step 5280, loss = 0.63680 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:44:55.697471 ops/training.py:65 2019-01-17 01:44:55.697425: step 5281, loss = 0.66919 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:44:56.987902 ops/training.py:65 2019-01-17 01:44:56.987860: step 5282, loss = 0.75311 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:44:58.275456 ops/training.py:65 2019-01-17 01:44:58.275364: step 5283, loss = 0.67965 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:44:59.565347 ops/training.py:65 2019-01-17 01:44:59.565282: step 5284, loss = 0.72882 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:45:00.848820 ops/training.py:65 2019-01-17 01:45:00.848738: step 5285, loss = 0.70002 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:45:02.139708 ops/training.py:65 2019-01-17 01:45:02.139671: step 5286, loss = 0.73514 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:45:03.432471 ops/training.py:65 2019-01-17 01:45:03.432394: step 5287, loss = 0.70687 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:45:04.722882 ops/training.py:65 2019-01-17 01:45:04.722785: step 5288, loss = 0.71349 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:45:06.009807 ops/training.py:65 2019-01-17 01:45:06.009707: step 5289, loss = 0.74645 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:45:07.297030 ops/training.py:65 2019-01-17 01:45:07.296965: step 5290, loss = 0.69781 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:45:08.581782 ops/training.py:65 2019-01-17 01:45:08.581711: step 5291, loss = 0.69606 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:45:09.873619 ops/training.py:65 2019-01-17 01:45:09.873522: step 5292, loss = 0.67045 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:45:11.161076 ops/training.py:65 2019-01-17 01:45:11.161005: step 5293, loss = 0.74467 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:45:12.448018 ops/training.py:65 2019-01-17 01:45:12.447910: step 5294, loss = 0.71091 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:45:13.738841 ops/training.py:65 2019-01-17 01:45:13.738763: step 5295, loss = 0.71389 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:45:15.022890 ops/training.py:65 2019-01-17 01:45:15.022824: step 5296, loss = 0.70701 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:45:16.307273 ops/training.py:65 2019-01-17 01:45:16.307168: step 5297, loss = 0.70530 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:45:17.598273 ops/training.py:65 2019-01-17 01:45:17.598168: step 5298, loss = 0.67311 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:45:18.890615 ops/training.py:65 2019-01-17 01:45:18.890539: step 5299, loss = 0.70420 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:45:20.173656 ops/training.py:65 2019-01-17 01:45:20.173590: step 5300, loss = 0.66203 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:45:21.464652 ops/training.py:65 2019-01-17 01:45:21.464553: step 5301, loss = 0.64662 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:45:22.751625 ops/training.py:65 2019-01-17 01:45:22.751534: step 5302, loss = 0.74065 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:45:24.042250 ops/training.py:65 2019-01-17 01:45:24.042147: step 5303, loss = 0.70835 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:45:25.318737 ops/training.py:65 2019-01-17 01:45:25.318655: step 5304, loss = 0.67381 (25.1 examples/sec; 1.275 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:45:26.599860 ops/training.py:65 2019-01-17 01:45:26.599765: step 5305, loss = 0.72028 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:45:27.887031 ops/training.py:65 2019-01-17 01:45:27.886918: step 5306, loss = 0.69173 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:45:29.169123 ops/training.py:65 2019-01-17 01:45:29.169012: step 5307, loss = 0.71786 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:45:30.449492 ops/training.py:65 2019-01-17 01:45:30.449389: step 5308, loss = 0.64600 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:45:31.731320 ops/training.py:65 2019-01-17 01:45:31.731205: step 5309, loss = 0.73499 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:45:33.014246 ops/training.py:65 2019-01-17 01:45:33.014137: step 5310, loss = 0.71439 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:45:34.304289 ops/training.py:65 2019-01-17 01:45:34.304201: step 5311, loss = 0.68377 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:45:35.589576 ops/training.py:65 2019-01-17 01:45:35.589507: step 5312, loss = 0.72449 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:45:36.875304 ops/training.py:65 2019-01-17 01:45:36.875196: step 5313, loss = 0.69021 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:45:38.158880 ops/training.py:65 2019-01-17 01:45:38.158771: step 5314, loss = 0.66824 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:45:39.446092 ops/training.py:65 2019-01-17 01:45:39.445989: step 5315, loss = 0.74078 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:45:40.722696 ops/training.py:65 2019-01-17 01:45:40.722589: step 5316, loss = 0.72491 (25.1 examples/sec; 1.275 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:45:42.005265 ops/training.py:65 2019-01-17 01:45:42.005131: step 5317, loss = 0.67620 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:45:43.295361 ops/training.py:65 2019-01-17 01:45:43.295214: step 5318, loss = 0.70390 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:45:44.585212 ops/training.py:65 2019-01-17 01:45:44.585112: step 5319, loss = 0.72390 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:45:45.869321 ops/training.py:65 2019-01-17 01:45:45.869233: step 5320, loss = 0.74174 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:45:47.150690 ops/training.py:65 2019-01-17 01:45:47.150582: step 5321, loss = 0.77353 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:45:48.436782 ops/training.py:65 2019-01-17 01:45:48.436679: step 5322, loss = 0.64287 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:45:49.726732 ops/training.py:65 2019-01-17 01:45:49.726587: step 5323, loss = 0.72000 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:45:51.016530 ops/training.py:65 2019-01-17 01:45:51.016450: step 5324, loss = 0.71164 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:45:52.305444 ops/training.py:65 2019-01-17 01:45:52.305370: step 5325, loss = 0.78944 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-17 01:45:53.593682 ops/training.py:65 2019-01-17 01:45:53.593580: step 5326, loss = 0.66167 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:45:54.878675 ops/training.py:65 2019-01-17 01:45:54.878564: step 5327, loss = 0.67350 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:45:56.165661 ops/training.py:65 2019-01-17 01:45:56.165565: step 5328, loss = 0.66810 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:45:57.450991 ops/training.py:65 2019-01-17 01:45:57.450884: step 5329, loss = 0.69627 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:45:58.733757 ops/training.py:65 2019-01-17 01:45:58.733649: step 5330, loss = 0.66569 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:46:00.020176 ops/training.py:65 2019-01-17 01:46:00.020062: step 5331, loss = 0.66561 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:46:01.300248 ops/training.py:65 2019-01-17 01:46:01.300145: step 5332, loss = 0.71726 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:46:02.595581 ops/training.py:65 2019-01-17 01:46:02.595419: step 5333, loss = 0.74171 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:46:03.882063 ops/training.py:65 2019-01-17 01:46:03.881990: step 5334, loss = 0.71851 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:46:05.172777 ops/training.py:65 2019-01-17 01:46:05.172621: step 5335, loss = 0.68085 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:46:06.462122 ops/training.py:65 2019-01-17 01:46:06.462049: step 5336, loss = 0.70033 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:46:07.743186 ops/training.py:65 2019-01-17 01:46:07.743115: step 5337, loss = 0.64236 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:46:09.031308 ops/training.py:65 2019-01-17 01:46:09.031196: step 5338, loss = 0.67797 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:46:10.314718 ops/training.py:65 2019-01-17 01:46:10.314609: step 5339, loss = 0.68424 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:46:11.597625 ops/training.py:65 2019-01-17 01:46:11.597503: step 5340, loss = 0.68572 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:46:12.884575 ops/training.py:65 2019-01-17 01:46:12.884466: step 5341, loss = 0.72133 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:46:14.171809 ops/training.py:65 2019-01-17 01:46:14.171701: step 5342, loss = 0.73049 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:46:15.456528 ops/training.py:65 2019-01-17 01:46:15.456385: step 5343, loss = 0.68880 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:46:16.743378 ops/training.py:65 2019-01-17 01:46:16.743270: step 5344, loss = 0.65298 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:46:18.029398 ops/training.py:65 2019-01-17 01:46:18.029290: step 5345, loss = 0.73097 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:46:19.309094 ops/training.py:65 2019-01-17 01:46:19.308980: step 5346, loss = 0.68955 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:46:20.593108 ops/training.py:65 2019-01-17 01:46:20.593006: step 5347, loss = 0.72360 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:46:21.882438 ops/training.py:65 2019-01-17 01:46:21.882331: step 5348, loss = 0.67548 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:46:23.165991 ops/training.py:65 2019-01-17 01:46:23.165900: step 5349, loss = 0.74692 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:46:24.456734 ops/training.py:65 2019-01-17 01:46:24.456572: step 5350, loss = 0.69628 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:46:25.742090 ops/training.py:65 2019-01-17 01:46:25.741993: step 5351, loss = 0.71227 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:46:27.023492 ops/training.py:65 2019-01-17 01:46:27.023390: step 5352, loss = 0.66926 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:46:28.308381 ops/training.py:65 2019-01-17 01:46:28.308228: step 5353, loss = 0.70502 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:46:29.589927 ops/training.py:65 2019-01-17 01:46:29.589823: step 5354, loss = 0.64765 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:46:30.875061 ops/training.py:65 2019-01-17 01:46:30.874964: step 5355, loss = 0.68046 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:46:32.161383 ops/training.py:65 2019-01-17 01:46:32.161283: step 5356, loss = 0.67586 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:46:33.440452 ops/training.py:65 2019-01-17 01:46:33.440344: step 5357, loss = 0.69804 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:46:34.731403 ops/training.py:65 2019-01-17 01:46:34.731308: step 5358, loss = 0.70627 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:46:36.012028 ops/training.py:65 2019-01-17 01:46:36.011951: step 5359, loss = 0.73352 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:46:37.302496 ops/training.py:65 2019-01-17 01:46:37.302387: step 5360, loss = 0.66589 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:46:38.592418 ops/training.py:65 2019-01-17 01:46:38.592315: step 5361, loss = 0.67843 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:46:39.881281 ops/training.py:65 2019-01-17 01:46:39.881210: step 5362, loss = 0.71937 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:46:41.160601 ops/training.py:65 2019-01-17 01:46:41.160532: step 5363, loss = 0.71140 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:46:42.442441 ops/training.py:65 2019-01-17 01:46:42.442343: step 5364, loss = 0.68957 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:46:43.728135 ops/training.py:65 2019-01-17 01:46:43.728036: step 5365, loss = 0.69567 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:46:45.010539 ops/training.py:65 2019-01-17 01:46:45.010432: step 5366, loss = 0.67207 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:46:46.298483 ops/training.py:65 2019-01-17 01:46:46.298381: step 5367, loss = 0.68155 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:46:47.584596 ops/training.py:65 2019-01-17 01:46:47.584486: step 5368, loss = 0.67772 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:46:48.869255 ops/training.py:65 2019-01-17 01:46:48.869150: step 5369, loss = 0.69160 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:46:50.150245 ops/training.py:65 2019-01-17 01:46:50.150133: step 5370, loss = 0.65983 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:46:51.440268 ops/training.py:65 2019-01-17 01:46:51.440111: step 5371, loss = 0.64697 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:46:52.726750 ops/training.py:65 2019-01-17 01:46:52.726674: step 5372, loss = 0.68667 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:46:54.010914 ops/training.py:65 2019-01-17 01:46:54.010816: step 5373, loss = 0.68485 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:46:55.298131 ops/training.py:65 2019-01-17 01:46:55.298030: step 5374, loss = 0.69527 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:46:56.584283 ops/training.py:65 2019-01-17 01:46:56.584183: step 5375, loss = 0.69667 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:46:57.871124 ops/training.py:65 2019-01-17 01:46:57.871022: step 5376, loss = 0.66122 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:46:59.158205 ops/training.py:65 2019-01-17 01:46:59.158102: step 5377, loss = 0.75714 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:47:00.440159 ops/training.py:65 2019-01-17 01:47:00.440058: step 5378, loss = 0.70410 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:47:01.725652 ops/training.py:65 2019-01-17 01:47:01.725510: step 5379, loss = 0.69600 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:47:03.010564 ops/training.py:65 2019-01-17 01:47:03.010468: step 5380, loss = 0.72785 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:47:04.303630 ops/training.py:65 2019-01-17 01:47:04.303523: step 5381, loss = 0.66902 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:47:05.587691 ops/training.py:65 2019-01-17 01:47:05.587589: step 5382, loss = 0.67223 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:47:06.875391 ops/training.py:65 2019-01-17 01:47:06.875288: step 5383, loss = 0.72811 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:47:08.162779 ops/training.py:65 2019-01-17 01:47:08.162634: step 5384, loss = 0.70478 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:47:09.449858 ops/training.py:65 2019-01-17 01:47:09.449743: step 5385, loss = 0.71853 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:47:10.740012 ops/training.py:65 2019-01-17 01:47:10.739904: step 5386, loss = 0.70032 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:47:12.025964 ops/training.py:65 2019-01-17 01:47:12.025884: step 5387, loss = 0.71766 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:47:13.309509 ops/training.py:65 2019-01-17 01:47:13.309414: step 5388, loss = 0.71993 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:47:14.602251 ops/training.py:65 2019-01-17 01:47:14.602143: step 5389, loss = 0.69402 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:47:15.888987 ops/training.py:65 2019-01-17 01:47:15.888913: step 5390, loss = 0.69214 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:47:17.173097 ops/training.py:65 2019-01-17 01:47:17.173031: step 5391, loss = 0.66638 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 01:47:18.462612 ops/training.py:65 2019-01-17 01:47:18.462502: step 5392, loss = 0.74730 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:47:19.754455 ops/training.py:65 2019-01-17 01:47:19.754352: step 5393, loss = 0.70583 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:47:21.045272 ops/training.py:65 2019-01-17 01:47:21.045171: step 5394, loss = 0.69515 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:47:22.334323 ops/training.py:65 2019-01-17 01:47:22.334222: step 5395, loss = 0.65361 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:47:23.623382 ops/training.py:65 2019-01-17 01:47:23.623303: step 5396, loss = 0.68883 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:47:24.904338 ops/training.py:65 2019-01-17 01:47:24.904260: step 5397, loss = 0.72970 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:47:26.186148 ops/training.py:65 2019-01-17 01:47:26.186048: step 5398, loss = 0.72708 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:47:27.470656 ops/training.py:65 2019-01-17 01:47:27.470548: step 5399, loss = 0.66766 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:47:28.761340 ops/training.py:65 2019-01-17 01:47:28.761175: step 5400, loss = 0.70319 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:47:30.045929 ops/training.py:65 2019-01-17 01:47:30.045865: step 5401, loss = 0.75777 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:47:31.337625 ops/training.py:65 2019-01-17 01:47:31.337523: step 5402, loss = 0.67437 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:47:32.621089 ops/training.py:65 2019-01-17 01:47:32.621015: step 5403, loss = 0.67003 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:47:33.900541 ops/training.py:65 2019-01-17 01:47:33.900435: step 5404, loss = 0.68045 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:47:35.185681 ops/training.py:65 2019-01-17 01:47:35.185574: step 5405, loss = 0.69910 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:47:36.466108 ops/training.py:65 2019-01-17 01:47:36.465993: step 5406, loss = 0.71094 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:47:37.747483 ops/training.py:65 2019-01-17 01:47:37.747370: step 5407, loss = 0.67117 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:47:39.032999 ops/training.py:65 2019-01-17 01:47:39.032885: step 5408, loss = 0.71693 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:47:40.316435 ops/training.py:65 2019-01-17 01:47:40.316334: step 5409, loss = 0.69360 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:47:41.603101 ops/training.py:65 2019-01-17 01:47:41.603000: step 5410, loss = 0.66340 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:47:42.884805 ops/training.py:65 2019-01-17 01:47:42.884701: step 5411, loss = 0.69466 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:47:44.169052 ops/training.py:65 2019-01-17 01:47:44.168946: step 5412, loss = 0.68335 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:47:45.459420 ops/training.py:65 2019-01-17 01:47:45.459309: step 5413, loss = 0.69327 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:47:46.743953 ops/training.py:65 2019-01-17 01:47:46.743885: step 5414, loss = 0.67436 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:47:48.027664 ops/training.py:65 2019-01-17 01:47:48.027573: step 5415, loss = 0.71506 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:47:49.315890 ops/training.py:65 2019-01-17 01:47:49.315801: step 5416, loss = 0.71400 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:47:50.601899 ops/training.py:65 2019-01-17 01:47:50.601787: step 5417, loss = 0.68735 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:47:51.884634 ops/training.py:65 2019-01-17 01:47:51.884547: step 5418, loss = 0.66810 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:47:53.165308 ops/training.py:65 2019-01-17 01:47:53.165201: step 5419, loss = 0.67692 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:47:54.445031 ops/training.py:65 2019-01-17 01:47:54.444920: step 5420, loss = 0.67774 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:47:55.731603 ops/training.py:65 2019-01-17 01:47:55.731498: step 5421, loss = 0.70525 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:47:57.017792 ops/training.py:65 2019-01-17 01:47:57.017697: step 5422, loss = 0.71390 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:47:58.309304 ops/training.py:65 2019-01-17 01:47:58.309204: step 5423, loss = 0.66919 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:47:59.592623 ops/training.py:65 2019-01-17 01:47:59.592536: step 5424, loss = 0.74108 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:48:00.876380 ops/training.py:65 2019-01-17 01:48:00.876274: step 5425, loss = 0.70318 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:48:02.168822 ops/training.py:65 2019-01-17 01:48:02.168713: step 5426, loss = 0.71679 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:48:03.452296 ops/training.py:65 2019-01-17 01:48:03.452206: step 5427, loss = 0.66035 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:48:04.733139 ops/training.py:65 2019-01-17 01:48:04.733046: step 5428, loss = 0.67752 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:48:06.017919 ops/training.py:65 2019-01-17 01:48:06.017806: step 5429, loss = 0.70232 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:48:07.297994 ops/training.py:65 2019-01-17 01:48:07.297898: step 5430, loss = 0.67894 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:48:08.578792 ops/training.py:65 2019-01-17 01:48:08.578696: step 5431, loss = 0.69628 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:48:09.863095 ops/training.py:65 2019-01-17 01:48:09.863001: step 5432, loss = 0.71791 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:48:11.144968 ops/training.py:65 2019-01-17 01:48:11.144877: step 5433, loss = 0.70824 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:48:12.425106 ops/training.py:65 2019-01-17 01:48:12.425008: step 5434, loss = 0.70207 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:48:13.708875 ops/training.py:65 2019-01-17 01:48:13.708770: step 5435, loss = 0.70406 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:48:14.991417 ops/training.py:65 2019-01-17 01:48:14.991322: step 5436, loss = 0.69545 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:48:16.276275 ops/training.py:65 2019-01-17 01:48:16.276173: step 5437, loss = 0.68163 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:48:17.562670 ops/training.py:65 2019-01-17 01:48:17.562569: step 5438, loss = 0.71249 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:48:18.845481 ops/training.py:65 2019-01-17 01:48:18.845390: step 5439, loss = 0.68221 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:48:20.130059 ops/training.py:65 2019-01-17 01:48:20.129955: step 5440, loss = 0.69875 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:48:21.410707 ops/training.py:65 2019-01-17 01:48:21.410611: step 5441, loss = 0.70528 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:48:22.696535 ops/training.py:65 2019-01-17 01:48:22.696440: step 5442, loss = 0.67904 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:48:23.980872 ops/training.py:65 2019-01-17 01:48:23.980774: step 5443, loss = 0.69461 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:48:25.266682 ops/training.py:65 2019-01-17 01:48:25.266579: step 5444, loss = 0.66372 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:48:26.549904 ops/training.py:65 2019-01-17 01:48:26.549806: step 5445, loss = 0.69947 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:48:27.829342 ops/training.py:65 2019-01-17 01:48:27.829242: step 5446, loss = 0.66668 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:48:29.116295 ops/training.py:65 2019-01-17 01:48:29.116193: step 5447, loss = 0.68029 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:48:30.400612 ops/training.py:65 2019-01-17 01:48:30.400511: step 5448, loss = 0.69774 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:48:31.687198 ops/training.py:65 2019-01-17 01:48:31.687091: step 5449, loss = 0.70261 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:48:32.967625 ops/training.py:65 2019-01-17 01:48:32.967526: step 5450, loss = 0.65835 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:48:34.247135 ops/training.py:65 2019-01-17 01:48:34.247031: step 5451, loss = 0.68992 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:48:35.527027 ops/training.py:65 2019-01-17 01:48:35.526935: step 5452, loss = 0.67985 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:48:36.815238 ops/training.py:65 2019-01-17 01:48:36.815147: step 5453, loss = 0.68180 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:48:38.104254 ops/training.py:65 2019-01-17 01:48:38.104181: step 5454, loss = 0.70634 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:48:39.391523 ops/training.py:65 2019-01-17 01:48:39.391437: step 5455, loss = 0.71897 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:48:40.674632 ops/training.py:65 2019-01-17 01:48:40.674559: step 5456, loss = 0.67495 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:48:41.958822 ops/training.py:65 2019-01-17 01:48:41.958702: step 5457, loss = 0.69222 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:48:43.246548 ops/training.py:65 2019-01-17 01:48:43.246449: step 5458, loss = 0.68651 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:48:44.527210 ops/training.py:65 2019-01-17 01:48:44.527106: step 5459, loss = 0.68486 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:48:45.810512 ops/training.py:65 2019-01-17 01:48:45.810413: step 5460, loss = 0.68907 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:48:47.093104 ops/training.py:65 2019-01-17 01:48:47.093009: step 5461, loss = 0.73601 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:48:48.372691 ops/training.py:65 2019-01-17 01:48:48.372582: step 5462, loss = 0.68534 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:48:49.652313 ops/training.py:65 2019-01-17 01:48:49.652207: step 5463, loss = 0.70188 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:48:50.933025 ops/training.py:65 2019-01-17 01:48:50.932876: step 5464, loss = 0.68005 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:48:52.219196 ops/training.py:65 2019-01-17 01:48:52.219107: step 5465, loss = 0.68568 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:48:53.504742 ops/training.py:65 2019-01-17 01:48:53.504654: step 5466, loss = 0.70135 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:48:54.788540 ops/training.py:65 2019-01-17 01:48:54.788441: step 5467, loss = 0.69549 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:48:56.074188 ops/training.py:65 2019-01-17 01:48:56.074086: step 5468, loss = 0.67877 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:48:57.355542 ops/training.py:65 2019-01-17 01:48:57.355444: step 5469, loss = 0.67401 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:48:58.634509 ops/training.py:65 2019-01-17 01:48:58.634410: step 5470, loss = 0.69731 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:48:59.917965 ops/training.py:65 2019-01-17 01:48:59.917860: step 5471, loss = 0.68325 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:49:01.204239 ops/training.py:65 2019-01-17 01:49:01.204148: step 5472, loss = 0.68517 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:49:02.489840 ops/training.py:65 2019-01-17 01:49:02.489740: step 5473, loss = 0.66080 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:49:03.776692 ops/training.py:65 2019-01-17 01:49:03.776598: step 5474, loss = 0.67674 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:49:05.057849 ops/training.py:65 2019-01-17 01:49:05.057747: step 5475, loss = 0.69521 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:49:06.341197 ops/training.py:65 2019-01-17 01:49:06.341086: step 5476, loss = 0.68923 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:49:07.628351 ops/training.py:65 2019-01-17 01:49:07.628243: step 5477, loss = 0.70938 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:49:08.914600 ops/training.py:65 2019-01-17 01:49:08.914501: step 5478, loss = 0.69434 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:49:10.203800 ops/training.py:65 2019-01-17 01:49:10.203703: step 5479, loss = 0.68290 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:49:11.489645 ops/training.py:65 2019-01-17 01:49:11.489574: step 5480, loss = 0.72491 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:49:12.774811 ops/training.py:65 2019-01-17 01:49:12.774708: step 5481, loss = 0.67391 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:49:14.061274 ops/training.py:65 2019-01-17 01:49:14.061177: step 5482, loss = 0.67269 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:49:15.343122 ops/training.py:65 2019-01-17 01:49:15.343013: step 5483, loss = 0.70002 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:49:16.628279 ops/training.py:65 2019-01-17 01:49:16.628180: step 5484, loss = 0.71096 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:49:17.918740 ops/training.py:65 2019-01-17 01:49:17.918643: step 5485, loss = 0.66793 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 01:49:19.203612 ops/training.py:65 2019-01-17 01:49:19.203512: step 5486, loss = 0.71896 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:49:20.489967 ops/training.py:65 2019-01-17 01:49:20.489861: step 5487, loss = 0.68010 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:49:21.781166 ops/training.py:65 2019-01-17 01:49:21.781068: step 5488, loss = 0.66829 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:49:23.065217 ops/training.py:65 2019-01-17 01:49:23.065121: step 5489, loss = 0.70280 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:49:24.349158 ops/training.py:65 2019-01-17 01:49:24.349062: step 5490, loss = 0.71552 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:49:25.629955 ops/training.py:65 2019-01-17 01:49:25.629851: step 5491, loss = 0.71511 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:49:26.917934 ops/training.py:65 2019-01-17 01:49:26.917843: step 5492, loss = 0.69119 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:49:28.202529 ops/training.py:65 2019-01-17 01:49:28.202419: step 5493, loss = 0.66986 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:49:29.495723 ops/training.py:65 2019-01-17 01:49:29.495614: step 5494, loss = 0.69443 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:49:30.784678 ops/training.py:65 2019-01-17 01:49:30.784544: step 5495, loss = 0.67372 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:49:32.069534 ops/training.py:65 2019-01-17 01:49:32.069457: step 5496, loss = 0.68524 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:49:33.353190 ops/training.py:65 2019-01-17 01:49:33.353064: step 5497, loss = 0.70878 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:49:34.643967 ops/training.py:65 2019-01-17 01:49:34.643863: step 5498, loss = 0.65411 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 01:49:35.935298 ops/training.py:65 2019-01-17 01:49:35.935213: step 5499, loss = 0.70325 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:49:37.224334 ops/training.py:65 2019-01-17 01:49:37.224262: step 5500, loss = 0.65024 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 01:49:38.513155 ops/training.py:65 2019-01-17 01:49:38.513071: step 5501, loss = 0.67037 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:49:39.799067 ops/training.py:65 2019-01-17 01:49:39.798991: step 5502, loss = 0.67362 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:49:41.087255 ops/training.py:65 2019-01-17 01:49:41.087173: step 5503, loss = 0.71211 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:49:42.376702 ops/training.py:65 2019-01-17 01:49:42.376604: step 5504, loss = 0.72178 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:49:43.666587 ops/training.py:65 2019-01-17 01:49:43.666489: step 5505, loss = 0.69524 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:49:44.954050 ops/training.py:65 2019-01-17 01:49:44.953956: step 5506, loss = 0.73072 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:49:46.243438 ops/training.py:65 2019-01-17 01:49:46.243366: step 5507, loss = 0.71469 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:49:47.530500 ops/training.py:65 2019-01-17 01:49:47.530412: step 5508, loss = 0.71671 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:49:48.819375 ops/training.py:65 2019-01-17 01:49:48.819303: step 5509, loss = 0.70680 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:49:50.101906 ops/training.py:65 2019-01-17 01:49:50.101842: step 5510, loss = 0.68503 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:49:51.387160 ops/training.py:65 2019-01-17 01:49:51.387053: step 5511, loss = 0.67872 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:49:52.670797 ops/training.py:65 2019-01-17 01:49:52.670658: step 5512, loss = 0.68902 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:49:53.957695 ops/training.py:65 2019-01-17 01:49:53.957591: step 5513, loss = 0.71364 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:49:55.242600 ops/training.py:65 2019-01-17 01:49:55.242500: step 5514, loss = 0.69866 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:49:56.530201 ops/training.py:65 2019-01-17 01:49:56.530109: step 5515, loss = 0.71841 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:49:57.819323 ops/training.py:65 2019-01-17 01:49:57.819230: step 5516, loss = 0.69256 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:49:59.105109 ops/training.py:65 2019-01-17 01:49:59.105035: step 5517, loss = 0.69081 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:50:00.395392 ops/training.py:65 2019-01-17 01:50:00.395288: step 5518, loss = 0.68725 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:50:01.683538 ops/training.py:65 2019-01-17 01:50:01.683453: step 5519, loss = 0.68141 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:50:02.978378 ops/training.py:65 2019-01-17 01:50:02.978302: step 5520, loss = 0.69335 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:50:04.266251 ops/training.py:65 2019-01-17 01:50:04.266173: step 5521, loss = 0.70237 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:50:05.554883 ops/training.py:65 2019-01-17 01:50:05.554793: step 5522, loss = 0.71421 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:50:06.842894 ops/training.py:65 2019-01-17 01:50:06.842818: step 5523, loss = 0.69354 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:50:08.131362 ops/training.py:65 2019-01-17 01:50:08.131234: step 5524, loss = 0.68848 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:50:09.421867 ops/training.py:65 2019-01-17 01:50:09.421779: step 5525, loss = 0.70960 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:50:10.711268 ops/training.py:65 2019-01-17 01:50:10.711181: step 5526, loss = 0.65436 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:50:12.000004 ops/training.py:65 2019-01-17 01:50:11.999920: step 5527, loss = 0.70253 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:50:13.287535 ops/training.py:65 2019-01-17 01:50:13.287468: step 5528, loss = 0.69753 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:50:14.574969 ops/training.py:65 2019-01-17 01:50:14.574908: step 5529, loss = 0.69203 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:50:15.860189 ops/training.py:65 2019-01-17 01:50:15.860114: step 5530, loss = 0.71503 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:50:17.150464 ops/training.py:65 2019-01-17 01:50:17.150358: step 5531, loss = 0.67773 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:50:18.441077 ops/training.py:65 2019-01-17 01:50:18.441011: step 5532, loss = 0.70910 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:50:19.728146 ops/training.py:65 2019-01-17 01:50:19.728079: step 5533, loss = 0.67647 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:50:21.017849 ops/training.py:65 2019-01-17 01:50:21.017748: step 5534, loss = 0.71828 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:50:22.306980 ops/training.py:65 2019-01-17 01:50:22.306903: step 5535, loss = 0.67796 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:50:23.594661 ops/training.py:65 2019-01-17 01:50:23.594589: step 5536, loss = 0.68327 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:50:24.882398 ops/training.py:65 2019-01-17 01:50:24.882325: step 5537, loss = 0.69894 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:50:26.169752 ops/training.py:65 2019-01-17 01:50:26.169682: step 5538, loss = 0.67334 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:50:27.453729 ops/training.py:65 2019-01-17 01:50:27.453656: step 5539, loss = 0.70152 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:50:28.735588 ops/training.py:65 2019-01-17 01:50:28.735434: step 5540, loss = 0.68214 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:50:30.026029 ops/training.py:65 2019-01-17 01:50:30.025921: step 5541, loss = 0.70792 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:50:31.314888 ops/training.py:65 2019-01-17 01:50:31.314811: step 5542, loss = 0.74735 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:50:32.604429 ops/training.py:65 2019-01-17 01:50:32.604350: step 5543, loss = 0.69316 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:50:33.894067 ops/training.py:65 2019-01-17 01:50:33.893997: step 5544, loss = 0.69561 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:50:35.183030 ops/training.py:65 2019-01-17 01:50:35.182951: step 5545, loss = 0.70997 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:50:36.470961 ops/training.py:65 2019-01-17 01:50:36.470885: step 5546, loss = 0.68722 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:50:37.760584 ops/training.py:65 2019-01-17 01:50:37.760515: step 5547, loss = 0.68706 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:50:39.049061 ops/training.py:65 2019-01-17 01:50:39.048988: step 5548, loss = 0.68023 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:50:40.337335 ops/training.py:65 2019-01-17 01:50:40.337259: step 5549, loss = 0.68828 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:50:41.621791 ops/training.py:65 2019-01-17 01:50:41.621722: step 5550, loss = 0.70884 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:50:42.905325 ops/training.py:65 2019-01-17 01:50:42.905264: step 5551, loss = 0.68794 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:50:44.189242 ops/training.py:65 2019-01-17 01:50:44.189098: step 5552, loss = 0.72470 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:50:45.480638 ops/training.py:65 2019-01-17 01:50:45.480533: step 5553, loss = 0.67737 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:50:46.766825 ops/training.py:65 2019-01-17 01:50:46.766757: step 5554, loss = 0.66926 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:50:48.048067 ops/training.py:65 2019-01-17 01:50:48.047965: step 5555, loss = 0.71738 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:50:49.333201 ops/training.py:65 2019-01-17 01:50:49.333099: step 5556, loss = 0.64669 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:50:50.624930 ops/training.py:65 2019-01-17 01:50:50.624821: step 5557, loss = 0.72881 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:50:51.907051 ops/training.py:65 2019-01-17 01:50:51.906982: step 5558, loss = 0.69805 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:50:53.194877 ops/training.py:65 2019-01-17 01:50:53.194776: step 5559, loss = 0.73293 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:50:54.484470 ops/training.py:65 2019-01-17 01:50:54.484379: step 5560, loss = 0.69927 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:50:55.773421 ops/training.py:65 2019-01-17 01:50:55.773351: step 5561, loss = 0.73852 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:50:57.060631 ops/training.py:65 2019-01-17 01:50:57.060554: step 5562, loss = 0.74082 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:50:58.347875 ops/training.py:65 2019-01-17 01:50:58.347799: step 5563, loss = 0.74494 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:50:59.636283 ops/training.py:65 2019-01-17 01:50:59.636177: step 5564, loss = 0.72266 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:51:00.925468 ops/training.py:65 2019-01-17 01:51:00.925366: step 5565, loss = 0.68387 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:51:02.214079 ops/training.py:65 2019-01-17 01:51:02.214007: step 5566, loss = 0.70425 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:51:03.503268 ops/training.py:65 2019-01-17 01:51:03.503152: step 5567, loss = 0.71154 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:51:04.792513 ops/training.py:65 2019-01-17 01:51:04.792442: step 5568, loss = 0.70629 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:51:06.079806 ops/training.py:65 2019-01-17 01:51:06.079727: step 5569, loss = 0.69070 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:51:07.363734 ops/training.py:65 2019-01-17 01:51:07.363635: step 5570, loss = 0.70488 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:51:08.647571 ops/training.py:65 2019-01-17 01:51:08.647464: step 5571, loss = 0.65994 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:51:09.934244 ops/training.py:65 2019-01-17 01:51:09.934145: step 5572, loss = 0.69668 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:51:11.224695 ops/training.py:65 2019-01-17 01:51:11.224540: step 5573, loss = 0.68958 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:51:12.511409 ops/training.py:65 2019-01-17 01:51:12.511342: step 5574, loss = 0.68548 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:51:13.798743 ops/training.py:65 2019-01-17 01:51:13.798637: step 5575, loss = 0.67515 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:51:15.083176 ops/training.py:65 2019-01-17 01:51:15.083101: step 5576, loss = 0.67988 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:51:16.366277 ops/training.py:65 2019-01-17 01:51:16.366175: step 5577, loss = 0.66728 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:51:17.657668 ops/training.py:65 2019-01-17 01:51:17.657511: step 5578, loss = 0.66696 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:51:18.942148 ops/training.py:65 2019-01-17 01:51:18.942081: step 5579, loss = 0.73124 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:51:20.230009 ops/training.py:65 2019-01-17 01:51:20.229888: step 5580, loss = 0.63853 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 01:51:21.520220 ops/training.py:65 2019-01-17 01:51:21.520061: step 5581, loss = 0.67522 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:51:22.810177 ops/training.py:65 2019-01-17 01:51:22.810077: step 5582, loss = 0.65876 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:51:24.098294 ops/training.py:65 2019-01-17 01:51:24.098208: step 5583, loss = 0.69878 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:51:25.386174 ops/training.py:65 2019-01-17 01:51:25.386083: step 5584, loss = 0.73949 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:51:26.669310 ops/training.py:65 2019-01-17 01:51:26.669240: step 5585, loss = 0.65593 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:51:27.959902 ops/training.py:65 2019-01-17 01:51:27.959789: step 5586, loss = 0.71993 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:51:29.245348 ops/training.py:65 2019-01-17 01:51:29.245282: step 5587, loss = 0.69028 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:51:30.530529 ops/training.py:65 2019-01-17 01:51:30.530428: step 5588, loss = 0.71023 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:51:31.815199 ops/training.py:65 2019-01-17 01:51:31.815097: step 5589, loss = 0.76244 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:51:33.112456 ops/training.py:65 2019-01-17 01:51:33.112365: step 5590, loss = 0.66752 (24.7 examples/sec; 1.296 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 01:51:34.397791 ops/training.py:65 2019-01-17 01:51:34.397729: step 5591, loss = 0.70403 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:51:35.685310 ops/training.py:65 2019-01-17 01:51:35.685205: step 5592, loss = 0.68453 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:51:36.974551 ops/training.py:65 2019-01-17 01:51:36.974486: step 5593, loss = 0.69065 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:51:38.259464 ops/training.py:65 2019-01-17 01:51:38.259373: step 5594, loss = 0.71063 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:51:39.547524 ops/training.py:65 2019-01-17 01:51:39.547456: step 5595, loss = 0.65248 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:51:40.836529 ops/training.py:65 2019-01-17 01:51:40.836421: step 5596, loss = 0.74942 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:51:42.122451 ops/training.py:65 2019-01-17 01:51:42.122360: step 5597, loss = 0.68245 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:51:43.405714 ops/training.py:65 2019-01-17 01:51:43.405619: step 5598, loss = 0.72073 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:51:44.694855 ops/training.py:65 2019-01-17 01:51:44.694749: step 5599, loss = 0.66581 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:51:45.984013 ops/training.py:65 2019-01-17 01:51:45.983942: step 5600, loss = 0.70194 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:51:47.265020 ops/training.py:65 2019-01-17 01:51:47.264955: step 5601, loss = 0.68872 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:51:48.548812 ops/training.py:65 2019-01-17 01:51:48.548702: step 5602, loss = 0.66619 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:51:49.828672 ops/training.py:65 2019-01-17 01:51:49.828564: step 5603, loss = 0.73686 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:51:51.118003 ops/training.py:65 2019-01-17 01:51:51.117902: step 5604, loss = 0.60529 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 01:51:52.403386 ops/training.py:65 2019-01-17 01:51:52.403315: step 5605, loss = 0.70707 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:51:53.687891 ops/training.py:65 2019-01-17 01:51:53.687804: step 5606, loss = 0.61437 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 01:51:54.971706 ops/training.py:65 2019-01-17 01:51:54.971597: step 5607, loss = 0.71200 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:51:56.259571 ops/training.py:65 2019-01-17 01:51:56.259456: step 5608, loss = 0.66337 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:51:57.543667 ops/training.py:65 2019-01-17 01:51:57.543596: step 5609, loss = 0.73870 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:51:58.826841 ops/training.py:65 2019-01-17 01:51:58.826732: step 5610, loss = 0.78846 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:52:00.110205 ops/training.py:65 2019-01-17 01:52:00.110102: step 5611, loss = 0.72570 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:52:01.395705 ops/training.py:65 2019-01-17 01:52:01.395594: step 5612, loss = 0.73428 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:52:02.684155 ops/training.py:65 2019-01-17 01:52:02.684046: step 5613, loss = 0.71696 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:52:03.968100 ops/training.py:65 2019-01-17 01:52:03.968002: step 5614, loss = 0.66972 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:52:05.258017 ops/training.py:65 2019-01-17 01:52:05.257904: step 5615, loss = 0.67182 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:52:06.541972 ops/training.py:65 2019-01-17 01:52:06.541908: step 5616, loss = 0.71681 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:52:07.825094 ops/training.py:65 2019-01-17 01:52:07.824994: step 5617, loss = 0.66796 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:52:09.108888 ops/training.py:65 2019-01-17 01:52:09.108785: step 5618, loss = 0.72317 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:52:10.399071 ops/training.py:65 2019-01-17 01:52:10.398999: step 5619, loss = 0.70001 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:52:11.682513 ops/training.py:65 2019-01-17 01:52:11.682450: step 5620, loss = 0.74555 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:52:12.966148 ops/training.py:65 2019-01-17 01:52:12.966041: step 5621, loss = 0.68356 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:52:14.252547 ops/training.py:65 2019-01-17 01:52:14.252448: step 5622, loss = 0.72369 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:52:15.541587 ops/training.py:65 2019-01-17 01:52:15.541476: step 5623, loss = 0.73240 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:52:16.826746 ops/training.py:65 2019-01-17 01:52:16.826634: step 5624, loss = 0.70014 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:52:18.114041 ops/training.py:65 2019-01-17 01:52:18.113929: step 5625, loss = 0.70376 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:52:19.399188 ops/training.py:65 2019-01-17 01:52:19.399078: step 5626, loss = 0.69848 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:52:20.681098 ops/training.py:65 2019-01-17 01:52:20.680991: step 5627, loss = 0.69556 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:52:21.961417 ops/training.py:65 2019-01-17 01:52:21.961322: step 5628, loss = 0.67529 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:52:23.246964 ops/training.py:65 2019-01-17 01:52:23.246872: step 5629, loss = 0.71299 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:52:24.532229 ops/training.py:65 2019-01-17 01:52:24.532157: step 5630, loss = 0.68071 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:52:25.811397 ops/training.py:65 2019-01-17 01:52:25.811295: step 5631, loss = 0.73138 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:52:27.097359 ops/training.py:65 2019-01-17 01:52:27.097259: step 5632, loss = 0.67859 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:52:28.388102 ops/training.py:65 2019-01-17 01:52:28.387964: step 5633, loss = 0.67426 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:52:29.678563 ops/training.py:65 2019-01-17 01:52:29.678495: step 5634, loss = 0.66990 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:52:30.962318 ops/training.py:65 2019-01-17 01:52:30.962256: step 5635, loss = 0.71999 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:52:32.249133 ops/training.py:65 2019-01-17 01:52:32.249047: step 5636, loss = 0.73679 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:52:33.533317 ops/training.py:65 2019-01-17 01:52:33.533252: step 5637, loss = 0.71171 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:52:34.816986 ops/training.py:65 2019-01-17 01:52:34.816881: step 5638, loss = 0.70611 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:52:36.104398 ops/training.py:65 2019-01-17 01:52:36.104291: step 5639, loss = 0.68202 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:52:37.388386 ops/training.py:65 2019-01-17 01:52:37.388280: step 5640, loss = 0.65058 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:52:38.670385 ops/training.py:65 2019-01-17 01:52:38.670278: step 5641, loss = 0.72135 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:52:39.951925 ops/training.py:65 2019-01-17 01:52:39.951810: step 5642, loss = 0.69187 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:52:41.234971 ops/training.py:65 2019-01-17 01:52:41.234803: step 5643, loss = 0.73520 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:52:42.525952 ops/training.py:65 2019-01-17 01:52:42.525850: step 5644, loss = 0.75256 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:52:43.814436 ops/training.py:65 2019-01-17 01:52:43.814354: step 5645, loss = 0.69447 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:52:45.099080 ops/training.py:65 2019-01-17 01:52:45.099003: step 5646, loss = 0.70871 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:52:46.378958 ops/training.py:65 2019-01-17 01:52:46.378848: step 5647, loss = 0.72624 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:52:47.666593 ops/training.py:65 2019-01-17 01:52:47.666488: step 5648, loss = 0.70926 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:52:48.951609 ops/training.py:65 2019-01-17 01:52:48.951541: step 5649, loss = 0.66988 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:52:50.237725 ops/training.py:65 2019-01-17 01:52:50.237628: step 5650, loss = 0.73507 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:52:51.522418 ops/training.py:65 2019-01-17 01:52:51.522346: step 5651, loss = 0.74792 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:52:52.811187 ops/training.py:65 2019-01-17 01:52:52.811105: step 5652, loss = 0.65526 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:52:54.096047 ops/training.py:65 2019-01-17 01:52:54.095974: step 5653, loss = 0.75754 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:52:55.379773 ops/training.py:65 2019-01-17 01:52:55.379672: step 5654, loss = 0.71797 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:52:56.669757 ops/training.py:65 2019-01-17 01:52:56.669651: step 5655, loss = 0.68471 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:52:57.956934 ops/training.py:65 2019-01-17 01:52:57.956866: step 5656, loss = 0.71604 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:52:59.242579 ops/training.py:65 2019-01-17 01:52:59.242476: step 5657, loss = 0.71553 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:53:00.528856 ops/training.py:65 2019-01-17 01:53:00.528740: step 5658, loss = 0.75989 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:53:01.815547 ops/training.py:65 2019-01-17 01:53:01.815449: step 5659, loss = 0.75848 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:53:03.098212 ops/training.py:65 2019-01-17 01:53:03.098125: step 5660, loss = 0.72659 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:53:04.386945 ops/training.py:65 2019-01-17 01:53:04.386853: step 5661, loss = 0.74262 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:53:05.673076 ops/training.py:65 2019-01-17 01:53:05.672966: step 5662, loss = 0.73367 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:53:06.958556 ops/training.py:65 2019-01-17 01:53:06.958459: step 5663, loss = 0.71775 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:53:08.245635 ops/training.py:65 2019-01-17 01:53:08.245475: step 5664, loss = 0.68465 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:53:09.530866 ops/training.py:65 2019-01-17 01:53:09.530758: step 5665, loss = 0.70362 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:53:10.818377 ops/training.py:65 2019-01-17 01:53:10.818268: step 5666, loss = 0.72269 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:53:12.104891 ops/training.py:65 2019-01-17 01:53:12.104796: step 5667, loss = 0.71289 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:53:13.387960 ops/training.py:65 2019-01-17 01:53:13.387857: step 5668, loss = 0.67294 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:53:14.670196 ops/training.py:65 2019-01-17 01:53:14.670089: step 5669, loss = 0.65474 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:53:15.961127 ops/training.py:65 2019-01-17 01:53:15.961018: step 5670, loss = 0.74028 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:53:17.248456 ops/training.py:65 2019-01-17 01:53:17.248347: step 5671, loss = 0.77472 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:53:18.535965 ops/training.py:65 2019-01-17 01:53:18.535863: step 5672, loss = 0.71768 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:53:19.821574 ops/training.py:65 2019-01-17 01:53:19.821510: step 5673, loss = 0.66757 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:53:21.105286 ops/training.py:65 2019-01-17 01:53:21.105172: step 5674, loss = 0.67653 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:53:22.393072 ops/training.py:65 2019-01-17 01:53:22.392961: step 5675, loss = 0.71512 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:53:23.676817 ops/training.py:65 2019-01-17 01:53:23.676718: step 5676, loss = 0.70368 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:53:24.968058 ops/training.py:65 2019-01-17 01:53:24.967947: step 5677, loss = 0.72252 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:53:26.251672 ops/training.py:65 2019-01-17 01:53:26.251600: step 5678, loss = 0.66691 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:53:27.537494 ops/training.py:65 2019-01-17 01:53:27.537395: step 5679, loss = 0.75846 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:53:28.827966 ops/training.py:65 2019-01-17 01:53:28.827863: step 5680, loss = 0.67188 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:53:30.117643 ops/training.py:65 2019-01-17 01:53:30.117581: step 5681, loss = 0.68327 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:53:31.405552 ops/training.py:65 2019-01-17 01:53:31.405476: step 5682, loss = 0.66049 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:53:32.689980 ops/training.py:65 2019-01-17 01:53:32.689900: step 5683, loss = 0.71363 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:53:33.980083 ops/training.py:65 2019-01-17 01:53:33.980010: step 5684, loss = 0.71978 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:53:35.270265 ops/training.py:65 2019-01-17 01:53:35.270194: step 5685, loss = 0.73445 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:53:36.556377 ops/training.py:65 2019-01-17 01:53:36.556303: step 5686, loss = 0.69098 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:53:37.847551 ops/training.py:65 2019-01-17 01:53:37.847448: step 5687, loss = 0.65513 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:53:39.134159 ops/training.py:65 2019-01-17 01:53:39.134072: step 5688, loss = 0.68478 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:53:40.417917 ops/training.py:65 2019-01-17 01:53:40.417769: step 5689, loss = 0.70335 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:53:41.709617 ops/training.py:65 2019-01-17 01:53:41.709513: step 5690, loss = 0.70129 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:53:42.993858 ops/training.py:65 2019-01-17 01:53:42.993793: step 5691, loss = 0.66847 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:53:44.277535 ops/training.py:65 2019-01-17 01:53:44.277428: step 5692, loss = 0.72364 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:53:45.565313 ops/training.py:65 2019-01-17 01:53:45.565155: step 5693, loss = 0.65532 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:53:46.852083 ops/training.py:65 2019-01-17 01:53:46.851979: step 5694, loss = 0.77397 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:53:48.135845 ops/training.py:65 2019-01-17 01:53:48.135733: step 5695, loss = 0.70927 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:53:49.421539 ops/training.py:65 2019-01-17 01:53:49.421394: step 5696, loss = 0.76925 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:53:50.703493 ops/training.py:65 2019-01-17 01:53:50.703394: step 5697, loss = 0.72419 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:53:51.983819 ops/training.py:65 2019-01-17 01:53:51.983712: step 5698, loss = 0.72029 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:53:53.273225 ops/training.py:65 2019-01-17 01:53:53.273093: step 5699, loss = 0.69095 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:53:54.556045 ops/training.py:65 2019-01-17 01:53:54.555968: step 5700, loss = 0.70656 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:53:55.835279 ops/training.py:65 2019-01-17 01:53:55.835175: step 5701, loss = 0.71026 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:53:57.120980 ops/training.py:65 2019-01-17 01:53:57.120881: step 5702, loss = 0.72333 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:53:58.405117 ops/training.py:65 2019-01-17 01:53:58.405016: step 5703, loss = 0.68739 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:53:59.692812 ops/training.py:65 2019-01-17 01:53:59.692701: step 5704, loss = 0.66947 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:54:00.979803 ops/training.py:65 2019-01-17 01:54:00.979701: step 5705, loss = 0.72496 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:54:02.266170 ops/training.py:65 2019-01-17 01:54:02.266059: step 5706, loss = 0.68221 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:54:03.551409 ops/training.py:65 2019-01-17 01:54:03.551299: step 5707, loss = 0.69863 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:54:04.837429 ops/training.py:65 2019-01-17 01:54:04.837270: step 5708, loss = 0.65503 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:54:06.124549 ops/training.py:65 2019-01-17 01:54:06.124434: step 5709, loss = 0.69047 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:54:07.408608 ops/training.py:65 2019-01-17 01:54:07.408458: step 5710, loss = 0.67912 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:54:08.694551 ops/training.py:65 2019-01-17 01:54:08.694454: step 5711, loss = 0.70445 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:54:09.981753 ops/training.py:65 2019-01-17 01:54:09.981647: step 5712, loss = 0.70913 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:54:11.268158 ops/training.py:65 2019-01-17 01:54:11.268052: step 5713, loss = 0.68584 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:54:12.552864 ops/training.py:65 2019-01-17 01:54:12.552764: step 5714, loss = 0.69696 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:54:13.837624 ops/training.py:65 2019-01-17 01:54:13.837526: step 5715, loss = 0.67782 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:54:15.127052 ops/training.py:65 2019-01-17 01:54:15.126941: step 5716, loss = 0.70695 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:54:16.410394 ops/training.py:65 2019-01-17 01:54:16.410325: step 5717, loss = 0.69291 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:54:17.692816 ops/training.py:65 2019-01-17 01:54:17.692706: step 5718, loss = 0.68193 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:54:18.978196 ops/training.py:65 2019-01-17 01:54:18.978048: step 5719, loss = 0.69950 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:54:20.261359 ops/training.py:65 2019-01-17 01:54:20.261263: step 5720, loss = 0.71412 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:54:21.548279 ops/training.py:65 2019-01-17 01:54:21.548140: step 5721, loss = 0.70557 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:54:22.833353 ops/training.py:65 2019-01-17 01:54:22.833247: step 5722, loss = 0.67551 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:54:24.117098 ops/training.py:65 2019-01-17 01:54:24.117011: step 5723, loss = 0.68083 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:54:25.401822 ops/training.py:65 2019-01-17 01:54:25.401681: step 5724, loss = 0.70842 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:54:26.689093 ops/training.py:65 2019-01-17 01:54:26.688989: step 5725, loss = 0.71511 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:54:27.977151 ops/training.py:65 2019-01-17 01:54:27.977045: step 5726, loss = 0.69126 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:54:29.264989 ops/training.py:65 2019-01-17 01:54:29.264919: step 5727, loss = 0.71258 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:54:30.558122 ops/training.py:65 2019-01-17 01:54:30.558047: step 5728, loss = 0.65678 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:54:31.846228 ops/training.py:65 2019-01-17 01:54:31.846155: step 5729, loss = 0.68543 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:54:33.130020 ops/training.py:65 2019-01-17 01:54:33.129920: step 5730, loss = 0.73232 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:54:34.415689 ops/training.py:65 2019-01-17 01:54:34.415574: step 5731, loss = 0.68529 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:54:35.702207 ops/training.py:65 2019-01-17 01:54:35.702092: step 5732, loss = 0.69695 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:54:36.985428 ops/training.py:65 2019-01-17 01:54:36.985326: step 5733, loss = 0.71561 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:54:38.272542 ops/training.py:65 2019-01-17 01:54:38.272427: step 5734, loss = 0.70359 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:54:39.558288 ops/training.py:65 2019-01-17 01:54:39.558184: step 5735, loss = 0.72358 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:54:40.848467 ops/training.py:65 2019-01-17 01:54:40.848355: step 5736, loss = 0.66444 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:54:42.138056 ops/training.py:65 2019-01-17 01:54:42.137971: step 5737, loss = 0.72742 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:54:43.422560 ops/training.py:65 2019-01-17 01:54:43.422483: step 5738, loss = 0.71616 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:54:44.706809 ops/training.py:65 2019-01-17 01:54:44.706708: step 5739, loss = 0.67479 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:54:45.996294 ops/training.py:65 2019-01-17 01:54:45.996177: step 5740, loss = 0.68086 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:54:47.282566 ops/training.py:65 2019-01-17 01:54:47.282493: step 5741, loss = 0.67253 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:54:48.562656 ops/training.py:65 2019-01-17 01:54:48.562551: step 5742, loss = 0.68208 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:54:49.843340 ops/training.py:65 2019-01-17 01:54:49.843231: step 5743, loss = 0.66298 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 01:54:51.133265 ops/training.py:65 2019-01-17 01:54:51.133164: step 5744, loss = 0.67986 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:54:52.421769 ops/training.py:65 2019-01-17 01:54:52.421696: step 5745, loss = 0.68952 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:54:53.706818 ops/training.py:65 2019-01-17 01:54:53.706728: step 5746, loss = 0.68385 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:54:55.003378 ops/training.py:65 2019-01-17 01:54:55.003278: step 5747, loss = 0.73242 (24.7 examples/sec; 1.295 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:54:56.293404 ops/training.py:65 2019-01-17 01:54:56.293330: step 5748, loss = 0.70835 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:54:57.583249 ops/training.py:65 2019-01-17 01:54:57.583173: step 5749, loss = 0.67596 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:54:58.867646 ops/training.py:65 2019-01-17 01:54:58.867581: step 5750, loss = 0.68629 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:55:00.155088 ops/training.py:65 2019-01-17 01:55:00.154989: step 5751, loss = 0.65919 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:55:01.443408 ops/training.py:65 2019-01-17 01:55:01.443326: step 5752, loss = 0.65819 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:55:02.728563 ops/training.py:65 2019-01-17 01:55:02.728475: step 5753, loss = 0.67849 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:55:04.018737 ops/training.py:65 2019-01-17 01:55:04.018597: step 5754, loss = 0.69554 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:55:05.306592 ops/training.py:65 2019-01-17 01:55:05.306500: step 5755, loss = 0.70718 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:55:06.589966 ops/training.py:65 2019-01-17 01:55:06.589899: step 5756, loss = 0.68696 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:55:07.876522 ops/training.py:65 2019-01-17 01:55:07.876421: step 5757, loss = 0.68997 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:55:09.166069 ops/training.py:65 2019-01-17 01:55:09.165998: step 5758, loss = 0.70153 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:55:10.449146 ops/training.py:65 2019-01-17 01:55:10.449042: step 5759, loss = 0.76840 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:55:11.733460 ops/training.py:65 2019-01-17 01:55:11.733368: step 5760, loss = 0.73017 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:55:13.024036 ops/training.py:65 2019-01-17 01:55:13.023940: step 5761, loss = 0.72828 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:55:14.312753 ops/training.py:65 2019-01-17 01:55:14.312681: step 5762, loss = 0.67919 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:55:15.598262 ops/training.py:65 2019-01-17 01:55:15.598173: step 5763, loss = 0.67809 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:55:16.879613 ops/training.py:65 2019-01-17 01:55:16.879504: step 5764, loss = 0.67843 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:55:18.164566 ops/training.py:65 2019-01-17 01:55:18.164466: step 5765, loss = 0.68133 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:55:19.456697 ops/training.py:65 2019-01-17 01:55:19.456584: step 5766, loss = 0.71387 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:55:20.741759 ops/training.py:65 2019-01-17 01:55:20.741692: step 5767, loss = 0.69911 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:55:22.026712 ops/training.py:65 2019-01-17 01:55:22.026615: step 5768, loss = 0.71829 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:55:23.314003 ops/training.py:65 2019-01-17 01:55:23.313894: step 5769, loss = 0.68362 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:55:24.598446 ops/training.py:65 2019-01-17 01:55:24.598338: step 5770, loss = 0.71380 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:55:25.885967 ops/training.py:65 2019-01-17 01:55:25.885860: step 5771, loss = 0.70962 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:55:27.169101 ops/training.py:65 2019-01-17 01:55:27.168962: step 5772, loss = 0.66899 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:55:28.453419 ops/training.py:65 2019-01-17 01:55:28.453310: step 5773, loss = 0.62855 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 01:55:29.740422 ops/training.py:65 2019-01-17 01:55:29.740321: step 5774, loss = 0.72449 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:55:31.029056 ops/training.py:65 2019-01-17 01:55:31.028955: step 5775, loss = 0.67509 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:55:32.314310 ops/training.py:65 2019-01-17 01:55:32.314208: step 5776, loss = 0.68981 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:55:33.605874 ops/training.py:65 2019-01-17 01:55:33.605773: step 5777, loss = 0.69839 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:55:34.889791 ops/training.py:65 2019-01-17 01:55:34.889700: step 5778, loss = 0.68835 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:55:36.173841 ops/training.py:65 2019-01-17 01:55:36.173741: step 5779, loss = 0.69445 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:55:37.460552 ops/training.py:65 2019-01-17 01:55:37.460443: step 5780, loss = 0.69578 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:55:38.745510 ops/training.py:65 2019-01-17 01:55:38.745408: step 5781, loss = 0.67759 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:55:40.035446 ops/training.py:65 2019-01-17 01:55:40.035342: step 5782, loss = 0.66531 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:55:41.322584 ops/training.py:65 2019-01-17 01:55:41.322473: step 5783, loss = 0.69289 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:55:42.612297 ops/training.py:65 2019-01-17 01:55:42.612194: step 5784, loss = 0.72522 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:55:43.897091 ops/training.py:65 2019-01-17 01:55:43.897002: step 5785, loss = 0.73598 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:55:45.185096 ops/training.py:65 2019-01-17 01:55:45.184965: step 5786, loss = 0.71477 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:55:46.474494 ops/training.py:65 2019-01-17 01:55:46.474375: step 5787, loss = 0.72136 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:55:47.758295 ops/training.py:65 2019-01-17 01:55:47.758205: step 5788, loss = 0.74711 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:55:49.041860 ops/training.py:65 2019-01-17 01:55:49.041751: step 5789, loss = 0.68926 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:55:50.325825 ops/training.py:65 2019-01-17 01:55:50.325719: step 5790, loss = 0.72730 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:55:51.607695 ops/training.py:65 2019-01-17 01:55:51.607602: step 5791, loss = 0.66724 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:55:52.891455 ops/training.py:65 2019-01-17 01:55:52.891349: step 5792, loss = 0.65592 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:55:54.178075 ops/training.py:65 2019-01-17 01:55:54.177969: step 5793, loss = 0.74521 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:55:55.464124 ops/training.py:65 2019-01-17 01:55:55.464031: step 5794, loss = 0.71714 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:55:56.754511 ops/training.py:65 2019-01-17 01:55:56.754410: step 5795, loss = 0.67981 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:55:58.045205 ops/training.py:65 2019-01-17 01:55:58.045136: step 5796, loss = 0.67662 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:55:59.330133 ops/training.py:65 2019-01-17 01:55:59.330037: step 5797, loss = 0.68732 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:56:00.612070 ops/training.py:65 2019-01-17 01:56:00.611979: step 5798, loss = 0.71302 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:56:01.894443 ops/training.py:65 2019-01-17 01:56:01.894401: step 5799, loss = 0.70091 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:56:03.179228 ops/training.py:65 2019-01-17 01:56:03.179128: step 5800, loss = 0.71804 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:56:04.463827 ops/training.py:65 2019-01-17 01:56:04.463722: step 5801, loss = 0.70429 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:56:05.748393 ops/training.py:65 2019-01-17 01:56:05.748300: step 5802, loss = 0.68494 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:56:07.033517 ops/training.py:65 2019-01-17 01:56:07.033421: step 5803, loss = 0.71807 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:56:08.316230 ops/training.py:65 2019-01-17 01:56:08.316132: step 5804, loss = 0.67865 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:56:09.607166 ops/training.py:65 2019-01-17 01:56:09.607064: step 5805, loss = 0.71520 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:56:10.892410 ops/training.py:65 2019-01-17 01:56:10.892347: step 5806, loss = 0.69729 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:56:12.178108 ops/training.py:65 2019-01-17 01:56:12.178007: step 5807, loss = 0.69619 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:56:13.466055 ops/training.py:65 2019-01-17 01:56:13.465965: step 5808, loss = 0.67192 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:56:14.748149 ops/training.py:65 2019-01-17 01:56:14.748048: step 5809, loss = 0.67670 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:56:16.033233 ops/training.py:65 2019-01-17 01:56:16.033118: step 5810, loss = 0.74624 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:56:17.318436 ops/training.py:65 2019-01-17 01:56:17.318324: step 5811, loss = 0.67312 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:56:18.604441 ops/training.py:65 2019-01-17 01:56:18.604336: step 5812, loss = 0.70583 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:56:19.897201 ops/training.py:65 2019-01-17 01:56:19.897089: step 5813, loss = 0.66700 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 01:56:21.182802 ops/training.py:65 2019-01-17 01:56:21.182690: step 5814, loss = 0.70147 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:56:22.467205 ops/training.py:65 2019-01-17 01:56:22.467094: step 5815, loss = 0.65959 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:56:23.752998 ops/training.py:65 2019-01-17 01:56:23.752905: step 5816, loss = 0.66449 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:56:25.039736 ops/training.py:65 2019-01-17 01:56:25.039593: step 5817, loss = 0.72794 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:56:26.326027 ops/training.py:65 2019-01-17 01:56:26.325922: step 5818, loss = 0.67116 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:56:27.608086 ops/training.py:65 2019-01-17 01:56:27.608010: step 5819, loss = 0.71535 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:56:28.890375 ops/training.py:65 2019-01-17 01:56:28.890271: step 5820, loss = 0.67289 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:56:30.175340 ops/training.py:65 2019-01-17 01:56:30.175226: step 5821, loss = 0.72126 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:56:31.459334 ops/training.py:65 2019-01-17 01:56:31.459224: step 5822, loss = 0.70404 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:56:32.744018 ops/training.py:65 2019-01-17 01:56:32.743917: step 5823, loss = 0.68660 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:56:34.035113 ops/training.py:65 2019-01-17 01:56:34.034963: step 5824, loss = 0.71259 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:56:35.324783 ops/training.py:65 2019-01-17 01:56:35.324712: step 5825, loss = 0.66467 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:56:36.607784 ops/training.py:65 2019-01-17 01:56:36.607714: step 5826, loss = 0.68815 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:56:37.890818 ops/training.py:65 2019-01-17 01:56:37.890709: step 5827, loss = 0.71597 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:56:39.174963 ops/training.py:65 2019-01-17 01:56:39.174855: step 5828, loss = 0.68614 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:56:40.467194 ops/training.py:65 2019-01-17 01:56:40.467032: step 5829, loss = 0.70657 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:56:41.748666 ops/training.py:65 2019-01-17 01:56:41.748566: step 5830, loss = 0.74446 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:56:43.038309 ops/training.py:65 2019-01-17 01:56:43.038212: step 5831, loss = 0.69580 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:56:44.323190 ops/training.py:65 2019-01-17 01:56:44.323096: step 5832, loss = 0.69123 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:56:45.608043 ops/training.py:65 2019-01-17 01:56:45.607933: step 5833, loss = 0.68950 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:56:46.897170 ops/training.py:65 2019-01-17 01:56:46.897011: step 5834, loss = 0.72513 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:56:48.183493 ops/training.py:65 2019-01-17 01:56:48.183428: step 5835, loss = 0.75967 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:56:49.464968 ops/training.py:65 2019-01-17 01:56:49.464855: step 5836, loss = 0.70834 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:56:50.756408 ops/training.py:65 2019-01-17 01:56:50.756302: step 5837, loss = 0.65000 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:56:52.040486 ops/training.py:65 2019-01-17 01:56:52.040396: step 5838, loss = 0.68507 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:56:53.327420 ops/training.py:65 2019-01-17 01:56:53.327315: step 5839, loss = 0.68477 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:56:54.611742 ops/training.py:65 2019-01-17 01:56:54.611640: step 5840, loss = 0.67146 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:56:55.899271 ops/training.py:65 2019-01-17 01:56:55.899164: step 5841, loss = 0.69772 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:56:57.183851 ops/training.py:65 2019-01-17 01:56:57.183749: step 5842, loss = 0.70191 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:56:58.466029 ops/training.py:65 2019-01-17 01:56:58.465921: step 5843, loss = 0.69795 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:56:59.754337 ops/training.py:65 2019-01-17 01:56:59.754242: step 5844, loss = 0.65866 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:57:01.040313 ops/training.py:65 2019-01-17 01:57:01.040254: step 5845, loss = 0.67229 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:57:02.324406 ops/training.py:65 2019-01-17 01:57:02.324323: step 5846, loss = 0.67182 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:57:03.612692 ops/training.py:65 2019-01-17 01:57:03.612599: step 5847, loss = 0.69419 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:57:04.893496 ops/training.py:65 2019-01-17 01:57:04.893402: step 5848, loss = 0.71567 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:57:06.182638 ops/training.py:65 2019-01-17 01:57:06.182526: step 5849, loss = 0.68371 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:57:07.469684 ops/training.py:65 2019-01-17 01:57:07.469615: step 5850, loss = 0.67817 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:57:08.756170 ops/training.py:65 2019-01-17 01:57:08.756058: step 5851, loss = 0.69929 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:57:10.042040 ops/training.py:65 2019-01-17 01:57:10.041971: step 5852, loss = 0.65044 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:57:11.326927 ops/training.py:65 2019-01-17 01:57:11.326815: step 5853, loss = 0.70906 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:57:12.612061 ops/training.py:65 2019-01-17 01:57:12.611965: step 5854, loss = 0.71737 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:57:13.899600 ops/training.py:65 2019-01-17 01:57:13.899490: step 5855, loss = 0.68863 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:57:15.183245 ops/training.py:65 2019-01-17 01:57:15.183145: step 5856, loss = 0.70865 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:57:16.462233 ops/training.py:65 2019-01-17 01:57:16.462120: step 5857, loss = 0.66869 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:57:17.748944 ops/training.py:65 2019-01-17 01:57:17.748839: step 5858, loss = 0.66043 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:57:19.037900 ops/training.py:65 2019-01-17 01:57:19.037790: step 5859, loss = 0.68203 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:57:20.323195 ops/training.py:65 2019-01-17 01:57:20.323092: step 5860, loss = 0.74602 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:57:21.607893 ops/training.py:65 2019-01-17 01:57:21.607796: step 5861, loss = 0.71916 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:57:22.894575 ops/training.py:65 2019-01-17 01:57:22.894475: step 5862, loss = 0.66577 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:57:24.176240 ops/training.py:65 2019-01-17 01:57:24.176127: step 5863, loss = 0.72683 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:57:25.461094 ops/training.py:65 2019-01-17 01:57:25.460982: step 5864, loss = 0.70993 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:57:26.747309 ops/training.py:65 2019-01-17 01:57:26.747206: step 5865, loss = 0.72564 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:57:28.032603 ops/training.py:65 2019-01-17 01:57:28.032518: step 5866, loss = 0.67710 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:57:29.320417 ops/training.py:65 2019-01-17 01:57:29.320313: step 5867, loss = 0.64726 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 01:57:30.606391 ops/training.py:65 2019-01-17 01:57:30.606290: step 5868, loss = 0.72644 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:57:31.893245 ops/training.py:65 2019-01-17 01:57:31.893139: step 5869, loss = 0.71482 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:57:33.179409 ops/training.py:65 2019-01-17 01:57:33.179307: step 5870, loss = 0.68283 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:57:34.463434 ops/training.py:65 2019-01-17 01:57:34.463330: step 5871, loss = 0.70232 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:57:35.754576 ops/training.py:65 2019-01-17 01:57:35.754484: step 5872, loss = 0.76577 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:57:37.040075 ops/training.py:65 2019-01-17 01:57:37.040016: step 5873, loss = 0.74597 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:57:38.323371 ops/training.py:65 2019-01-17 01:57:38.323271: step 5874, loss = 0.67689 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:57:39.614586 ops/training.py:65 2019-01-17 01:57:39.614477: step 5875, loss = 0.68568 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:57:40.901042 ops/training.py:65 2019-01-17 01:57:40.900980: step 5876, loss = 0.68019 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:57:42.186299 ops/training.py:65 2019-01-17 01:57:42.186203: step 5877, loss = 0.73910 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:57:43.472630 ops/training.py:65 2019-01-17 01:57:43.472567: step 5878, loss = 0.67211 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:57:44.762226 ops/training.py:65 2019-01-17 01:57:44.762126: step 5879, loss = 0.71262 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:57:46.051991 ops/training.py:65 2019-01-17 01:57:46.051923: step 5880, loss = 0.72179 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:57:47.341015 ops/training.py:65 2019-01-17 01:57:47.340955: step 5881, loss = 0.67694 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:57:48.628311 ops/training.py:65 2019-01-17 01:57:48.628244: step 5882, loss = 0.75169 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:57:49.911321 ops/training.py:65 2019-01-17 01:57:49.911255: step 5883, loss = 0.68980 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:57:51.196290 ops/training.py:65 2019-01-17 01:57:51.196185: step 5884, loss = 0.71497 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:57:52.483152 ops/training.py:65 2019-01-17 01:57:52.483040: step 5885, loss = 0.70571 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:57:53.765971 ops/training.py:65 2019-01-17 01:57:53.765888: step 5886, loss = 0.69335 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:57:55.050527 ops/training.py:65 2019-01-17 01:57:55.050419: step 5887, loss = 0.72665 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:57:56.335560 ops/training.py:65 2019-01-17 01:57:56.335462: step 5888, loss = 0.67522 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:57:57.623028 ops/training.py:65 2019-01-17 01:57:57.622926: step 5889, loss = 0.70115 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:57:58.905600 ops/training.py:65 2019-01-17 01:57:58.905498: step 5890, loss = 0.66030 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:58:00.192688 ops/training.py:65 2019-01-17 01:58:00.192586: step 5891, loss = 0.68885 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:58:01.478040 ops/training.py:65 2019-01-17 01:58:01.477938: step 5892, loss = 0.65538 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:58:02.766293 ops/training.py:65 2019-01-17 01:58:02.766187: step 5893, loss = 0.72155 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:58:04.051988 ops/training.py:65 2019-01-17 01:58:04.051891: step 5894, loss = 0.65851 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:58:05.337801 ops/training.py:65 2019-01-17 01:58:05.337691: step 5895, loss = 0.72618 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:58:06.621417 ops/training.py:65 2019-01-17 01:58:06.621324: step 5896, loss = 0.70482 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:58:07.906121 ops/training.py:65 2019-01-17 01:58:07.906010: step 5897, loss = 0.74750 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:58:09.198655 ops/training.py:65 2019-01-17 01:58:09.198546: step 5898, loss = 0.68020 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:58:10.483089 ops/training.py:65 2019-01-17 01:58:10.483015: step 5899, loss = 0.68528 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:58:11.764502 ops/training.py:65 2019-01-17 01:58:11.764408: step 5900, loss = 0.68096 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:58:13.048388 ops/training.py:65 2019-01-17 01:58:13.048299: step 5901, loss = 0.64243 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:58:14.329581 ops/training.py:65 2019-01-17 01:58:14.329529: step 5902, loss = 0.73971 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:58:15.614939 ops/training.py:65 2019-01-17 01:58:15.614869: step 5903, loss = 0.71688 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:58:16.894113 ops/training.py:65 2019-01-17 01:58:16.894078: step 5904, loss = 0.69159 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:58:18.174261 ops/training.py:65 2019-01-17 01:58:18.174224: step 5905, loss = 0.70280 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:58:19.462540 ops/training.py:65 2019-01-17 01:58:19.462506: step 5906, loss = 0.70010 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:58:20.744357 ops/training.py:65 2019-01-17 01:58:20.744316: step 5907, loss = 0.68149 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:58:22.027368 ops/training.py:65 2019-01-17 01:58:22.027324: step 5908, loss = 0.68366 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:58:23.306893 ops/training.py:65 2019-01-17 01:58:23.306832: step 5909, loss = 0.70923 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:58:24.590368 ops/training.py:65 2019-01-17 01:58:24.590267: step 5910, loss = 0.70587 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:58:25.874620 ops/training.py:65 2019-01-17 01:58:25.874507: step 5911, loss = 0.70396 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:58:27.156497 ops/training.py:65 2019-01-17 01:58:27.156422: step 5912, loss = 0.69399 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:58:28.451603 ops/training.py:65 2019-01-17 01:58:28.451496: step 5913, loss = 0.65856 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 01:58:29.735006 ops/training.py:65 2019-01-17 01:58:29.734921: step 5914, loss = 0.69619 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:58:31.018064 ops/training.py:65 2019-01-17 01:58:31.017966: step 5915, loss = 0.68554 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:58:32.299618 ops/training.py:65 2019-01-17 01:58:32.299525: step 5916, loss = 0.66505 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 01:58:33.580550 ops/training.py:65 2019-01-17 01:58:33.580455: step 5917, loss = 0.68667 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:58:34.859683 ops/training.py:65 2019-01-17 01:58:34.859592: step 5918, loss = 0.69168 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:58:36.146033 ops/training.py:65 2019-01-17 01:58:36.145924: step 5919, loss = 0.69989 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:58:37.428781 ops/training.py:65 2019-01-17 01:58:37.428676: step 5920, loss = 0.74947 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:58:38.711141 ops/training.py:65 2019-01-17 01:58:38.711017: step 5921, loss = 0.75218 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:58:39.987968 ops/training.py:65 2019-01-17 01:58:39.987875: step 5922, loss = 0.63379 (25.1 examples/sec; 1.275 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 01:58:41.274061 ops/training.py:65 2019-01-17 01:58:41.273962: step 5923, loss = 0.69274 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:58:42.562740 ops/training.py:65 2019-01-17 01:58:42.562625: step 5924, loss = 0.68344 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:58:43.847490 ops/training.py:65 2019-01-17 01:58:43.847428: step 5925, loss = 0.72228 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:58:45.133939 ops/training.py:65 2019-01-17 01:58:45.133829: step 5926, loss = 0.69893 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:58:46.420463 ops/training.py:65 2019-01-17 01:58:46.420319: step 5927, loss = 0.71269 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:58:47.707520 ops/training.py:65 2019-01-17 01:58:47.707416: step 5928, loss = 0.74285 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:58:48.992289 ops/training.py:65 2019-01-17 01:58:48.992178: step 5929, loss = 0.73299 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:58:50.277946 ops/training.py:65 2019-01-17 01:58:50.277832: step 5930, loss = 0.69887 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:58:51.557673 ops/training.py:65 2019-01-17 01:58:51.557575: step 5931, loss = 0.70772 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:58:52.839989 ops/training.py:65 2019-01-17 01:58:52.839834: step 5932, loss = 0.67274 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:58:54.129325 ops/training.py:65 2019-01-17 01:58:54.129178: step 5933, loss = 0.67376 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:58:55.415939 ops/training.py:65 2019-01-17 01:58:55.415863: step 5934, loss = 0.67587 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:58:56.704383 ops/training.py:65 2019-01-17 01:58:56.704275: step 5935, loss = 0.68806 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:58:57.995376 ops/training.py:65 2019-01-17 01:58:57.995277: step 5936, loss = 0.76588 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:58:59.281953 ops/training.py:65 2019-01-17 01:58:59.281882: step 5937, loss = 0.67920 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:59:00.568487 ops/training.py:65 2019-01-17 01:59:00.568392: step 5938, loss = 0.78085 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:59:01.854521 ops/training.py:65 2019-01-17 01:59:01.854418: step 5939, loss = 0.65461 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:59:03.137011 ops/training.py:65 2019-01-17 01:59:03.136916: step 5940, loss = 0.69857 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:59:04.426851 ops/training.py:65 2019-01-17 01:59:04.426757: step 5941, loss = 0.74494 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:59:05.712803 ops/training.py:65 2019-01-17 01:59:05.712735: step 5942, loss = 0.69500 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:59:06.994780 ops/training.py:65 2019-01-17 01:59:06.994674: step 5943, loss = 0.71164 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:59:08.284970 ops/training.py:65 2019-01-17 01:59:08.284814: step 5944, loss = 0.77350 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:59:09.574039 ops/training.py:65 2019-01-17 01:59:09.573932: step 5945, loss = 0.71483 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:59:10.857964 ops/training.py:65 2019-01-17 01:59:10.857889: step 5946, loss = 0.71363 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:59:12.137352 ops/training.py:65 2019-01-17 01:59:12.137246: step 5947, loss = 0.70621 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:59:13.424226 ops/training.py:65 2019-01-17 01:59:13.424122: step 5948, loss = 0.68849 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:59:14.709819 ops/training.py:65 2019-01-17 01:59:14.709749: step 5949, loss = 0.75486 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:59:16.002036 ops/training.py:65 2019-01-17 01:59:16.001931: step 5950, loss = 0.78308 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:59:17.287314 ops/training.py:65 2019-01-17 01:59:17.287203: step 5951, loss = 0.70877 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:59:18.572434 ops/training.py:65 2019-01-17 01:59:18.572351: step 5952, loss = 0.70524 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:59:19.852384 ops/training.py:65 2019-01-17 01:59:19.852281: step 5953, loss = 0.67840 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:59:21.138373 ops/training.py:65 2019-01-17 01:59:21.138272: step 5954, loss = 0.64057 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:59:22.422992 ops/training.py:65 2019-01-17 01:59:22.422884: step 5955, loss = 0.63269 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:59:23.707469 ops/training.py:65 2019-01-17 01:59:23.707361: step 5956, loss = 0.67140 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:59:24.987728 ops/training.py:65 2019-01-17 01:59:24.987626: step 5957, loss = 0.70637 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:59:26.274235 ops/training.py:65 2019-01-17 01:59:26.274134: step 5958, loss = 0.74464 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 01:59:27.560272 ops/training.py:65 2019-01-17 01:59:27.560183: step 5959, loss = 0.71393 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:59:28.844613 ops/training.py:65 2019-01-17 01:59:28.844512: step 5960, loss = 0.69913 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:59:30.130992 ops/training.py:65 2019-01-17 01:59:30.130887: step 5961, loss = 0.67095 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 01:59:31.419246 ops/training.py:65 2019-01-17 01:59:31.419138: step 5962, loss = 0.72335 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 01:59:32.707201 ops/training.py:65 2019-01-17 01:59:32.707094: step 5963, loss = 0.67308 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:59:33.990514 ops/training.py:65 2019-01-17 01:59:33.990408: step 5964, loss = 0.71890 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 01:59:35.275075 ops/training.py:65 2019-01-17 01:59:35.274964: step 5965, loss = 0.69005 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:59:36.562166 ops/training.py:65 2019-01-17 01:59:36.562053: step 5966, loss = 0.71799 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:59:37.847500 ops/training.py:65 2019-01-17 01:59:37.847399: step 5967, loss = 0.68454 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 01:59:39.131886 ops/training.py:65 2019-01-17 01:59:39.131784: step 5968, loss = 0.70781 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:59:40.417803 ops/training.py:65 2019-01-17 01:59:40.417702: step 5969, loss = 0.66325 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 01:59:41.699977 ops/training.py:65 2019-01-17 01:59:41.699866: step 5970, loss = 0.67440 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 01:59:42.984286 ops/training.py:65 2019-01-17 01:59:42.984198: step 5971, loss = 0.70118 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:59:44.264625 ops/training.py:65 2019-01-17 01:59:44.264543: step 5972, loss = 0.70257 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 01:59:45.550176 ops/training.py:65 2019-01-17 01:59:45.550070: step 5973, loss = 0.69760 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:59:46.842011 ops/training.py:65 2019-01-17 01:59:46.841859: step 5974, loss = 0.71904 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:59:48.127887 ops/training.py:65 2019-01-17 01:59:48.127824: step 5975, loss = 0.69420 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:59:49.416856 ops/training.py:65 2019-01-17 01:59:49.416716: step 5976, loss = 0.66506 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 01:59:50.702616 ops/training.py:65 2019-01-17 01:59:50.702546: step 5977, loss = 0.69941 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:59:51.988272 ops/training.py:65 2019-01-17 01:59:51.988191: step 5978, loss = 0.69830 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:59:53.274364 ops/training.py:65 2019-01-17 01:59:53.274299: step 5979, loss = 0.70584 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 01:59:54.556743 ops/training.py:65 2019-01-17 01:59:54.556611: step 5980, loss = 0.71251 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 01:59:55.842721 ops/training.py:65 2019-01-17 01:59:55.842614: step 5981, loss = 0.68884 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:59:57.128358 ops/training.py:65 2019-01-17 01:59:57.128286: step 5982, loss = 0.68780 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 01:59:58.413519 ops/training.py:65 2019-01-17 01:59:58.413410: step 5983, loss = 0.69436 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 01:59:59.700232 ops/training.py:65 2019-01-17 01:59:59.700125: step 5984, loss = 0.69992 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:00:00.990876 ops/training.py:65 2019-01-17 02:00:00.990771: step 5985, loss = 0.69790 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:00:02.278680 ops/training.py:65 2019-01-17 02:00:02.278581: step 5986, loss = 0.66894 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:00:03.565307 ops/training.py:65 2019-01-17 02:00:03.565202: step 5987, loss = 0.67052 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:00:04.848316 ops/training.py:65 2019-01-17 02:00:04.848213: step 5988, loss = 0.66414 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:00:06.139409 ops/training.py:65 2019-01-17 02:00:06.139306: step 5989, loss = 0.69388 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:00:07.425245 ops/training.py:65 2019-01-17 02:00:07.425182: step 5990, loss = 0.69000 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:00:08.711695 ops/training.py:65 2019-01-17 02:00:08.711589: step 5991, loss = 0.71224 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:00:09.997708 ops/training.py:65 2019-01-17 02:00:09.997603: step 5992, loss = 0.72238 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:00:11.282022 ops/training.py:65 2019-01-17 02:00:11.281921: step 5993, loss = 0.69214 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:00:12.567157 ops/training.py:65 2019-01-17 02:00:12.567059: step 5994, loss = 0.69158 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:00:13.854752 ops/training.py:65 2019-01-17 02:00:13.854644: step 5995, loss = 0.71497 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:00:15.135614 ops/training.py:65 2019-01-17 02:00:15.135524: step 5996, loss = 0.66761 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:00:16.425423 ops/training.py:65 2019-01-17 02:00:16.425316: step 5997, loss = 0.70496 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:00:17.709261 ops/training.py:65 2019-01-17 02:00:17.709201: step 5998, loss = 0.71681 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:00:18.991244 ops/training.py:65 2019-01-17 02:00:18.991140: step 5999, loss = 0.67621 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:06:23.761523 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I4672 2019-01-17 02:06:23.762585 ops/training.py:41 2019-01-17 02:06:23.762523: step 6000, loss = 0.69 (0.1 examples/sec; 363.484 sec/batch) | Training accuracy = 0.5 | Validation accuracy = 0.50695 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_23_33_01_706250
I4672 2019-01-17 02:06:25.049965 ops/training.py:65 2019-01-17 02:06:25.049862: step 6001, loss = 0.69372 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:06:26.342105 ops/training.py:65 2019-01-17 02:06:26.341994: step 6002, loss = 0.69576 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:06:27.626787 ops/training.py:65 2019-01-17 02:06:27.626691: step 6003, loss = 0.69912 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:06:28.917703 ops/training.py:65 2019-01-17 02:06:28.917595: step 6004, loss = 0.67634 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:06:30.203272 ops/training.py:65 2019-01-17 02:06:30.203193: step 6005, loss = 0.68390 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:06:31.486068 ops/training.py:65 2019-01-17 02:06:31.485975: step 6006, loss = 0.67241 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:06:32.774694 ops/training.py:65 2019-01-17 02:06:32.774583: step 6007, loss = 0.70638 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:06:34.057768 ops/training.py:65 2019-01-17 02:06:34.057679: step 6008, loss = 0.68391 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:06:35.342958 ops/training.py:65 2019-01-17 02:06:35.342853: step 6009, loss = 0.67022 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:06:36.626510 ops/training.py:65 2019-01-17 02:06:36.626405: step 6010, loss = 0.67522 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:06:37.919709 ops/training.py:65 2019-01-17 02:06:37.919625: step 6011, loss = 0.71193 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:06:39.200367 ops/training.py:65 2019-01-17 02:06:39.200316: step 6012, loss = 0.71916 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:06:40.484436 ops/training.py:65 2019-01-17 02:06:40.484334: step 6013, loss = 0.68573 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:06:41.764739 ops/training.py:65 2019-01-17 02:06:41.764678: step 6014, loss = 0.69080 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:06:43.046137 ops/training.py:65 2019-01-17 02:06:43.046065: step 6015, loss = 0.68661 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:06:44.331774 ops/training.py:65 2019-01-17 02:06:44.331743: step 6016, loss = 0.67210 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:06:45.616753 ops/training.py:65 2019-01-17 02:06:45.616657: step 6017, loss = 0.71051 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:06:46.901937 ops/training.py:65 2019-01-17 02:06:46.901832: step 6018, loss = 0.68729 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:06:48.187183 ops/training.py:65 2019-01-17 02:06:48.187088: step 6019, loss = 0.72881 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:06:49.471637 ops/training.py:65 2019-01-17 02:06:49.471541: step 6020, loss = 0.67584 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:06:50.756153 ops/training.py:65 2019-01-17 02:06:50.756054: step 6021, loss = 0.66240 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:06:52.042666 ops/training.py:65 2019-01-17 02:06:52.042595: step 6022, loss = 0.70807 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:06:53.329790 ops/training.py:65 2019-01-17 02:06:53.329757: step 6023, loss = 0.69854 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:06:54.624606 ops/training.py:65 2019-01-17 02:06:54.624528: step 6024, loss = 0.66393 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:06:55.911913 ops/training.py:65 2019-01-17 02:06:55.911813: step 6025, loss = 0.67121 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:06:57.201413 ops/training.py:65 2019-01-17 02:06:57.201379: step 6026, loss = 0.67496 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:06:58.483469 ops/training.py:65 2019-01-17 02:06:58.483426: step 6027, loss = 0.71490 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:06:59.768673 ops/training.py:65 2019-01-17 02:06:59.768619: step 6028, loss = 0.70114 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:07:01.056353 ops/training.py:65 2019-01-17 02:07:01.056324: step 6029, loss = 0.65851 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:07:02.336333 ops/training.py:65 2019-01-17 02:07:02.336303: step 6030, loss = 0.68708 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:07:03.621902 ops/training.py:65 2019-01-17 02:07:03.621874: step 6031, loss = 0.68805 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:07:04.906568 ops/training.py:65 2019-01-17 02:07:04.906541: step 6032, loss = 0.70258 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:07:06.195636 ops/training.py:65 2019-01-17 02:07:06.195608: step 6033, loss = 0.68029 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:07:07.481466 ops/training.py:65 2019-01-17 02:07:07.481390: step 6034, loss = 0.66895 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:07:08.767102 ops/training.py:65 2019-01-17 02:07:08.767050: step 6035, loss = 0.71520 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:07:10.059298 ops/training.py:65 2019-01-17 02:07:10.059267: step 6036, loss = 0.71720 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:07:11.350348 ops/training.py:65 2019-01-17 02:07:11.350308: step 6037, loss = 0.76159 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:07:12.634234 ops/training.py:65 2019-01-17 02:07:12.634196: step 6038, loss = 0.71724 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:07:13.928164 ops/training.py:65 2019-01-17 02:07:13.928120: step 6039, loss = 0.67259 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:07:15.212587 ops/training.py:65 2019-01-17 02:07:15.212509: step 6040, loss = 0.72463 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:07:16.500500 ops/training.py:65 2019-01-17 02:07:16.500425: step 6041, loss = 0.70429 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:07:17.787014 ops/training.py:65 2019-01-17 02:07:17.786967: step 6042, loss = 0.69159 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:07:19.072473 ops/training.py:65 2019-01-17 02:07:19.072404: step 6043, loss = 0.68586 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:07:20.355653 ops/training.py:65 2019-01-17 02:07:20.355617: step 6044, loss = 0.69235 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:07:21.644620 ops/training.py:65 2019-01-17 02:07:21.644569: step 6045, loss = 0.70708 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:07:22.931856 ops/training.py:65 2019-01-17 02:07:22.931801: step 6046, loss = 0.67682 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:07:24.224100 ops/training.py:65 2019-01-17 02:07:24.224021: step 6047, loss = 0.71624 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:07:25.507040 ops/training.py:65 2019-01-17 02:07:25.506970: step 6048, loss = 0.67976 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:07:26.787783 ops/training.py:65 2019-01-17 02:07:26.787739: step 6049, loss = 0.73993 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:07:28.078076 ops/training.py:65 2019-01-17 02:07:28.078004: step 6050, loss = 0.71472 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:07:29.366224 ops/training.py:65 2019-01-17 02:07:29.366173: step 6051, loss = 0.66901 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:07:30.651326 ops/training.py:65 2019-01-17 02:07:30.651298: step 6052, loss = 0.67161 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:07:31.944780 ops/training.py:65 2019-01-17 02:07:31.944742: step 6053, loss = 0.69559 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:07:33.231631 ops/training.py:65 2019-01-17 02:07:33.231601: step 6054, loss = 0.68788 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:07:34.518257 ops/training.py:65 2019-01-17 02:07:34.518206: step 6055, loss = 0.71079 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:07:35.804061 ops/training.py:65 2019-01-17 02:07:35.804021: step 6056, loss = 0.72311 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:07:37.088179 ops/training.py:65 2019-01-17 02:07:37.088078: step 6057, loss = 0.67686 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:07:38.377494 ops/training.py:65 2019-01-17 02:07:38.377390: step 6058, loss = 0.75435 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:07:39.661684 ops/training.py:65 2019-01-17 02:07:39.661606: step 6059, loss = 0.70480 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:07:40.942950 ops/training.py:65 2019-01-17 02:07:40.942895: step 6060, loss = 0.69173 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:07:42.224548 ops/training.py:65 2019-01-17 02:07:42.224447: step 6061, loss = 0.70099 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:07:43.514263 ops/training.py:65 2019-01-17 02:07:43.514164: step 6062, loss = 0.69574 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:07:44.804598 ops/training.py:65 2019-01-17 02:07:44.804488: step 6063, loss = 0.68024 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:07:46.090934 ops/training.py:65 2019-01-17 02:07:46.090830: step 6064, loss = 0.68662 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:07:47.377778 ops/training.py:65 2019-01-17 02:07:47.377669: step 6065, loss = 0.70593 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:07:48.663359 ops/training.py:65 2019-01-17 02:07:48.663292: step 6066, loss = 0.67541 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:07:49.947495 ops/training.py:65 2019-01-17 02:07:49.947439: step 6067, loss = 0.68068 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:07:51.234591 ops/training.py:65 2019-01-17 02:07:51.234479: step 6068, loss = 0.70598 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:07:52.524964 ops/training.py:65 2019-01-17 02:07:52.524851: step 6069, loss = 0.68113 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:07:53.810267 ops/training.py:65 2019-01-17 02:07:53.810202: step 6070, loss = 0.69040 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:07:55.095667 ops/training.py:65 2019-01-17 02:07:55.095558: step 6071, loss = 0.68541 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:07:56.382028 ops/training.py:65 2019-01-17 02:07:56.381927: step 6072, loss = 0.71922 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:07:57.663323 ops/training.py:65 2019-01-17 02:07:57.663234: step 6073, loss = 0.70496 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:07:58.941537 ops/training.py:65 2019-01-17 02:07:58.941433: step 6074, loss = 0.69898 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:08:00.235685 ops/training.py:65 2019-01-17 02:08:00.235587: step 6075, loss = 0.70077 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:08:01.520494 ops/training.py:65 2019-01-17 02:08:01.520408: step 6076, loss = 0.67031 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:08:02.803609 ops/training.py:65 2019-01-17 02:08:02.803510: step 6077, loss = 0.69512 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:08:04.086567 ops/training.py:65 2019-01-17 02:08:04.086501: step 6078, loss = 0.67055 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:08:05.368728 ops/training.py:65 2019-01-17 02:08:05.368644: step 6079, loss = 0.71228 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:08:06.652049 ops/training.py:65 2019-01-17 02:08:06.651937: step 6080, loss = 0.76041 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.25
I4672 2019-01-17 02:08:07.931435 ops/training.py:65 2019-01-17 02:08:07.931330: step 6081, loss = 0.74303 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:08:09.213362 ops/training.py:65 2019-01-17 02:08:09.213264: step 6082, loss = 0.70206 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:08:10.495692 ops/training.py:65 2019-01-17 02:08:10.495587: step 6083, loss = 0.69312 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:08:11.786756 ops/training.py:65 2019-01-17 02:08:11.786654: step 6084, loss = 0.69232 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:08:13.076919 ops/training.py:65 2019-01-17 02:08:13.076849: step 6085, loss = 0.70556 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:08:14.363983 ops/training.py:65 2019-01-17 02:08:14.363914: step 6086, loss = 0.69385 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:08:15.646748 ops/training.py:65 2019-01-17 02:08:15.646674: step 6087, loss = 0.70602 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:08:16.935372 ops/training.py:65 2019-01-17 02:08:16.935268: step 6088, loss = 0.68453 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:08:18.220518 ops/training.py:65 2019-01-17 02:08:18.220471: step 6089, loss = 0.67251 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:08:19.511595 ops/training.py:65 2019-01-17 02:08:19.511567: step 6090, loss = 0.67749 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:08:20.795782 ops/training.py:65 2019-01-17 02:08:20.795752: step 6091, loss = 0.68581 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:08:22.079522 ops/training.py:65 2019-01-17 02:08:22.079449: step 6092, loss = 0.71972 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:08:23.369359 ops/training.py:65 2019-01-17 02:08:23.369282: step 6093, loss = 0.71657 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:08:24.655066 ops/training.py:65 2019-01-17 02:08:24.654994: step 6094, loss = 0.68179 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:08:25.934725 ops/training.py:65 2019-01-17 02:08:25.934624: step 6095, loss = 0.70517 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:08:27.219221 ops/training.py:65 2019-01-17 02:08:27.219123: step 6096, loss = 0.71346 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:08:28.510005 ops/training.py:65 2019-01-17 02:08:28.509900: step 6097, loss = 0.68109 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:08:29.798963 ops/training.py:65 2019-01-17 02:08:29.798884: step 6098, loss = 0.71814 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:08:31.079862 ops/training.py:65 2019-01-17 02:08:31.079787: step 6099, loss = 0.73308 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:08:32.366448 ops/training.py:65 2019-01-17 02:08:32.366346: step 6100, loss = 0.70628 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:08:33.646619 ops/training.py:65 2019-01-17 02:08:33.646532: step 6101, loss = 0.69048 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:08:34.929561 ops/training.py:65 2019-01-17 02:08:34.929459: step 6102, loss = 0.70130 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:08:36.214812 ops/training.py:65 2019-01-17 02:08:36.214712: step 6103, loss = 0.68584 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:08:37.501021 ops/training.py:65 2019-01-17 02:08:37.500913: step 6104, loss = 0.69711 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:08:38.781554 ops/training.py:65 2019-01-17 02:08:38.781456: step 6105, loss = 0.67117 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:08:40.071564 ops/training.py:65 2019-01-17 02:08:40.071459: step 6106, loss = 0.72959 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:08:41.360413 ops/training.py:65 2019-01-17 02:08:41.360326: step 6107, loss = 0.70795 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:08:42.646984 ops/training.py:65 2019-01-17 02:08:42.646884: step 6108, loss = 0.69287 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:08:43.935577 ops/training.py:65 2019-01-17 02:08:43.935445: step 6109, loss = 0.68610 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:08:45.219887 ops/training.py:65 2019-01-17 02:08:45.219820: step 6110, loss = 0.66967 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:08:46.506890 ops/training.py:65 2019-01-17 02:08:46.506789: step 6111, loss = 0.69451 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:08:47.792689 ops/training.py:65 2019-01-17 02:08:47.792593: step 6112, loss = 0.68609 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:08:49.076094 ops/training.py:65 2019-01-17 02:08:49.075992: step 6113, loss = 0.65449 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:08:50.371487 ops/training.py:65 2019-01-17 02:08:50.371417: step 6114, loss = 0.68260 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:08:51.654613 ops/training.py:65 2019-01-17 02:08:51.654578: step 6115, loss = 0.71138 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:08:52.941391 ops/training.py:65 2019-01-17 02:08:52.941289: step 6116, loss = 0.70057 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:08:54.227297 ops/training.py:65 2019-01-17 02:08:54.227211: step 6117, loss = 0.71976 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:08:55.513254 ops/training.py:65 2019-01-17 02:08:55.513189: step 6118, loss = 0.67256 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:08:56.802024 ops/training.py:65 2019-01-17 02:08:56.801983: step 6119, loss = 0.68089 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:08:58.085996 ops/training.py:65 2019-01-17 02:08:58.085952: step 6120, loss = 0.65543 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:08:59.368952 ops/training.py:65 2019-01-17 02:08:59.368918: step 6121, loss = 0.70331 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:09:00.652554 ops/training.py:65 2019-01-17 02:09:00.652522: step 6122, loss = 0.72173 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:09:01.937412 ops/training.py:65 2019-01-17 02:09:01.937380: step 6123, loss = 0.70914 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:09:03.222646 ops/training.py:65 2019-01-17 02:09:03.222612: step 6124, loss = 0.69335 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:09:04.512393 ops/training.py:65 2019-01-17 02:09:04.512360: step 6125, loss = 0.68646 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:09:05.800260 ops/training.py:65 2019-01-17 02:09:05.800200: step 6126, loss = 0.66948 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:09:07.083988 ops/training.py:65 2019-01-17 02:09:07.083934: step 6127, loss = 0.69916 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:09:08.367909 ops/training.py:65 2019-01-17 02:09:08.367806: step 6128, loss = 0.70806 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:09:09.648305 ops/training.py:65 2019-01-17 02:09:09.648240: step 6129, loss = 0.72107 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:09:10.928535 ops/training.py:65 2019-01-17 02:09:10.928491: step 6130, loss = 0.69421 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:09:12.215485 ops/training.py:65 2019-01-17 02:09:12.215389: step 6131, loss = 0.72352 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:09:13.505617 ops/training.py:65 2019-01-17 02:09:13.505535: step 6132, loss = 0.68712 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:09:14.792990 ops/training.py:65 2019-01-17 02:09:14.792918: step 6133, loss = 0.72127 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:09:16.074136 ops/training.py:65 2019-01-17 02:09:16.074020: step 6134, loss = 0.72668 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:09:17.360458 ops/training.py:65 2019-01-17 02:09:17.360352: step 6135, loss = 0.69112 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:09:18.652605 ops/training.py:65 2019-01-17 02:09:18.652455: step 6136, loss = 0.71666 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:09:19.939634 ops/training.py:65 2019-01-17 02:09:19.939539: step 6137, loss = 0.68863 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:09:21.231023 ops/training.py:65 2019-01-17 02:09:21.230924: step 6138, loss = 0.69180 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:09:22.515872 ops/training.py:65 2019-01-17 02:09:22.515810: step 6139, loss = 0.67635 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:09:23.800838 ops/training.py:65 2019-01-17 02:09:23.800743: step 6140, loss = 0.72868 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:09:25.085514 ops/training.py:65 2019-01-17 02:09:25.085355: step 6141, loss = 0.68912 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:09:26.371888 ops/training.py:65 2019-01-17 02:09:26.371734: step 6142, loss = 0.69671 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:09:27.664879 ops/training.py:65 2019-01-17 02:09:27.664787: step 6143, loss = 0.71895 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:09:28.948409 ops/training.py:65 2019-01-17 02:09:28.948311: step 6144, loss = 0.71075 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:09:30.233703 ops/training.py:65 2019-01-17 02:09:30.233592: step 6145, loss = 0.72175 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:09:31.522120 ops/training.py:65 2019-01-17 02:09:31.522022: step 6146, loss = 0.67936 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:09:32.809979 ops/training.py:65 2019-01-17 02:09:32.809868: step 6147, loss = 0.70724 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:09:34.097720 ops/training.py:65 2019-01-17 02:09:34.097621: step 6148, loss = 0.69580 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:09:35.384774 ops/training.py:65 2019-01-17 02:09:35.384676: step 6149, loss = 0.65878 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:09:36.670646 ops/training.py:65 2019-01-17 02:09:36.670541: step 6150, loss = 0.71417 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:09:37.956434 ops/training.py:65 2019-01-17 02:09:37.956331: step 6151, loss = 0.68499 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:09:39.243917 ops/training.py:65 2019-01-17 02:09:39.243813: step 6152, loss = 0.67753 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:09:40.530910 ops/training.py:65 2019-01-17 02:09:40.530812: step 6153, loss = 0.69346 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:09:41.820534 ops/training.py:65 2019-01-17 02:09:41.820436: step 6154, loss = 0.70997 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:09:43.105391 ops/training.py:65 2019-01-17 02:09:43.105324: step 6155, loss = 0.71573 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:09:44.388816 ops/training.py:65 2019-01-17 02:09:44.388720: step 6156, loss = 0.69477 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:09:45.675164 ops/training.py:65 2019-01-17 02:09:45.675069: step 6157, loss = 0.69178 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:09:46.956367 ops/training.py:65 2019-01-17 02:09:46.956270: step 6158, loss = 0.68252 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:09:48.247763 ops/training.py:65 2019-01-17 02:09:48.247660: step 6159, loss = 0.71858 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:09:49.528003 ops/training.py:65 2019-01-17 02:09:49.527902: step 6160, loss = 0.69288 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:09:50.816639 ops/training.py:65 2019-01-17 02:09:50.816527: step 6161, loss = 0.68903 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:09:52.106691 ops/training.py:65 2019-01-17 02:09:52.106593: step 6162, loss = 0.68840 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:09:53.390392 ops/training.py:65 2019-01-17 02:09:53.390323: step 6163, loss = 0.70826 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:09:54.672376 ops/training.py:65 2019-01-17 02:09:54.672287: step 6164, loss = 0.69655 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:09:55.956903 ops/training.py:65 2019-01-17 02:09:55.956800: step 6165, loss = 0.69379 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:09:57.240767 ops/training.py:65 2019-01-17 02:09:57.240665: step 6166, loss = 0.69168 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:09:58.521469 ops/training.py:65 2019-01-17 02:09:58.521375: step 6167, loss = 0.71368 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:09:59.809024 ops/training.py:65 2019-01-17 02:09:59.808914: step 6168, loss = 0.67349 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:10:01.089276 ops/training.py:65 2019-01-17 02:10:01.089169: step 6169, loss = 0.67795 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:10:02.368599 ops/training.py:65 2019-01-17 02:10:02.368515: step 6170, loss = 0.68817 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:10:03.655780 ops/training.py:65 2019-01-17 02:10:03.655683: step 6171, loss = 0.67402 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:10:04.938865 ops/training.py:65 2019-01-17 02:10:04.938765: step 6172, loss = 0.67534 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:10:06.226171 ops/training.py:65 2019-01-17 02:10:06.226069: step 6173, loss = 0.69102 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:10:07.510980 ops/training.py:65 2019-01-17 02:10:07.510908: step 6174, loss = 0.66212 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:10:08.793406 ops/training.py:65 2019-01-17 02:10:08.793334: step 6175, loss = 0.66123 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:10:10.078614 ops/training.py:65 2019-01-17 02:10:10.078508: step 6176, loss = 0.71006 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:10:11.369577 ops/training.py:65 2019-01-17 02:10:11.369474: step 6177, loss = 0.66464 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:10:12.655711 ops/training.py:65 2019-01-17 02:10:12.655644: step 6178, loss = 0.67687 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:10:13.938725 ops/training.py:65 2019-01-17 02:10:13.938639: step 6179, loss = 0.67722 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:10:15.225417 ops/training.py:65 2019-01-17 02:10:15.225312: step 6180, loss = 0.71284 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:10:16.513133 ops/training.py:65 2019-01-17 02:10:16.512980: step 6181, loss = 0.69688 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:10:17.805516 ops/training.py:65 2019-01-17 02:10:17.805410: step 6182, loss = 0.69226 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:10:19.095777 ops/training.py:65 2019-01-17 02:10:19.095686: step 6183, loss = 0.69118 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:10:20.380712 ops/training.py:65 2019-01-17 02:10:20.380631: step 6184, loss = 0.69446 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:10:21.670142 ops/training.py:65 2019-01-17 02:10:21.670031: step 6185, loss = 0.69880 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:10:22.960916 ops/training.py:65 2019-01-17 02:10:22.960808: step 6186, loss = 0.68198 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:10:24.242262 ops/training.py:65 2019-01-17 02:10:24.242188: step 6187, loss = 0.70253 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:10:25.534327 ops/training.py:65 2019-01-17 02:10:25.534221: step 6188, loss = 0.70682 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:10:26.817554 ops/training.py:65 2019-01-17 02:10:26.817493: step 6189, loss = 0.68967 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:10:28.098879 ops/training.py:65 2019-01-17 02:10:28.098791: step 6190, loss = 0.69383 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:10:29.388979 ops/training.py:65 2019-01-17 02:10:29.388870: step 6191, loss = 0.70114 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:10:30.673973 ops/training.py:65 2019-01-17 02:10:30.673868: step 6192, loss = 0.71971 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 02:10:31.962125 ops/training.py:65 2019-01-17 02:10:31.962013: step 6193, loss = 0.71132 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:10:33.245205 ops/training.py:65 2019-01-17 02:10:33.245110: step 6194, loss = 0.65860 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:10:34.537652 ops/training.py:65 2019-01-17 02:10:34.537550: step 6195, loss = 0.69644 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:10:35.821135 ops/training.py:65 2019-01-17 02:10:35.821070: step 6196, loss = 0.67504 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:10:37.102715 ops/training.py:65 2019-01-17 02:10:37.102634: step 6197, loss = 0.69902 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:10:38.389642 ops/training.py:65 2019-01-17 02:10:38.389536: step 6198, loss = 0.69439 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:10:39.670600 ops/training.py:65 2019-01-17 02:10:39.670485: step 6199, loss = 0.69616 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:10:40.958483 ops/training.py:65 2019-01-17 02:10:40.958370: step 6200, loss = 0.73611 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:10:42.250562 ops/training.py:65 2019-01-17 02:10:42.250462: step 6201, loss = 0.71167 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:10:43.536609 ops/training.py:65 2019-01-17 02:10:43.536541: step 6202, loss = 0.69650 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:10:44.826392 ops/training.py:65 2019-01-17 02:10:44.826286: step 6203, loss = 0.69548 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:10:46.113202 ops/training.py:65 2019-01-17 02:10:46.113138: step 6204, loss = 0.69877 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:10:47.395649 ops/training.py:65 2019-01-17 02:10:47.395557: step 6205, loss = 0.71365 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:10:48.683121 ops/training.py:65 2019-01-17 02:10:48.683003: step 6206, loss = 0.72141 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:10:49.965398 ops/training.py:65 2019-01-17 02:10:49.965287: step 6207, loss = 0.70493 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:10:51.252042 ops/training.py:65 2019-01-17 02:10:51.251929: step 6208, loss = 0.68007 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:10:52.537139 ops/training.py:65 2019-01-17 02:10:52.537030: step 6209, loss = 0.68134 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:10:53.830652 ops/training.py:65 2019-01-17 02:10:53.830550: step 6210, loss = 0.70125 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:10:55.120873 ops/training.py:65 2019-01-17 02:10:55.120772: step 6211, loss = 0.69900 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:10:56.409680 ops/training.py:65 2019-01-17 02:10:56.409578: step 6212, loss = 0.70763 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:10:57.692744 ops/training.py:65 2019-01-17 02:10:57.692681: step 6213, loss = 0.69245 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:10:58.973894 ops/training.py:65 2019-01-17 02:10:58.973801: step 6214, loss = 0.69303 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:11:00.256231 ops/training.py:65 2019-01-17 02:11:00.256131: step 6215, loss = 0.70031 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:11:01.539095 ops/training.py:65 2019-01-17 02:11:01.539001: step 6216, loss = 0.70080 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:11:02.819725 ops/training.py:65 2019-01-17 02:11:02.819621: step 6217, loss = 0.68658 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:11:04.106576 ops/training.py:65 2019-01-17 02:11:04.106478: step 6218, loss = 0.69417 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:11:05.390369 ops/training.py:65 2019-01-17 02:11:05.390265: step 6219, loss = 0.68654 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:11:06.677211 ops/training.py:65 2019-01-17 02:11:06.677123: step 6220, loss = 0.66299 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:11:07.960452 ops/training.py:65 2019-01-17 02:11:07.960367: step 6221, loss = 0.70497 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:11:09.241960 ops/training.py:65 2019-01-17 02:11:09.241857: step 6222, loss = 0.67813 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:11:10.523384 ops/training.py:65 2019-01-17 02:11:10.523301: step 6223, loss = 0.73508 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:11:11.804743 ops/training.py:65 2019-01-17 02:11:11.804635: step 6224, loss = 0.70202 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:11:13.085360 ops/training.py:65 2019-01-17 02:11:13.085278: step 6225, loss = 0.70321 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:11:14.370960 ops/training.py:65 2019-01-17 02:11:14.370852: step 6226, loss = 0.67851 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:11:15.660862 ops/training.py:65 2019-01-17 02:11:15.660765: step 6227, loss = 0.68989 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:11:16.945899 ops/training.py:65 2019-01-17 02:11:16.945801: step 6228, loss = 0.66885 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:11:18.232757 ops/training.py:65 2019-01-17 02:11:18.232646: step 6229, loss = 0.64260 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:11:19.513036 ops/training.py:65 2019-01-17 02:11:19.512877: step 6230, loss = 0.71206 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:11:20.797103 ops/training.py:65 2019-01-17 02:11:20.796995: step 6231, loss = 0.72288 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:11:22.087118 ops/training.py:65 2019-01-17 02:11:22.087030: step 6232, loss = 0.71233 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:11:23.373824 ops/training.py:65 2019-01-17 02:11:23.373757: step 6233, loss = 0.67455 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:11:24.662233 ops/training.py:65 2019-01-17 02:11:24.662141: step 6234, loss = 0.65901 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 02:11:25.947508 ops/training.py:65 2019-01-17 02:11:25.947423: step 6235, loss = 0.70138 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:11:27.230782 ops/training.py:65 2019-01-17 02:11:27.230689: step 6236, loss = 0.65228 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:11:28.521960 ops/training.py:65 2019-01-17 02:11:28.521819: step 6237, loss = 0.66759 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:11:29.814106 ops/training.py:65 2019-01-17 02:11:29.814041: step 6238, loss = 0.72168 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:11:31.101906 ops/training.py:65 2019-01-17 02:11:31.101831: step 6239, loss = 0.70617 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:11:32.386330 ops/training.py:65 2019-01-17 02:11:32.386266: step 6240, loss = 0.67547 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:11:33.667816 ops/training.py:65 2019-01-17 02:11:33.667749: step 6241, loss = 0.68840 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:11:34.950639 ops/training.py:65 2019-01-17 02:11:34.950544: step 6242, loss = 0.66047 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:11:36.241515 ops/training.py:65 2019-01-17 02:11:36.241414: step 6243, loss = 0.68313 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:11:37.528708 ops/training.py:65 2019-01-17 02:11:37.528628: step 6244, loss = 0.67724 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:11:38.817565 ops/training.py:65 2019-01-17 02:11:38.817495: step 6245, loss = 0.68085 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:11:40.105768 ops/training.py:65 2019-01-17 02:11:40.105675: step 6246, loss = 0.69632 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:11:41.389401 ops/training.py:65 2019-01-17 02:11:41.389321: step 6247, loss = 0.69671 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:11:42.673131 ops/training.py:65 2019-01-17 02:11:42.673028: step 6248, loss = 0.70394 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:11:43.965326 ops/training.py:65 2019-01-17 02:11:43.965229: step 6249, loss = 0.71124 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:11:45.255419 ops/training.py:65 2019-01-17 02:11:45.255342: step 6250, loss = 0.68926 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:11:46.538745 ops/training.py:65 2019-01-17 02:11:46.538646: step 6251, loss = 0.67943 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:11:47.828914 ops/training.py:65 2019-01-17 02:11:47.828819: step 6252, loss = 0.69112 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:11:49.113618 ops/training.py:65 2019-01-17 02:11:49.113546: step 6253, loss = 0.68987 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:11:50.402158 ops/training.py:65 2019-01-17 02:11:50.402060: step 6254, loss = 0.67083 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:11:51.689549 ops/training.py:65 2019-01-17 02:11:51.689479: step 6255, loss = 0.69202 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:11:52.972800 ops/training.py:65 2019-01-17 02:11:52.972733: step 6256, loss = 0.71067 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:11:54.259360 ops/training.py:65 2019-01-17 02:11:54.259262: step 6257, loss = 0.68458 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:11:55.546783 ops/training.py:65 2019-01-17 02:11:55.546685: step 6258, loss = 0.69064 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:11:56.832445 ops/training.py:65 2019-01-17 02:11:56.832341: step 6259, loss = 0.60828 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 02:11:58.116607 ops/training.py:65 2019-01-17 02:11:58.116515: step 6260, loss = 0.68634 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:11:59.403574 ops/training.py:65 2019-01-17 02:11:59.403475: step 6261, loss = 0.67616 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:12:00.695090 ops/training.py:65 2019-01-17 02:12:00.694953: step 6262, loss = 0.64916 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 02:12:01.982034 ops/training.py:65 2019-01-17 02:12:01.981931: step 6263, loss = 0.70748 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:12:03.265710 ops/training.py:65 2019-01-17 02:12:03.265617: step 6264, loss = 0.70675 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:12:04.545755 ops/training.py:65 2019-01-17 02:12:04.545689: step 6265, loss = 0.68616 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:12:05.832354 ops/training.py:65 2019-01-17 02:12:05.832264: step 6266, loss = 0.67529 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:12:07.112090 ops/training.py:65 2019-01-17 02:12:07.112003: step 6267, loss = 0.69983 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:12:08.393428 ops/training.py:65 2019-01-17 02:12:08.393328: step 6268, loss = 0.70659 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:12:09.676040 ops/training.py:65 2019-01-17 02:12:09.675961: step 6269, loss = 0.70835 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:12:10.961005 ops/training.py:65 2019-01-17 02:12:10.960898: step 6270, loss = 0.70096 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:12:12.251097 ops/training.py:65 2019-01-17 02:12:12.250995: step 6271, loss = 0.68015 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:12:13.532012 ops/training.py:65 2019-01-17 02:12:13.531923: step 6272, loss = 0.70692 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 02:12:14.817419 ops/training.py:65 2019-01-17 02:12:14.817319: step 6273, loss = 0.70663 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:12:16.102504 ops/training.py:65 2019-01-17 02:12:16.102402: step 6274, loss = 0.68249 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:12:17.389299 ops/training.py:65 2019-01-17 02:12:17.389191: step 6275, loss = 0.68537 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:12:18.671823 ops/training.py:65 2019-01-17 02:12:18.671709: step 6276, loss = 0.69517 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:12:19.950270 ops/training.py:65 2019-01-17 02:12:19.950112: step 6277, loss = 0.70849 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:12:21.236006 ops/training.py:65 2019-01-17 02:12:21.235908: step 6278, loss = 0.68387 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:12:22.520461 ops/training.py:65 2019-01-17 02:12:22.520358: step 6279, loss = 0.68488 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:12:23.808107 ops/training.py:65 2019-01-17 02:12:23.808005: step 6280, loss = 0.70937 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:12:25.098680 ops/training.py:65 2019-01-17 02:12:25.098586: step 6281, loss = 0.67460 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:12:26.386931 ops/training.py:65 2019-01-17 02:12:26.386783: step 6282, loss = 0.71889 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:12:27.676492 ops/training.py:65 2019-01-17 02:12:27.676416: step 6283, loss = 0.68348 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:12:28.959086 ops/training.py:65 2019-01-17 02:12:28.959013: step 6284, loss = 0.67295 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:12:30.242418 ops/training.py:65 2019-01-17 02:12:30.242309: step 6285, loss = 0.66412 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:12:31.530404 ops/training.py:65 2019-01-17 02:12:31.530304: step 6286, loss = 0.69912 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:12:32.814602 ops/training.py:65 2019-01-17 02:12:32.814531: step 6287, loss = 0.66558 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:12:34.102511 ops/training.py:65 2019-01-17 02:12:34.102363: step 6288, loss = 0.69436 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:12:35.389263 ops/training.py:65 2019-01-17 02:12:35.389155: step 6289, loss = 0.72418 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:12:36.676799 ops/training.py:65 2019-01-17 02:12:36.676700: step 6290, loss = 0.68244 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:12:37.968491 ops/training.py:65 2019-01-17 02:12:37.968390: step 6291, loss = 0.71068 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:12:39.257679 ops/training.py:65 2019-01-17 02:12:39.257604: step 6292, loss = 0.67658 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:12:40.544639 ops/training.py:65 2019-01-17 02:12:40.544562: step 6293, loss = 0.69343 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:12:41.828485 ops/training.py:65 2019-01-17 02:12:41.828409: step 6294, loss = 0.69399 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:12:43.116878 ops/training.py:65 2019-01-17 02:12:43.116803: step 6295, loss = 0.69412 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:12:44.399101 ops/training.py:65 2019-01-17 02:12:44.399002: step 6296, loss = 0.65947 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:12:45.683048 ops/training.py:65 2019-01-17 02:12:45.682935: step 6297, loss = 0.68414 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:12:46.970136 ops/training.py:65 2019-01-17 02:12:46.970029: step 6298, loss = 0.69025 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:12:48.261853 ops/training.py:65 2019-01-17 02:12:48.261751: step 6299, loss = 0.72271 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:12:49.552952 ops/training.py:65 2019-01-17 02:12:49.552877: step 6300, loss = 0.66454 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:12:50.841669 ops/training.py:65 2019-01-17 02:12:50.841598: step 6301, loss = 0.70553 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:12:52.132587 ops/training.py:65 2019-01-17 02:12:52.132509: step 6302, loss = 0.67171 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:12:53.422059 ops/training.py:65 2019-01-17 02:12:53.421994: step 6303, loss = 0.70006 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:12:54.706395 ops/training.py:65 2019-01-17 02:12:54.706329: step 6304, loss = 0.68009 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:12:55.990797 ops/training.py:65 2019-01-17 02:12:55.990720: step 6305, loss = 0.67545 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:12:57.275760 ops/training.py:65 2019-01-17 02:12:57.275651: step 6306, loss = 0.67029 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:12:58.565469 ops/training.py:65 2019-01-17 02:12:58.565363: step 6307, loss = 0.68481 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:12:59.851092 ops/training.py:65 2019-01-17 02:12:59.851025: step 6308, loss = 0.67797 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:13:01.137746 ops/training.py:65 2019-01-17 02:13:01.137643: step 6309, loss = 0.66276 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:13:02.423671 ops/training.py:65 2019-01-17 02:13:02.423561: step 6310, loss = 0.66956 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:13:03.708213 ops/training.py:65 2019-01-17 02:13:03.708129: step 6311, loss = 0.66793 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:13:04.992425 ops/training.py:65 2019-01-17 02:13:04.992324: step 6312, loss = 0.67698 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:13:06.278449 ops/training.py:65 2019-01-17 02:13:06.278351: step 6313, loss = 0.69557 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:13:07.565822 ops/training.py:65 2019-01-17 02:13:07.565719: step 6314, loss = 0.73563 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 02:13:08.852200 ops/training.py:65 2019-01-17 02:13:08.852100: step 6315, loss = 0.69634 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:13:10.138938 ops/training.py:65 2019-01-17 02:13:10.138826: step 6316, loss = 0.67377 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:13:11.423589 ops/training.py:65 2019-01-17 02:13:11.423486: step 6317, loss = 0.68576 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:13:12.712509 ops/training.py:65 2019-01-17 02:13:12.712401: step 6318, loss = 0.69966 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:13:13.997328 ops/training.py:65 2019-01-17 02:13:13.997251: step 6319, loss = 0.71204 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:13:15.285087 ops/training.py:65 2019-01-17 02:13:15.285007: step 6320, loss = 0.71091 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:13:16.572531 ops/training.py:65 2019-01-17 02:13:16.572420: step 6321, loss = 0.74562 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 02:13:17.862389 ops/training.py:65 2019-01-17 02:13:17.862285: step 6322, loss = 0.70120 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:13:19.147734 ops/training.py:65 2019-01-17 02:13:19.147668: step 6323, loss = 0.71803 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:13:20.430727 ops/training.py:65 2019-01-17 02:13:20.430620: step 6324, loss = 0.66955 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:13:21.730004 ops/training.py:65 2019-01-17 02:13:21.729899: step 6325, loss = 0.65736 (24.7 examples/sec; 1.298 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:13:23.021156 ops/training.py:65 2019-01-17 02:13:23.021056: step 6326, loss = 0.71721 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:13:24.305720 ops/training.py:65 2019-01-17 02:13:24.305643: step 6327, loss = 0.71883 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:13:25.590853 ops/training.py:65 2019-01-17 02:13:25.590779: step 6328, loss = 0.67795 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:13:26.875891 ops/training.py:65 2019-01-17 02:13:26.875816: step 6329, loss = 0.69406 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:13:28.163107 ops/training.py:65 2019-01-17 02:13:28.163012: step 6330, loss = 0.69832 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:13:29.445905 ops/training.py:65 2019-01-17 02:13:29.445793: step 6331, loss = 0.68060 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:13:30.737211 ops/training.py:65 2019-01-17 02:13:30.737100: step 6332, loss = 0.68272 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:13:32.023265 ops/training.py:65 2019-01-17 02:13:32.023187: step 6333, loss = 0.69244 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:13:33.310279 ops/training.py:65 2019-01-17 02:13:33.310148: step 6334, loss = 0.66679 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:13:34.601947 ops/training.py:65 2019-01-17 02:13:34.601789: step 6335, loss = 0.69994 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:13:35.889925 ops/training.py:65 2019-01-17 02:13:35.889853: step 6336, loss = 0.68089 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:13:37.179501 ops/training.py:65 2019-01-17 02:13:37.179395: step 6337, loss = 0.67541 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:13:38.469541 ops/training.py:65 2019-01-17 02:13:38.469453: step 6338, loss = 0.65548 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:13:39.751148 ops/training.py:65 2019-01-17 02:13:39.751069: step 6339, loss = 0.68433 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:13:41.040748 ops/training.py:65 2019-01-17 02:13:41.040647: step 6340, loss = 0.70516 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:13:42.332809 ops/training.py:65 2019-01-17 02:13:42.332738: step 6341, loss = 0.70548 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:13:43.616490 ops/training.py:65 2019-01-17 02:13:43.616428: step 6342, loss = 0.67899 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:13:44.896334 ops/training.py:65 2019-01-17 02:13:44.896223: step 6343, loss = 0.72055 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:13:46.182822 ops/training.py:65 2019-01-17 02:13:46.182713: step 6344, loss = 0.69389 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:13:47.474254 ops/training.py:65 2019-01-17 02:13:47.474144: step 6345, loss = 0.66846 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:13:48.760923 ops/training.py:65 2019-01-17 02:13:48.760858: step 6346, loss = 0.66691 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:13:50.042703 ops/training.py:65 2019-01-17 02:13:50.042598: step 6347, loss = 0.68486 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:13:51.326327 ops/training.py:65 2019-01-17 02:13:51.326227: step 6348, loss = 0.66340 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:13:52.613521 ops/training.py:65 2019-01-17 02:13:52.613412: step 6349, loss = 0.69700 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:13:53.904726 ops/training.py:65 2019-01-17 02:13:53.904660: step 6350, loss = 0.68844 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:13:55.192881 ops/training.py:65 2019-01-17 02:13:55.192818: step 6351, loss = 0.66984 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:13:56.480674 ops/training.py:65 2019-01-17 02:13:56.480606: step 6352, loss = 0.70616 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:13:57.764240 ops/training.py:65 2019-01-17 02:13:57.764178: step 6353, loss = 0.68029 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:13:59.053504 ops/training.py:65 2019-01-17 02:13:59.053434: step 6354, loss = 0.69163 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:14:00.342850 ops/training.py:65 2019-01-17 02:14:00.342782: step 6355, loss = 0.67294 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:14:01.628511 ops/training.py:65 2019-01-17 02:14:01.628446: step 6356, loss = 0.69295 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:14:02.914529 ops/training.py:65 2019-01-17 02:14:02.914442: step 6357, loss = 0.69635 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:14:04.205630 ops/training.py:65 2019-01-17 02:14:04.205529: step 6358, loss = 0.73742 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:14:05.496225 ops/training.py:65 2019-01-17 02:14:05.496151: step 6359, loss = 0.63362 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:14:06.784397 ops/training.py:65 2019-01-17 02:14:06.784326: step 6360, loss = 0.66025 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:14:08.071638 ops/training.py:65 2019-01-17 02:14:08.071567: step 6361, loss = 0.68809 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:14:09.360287 ops/training.py:65 2019-01-17 02:14:09.360197: step 6362, loss = 0.76563 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:14:10.651158 ops/training.py:65 2019-01-17 02:14:10.651086: step 6363, loss = 0.71616 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:14:11.940201 ops/training.py:65 2019-01-17 02:14:11.940134: step 6364, loss = 0.74127 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:14:13.228664 ops/training.py:65 2019-01-17 02:14:13.228578: step 6365, loss = 0.67613 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:14:14.512543 ops/training.py:65 2019-01-17 02:14:14.512473: step 6366, loss = 0.66859 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:14:15.797005 ops/training.py:65 2019-01-17 02:14:15.796900: step 6367, loss = 0.75530 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:14:17.083519 ops/training.py:65 2019-01-17 02:14:17.083406: step 6368, loss = 0.70489 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:14:18.374129 ops/training.py:65 2019-01-17 02:14:18.374029: step 6369, loss = 0.73491 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:14:19.664443 ops/training.py:65 2019-01-17 02:14:19.664374: step 6370, loss = 0.75434 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:14:20.953083 ops/training.py:65 2019-01-17 02:14:20.952986: step 6371, loss = 0.67604 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:14:22.243512 ops/training.py:65 2019-01-17 02:14:22.243450: step 6372, loss = 0.62945 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:14:23.531828 ops/training.py:65 2019-01-17 02:14:23.531764: step 6373, loss = 0.69410 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:14:24.819859 ops/training.py:65 2019-01-17 02:14:24.819764: step 6374, loss = 0.68595 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:14:26.105831 ops/training.py:65 2019-01-17 02:14:26.105763: step 6375, loss = 0.63185 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:14:27.394036 ops/training.py:65 2019-01-17 02:14:27.393973: step 6376, loss = 0.71147 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:14:28.677714 ops/training.py:65 2019-01-17 02:14:28.677652: step 6377, loss = 0.67677 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:14:29.962045 ops/training.py:65 2019-01-17 02:14:29.961945: step 6378, loss = 0.69105 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:14:31.253569 ops/training.py:65 2019-01-17 02:14:31.253460: step 6379, loss = 0.68165 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:14:32.534448 ops/training.py:65 2019-01-17 02:14:32.534368: step 6380, loss = 0.68271 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:14:33.820488 ops/training.py:65 2019-01-17 02:14:33.820388: step 6381, loss = 0.64526 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:14:35.104247 ops/training.py:65 2019-01-17 02:14:35.104137: step 6382, loss = 0.73694 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:14:36.397703 ops/training.py:65 2019-01-17 02:14:36.397552: step 6383, loss = 0.70305 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:14:37.688548 ops/training.py:65 2019-01-17 02:14:37.688475: step 6384, loss = 0.72881 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:14:38.979047 ops/training.py:65 2019-01-17 02:14:38.978979: step 6385, loss = 0.66706 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:14:40.269751 ops/training.py:65 2019-01-17 02:14:40.269656: step 6386, loss = 0.67971 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:14:41.559882 ops/training.py:65 2019-01-17 02:14:41.559791: step 6387, loss = 0.69098 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:14:42.849597 ops/training.py:65 2019-01-17 02:14:42.849531: step 6388, loss = 0.73179 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:14:44.137966 ops/training.py:65 2019-01-17 02:14:44.137896: step 6389, loss = 0.67764 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:14:45.426891 ops/training.py:65 2019-01-17 02:14:45.426816: step 6390, loss = 0.73050 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:14:46.716411 ops/training.py:65 2019-01-17 02:14:46.716341: step 6391, loss = 0.69197 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:14:48.004910 ops/training.py:65 2019-01-17 02:14:48.004831: step 6392, loss = 0.68202 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:14:49.300176 ops/training.py:65 2019-01-17 02:14:49.300105: step 6393, loss = 0.67915 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:14:50.588680 ops/training.py:65 2019-01-17 02:14:50.588585: step 6394, loss = 0.67196 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:14:51.878579 ops/training.py:65 2019-01-17 02:14:51.878505: step 6395, loss = 0.69019 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:14:53.168757 ops/training.py:65 2019-01-17 02:14:53.168665: step 6396, loss = 0.64694 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:14:54.458415 ops/training.py:65 2019-01-17 02:14:54.458333: step 6397, loss = 0.69626 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:14:55.747862 ops/training.py:65 2019-01-17 02:14:55.747779: step 6398, loss = 0.69256 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:14:57.031917 ops/training.py:65 2019-01-17 02:14:57.031855: step 6399, loss = 0.71643 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:14:58.315388 ops/training.py:65 2019-01-17 02:14:58.315285: step 6400, loss = 0.70035 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:14:59.601122 ops/training.py:65 2019-01-17 02:14:59.601020: step 6401, loss = 0.67562 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:15:00.884622 ops/training.py:65 2019-01-17 02:15:00.884470: step 6402, loss = 0.67057 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:15:02.177162 ops/training.py:65 2019-01-17 02:15:02.177006: step 6403, loss = 0.68220 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:15:03.462686 ops/training.py:65 2019-01-17 02:15:03.462617: step 6404, loss = 0.70756 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:15:04.746236 ops/training.py:65 2019-01-17 02:15:04.746131: step 6405, loss = 0.70555 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:15:06.030976 ops/training.py:65 2019-01-17 02:15:06.030873: step 6406, loss = 0.69282 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:15:07.315870 ops/training.py:65 2019-01-17 02:15:07.315764: step 6407, loss = 0.68384 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:15:08.601040 ops/training.py:65 2019-01-17 02:15:08.600883: step 6408, loss = 0.66865 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:15:09.889301 ops/training.py:65 2019-01-17 02:15:09.889195: step 6409, loss = 0.69374 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:15:11.180325 ops/training.py:65 2019-01-17 02:15:11.180224: step 6410, loss = 0.69535 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:15:12.464915 ops/training.py:65 2019-01-17 02:15:12.464845: step 6411, loss = 0.68062 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:15:13.752667 ops/training.py:65 2019-01-17 02:15:13.752564: step 6412, loss = 0.69665 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:15:15.043198 ops/training.py:65 2019-01-17 02:15:15.043106: step 6413, loss = 0.71467 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:15:16.333613 ops/training.py:65 2019-01-17 02:15:16.333539: step 6414, loss = 0.71559 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:15:17.623218 ops/training.py:65 2019-01-17 02:15:17.623144: step 6415, loss = 0.69046 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:15:18.912379 ops/training.py:65 2019-01-17 02:15:18.912308: step 6416, loss = 0.64340 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 02:15:20.200379 ops/training.py:65 2019-01-17 02:15:20.200306: step 6417, loss = 0.67874 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:15:21.489613 ops/training.py:65 2019-01-17 02:15:21.489542: step 6418, loss = 0.68112 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:15:22.774161 ops/training.py:65 2019-01-17 02:15:22.774095: step 6419, loss = 0.70726 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:15:24.062927 ops/training.py:65 2019-01-17 02:15:24.062826: step 6420, loss = 0.70382 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:15:25.352389 ops/training.py:65 2019-01-17 02:15:25.352304: step 6421, loss = 0.68319 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:15:26.637752 ops/training.py:65 2019-01-17 02:15:26.637687: step 6422, loss = 0.70487 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:15:27.921341 ops/training.py:65 2019-01-17 02:15:27.921244: step 6423, loss = 0.66918 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 02:15:29.204514 ops/training.py:65 2019-01-17 02:15:29.204426: step 6424, loss = 0.68291 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:15:30.496955 ops/training.py:65 2019-01-17 02:15:30.496853: step 6425, loss = 0.70238 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:15:31.788154 ops/training.py:65 2019-01-17 02:15:31.788064: step 6426, loss = 0.68668 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:15:33.076259 ops/training.py:65 2019-01-17 02:15:33.076185: step 6427, loss = 0.67231 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:15:34.362737 ops/training.py:65 2019-01-17 02:15:34.362664: step 6428, loss = 0.66926 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:15:35.647841 ops/training.py:65 2019-01-17 02:15:35.647783: step 6429, loss = 0.66477 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:15:36.931445 ops/training.py:65 2019-01-17 02:15:36.931356: step 6430, loss = 0.70880 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:15:38.221410 ops/training.py:65 2019-01-17 02:15:38.221304: step 6431, loss = 0.71206 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:15:39.510390 ops/training.py:65 2019-01-17 02:15:39.510308: step 6432, loss = 0.64907 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:15:40.799262 ops/training.py:65 2019-01-17 02:15:40.799197: step 6433, loss = 0.70954 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:15:42.095194 ops/training.py:65 2019-01-17 02:15:42.095123: step 6434, loss = 0.70753 (24.7 examples/sec; 1.295 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:15:43.380468 ops/training.py:65 2019-01-17 02:15:43.380403: step 6435, loss = 0.67907 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:15:44.663157 ops/training.py:65 2019-01-17 02:15:44.663085: step 6436, loss = 0.68224 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:15:45.947576 ops/training.py:65 2019-01-17 02:15:45.947476: step 6437, loss = 0.70285 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:15:47.235952 ops/training.py:65 2019-01-17 02:15:47.235843: step 6438, loss = 0.72119 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:15:48.519524 ops/training.py:65 2019-01-17 02:15:48.519416: step 6439, loss = 0.68905 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:15:49.804112 ops/training.py:65 2019-01-17 02:15:49.804008: step 6440, loss = 0.72005 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:15:51.086517 ops/training.py:65 2019-01-17 02:15:51.086414: step 6441, loss = 0.64784 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:15:52.379674 ops/training.py:65 2019-01-17 02:15:52.379571: step 6442, loss = 0.68972 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:15:53.666801 ops/training.py:65 2019-01-17 02:15:53.666725: step 6443, loss = 0.69559 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:15:54.952485 ops/training.py:65 2019-01-17 02:15:54.952383: step 6444, loss = 0.71278 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:15:56.239194 ops/training.py:65 2019-01-17 02:15:56.239090: step 6445, loss = 0.71614 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:15:57.519109 ops/training.py:65 2019-01-17 02:15:57.519001: step 6446, loss = 0.68535 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:15:58.806469 ops/training.py:65 2019-01-17 02:15:58.806370: step 6447, loss = 0.68506 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:16:00.092116 ops/training.py:65 2019-01-17 02:16:00.092012: step 6448, loss = 0.66988 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:16:01.379216 ops/training.py:65 2019-01-17 02:16:01.379107: step 6449, loss = 0.70127 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:16:02.663356 ops/training.py:65 2019-01-17 02:16:02.663200: step 6450, loss = 0.68765 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:16:03.953978 ops/training.py:65 2019-01-17 02:16:03.953875: step 6451, loss = 0.74385 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:16:05.241152 ops/training.py:65 2019-01-17 02:16:05.241059: step 6452, loss = 0.69121 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:16:06.528358 ops/training.py:65 2019-01-17 02:16:06.528265: step 6453, loss = 0.68276 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:16:07.815216 ops/training.py:65 2019-01-17 02:16:07.815118: step 6454, loss = 0.72867 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:16:09.108709 ops/training.py:65 2019-01-17 02:16:09.108602: step 6455, loss = 0.74546 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:16:10.396816 ops/training.py:65 2019-01-17 02:16:10.396744: step 6456, loss = 0.70100 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:16:11.682462 ops/training.py:65 2019-01-17 02:16:11.682374: step 6457, loss = 0.71951 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:16:12.966151 ops/training.py:65 2019-01-17 02:16:12.966086: step 6458, loss = 0.67517 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:16:14.246184 ops/training.py:65 2019-01-17 02:16:14.246091: step 6459, loss = 0.67527 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:16:15.528885 ops/training.py:65 2019-01-17 02:16:15.528786: step 6460, loss = 0.68491 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:16:16.813283 ops/training.py:65 2019-01-17 02:16:16.813176: step 6461, loss = 0.69293 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:16:18.106447 ops/training.py:65 2019-01-17 02:16:18.106338: step 6462, loss = 0.71851 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:16:19.392461 ops/training.py:65 2019-01-17 02:16:19.392392: step 6463, loss = 0.70376 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:16:20.677859 ops/training.py:65 2019-01-17 02:16:20.677758: step 6464, loss = 0.67134 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:16:21.966522 ops/training.py:65 2019-01-17 02:16:21.966421: step 6465, loss = 0.68981 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:16:23.251477 ops/training.py:65 2019-01-17 02:16:23.251375: step 6466, loss = 0.65392 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:16:24.543849 ops/training.py:65 2019-01-17 02:16:24.543745: step 6467, loss = 0.71548 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:16:25.831285 ops/training.py:65 2019-01-17 02:16:25.831223: step 6468, loss = 0.62673 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 02:16:27.116423 ops/training.py:65 2019-01-17 02:16:27.116317: step 6469, loss = 0.68831 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:16:28.402816 ops/training.py:65 2019-01-17 02:16:28.402755: step 6470, loss = 0.69495 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:16:29.689815 ops/training.py:65 2019-01-17 02:16:29.689663: step 6471, loss = 0.64683 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:16:30.982579 ops/training.py:65 2019-01-17 02:16:30.982471: step 6472, loss = 0.69777 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:16:32.273579 ops/training.py:65 2019-01-17 02:16:32.273498: step 6473, loss = 0.63091 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:16:33.558199 ops/training.py:65 2019-01-17 02:16:33.558134: step 6474, loss = 0.67236 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:16:34.842678 ops/training.py:65 2019-01-17 02:16:34.842574: step 6475, loss = 0.71739 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:16:36.134735 ops/training.py:65 2019-01-17 02:16:36.134583: step 6476, loss = 0.66408 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:16:37.423693 ops/training.py:65 2019-01-17 02:16:37.423607: step 6477, loss = 0.71710 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:16:38.709017 ops/training.py:65 2019-01-17 02:16:38.708936: step 6478, loss = 0.69486 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:16:39.989424 ops/training.py:65 2019-01-17 02:16:39.989313: step 6479, loss = 0.70957 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:16:41.275633 ops/training.py:65 2019-01-17 02:16:41.275522: step 6480, loss = 0.71330 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:16:42.562167 ops/training.py:65 2019-01-17 02:16:42.562060: step 6481, loss = 0.69569 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:16:43.854666 ops/training.py:65 2019-01-17 02:16:43.854578: step 6482, loss = 0.69288 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:16:45.142337 ops/training.py:65 2019-01-17 02:16:45.142247: step 6483, loss = 0.73039 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:16:46.429088 ops/training.py:65 2019-01-17 02:16:46.429021: step 6484, loss = 0.67415 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:16:47.717858 ops/training.py:65 2019-01-17 02:16:47.717796: step 6485, loss = 0.69431 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:16:49.007464 ops/training.py:65 2019-01-17 02:16:49.007399: step 6486, loss = 0.69903 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:16:50.296353 ops/training.py:65 2019-01-17 02:16:50.296265: step 6487, loss = 0.66233 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:16:51.579400 ops/training.py:65 2019-01-17 02:16:51.579322: step 6488, loss = 0.66340 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:16:52.865640 ops/training.py:65 2019-01-17 02:16:52.865540: step 6489, loss = 0.73487 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:16:54.152859 ops/training.py:65 2019-01-17 02:16:54.152756: step 6490, loss = 0.66417 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:16:55.444904 ops/training.py:65 2019-01-17 02:16:55.444749: step 6491, loss = 0.71342 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:16:56.736941 ops/training.py:65 2019-01-17 02:16:56.736870: step 6492, loss = 0.67729 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:16:58.024734 ops/training.py:65 2019-01-17 02:16:58.024645: step 6493, loss = 0.68292 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:16:59.309169 ops/training.py:65 2019-01-17 02:16:59.309104: step 6494, loss = 0.72632 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:17:00.594854 ops/training.py:65 2019-01-17 02:17:00.594757: step 6495, loss = 0.66251 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:17:01.885477 ops/training.py:65 2019-01-17 02:17:01.885375: step 6496, loss = 0.70371 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:17:03.175844 ops/training.py:65 2019-01-17 02:17:03.175776: step 6497, loss = 0.68623 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:17:04.460707 ops/training.py:65 2019-01-17 02:17:04.460639: step 6498, loss = 0.67149 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:17:05.747431 ops/training.py:65 2019-01-17 02:17:05.747371: step 6499, loss = 0.72472 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:17:07.035202 ops/training.py:65 2019-01-17 02:17:07.035114: step 6500, loss = 0.66817 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:17:08.324789 ops/training.py:65 2019-01-17 02:17:08.324728: step 6501, loss = 0.74825 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:17:09.610377 ops/training.py:65 2019-01-17 02:17:09.610309: step 6502, loss = 0.66927 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:17:10.899844 ops/training.py:65 2019-01-17 02:17:10.899776: step 6503, loss = 0.71125 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:17:12.183668 ops/training.py:65 2019-01-17 02:17:12.183601: step 6504, loss = 0.71436 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:17:13.470853 ops/training.py:65 2019-01-17 02:17:13.470758: step 6505, loss = 0.70362 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:17:14.764463 ops/training.py:65 2019-01-17 02:17:14.764355: step 6506, loss = 0.71472 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:17:16.062141 ops/training.py:65 2019-01-17 02:17:16.062070: step 6507, loss = 0.68133 (24.7 examples/sec; 1.296 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:17:17.347482 ops/training.py:65 2019-01-17 02:17:17.347412: step 6508, loss = 0.69649 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:17:18.635452 ops/training.py:65 2019-01-17 02:17:18.635378: step 6509, loss = 0.65736 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:17:19.918651 ops/training.py:65 2019-01-17 02:17:19.918588: step 6510, loss = 0.64943 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:17:21.204855 ops/training.py:65 2019-01-17 02:17:21.204745: step 6511, loss = 0.69223 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:17:22.497328 ops/training.py:65 2019-01-17 02:17:22.497224: step 6512, loss = 0.70316 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:17:23.787207 ops/training.py:65 2019-01-17 02:17:23.787142: step 6513, loss = 0.71454 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:17:25.081654 ops/training.py:65 2019-01-17 02:17:25.081574: step 6514, loss = 0.67434 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:17:26.371679 ops/training.py:65 2019-01-17 02:17:26.371608: step 6515, loss = 0.67823 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:17:27.656149 ops/training.py:65 2019-01-17 02:17:27.656086: step 6516, loss = 0.70964 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:17:28.946160 ops/training.py:65 2019-01-17 02:17:28.946092: step 6517, loss = 0.67148 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:17:30.236054 ops/training.py:65 2019-01-17 02:17:30.235985: step 6518, loss = 0.76180 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 02:17:31.522334 ops/training.py:65 2019-01-17 02:17:31.522264: step 6519, loss = 0.68681 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:17:32.811215 ops/training.py:65 2019-01-17 02:17:32.811147: step 6520, loss = 0.70114 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:17:34.094567 ops/training.py:65 2019-01-17 02:17:34.094500: step 6521, loss = 0.67845 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:17:35.375797 ops/training.py:65 2019-01-17 02:17:35.375691: step 6522, loss = 0.76009 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:17:36.661201 ops/training.py:65 2019-01-17 02:17:36.661093: step 6523, loss = 0.74107 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:17:37.951640 ops/training.py:65 2019-01-17 02:17:37.951541: step 6524, loss = 0.73678 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:17:39.239430 ops/training.py:65 2019-01-17 02:17:39.239365: step 6525, loss = 0.70916 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:17:40.524359 ops/training.py:65 2019-01-17 02:17:40.524296: step 6526, loss = 0.70883 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:17:41.809602 ops/training.py:65 2019-01-17 02:17:41.809491: step 6527, loss = 0.68703 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:17:43.103250 ops/training.py:65 2019-01-17 02:17:43.103154: step 6528, loss = 0.69107 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:17:44.395599 ops/training.py:65 2019-01-17 02:17:44.395523: step 6529, loss = 0.67122 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:17:45.681563 ops/training.py:65 2019-01-17 02:17:45.681503: step 6530, loss = 0.66589 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:17:46.970942 ops/training.py:65 2019-01-17 02:17:46.970853: step 6531, loss = 0.70145 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:17:48.254495 ops/training.py:65 2019-01-17 02:17:48.254432: step 6532, loss = 0.69728 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:17:49.543120 ops/training.py:65 2019-01-17 02:17:49.543045: step 6533, loss = 0.67248 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:17:50.832158 ops/training.py:65 2019-01-17 02:17:50.832069: step 6534, loss = 0.69913 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:17:52.122073 ops/training.py:65 2019-01-17 02:17:52.121993: step 6535, loss = 0.67479 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:17:53.410346 ops/training.py:65 2019-01-17 02:17:53.410280: step 6536, loss = 0.66022 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:17:54.699165 ops/training.py:65 2019-01-17 02:17:54.699080: step 6537, loss = 0.69300 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:17:55.986980 ops/training.py:65 2019-01-17 02:17:55.986890: step 6538, loss = 0.71007 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:17:57.268084 ops/training.py:65 2019-01-17 02:17:57.268023: step 6539, loss = 0.70125 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:17:58.553046 ops/training.py:65 2019-01-17 02:17:58.552945: step 6540, loss = 0.68770 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:17:59.838481 ops/training.py:65 2019-01-17 02:17:59.838372: step 6541, loss = 0.67140 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:18:01.121369 ops/training.py:65 2019-01-17 02:18:01.121291: step 6542, loss = 0.69015 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:18:02.413469 ops/training.py:65 2019-01-17 02:18:02.413316: step 6543, loss = 0.71111 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:18:03.699244 ops/training.py:65 2019-01-17 02:18:03.699173: step 6544, loss = 0.67929 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:18:04.983351 ops/training.py:65 2019-01-17 02:18:04.983286: step 6545, loss = 0.67885 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:18:06.262692 ops/training.py:65 2019-01-17 02:18:06.262577: step 6546, loss = 0.68132 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:18:07.544150 ops/training.py:65 2019-01-17 02:18:07.544036: step 6547, loss = 0.67688 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:18:08.830761 ops/training.py:65 2019-01-17 02:18:08.830647: step 6548, loss = 0.70906 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:18:10.116721 ops/training.py:65 2019-01-17 02:18:10.116613: step 6549, loss = 0.69293 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:18:11.402052 ops/training.py:65 2019-01-17 02:18:11.401951: step 6550, loss = 0.67172 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:18:12.687945 ops/training.py:65 2019-01-17 02:18:12.687838: step 6551, loss = 0.70121 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:18:13.973852 ops/training.py:65 2019-01-17 02:18:13.973757: step 6552, loss = 0.66573 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:18:15.265589 ops/training.py:65 2019-01-17 02:18:15.265488: step 6553, loss = 0.68654 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:18:16.555523 ops/training.py:65 2019-01-17 02:18:16.555439: step 6554, loss = 0.68616 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:18:17.837989 ops/training.py:65 2019-01-17 02:18:17.837915: step 6555, loss = 0.68791 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:18:19.123950 ops/training.py:65 2019-01-17 02:18:19.123840: step 6556, loss = 0.73818 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:18:20.422770 ops/training.py:65 2019-01-17 02:18:20.422669: step 6557, loss = 0.71771 (24.7 examples/sec; 1.297 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:18:21.703940 ops/training.py:65 2019-01-17 02:18:21.703854: step 6558, loss = 0.71998 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:18:22.990821 ops/training.py:65 2019-01-17 02:18:22.990712: step 6559, loss = 0.71753 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:18:24.276408 ops/training.py:65 2019-01-17 02:18:24.276306: step 6560, loss = 0.67990 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:18:25.562951 ops/training.py:65 2019-01-17 02:18:25.562838: step 6561, loss = 0.70084 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:18:26.849212 ops/training.py:65 2019-01-17 02:18:26.849134: step 6562, loss = 0.70970 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:18:28.141962 ops/training.py:65 2019-01-17 02:18:28.141855: step 6563, loss = 0.68556 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:18:29.426636 ops/training.py:65 2019-01-17 02:18:29.426565: step 6564, loss = 0.68284 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:18:30.710308 ops/training.py:65 2019-01-17 02:18:30.710199: step 6565, loss = 0.79895 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.25
I4672 2019-01-17 02:18:31.994094 ops/training.py:65 2019-01-17 02:18:31.993991: step 6566, loss = 0.69634 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:18:33.273615 ops/training.py:65 2019-01-17 02:18:33.273523: step 6567, loss = 0.68481 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:18:34.560123 ops/training.py:65 2019-01-17 02:18:34.560022: step 6568, loss = 0.66107 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:18:35.844134 ops/training.py:65 2019-01-17 02:18:35.844024: step 6569, loss = 0.73053 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:18:37.130606 ops/training.py:65 2019-01-17 02:18:37.130491: step 6570, loss = 0.64647 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:18:38.414727 ops/training.py:65 2019-01-17 02:18:38.414617: step 6571, loss = 0.65848 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:18:39.708989 ops/training.py:65 2019-01-17 02:18:39.708873: step 6572, loss = 0.67127 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:18:40.994966 ops/training.py:65 2019-01-17 02:18:40.994891: step 6573, loss = 0.65775 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:18:42.284863 ops/training.py:65 2019-01-17 02:18:42.284762: step 6574, loss = 0.69200 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:18:43.569625 ops/training.py:65 2019-01-17 02:18:43.569535: step 6575, loss = 0.69721 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:18:44.856400 ops/training.py:65 2019-01-17 02:18:44.856292: step 6576, loss = 0.71528 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:18:46.141699 ops/training.py:65 2019-01-17 02:18:46.141594: step 6577, loss = 0.68612 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:18:47.435072 ops/training.py:65 2019-01-17 02:18:47.434974: step 6578, loss = 0.71561 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:18:48.717144 ops/training.py:65 2019-01-17 02:18:48.717083: step 6579, loss = 0.69870 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:18:50.001305 ops/training.py:65 2019-01-17 02:18:50.001198: step 6580, loss = 0.70417 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:18:51.288585 ops/training.py:65 2019-01-17 02:18:51.288471: step 6581, loss = 0.67498 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:18:52.574193 ops/training.py:65 2019-01-17 02:18:52.574084: step 6582, loss = 0.76078 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:18:53.866199 ops/training.py:65 2019-01-17 02:18:53.866094: step 6583, loss = 0.71692 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:18:55.157255 ops/training.py:65 2019-01-17 02:18:55.157188: step 6584, loss = 0.69137 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:18:56.446741 ops/training.py:65 2019-01-17 02:18:56.446671: step 6585, loss = 0.72425 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:18:57.735431 ops/training.py:65 2019-01-17 02:18:57.735365: step 6586, loss = 0.71802 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:18:59.022983 ops/training.py:65 2019-01-17 02:18:59.022890: step 6587, loss = 0.68173 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:19:00.312003 ops/training.py:65 2019-01-17 02:19:00.311935: step 6588, loss = 0.70923 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:19:01.595400 ops/training.py:65 2019-01-17 02:19:01.595324: step 6589, loss = 0.72579 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:19:02.879564 ops/training.py:65 2019-01-17 02:19:02.879462: step 6590, loss = 0.67761 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:19:04.160271 ops/training.py:65 2019-01-17 02:19:04.160175: step 6591, loss = 0.73714 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:19:05.446080 ops/training.py:65 2019-01-17 02:19:05.445973: step 6592, loss = 0.65763 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:19:06.737425 ops/training.py:65 2019-01-17 02:19:06.737314: step 6593, loss = 0.70078 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:19:08.027771 ops/training.py:65 2019-01-17 02:19:08.027696: step 6594, loss = 0.72253 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:19:09.312145 ops/training.py:65 2019-01-17 02:19:09.312073: step 6595, loss = 0.69590 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:19:10.597325 ops/training.py:65 2019-01-17 02:19:10.597250: step 6596, loss = 0.69659 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:19:11.887325 ops/training.py:65 2019-01-17 02:19:11.887256: step 6597, loss = 0.66898 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:19:13.170078 ops/training.py:65 2019-01-17 02:19:13.170008: step 6598, loss = 0.69042 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:19:14.454602 ops/training.py:65 2019-01-17 02:19:14.454530: step 6599, loss = 0.66115 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:19:15.740807 ops/training.py:65 2019-01-17 02:19:15.740707: step 6600, loss = 0.65679 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:19:17.029211 ops/training.py:65 2019-01-17 02:19:17.029100: step 6601, loss = 0.72134 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:19:18.311431 ops/training.py:65 2019-01-17 02:19:18.311326: step 6602, loss = 0.67993 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:19:19.597538 ops/training.py:65 2019-01-17 02:19:19.597440: step 6603, loss = 0.69737 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:19:20.888839 ops/training.py:65 2019-01-17 02:19:20.888686: step 6604, loss = 0.70822 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:19:22.174902 ops/training.py:65 2019-01-17 02:19:22.174817: step 6605, loss = 0.68525 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:19:23.461709 ops/training.py:65 2019-01-17 02:19:23.461606: step 6606, loss = 0.67427 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:19:24.748956 ops/training.py:65 2019-01-17 02:19:24.748798: step 6607, loss = 0.67339 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:19:26.035502 ops/training.py:65 2019-01-17 02:19:26.035344: step 6608, loss = 0.67346 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:19:27.323237 ops/training.py:65 2019-01-17 02:19:27.323128: step 6609, loss = 0.71384 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:19:28.605137 ops/training.py:65 2019-01-17 02:19:28.605048: step 6610, loss = 0.69443 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:19:29.896202 ops/training.py:65 2019-01-17 02:19:29.896097: step 6611, loss = 0.68153 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:19:31.186139 ops/training.py:65 2019-01-17 02:19:31.186063: step 6612, loss = 0.65765 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:19:32.472247 ops/training.py:65 2019-01-17 02:19:32.472166: step 6613, loss = 0.67959 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:19:33.763828 ops/training.py:65 2019-01-17 02:19:33.763730: step 6614, loss = 0.73665 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:19:35.050994 ops/training.py:65 2019-01-17 02:19:35.050936: step 6615, loss = 0.70226 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:19:36.337441 ops/training.py:65 2019-01-17 02:19:36.337339: step 6616, loss = 0.70858 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:19:37.625783 ops/training.py:65 2019-01-17 02:19:37.625675: step 6617, loss = 0.68141 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:19:38.911053 ops/training.py:65 2019-01-17 02:19:38.910945: step 6618, loss = 0.69595 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:19:40.198396 ops/training.py:65 2019-01-17 02:19:40.198294: step 6619, loss = 0.71319 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:19:41.485559 ops/training.py:65 2019-01-17 02:19:41.485497: step 6620, loss = 0.70589 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:19:42.773357 ops/training.py:65 2019-01-17 02:19:42.773292: step 6621, loss = 0.70776 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:19:44.059355 ops/training.py:65 2019-01-17 02:19:44.059289: step 6622, loss = 0.70443 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:19:45.340805 ops/training.py:65 2019-01-17 02:19:45.340730: step 6623, loss = 0.66720 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:19:46.626392 ops/training.py:65 2019-01-17 02:19:46.626288: step 6624, loss = 0.70789 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:19:47.911207 ops/training.py:65 2019-01-17 02:19:47.911106: step 6625, loss = 0.68159 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:19:49.203509 ops/training.py:65 2019-01-17 02:19:49.203409: step 6626, loss = 0.72532 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:19:50.493173 ops/training.py:65 2019-01-17 02:19:50.493112: step 6627, loss = 0.69160 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:19:51.773082 ops/training.py:65 2019-01-17 02:19:51.773024: step 6628, loss = 0.68362 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:19:53.054471 ops/training.py:65 2019-01-17 02:19:53.054400: step 6629, loss = 0.70174 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:19:54.338891 ops/training.py:65 2019-01-17 02:19:54.338786: step 6630, loss = 0.67355 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:19:55.625865 ops/training.py:65 2019-01-17 02:19:55.625763: step 6631, loss = 0.69624 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:19:56.909578 ops/training.py:65 2019-01-17 02:19:56.909496: step 6632, loss = 0.69455 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:19:58.199298 ops/training.py:65 2019-01-17 02:19:58.199189: step 6633, loss = 0.72665 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:19:59.485849 ops/training.py:65 2019-01-17 02:19:59.485775: step 6634, loss = 0.67980 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:20:00.765846 ops/training.py:65 2019-01-17 02:20:00.765737: step 6635, loss = 0.66307 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:20:02.062288 ops/training.py:65 2019-01-17 02:20:02.062193: step 6636, loss = 0.70172 (24.7 examples/sec; 1.295 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:20:03.346039 ops/training.py:65 2019-01-17 02:20:03.345965: step 6637, loss = 0.69441 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:20:04.638222 ops/training.py:65 2019-01-17 02:20:04.638123: step 6638, loss = 0.72779 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:20:05.927528 ops/training.py:65 2019-01-17 02:20:05.927432: step 6639, loss = 0.66974 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:20:07.215128 ops/training.py:65 2019-01-17 02:20:07.215060: step 6640, loss = 0.70446 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:20:08.502992 ops/training.py:65 2019-01-17 02:20:08.502902: step 6641, loss = 0.65676 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:20:09.792705 ops/training.py:65 2019-01-17 02:20:09.792613: step 6642, loss = 0.70066 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:20:11.077117 ops/training.py:65 2019-01-17 02:20:11.077040: step 6643, loss = 0.67804 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:20:12.360237 ops/training.py:65 2019-01-17 02:20:12.360129: step 6644, loss = 0.67217 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:20:13.652190 ops/training.py:65 2019-01-17 02:20:13.652094: step 6645, loss = 0.68749 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:20:14.943454 ops/training.py:65 2019-01-17 02:20:14.943358: step 6646, loss = 0.68396 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:20:16.228417 ops/training.py:65 2019-01-17 02:20:16.228354: step 6647, loss = 0.68089 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:20:17.513162 ops/training.py:65 2019-01-17 02:20:17.513104: step 6648, loss = 0.69860 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:20:18.801844 ops/training.py:65 2019-01-17 02:20:18.801733: step 6649, loss = 0.72350 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:20:20.092227 ops/training.py:65 2019-01-17 02:20:20.092157: step 6650, loss = 0.69056 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:20:21.381159 ops/training.py:65 2019-01-17 02:20:21.381071: step 6651, loss = 0.64961 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:20:22.671773 ops/training.py:65 2019-01-17 02:20:22.671701: step 6652, loss = 0.68576 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:20:23.960925 ops/training.py:65 2019-01-17 02:20:23.960854: step 6653, loss = 0.66352 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:20:25.246463 ops/training.py:65 2019-01-17 02:20:25.246387: step 6654, loss = 0.65962 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:20:26.530889 ops/training.py:65 2019-01-17 02:20:26.530776: step 6655, loss = 0.71694 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:20:27.814079 ops/training.py:65 2019-01-17 02:20:27.813996: step 6656, loss = 0.71882 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:20:29.097452 ops/training.py:65 2019-01-17 02:20:29.097355: step 6657, loss = 0.66105 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:20:30.385036 ops/training.py:65 2019-01-17 02:20:30.384938: step 6658, loss = 0.70235 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:20:31.669259 ops/training.py:65 2019-01-17 02:20:31.669179: step 6659, loss = 0.71183 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:20:32.961249 ops/training.py:65 2019-01-17 02:20:32.961092: step 6660, loss = 0.73000 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:20:34.246460 ops/training.py:65 2019-01-17 02:20:34.246393: step 6661, loss = 0.66019 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:20:35.529842 ops/training.py:65 2019-01-17 02:20:35.529744: step 6662, loss = 0.67652 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:20:36.821183 ops/training.py:65 2019-01-17 02:20:36.821076: step 6663, loss = 0.71828 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:20:38.108606 ops/training.py:65 2019-01-17 02:20:38.108540: step 6664, loss = 0.68504 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:20:39.391290 ops/training.py:65 2019-01-17 02:20:39.391207: step 6665, loss = 0.68860 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:20:40.679270 ops/training.py:65 2019-01-17 02:20:40.679161: step 6666, loss = 0.68903 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:20:41.959422 ops/training.py:65 2019-01-17 02:20:41.959314: step 6667, loss = 0.67337 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:20:43.246656 ops/training.py:65 2019-01-17 02:20:43.246551: step 6668, loss = 0.71505 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:20:44.533614 ops/training.py:65 2019-01-17 02:20:44.533524: step 6669, loss = 0.68192 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:20:45.824450 ops/training.py:65 2019-01-17 02:20:45.824339: step 6670, loss = 0.70803 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:20:47.109648 ops/training.py:65 2019-01-17 02:20:47.109578: step 6671, loss = 0.65945 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:20:48.389689 ops/training.py:65 2019-01-17 02:20:48.389594: step 6672, loss = 0.69789 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:20:49.675669 ops/training.py:65 2019-01-17 02:20:49.675568: step 6673, loss = 0.65582 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:20:50.960350 ops/training.py:65 2019-01-17 02:20:50.960247: step 6674, loss = 0.69154 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:20:52.246197 ops/training.py:65 2019-01-17 02:20:52.246096: step 6675, loss = 0.70295 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:20:53.528219 ops/training.py:65 2019-01-17 02:20:53.528120: step 6676, loss = 0.67267 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:20:54.813066 ops/training.py:65 2019-01-17 02:20:54.812965: step 6677, loss = 0.71921 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:20:56.105428 ops/training.py:65 2019-01-17 02:20:56.105272: step 6678, loss = 0.67466 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:20:57.397932 ops/training.py:65 2019-01-17 02:20:57.397866: step 6679, loss = 0.72426 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:20:58.682538 ops/training.py:65 2019-01-17 02:20:58.682462: step 6680, loss = 0.66207 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:20:59.963719 ops/training.py:65 2019-01-17 02:20:59.963614: step 6681, loss = 0.67361 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:21:01.247758 ops/training.py:65 2019-01-17 02:21:01.247646: step 6682, loss = 0.65512 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:21:02.534332 ops/training.py:65 2019-01-17 02:21:02.534232: step 6683, loss = 0.67646 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:21:03.821131 ops/training.py:65 2019-01-17 02:21:03.821032: step 6684, loss = 0.69260 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:21:05.105806 ops/training.py:65 2019-01-17 02:21:05.105698: step 6685, loss = 0.67630 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:21:06.397924 ops/training.py:65 2019-01-17 02:21:06.397814: step 6686, loss = 0.68350 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:21:07.688852 ops/training.py:65 2019-01-17 02:21:07.688784: step 6687, loss = 0.69060 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:21:08.974626 ops/training.py:65 2019-01-17 02:21:08.974561: step 6688, loss = 0.65808 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:21:10.259804 ops/training.py:65 2019-01-17 02:21:10.259702: step 6689, loss = 0.72978 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:21:11.550279 ops/training.py:65 2019-01-17 02:21:11.550181: step 6690, loss = 0.70133 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:21:12.839976 ops/training.py:65 2019-01-17 02:21:12.839900: step 6691, loss = 0.71793 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:21:14.122606 ops/training.py:65 2019-01-17 02:21:14.122539: step 6692, loss = 0.63388 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 02:21:15.407912 ops/training.py:65 2019-01-17 02:21:15.407804: step 6693, loss = 0.63947 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:21:16.690022 ops/training.py:65 2019-01-17 02:21:16.689920: step 6694, loss = 0.71914 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:21:17.980908 ops/training.py:65 2019-01-17 02:21:17.980807: step 6695, loss = 0.70586 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:21:19.269778 ops/training.py:65 2019-01-17 02:21:19.269713: step 6696, loss = 0.67290 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:21:20.552944 ops/training.py:65 2019-01-17 02:21:20.552869: step 6697, loss = 0.67154 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:21:21.837474 ops/training.py:65 2019-01-17 02:21:21.837371: step 6698, loss = 0.68573 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:21:23.118116 ops/training.py:65 2019-01-17 02:21:23.118021: step 6699, loss = 0.68419 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:21:24.409385 ops/training.py:65 2019-01-17 02:21:24.409247: step 6700, loss = 0.72557 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:21:25.698834 ops/training.py:65 2019-01-17 02:21:25.698765: step 6701, loss = 0.67186 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:21:26.986353 ops/training.py:65 2019-01-17 02:21:26.986289: step 6702, loss = 0.69251 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:21:28.273969 ops/training.py:65 2019-01-17 02:21:28.273904: step 6703, loss = 0.69180 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:21:29.561953 ops/training.py:65 2019-01-17 02:21:29.561887: step 6704, loss = 0.66245 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:21:30.856104 ops/training.py:65 2019-01-17 02:21:30.856031: step 6705, loss = 0.71295 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:21:32.144737 ops/training.py:65 2019-01-17 02:21:32.144669: step 6706, loss = 0.69993 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:21:33.432745 ops/training.py:65 2019-01-17 02:21:33.432677: step 6707, loss = 0.75177 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-17 02:21:34.721025 ops/training.py:65 2019-01-17 02:21:34.720952: step 6708, loss = 0.66290 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:21:36.004675 ops/training.py:65 2019-01-17 02:21:36.004612: step 6709, loss = 0.63156 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:21:37.294051 ops/training.py:65 2019-01-17 02:21:37.293989: step 6710, loss = 0.69292 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:21:38.581298 ops/training.py:65 2019-01-17 02:21:38.581225: step 6711, loss = 0.67370 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:21:39.868266 ops/training.py:65 2019-01-17 02:21:39.868195: step 6712, loss = 0.70414 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:21:41.158168 ops/training.py:65 2019-01-17 02:21:41.158098: step 6713, loss = 0.75092 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:21:42.446641 ops/training.py:65 2019-01-17 02:21:42.446569: step 6714, loss = 0.68514 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:21:43.737455 ops/training.py:65 2019-01-17 02:21:43.737383: step 6715, loss = 0.65849 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:21:45.027346 ops/training.py:65 2019-01-17 02:21:45.027269: step 6716, loss = 0.68510 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:21:46.316429 ops/training.py:65 2019-01-17 02:21:46.316365: step 6717, loss = 0.72370 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:21:47.604327 ops/training.py:65 2019-01-17 02:21:47.604259: step 6718, loss = 0.64484 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:21:48.889435 ops/training.py:65 2019-01-17 02:21:48.889372: step 6719, loss = 0.68444 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:21:50.171952 ops/training.py:65 2019-01-17 02:21:50.171881: step 6720, loss = 0.67738 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:21:51.457733 ops/training.py:65 2019-01-17 02:21:51.457623: step 6721, loss = 0.68427 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:21:52.737988 ops/training.py:65 2019-01-17 02:21:52.737882: step 6722, loss = 0.65456 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:21:54.028704 ops/training.py:65 2019-01-17 02:21:54.028612: step 6723, loss = 0.71961 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:21:55.315392 ops/training.py:65 2019-01-17 02:21:55.315320: step 6724, loss = 0.70340 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:21:56.598243 ops/training.py:65 2019-01-17 02:21:56.598146: step 6725, loss = 0.70268 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:21:57.889952 ops/training.py:65 2019-01-17 02:21:57.889846: step 6726, loss = 0.70933 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:21:59.181735 ops/training.py:65 2019-01-17 02:21:59.181669: step 6727, loss = 0.71978 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:22:00.477644 ops/training.py:65 2019-01-17 02:22:00.477579: step 6728, loss = 0.66968 (24.7 examples/sec; 1.295 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:22:01.767242 ops/training.py:65 2019-01-17 02:22:01.767172: step 6729, loss = 0.66450 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:22:03.056098 ops/training.py:65 2019-01-17 02:22:03.056007: step 6730, loss = 0.69425 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:22:04.345320 ops/training.py:65 2019-01-17 02:22:04.345239: step 6731, loss = 0.69256 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:22:05.634386 ops/training.py:65 2019-01-17 02:22:05.634309: step 6732, loss = 0.66292 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:22:06.917920 ops/training.py:65 2019-01-17 02:22:06.917845: step 6733, loss = 0.71911 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:22:08.211514 ops/training.py:65 2019-01-17 02:22:08.211407: step 6734, loss = 0.69219 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:22:09.501568 ops/training.py:65 2019-01-17 02:22:09.501497: step 6735, loss = 0.69779 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:22:10.786287 ops/training.py:65 2019-01-17 02:22:10.786224: step 6736, loss = 0.67624 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:22:12.074771 ops/training.py:65 2019-01-17 02:22:12.074662: step 6737, loss = 0.70107 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:22:13.365279 ops/training.py:65 2019-01-17 02:22:13.365135: step 6738, loss = 0.68912 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:22:14.652037 ops/training.py:65 2019-01-17 02:22:14.651968: step 6739, loss = 0.70392 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:22:15.940716 ops/training.py:65 2019-01-17 02:22:15.940606: step 6740, loss = 0.66189 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:22:17.227366 ops/training.py:65 2019-01-17 02:22:17.227302: step 6741, loss = 0.68003 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:22:18.515311 ops/training.py:65 2019-01-17 02:22:18.515248: step 6742, loss = 0.67062 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:22:19.804686 ops/training.py:65 2019-01-17 02:22:19.804613: step 6743, loss = 0.72018 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:22:21.094672 ops/training.py:65 2019-01-17 02:22:21.094608: step 6744, loss = 0.67179 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:22:22.383412 ops/training.py:65 2019-01-17 02:22:22.383342: step 6745, loss = 0.67675 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:22:23.667691 ops/training.py:65 2019-01-17 02:22:23.667622: step 6746, loss = 0.71443 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:22:24.956494 ops/training.py:65 2019-01-17 02:22:24.956385: step 6747, loss = 0.73141 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:22:26.251909 ops/training.py:65 2019-01-17 02:22:26.251844: step 6748, loss = 0.71089 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:22:27.536543 ops/training.py:65 2019-01-17 02:22:27.536465: step 6749, loss = 0.72678 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:22:28.825589 ops/training.py:65 2019-01-17 02:22:28.825447: step 6750, loss = 0.72916 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:22:30.116014 ops/training.py:65 2019-01-17 02:22:30.115939: step 6751, loss = 0.67849 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:22:31.399202 ops/training.py:65 2019-01-17 02:22:31.399128: step 6752, loss = 0.69019 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:22:32.691891 ops/training.py:65 2019-01-17 02:22:32.691737: step 6753, loss = 0.68463 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:22:33.982911 ops/training.py:65 2019-01-17 02:22:33.982832: step 6754, loss = 0.68672 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:22:35.272345 ops/training.py:65 2019-01-17 02:22:35.272277: step 6755, loss = 0.66786 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:22:36.560696 ops/training.py:65 2019-01-17 02:22:36.560617: step 6756, loss = 0.66880 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:22:37.848552 ops/training.py:65 2019-01-17 02:22:37.848451: step 6757, loss = 0.68702 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:22:39.135227 ops/training.py:65 2019-01-17 02:22:39.135150: step 6758, loss = 0.65649 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:22:40.423276 ops/training.py:65 2019-01-17 02:22:40.423167: step 6759, loss = 0.69330 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:22:41.713901 ops/training.py:65 2019-01-17 02:22:41.713822: step 6760, loss = 0.70438 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:22:43.003863 ops/training.py:65 2019-01-17 02:22:43.003788: step 6761, loss = 0.69011 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:22:44.285554 ops/training.py:65 2019-01-17 02:22:44.285482: step 6762, loss = 0.67249 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:22:45.572619 ops/training.py:65 2019-01-17 02:22:45.572509: step 6763, loss = 0.68306 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:22:46.860941 ops/training.py:65 2019-01-17 02:22:46.860860: step 6764, loss = 0.69838 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:22:48.150386 ops/training.py:65 2019-01-17 02:22:48.150313: step 6765, loss = 0.74184 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:22:49.439115 ops/training.py:65 2019-01-17 02:22:49.439025: step 6766, loss = 0.68683 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:22:50.728329 ops/training.py:65 2019-01-17 02:22:50.728235: step 6767, loss = 0.70948 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:22:52.015766 ops/training.py:65 2019-01-17 02:22:52.015696: step 6768, loss = 0.66846 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:22:53.304106 ops/training.py:65 2019-01-17 02:22:53.304032: step 6769, loss = 0.66075 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:22:54.586375 ops/training.py:65 2019-01-17 02:22:54.586311: step 6770, loss = 0.71406 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 02:22:55.874852 ops/training.py:65 2019-01-17 02:22:55.874762: step 6771, loss = 0.66361 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:22:57.164055 ops/training.py:65 2019-01-17 02:22:57.163988: step 6772, loss = 0.72626 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:22:58.453507 ops/training.py:65 2019-01-17 02:22:58.453416: step 6773, loss = 0.65446 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 02:22:59.747199 ops/training.py:65 2019-01-17 02:22:59.747100: step 6774, loss = 0.67023 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:23:01.033391 ops/training.py:65 2019-01-17 02:23:01.033317: step 6775, loss = 0.68023 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:23:02.321540 ops/training.py:65 2019-01-17 02:23:02.321440: step 6776, loss = 0.70314 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:23:03.610792 ops/training.py:65 2019-01-17 02:23:03.610724: step 6777, loss = 0.67148 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:23:04.896636 ops/training.py:65 2019-01-17 02:23:04.896547: step 6778, loss = 0.65310 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:23:06.187071 ops/training.py:65 2019-01-17 02:23:06.186977: step 6779, loss = 0.66882 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:23:07.476843 ops/training.py:65 2019-01-17 02:23:07.476779: step 6780, loss = 0.69319 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:23:08.765433 ops/training.py:65 2019-01-17 02:23:08.765369: step 6781, loss = 0.65720 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:23:10.052186 ops/training.py:65 2019-01-17 02:23:10.052111: step 6782, loss = 0.69592 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:23:11.336732 ops/training.py:65 2019-01-17 02:23:11.336667: step 6783, loss = 0.67257 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:23:12.624152 ops/training.py:65 2019-01-17 02:23:12.624080: step 6784, loss = 0.69150 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:23:13.907714 ops/training.py:65 2019-01-17 02:23:13.907624: step 6785, loss = 0.70138 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:23:15.188888 ops/training.py:65 2019-01-17 02:23:15.188808: step 6786, loss = 0.71140 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:23:16.469325 ops/training.py:65 2019-01-17 02:23:16.469222: step 6787, loss = 0.67135 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:23:17.762676 ops/training.py:65 2019-01-17 02:23:17.762563: step 6788, loss = 0.67648 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:23:19.053123 ops/training.py:65 2019-01-17 02:23:19.053046: step 6789, loss = 0.68600 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:23:20.336781 ops/training.py:65 2019-01-17 02:23:20.336712: step 6790, loss = 0.65949 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:23:21.624986 ops/training.py:65 2019-01-17 02:23:21.624900: step 6791, loss = 0.68908 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:23:22.905473 ops/training.py:65 2019-01-17 02:23:22.905401: step 6792, loss = 0.67736 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:23:24.196760 ops/training.py:65 2019-01-17 02:23:24.196666: step 6793, loss = 0.73454 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:23:25.483489 ops/training.py:65 2019-01-17 02:23:25.483421: step 6794, loss = 0.71106 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:23:26.767929 ops/training.py:65 2019-01-17 02:23:26.767828: step 6795, loss = 0.66647 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:23:28.059857 ops/training.py:65 2019-01-17 02:23:28.059696: step 6796, loss = 0.72383 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:23:29.348215 ops/training.py:65 2019-01-17 02:23:29.348143: step 6797, loss = 0.69982 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:23:30.637279 ops/training.py:65 2019-01-17 02:23:30.637118: step 6798, loss = 0.73039 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:23:31.928421 ops/training.py:65 2019-01-17 02:23:31.928344: step 6799, loss = 0.67713 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:23:33.211998 ops/training.py:65 2019-01-17 02:23:33.211901: step 6800, loss = 0.71125 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:23:34.495593 ops/training.py:65 2019-01-17 02:23:34.495514: step 6801, loss = 0.74288 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:23:35.783491 ops/training.py:65 2019-01-17 02:23:35.783383: step 6802, loss = 0.70153 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:23:37.070754 ops/training.py:65 2019-01-17 02:23:37.070651: step 6803, loss = 0.69114 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:23:38.350417 ops/training.py:65 2019-01-17 02:23:38.350307: step 6804, loss = 0.67634 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:23:39.642066 ops/training.py:65 2019-01-17 02:23:39.641919: step 6805, loss = 0.68851 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:23:40.929782 ops/training.py:65 2019-01-17 02:23:40.929705: step 6806, loss = 0.70440 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:23:42.213290 ops/training.py:65 2019-01-17 02:23:42.213180: step 6807, loss = 0.67862 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:23:43.504919 ops/training.py:65 2019-01-17 02:23:43.504822: step 6808, loss = 0.65184 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:23:44.790921 ops/training.py:65 2019-01-17 02:23:44.790851: step 6809, loss = 0.69778 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:23:46.079753 ops/training.py:65 2019-01-17 02:23:46.079687: step 6810, loss = 0.70656 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:23:47.360251 ops/training.py:65 2019-01-17 02:23:47.360176: step 6811, loss = 0.66969 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:23:48.647994 ops/training.py:65 2019-01-17 02:23:48.647886: step 6812, loss = 0.63615 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:23:49.933168 ops/training.py:65 2019-01-17 02:23:49.933060: step 6813, loss = 0.71122 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:23:51.224841 ops/training.py:65 2019-01-17 02:23:51.224737: step 6814, loss = 0.68602 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:23:52.515275 ops/training.py:65 2019-01-17 02:23:52.515203: step 6815, loss = 0.70709 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:23:53.803434 ops/training.py:65 2019-01-17 02:23:53.803357: step 6816, loss = 0.70238 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:23:55.089540 ops/training.py:65 2019-01-17 02:23:55.089466: step 6817, loss = 0.72847 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:23:56.373326 ops/training.py:65 2019-01-17 02:23:56.373221: step 6818, loss = 0.72204 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:23:57.665229 ops/training.py:65 2019-01-17 02:23:57.665126: step 6819, loss = 0.69085 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:23:58.952704 ops/training.py:65 2019-01-17 02:23:58.952638: step 6820, loss = 0.66030 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:24:00.236063 ops/training.py:65 2019-01-17 02:24:00.235982: step 6821, loss = 0.67490 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:24:01.521717 ops/training.py:65 2019-01-17 02:24:01.521618: step 6822, loss = 0.66594 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:24:02.813365 ops/training.py:65 2019-01-17 02:24:02.813293: step 6823, loss = 0.66504 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:24:04.098989 ops/training.py:65 2019-01-17 02:24:04.098920: step 6824, loss = 0.66108 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:24:05.389378 ops/training.py:65 2019-01-17 02:24:05.389309: step 6825, loss = 0.67557 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:24:06.678643 ops/training.py:65 2019-01-17 02:24:06.678569: step 6826, loss = 0.69961 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:24:07.967693 ops/training.py:65 2019-01-17 02:24:07.967620: step 6827, loss = 0.71914 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:24:09.256703 ops/training.py:65 2019-01-17 02:24:09.256634: step 6828, loss = 0.70267 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:24:10.545711 ops/training.py:65 2019-01-17 02:24:10.545637: step 6829, loss = 0.69670 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:24:11.833932 ops/training.py:65 2019-01-17 02:24:11.833864: step 6830, loss = 0.69584 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:24:13.119556 ops/training.py:65 2019-01-17 02:24:13.119486: step 6831, loss = 0.67370 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:24:14.407807 ops/training.py:65 2019-01-17 02:24:14.407744: step 6832, loss = 0.66950 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:24:15.692689 ops/training.py:65 2019-01-17 02:24:15.692614: step 6833, loss = 0.67781 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:24:16.974091 ops/training.py:65 2019-01-17 02:24:16.974028: step 6834, loss = 0.71129 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:24:18.262646 ops/training.py:65 2019-01-17 02:24:18.262552: step 6835, loss = 0.77931 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-17 02:24:19.548967 ops/training.py:65 2019-01-17 02:24:19.548899: step 6836, loss = 0.70399 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:24:20.836653 ops/training.py:65 2019-01-17 02:24:20.836572: step 6837, loss = 0.70261 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:24:22.118561 ops/training.py:65 2019-01-17 02:24:22.118492: step 6838, loss = 0.72339 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:24:23.399850 ops/training.py:65 2019-01-17 02:24:23.399775: step 6839, loss = 0.71065 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:24:24.687037 ops/training.py:65 2019-01-17 02:24:24.686969: step 6840, loss = 0.67752 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:24:25.974277 ops/training.py:65 2019-01-17 02:24:25.974192: step 6841, loss = 0.70140 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:24:27.258930 ops/training.py:65 2019-01-17 02:24:27.258855: step 6842, loss = 0.67815 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:24:28.543863 ops/training.py:65 2019-01-17 02:24:28.543757: step 6843, loss = 0.66031 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:24:29.836018 ops/training.py:65 2019-01-17 02:24:29.835917: step 6844, loss = 0.68245 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:24:31.123392 ops/training.py:65 2019-01-17 02:24:31.123317: step 6845, loss = 0.69158 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:24:32.407191 ops/training.py:65 2019-01-17 02:24:32.407085: step 6846, loss = 0.70863 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:24:33.693381 ops/training.py:65 2019-01-17 02:24:33.693280: step 6847, loss = 0.70886 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:24:34.973763 ops/training.py:65 2019-01-17 02:24:34.973661: step 6848, loss = 0.65309 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:24:36.259529 ops/training.py:65 2019-01-17 02:24:36.259421: step 6849, loss = 0.76229 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:24:37.546206 ops/training.py:65 2019-01-17 02:24:37.546105: step 6850, loss = 0.70117 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:24:38.831589 ops/training.py:65 2019-01-17 02:24:38.831491: step 6851, loss = 0.71869 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:24:40.126411 ops/training.py:65 2019-01-17 02:24:40.126307: step 6852, loss = 0.64796 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:24:41.409386 ops/training.py:65 2019-01-17 02:24:41.409307: step 6853, loss = 0.69394 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:24:42.695896 ops/training.py:65 2019-01-17 02:24:42.695790: step 6854, loss = 0.64664 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:24:43.979015 ops/training.py:65 2019-01-17 02:24:43.978917: step 6855, loss = 0.67564 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:24:45.270492 ops/training.py:65 2019-01-17 02:24:45.270335: step 6856, loss = 0.71157 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:24:46.559257 ops/training.py:65 2019-01-17 02:24:46.559173: step 6857, loss = 0.68859 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:24:47.842912 ops/training.py:65 2019-01-17 02:24:47.842823: step 6858, loss = 0.69093 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:24:49.127660 ops/training.py:65 2019-01-17 02:24:49.127572: step 6859, loss = 0.61300 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:24:50.416458 ops/training.py:65 2019-01-17 02:24:50.416372: step 6860, loss = 0.64393 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:24:51.703542 ops/training.py:65 2019-01-17 02:24:51.703440: step 6861, loss = 0.69527 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:24:52.983865 ops/training.py:65 2019-01-17 02:24:52.983792: step 6862, loss = 0.65703 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:24:54.265888 ops/training.py:65 2019-01-17 02:24:54.265789: step 6863, loss = 0.69994 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:24:55.556746 ops/training.py:65 2019-01-17 02:24:55.556650: step 6864, loss = 0.66885 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:24:56.847010 ops/training.py:65 2019-01-17 02:24:56.846926: step 6865, loss = 0.72809 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:24:58.133465 ops/training.py:65 2019-01-17 02:24:58.133366: step 6866, loss = 0.73344 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:24:59.424375 ops/training.py:65 2019-01-17 02:24:59.424277: step 6867, loss = 0.69927 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:25:00.708058 ops/training.py:65 2019-01-17 02:25:00.707988: step 6868, loss = 0.71371 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:25:01.993461 ops/training.py:65 2019-01-17 02:25:01.993365: step 6869, loss = 0.70328 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:25:03.283873 ops/training.py:65 2019-01-17 02:25:03.283775: step 6870, loss = 0.69227 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:25:04.570820 ops/training.py:65 2019-01-17 02:25:04.570756: step 6871, loss = 0.77463 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:25:05.854158 ops/training.py:65 2019-01-17 02:25:05.854082: step 6872, loss = 0.64447 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:25:07.145130 ops/training.py:65 2019-01-17 02:25:07.145024: step 6873, loss = 0.69265 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:25:08.427998 ops/training.py:65 2019-01-17 02:25:08.427931: step 6874, loss = 0.64611 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:25:09.715462 ops/training.py:65 2019-01-17 02:25:09.715374: step 6875, loss = 0.72252 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:25:11.001637 ops/training.py:65 2019-01-17 02:25:11.001526: step 6876, loss = 0.71628 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:25:12.287392 ops/training.py:65 2019-01-17 02:25:12.287288: step 6877, loss = 0.74452 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:25:13.575135 ops/training.py:65 2019-01-17 02:25:13.575039: step 6878, loss = 0.68484 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:25:14.863822 ops/training.py:65 2019-01-17 02:25:14.863724: step 6879, loss = 0.75021 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:25:16.148028 ops/training.py:65 2019-01-17 02:25:16.147959: step 6880, loss = 0.67904 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:25:17.428617 ops/training.py:65 2019-01-17 02:25:17.428463: step 6881, loss = 0.72182 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:25:18.715044 ops/training.py:65 2019-01-17 02:25:18.714943: step 6882, loss = 0.73000 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:25:19.999584 ops/training.py:65 2019-01-17 02:25:19.999482: step 6883, loss = 0.65320 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:25:21.285526 ops/training.py:65 2019-01-17 02:25:21.285372: step 6884, loss = 0.70208 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:25:22.578125 ops/training.py:65 2019-01-17 02:25:22.577975: step 6885, loss = 0.73753 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:25:23.865756 ops/training.py:65 2019-01-17 02:25:23.865688: step 6886, loss = 0.69511 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:25:25.152621 ops/training.py:65 2019-01-17 02:25:25.152526: step 6887, loss = 0.71555 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:25:26.444784 ops/training.py:65 2019-01-17 02:25:26.444656: step 6888, loss = 0.66878 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:25:27.733983 ops/training.py:65 2019-01-17 02:25:27.733886: step 6889, loss = 0.67622 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:25:29.014467 ops/training.py:65 2019-01-17 02:25:29.014367: step 6890, loss = 0.68931 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:25:30.295269 ops/training.py:65 2019-01-17 02:25:30.295160: step 6891, loss = 0.68019 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:25:31.587398 ops/training.py:65 2019-01-17 02:25:31.587285: step 6892, loss = 0.69986 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:25:32.873235 ops/training.py:65 2019-01-17 02:25:32.873166: step 6893, loss = 0.69163 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:25:34.159404 ops/training.py:65 2019-01-17 02:25:34.159319: step 6894, loss = 0.68839 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:25:35.440694 ops/training.py:65 2019-01-17 02:25:35.440588: step 6895, loss = 0.71726 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:25:36.738180 ops/training.py:65 2019-01-17 02:25:36.738077: step 6896, loss = 0.67738 (24.7 examples/sec; 1.296 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:25:38.024371 ops/training.py:65 2019-01-17 02:25:38.024295: step 6897, loss = 0.68074 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:25:39.315752 ops/training.py:65 2019-01-17 02:25:39.315647: step 6898, loss = 0.69044 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:25:40.601951 ops/training.py:65 2019-01-17 02:25:40.601889: step 6899, loss = 0.70005 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:25:41.885335 ops/training.py:65 2019-01-17 02:25:41.885226: step 6900, loss = 0.67232 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:25:43.174323 ops/training.py:65 2019-01-17 02:25:43.174230: step 6901, loss = 0.66837 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:25:44.463283 ops/training.py:65 2019-01-17 02:25:44.463211: step 6902, loss = 0.69043 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:25:45.750118 ops/training.py:65 2019-01-17 02:25:45.750052: step 6903, loss = 0.69781 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:25:47.039515 ops/training.py:65 2019-01-17 02:25:47.039440: step 6904, loss = 0.70381 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:25:48.334221 ops/training.py:65 2019-01-17 02:25:48.334142: step 6905, loss = 0.68459 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:25:49.623739 ops/training.py:65 2019-01-17 02:25:49.623643: step 6906, loss = 0.66830 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:25:50.913233 ops/training.py:65 2019-01-17 02:25:50.913163: step 6907, loss = 0.69412 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:25:52.203389 ops/training.py:65 2019-01-17 02:25:52.203307: step 6908, loss = 0.69425 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:25:53.491190 ops/training.py:65 2019-01-17 02:25:53.491113: step 6909, loss = 0.71715 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:25:54.779561 ops/training.py:65 2019-01-17 02:25:54.779484: step 6910, loss = 0.68925 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:25:56.067710 ops/training.py:65 2019-01-17 02:25:56.067643: step 6911, loss = 0.69579 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:25:57.356896 ops/training.py:65 2019-01-17 02:25:57.356788: step 6912, loss = 0.66103 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:25:58.646290 ops/training.py:65 2019-01-17 02:25:58.646193: step 6913, loss = 0.67671 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:25:59.934580 ops/training.py:65 2019-01-17 02:25:59.934481: step 6914, loss = 0.69420 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:26:01.220910 ops/training.py:65 2019-01-17 02:26:01.220836: step 6915, loss = 0.67355 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:26:02.508098 ops/training.py:65 2019-01-17 02:26:02.508029: step 6916, loss = 0.65853 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:26:03.792228 ops/training.py:65 2019-01-17 02:26:03.792153: step 6917, loss = 0.64999 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:26:05.074669 ops/training.py:65 2019-01-17 02:26:05.074593: step 6918, loss = 0.68608 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:26:06.365752 ops/training.py:65 2019-01-17 02:26:06.365642: step 6919, loss = 0.73053 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:26:07.656476 ops/training.py:65 2019-01-17 02:26:07.656400: step 6920, loss = 0.67231 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:26:08.944588 ops/training.py:65 2019-01-17 02:26:08.944488: step 6921, loss = 0.70530 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:26:10.235062 ops/training.py:65 2019-01-17 02:26:10.234960: step 6922, loss = 0.69108 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:26:11.524921 ops/training.py:65 2019-01-17 02:26:11.524851: step 6923, loss = 0.69059 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:26:12.813962 ops/training.py:65 2019-01-17 02:26:12.813894: step 6924, loss = 0.72531 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:26:14.108584 ops/training.py:65 2019-01-17 02:26:14.108508: step 6925, loss = 0.70253 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:26:15.395086 ops/training.py:65 2019-01-17 02:26:15.395003: step 6926, loss = 0.70510 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:26:16.678688 ops/training.py:65 2019-01-17 02:26:16.678584: step 6927, loss = 0.65317 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:26:17.970532 ops/training.py:65 2019-01-17 02:26:17.970378: step 6928, loss = 0.69933 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:26:19.257037 ops/training.py:65 2019-01-17 02:26:19.256963: step 6929, loss = 0.71456 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:26:20.542313 ops/training.py:65 2019-01-17 02:26:20.542211: step 6930, loss = 0.66018 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:26:21.833872 ops/training.py:65 2019-01-17 02:26:21.833761: step 6931, loss = 0.68952 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:26:23.126684 ops/training.py:65 2019-01-17 02:26:23.126602: step 6932, loss = 0.71258 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:26:24.415965 ops/training.py:65 2019-01-17 02:26:24.415892: step 6933, loss = 0.67120 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:26:25.705548 ops/training.py:65 2019-01-17 02:26:25.705476: step 6934, loss = 0.68582 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:26:26.990323 ops/training.py:65 2019-01-17 02:26:26.990249: step 6935, loss = 0.68215 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:26:28.277754 ops/training.py:65 2019-01-17 02:26:28.277686: step 6936, loss = 0.72652 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:26:29.561770 ops/training.py:65 2019-01-17 02:26:29.561706: step 6937, loss = 0.68884 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:26:30.847430 ops/training.py:65 2019-01-17 02:26:30.847314: step 6938, loss = 0.71484 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:26:32.136346 ops/training.py:65 2019-01-17 02:26:32.136238: step 6939, loss = 0.67280 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:26:33.421860 ops/training.py:65 2019-01-17 02:26:33.421763: step 6940, loss = 0.70268 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:26:34.713599 ops/training.py:65 2019-01-17 02:26:34.713485: step 6941, loss = 0.70782 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:26:35.999524 ops/training.py:65 2019-01-17 02:26:35.999461: step 6942, loss = 0.73495 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:26:37.287388 ops/training.py:65 2019-01-17 02:26:37.287319: step 6943, loss = 0.69952 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:26:38.570907 ops/training.py:65 2019-01-17 02:26:38.570831: step 6944, loss = 0.67240 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:26:39.860107 ops/training.py:65 2019-01-17 02:26:39.860039: step 6945, loss = 0.64367 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:26:41.149188 ops/training.py:65 2019-01-17 02:26:41.149124: step 6946, loss = 0.74668 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:26:42.438632 ops/training.py:65 2019-01-17 02:26:42.438562: step 6947, loss = 0.67493 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:26:43.723992 ops/training.py:65 2019-01-17 02:26:43.723920: step 6948, loss = 0.68799 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:26:45.014155 ops/training.py:65 2019-01-17 02:26:45.014086: step 6949, loss = 0.67555 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:26:46.303502 ops/training.py:65 2019-01-17 02:26:46.303421: step 6950, loss = 0.72244 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:26:47.593066 ops/training.py:65 2019-01-17 02:26:47.592990: step 6951, loss = 0.74750 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:26:48.882897 ops/training.py:65 2019-01-17 02:26:48.882823: step 6952, loss = 0.73330 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:26:50.167804 ops/training.py:65 2019-01-17 02:26:50.167734: step 6953, loss = 0.80668 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:26:51.457584 ops/training.py:65 2019-01-17 02:26:51.457474: step 6954, loss = 0.72974 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:26:52.743177 ops/training.py:65 2019-01-17 02:26:52.743092: step 6955, loss = 0.78410 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:26:54.029206 ops/training.py:65 2019-01-17 02:26:54.029111: step 6956, loss = 0.72721 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:26:55.317803 ops/training.py:65 2019-01-17 02:26:55.317708: step 6957, loss = 0.66457 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:26:56.606147 ops/training.py:65 2019-01-17 02:26:56.606055: step 6958, loss = 0.72296 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:26:57.896489 ops/training.py:65 2019-01-17 02:26:57.896420: step 6959, loss = 0.71544 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:26:59.180985 ops/training.py:65 2019-01-17 02:26:59.180918: step 6960, loss = 0.63830 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:27:00.465480 ops/training.py:65 2019-01-17 02:27:00.465330: step 6961, loss = 0.67080 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:27:01.751687 ops/training.py:65 2019-01-17 02:27:01.751576: step 6962, loss = 0.73952 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:27:03.043854 ops/training.py:65 2019-01-17 02:27:03.043753: step 6963, loss = 0.73714 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:27:04.332680 ops/training.py:65 2019-01-17 02:27:04.332559: step 6964, loss = 0.72281 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:27:05.623819 ops/training.py:65 2019-01-17 02:27:05.623747: step 6965, loss = 0.66281 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:27:06.911361 ops/training.py:65 2019-01-17 02:27:06.911273: step 6966, loss = 0.66953 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:27:08.200576 ops/training.py:65 2019-01-17 02:27:08.200471: step 6967, loss = 0.71333 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:27:09.489843 ops/training.py:65 2019-01-17 02:27:09.489742: step 6968, loss = 0.78618 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:27:10.778708 ops/training.py:65 2019-01-17 02:27:10.778615: step 6969, loss = 0.68884 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:27:12.067245 ops/training.py:65 2019-01-17 02:27:12.067169: step 6970, loss = 0.75232 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:27:13.356857 ops/training.py:65 2019-01-17 02:27:13.356778: step 6971, loss = 0.63344 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:27:14.646114 ops/training.py:65 2019-01-17 02:27:14.646036: step 6972, loss = 0.62376 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:27:15.929772 ops/training.py:65 2019-01-17 02:27:15.929706: step 6973, loss = 0.67083 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:27:17.218939 ops/training.py:65 2019-01-17 02:27:17.218830: step 6974, loss = 0.70576 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:27:18.506757 ops/training.py:65 2019-01-17 02:27:18.506663: step 6975, loss = 0.77827 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:27:19.794710 ops/training.py:65 2019-01-17 02:27:19.794612: step 6976, loss = 0.63816 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:27:21.080101 ops/training.py:65 2019-01-17 02:27:21.080004: step 6977, loss = 0.63413 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:27:22.368982 ops/training.py:65 2019-01-17 02:27:22.368879: step 6978, loss = 0.74524 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:27:23.657404 ops/training.py:65 2019-01-17 02:27:23.657334: step 6979, loss = 0.75531 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:27:24.945907 ops/training.py:65 2019-01-17 02:27:24.945808: step 6980, loss = 0.64562 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:27:26.234815 ops/training.py:65 2019-01-17 02:27:26.234725: step 6981, loss = 0.71764 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:27:27.519567 ops/training.py:65 2019-01-17 02:27:27.519499: step 6982, loss = 0.80649 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:27:28.807006 ops/training.py:65 2019-01-17 02:27:28.806909: step 6983, loss = 0.71171 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:27:30.094198 ops/training.py:65 2019-01-17 02:27:30.094110: step 6984, loss = 0.72911 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:27:31.380271 ops/training.py:65 2019-01-17 02:27:31.380162: step 6985, loss = 0.70593 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:27:32.671465 ops/training.py:65 2019-01-17 02:27:32.671364: step 6986, loss = 0.72717 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:27:33.958184 ops/training.py:65 2019-01-17 02:27:33.958117: step 6987, loss = 0.71297 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:27:35.243700 ops/training.py:65 2019-01-17 02:27:35.243604: step 6988, loss = 0.67069 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:27:36.527233 ops/training.py:65 2019-01-17 02:27:36.527122: step 6989, loss = 0.75875 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:27:37.805235 ops/training.py:65 2019-01-17 02:27:37.805122: step 6990, loss = 0.74081 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:27:39.097619 ops/training.py:65 2019-01-17 02:27:39.097462: step 6991, loss = 0.72540 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:27:40.388576 ops/training.py:65 2019-01-17 02:27:40.388495: step 6992, loss = 0.63498 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:27:41.677287 ops/training.py:65 2019-01-17 02:27:41.677211: step 6993, loss = 0.66461 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:27:42.960426 ops/training.py:65 2019-01-17 02:27:42.960338: step 6994, loss = 0.70345 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:27:44.250322 ops/training.py:65 2019-01-17 02:27:44.250289: step 6995, loss = 0.67424 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:27:45.534608 ops/training.py:65 2019-01-17 02:27:45.534568: step 6996, loss = 0.76245 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:27:46.823562 ops/training.py:65 2019-01-17 02:27:46.823505: step 6997, loss = 0.70368 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:27:48.109573 ops/training.py:65 2019-01-17 02:27:48.109539: step 6998, loss = 0.73769 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:27:49.395645 ops/training.py:65 2019-01-17 02:27:49.395608: step 6999, loss = 0.66912 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:27:50.686201 ops/training.py:65 2019-01-17 02:27:50.686164: step 7000, loss = 0.66870 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:27:51.976584 ops/training.py:65 2019-01-17 02:27:51.976491: step 7001, loss = 0.71880 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:27:53.260959 ops/training.py:65 2019-01-17 02:27:53.260895: step 7002, loss = 0.68995 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:27:54.545472 ops/training.py:65 2019-01-17 02:27:54.545435: step 7003, loss = 0.70839 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:27:55.832219 ops/training.py:65 2019-01-17 02:27:55.832187: step 7004, loss = 0.69959 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:27:57.114956 ops/training.py:65 2019-01-17 02:27:57.114924: step 7005, loss = 0.69921 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:27:58.401641 ops/training.py:65 2019-01-17 02:27:58.401606: step 7006, loss = 0.69978 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:27:59.687462 ops/training.py:65 2019-01-17 02:27:59.687429: step 7007, loss = 0.70324 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:28:00.974414 ops/training.py:65 2019-01-17 02:28:00.974384: step 7008, loss = 0.70311 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:28:02.260991 ops/training.py:65 2019-01-17 02:28:02.260960: step 7009, loss = 0.68678 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:28:03.544621 ops/training.py:65 2019-01-17 02:28:03.544529: step 7010, loss = 0.69447 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:28:04.832038 ops/training.py:65 2019-01-17 02:28:04.831933: step 7011, loss = 0.67481 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:28:06.111718 ops/training.py:65 2019-01-17 02:28:06.111611: step 7012, loss = 0.68846 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:28:07.403762 ops/training.py:65 2019-01-17 02:28:07.403655: step 7013, loss = 0.67475 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:28:08.692139 ops/training.py:65 2019-01-17 02:28:08.692032: step 7014, loss = 0.71209 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:28:09.976269 ops/training.py:65 2019-01-17 02:28:09.976158: step 7015, loss = 0.81683 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:28:11.260011 ops/training.py:65 2019-01-17 02:28:11.259901: step 7016, loss = 0.72735 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:28:12.548043 ops/training.py:65 2019-01-17 02:28:12.547939: step 7017, loss = 0.68380 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:28:13.832406 ops/training.py:65 2019-01-17 02:28:13.832313: step 7018, loss = 0.65270 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:28:15.122522 ops/training.py:65 2019-01-17 02:28:15.122386: step 7019, loss = 0.69221 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:28:16.404120 ops/training.py:65 2019-01-17 02:28:16.404039: step 7020, loss = 0.70689 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:28:17.687588 ops/training.py:65 2019-01-17 02:28:17.687489: step 7021, loss = 0.73732 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:28:18.974513 ops/training.py:65 2019-01-17 02:28:18.974417: step 7022, loss = 0.67037 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:28:20.259877 ops/training.py:65 2019-01-17 02:28:20.259769: step 7023, loss = 0.63725 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:28:21.549204 ops/training.py:65 2019-01-17 02:28:21.549112: step 7024, loss = 0.67383 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:28:22.838262 ops/training.py:65 2019-01-17 02:28:22.838196: step 7025, loss = 0.69464 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:28:24.120999 ops/training.py:65 2019-01-17 02:28:24.120927: step 7026, loss = 0.68399 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:28:25.405670 ops/training.py:65 2019-01-17 02:28:25.405571: step 7027, loss = 0.66699 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:28:26.695702 ops/training.py:65 2019-01-17 02:28:26.695598: step 7028, loss = 0.71627 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:28:27.978624 ops/training.py:65 2019-01-17 02:28:27.978563: step 7029, loss = 0.67310 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:28:29.263386 ops/training.py:65 2019-01-17 02:28:29.263281: step 7030, loss = 0.76068 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 02:28:30.550944 ops/training.py:65 2019-01-17 02:28:30.550842: step 7031, loss = 0.66338 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:28:31.836844 ops/training.py:65 2019-01-17 02:28:31.836720: step 7032, loss = 0.70560 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:28:33.122290 ops/training.py:65 2019-01-17 02:28:33.122188: step 7033, loss = 0.69246 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:28:34.406711 ops/training.py:65 2019-01-17 02:28:34.406615: step 7034, loss = 0.66092 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:28:35.690466 ops/training.py:65 2019-01-17 02:28:35.690360: step 7035, loss = 0.66264 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:28:36.971906 ops/training.py:65 2019-01-17 02:28:36.971820: step 7036, loss = 0.69706 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:28:38.258426 ops/training.py:65 2019-01-17 02:28:38.258320: step 7037, loss = 0.65251 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:28:39.545955 ops/training.py:65 2019-01-17 02:28:39.545846: step 7038, loss = 0.68936 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:28:40.837761 ops/training.py:65 2019-01-17 02:28:40.837658: step 7039, loss = 0.70779 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:28:42.128055 ops/training.py:65 2019-01-17 02:28:42.127985: step 7040, loss = 0.72650 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:28:43.410785 ops/training.py:65 2019-01-17 02:28:43.410705: step 7041, loss = 0.70932 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:28:44.696910 ops/training.py:65 2019-01-17 02:28:44.696812: step 7042, loss = 0.68379 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:28:45.990108 ops/training.py:65 2019-01-17 02:28:45.990005: step 7043, loss = 0.69953 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:28:47.281337 ops/training.py:65 2019-01-17 02:28:47.281276: step 7044, loss = 0.64482 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:28:48.570012 ops/training.py:65 2019-01-17 02:28:48.569944: step 7045, loss = 0.74865 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 02:28:49.859440 ops/training.py:65 2019-01-17 02:28:49.859370: step 7046, loss = 0.69373 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:28:51.143013 ops/training.py:65 2019-01-17 02:28:51.142943: step 7047, loss = 0.67782 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:28:52.431041 ops/training.py:65 2019-01-17 02:28:52.430929: step 7048, loss = 0.68484 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:28:53.723083 ops/training.py:65 2019-01-17 02:28:53.722979: step 7049, loss = 0.70762 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:28:55.003203 ops/training.py:65 2019-01-17 02:28:55.003127: step 7050, loss = 0.66480 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:28:56.282321 ops/training.py:65 2019-01-17 02:28:56.282212: step 7051, loss = 0.68590 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:28:57.569121 ops/training.py:65 2019-01-17 02:28:57.569019: step 7052, loss = 0.68499 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:28:58.854323 ops/training.py:65 2019-01-17 02:28:58.854224: step 7053, loss = 0.67055 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:29:00.146747 ops/training.py:65 2019-01-17 02:29:00.146605: step 7054, loss = 0.71534 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:29:01.435180 ops/training.py:65 2019-01-17 02:29:01.435107: step 7055, loss = 0.67848 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:29:02.723752 ops/training.py:65 2019-01-17 02:29:02.723683: step 7056, loss = 0.68193 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:29:04.011162 ops/training.py:65 2019-01-17 02:29:04.011084: step 7057, loss = 0.69932 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:29:05.300225 ops/training.py:65 2019-01-17 02:29:05.300155: step 7058, loss = 0.70428 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:29:06.584986 ops/training.py:65 2019-01-17 02:29:06.584918: step 7059, loss = 0.69026 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:29:07.873526 ops/training.py:65 2019-01-17 02:29:07.873442: step 7060, loss = 0.69995 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:29:09.159190 ops/training.py:65 2019-01-17 02:29:09.159126: step 7061, loss = 0.72631 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:29:10.449833 ops/training.py:65 2019-01-17 02:29:10.449698: step 7062, loss = 0.68171 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:29:11.735395 ops/training.py:65 2019-01-17 02:29:11.735321: step 7063, loss = 0.70743 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:29:13.019467 ops/training.py:65 2019-01-17 02:29:13.019360: step 7064, loss = 0.67549 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:29:14.304399 ops/training.py:65 2019-01-17 02:29:14.304308: step 7065, loss = 0.68403 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:29:15.590058 ops/training.py:65 2019-01-17 02:29:15.589943: step 7066, loss = 0.68673 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:29:16.876482 ops/training.py:65 2019-01-17 02:29:16.876385: step 7067, loss = 0.69067 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:29:18.164525 ops/training.py:65 2019-01-17 02:29:18.164383: step 7068, loss = 0.71817 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:29:19.452923 ops/training.py:65 2019-01-17 02:29:19.452847: step 7069, loss = 0.64984 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:29:20.741509 ops/training.py:65 2019-01-17 02:29:20.741443: step 7070, loss = 0.67481 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:29:22.024623 ops/training.py:65 2019-01-17 02:29:22.024557: step 7071, loss = 0.69942 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:29:23.309116 ops/training.py:65 2019-01-17 02:29:23.309019: step 7072, loss = 0.69077 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:29:24.596874 ops/training.py:65 2019-01-17 02:29:24.596766: step 7073, loss = 0.71395 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:29:25.888560 ops/training.py:65 2019-01-17 02:29:25.888411: step 7074, loss = 0.72619 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:29:27.176209 ops/training.py:65 2019-01-17 02:29:27.176134: step 7075, loss = 0.70752 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:29:28.466187 ops/training.py:65 2019-01-17 02:29:28.466081: step 7076, loss = 0.67594 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:29:29.756640 ops/training.py:65 2019-01-17 02:29:29.756572: step 7077, loss = 0.68615 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:29:31.044795 ops/training.py:65 2019-01-17 02:29:31.044724: step 7078, loss = 0.70453 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:29:32.330175 ops/training.py:65 2019-01-17 02:29:32.330110: step 7079, loss = 0.68960 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:29:33.618556 ops/training.py:65 2019-01-17 02:29:33.618483: step 7080, loss = 0.65720 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:29:34.904224 ops/training.py:65 2019-01-17 02:29:34.904122: step 7081, loss = 0.66405 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:29:36.194148 ops/training.py:65 2019-01-17 02:29:36.194079: step 7082, loss = 0.72669 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:29:37.487358 ops/training.py:65 2019-01-17 02:29:37.487266: step 7083, loss = 0.68525 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:29:38.775120 ops/training.py:65 2019-01-17 02:29:38.775054: step 7084, loss = 0.65736 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:29:40.063505 ops/training.py:65 2019-01-17 02:29:40.063441: step 7085, loss = 0.72387 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:29:41.350963 ops/training.py:65 2019-01-17 02:29:41.350889: step 7086, loss = 0.68814 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:29:42.637535 ops/training.py:65 2019-01-17 02:29:42.637463: step 7087, loss = 0.71142 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:29:43.926519 ops/training.py:65 2019-01-17 02:29:43.926447: step 7088, loss = 0.71595 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:29:45.209901 ops/training.py:65 2019-01-17 02:29:45.209834: step 7089, loss = 0.70288 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:29:46.500581 ops/training.py:65 2019-01-17 02:29:46.500484: step 7090, loss = 0.66310 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:29:47.782394 ops/training.py:65 2019-01-17 02:29:47.782323: step 7091, loss = 0.71344 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:29:49.069274 ops/training.py:65 2019-01-17 02:29:49.069162: step 7092, loss = 0.72299 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:29:50.349068 ops/training.py:65 2019-01-17 02:29:50.348967: step 7093, loss = 0.73515 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-17 02:29:51.641238 ops/training.py:65 2019-01-17 02:29:51.641095: step 7094, loss = 0.70508 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:29:52.924958 ops/training.py:65 2019-01-17 02:29:52.924897: step 7095, loss = 0.63576 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:29:54.205254 ops/training.py:65 2019-01-17 02:29:54.205104: step 7096, loss = 0.71350 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:29:55.490199 ops/training.py:65 2019-01-17 02:29:55.490096: step 7097, loss = 0.71362 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:29:56.774776 ops/training.py:65 2019-01-17 02:29:56.774679: step 7098, loss = 0.71133 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:29:58.062368 ops/training.py:65 2019-01-17 02:29:58.062260: step 7099, loss = 0.71605 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:29:59.346782 ops/training.py:65 2019-01-17 02:29:59.346689: step 7100, loss = 0.65473 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:30:00.638656 ops/training.py:65 2019-01-17 02:30:00.638521: step 7101, loss = 0.77223 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:30:01.924519 ops/training.py:65 2019-01-17 02:30:01.924461: step 7102, loss = 0.70265 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:30:03.208160 ops/training.py:65 2019-01-17 02:30:03.208043: step 7103, loss = 0.73370 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:30:04.496183 ops/training.py:65 2019-01-17 02:30:04.496070: step 7104, loss = 0.76306 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:30:05.776725 ops/training.py:65 2019-01-17 02:30:05.776574: step 7105, loss = 0.70381 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:30:07.068275 ops/training.py:65 2019-01-17 02:30:07.068168: step 7106, loss = 0.70581 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:30:08.354425 ops/training.py:65 2019-01-17 02:30:08.354360: step 7107, loss = 0.65864 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:30:09.639492 ops/training.py:65 2019-01-17 02:30:09.639415: step 7108, loss = 0.69932 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:30:10.923486 ops/training.py:65 2019-01-17 02:30:10.923331: step 7109, loss = 0.75869 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:30:12.215141 ops/training.py:65 2019-01-17 02:30:12.215031: step 7110, loss = 0.76921 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:30:13.501128 ops/training.py:65 2019-01-17 02:30:13.501059: step 7111, loss = 0.71920 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:30:14.784742 ops/training.py:65 2019-01-17 02:30:14.784671: step 7112, loss = 0.74967 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:30:16.074559 ops/training.py:65 2019-01-17 02:30:16.074401: step 7113, loss = 0.72197 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:30:17.368143 ops/training.py:65 2019-01-17 02:30:17.368067: step 7114, loss = 0.71707 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:30:18.655837 ops/training.py:65 2019-01-17 02:30:18.655727: step 7115, loss = 0.76132 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:30:19.946999 ops/training.py:65 2019-01-17 02:30:19.946849: step 7116, loss = 0.71752 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:30:21.231366 ops/training.py:65 2019-01-17 02:30:21.231299: step 7117, loss = 0.70590 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:30:22.514952 ops/training.py:65 2019-01-17 02:30:22.514842: step 7118, loss = 0.73990 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:30:23.798785 ops/training.py:65 2019-01-17 02:30:23.798679: step 7119, loss = 0.68422 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:30:25.082760 ops/training.py:65 2019-01-17 02:30:25.082659: step 7120, loss = 0.63724 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 02:30:26.370716 ops/training.py:65 2019-01-17 02:30:26.370611: step 7121, loss = 0.70397 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:30:27.654879 ops/training.py:65 2019-01-17 02:30:27.654739: step 7122, loss = 0.69224 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:30:28.946529 ops/training.py:65 2019-01-17 02:30:28.946426: step 7123, loss = 0.73866 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:30:30.230908 ops/training.py:65 2019-01-17 02:30:30.230828: step 7124, loss = 0.69914 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:30:31.517814 ops/training.py:65 2019-01-17 02:30:31.517705: step 7125, loss = 0.71650 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:30:32.808077 ops/training.py:65 2019-01-17 02:30:32.807973: step 7126, loss = 0.70851 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:30:34.094526 ops/training.py:65 2019-01-17 02:30:34.094456: step 7127, loss = 0.75412 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:30:35.379449 ops/training.py:65 2019-01-17 02:30:35.379340: step 7128, loss = 0.70653 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:30:36.670922 ops/training.py:65 2019-01-17 02:30:36.670819: step 7129, loss = 0.72521 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:30:37.959304 ops/training.py:65 2019-01-17 02:30:37.959244: step 7130, loss = 0.73940 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:30:39.242845 ops/training.py:65 2019-01-17 02:30:39.242736: step 7131, loss = 0.67179 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:30:40.535696 ops/training.py:65 2019-01-17 02:30:40.535637: step 7132, loss = 0.71416 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:30:41.826509 ops/training.py:65 2019-01-17 02:30:41.826435: step 7133, loss = 0.71304 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:30:43.110175 ops/training.py:65 2019-01-17 02:30:43.110109: step 7134, loss = 0.68771 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:30:44.398505 ops/training.py:65 2019-01-17 02:30:44.398443: step 7135, loss = 0.70577 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:30:45.687953 ops/training.py:65 2019-01-17 02:30:45.687883: step 7136, loss = 0.67371 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:30:46.969668 ops/training.py:65 2019-01-17 02:30:46.969601: step 7137, loss = 0.68870 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:30:48.259498 ops/training.py:65 2019-01-17 02:30:48.259391: step 7138, loss = 0.72953 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:30:49.544558 ops/training.py:65 2019-01-17 02:30:49.544492: step 7139, loss = 0.72795 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:30:50.828542 ops/training.py:65 2019-01-17 02:30:50.828434: step 7140, loss = 0.72978 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:30:52.116316 ops/training.py:65 2019-01-17 02:30:52.116215: step 7141, loss = 0.69591 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:30:53.400895 ops/training.py:65 2019-01-17 02:30:53.400797: step 7142, loss = 0.73359 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:30:54.688810 ops/training.py:65 2019-01-17 02:30:54.688704: step 7143, loss = 0.70243 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:30:55.973829 ops/training.py:65 2019-01-17 02:30:55.973720: step 7144, loss = 0.67679 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:30:57.265628 ops/training.py:65 2019-01-17 02:30:57.265521: step 7145, loss = 0.71366 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:30:58.547413 ops/training.py:65 2019-01-17 02:30:58.547336: step 7146, loss = 0.65581 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:30:59.831606 ops/training.py:65 2019-01-17 02:30:59.831509: step 7147, loss = 0.71315 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:31:01.116166 ops/training.py:65 2019-01-17 02:31:01.116067: step 7148, loss = 0.72278 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:31:02.406919 ops/training.py:65 2019-01-17 02:31:02.406819: step 7149, loss = 0.67189 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:31:03.696580 ops/training.py:65 2019-01-17 02:31:03.696501: step 7150, loss = 0.66857 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:31:04.983226 ops/training.py:65 2019-01-17 02:31:04.983161: step 7151, loss = 0.71023 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:31:06.271683 ops/training.py:65 2019-01-17 02:31:06.271612: step 7152, loss = 0.64889 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:31:07.561053 ops/training.py:65 2019-01-17 02:31:07.560974: step 7153, loss = 0.68714 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:31:08.849034 ops/training.py:65 2019-01-17 02:31:08.848962: step 7154, loss = 0.73262 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 02:31:10.133818 ops/training.py:65 2019-01-17 02:31:10.133746: step 7155, loss = 0.70441 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:31:11.417259 ops/training.py:65 2019-01-17 02:31:11.417178: step 7156, loss = 0.67444 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:31:12.703741 ops/training.py:65 2019-01-17 02:31:12.703636: step 7157, loss = 0.68936 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:31:13.985885 ops/training.py:65 2019-01-17 02:31:13.985790: step 7158, loss = 0.68871 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:31:15.270915 ops/training.py:65 2019-01-17 02:31:15.270821: step 7159, loss = 0.70706 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:31:16.558639 ops/training.py:65 2019-01-17 02:31:16.558526: step 7160, loss = 0.64824 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:31:17.843118 ops/training.py:65 2019-01-17 02:31:17.843014: step 7161, loss = 0.65106 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:31:19.131024 ops/training.py:65 2019-01-17 02:31:19.130924: step 7162, loss = 0.68523 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:31:20.417669 ops/training.py:65 2019-01-17 02:31:20.417573: step 7163, loss = 0.67914 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:31:21.701840 ops/training.py:65 2019-01-17 02:31:21.701735: step 7164, loss = 0.67505 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:31:22.986558 ops/training.py:65 2019-01-17 02:31:22.986447: step 7165, loss = 0.69537 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:31:24.268524 ops/training.py:65 2019-01-17 02:31:24.268418: step 7166, loss = 0.68712 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:31:25.552527 ops/training.py:65 2019-01-17 02:31:25.552419: step 7167, loss = 0.69090 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:31:26.837822 ops/training.py:65 2019-01-17 02:31:26.837713: step 7168, loss = 0.67222 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:31:28.124814 ops/training.py:65 2019-01-17 02:31:28.124701: step 7169, loss = 0.70914 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:31:29.404995 ops/training.py:65 2019-01-17 02:31:29.404890: step 7170, loss = 0.69958 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:31:30.690985 ops/training.py:65 2019-01-17 02:31:30.690880: step 7171, loss = 0.70495 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:31:31.974769 ops/training.py:65 2019-01-17 02:31:31.974665: step 7172, loss = 0.69353 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:31:33.259211 ops/training.py:65 2019-01-17 02:31:33.259107: step 7173, loss = 0.68468 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:31:34.547023 ops/training.py:65 2019-01-17 02:31:34.546915: step 7174, loss = 0.68984 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:31:35.831039 ops/training.py:65 2019-01-17 02:31:35.830937: step 7175, loss = 0.68230 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:31:37.120573 ops/training.py:65 2019-01-17 02:31:37.120464: step 7176, loss = 0.72693 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:31:38.401107 ops/training.py:65 2019-01-17 02:31:38.400996: step 7177, loss = 0.68653 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:31:39.683910 ops/training.py:65 2019-01-17 02:31:39.683804: step 7178, loss = 0.70416 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:31:40.971130 ops/training.py:65 2019-01-17 02:31:40.971027: step 7179, loss = 0.71071 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:31:42.261678 ops/training.py:65 2019-01-17 02:31:42.261571: step 7180, loss = 0.65931 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:31:43.552511 ops/training.py:65 2019-01-17 02:31:43.552440: step 7181, loss = 0.70634 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:31:44.841641 ops/training.py:65 2019-01-17 02:31:44.841569: step 7182, loss = 0.67567 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:31:46.129467 ops/training.py:65 2019-01-17 02:31:46.129396: step 7183, loss = 0.72980 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:31:47.413338 ops/training.py:65 2019-01-17 02:31:47.413265: step 7184, loss = 0.69300 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:31:48.699841 ops/training.py:65 2019-01-17 02:31:48.699760: step 7185, loss = 0.68889 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:31:49.987576 ops/training.py:65 2019-01-17 02:31:49.987474: step 7186, loss = 0.69518 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:31:51.274231 ops/training.py:65 2019-01-17 02:31:51.274126: step 7187, loss = 0.70253 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:31:52.560901 ops/training.py:65 2019-01-17 02:31:52.560793: step 7188, loss = 0.67903 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:31:53.845668 ops/training.py:65 2019-01-17 02:31:53.845571: step 7189, loss = 0.72200 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:31:55.133612 ops/training.py:65 2019-01-17 02:31:55.133510: step 7190, loss = 0.69396 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:31:56.419860 ops/training.py:65 2019-01-17 02:31:56.419764: step 7191, loss = 0.72839 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:31:57.713219 ops/training.py:65 2019-01-17 02:31:57.713119: step 7192, loss = 0.64846 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 02:31:58.997349 ops/training.py:65 2019-01-17 02:31:58.997271: step 7193, loss = 0.68240 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:32:00.290392 ops/training.py:65 2019-01-17 02:32:00.290299: step 7194, loss = 0.70276 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:32:01.579553 ops/training.py:65 2019-01-17 02:32:01.579489: step 7195, loss = 0.67189 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:32:02.863215 ops/training.py:65 2019-01-17 02:32:02.863130: step 7196, loss = 0.68277 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:32:04.152687 ops/training.py:65 2019-01-17 02:32:04.152532: step 7197, loss = 0.67033 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:32:05.443226 ops/training.py:65 2019-01-17 02:32:05.443132: step 7198, loss = 0.67438 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:32:06.730050 ops/training.py:65 2019-01-17 02:32:06.729920: step 7199, loss = 0.71922 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:32:08.018492 ops/training.py:65 2019-01-17 02:32:08.018383: step 7200, loss = 0.69705 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:32:09.300892 ops/training.py:65 2019-01-17 02:32:09.300782: step 7201, loss = 0.73406 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:32:10.586473 ops/training.py:65 2019-01-17 02:32:10.586323: step 7202, loss = 0.69706 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:32:11.878791 ops/training.py:65 2019-01-17 02:32:11.878688: step 7203, loss = 0.71394 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:32:13.170300 ops/training.py:65 2019-01-17 02:32:13.170231: step 7204, loss = 0.69034 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:32:14.451802 ops/training.py:65 2019-01-17 02:32:14.451726: step 7205, loss = 0.66931 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:32:15.742882 ops/training.py:65 2019-01-17 02:32:15.742775: step 7206, loss = 0.70905 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:32:17.032580 ops/training.py:65 2019-01-17 02:32:17.032478: step 7207, loss = 0.69213 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:32:18.320264 ops/training.py:65 2019-01-17 02:32:18.320197: step 7208, loss = 0.70473 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:32:19.605667 ops/training.py:65 2019-01-17 02:32:19.605583: step 7209, loss = 0.68255 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:32:20.896430 ops/training.py:65 2019-01-17 02:32:20.896328: step 7210, loss = 0.73669 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:32:22.188404 ops/training.py:65 2019-01-17 02:32:22.188336: step 7211, loss = 0.66339 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:32:23.472712 ops/training.py:65 2019-01-17 02:32:23.472630: step 7212, loss = 0.66228 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:32:24.760816 ops/training.py:65 2019-01-17 02:32:24.760668: step 7213, loss = 0.70789 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:32:26.051802 ops/training.py:65 2019-01-17 02:32:26.051736: step 7214, loss = 0.66586 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:32:27.340844 ops/training.py:65 2019-01-17 02:32:27.340773: step 7215, loss = 0.72042 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:32:28.625364 ops/training.py:65 2019-01-17 02:32:28.625283: step 7216, loss = 0.67586 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:32:29.916424 ops/training.py:65 2019-01-17 02:32:29.916294: step 7217, loss = 0.71499 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:32:31.206958 ops/training.py:65 2019-01-17 02:32:31.206887: step 7218, loss = 0.65621 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:32:32.492286 ops/training.py:65 2019-01-17 02:32:32.492217: step 7219, loss = 0.66971 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:32:33.774722 ops/training.py:65 2019-01-17 02:32:33.774624: step 7220, loss = 0.63556 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:32:35.066476 ops/training.py:65 2019-01-17 02:32:35.066368: step 7221, loss = 0.72726 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:32:36.352372 ops/training.py:65 2019-01-17 02:32:36.352304: step 7222, loss = 0.67433 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:32:37.637768 ops/training.py:65 2019-01-17 02:32:37.637659: step 7223, loss = 0.73193 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:32:38.925875 ops/training.py:65 2019-01-17 02:32:38.925763: step 7224, loss = 0.70876 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:32:40.219434 ops/training.py:65 2019-01-17 02:32:40.219329: step 7225, loss = 0.70189 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:32:41.511386 ops/training.py:65 2019-01-17 02:32:41.511284: step 7226, loss = 0.68717 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:32:42.796335 ops/training.py:65 2019-01-17 02:32:42.796270: step 7227, loss = 0.69786 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:32:44.077275 ops/training.py:65 2019-01-17 02:32:44.077170: step 7228, loss = 0.70553 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:32:45.368093 ops/training.py:65 2019-01-17 02:32:45.367951: step 7229, loss = 0.69015 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:32:46.657745 ops/training.py:65 2019-01-17 02:32:46.657653: step 7230, loss = 0.69256 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:32:47.939590 ops/training.py:65 2019-01-17 02:32:47.939515: step 7231, loss = 0.69726 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:32:49.225504 ops/training.py:65 2019-01-17 02:32:49.225396: step 7232, loss = 0.66889 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:32:50.512233 ops/training.py:65 2019-01-17 02:32:50.512133: step 7233, loss = 0.73141 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:32:51.801527 ops/training.py:65 2019-01-17 02:32:51.801420: step 7234, loss = 0.71958 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:32:53.093662 ops/training.py:65 2019-01-17 02:32:53.093564: step 7235, loss = 0.71867 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:32:54.382867 ops/training.py:65 2019-01-17 02:32:54.382797: step 7236, loss = 0.66887 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:32:55.668092 ops/training.py:65 2019-01-17 02:32:55.668023: step 7237, loss = 0.74947 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:32:56.958508 ops/training.py:65 2019-01-17 02:32:56.958408: step 7238, loss = 0.69867 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:32:58.245755 ops/training.py:65 2019-01-17 02:32:58.245685: step 7239, loss = 0.65773 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:32:59.527216 ops/training.py:65 2019-01-17 02:32:59.527121: step 7240, loss = 0.68534 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:33:00.811748 ops/training.py:65 2019-01-17 02:33:00.811639: step 7241, loss = 0.69947 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:33:02.097360 ops/training.py:65 2019-01-17 02:33:02.097261: step 7242, loss = 0.66490 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:33:03.384664 ops/training.py:65 2019-01-17 02:33:03.384559: step 7243, loss = 0.67237 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:33:04.669743 ops/training.py:65 2019-01-17 02:33:04.669638: step 7244, loss = 0.73098 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:33:05.962939 ops/training.py:65 2019-01-17 02:33:05.962825: step 7245, loss = 0.68838 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:33:07.249344 ops/training.py:65 2019-01-17 02:33:07.249247: step 7246, loss = 0.68172 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:33:08.534151 ops/training.py:65 2019-01-17 02:33:08.534051: step 7247, loss = 0.67298 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:33:09.825773 ops/training.py:65 2019-01-17 02:33:09.825634: step 7248, loss = 0.67732 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:33:11.115228 ops/training.py:65 2019-01-17 02:33:11.115155: step 7249, loss = 0.67418 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:33:12.395356 ops/training.py:65 2019-01-17 02:33:12.395276: step 7250, loss = 0.73414 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:33:13.680320 ops/training.py:65 2019-01-17 02:33:13.680218: step 7251, loss = 0.74021 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:33:14.968779 ops/training.py:65 2019-01-17 02:33:14.968686: step 7252, loss = 0.71274 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:33:16.259129 ops/training.py:65 2019-01-17 02:33:16.259025: step 7253, loss = 0.70315 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:33:17.547110 ops/training.py:65 2019-01-17 02:33:17.547008: step 7254, loss = 0.71218 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:33:18.837049 ops/training.py:65 2019-01-17 02:33:18.836947: step 7255, loss = 0.70311 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:33:20.121918 ops/training.py:65 2019-01-17 02:33:20.121849: step 7256, loss = 0.66859 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:33:21.405894 ops/training.py:65 2019-01-17 02:33:21.405828: step 7257, loss = 0.74567 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:33:22.683385 ops/training.py:65 2019-01-17 02:33:22.683278: step 7258, loss = 0.68200 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:33:23.969881 ops/training.py:65 2019-01-17 02:33:23.969783: step 7259, loss = 0.71351 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:33:25.257324 ops/training.py:65 2019-01-17 02:33:25.257227: step 7260, loss = 0.65138 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:33:26.547229 ops/training.py:65 2019-01-17 02:33:26.547129: step 7261, loss = 0.70573 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:33:27.837694 ops/training.py:65 2019-01-17 02:33:27.837618: step 7262, loss = 0.66903 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:33:29.128011 ops/training.py:65 2019-01-17 02:33:29.127940: step 7263, loss = 0.69991 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:33:30.411548 ops/training.py:65 2019-01-17 02:33:30.411479: step 7264, loss = 0.69711 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:33:31.700652 ops/training.py:65 2019-01-17 02:33:31.700544: step 7265, loss = 0.73018 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:33:32.989198 ops/training.py:65 2019-01-17 02:33:32.989122: step 7266, loss = 0.69494 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:33:34.274918 ops/training.py:65 2019-01-17 02:33:34.274845: step 7267, loss = 0.69564 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:33:35.563898 ops/training.py:65 2019-01-17 02:33:35.563823: step 7268, loss = 0.67511 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:33:36.849321 ops/training.py:65 2019-01-17 02:33:36.849249: step 7269, loss = 0.67789 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:33:38.136991 ops/training.py:65 2019-01-17 02:33:38.136919: step 7270, loss = 0.68924 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:33:39.424946 ops/training.py:65 2019-01-17 02:33:39.424877: step 7271, loss = 0.70251 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:33:40.705448 ops/training.py:65 2019-01-17 02:33:40.705379: step 7272, loss = 0.70745 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:33:41.989299 ops/training.py:65 2019-01-17 02:33:41.989190: step 7273, loss = 0.69839 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:33:43.280980 ops/training.py:65 2019-01-17 02:33:43.280848: step 7274, loss = 0.71285 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:33:44.566154 ops/training.py:65 2019-01-17 02:33:44.566079: step 7275, loss = 0.68843 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:33:45.852675 ops/training.py:65 2019-01-17 02:33:45.852573: step 7276, loss = 0.68586 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:33:47.142908 ops/training.py:65 2019-01-17 02:33:47.142812: step 7277, loss = 0.65629 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:33:48.428695 ops/training.py:65 2019-01-17 02:33:48.428630: step 7278, loss = 0.69204 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:33:49.717942 ops/training.py:65 2019-01-17 02:33:49.717791: step 7279, loss = 0.71799 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:33:51.009696 ops/training.py:65 2019-01-17 02:33:51.009555: step 7280, loss = 0.66711 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:33:52.294830 ops/training.py:65 2019-01-17 02:33:52.294761: step 7281, loss = 0.67924 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:33:53.581101 ops/training.py:65 2019-01-17 02:33:53.581000: step 7282, loss = 0.69754 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:33:54.865892 ops/training.py:65 2019-01-17 02:33:54.865788: step 7283, loss = 0.65901 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:33:56.153022 ops/training.py:65 2019-01-17 02:33:56.152919: step 7284, loss = 0.70302 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:33:57.433799 ops/training.py:65 2019-01-17 02:33:57.433695: step 7285, loss = 0.67988 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:33:58.719125 ops/training.py:65 2019-01-17 02:33:58.718987: step 7286, loss = 0.68787 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:34:00.013669 ops/training.py:65 2019-01-17 02:34:00.013569: step 7287, loss = 0.72535 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:34:01.300542 ops/training.py:65 2019-01-17 02:34:01.300438: step 7288, loss = 0.70261 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:34:02.589264 ops/training.py:65 2019-01-17 02:34:02.589195: step 7289, loss = 0.66847 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:34:03.877339 ops/training.py:65 2019-01-17 02:34:03.877268: step 7290, loss = 0.67526 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:34:05.162667 ops/training.py:65 2019-01-17 02:34:05.162569: step 7291, loss = 0.69232 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:34:06.447177 ops/training.py:65 2019-01-17 02:34:06.447079: step 7292, loss = 0.67750 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:34:07.738781 ops/training.py:65 2019-01-17 02:34:07.738675: step 7293, loss = 0.64930 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:34:09.024129 ops/training.py:65 2019-01-17 02:34:09.024067: step 7294, loss = 0.64497 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:34:10.312971 ops/training.py:65 2019-01-17 02:34:10.312879: step 7295, loss = 0.67168 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:34:11.601530 ops/training.py:65 2019-01-17 02:34:11.601442: step 7296, loss = 0.69514 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:34:12.886717 ops/training.py:65 2019-01-17 02:34:12.886655: step 7297, loss = 0.69118 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:34:14.172930 ops/training.py:65 2019-01-17 02:34:14.172834: step 7298, loss = 0.70735 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:34:15.458789 ops/training.py:65 2019-01-17 02:34:15.458697: step 7299, loss = 0.71596 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:34:16.743332 ops/training.py:65 2019-01-17 02:34:16.743227: step 7300, loss = 0.69343 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:34:18.028207 ops/training.py:65 2019-01-17 02:34:18.028112: step 7301, loss = 0.68067 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:34:19.316635 ops/training.py:65 2019-01-17 02:34:19.316540: step 7302, loss = 0.70691 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:34:20.602703 ops/training.py:65 2019-01-17 02:34:20.602612: step 7303, loss = 0.70021 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:34:21.889567 ops/training.py:65 2019-01-17 02:34:21.889459: step 7304, loss = 0.68687 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:34:23.175184 ops/training.py:65 2019-01-17 02:34:23.175082: step 7305, loss = 0.66782 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:34:24.461975 ops/training.py:65 2019-01-17 02:34:24.461868: step 7306, loss = 0.66773 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:34:25.746327 ops/training.py:65 2019-01-17 02:34:25.746222: step 7307, loss = 0.70574 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:34:27.035844 ops/training.py:65 2019-01-17 02:34:27.035741: step 7308, loss = 0.64204 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:34:28.324940 ops/training.py:65 2019-01-17 02:34:28.324834: step 7309, loss = 0.66306 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:34:29.611764 ops/training.py:65 2019-01-17 02:34:29.611695: step 7310, loss = 0.69375 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:34:30.895348 ops/training.py:65 2019-01-17 02:34:30.895286: step 7311, loss = 0.68381 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:34:32.179955 ops/training.py:65 2019-01-17 02:34:32.179846: step 7312, loss = 0.70420 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:34:33.472026 ops/training.py:65 2019-01-17 02:34:33.471922: step 7313, loss = 0.66117 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:34:34.762375 ops/training.py:65 2019-01-17 02:34:34.762293: step 7314, loss = 0.72544 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:34:36.047112 ops/training.py:65 2019-01-17 02:34:36.047050: step 7315, loss = 0.68576 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:34:37.331401 ops/training.py:65 2019-01-17 02:34:37.331304: step 7316, loss = 0.72712 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:34:38.617562 ops/training.py:65 2019-01-17 02:34:38.617459: step 7317, loss = 0.68157 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:34:39.905396 ops/training.py:65 2019-01-17 02:34:39.905292: step 7318, loss = 0.72051 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:34:41.195983 ops/training.py:65 2019-01-17 02:34:41.195878: step 7319, loss = 0.65956 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:34:42.483861 ops/training.py:65 2019-01-17 02:34:42.483796: step 7320, loss = 0.67956 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:34:43.768422 ops/training.py:65 2019-01-17 02:34:43.768351: step 7321, loss = 0.71336 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:34:45.053719 ops/training.py:65 2019-01-17 02:34:45.053629: step 7322, loss = 0.72812 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:34:46.335453 ops/training.py:65 2019-01-17 02:34:46.335351: step 7323, loss = 0.65929 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 02:34:47.620023 ops/training.py:65 2019-01-17 02:34:47.619911: step 7324, loss = 0.67239 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:34:48.911657 ops/training.py:65 2019-01-17 02:34:48.911552: step 7325, loss = 0.68924 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:34:50.196218 ops/training.py:65 2019-01-17 02:34:50.196155: step 7326, loss = 0.68728 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:34:51.480471 ops/training.py:65 2019-01-17 02:34:51.480365: step 7327, loss = 0.71058 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:34:52.771032 ops/training.py:65 2019-01-17 02:34:52.770925: step 7328, loss = 0.66105 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:34:54.061651 ops/training.py:65 2019-01-17 02:34:54.061573: step 7329, loss = 0.69386 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:34:55.349862 ops/training.py:65 2019-01-17 02:34:55.349768: step 7330, loss = 0.68350 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:34:56.636879 ops/training.py:65 2019-01-17 02:34:56.636788: step 7331, loss = 0.68923 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:34:57.924066 ops/training.py:65 2019-01-17 02:34:57.923980: step 7332, loss = 0.70256 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:34:59.207318 ops/training.py:65 2019-01-17 02:34:59.207239: step 7333, loss = 0.67263 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:35:00.498088 ops/training.py:65 2019-01-17 02:35:00.497991: step 7334, loss = 0.70621 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:35:01.785772 ops/training.py:65 2019-01-17 02:35:01.785711: step 7335, loss = 0.70280 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:35:03.073623 ops/training.py:65 2019-01-17 02:35:03.073554: step 7336, loss = 0.67204 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:35:04.361861 ops/training.py:65 2019-01-17 02:35:04.361786: step 7337, loss = 0.71384 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:35:05.644858 ops/training.py:65 2019-01-17 02:35:05.644779: step 7338, loss = 0.70063 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:35:06.929961 ops/training.py:65 2019-01-17 02:35:06.929864: step 7339, loss = 0.70704 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:35:08.217847 ops/training.py:65 2019-01-17 02:35:08.217741: step 7340, loss = 0.69010 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:35:09.509153 ops/training.py:65 2019-01-17 02:35:09.509046: step 7341, loss = 0.66864 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:35:10.796774 ops/training.py:65 2019-01-17 02:35:10.796709: step 7342, loss = 0.66620 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:35:12.081502 ops/training.py:65 2019-01-17 02:35:12.081432: step 7343, loss = 0.63724 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 02:35:13.372675 ops/training.py:65 2019-01-17 02:35:13.372573: step 7344, loss = 0.69627 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:35:14.663328 ops/training.py:65 2019-01-17 02:35:14.663257: step 7345, loss = 0.67628 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:35:15.951507 ops/training.py:65 2019-01-17 02:35:15.951400: step 7346, loss = 0.68595 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:35:17.240626 ops/training.py:65 2019-01-17 02:35:17.240503: step 7347, loss = 0.70840 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:35:18.529368 ops/training.py:65 2019-01-17 02:35:18.529268: step 7348, loss = 0.70081 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:35:19.809758 ops/training.py:65 2019-01-17 02:35:19.809686: step 7349, loss = 0.74507 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:35:21.089664 ops/training.py:65 2019-01-17 02:35:21.089558: step 7350, loss = 0.71176 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:35:22.378850 ops/training.py:65 2019-01-17 02:35:22.378744: step 7351, loss = 0.65155 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:35:23.668656 ops/training.py:65 2019-01-17 02:35:23.668579: step 7352, loss = 0.72255 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:35:24.952333 ops/training.py:65 2019-01-17 02:35:24.952269: step 7353, loss = 0.67275 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:35:26.234432 ops/training.py:65 2019-01-17 02:35:26.234331: step 7354, loss = 0.62783 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:35:27.521931 ops/training.py:65 2019-01-17 02:35:27.521824: step 7355, loss = 0.73786 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:35:28.812594 ops/training.py:65 2019-01-17 02:35:28.812487: step 7356, loss = 0.65817 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:35:30.102344 ops/training.py:65 2019-01-17 02:35:30.102266: step 7357, loss = 0.74152 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:35:31.391096 ops/training.py:65 2019-01-17 02:35:31.390986: step 7358, loss = 0.75367 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:35:32.675669 ops/training.py:65 2019-01-17 02:35:32.675560: step 7359, loss = 0.62040 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:35:33.959923 ops/training.py:65 2019-01-17 02:35:33.959820: step 7360, loss = 0.77407 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:35:35.249772 ops/training.py:65 2019-01-17 02:35:35.249634: step 7361, loss = 0.71912 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:35:36.530690 ops/training.py:65 2019-01-17 02:35:36.530580: step 7362, loss = 0.68159 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:35:37.813776 ops/training.py:65 2019-01-17 02:35:37.813672: step 7363, loss = 0.72401 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:35:39.100073 ops/training.py:65 2019-01-17 02:35:39.099968: step 7364, loss = 0.66928 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:35:40.384775 ops/training.py:65 2019-01-17 02:35:40.384663: step 7365, loss = 0.68512 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:35:41.672624 ops/training.py:65 2019-01-17 02:35:41.672525: step 7366, loss = 0.70599 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:35:42.962065 ops/training.py:65 2019-01-17 02:35:42.961908: step 7367, loss = 0.69282 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:35:44.246632 ops/training.py:65 2019-01-17 02:35:44.246530: step 7368, loss = 0.64450 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:35:45.529787 ops/training.py:65 2019-01-17 02:35:45.529687: step 7369, loss = 0.79619 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:35:46.817377 ops/training.py:65 2019-01-17 02:35:46.817217: step 7370, loss = 0.72955 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:35:48.102100 ops/training.py:65 2019-01-17 02:35:48.101994: step 7371, loss = 0.79249 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:35:49.392183 ops/training.py:65 2019-01-17 02:35:49.392074: step 7372, loss = 0.69479 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:35:50.680137 ops/training.py:65 2019-01-17 02:35:50.680036: step 7373, loss = 0.69537 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:35:51.967609 ops/training.py:65 2019-01-17 02:35:51.967532: step 7374, loss = 0.67445 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:35:53.255791 ops/training.py:65 2019-01-17 02:35:53.255719: step 7375, loss = 0.68399 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:35:54.539996 ops/training.py:65 2019-01-17 02:35:54.539916: step 7376, loss = 0.68275 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:35:55.827909 ops/training.py:65 2019-01-17 02:35:55.827841: step 7377, loss = 0.68945 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:35:57.114913 ops/training.py:65 2019-01-17 02:35:57.114815: step 7378, loss = 0.64434 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:35:58.402973 ops/training.py:65 2019-01-17 02:35:58.402899: step 7379, loss = 0.67038 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:35:59.691223 ops/training.py:65 2019-01-17 02:35:59.691150: step 7380, loss = 0.71996 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:36:00.979208 ops/training.py:65 2019-01-17 02:36:00.979136: step 7381, loss = 0.73088 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:36:02.269210 ops/training.py:65 2019-01-17 02:36:02.269139: step 7382, loss = 0.69536 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:36:03.554183 ops/training.py:65 2019-01-17 02:36:03.554114: step 7383, loss = 0.76387 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:36:04.837158 ops/training.py:65 2019-01-17 02:36:04.837055: step 7384, loss = 0.66312 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:36:06.129248 ops/training.py:65 2019-01-17 02:36:06.129149: step 7385, loss = 0.68504 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:36:07.420035 ops/training.py:65 2019-01-17 02:36:07.419951: step 7386, loss = 0.77082 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:36:08.709462 ops/training.py:65 2019-01-17 02:36:08.709388: step 7387, loss = 0.66936 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:36:09.997740 ops/training.py:65 2019-01-17 02:36:09.997654: step 7388, loss = 0.67132 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:36:11.282625 ops/training.py:65 2019-01-17 02:36:11.282531: step 7389, loss = 0.67711 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:36:12.572305 ops/training.py:65 2019-01-17 02:36:12.572204: step 7390, loss = 0.68595 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:36:13.859911 ops/training.py:65 2019-01-17 02:36:13.859834: step 7391, loss = 0.70171 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:36:15.142035 ops/training.py:65 2019-01-17 02:36:15.141962: step 7392, loss = 0.70472 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:36:16.431675 ops/training.py:65 2019-01-17 02:36:16.431520: step 7393, loss = 0.62867 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:36:17.723384 ops/training.py:65 2019-01-17 02:36:17.723247: step 7394, loss = 0.58366 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 02:36:19.012444 ops/training.py:65 2019-01-17 02:36:19.012362: step 7395, loss = 0.67671 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:36:20.296798 ops/training.py:65 2019-01-17 02:36:20.296734: step 7396, loss = 0.71179 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:36:21.585362 ops/training.py:65 2019-01-17 02:36:21.585265: step 7397, loss = 0.72401 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:36:22.868419 ops/training.py:65 2019-01-17 02:36:22.868351: step 7398, loss = 0.69901 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:36:24.152353 ops/training.py:65 2019-01-17 02:36:24.152260: step 7399, loss = 0.68924 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:36:25.432612 ops/training.py:65 2019-01-17 02:36:25.432511: step 7400, loss = 0.72295 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:36:26.722560 ops/training.py:65 2019-01-17 02:36:26.722424: step 7401, loss = 0.68856 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:36:28.013936 ops/training.py:65 2019-01-17 02:36:28.013831: step 7402, loss = 0.66770 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:36:29.303957 ops/training.py:65 2019-01-17 02:36:29.303869: step 7403, loss = 0.69054 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:36:30.587789 ops/training.py:65 2019-01-17 02:36:30.587716: step 7404, loss = 0.68380 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:36:31.868252 ops/training.py:65 2019-01-17 02:36:31.868142: step 7405, loss = 0.67047 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:36:33.153292 ops/training.py:65 2019-01-17 02:36:33.153193: step 7406, loss = 0.60323 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:36:34.444700 ops/training.py:65 2019-01-17 02:36:34.444597: step 7407, loss = 0.70335 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:36:35.735460 ops/training.py:65 2019-01-17 02:36:35.735380: step 7408, loss = 0.70141 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:36:37.023025 ops/training.py:65 2019-01-17 02:36:37.022951: step 7409, loss = 0.67104 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:36:38.312504 ops/training.py:65 2019-01-17 02:36:38.312427: step 7410, loss = 0.72099 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:36:39.603551 ops/training.py:65 2019-01-17 02:36:39.603471: step 7411, loss = 0.69494 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:36:40.888792 ops/training.py:65 2019-01-17 02:36:40.888719: step 7412, loss = 0.65623 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:36:42.169400 ops/training.py:65 2019-01-17 02:36:42.169293: step 7413, loss = 0.64704 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:36:43.453877 ops/training.py:65 2019-01-17 02:36:43.453783: step 7414, loss = 0.66512 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:36:44.745123 ops/training.py:65 2019-01-17 02:36:44.745031: step 7415, loss = 0.69155 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:36:46.034553 ops/training.py:65 2019-01-17 02:36:46.034475: step 7416, loss = 0.68503 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:36:47.315061 ops/training.py:65 2019-01-17 02:36:47.314975: step 7417, loss = 0.68871 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:36:48.595939 ops/training.py:65 2019-01-17 02:36:48.595839: step 7418, loss = 0.75155 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:36:49.876703 ops/training.py:65 2019-01-17 02:36:49.876593: step 7419, loss = 0.75939 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:36:51.160300 ops/training.py:65 2019-01-17 02:36:51.160199: step 7420, loss = 0.72406 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:36:52.445640 ops/training.py:65 2019-01-17 02:36:52.445531: step 7421, loss = 0.71788 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:36:53.730450 ops/training.py:65 2019-01-17 02:36:53.730350: step 7422, loss = 0.69858 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:36:55.021902 ops/training.py:65 2019-01-17 02:36:55.021807: step 7423, loss = 0.64845 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:36:56.308517 ops/training.py:65 2019-01-17 02:36:56.308456: step 7424, loss = 0.69135 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:36:57.591770 ops/training.py:65 2019-01-17 02:36:57.591673: step 7425, loss = 0.66234 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:36:58.878984 ops/training.py:65 2019-01-17 02:36:58.878878: step 7426, loss = 0.69701 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:37:00.163094 ops/training.py:65 2019-01-17 02:37:00.162999: step 7427, loss = 0.72286 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 02:37:01.454506 ops/training.py:65 2019-01-17 02:37:01.454398: step 7428, loss = 0.68398 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:37:02.746493 ops/training.py:65 2019-01-17 02:37:02.746424: step 7429, loss = 0.68659 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:37:04.035757 ops/training.py:65 2019-01-17 02:37:04.035687: step 7430, loss = 0.71137 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:37:05.316432 ops/training.py:65 2019-01-17 02:37:05.316372: step 7431, loss = 0.74037 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:37:06.600817 ops/training.py:65 2019-01-17 02:37:06.600715: step 7432, loss = 0.68482 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:37:07.887759 ops/training.py:65 2019-01-17 02:37:07.887654: step 7433, loss = 0.67461 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:37:09.172803 ops/training.py:65 2019-01-17 02:37:09.172696: step 7434, loss = 0.68179 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:37:10.463598 ops/training.py:65 2019-01-17 02:37:10.463500: step 7435, loss = 0.69449 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:37:11.753623 ops/training.py:65 2019-01-17 02:37:11.753551: step 7436, loss = 0.72473 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:37:13.043090 ops/training.py:65 2019-01-17 02:37:13.043021: step 7437, loss = 0.68371 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:37:14.327462 ops/training.py:65 2019-01-17 02:37:14.327383: step 7438, loss = 0.69475 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:37:15.613029 ops/training.py:65 2019-01-17 02:37:15.612934: step 7439, loss = 0.68543 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:37:16.905361 ops/training.py:65 2019-01-17 02:37:16.905260: step 7440, loss = 0.73463 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:37:18.195826 ops/training.py:65 2019-01-17 02:37:18.195760: step 7441, loss = 0.68751 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:37:19.480012 ops/training.py:65 2019-01-17 02:37:19.479940: step 7442, loss = 0.72617 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:37:20.769982 ops/training.py:65 2019-01-17 02:37:20.769858: step 7443, loss = 0.69038 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:37:22.060402 ops/training.py:65 2019-01-17 02:37:22.060338: step 7444, loss = 0.68340 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:37:23.347270 ops/training.py:65 2019-01-17 02:37:23.347192: step 7445, loss = 0.67091 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:37:24.638223 ops/training.py:65 2019-01-17 02:37:24.638119: step 7446, loss = 0.73216 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:37:25.927742 ops/training.py:65 2019-01-17 02:37:25.927675: step 7447, loss = 0.69234 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:37:27.216249 ops/training.py:65 2019-01-17 02:37:27.216156: step 7448, loss = 0.66481 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:37:28.505910 ops/training.py:65 2019-01-17 02:37:28.505839: step 7449, loss = 0.70748 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:37:29.794740 ops/training.py:65 2019-01-17 02:37:29.794659: step 7450, loss = 0.69511 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:37:31.090144 ops/training.py:65 2019-01-17 02:37:31.090050: step 7451, loss = 0.74232 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:37:32.375341 ops/training.py:65 2019-01-17 02:37:32.375279: step 7452, loss = 0.66305 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:37:33.660889 ops/training.py:65 2019-01-17 02:37:33.660788: step 7453, loss = 0.64847 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:37:34.945791 ops/training.py:65 2019-01-17 02:37:34.945688: step 7454, loss = 0.66603 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:37:36.233402 ops/training.py:65 2019-01-17 02:37:36.233251: step 7455, loss = 0.67464 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:37:37.523164 ops/training.py:65 2019-01-17 02:37:37.523061: step 7456, loss = 0.71782 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:37:38.807891 ops/training.py:65 2019-01-17 02:37:38.807783: step 7457, loss = 0.70777 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:37:40.100230 ops/training.py:65 2019-01-17 02:37:40.100125: step 7458, loss = 0.66385 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:37:41.386235 ops/training.py:65 2019-01-17 02:37:41.386176: step 7459, loss = 0.72346 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:37:42.670918 ops/training.py:65 2019-01-17 02:37:42.670820: step 7460, loss = 0.66503 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:37:43.963320 ops/training.py:65 2019-01-17 02:37:43.963172: step 7461, loss = 0.64353 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:37:45.255482 ops/training.py:65 2019-01-17 02:37:45.255398: step 7462, loss = 0.72026 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:37:46.541909 ops/training.py:65 2019-01-17 02:37:46.541800: step 7463, loss = 0.66242 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:37:47.822302 ops/training.py:65 2019-01-17 02:37:47.822194: step 7464, loss = 0.68803 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:37:49.113472 ops/training.py:65 2019-01-17 02:37:49.113364: step 7465, loss = 0.62762 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 02:37:50.402283 ops/training.py:65 2019-01-17 02:37:50.402216: step 7466, loss = 0.70015 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:37:51.686424 ops/training.py:65 2019-01-17 02:37:51.686364: step 7467, loss = 0.72846 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:37:52.969460 ops/training.py:65 2019-01-17 02:37:52.969310: step 7468, loss = 0.68533 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:37:54.263357 ops/training.py:65 2019-01-17 02:37:54.263257: step 7469, loss = 0.68342 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:37:55.554413 ops/training.py:65 2019-01-17 02:37:55.554262: step 7470, loss = 0.66573 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:37:56.838954 ops/training.py:65 2019-01-17 02:37:56.838856: step 7471, loss = 0.68158 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:37:58.118584 ops/training.py:65 2019-01-17 02:37:58.118482: step 7472, loss = 0.68120 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:37:59.411080 ops/training.py:65 2019-01-17 02:37:59.410975: step 7473, loss = 0.63981 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:38:00.699700 ops/training.py:65 2019-01-17 02:38:00.699610: step 7474, loss = 0.73234 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-17 02:38:01.988811 ops/training.py:65 2019-01-17 02:38:01.988715: step 7475, loss = 0.67440 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:38:03.272488 ops/training.py:65 2019-01-17 02:38:03.272411: step 7476, loss = 0.68395 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:38:04.563968 ops/training.py:65 2019-01-17 02:38:04.563868: step 7477, loss = 0.69154 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:38:05.853721 ops/training.py:65 2019-01-17 02:38:05.853628: step 7478, loss = 0.65749 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:38:07.143310 ops/training.py:65 2019-01-17 02:38:07.143237: step 7479, loss = 0.67063 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:38:08.432107 ops/training.py:65 2019-01-17 02:38:08.432040: step 7480, loss = 0.68830 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:38:09.718420 ops/training.py:65 2019-01-17 02:38:09.718353: step 7481, loss = 0.66669 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:38:11.005371 ops/training.py:65 2019-01-17 02:38:11.005304: step 7482, loss = 0.65676 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:38:12.292717 ops/training.py:65 2019-01-17 02:38:12.292652: step 7483, loss = 0.72493 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:38:13.581339 ops/training.py:65 2019-01-17 02:38:13.581272: step 7484, loss = 0.69654 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:38:14.870143 ops/training.py:65 2019-01-17 02:38:14.870075: step 7485, loss = 0.68446 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:38:16.158970 ops/training.py:65 2019-01-17 02:38:16.158901: step 7486, loss = 0.72242 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:38:17.448560 ops/training.py:65 2019-01-17 02:38:17.448478: step 7487, loss = 0.68159 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:38:18.737880 ops/training.py:65 2019-01-17 02:38:18.737805: step 7488, loss = 0.68282 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:38:20.021945 ops/training.py:65 2019-01-17 02:38:20.021879: step 7489, loss = 0.66900 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:38:21.305542 ops/training.py:65 2019-01-17 02:38:21.305435: step 7490, loss = 0.74110 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:38:22.593191 ops/training.py:65 2019-01-17 02:38:22.593082: step 7491, loss = 0.68141 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:38:23.884395 ops/training.py:65 2019-01-17 02:38:23.884254: step 7492, loss = 0.67375 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:38:25.171670 ops/training.py:65 2019-01-17 02:38:25.171583: step 7493, loss = 0.71628 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:38:26.455891 ops/training.py:65 2019-01-17 02:38:26.455792: step 7494, loss = 0.67250 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:38:27.734938 ops/training.py:65 2019-01-17 02:38:27.734828: step 7495, loss = 0.66988 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:38:29.017440 ops/training.py:65 2019-01-17 02:38:29.017334: step 7496, loss = 0.70929 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:38:30.300866 ops/training.py:65 2019-01-17 02:38:30.300769: step 7497, loss = 0.69000 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:38:31.591956 ops/training.py:65 2019-01-17 02:38:31.591860: step 7498, loss = 0.68218 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:38:32.882070 ops/training.py:65 2019-01-17 02:38:32.881983: step 7499, loss = 0.75370 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:38:34.171134 ops/training.py:65 2019-01-17 02:38:34.171064: step 7500, loss = 0.68439 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:38:35.458223 ops/training.py:65 2019-01-17 02:38:35.458152: step 7501, loss = 0.71614 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:38:36.746931 ops/training.py:65 2019-01-17 02:38:36.746862: step 7502, loss = 0.64691 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:38:38.033157 ops/training.py:65 2019-01-17 02:38:38.033091: step 7503, loss = 0.73800 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:38:39.318586 ops/training.py:65 2019-01-17 02:38:39.318522: step 7504, loss = 0.69895 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:38:40.608006 ops/training.py:65 2019-01-17 02:38:40.607895: step 7505, loss = 0.69513 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:38:41.891640 ops/training.py:65 2019-01-17 02:38:41.891536: step 7506, loss = 0.65489 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:38:43.178914 ops/training.py:65 2019-01-17 02:38:43.178804: step 7507, loss = 0.70008 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:38:44.461166 ops/training.py:65 2019-01-17 02:38:44.461060: step 7508, loss = 0.67002 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:38:45.747814 ops/training.py:65 2019-01-17 02:38:45.747722: step 7509, loss = 0.65181 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:38:47.030434 ops/training.py:65 2019-01-17 02:38:47.030334: step 7510, loss = 0.71584 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:38:48.321185 ops/training.py:65 2019-01-17 02:38:48.321076: step 7511, loss = 0.74901 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:38:49.607724 ops/training.py:65 2019-01-17 02:38:49.607660: step 7512, loss = 0.74501 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:38:50.899295 ops/training.py:65 2019-01-17 02:38:50.899196: step 7513, loss = 0.72785 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:38:52.187564 ops/training.py:65 2019-01-17 02:38:52.187414: step 7514, loss = 0.69016 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:38:53.477546 ops/training.py:65 2019-01-17 02:38:53.477443: step 7515, loss = 0.74075 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:38:54.764066 ops/training.py:65 2019-01-17 02:38:54.763981: step 7516, loss = 0.70921 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:38:56.050056 ops/training.py:65 2019-01-17 02:38:56.049984: step 7517, loss = 0.70271 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:38:57.339329 ops/training.py:65 2019-01-17 02:38:57.339263: step 7518, loss = 0.66876 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:38:58.622799 ops/training.py:65 2019-01-17 02:38:58.622692: step 7519, loss = 0.70425 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:38:59.913196 ops/training.py:65 2019-01-17 02:38:59.913099: step 7520, loss = 0.74217 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:39:01.199747 ops/training.py:65 2019-01-17 02:39:01.199664: step 7521, loss = 0.68445 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:39:02.485002 ops/training.py:65 2019-01-17 02:39:02.484902: step 7522, loss = 0.63817 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:39:03.774684 ops/training.py:65 2019-01-17 02:39:03.774609: step 7523, loss = 0.69389 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:39:05.063118 ops/training.py:65 2019-01-17 02:39:05.063045: step 7524, loss = 0.68181 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:39:06.355662 ops/training.py:65 2019-01-17 02:39:06.355513: step 7525, loss = 0.63461 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:39:07.646468 ops/training.py:65 2019-01-17 02:39:07.646398: step 7526, loss = 0.70016 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:39:08.934173 ops/training.py:65 2019-01-17 02:39:08.934091: step 7527, loss = 0.70112 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:39:10.221113 ops/training.py:65 2019-01-17 02:39:10.221017: step 7528, loss = 0.74774 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:39:11.504714 ops/training.py:65 2019-01-17 02:39:11.504636: step 7529, loss = 0.70328 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:39:12.795327 ops/training.py:65 2019-01-17 02:39:12.795199: step 7530, loss = 0.64767 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:39:14.080090 ops/training.py:65 2019-01-17 02:39:14.080020: step 7531, loss = 0.70904 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:39:15.364611 ops/training.py:65 2019-01-17 02:39:15.364537: step 7532, loss = 0.68058 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:39:16.649497 ops/training.py:65 2019-01-17 02:39:16.649429: step 7533, loss = 0.68007 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:39:17.938352 ops/training.py:65 2019-01-17 02:39:17.938241: step 7534, loss = 0.67537 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:39:19.227640 ops/training.py:65 2019-01-17 02:39:19.227530: step 7535, loss = 0.68044 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:39:20.516722 ops/training.py:65 2019-01-17 02:39:20.516653: step 7536, loss = 0.70902 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:39:21.806374 ops/training.py:65 2019-01-17 02:39:21.806262: step 7537, loss = 0.70317 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:39:23.096206 ops/training.py:65 2019-01-17 02:39:23.096132: step 7538, loss = 0.68759 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:39:24.386116 ops/training.py:65 2019-01-17 02:39:24.386051: step 7539, loss = 0.71800 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:39:25.676330 ops/training.py:65 2019-01-17 02:39:25.676261: step 7540, loss = 0.65940 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:39:26.962384 ops/training.py:65 2019-01-17 02:39:26.962324: step 7541, loss = 0.68234 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:39:28.246451 ops/training.py:65 2019-01-17 02:39:28.246386: step 7542, loss = 0.67401 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:39:29.534881 ops/training.py:65 2019-01-17 02:39:29.534781: step 7543, loss = 0.67123 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:39:30.824543 ops/training.py:65 2019-01-17 02:39:30.824440: step 7544, loss = 0.68415 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:39:32.113415 ops/training.py:65 2019-01-17 02:39:32.113323: step 7545, loss = 0.69419 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:39:33.402541 ops/training.py:65 2019-01-17 02:39:33.402468: step 7546, loss = 0.63574 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 02:39:34.687117 ops/training.py:65 2019-01-17 02:39:34.687051: step 7547, loss = 0.66245 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:39:35.973500 ops/training.py:65 2019-01-17 02:39:35.973429: step 7548, loss = 0.68859 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:39:37.261920 ops/training.py:65 2019-01-17 02:39:37.261855: step 7549, loss = 0.66754 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:39:38.551701 ops/training.py:65 2019-01-17 02:39:38.551617: step 7550, loss = 0.68482 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:39:39.839702 ops/training.py:65 2019-01-17 02:39:39.839640: step 7551, loss = 0.64647 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:39:41.124907 ops/training.py:65 2019-01-17 02:39:41.124842: step 7552, loss = 0.69836 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:39:42.412561 ops/training.py:65 2019-01-17 02:39:42.412494: step 7553, loss = 0.64950 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:39:43.701683 ops/training.py:65 2019-01-17 02:39:43.701589: step 7554, loss = 0.72563 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:39:44.992500 ops/training.py:65 2019-01-17 02:39:44.992433: step 7555, loss = 0.67697 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:39:46.282572 ops/training.py:65 2019-01-17 02:39:46.282482: step 7556, loss = 0.61322 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:39:47.566881 ops/training.py:65 2019-01-17 02:39:47.566784: step 7557, loss = 0.65883 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:39:48.859713 ops/training.py:65 2019-01-17 02:39:48.859605: step 7558, loss = 0.70716 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:39:50.143123 ops/training.py:65 2019-01-17 02:39:50.143056: step 7559, loss = 0.70345 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:39:51.424184 ops/training.py:65 2019-01-17 02:39:51.424070: step 7560, loss = 0.68937 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:39:52.716010 ops/training.py:65 2019-01-17 02:39:52.715907: step 7561, loss = 0.66021 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:39:54.007602 ops/training.py:65 2019-01-17 02:39:54.007500: step 7562, loss = 0.67048 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:39:55.288815 ops/training.py:65 2019-01-17 02:39:55.288723: step 7563, loss = 0.73168 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:39:56.570540 ops/training.py:65 2019-01-17 02:39:56.570435: step 7564, loss = 0.69639 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:39:57.861524 ops/training.py:65 2019-01-17 02:39:57.861370: step 7565, loss = 0.70615 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:39:59.143068 ops/training.py:65 2019-01-17 02:39:59.142960: step 7566, loss = 0.67926 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:40:00.430751 ops/training.py:65 2019-01-17 02:40:00.430654: step 7567, loss = 0.67182 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:40:01.720765 ops/training.py:65 2019-01-17 02:40:01.720697: step 7568, loss = 0.71700 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:40:03.007144 ops/training.py:65 2019-01-17 02:40:03.007080: step 7569, loss = 0.70364 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:40:04.288915 ops/training.py:65 2019-01-17 02:40:04.288807: step 7570, loss = 0.72241 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:40:05.575617 ops/training.py:65 2019-01-17 02:40:05.575508: step 7571, loss = 0.65899 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:40:06.861602 ops/training.py:65 2019-01-17 02:40:06.861496: step 7572, loss = 0.66309 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:40:08.155936 ops/training.py:65 2019-01-17 02:40:08.155829: step 7573, loss = 0.71616 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:40:09.447009 ops/training.py:65 2019-01-17 02:40:09.446922: step 7574, loss = 0.69667 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:40:10.732992 ops/training.py:65 2019-01-17 02:40:10.732922: step 7575, loss = 0.67273 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:40:12.016246 ops/training.py:65 2019-01-17 02:40:12.016176: step 7576, loss = 0.67263 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:40:13.298297 ops/training.py:65 2019-01-17 02:40:13.298193: step 7577, loss = 0.68735 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:40:14.585903 ops/training.py:65 2019-01-17 02:40:14.585799: step 7578, loss = 0.65856 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:40:15.870001 ops/training.py:65 2019-01-17 02:40:15.869898: step 7579, loss = 0.67465 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:40:17.161920 ops/training.py:65 2019-01-17 02:40:17.161812: step 7580, loss = 0.66334 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:40:18.452789 ops/training.py:65 2019-01-17 02:40:18.452695: step 7581, loss = 0.71293 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:40:19.742455 ops/training.py:65 2019-01-17 02:40:19.742385: step 7582, loss = 0.69626 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:40:21.032629 ops/training.py:65 2019-01-17 02:40:21.032531: step 7583, loss = 0.70566 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:40:22.321409 ops/training.py:65 2019-01-17 02:40:22.321336: step 7584, loss = 0.65111 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:40:23.609916 ops/training.py:65 2019-01-17 02:40:23.609831: step 7585, loss = 0.72705 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:40:24.900297 ops/training.py:65 2019-01-17 02:40:24.900230: step 7586, loss = 0.70431 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:40:26.189384 ops/training.py:65 2019-01-17 02:40:26.189316: step 7587, loss = 0.68782 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:40:27.478653 ops/training.py:65 2019-01-17 02:40:27.478582: step 7588, loss = 0.66831 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:40:28.768290 ops/training.py:65 2019-01-17 02:40:28.768201: step 7589, loss = 0.70441 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:40:30.054585 ops/training.py:65 2019-01-17 02:40:30.054487: step 7590, loss = 0.69846 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:40:31.338220 ops/training.py:65 2019-01-17 02:40:31.338151: step 7591, loss = 0.73463 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:40:32.626890 ops/training.py:65 2019-01-17 02:40:32.626829: step 7592, loss = 0.69946 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:40:33.913857 ops/training.py:65 2019-01-17 02:40:33.913781: step 7593, loss = 0.66965 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:40:35.202561 ops/training.py:65 2019-01-17 02:40:35.202478: step 7594, loss = 0.69978 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:40:36.493134 ops/training.py:65 2019-01-17 02:40:36.493073: step 7595, loss = 0.72210 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:40:37.781612 ops/training.py:65 2019-01-17 02:40:37.781540: step 7596, loss = 0.68928 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:40:39.069659 ops/training.py:65 2019-01-17 02:40:39.069585: step 7597, loss = 0.65646 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:40:40.358795 ops/training.py:65 2019-01-17 02:40:40.358726: step 7598, loss = 0.72332 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 02:40:41.642721 ops/training.py:65 2019-01-17 02:40:41.642657: step 7599, loss = 0.65426 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:40:42.929920 ops/training.py:65 2019-01-17 02:40:42.929857: step 7600, loss = 0.68338 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:40:44.215516 ops/training.py:65 2019-01-17 02:40:44.215450: step 7601, loss = 0.67320 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:40:45.504370 ops/training.py:65 2019-01-17 02:40:45.504291: step 7602, loss = 0.68613 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:40:46.794137 ops/training.py:65 2019-01-17 02:40:46.794072: step 7603, loss = 0.70211 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:40:48.077549 ops/training.py:65 2019-01-17 02:40:48.077473: step 7604, loss = 0.67983 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:40:49.368231 ops/training.py:65 2019-01-17 02:40:49.368122: step 7605, loss = 0.70062 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:40:50.659226 ops/training.py:65 2019-01-17 02:40:50.659168: step 7606, loss = 0.67658 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:40:51.947576 ops/training.py:65 2019-01-17 02:40:51.947501: step 7607, loss = 0.69319 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:40:53.232445 ops/training.py:65 2019-01-17 02:40:53.232367: step 7608, loss = 0.67583 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:40:54.519146 ops/training.py:65 2019-01-17 02:40:54.519043: step 7609, loss = 0.63984 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:40:55.805976 ops/training.py:65 2019-01-17 02:40:55.805866: step 7610, loss = 0.72345 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:40:57.098313 ops/training.py:65 2019-01-17 02:40:57.098176: step 7611, loss = 0.66902 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:40:58.389255 ops/training.py:65 2019-01-17 02:40:58.389185: step 7612, loss = 0.68186 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:40:59.671193 ops/training.py:65 2019-01-17 02:40:59.671123: step 7613, loss = 0.67834 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:41:00.955777 ops/training.py:65 2019-01-17 02:41:00.955645: step 7614, loss = 0.67665 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:41:02.238749 ops/training.py:65 2019-01-17 02:41:02.238643: step 7615, loss = 0.73684 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:41:03.519779 ops/training.py:65 2019-01-17 02:41:03.519680: step 7616, loss = 0.75471 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 02:41:04.812102 ops/training.py:65 2019-01-17 02:41:04.811996: step 7617, loss = 0.74451 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:41:06.093432 ops/training.py:65 2019-01-17 02:41:06.093336: step 7618, loss = 0.68693 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:41:07.378259 ops/training.py:65 2019-01-17 02:41:07.378150: step 7619, loss = 0.73239 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:41:08.666029 ops/training.py:65 2019-01-17 02:41:08.665918: step 7620, loss = 0.72985 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:41:09.949716 ops/training.py:65 2019-01-17 02:41:09.949613: step 7621, loss = 0.74530 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:41:11.236367 ops/training.py:65 2019-01-17 02:41:11.236259: step 7622, loss = 0.76379 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:41:12.522080 ops/training.py:65 2019-01-17 02:41:12.521968: step 7623, loss = 0.71860 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:41:13.808017 ops/training.py:65 2019-01-17 02:41:13.807910: step 7624, loss = 0.65016 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:41:15.097364 ops/training.py:65 2019-01-17 02:41:15.097243: step 7625, loss = 0.68315 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:41:16.382392 ops/training.py:65 2019-01-17 02:41:16.382327: step 7626, loss = 0.66051 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:41:17.666298 ops/training.py:65 2019-01-17 02:41:17.666189: step 7627, loss = 0.71013 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:41:18.948536 ops/training.py:65 2019-01-17 02:41:18.948428: step 7628, loss = 0.67520 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:41:20.233458 ops/training.py:65 2019-01-17 02:41:20.233352: step 7629, loss = 0.67141 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:41:21.521251 ops/training.py:65 2019-01-17 02:41:21.521142: step 7630, loss = 0.69423 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:41:22.806920 ops/training.py:65 2019-01-17 02:41:22.806808: step 7631, loss = 0.73187 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:41:24.091395 ops/training.py:65 2019-01-17 02:41:24.091298: step 7632, loss = 0.65988 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:41:25.377723 ops/training.py:65 2019-01-17 02:41:25.377615: step 7633, loss = 0.69367 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:41:26.668427 ops/training.py:65 2019-01-17 02:41:26.668268: step 7634, loss = 0.70081 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:41:27.953344 ops/training.py:65 2019-01-17 02:41:27.953277: step 7635, loss = 0.69484 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:41:29.234183 ops/training.py:65 2019-01-17 02:41:29.234072: step 7636, loss = 0.72113 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:41:30.517977 ops/training.py:65 2019-01-17 02:41:30.517888: step 7637, loss = 0.69174 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:41:31.803740 ops/training.py:65 2019-01-17 02:41:31.803634: step 7638, loss = 0.69154 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:41:33.085654 ops/training.py:65 2019-01-17 02:41:33.085563: step 7639, loss = 0.68259 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:41:34.370756 ops/training.py:65 2019-01-17 02:41:34.370656: step 7640, loss = 0.60282 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 02:41:35.655581 ops/training.py:65 2019-01-17 02:41:35.655488: step 7641, loss = 0.67978 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:41:36.939305 ops/training.py:65 2019-01-17 02:41:36.939202: step 7642, loss = 0.75254 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:41:38.222806 ops/training.py:65 2019-01-17 02:41:38.222710: step 7643, loss = 0.70809 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:41:39.503310 ops/training.py:65 2019-01-17 02:41:39.503214: step 7644, loss = 0.63816 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:41:40.790775 ops/training.py:65 2019-01-17 02:41:40.790678: step 7645, loss = 0.71195 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:41:42.080223 ops/training.py:65 2019-01-17 02:41:42.080116: step 7646, loss = 0.58896 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 02:41:43.369757 ops/training.py:65 2019-01-17 02:41:43.369686: step 7647, loss = 0.68002 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:41:44.653924 ops/training.py:65 2019-01-17 02:41:44.653861: step 7648, loss = 0.69351 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:41:45.941781 ops/training.py:65 2019-01-17 02:41:45.941687: step 7649, loss = 0.70449 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:41:47.229432 ops/training.py:65 2019-01-17 02:41:47.229347: step 7650, loss = 0.71215 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:41:48.512441 ops/training.py:65 2019-01-17 02:41:48.512377: step 7651, loss = 0.69509 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:41:49.800897 ops/training.py:65 2019-01-17 02:41:49.800804: step 7652, loss = 0.68476 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:41:51.081740 ops/training.py:65 2019-01-17 02:41:51.081630: step 7653, loss = 0.67725 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:41:52.365785 ops/training.py:65 2019-01-17 02:41:52.365687: step 7654, loss = 0.70902 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:41:53.650509 ops/training.py:65 2019-01-17 02:41:53.650414: step 7655, loss = 0.67619 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:41:54.933403 ops/training.py:65 2019-01-17 02:41:54.933308: step 7656, loss = 0.69013 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:41:56.217862 ops/training.py:65 2019-01-17 02:41:56.217759: step 7657, loss = 0.63253 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:41:57.504253 ops/training.py:65 2019-01-17 02:41:57.504154: step 7658, loss = 0.68197 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:41:58.792358 ops/training.py:65 2019-01-17 02:41:58.792265: step 7659, loss = 0.70136 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:42:00.084062 ops/training.py:65 2019-01-17 02:42:00.083973: step 7660, loss = 0.70526 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:42:01.367667 ops/training.py:65 2019-01-17 02:42:01.367599: step 7661, loss = 0.68502 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:42:02.657063 ops/training.py:65 2019-01-17 02:42:02.656956: step 7662, loss = 0.66726 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:42:03.941223 ops/training.py:65 2019-01-17 02:42:03.941151: step 7663, loss = 0.71581 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:42:05.228197 ops/training.py:65 2019-01-17 02:42:05.228101: step 7664, loss = 0.73114 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:42:06.517490 ops/training.py:65 2019-01-17 02:42:06.517419: step 7665, loss = 0.70811 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:42:07.802728 ops/training.py:65 2019-01-17 02:42:07.802657: step 7666, loss = 0.72162 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:42:09.088284 ops/training.py:65 2019-01-17 02:42:09.088181: step 7667, loss = 0.70255 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:42:10.381405 ops/training.py:65 2019-01-17 02:42:10.381304: step 7668, loss = 0.71860 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:42:11.667405 ops/training.py:65 2019-01-17 02:42:11.667331: step 7669, loss = 0.68157 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:42:12.953660 ops/training.py:65 2019-01-17 02:42:12.953581: step 7670, loss = 0.68746 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:42:14.245419 ops/training.py:65 2019-01-17 02:42:14.245325: step 7671, loss = 0.70221 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:42:15.538720 ops/training.py:65 2019-01-17 02:42:15.538657: step 7672, loss = 0.68274 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:42:16.823094 ops/training.py:65 2019-01-17 02:42:16.823030: step 7673, loss = 0.70104 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:42:18.105975 ops/training.py:65 2019-01-17 02:42:18.105875: step 7674, loss = 0.68376 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:42:19.397723 ops/training.py:65 2019-01-17 02:42:19.397625: step 7675, loss = 0.65264 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:42:20.688726 ops/training.py:65 2019-01-17 02:42:20.688655: step 7676, loss = 0.71680 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:42:21.973295 ops/training.py:65 2019-01-17 02:42:21.973232: step 7677, loss = 0.72874 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:42:23.261765 ops/training.py:65 2019-01-17 02:42:23.261682: step 7678, loss = 0.67327 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:42:24.551081 ops/training.py:65 2019-01-17 02:42:24.551010: step 7679, loss = 0.69851 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:42:25.834791 ops/training.py:65 2019-01-17 02:42:25.834719: step 7680, loss = 0.73312 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:42:27.118771 ops/training.py:65 2019-01-17 02:42:27.118624: step 7681, loss = 0.62943 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:42:28.409007 ops/training.py:65 2019-01-17 02:42:28.408867: step 7682, loss = 0.69280 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:42:29.698151 ops/training.py:65 2019-01-17 02:42:29.698053: step 7683, loss = 0.71677 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:42:30.985972 ops/training.py:65 2019-01-17 02:42:30.985899: step 7684, loss = 0.70629 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:42:32.273963 ops/training.py:65 2019-01-17 02:42:32.273882: step 7685, loss = 0.69855 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:42:33.557167 ops/training.py:65 2019-01-17 02:42:33.557095: step 7686, loss = 0.70001 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:42:34.841830 ops/training.py:65 2019-01-17 02:42:34.841750: step 7687, loss = 0.71389 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:42:36.133295 ops/training.py:65 2019-01-17 02:42:36.133141: step 7688, loss = 0.71763 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:42:37.417948 ops/training.py:65 2019-01-17 02:42:37.417862: step 7689, loss = 0.67738 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:42:38.704705 ops/training.py:65 2019-01-17 02:42:38.704598: step 7690, loss = 0.68509 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:42:39.994287 ops/training.py:65 2019-01-17 02:42:39.994188: step 7691, loss = 0.71677 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:42:41.278655 ops/training.py:65 2019-01-17 02:42:41.278554: step 7692, loss = 0.69037 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:42:42.566046 ops/training.py:65 2019-01-17 02:42:42.565897: step 7693, loss = 0.68360 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:42:43.851479 ops/training.py:65 2019-01-17 02:42:43.851408: step 7694, loss = 0.71703 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:42:45.134661 ops/training.py:65 2019-01-17 02:42:45.134589: step 7695, loss = 0.67643 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:42:46.422696 ops/training.py:65 2019-01-17 02:42:46.422545: step 7696, loss = 0.68291 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:42:47.707837 ops/training.py:65 2019-01-17 02:42:47.707774: step 7697, loss = 0.74715 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:42:48.987568 ops/training.py:65 2019-01-17 02:42:48.987413: step 7698, loss = 0.70478 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:42:50.275734 ops/training.py:65 2019-01-17 02:42:50.275626: step 7699, loss = 0.64429 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:42:51.561996 ops/training.py:65 2019-01-17 02:42:51.561928: step 7700, loss = 0.73643 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:42:52.850886 ops/training.py:65 2019-01-17 02:42:52.850812: step 7701, loss = 0.70134 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:42:54.134388 ops/training.py:65 2019-01-17 02:42:54.134303: step 7702, loss = 0.66953 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:42:55.422291 ops/training.py:65 2019-01-17 02:42:55.422225: step 7703, loss = 0.70391 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:42:56.711355 ops/training.py:65 2019-01-17 02:42:56.711292: step 7704, loss = 0.67454 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:42:58.000734 ops/training.py:65 2019-01-17 02:42:58.000657: step 7705, loss = 0.72380 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:42:59.287876 ops/training.py:65 2019-01-17 02:42:59.287762: step 7706, loss = 0.68289 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:43:00.572031 ops/training.py:65 2019-01-17 02:43:00.571929: step 7707, loss = 0.67048 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:43:01.863112 ops/training.py:65 2019-01-17 02:43:01.863007: step 7708, loss = 0.67466 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:43:03.153643 ops/training.py:65 2019-01-17 02:43:03.153572: step 7709, loss = 0.68303 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:43:04.442231 ops/training.py:65 2019-01-17 02:43:04.442161: step 7710, loss = 0.68548 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:43:05.726320 ops/training.py:65 2019-01-17 02:43:05.726254: step 7711, loss = 0.69184 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:43:07.005941 ops/training.py:65 2019-01-17 02:43:07.005840: step 7712, loss = 0.71722 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:43:08.294336 ops/training.py:65 2019-01-17 02:43:08.294228: step 7713, loss = 0.68632 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:43:09.578222 ops/training.py:65 2019-01-17 02:43:09.578115: step 7714, loss = 0.70563 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:43:10.866025 ops/training.py:65 2019-01-17 02:43:10.865867: step 7715, loss = 0.66908 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:43:12.149153 ops/training.py:65 2019-01-17 02:43:12.149044: step 7716, loss = 0.66375 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:43:13.437063 ops/training.py:65 2019-01-17 02:43:13.436961: step 7717, loss = 0.71437 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:43:14.723170 ops/training.py:65 2019-01-17 02:43:14.723097: step 7718, loss = 0.65420 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:43:16.011847 ops/training.py:65 2019-01-17 02:43:16.011759: step 7719, loss = 0.69413 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:43:17.296978 ops/training.py:65 2019-01-17 02:43:17.296914: step 7720, loss = 0.68759 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:43:18.581586 ops/training.py:65 2019-01-17 02:43:18.581494: step 7721, loss = 0.67696 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:43:19.871157 ops/training.py:65 2019-01-17 02:43:19.871044: step 7722, loss = 0.67285 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:43:21.158693 ops/training.py:65 2019-01-17 02:43:21.158590: step 7723, loss = 0.66933 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:43:22.441258 ops/training.py:65 2019-01-17 02:43:22.441150: step 7724, loss = 0.71248 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:43:23.727972 ops/training.py:65 2019-01-17 02:43:23.727873: step 7725, loss = 0.69175 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:43:25.014044 ops/training.py:65 2019-01-17 02:43:25.013935: step 7726, loss = 0.67683 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:43:26.297054 ops/training.py:65 2019-01-17 02:43:26.296943: step 7727, loss = 0.70846 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:43:27.585263 ops/training.py:65 2019-01-17 02:43:27.585120: step 7728, loss = 0.70241 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:43:28.872754 ops/training.py:65 2019-01-17 02:43:28.872684: step 7729, loss = 0.67399 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:43:30.161490 ops/training.py:65 2019-01-17 02:43:30.161419: step 7730, loss = 0.64557 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:43:31.449849 ops/training.py:65 2019-01-17 02:43:31.449779: step 7731, loss = 0.68477 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:43:32.737507 ops/training.py:65 2019-01-17 02:43:32.737437: step 7732, loss = 0.66829 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:43:34.019818 ops/training.py:65 2019-01-17 02:43:34.019746: step 7733, loss = 0.66689 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:43:35.309318 ops/training.py:65 2019-01-17 02:43:35.309212: step 7734, loss = 0.70089 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:43:36.599434 ops/training.py:65 2019-01-17 02:43:36.599354: step 7735, loss = 0.70672 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:43:37.888081 ops/training.py:65 2019-01-17 02:43:37.888013: step 7736, loss = 0.73258 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:43:39.176109 ops/training.py:65 2019-01-17 02:43:39.176045: step 7737, loss = 0.70469 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:43:40.459996 ops/training.py:65 2019-01-17 02:43:40.459921: step 7738, loss = 0.68158 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:43:41.746412 ops/training.py:65 2019-01-17 02:43:41.746316: step 7739, loss = 0.70069 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:43:43.041815 ops/training.py:65 2019-01-17 02:43:43.041745: step 7740, loss = 0.71386 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:43:44.331327 ops/training.py:65 2019-01-17 02:43:44.331251: step 7741, loss = 0.63968 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:43:45.622125 ops/training.py:65 2019-01-17 02:43:45.621981: step 7742, loss = 0.71877 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:43:46.909206 ops/training.py:65 2019-01-17 02:43:46.909142: step 7743, loss = 0.67147 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:43:48.193012 ops/training.py:65 2019-01-17 02:43:48.192947: step 7744, loss = 0.67994 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:43:49.474846 ops/training.py:65 2019-01-17 02:43:49.474737: step 7745, loss = 0.66167 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:43:50.766337 ops/training.py:65 2019-01-17 02:43:50.766185: step 7746, loss = 0.67678 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:43:52.053134 ops/training.py:65 2019-01-17 02:43:52.053072: step 7747, loss = 0.68248 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:43:53.340729 ops/training.py:65 2019-01-17 02:43:53.340656: step 7748, loss = 0.67756 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:43:54.629308 ops/training.py:65 2019-01-17 02:43:54.629232: step 7749, loss = 0.66749 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:43:55.917864 ops/training.py:65 2019-01-17 02:43:55.917767: step 7750, loss = 0.70281 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:43:57.207483 ops/training.py:65 2019-01-17 02:43:57.207390: step 7751, loss = 0.70657 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:43:58.493671 ops/training.py:65 2019-01-17 02:43:58.493593: step 7752, loss = 0.62742 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:43:59.782154 ops/training.py:65 2019-01-17 02:43:59.782083: step 7753, loss = 0.77314 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:44:01.071578 ops/training.py:65 2019-01-17 02:44:01.071487: step 7754, loss = 0.71563 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:44:02.360554 ops/training.py:65 2019-01-17 02:44:02.360481: step 7755, loss = 0.71884 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:44:03.648476 ops/training.py:65 2019-01-17 02:44:03.648402: step 7756, loss = 0.70949 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:44:04.936965 ops/training.py:65 2019-01-17 02:44:04.936872: step 7757, loss = 0.63833 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:44:06.225929 ops/training.py:65 2019-01-17 02:44:06.225841: step 7758, loss = 0.69285 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:44:07.514595 ops/training.py:65 2019-01-17 02:44:07.514522: step 7759, loss = 0.73266 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:44:08.803776 ops/training.py:65 2019-01-17 02:44:08.803671: step 7760, loss = 0.75790 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:44:10.092435 ops/training.py:65 2019-01-17 02:44:10.092361: step 7761, loss = 0.70759 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:44:11.377209 ops/training.py:65 2019-01-17 02:44:11.377122: step 7762, loss = 0.69169 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:44:12.665649 ops/training.py:65 2019-01-17 02:44:12.665576: step 7763, loss = 0.67921 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:44:13.948217 ops/training.py:65 2019-01-17 02:44:13.948139: step 7764, loss = 0.70768 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:44:15.231230 ops/training.py:65 2019-01-17 02:44:15.231161: step 7765, loss = 0.68660 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:44:16.523132 ops/training.py:65 2019-01-17 02:44:16.522983: step 7766, loss = 0.67879 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:44:17.813538 ops/training.py:65 2019-01-17 02:44:17.813461: step 7767, loss = 0.65922 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:44:19.098263 ops/training.py:65 2019-01-17 02:44:19.098197: step 7768, loss = 0.65201 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:44:20.380847 ops/training.py:65 2019-01-17 02:44:20.380777: step 7769, loss = 0.68384 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:44:21.671487 ops/training.py:65 2019-01-17 02:44:21.671384: step 7770, loss = 0.64530 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:44:22.956256 ops/training.py:65 2019-01-17 02:44:22.956195: step 7771, loss = 0.70076 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:44:24.244664 ops/training.py:65 2019-01-17 02:44:24.244592: step 7772, loss = 0.73116 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:44:25.535278 ops/training.py:65 2019-01-17 02:44:25.535181: step 7773, loss = 0.68908 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:44:26.824158 ops/training.py:65 2019-01-17 02:44:26.824064: step 7774, loss = 0.68560 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:44:28.111671 ops/training.py:65 2019-01-17 02:44:28.111605: step 7775, loss = 0.66250 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:44:29.399616 ops/training.py:65 2019-01-17 02:44:29.399538: step 7776, loss = 0.65384 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:44:30.688893 ops/training.py:65 2019-01-17 02:44:30.688816: step 7777, loss = 0.68511 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:44:31.978246 ops/training.py:65 2019-01-17 02:44:31.978176: step 7778, loss = 0.67881 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:44:33.261375 ops/training.py:65 2019-01-17 02:44:33.261296: step 7779, loss = 0.66049 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:44:34.543199 ops/training.py:65 2019-01-17 02:44:34.543108: step 7780, loss = 0.69476 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:44:35.834789 ops/training.py:65 2019-01-17 02:44:35.834681: step 7781, loss = 0.68635 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:44:37.125138 ops/training.py:65 2019-01-17 02:44:37.125034: step 7782, loss = 0.72335 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:44:38.414868 ops/training.py:65 2019-01-17 02:44:38.414793: step 7783, loss = 0.71727 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:44:39.702903 ops/training.py:65 2019-01-17 02:44:39.702835: step 7784, loss = 0.67060 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:44:40.990865 ops/training.py:65 2019-01-17 02:44:40.990792: step 7785, loss = 0.68817 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:44:42.279453 ops/training.py:65 2019-01-17 02:44:42.279385: step 7786, loss = 0.68743 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:44:43.564248 ops/training.py:65 2019-01-17 02:44:43.564180: step 7787, loss = 0.68015 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:44:44.848593 ops/training.py:65 2019-01-17 02:44:44.848488: step 7788, loss = 0.68418 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:44:46.132426 ops/training.py:65 2019-01-17 02:44:46.132338: step 7789, loss = 0.67643 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:44:47.424090 ops/training.py:65 2019-01-17 02:44:47.423981: step 7790, loss = 0.70220 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:44:48.709146 ops/training.py:65 2019-01-17 02:44:48.709075: step 7791, loss = 0.72366 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:44:50.000560 ops/training.py:65 2019-01-17 02:44:50.000410: step 7792, loss = 0.66944 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:44:51.289892 ops/training.py:65 2019-01-17 02:44:51.289825: step 7793, loss = 0.65680 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:44:52.573666 ops/training.py:65 2019-01-17 02:44:52.573606: step 7794, loss = 0.68709 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:44:53.859047 ops/training.py:65 2019-01-17 02:44:53.858946: step 7795, loss = 0.69233 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:44:55.149020 ops/training.py:65 2019-01-17 02:44:55.148950: step 7796, loss = 0.77071 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:44:56.433266 ops/training.py:65 2019-01-17 02:44:56.433195: step 7797, loss = 0.65956 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:44:57.717791 ops/training.py:65 2019-01-17 02:44:57.717722: step 7798, loss = 0.65935 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:44:59.001035 ops/training.py:65 2019-01-17 02:44:59.000932: step 7799, loss = 0.76332 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:45:00.288195 ops/training.py:65 2019-01-17 02:45:00.288099: step 7800, loss = 0.70090 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:45:01.568060 ops/training.py:65 2019-01-17 02:45:01.567958: step 7801, loss = 0.59763 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 02:45:02.848048 ops/training.py:65 2019-01-17 02:45:02.847936: step 7802, loss = 0.63178 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 02:45:04.136299 ops/training.py:65 2019-01-17 02:45:04.136197: step 7803, loss = 0.74401 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:45:05.420846 ops/training.py:65 2019-01-17 02:45:05.420764: step 7804, loss = 0.73264 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:45:06.711524 ops/training.py:65 2019-01-17 02:45:06.711408: step 7805, loss = 0.70204 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:45:07.996017 ops/training.py:65 2019-01-17 02:45:07.995938: step 7806, loss = 0.65996 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:45:09.287703 ops/training.py:65 2019-01-17 02:45:09.287565: step 7807, loss = 0.65731 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:45:10.567969 ops/training.py:65 2019-01-17 02:45:10.567886: step 7808, loss = 0.70601 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:45:11.854266 ops/training.py:65 2019-01-17 02:45:11.854155: step 7809, loss = 0.71885 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:45:13.130640 ops/training.py:65 2019-01-17 02:45:13.130537: step 7810, loss = 0.65762 (25.1 examples/sec; 1.275 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:45:14.415179 ops/training.py:65 2019-01-17 02:45:14.415076: step 7811, loss = 0.68361 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:45:15.706100 ops/training.py:65 2019-01-17 02:45:15.706010: step 7812, loss = 0.67758 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:45:16.991561 ops/training.py:65 2019-01-17 02:45:16.991497: step 7813, loss = 0.70374 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:45:18.274538 ops/training.py:65 2019-01-17 02:45:18.274465: step 7814, loss = 0.71303 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:45:19.563045 ops/training.py:65 2019-01-17 02:45:19.562939: step 7815, loss = 0.66177 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:45:20.851009 ops/training.py:65 2019-01-17 02:45:20.850896: step 7816, loss = 0.67478 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:45:22.132025 ops/training.py:65 2019-01-17 02:45:22.131925: step 7817, loss = 0.64482 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:45:23.411455 ops/training.py:65 2019-01-17 02:45:23.411348: step 7818, loss = 0.69979 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:45:24.695874 ops/training.py:65 2019-01-17 02:45:24.695720: step 7819, loss = 0.60229 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 02:45:25.987981 ops/training.py:65 2019-01-17 02:45:25.987876: step 7820, loss = 0.70737 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:45:27.274196 ops/training.py:65 2019-01-17 02:45:27.274125: step 7821, loss = 0.67788 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:45:28.557116 ops/training.py:65 2019-01-17 02:45:28.557014: step 7822, loss = 0.68932 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:45:29.846469 ops/training.py:65 2019-01-17 02:45:29.846370: step 7823, loss = 0.70535 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:45:31.129527 ops/training.py:65 2019-01-17 02:45:31.129437: step 7824, loss = 0.68400 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:45:32.414276 ops/training.py:65 2019-01-17 02:45:32.414174: step 7825, loss = 0.69015 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:45:33.706477 ops/training.py:65 2019-01-17 02:45:33.706385: step 7826, loss = 0.69347 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:45:34.994856 ops/training.py:65 2019-01-17 02:45:34.994784: step 7827, loss = 0.67779 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:45:36.283589 ops/training.py:65 2019-01-17 02:45:36.283498: step 7828, loss = 0.68172 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:45:37.571555 ops/training.py:65 2019-01-17 02:45:37.571485: step 7829, loss = 0.71932 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:45:38.859407 ops/training.py:65 2019-01-17 02:45:38.859335: step 7830, loss = 0.70889 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:45:40.146673 ops/training.py:65 2019-01-17 02:45:40.146597: step 7831, loss = 0.67478 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:45:41.435494 ops/training.py:65 2019-01-17 02:45:41.435415: step 7832, loss = 0.68175 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:45:42.724087 ops/training.py:65 2019-01-17 02:45:42.724016: step 7833, loss = 0.68147 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:45:44.007365 ops/training.py:65 2019-01-17 02:45:44.007298: step 7834, loss = 0.70750 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:45:45.290902 ops/training.py:65 2019-01-17 02:45:45.290839: step 7835, loss = 0.66912 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:45:46.580321 ops/training.py:65 2019-01-17 02:45:46.580218: step 7836, loss = 0.65403 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:45:47.864247 ops/training.py:65 2019-01-17 02:45:47.864185: step 7837, loss = 0.67351 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:45:49.148465 ops/training.py:65 2019-01-17 02:45:49.148367: step 7838, loss = 0.69533 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:45:50.435235 ops/training.py:65 2019-01-17 02:45:50.435134: step 7839, loss = 0.70106 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:45:51.725554 ops/training.py:65 2019-01-17 02:45:51.725478: step 7840, loss = 0.70157 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:45:53.006349 ops/training.py:65 2019-01-17 02:45:53.006281: step 7841, loss = 0.68486 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:45:54.290075 ops/training.py:65 2019-01-17 02:45:54.289963: step 7842, loss = 0.64245 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 02:45:55.574456 ops/training.py:65 2019-01-17 02:45:55.574352: step 7843, loss = 0.71041 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:45:56.865131 ops/training.py:65 2019-01-17 02:45:56.865026: step 7844, loss = 0.69513 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:45:58.154724 ops/training.py:65 2019-01-17 02:45:58.154640: step 7845, loss = 0.67774 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:45:59.444148 ops/training.py:65 2019-01-17 02:45:59.444075: step 7846, loss = 0.65523 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:46:00.736887 ops/training.py:65 2019-01-17 02:46:00.736815: step 7847, loss = 0.67057 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:46:02.021636 ops/training.py:65 2019-01-17 02:46:02.021568: step 7848, loss = 0.66049 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:46:03.308202 ops/training.py:65 2019-01-17 02:46:03.308123: step 7849, loss = 0.69561 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:46:04.600257 ops/training.py:65 2019-01-17 02:46:04.600158: step 7850, loss = 0.72744 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:46:05.887099 ops/training.py:65 2019-01-17 02:46:05.887031: step 7851, loss = 0.67272 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:46:07.173167 ops/training.py:65 2019-01-17 02:46:07.173098: step 7852, loss = 0.65898 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:46:08.462807 ops/training.py:65 2019-01-17 02:46:08.462699: step 7853, loss = 0.71280 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:46:09.753714 ops/training.py:65 2019-01-17 02:46:09.753629: step 7854, loss = 0.68378 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:46:11.037004 ops/training.py:65 2019-01-17 02:46:11.036937: step 7855, loss = 0.70624 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:46:12.325288 ops/training.py:65 2019-01-17 02:46:12.325218: step 7856, loss = 0.65124 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:46:13.613419 ops/training.py:65 2019-01-17 02:46:13.613351: step 7857, loss = 0.67218 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:46:14.902889 ops/training.py:65 2019-01-17 02:46:14.902809: step 7858, loss = 0.67523 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:46:16.191621 ops/training.py:65 2019-01-17 02:46:16.191538: step 7859, loss = 0.67012 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:46:17.479511 ops/training.py:65 2019-01-17 02:46:17.479445: step 7860, loss = 0.68774 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:46:18.766925 ops/training.py:65 2019-01-17 02:46:18.766856: step 7861, loss = 0.66418 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:46:20.054989 ops/training.py:65 2019-01-17 02:46:20.054920: step 7862, loss = 0.67380 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:46:21.340970 ops/training.py:65 2019-01-17 02:46:21.340907: step 7863, loss = 0.65798 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:46:22.629188 ops/training.py:65 2019-01-17 02:46:22.629115: step 7864, loss = 0.70566 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:46:23.913132 ops/training.py:65 2019-01-17 02:46:23.913066: step 7865, loss = 0.66585 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:46:25.196503 ops/training.py:65 2019-01-17 02:46:25.196431: step 7866, loss = 0.67668 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:46:26.482145 ops/training.py:65 2019-01-17 02:46:26.482041: step 7867, loss = 0.71356 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:46:27.763176 ops/training.py:65 2019-01-17 02:46:27.763065: step 7868, loss = 0.69770 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:46:29.042945 ops/training.py:65 2019-01-17 02:46:29.042839: step 7869, loss = 0.70393 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:46:30.326650 ops/training.py:65 2019-01-17 02:46:30.326563: step 7870, loss = 0.68803 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:46:31.610834 ops/training.py:65 2019-01-17 02:46:31.610739: step 7871, loss = 0.68702 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:46:32.898674 ops/training.py:65 2019-01-17 02:46:32.898580: step 7872, loss = 0.66092 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:46:34.182523 ops/training.py:65 2019-01-17 02:46:34.182403: step 7873, loss = 0.69803 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:46:35.462736 ops/training.py:65 2019-01-17 02:46:35.462646: step 7874, loss = 0.70600 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:46:36.746556 ops/training.py:65 2019-01-17 02:46:36.746418: step 7875, loss = 0.68428 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:46:38.033680 ops/training.py:65 2019-01-17 02:46:38.033585: step 7876, loss = 0.72335 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:46:39.322196 ops/training.py:65 2019-01-17 02:46:39.322097: step 7877, loss = 0.69741 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:46:40.611154 ops/training.py:65 2019-01-17 02:46:40.611083: step 7878, loss = 0.69734 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:46:41.897640 ops/training.py:65 2019-01-17 02:46:41.897542: step 7879, loss = 0.75246 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:46:43.181113 ops/training.py:65 2019-01-17 02:46:43.181038: step 7880, loss = 0.67816 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:46:44.465937 ops/training.py:65 2019-01-17 02:46:44.465792: step 7881, loss = 0.65613 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:46:45.755684 ops/training.py:65 2019-01-17 02:46:45.755552: step 7882, loss = 0.68718 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:46:47.045367 ops/training.py:65 2019-01-17 02:46:47.045267: step 7883, loss = 0.64553 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:46:48.330194 ops/training.py:65 2019-01-17 02:46:48.330133: step 7884, loss = 0.71402 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:46:49.617521 ops/training.py:65 2019-01-17 02:46:49.617421: step 7885, loss = 0.68753 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:46:50.905965 ops/training.py:65 2019-01-17 02:46:50.905899: step 7886, loss = 0.75272 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:46:52.193677 ops/training.py:65 2019-01-17 02:46:52.193606: step 7887, loss = 0.66166 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:46:53.477860 ops/training.py:65 2019-01-17 02:46:53.477791: step 7888, loss = 0.76445 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:46:54.761906 ops/training.py:65 2019-01-17 02:46:54.761798: step 7889, loss = 0.69006 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:46:56.041183 ops/training.py:65 2019-01-17 02:46:56.041073: step 7890, loss = 0.66229 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:46:57.332573 ops/training.py:65 2019-01-17 02:46:57.332478: step 7891, loss = 0.65190 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:46:58.621472 ops/training.py:65 2019-01-17 02:46:58.621401: step 7892, loss = 0.68268 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:46:59.905606 ops/training.py:65 2019-01-17 02:46:59.905540: step 7893, loss = 0.71110 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:47:01.195835 ops/training.py:65 2019-01-17 02:47:01.195734: step 7894, loss = 0.70888 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:47:02.480466 ops/training.py:65 2019-01-17 02:47:02.480400: step 7895, loss = 0.66076 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:47:03.765398 ops/training.py:65 2019-01-17 02:47:03.765311: step 7896, loss = 0.65460 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:47:05.048592 ops/training.py:65 2019-01-17 02:47:05.048530: step 7897, loss = 0.69781 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:47:06.331853 ops/training.py:65 2019-01-17 02:47:06.331745: step 7898, loss = 0.67191 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:47:07.620935 ops/training.py:65 2019-01-17 02:47:07.620841: step 7899, loss = 0.69776 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:47:08.909175 ops/training.py:65 2019-01-17 02:47:08.909102: step 7900, loss = 0.70057 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:47:10.197565 ops/training.py:65 2019-01-17 02:47:10.197466: step 7901, loss = 0.66303 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:47:11.481173 ops/training.py:65 2019-01-17 02:47:11.481103: step 7902, loss = 0.66776 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:47:12.761412 ops/training.py:65 2019-01-17 02:47:12.761304: step 7903, loss = 0.67268 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:47:14.047158 ops/training.py:65 2019-01-17 02:47:14.047060: step 7904, loss = 0.68449 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:47:15.332813 ops/training.py:65 2019-01-17 02:47:15.332710: step 7905, loss = 0.67073 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:47:16.624331 ops/training.py:65 2019-01-17 02:47:16.624242: step 7906, loss = 0.66171 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:47:17.910407 ops/training.py:65 2019-01-17 02:47:17.910344: step 7907, loss = 0.70437 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:47:19.198710 ops/training.py:65 2019-01-17 02:47:19.198606: step 7908, loss = 0.69627 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:47:20.482653 ops/training.py:65 2019-01-17 02:47:20.482591: step 7909, loss = 0.73015 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:47:21.767640 ops/training.py:65 2019-01-17 02:47:21.767534: step 7910, loss = 0.71513 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:47:23.059067 ops/training.py:65 2019-01-17 02:47:23.058971: step 7911, loss = 0.65012 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:47:24.343099 ops/training.py:65 2019-01-17 02:47:24.343025: step 7912, loss = 0.66601 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:47:25.626787 ops/training.py:65 2019-01-17 02:47:25.626716: step 7913, loss = 0.67075 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:47:26.913052 ops/training.py:65 2019-01-17 02:47:26.912955: step 7914, loss = 0.69089 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:47:28.200055 ops/training.py:65 2019-01-17 02:47:28.199963: step 7915, loss = 0.65946 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:47:29.489743 ops/training.py:65 2019-01-17 02:47:29.489645: step 7916, loss = 0.70087 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:47:30.780977 ops/training.py:65 2019-01-17 02:47:30.780862: step 7917, loss = 0.67926 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:47:32.067209 ops/training.py:65 2019-01-17 02:47:32.067141: step 7918, loss = 0.69775 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:47:33.358645 ops/training.py:65 2019-01-17 02:47:33.358554: step 7919, loss = 0.74248 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:47:34.648638 ops/training.py:65 2019-01-17 02:47:34.648570: step 7920, loss = 0.68262 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:47:35.937594 ops/training.py:65 2019-01-17 02:47:35.937525: step 7921, loss = 0.64829 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:47:37.226008 ops/training.py:65 2019-01-17 02:47:37.225934: step 7922, loss = 0.68145 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:47:38.509805 ops/training.py:65 2019-01-17 02:47:38.509735: step 7923, loss = 0.71158 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:47:39.798207 ops/training.py:65 2019-01-17 02:47:39.798109: step 7924, loss = 0.64889 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:47:41.087352 ops/training.py:65 2019-01-17 02:47:41.087268: step 7925, loss = 0.68219 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:47:42.375083 ops/training.py:65 2019-01-17 02:47:42.375015: step 7926, loss = 0.68145 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:47:43.662919 ops/training.py:65 2019-01-17 02:47:43.662846: step 7927, loss = 0.66381 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:47:44.947776 ops/training.py:65 2019-01-17 02:47:44.947710: step 7928, loss = 0.64435 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:47:46.233062 ops/training.py:65 2019-01-17 02:47:46.232978: step 7929, loss = 0.66616 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:47:47.517679 ops/training.py:65 2019-01-17 02:47:47.517579: step 7930, loss = 0.71393 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:47:48.808658 ops/training.py:65 2019-01-17 02:47:48.808564: step 7931, loss = 0.68212 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:47:50.093860 ops/training.py:65 2019-01-17 02:47:50.093792: step 7932, loss = 0.69863 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:47:51.378143 ops/training.py:65 2019-01-17 02:47:51.378045: step 7933, loss = 0.68808 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:47:52.665169 ops/training.py:65 2019-01-17 02:47:52.665062: step 7934, loss = 0.67327 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:47:53.950429 ops/training.py:65 2019-01-17 02:47:53.950335: step 7935, loss = 0.72762 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:47:55.242361 ops/training.py:65 2019-01-17 02:47:55.242263: step 7936, loss = 0.74087 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:47:56.524255 ops/training.py:65 2019-01-17 02:47:56.524177: step 7937, loss = 0.67647 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:47:57.816183 ops/training.py:65 2019-01-17 02:47:57.816075: step 7938, loss = 0.69581 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:47:59.108681 ops/training.py:65 2019-01-17 02:47:59.108582: step 7939, loss = 0.75283 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:48:00.395543 ops/training.py:65 2019-01-17 02:48:00.395475: step 7940, loss = 0.67783 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:48:01.679352 ops/training.py:65 2019-01-17 02:48:01.679261: step 7941, loss = 0.73203 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:48:02.970232 ops/training.py:65 2019-01-17 02:48:02.970135: step 7942, loss = 0.63317 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:48:04.256364 ops/training.py:65 2019-01-17 02:48:04.256292: step 7943, loss = 0.64448 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:48:05.541791 ops/training.py:65 2019-01-17 02:48:05.541692: step 7944, loss = 0.74625 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:48:06.834358 ops/training.py:65 2019-01-17 02:48:06.834251: step 7945, loss = 0.70641 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:48:08.125246 ops/training.py:65 2019-01-17 02:48:08.125180: step 7946, loss = 0.64801 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:48:09.409332 ops/training.py:65 2019-01-17 02:48:09.409261: step 7947, loss = 0.69166 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:48:10.690394 ops/training.py:65 2019-01-17 02:48:10.690310: step 7948, loss = 0.67990 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:48:11.976564 ops/training.py:65 2019-01-17 02:48:11.976466: step 7949, loss = 0.70719 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:48:13.258453 ops/training.py:65 2019-01-17 02:48:13.258331: step 7950, loss = 0.70559 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:48:14.548818 ops/training.py:65 2019-01-17 02:48:14.548720: step 7951, loss = 0.68762 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:48:15.834734 ops/training.py:65 2019-01-17 02:48:15.834665: step 7952, loss = 0.71489 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:48:17.119017 ops/training.py:65 2019-01-17 02:48:17.118921: step 7953, loss = 0.65928 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:48:18.404580 ops/training.py:65 2019-01-17 02:48:18.404485: step 7954, loss = 0.68115 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:48:19.691438 ops/training.py:65 2019-01-17 02:48:19.691333: step 7955, loss = 0.70241 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:48:20.976345 ops/training.py:65 2019-01-17 02:48:20.976244: step 7956, loss = 0.70220 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:48:22.264436 ops/training.py:65 2019-01-17 02:48:22.264335: step 7957, loss = 0.68885 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:48:23.555880 ops/training.py:65 2019-01-17 02:48:23.555783: step 7958, loss = 0.66163 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:48:24.841249 ops/training.py:65 2019-01-17 02:48:24.841187: step 7959, loss = 0.64927 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:48:26.130315 ops/training.py:65 2019-01-17 02:48:26.130226: step 7960, loss = 0.68301 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:48:27.414522 ops/training.py:65 2019-01-17 02:48:27.414454: step 7961, loss = 0.68081 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:48:28.703836 ops/training.py:65 2019-01-17 02:48:28.703748: step 7962, loss = 0.67424 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:48:29.992634 ops/training.py:65 2019-01-17 02:48:29.992563: step 7963, loss = 0.70850 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:48:31.281544 ops/training.py:65 2019-01-17 02:48:31.281461: step 7964, loss = 0.66261 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:48:32.570618 ops/training.py:65 2019-01-17 02:48:32.570525: step 7965, loss = 0.72032 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:48:33.853952 ops/training.py:65 2019-01-17 02:48:33.853879: step 7966, loss = 0.66688 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:48:35.134292 ops/training.py:65 2019-01-17 02:48:35.134181: step 7967, loss = 0.71542 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:48:36.420136 ops/training.py:65 2019-01-17 02:48:36.420035: step 7968, loss = 0.65669 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:48:37.704949 ops/training.py:65 2019-01-17 02:48:37.704848: step 7969, loss = 0.70474 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:48:38.996256 ops/training.py:65 2019-01-17 02:48:38.996164: step 7970, loss = 0.63432 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:48:40.280571 ops/training.py:65 2019-01-17 02:48:40.280472: step 7971, loss = 0.69082 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:48:41.564367 ops/training.py:65 2019-01-17 02:48:41.564227: step 7972, loss = 0.67248 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:48:42.855786 ops/training.py:65 2019-01-17 02:48:42.855684: step 7973, loss = 0.67991 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:48:44.139691 ops/training.py:65 2019-01-17 02:48:44.139627: step 7974, loss = 0.69921 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:48:45.424627 ops/training.py:65 2019-01-17 02:48:45.424522: step 7975, loss = 0.68891 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:48:46.709461 ops/training.py:65 2019-01-17 02:48:46.709373: step 7976, loss = 0.71705 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:48:47.996731 ops/training.py:65 2019-01-17 02:48:47.996635: step 7977, loss = 0.67601 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:48:49.280535 ops/training.py:65 2019-01-17 02:48:49.280438: step 7978, loss = 0.67015 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:48:50.572065 ops/training.py:65 2019-01-17 02:48:50.571914: step 7979, loss = 0.67255 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:48:51.863973 ops/training.py:65 2019-01-17 02:48:51.863883: step 7980, loss = 0.68544 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:48:53.153070 ops/training.py:65 2019-01-17 02:48:53.152995: step 7981, loss = 0.70230 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:48:54.437100 ops/training.py:65 2019-01-17 02:48:54.437032: step 7982, loss = 0.67778 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:48:55.725079 ops/training.py:65 2019-01-17 02:48:55.724985: step 7983, loss = 0.66646 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:48:57.008560 ops/training.py:65 2019-01-17 02:48:57.008490: step 7984, loss = 0.71132 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:48:58.294874 ops/training.py:65 2019-01-17 02:48:58.294798: step 7985, loss = 0.72103 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:48:59.583489 ops/training.py:65 2019-01-17 02:48:59.583419: step 7986, loss = 0.69111 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:49:00.871868 ops/training.py:65 2019-01-17 02:49:00.871797: step 7987, loss = 0.68186 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:49:02.155636 ops/training.py:65 2019-01-17 02:49:02.155573: step 7988, loss = 0.72636 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:49:03.436538 ops/training.py:65 2019-01-17 02:49:03.436446: step 7989, loss = 0.67568 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:49:04.727978 ops/training.py:65 2019-01-17 02:49:04.727877: step 7990, loss = 0.67180 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:49:06.013781 ops/training.py:65 2019-01-17 02:49:06.013705: step 7991, loss = 0.64599 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:49:07.297229 ops/training.py:65 2019-01-17 02:49:07.297130: step 7992, loss = 0.68399 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:49:08.587900 ops/training.py:65 2019-01-17 02:49:08.587796: step 7993, loss = 0.67926 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:49:09.877177 ops/training.py:65 2019-01-17 02:49:09.877106: step 7994, loss = 0.69125 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:49:11.164789 ops/training.py:65 2019-01-17 02:49:11.164695: step 7995, loss = 0.69478 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:49:12.454113 ops/training.py:65 2019-01-17 02:49:12.454043: step 7996, loss = 0.70828 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:49:13.738502 ops/training.py:65 2019-01-17 02:49:13.738434: step 7997, loss = 0.70526 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:49:15.027118 ops/training.py:65 2019-01-17 02:49:15.027019: step 7998, loss = 0.72872 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:49:16.315456 ops/training.py:65 2019-01-17 02:49:16.315382: step 7999, loss = 0.70033 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:55:22.072012 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I4672 2019-01-17 02:55:22.074221 ops/training.py:41 2019-01-17 02:55:22.074160: step 8000, loss = 0.71 (0.1 examples/sec; 364.473 sec/batch) | Training accuracy = 0.5625 | Validation accuracy = 0.5104 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_23_33_01_706250
I4672 2019-01-17 02:55:23.360621 ops/training.py:65 2019-01-17 02:55:23.360524: step 8001, loss = 0.68243 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:55:24.643842 ops/training.py:65 2019-01-17 02:55:24.643695: step 8002, loss = 0.71107 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:55:25.935006 ops/training.py:65 2019-01-17 02:55:25.934907: step 8003, loss = 0.66764 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:55:27.223173 ops/training.py:65 2019-01-17 02:55:27.223093: step 8004, loss = 0.63617 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:55:28.510878 ops/training.py:65 2019-01-17 02:55:28.510813: step 8005, loss = 0.70199 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:55:29.794183 ops/training.py:65 2019-01-17 02:55:29.794115: step 8006, loss = 0.66861 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:55:31.079778 ops/training.py:65 2019-01-17 02:55:31.079698: step 8007, loss = 0.70062 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:55:32.367521 ops/training.py:65 2019-01-17 02:55:32.367452: step 8008, loss = 0.65520 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:55:33.655278 ops/training.py:65 2019-01-17 02:55:33.655208: step 8009, loss = 0.70127 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:55:34.943709 ops/training.py:65 2019-01-17 02:55:34.943631: step 8010, loss = 0.68680 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:55:36.227660 ops/training.py:65 2019-01-17 02:55:36.227616: step 8011, loss = 0.72439 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:55:37.511554 ops/training.py:65 2019-01-17 02:55:37.511469: step 8012, loss = 0.69888 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:55:38.799631 ops/training.py:65 2019-01-17 02:55:38.799527: step 8013, loss = 0.71596 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:55:40.087624 ops/training.py:65 2019-01-17 02:55:40.087524: step 8014, loss = 0.62211 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:55:41.375655 ops/training.py:65 2019-01-17 02:55:41.375496: step 8015, loss = 0.67005 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:55:42.668074 ops/training.py:65 2019-01-17 02:55:42.667977: step 8016, loss = 0.64932 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:55:43.953965 ops/training.py:65 2019-01-17 02:55:43.953881: step 8017, loss = 0.69616 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:55:45.239151 ops/training.py:65 2019-01-17 02:55:45.239009: step 8018, loss = 0.63858 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:55:46.529424 ops/training.py:65 2019-01-17 02:55:46.529356: step 8019, loss = 0.66909 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:55:47.820284 ops/training.py:65 2019-01-17 02:55:47.820215: step 8020, loss = 0.67878 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:55:49.103571 ops/training.py:65 2019-01-17 02:55:49.103505: step 8021, loss = 0.68903 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:55:50.385650 ops/training.py:65 2019-01-17 02:55:50.385551: step 8022, loss = 0.69992 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:55:51.671466 ops/training.py:65 2019-01-17 02:55:51.671360: step 8023, loss = 0.68023 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:55:52.964165 ops/training.py:65 2019-01-17 02:55:52.964062: step 8024, loss = 0.69266 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:55:54.254312 ops/training.py:65 2019-01-17 02:55:54.254243: step 8025, loss = 0.68156 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:55:55.549704 ops/training.py:65 2019-01-17 02:55:55.549642: step 8026, loss = 0.71174 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:55:56.834358 ops/training.py:65 2019-01-17 02:55:56.834299: step 8027, loss = 0.68767 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:55:58.123128 ops/training.py:65 2019-01-17 02:55:58.123032: step 8028, loss = 0.65858 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:55:59.408259 ops/training.py:65 2019-01-17 02:55:59.408198: step 8029, loss = 0.65721 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:56:00.690695 ops/training.py:65 2019-01-17 02:56:00.690612: step 8030, loss = 0.69028 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:56:01.977423 ops/training.py:65 2019-01-17 02:56:01.977325: step 8031, loss = 0.66297 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:56:03.270148 ops/training.py:65 2019-01-17 02:56:03.270045: step 8032, loss = 0.72659 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:56:04.556572 ops/training.py:65 2019-01-17 02:56:04.556465: step 8033, loss = 0.68382 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:56:05.845231 ops/training.py:65 2019-01-17 02:56:05.845129: step 8034, loss = 0.66936 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:56:07.137659 ops/training.py:65 2019-01-17 02:56:07.137550: step 8035, loss = 0.70798 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:56:08.424556 ops/training.py:65 2019-01-17 02:56:08.424486: step 8036, loss = 0.66325 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:56:09.707669 ops/training.py:65 2019-01-17 02:56:09.707603: step 8037, loss = 0.71537 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:56:10.998462 ops/training.py:65 2019-01-17 02:56:10.998362: step 8038, loss = 0.74171 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:56:12.288387 ops/training.py:65 2019-01-17 02:56:12.288328: step 8039, loss = 0.65910 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:56:13.576875 ops/training.py:65 2019-01-17 02:56:13.576810: step 8040, loss = 0.64684 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:56:14.865108 ops/training.py:65 2019-01-17 02:56:14.865040: step 8041, loss = 0.67759 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:56:16.154482 ops/training.py:65 2019-01-17 02:56:16.154391: step 8042, loss = 0.68168 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:56:17.443158 ops/training.py:65 2019-01-17 02:56:17.443066: step 8043, loss = 0.68186 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:56:18.733210 ops/training.py:65 2019-01-17 02:56:18.733139: step 8044, loss = 0.68302 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:56:20.021966 ops/training.py:65 2019-01-17 02:56:20.021898: step 8045, loss = 0.68157 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:56:21.306181 ops/training.py:65 2019-01-17 02:56:21.306119: step 8046, loss = 0.69415 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:56:22.596703 ops/training.py:65 2019-01-17 02:56:22.596607: step 8047, loss = 0.69511 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:56:23.878214 ops/training.py:65 2019-01-17 02:56:23.878145: step 8048, loss = 0.66470 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:56:25.170291 ops/training.py:65 2019-01-17 02:56:25.170186: step 8049, loss = 0.66668 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:56:26.459699 ops/training.py:65 2019-01-17 02:56:26.459627: step 8050, loss = 0.65057 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:56:27.748741 ops/training.py:65 2019-01-17 02:56:27.748666: step 8051, loss = 0.67019 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:56:29.032400 ops/training.py:65 2019-01-17 02:56:29.032314: step 8052, loss = 0.62834 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:56:30.322816 ops/training.py:65 2019-01-17 02:56:30.322668: step 8053, loss = 0.66706 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:56:31.611813 ops/training.py:65 2019-01-17 02:56:31.611739: step 8054, loss = 0.65830 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:56:32.901451 ops/training.py:65 2019-01-17 02:56:32.901388: step 8055, loss = 0.67916 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:56:34.190617 ops/training.py:65 2019-01-17 02:56:34.190541: step 8056, loss = 0.68895 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:56:35.480841 ops/training.py:65 2019-01-17 02:56:35.480770: step 8057, loss = 0.61478 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 02:56:36.765151 ops/training.py:65 2019-01-17 02:56:36.765085: step 8058, loss = 0.75005 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:56:38.050328 ops/training.py:65 2019-01-17 02:56:38.050263: step 8059, loss = 0.67740 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:56:39.341957 ops/training.py:65 2019-01-17 02:56:39.341851: step 8060, loss = 0.69642 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:56:40.633070 ops/training.py:65 2019-01-17 02:56:40.632973: step 8061, loss = 0.68037 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:56:41.922889 ops/training.py:65 2019-01-17 02:56:41.922800: step 8062, loss = 0.69195 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:56:43.213119 ops/training.py:65 2019-01-17 02:56:43.213051: step 8063, loss = 0.65579 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:56:44.500757 ops/training.py:65 2019-01-17 02:56:44.500694: step 8064, loss = 0.67254 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:56:45.786311 ops/training.py:65 2019-01-17 02:56:45.786241: step 8065, loss = 0.72252 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:56:47.071133 ops/training.py:65 2019-01-17 02:56:47.071064: step 8066, loss = 0.70802 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:56:48.352880 ops/training.py:65 2019-01-17 02:56:48.352768: step 8067, loss = 0.67721 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:56:49.642826 ops/training.py:65 2019-01-17 02:56:49.642723: step 8068, loss = 0.74100 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:56:50.931544 ops/training.py:65 2019-01-17 02:56:50.931457: step 8069, loss = 0.68202 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:56:52.215435 ops/training.py:65 2019-01-17 02:56:52.215361: step 8070, loss = 0.69936 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:56:53.496341 ops/training.py:65 2019-01-17 02:56:53.496243: step 8071, loss = 0.63319 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:56:54.784785 ops/training.py:65 2019-01-17 02:56:54.784676: step 8072, loss = 0.65742 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:56:56.065486 ops/training.py:65 2019-01-17 02:56:56.065388: step 8073, loss = 0.68488 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:56:57.357419 ops/training.py:65 2019-01-17 02:56:57.357316: step 8074, loss = 0.72483 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:56:58.649834 ops/training.py:65 2019-01-17 02:56:58.649759: step 8075, loss = 0.67714 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:56:59.939263 ops/training.py:65 2019-01-17 02:56:59.939202: step 8076, loss = 0.69351 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:57:01.227843 ops/training.py:65 2019-01-17 02:57:01.227774: step 8077, loss = 0.70393 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:57:02.515309 ops/training.py:65 2019-01-17 02:57:02.515238: step 8078, loss = 0.68200 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:57:03.803986 ops/training.py:65 2019-01-17 02:57:03.803911: step 8079, loss = 0.68957 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:57:05.093061 ops/training.py:65 2019-01-17 02:57:05.092972: step 8080, loss = 0.70063 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:57:06.382717 ops/training.py:65 2019-01-17 02:57:06.382640: step 8081, loss = 0.75160 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:57:07.668292 ops/training.py:65 2019-01-17 02:57:07.668223: step 8082, loss = 0.66352 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:57:08.951569 ops/training.py:65 2019-01-17 02:57:08.951458: step 8083, loss = 0.66600 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:57:10.236524 ops/training.py:65 2019-01-17 02:57:10.236427: step 8084, loss = 0.70307 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:57:11.529871 ops/training.py:65 2019-01-17 02:57:11.529766: step 8085, loss = 0.64855 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:57:12.822307 ops/training.py:65 2019-01-17 02:57:12.822233: step 8086, loss = 0.73806 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:57:14.106552 ops/training.py:65 2019-01-17 02:57:14.106481: step 8087, loss = 0.73727 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:57:15.394874 ops/training.py:65 2019-01-17 02:57:15.394770: step 8088, loss = 0.67855 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:57:16.683303 ops/training.py:65 2019-01-17 02:57:16.683236: step 8089, loss = 0.70638 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:57:17.973037 ops/training.py:65 2019-01-17 02:57:17.972971: step 8090, loss = 0.71942 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:57:19.262033 ops/training.py:65 2019-01-17 02:57:19.261968: step 8091, loss = 0.76049 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:57:20.550034 ops/training.py:65 2019-01-17 02:57:20.549961: step 8092, loss = 0.66723 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:57:21.832126 ops/training.py:65 2019-01-17 02:57:21.832064: step 8093, loss = 0.62693 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:57:23.115285 ops/training.py:65 2019-01-17 02:57:23.115169: step 8094, loss = 0.70811 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:57:24.405933 ops/training.py:65 2019-01-17 02:57:24.405854: step 8095, loss = 0.70399 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:57:25.687239 ops/training.py:65 2019-01-17 02:57:25.687148: step 8096, loss = 0.67648 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:57:26.970435 ops/training.py:65 2019-01-17 02:57:26.970325: step 8097, loss = 0.68774 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:57:28.259058 ops/training.py:65 2019-01-17 02:57:28.258957: step 8098, loss = 0.68438 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:57:29.550629 ops/training.py:65 2019-01-17 02:57:29.550533: step 8099, loss = 0.72615 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:57:30.836256 ops/training.py:65 2019-01-17 02:57:30.836191: step 8100, loss = 0.65374 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:57:32.126026 ops/training.py:65 2019-01-17 02:57:32.125941: step 8101, loss = 0.66046 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:57:33.415829 ops/training.py:65 2019-01-17 02:57:33.415764: step 8102, loss = 0.71980 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:57:34.702546 ops/training.py:65 2019-01-17 02:57:34.702477: step 8103, loss = 0.69758 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:57:35.983828 ops/training.py:65 2019-01-17 02:57:35.983764: step 8104, loss = 0.60879 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:57:37.267485 ops/training.py:65 2019-01-17 02:57:37.267386: step 8105, loss = 0.71118 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:57:38.559352 ops/training.py:65 2019-01-17 02:57:38.559244: step 8106, loss = 0.73254 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:57:39.846405 ops/training.py:65 2019-01-17 02:57:39.846338: step 8107, loss = 0.66425 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:57:41.124276 ops/training.py:65 2019-01-17 02:57:41.124168: step 8108, loss = 0.66170 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:57:42.415844 ops/training.py:65 2019-01-17 02:57:42.415692: step 8109, loss = 0.68600 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:57:43.702358 ops/training.py:65 2019-01-17 02:57:43.702288: step 8110, loss = 0.67302 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:57:44.986209 ops/training.py:65 2019-01-17 02:57:44.986138: step 8111, loss = 0.71353 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:57:46.275767 ops/training.py:65 2019-01-17 02:57:46.275632: step 8112, loss = 0.68809 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:57:47.562983 ops/training.py:65 2019-01-17 02:57:47.562917: step 8113, loss = 0.66042 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:57:48.848823 ops/training.py:65 2019-01-17 02:57:48.848718: step 8114, loss = 0.66375 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:57:50.139807 ops/training.py:65 2019-01-17 02:57:50.139700: step 8115, loss = 0.63205 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:57:51.431158 ops/training.py:65 2019-01-17 02:57:51.431092: step 8116, loss = 0.72275 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:57:52.717043 ops/training.py:65 2019-01-17 02:57:52.716978: step 8117, loss = 0.73164 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:57:54.006731 ops/training.py:65 2019-01-17 02:57:54.006658: step 8118, loss = 0.67177 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:57:55.290969 ops/training.py:65 2019-01-17 02:57:55.290894: step 8119, loss = 0.65938 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:57:56.574716 ops/training.py:65 2019-01-17 02:57:56.574605: step 8120, loss = 0.75010 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:57:57.861582 ops/training.py:65 2019-01-17 02:57:57.861477: step 8121, loss = 0.69639 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:57:59.145744 ops/training.py:65 2019-01-17 02:57:59.145602: step 8122, loss = 0.61618 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:58:00.436344 ops/training.py:65 2019-01-17 02:58:00.436246: step 8123, loss = 0.70896 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:58:01.722354 ops/training.py:65 2019-01-17 02:58:01.722262: step 8124, loss = 0.74301 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:58:03.006001 ops/training.py:65 2019-01-17 02:58:03.005894: step 8125, loss = 0.67658 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:58:04.291790 ops/training.py:65 2019-01-17 02:58:04.291685: step 8126, loss = 0.65695 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:58:05.582754 ops/training.py:65 2019-01-17 02:58:05.582653: step 8127, loss = 0.68155 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:58:06.872824 ops/training.py:65 2019-01-17 02:58:06.872736: step 8128, loss = 0.73397 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:58:08.162212 ops/training.py:65 2019-01-17 02:58:08.162152: step 8129, loss = 0.67903 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:58:09.446679 ops/training.py:65 2019-01-17 02:58:09.446617: step 8130, loss = 0.64454 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:58:10.732434 ops/training.py:65 2019-01-17 02:58:10.732278: step 8131, loss = 0.68838 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:58:12.024798 ops/training.py:65 2019-01-17 02:58:12.024692: step 8132, loss = 0.66539 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:58:13.316740 ops/training.py:65 2019-01-17 02:58:13.316672: step 8133, loss = 0.66699 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:58:14.604551 ops/training.py:65 2019-01-17 02:58:14.604478: step 8134, loss = 0.65679 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:58:15.889639 ops/training.py:65 2019-01-17 02:58:15.889569: step 8135, loss = 0.73332 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 02:58:17.178246 ops/training.py:65 2019-01-17 02:58:17.178152: step 8136, loss = 0.65570 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:58:18.467052 ops/training.py:65 2019-01-17 02:58:18.466981: step 8137, loss = 0.62156 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:58:19.751367 ops/training.py:65 2019-01-17 02:58:19.751300: step 8138, loss = 0.73450 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:58:21.034507 ops/training.py:65 2019-01-17 02:58:21.034398: step 8139, loss = 0.71311 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:58:22.326679 ops/training.py:65 2019-01-17 02:58:22.326571: step 8140, loss = 0.63454 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:58:23.617151 ops/training.py:65 2019-01-17 02:58:23.617054: step 8141, loss = 0.67722 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:58:24.907366 ops/training.py:65 2019-01-17 02:58:24.907277: step 8142, loss = 0.66953 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:58:26.192276 ops/training.py:65 2019-01-17 02:58:26.192211: step 8143, loss = 0.65255 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:58:27.481534 ops/training.py:65 2019-01-17 02:58:27.481448: step 8144, loss = 0.71258 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:58:28.771724 ops/training.py:65 2019-01-17 02:58:28.771631: step 8145, loss = 0.70955 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:58:30.059652 ops/training.py:65 2019-01-17 02:58:30.059581: step 8146, loss = 0.66410 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:58:31.347733 ops/training.py:65 2019-01-17 02:58:31.347661: step 8147, loss = 0.63768 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:58:32.630858 ops/training.py:65 2019-01-17 02:58:32.630795: step 8148, loss = 0.67939 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:58:33.921103 ops/training.py:65 2019-01-17 02:58:33.921005: step 8149, loss = 0.64900 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 02:58:35.206857 ops/training.py:65 2019-01-17 02:58:35.206788: step 8150, loss = 0.72184 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:58:36.492266 ops/training.py:65 2019-01-17 02:58:36.492165: step 8151, loss = 0.71653 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:58:37.780525 ops/training.py:65 2019-01-17 02:58:37.780449: step 8152, loss = 0.63751 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:58:39.069753 ops/training.py:65 2019-01-17 02:58:39.069665: step 8153, loss = 0.64439 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:58:40.358234 ops/training.py:65 2019-01-17 02:58:40.358154: step 8154, loss = 0.70520 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:58:41.642706 ops/training.py:65 2019-01-17 02:58:41.642634: step 8155, loss = 0.70077 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:58:42.931474 ops/training.py:65 2019-01-17 02:58:42.931406: step 8156, loss = 0.72106 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:58:44.215359 ops/training.py:65 2019-01-17 02:58:44.215287: step 8157, loss = 0.66897 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:58:45.502699 ops/training.py:65 2019-01-17 02:58:45.502595: step 8158, loss = 0.75898 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:58:46.794392 ops/training.py:65 2019-01-17 02:58:46.794266: step 8159, loss = 0.72172 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:58:48.081707 ops/training.py:65 2019-01-17 02:58:48.081644: step 8160, loss = 0.67707 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:58:49.357990 ops/training.py:65 2019-01-17 02:58:49.357889: step 8161, loss = 0.64837 (25.1 examples/sec; 1.275 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:58:50.642524 ops/training.py:65 2019-01-17 02:58:50.642420: step 8162, loss = 0.76582 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:58:51.934551 ops/training.py:65 2019-01-17 02:58:51.934455: step 8163, loss = 0.70241 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:58:53.226048 ops/training.py:65 2019-01-17 02:58:53.225976: step 8164, loss = 0.66134 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:58:54.515180 ops/training.py:65 2019-01-17 02:58:54.515111: step 8165, loss = 0.70491 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:58:55.799976 ops/training.py:65 2019-01-17 02:58:55.799898: step 8166, loss = 0.70543 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:58:57.091730 ops/training.py:65 2019-01-17 02:58:57.091628: step 8167, loss = 0.68467 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:58:58.380053 ops/training.py:65 2019-01-17 02:58:58.379962: step 8168, loss = 0.69540 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:58:59.668956 ops/training.py:65 2019-01-17 02:58:59.668801: step 8169, loss = 0.70646 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:59:00.954713 ops/training.py:65 2019-01-17 02:59:00.954646: step 8170, loss = 0.62634 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:59:02.239891 ops/training.py:65 2019-01-17 02:59:02.239796: step 8171, loss = 0.70187 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:59:03.521148 ops/training.py:65 2019-01-17 02:59:03.521046: step 8172, loss = 0.69703 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:59:04.819759 ops/training.py:65 2019-01-17 02:59:04.819652: step 8173, loss = 0.68264 (24.7 examples/sec; 1.297 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:59:06.106683 ops/training.py:65 2019-01-17 02:59:06.106613: step 8174, loss = 0.67242 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:59:07.390844 ops/training.py:65 2019-01-17 02:59:07.390782: step 8175, loss = 0.71475 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:59:08.675649 ops/training.py:65 2019-01-17 02:59:08.675545: step 8176, loss = 0.70126 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:59:09.965667 ops/training.py:65 2019-01-17 02:59:09.965569: step 8177, loss = 0.66580 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:59:11.261005 ops/training.py:65 2019-01-17 02:59:11.260914: step 8178, loss = 0.73229 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 02:59:12.550052 ops/training.py:65 2019-01-17 02:59:12.549991: step 8179, loss = 0.65143 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 02:59:13.835237 ops/training.py:65 2019-01-17 02:59:13.835164: step 8180, loss = 0.69741 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:59:15.124726 ops/training.py:65 2019-01-17 02:59:15.124581: step 8181, loss = 0.67889 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:59:16.414745 ops/training.py:65 2019-01-17 02:59:16.414650: step 8182, loss = 0.63790 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:59:17.700174 ops/training.py:65 2019-01-17 02:59:17.700107: step 8183, loss = 0.68036 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 02:59:18.988936 ops/training.py:65 2019-01-17 02:59:18.988834: step 8184, loss = 0.69275 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:59:20.279178 ops/training.py:65 2019-01-17 02:59:20.279118: step 8185, loss = 0.66422 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:59:21.564504 ops/training.py:65 2019-01-17 02:59:21.564437: step 8186, loss = 0.68511 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:59:22.853415 ops/training.py:65 2019-01-17 02:59:22.853272: step 8187, loss = 0.70735 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:59:24.142860 ops/training.py:65 2019-01-17 02:59:24.142786: step 8188, loss = 0.66575 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:59:25.427586 ops/training.py:65 2019-01-17 02:59:25.427522: step 8189, loss = 0.62954 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 02:59:26.716070 ops/training.py:65 2019-01-17 02:59:26.715970: step 8190, loss = 0.74931 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:59:28.005906 ops/training.py:65 2019-01-17 02:59:28.005838: step 8191, loss = 0.68495 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:59:29.289947 ops/training.py:65 2019-01-17 02:59:29.289882: step 8192, loss = 0.68311 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:59:30.575992 ops/training.py:65 2019-01-17 02:59:30.575889: step 8193, loss = 0.63100 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:59:31.865295 ops/training.py:65 2019-01-17 02:59:31.865162: step 8194, loss = 0.70274 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:59:33.156396 ops/training.py:65 2019-01-17 02:59:33.156327: step 8195, loss = 0.74806 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:59:34.445021 ops/training.py:65 2019-01-17 02:59:34.444948: step 8196, loss = 0.69665 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:59:35.729836 ops/training.py:65 2019-01-17 02:59:35.729750: step 8197, loss = 0.67894 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:59:37.013580 ops/training.py:65 2019-01-17 02:59:37.013479: step 8198, loss = 0.63495 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:59:38.301826 ops/training.py:65 2019-01-17 02:59:38.301724: step 8199, loss = 0.65722 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 02:59:39.588568 ops/training.py:65 2019-01-17 02:59:39.588430: step 8200, loss = 0.68689 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:59:40.876199 ops/training.py:65 2019-01-17 02:59:40.876097: step 8201, loss = 0.64308 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 02:59:42.159107 ops/training.py:65 2019-01-17 02:59:42.159007: step 8202, loss = 0.72394 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 02:59:43.445605 ops/training.py:65 2019-01-17 02:59:43.445505: step 8203, loss = 0.71432 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:59:44.734846 ops/training.py:65 2019-01-17 02:59:44.734738: step 8204, loss = 0.71441 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:59:46.024497 ops/training.py:65 2019-01-17 02:59:46.024389: step 8205, loss = 0.73490 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 02:59:47.315242 ops/training.py:65 2019-01-17 02:59:47.315179: step 8206, loss = 0.65223 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 02:59:48.598977 ops/training.py:65 2019-01-17 02:59:48.598914: step 8207, loss = 0.68863 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:59:49.888057 ops/training.py:65 2019-01-17 02:59:49.887991: step 8208, loss = 0.71781 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 02:59:51.178193 ops/training.py:65 2019-01-17 02:59:51.178124: step 8209, loss = 0.68861 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:59:52.463462 ops/training.py:65 2019-01-17 02:59:52.463399: step 8210, loss = 0.68174 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 02:59:53.747567 ops/training.py:65 2019-01-17 02:59:53.747467: step 8211, loss = 0.66302 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:59:55.034599 ops/training.py:65 2019-01-17 02:59:55.034490: step 8212, loss = 0.76342 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 02:59:56.317890 ops/training.py:65 2019-01-17 02:59:56.317784: step 8213, loss = 0.68461 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 02:59:57.609993 ops/training.py:65 2019-01-17 02:59:57.609878: step 8214, loss = 0.71676 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 02:59:58.898930 ops/training.py:65 2019-01-17 02:59:58.898858: step 8215, loss = 0.75440 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:00:00.183102 ops/training.py:65 2019-01-17 03:00:00.183032: step 8216, loss = 0.64092 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:00:01.468228 ops/training.py:65 2019-01-17 03:00:01.468129: step 8217, loss = 0.69851 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:00:02.755221 ops/training.py:65 2019-01-17 03:00:02.755133: step 8218, loss = 0.63483 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:00:04.045641 ops/training.py:65 2019-01-17 03:00:04.045544: step 8219, loss = 0.71084 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:00:05.338616 ops/training.py:65 2019-01-17 03:00:05.338511: step 8220, loss = 0.67873 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:00:06.625961 ops/training.py:65 2019-01-17 03:00:06.625854: step 8221, loss = 0.67884 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:00:07.916214 ops/training.py:65 2019-01-17 03:00:07.916108: step 8222, loss = 0.63356 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:00:09.198439 ops/training.py:65 2019-01-17 03:00:09.198363: step 8223, loss = 0.69482 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:00:10.489598 ops/training.py:65 2019-01-17 03:00:10.489440: step 8224, loss = 0.71980 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:00:11.779321 ops/training.py:65 2019-01-17 03:00:11.779251: step 8225, loss = 0.64944 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:00:13.063430 ops/training.py:65 2019-01-17 03:00:13.063361: step 8226, loss = 0.70229 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:00:14.350237 ops/training.py:65 2019-01-17 03:00:14.350139: step 8227, loss = 0.70463 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:00:15.642178 ops/training.py:65 2019-01-17 03:00:15.642019: step 8228, loss = 0.69502 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:00:16.935072 ops/training.py:65 2019-01-17 03:00:16.934968: step 8229, loss = 0.70958 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:00:18.221042 ops/training.py:65 2019-01-17 03:00:18.220973: step 8230, loss = 0.70478 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:00:19.507087 ops/training.py:65 2019-01-17 03:00:19.506982: step 8231, loss = 0.73160 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:00:20.789381 ops/training.py:65 2019-01-17 03:00:20.789272: step 8232, loss = 0.65541 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:00:22.074743 ops/training.py:65 2019-01-17 03:00:22.074588: step 8233, loss = 0.67158 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:00:23.373834 ops/training.py:65 2019-01-17 03:00:23.373730: step 8234, loss = 0.74928 (24.7 examples/sec; 1.297 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:00:24.665178 ops/training.py:65 2019-01-17 03:00:24.665114: step 8235, loss = 0.64423 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:00:25.949173 ops/training.py:65 2019-01-17 03:00:25.949095: step 8236, loss = 0.71062 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:00:27.239954 ops/training.py:65 2019-01-17 03:00:27.239805: step 8237, loss = 0.56293 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:00:28.528681 ops/training.py:65 2019-01-17 03:00:28.528587: step 8238, loss = 0.77014 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 03:00:29.813236 ops/training.py:65 2019-01-17 03:00:29.813136: step 8239, loss = 0.75881 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:00:31.107123 ops/training.py:65 2019-01-17 03:00:31.107015: step 8240, loss = 0.73050 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:00:32.398101 ops/training.py:65 2019-01-17 03:00:32.398015: step 8241, loss = 0.62615 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:00:33.686882 ops/training.py:65 2019-01-17 03:00:33.686806: step 8242, loss = 0.72747 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:00:34.975908 ops/training.py:65 2019-01-17 03:00:34.975836: step 8243, loss = 0.77159 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:00:36.264066 ops/training.py:65 2019-01-17 03:00:36.264001: step 8244, loss = 0.68854 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:00:37.547478 ops/training.py:65 2019-01-17 03:00:37.547414: step 8245, loss = 0.72270 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:00:38.831630 ops/training.py:65 2019-01-17 03:00:38.831524: step 8246, loss = 0.72710 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:00:40.124446 ops/training.py:65 2019-01-17 03:00:40.124340: step 8247, loss = 0.69594 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:00:41.415348 ops/training.py:65 2019-01-17 03:00:41.415287: step 8248, loss = 0.67399 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:00:42.704367 ops/training.py:65 2019-01-17 03:00:42.704302: step 8249, loss = 0.71736 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:00:43.989271 ops/training.py:65 2019-01-17 03:00:43.989201: step 8250, loss = 0.71922 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:00:45.273162 ops/training.py:65 2019-01-17 03:00:45.273082: step 8251, loss = 0.74667 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:00:46.563050 ops/training.py:65 2019-01-17 03:00:46.562914: step 8252, loss = 0.69563 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:00:47.845240 ops/training.py:65 2019-01-17 03:00:47.845163: step 8253, loss = 0.71438 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:00:49.134209 ops/training.py:65 2019-01-17 03:00:49.134101: step 8254, loss = 0.73810 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:00:50.421658 ops/training.py:65 2019-01-17 03:00:50.421558: step 8255, loss = 0.72407 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:00:51.704258 ops/training.py:65 2019-01-17 03:00:51.704161: step 8256, loss = 0.68956 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:00:52.991350 ops/training.py:65 2019-01-17 03:00:52.991256: step 8257, loss = 0.70291 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:00:54.283326 ops/training.py:65 2019-01-17 03:00:54.283225: step 8258, loss = 0.71765 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:00:55.570877 ops/training.py:65 2019-01-17 03:00:55.570807: step 8259, loss = 0.71617 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:00:56.859758 ops/training.py:65 2019-01-17 03:00:56.859683: step 8260, loss = 0.71497 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:00:58.142625 ops/training.py:65 2019-01-17 03:00:58.142550: step 8261, loss = 0.70180 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:00:59.437211 ops/training.py:65 2019-01-17 03:00:59.437115: step 8262, loss = 0.65209 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:01:00.719979 ops/training.py:65 2019-01-17 03:01:00.719893: step 8263, loss = 0.66585 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:01:02.003942 ops/training.py:65 2019-01-17 03:01:02.003856: step 8264, loss = 0.62438 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:01:03.286048 ops/training.py:65 2019-01-17 03:01:03.285944: step 8265, loss = 0.71672 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:01:04.576797 ops/training.py:65 2019-01-17 03:01:04.576695: step 8266, loss = 0.68995 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:01:05.863066 ops/training.py:65 2019-01-17 03:01:05.862999: step 8267, loss = 0.72253 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:01:07.148662 ops/training.py:65 2019-01-17 03:01:07.148555: step 8268, loss = 0.70114 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:01:08.436274 ops/training.py:65 2019-01-17 03:01:08.436174: step 8269, loss = 0.67572 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:01:09.727981 ops/training.py:65 2019-01-17 03:01:09.727882: step 8270, loss = 0.69424 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:01:11.014845 ops/training.py:65 2019-01-17 03:01:11.014785: step 8271, loss = 0.62082 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:01:12.300107 ops/training.py:65 2019-01-17 03:01:12.300007: step 8272, loss = 0.71916 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:01:13.587446 ops/training.py:65 2019-01-17 03:01:13.587339: step 8273, loss = 0.63426 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:01:14.879109 ops/training.py:65 2019-01-17 03:01:14.879024: step 8274, loss = 0.61981 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:01:16.168863 ops/training.py:65 2019-01-17 03:01:16.168795: step 8275, loss = 0.66395 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:01:17.459042 ops/training.py:65 2019-01-17 03:01:17.458947: step 8276, loss = 0.70101 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:01:18.742427 ops/training.py:65 2019-01-17 03:01:18.742362: step 8277, loss = 0.65293 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:01:20.030121 ops/training.py:65 2019-01-17 03:01:20.030023: step 8278, loss = 0.72596 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:01:21.320243 ops/training.py:65 2019-01-17 03:01:21.320167: step 8279, loss = 0.66653 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:01:22.609601 ops/training.py:65 2019-01-17 03:01:22.609531: step 8280, loss = 0.64315 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:01:23.897300 ops/training.py:65 2019-01-17 03:01:23.897232: step 8281, loss = 0.66250 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:01:25.186146 ops/training.py:65 2019-01-17 03:01:25.186074: step 8282, loss = 0.69917 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:01:26.476497 ops/training.py:65 2019-01-17 03:01:26.476408: step 8283, loss = 0.67637 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:01:27.765349 ops/training.py:65 2019-01-17 03:01:27.765287: step 8284, loss = 0.71293 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:01:29.050856 ops/training.py:65 2019-01-17 03:01:29.050790: step 8285, loss = 0.69149 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:01:30.332567 ops/training.py:65 2019-01-17 03:01:30.332497: step 8286, loss = 0.65999 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:01:31.615933 ops/training.py:65 2019-01-17 03:01:31.615839: step 8287, loss = 0.69024 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:01:32.898383 ops/training.py:65 2019-01-17 03:01:32.898284: step 8288, loss = 0.71984 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:01:34.180933 ops/training.py:65 2019-01-17 03:01:34.180837: step 8289, loss = 0.68030 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:01:35.471793 ops/training.py:65 2019-01-17 03:01:35.471684: step 8290, loss = 0.66263 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:01:36.761321 ops/training.py:65 2019-01-17 03:01:36.761236: step 8291, loss = 0.69417 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:01:38.046360 ops/training.py:65 2019-01-17 03:01:38.046281: step 8292, loss = 0.63076 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:01:39.334522 ops/training.py:65 2019-01-17 03:01:39.334460: step 8293, loss = 0.67551 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:01:40.618654 ops/training.py:65 2019-01-17 03:01:40.618589: step 8294, loss = 0.75662 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:01:41.904883 ops/training.py:65 2019-01-17 03:01:41.904814: step 8295, loss = 0.66242 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:01:43.188121 ops/training.py:65 2019-01-17 03:01:43.188057: step 8296, loss = 0.69826 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:01:44.470667 ops/training.py:65 2019-01-17 03:01:44.470567: step 8297, loss = 0.63203 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:01:45.757945 ops/training.py:65 2019-01-17 03:01:45.757848: step 8298, loss = 0.63580 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:01:47.048810 ops/training.py:65 2019-01-17 03:01:47.048710: step 8299, loss = 0.64501 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:01:48.339475 ops/training.py:65 2019-01-17 03:01:48.339406: step 8300, loss = 0.68282 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:01:49.628003 ops/training.py:65 2019-01-17 03:01:49.627936: step 8301, loss = 0.63110 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:01:50.913082 ops/training.py:65 2019-01-17 03:01:50.913012: step 8302, loss = 0.67874 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:01:52.200281 ops/training.py:65 2019-01-17 03:01:52.200216: step 8303, loss = 0.67979 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:01:53.489596 ops/training.py:65 2019-01-17 03:01:53.489522: step 8304, loss = 0.69337 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:01:54.779274 ops/training.py:65 2019-01-17 03:01:54.779212: step 8305, loss = 0.67148 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:01:56.067963 ops/training.py:65 2019-01-17 03:01:56.067889: step 8306, loss = 0.69782 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:01:57.356925 ops/training.py:65 2019-01-17 03:01:57.356851: step 8307, loss = 0.65941 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:01:58.642989 ops/training.py:65 2019-01-17 03:01:58.642902: step 8308, loss = 0.67038 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:01:59.929631 ops/training.py:65 2019-01-17 03:01:59.929554: step 8309, loss = 0.71228 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:02:01.213561 ops/training.py:65 2019-01-17 03:02:01.213494: step 8310, loss = 0.69600 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:02:02.492975 ops/training.py:65 2019-01-17 03:02:02.492913: step 8311, loss = 0.67689 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:02:03.779716 ops/training.py:65 2019-01-17 03:02:03.779610: step 8312, loss = 0.68290 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:02:05.069814 ops/training.py:65 2019-01-17 03:02:05.069711: step 8313, loss = 0.66408 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:02:06.355619 ops/training.py:65 2019-01-17 03:02:06.355560: step 8314, loss = 0.62760 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:02:07.639599 ops/training.py:65 2019-01-17 03:02:07.639501: step 8315, loss = 0.68660 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:02:08.932021 ops/training.py:65 2019-01-17 03:02:08.931921: step 8316, loss = 0.68782 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:02:10.222842 ops/training.py:65 2019-01-17 03:02:10.222769: step 8317, loss = 0.72220 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:02:11.504019 ops/training.py:65 2019-01-17 03:02:11.503941: step 8318, loss = 0.71844 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:02:12.789390 ops/training.py:65 2019-01-17 03:02:12.789290: step 8319, loss = 0.74386 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:02:14.072845 ops/training.py:65 2019-01-17 03:02:14.072752: step 8320, loss = 0.70127 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:02:15.355374 ops/training.py:65 2019-01-17 03:02:15.355264: step 8321, loss = 0.69504 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:02:16.647331 ops/training.py:65 2019-01-17 03:02:16.647200: step 8322, loss = 0.66615 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:02:17.934560 ops/training.py:65 2019-01-17 03:02:17.934495: step 8323, loss = 0.68577 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:02:19.221205 ops/training.py:65 2019-01-17 03:02:19.221110: step 8324, loss = 0.66499 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:02:20.510180 ops/training.py:65 2019-01-17 03:02:20.510111: step 8325, loss = 0.69972 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:02:21.798951 ops/training.py:65 2019-01-17 03:02:21.798889: step 8326, loss = 0.70712 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:02:23.086267 ops/training.py:65 2019-01-17 03:02:23.086200: step 8327, loss = 0.69271 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:02:24.375572 ops/training.py:65 2019-01-17 03:02:24.375480: step 8328, loss = 0.67301 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:02:25.665874 ops/training.py:65 2019-01-17 03:02:25.665787: step 8329, loss = 0.61839 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:02:26.954226 ops/training.py:65 2019-01-17 03:02:26.954164: step 8330, loss = 0.62103 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 03:02:28.241680 ops/training.py:65 2019-01-17 03:02:28.241614: step 8331, loss = 0.66852 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:02:29.524314 ops/training.py:65 2019-01-17 03:02:29.524251: step 8332, loss = 0.67082 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:02:30.813046 ops/training.py:65 2019-01-17 03:02:30.812973: step 8333, loss = 0.67965 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:02:32.102192 ops/training.py:65 2019-01-17 03:02:32.102125: step 8334, loss = 0.66476 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:02:33.390737 ops/training.py:65 2019-01-17 03:02:33.390669: step 8335, loss = 0.70342 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:02:34.679095 ops/training.py:65 2019-01-17 03:02:34.679022: step 8336, loss = 0.69237 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:02:35.962904 ops/training.py:65 2019-01-17 03:02:35.962840: step 8337, loss = 0.64159 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:02:37.245247 ops/training.py:65 2019-01-17 03:02:37.245140: step 8338, loss = 0.69190 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:02:38.537120 ops/training.py:65 2019-01-17 03:02:38.537020: step 8339, loss = 0.67096 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:02:39.827505 ops/training.py:65 2019-01-17 03:02:39.827427: step 8340, loss = 0.69236 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:02:41.115467 ops/training.py:65 2019-01-17 03:02:41.115392: step 8341, loss = 0.65700 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:02:42.404996 ops/training.py:65 2019-01-17 03:02:42.404904: step 8342, loss = 0.67695 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:02:43.690836 ops/training.py:65 2019-01-17 03:02:43.690763: step 8343, loss = 0.70176 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:02:44.980144 ops/training.py:65 2019-01-17 03:02:44.980035: step 8344, loss = 0.70408 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:02:46.267302 ops/training.py:65 2019-01-17 03:02:46.267205: step 8345, loss = 0.67952 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:02:47.557128 ops/training.py:65 2019-01-17 03:02:47.557059: step 8346, loss = 0.63497 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:02:48.841173 ops/training.py:65 2019-01-17 03:02:48.841107: step 8347, loss = 0.67815 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:02:50.130032 ops/training.py:65 2019-01-17 03:02:50.129937: step 8348, loss = 0.65027 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:02:51.417903 ops/training.py:65 2019-01-17 03:02:51.417829: step 8349, loss = 0.74839 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:02:52.706290 ops/training.py:65 2019-01-17 03:02:52.706199: step 8350, loss = 0.70284 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:02:53.991214 ops/training.py:65 2019-01-17 03:02:53.991135: step 8351, loss = 0.68631 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:02:55.279814 ops/training.py:65 2019-01-17 03:02:55.279714: step 8352, loss = 0.67673 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:02:56.568304 ops/training.py:65 2019-01-17 03:02:56.568238: step 8353, loss = 0.70742 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:02:57.851332 ops/training.py:65 2019-01-17 03:02:57.851262: step 8354, loss = 0.73903 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:02:59.135665 ops/training.py:65 2019-01-17 03:02:59.135558: step 8355, loss = 0.67454 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:03:00.425537 ops/training.py:65 2019-01-17 03:03:00.425433: step 8356, loss = 0.68031 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:03:01.708762 ops/training.py:65 2019-01-17 03:03:01.708697: step 8357, loss = 0.64848 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:03:02.995910 ops/training.py:65 2019-01-17 03:03:02.995821: step 8358, loss = 0.70809 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:03:04.276685 ops/training.py:65 2019-01-17 03:03:04.276609: step 8359, loss = 0.68755 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:03:05.569885 ops/training.py:65 2019-01-17 03:03:05.569777: step 8360, loss = 0.69638 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:03:06.859221 ops/training.py:65 2019-01-17 03:03:06.859153: step 8361, loss = 0.76341 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:03:08.142600 ops/training.py:65 2019-01-17 03:03:08.142527: step 8362, loss = 0.66680 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:03:09.421626 ops/training.py:65 2019-01-17 03:03:09.421525: step 8363, loss = 0.66921 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:03:10.714104 ops/training.py:65 2019-01-17 03:03:10.713955: step 8364, loss = 0.70067 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:03:12.006005 ops/training.py:65 2019-01-17 03:03:12.005941: step 8365, loss = 0.68815 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:03:13.296808 ops/training.py:65 2019-01-17 03:03:13.296739: step 8366, loss = 0.66379 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:03:14.585523 ops/training.py:65 2019-01-17 03:03:14.585455: step 8367, loss = 0.65169 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:03:15.874626 ops/training.py:65 2019-01-17 03:03:15.874553: step 8368, loss = 0.70169 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:03:17.162986 ops/training.py:65 2019-01-17 03:03:17.162918: step 8369, loss = 0.67513 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:03:18.451282 ops/training.py:65 2019-01-17 03:03:18.451222: step 8370, loss = 0.67368 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:03:19.739285 ops/training.py:65 2019-01-17 03:03:19.739201: step 8371, loss = 0.62590 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:03:21.024937 ops/training.py:65 2019-01-17 03:03:21.024870: step 8372, loss = 0.63760 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:03:22.313384 ops/training.py:65 2019-01-17 03:03:22.313310: step 8373, loss = 0.73462 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:03:23.593367 ops/training.py:65 2019-01-17 03:03:23.593290: step 8374, loss = 0.68371 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:03:24.877144 ops/training.py:65 2019-01-17 03:03:24.877034: step 8375, loss = 0.69409 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:03:26.161430 ops/training.py:65 2019-01-17 03:03:26.161332: step 8376, loss = 0.66084 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:03:27.452939 ops/training.py:65 2019-01-17 03:03:27.452834: step 8377, loss = 0.73168 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:03:28.743201 ops/training.py:65 2019-01-17 03:03:28.743134: step 8378, loss = 0.73352 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:03:30.026944 ops/training.py:65 2019-01-17 03:03:30.026881: step 8379, loss = 0.67751 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:03:31.315629 ops/training.py:65 2019-01-17 03:03:31.315524: step 8380, loss = 0.67538 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:03:32.601220 ops/training.py:65 2019-01-17 03:03:32.601156: step 8381, loss = 0.71752 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:03:33.890891 ops/training.py:65 2019-01-17 03:03:33.890787: step 8382, loss = 0.65403 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:03:35.176353 ops/training.py:65 2019-01-17 03:03:35.176285: step 8383, loss = 0.68671 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:03:36.460039 ops/training.py:65 2019-01-17 03:03:36.459947: step 8384, loss = 0.68172 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:03:37.750734 ops/training.py:65 2019-01-17 03:03:37.750629: step 8385, loss = 0.66514 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:03:39.041134 ops/training.py:65 2019-01-17 03:03:39.041068: step 8386, loss = 0.62260 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:03:40.330392 ops/training.py:65 2019-01-17 03:03:40.330309: step 8387, loss = 0.72306 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:03:41.618213 ops/training.py:65 2019-01-17 03:03:41.618139: step 8388, loss = 0.68143 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:03:42.908051 ops/training.py:65 2019-01-17 03:03:42.907959: step 8389, loss = 0.64839 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:03:44.196422 ops/training.py:65 2019-01-17 03:03:44.196356: step 8390, loss = 0.71102 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:03:45.490541 ops/training.py:65 2019-01-17 03:03:45.490475: step 8391, loss = 0.67199 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:03:46.779686 ops/training.py:65 2019-01-17 03:03:46.779593: step 8392, loss = 0.71405 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:03:48.067843 ops/training.py:65 2019-01-17 03:03:48.067744: step 8393, loss = 0.65062 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:03:49.356718 ops/training.py:65 2019-01-17 03:03:49.356647: step 8394, loss = 0.67653 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:03:50.640500 ops/training.py:65 2019-01-17 03:03:50.640431: step 8395, loss = 0.63513 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:03:51.923943 ops/training.py:65 2019-01-17 03:03:51.923839: step 8396, loss = 0.67189 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:03:53.215443 ops/training.py:65 2019-01-17 03:03:53.215342: step 8397, loss = 0.74391 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:03:54.501458 ops/training.py:65 2019-01-17 03:03:54.501387: step 8398, loss = 0.68395 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:03:55.784935 ops/training.py:65 2019-01-17 03:03:55.784829: step 8399, loss = 0.66601 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:03:57.072892 ops/training.py:65 2019-01-17 03:03:57.072791: step 8400, loss = 0.64624 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:03:58.357000 ops/training.py:65 2019-01-17 03:03:58.356900: step 8401, loss = 0.68662 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:03:59.648428 ops/training.py:65 2019-01-17 03:03:59.648323: step 8402, loss = 0.68415 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:04:00.939217 ops/training.py:65 2019-01-17 03:04:00.939126: step 8403, loss = 0.68941 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:04:02.227927 ops/training.py:65 2019-01-17 03:04:02.227856: step 8404, loss = 0.67329 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:04:03.517866 ops/training.py:65 2019-01-17 03:04:03.517786: step 8405, loss = 0.66998 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:04:04.806105 ops/training.py:65 2019-01-17 03:04:04.806010: step 8406, loss = 0.67702 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:04:06.094775 ops/training.py:65 2019-01-17 03:04:06.094702: step 8407, loss = 0.69257 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:04:07.383065 ops/training.py:65 2019-01-17 03:04:07.382996: step 8408, loss = 0.67228 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:04:08.672019 ops/training.py:65 2019-01-17 03:04:08.671952: step 8409, loss = 0.68382 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:04:09.957070 ops/training.py:65 2019-01-17 03:04:09.957003: step 8410, loss = 0.75243 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:04:11.240748 ops/training.py:65 2019-01-17 03:04:11.240642: step 8411, loss = 0.63882 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:04:12.533843 ops/training.py:65 2019-01-17 03:04:12.533743: step 8412, loss = 0.73216 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:04:13.820853 ops/training.py:65 2019-01-17 03:04:13.820761: step 8413, loss = 0.70925 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:04:15.105073 ops/training.py:65 2019-01-17 03:04:15.104967: step 8414, loss = 0.67949 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:04:16.396362 ops/training.py:65 2019-01-17 03:04:16.396260: step 8415, loss = 0.67053 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:04:17.681648 ops/training.py:65 2019-01-17 03:04:17.681582: step 8416, loss = 0.68178 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:04:18.965375 ops/training.py:65 2019-01-17 03:04:18.965277: step 8417, loss = 0.69242 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:04:20.253931 ops/training.py:65 2019-01-17 03:04:20.253774: step 8418, loss = 0.74235 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:04:21.540683 ops/training.py:65 2019-01-17 03:04:21.540574: step 8419, loss = 0.69504 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:04:22.832399 ops/training.py:65 2019-01-17 03:04:22.832289: step 8420, loss = 0.70938 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:04:24.124159 ops/training.py:65 2019-01-17 03:04:24.124072: step 8421, loss = 0.72376 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:04:25.414960 ops/training.py:65 2019-01-17 03:04:25.414883: step 8422, loss = 0.66779 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:04:26.694726 ops/training.py:65 2019-01-17 03:04:26.694664: step 8423, loss = 0.65120 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:04:27.979511 ops/training.py:65 2019-01-17 03:04:27.979411: step 8424, loss = 0.68086 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:04:29.265036 ops/training.py:65 2019-01-17 03:04:29.264927: step 8425, loss = 0.66072 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:04:30.552619 ops/training.py:65 2019-01-17 03:04:30.552513: step 8426, loss = 0.71406 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:04:31.838832 ops/training.py:65 2019-01-17 03:04:31.838732: step 8427, loss = 0.68292 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:04:33.132529 ops/training.py:65 2019-01-17 03:04:33.132432: step 8428, loss = 0.72643 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:04:34.421433 ops/training.py:65 2019-01-17 03:04:34.421364: step 8429, loss = 0.68809 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:04:35.705636 ops/training.py:65 2019-01-17 03:04:35.705563: step 8430, loss = 0.71997 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:04:36.993939 ops/training.py:65 2019-01-17 03:04:36.993876: step 8431, loss = 0.71901 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:04:38.282519 ops/training.py:65 2019-01-17 03:04:38.282429: step 8432, loss = 0.64902 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:04:39.562706 ops/training.py:65 2019-01-17 03:04:39.562627: step 8433, loss = 0.66089 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:04:40.841045 ops/training.py:65 2019-01-17 03:04:40.840939: step 8434, loss = 0.65600 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:04:42.120512 ops/training.py:65 2019-01-17 03:04:42.120404: step 8435, loss = 0.70106 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:04:43.407337 ops/training.py:65 2019-01-17 03:04:43.407240: step 8436, loss = 0.69220 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:04:44.696595 ops/training.py:65 2019-01-17 03:04:44.696445: step 8437, loss = 0.75092 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 03:04:45.985929 ops/training.py:65 2019-01-17 03:04:45.985860: step 8438, loss = 0.66916 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:04:47.270605 ops/training.py:65 2019-01-17 03:04:47.270538: step 8439, loss = 0.61028 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:04:48.559673 ops/training.py:65 2019-01-17 03:04:48.559612: step 8440, loss = 0.67196 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:04:49.842730 ops/training.py:65 2019-01-17 03:04:49.842661: step 8441, loss = 0.62771 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:04:51.135266 ops/training.py:65 2019-01-17 03:04:51.135160: step 8442, loss = 0.62577 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:04:52.431562 ops/training.py:65 2019-01-17 03:04:52.431496: step 8443, loss = 0.68281 (24.7 examples/sec; 1.295 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:04:53.716409 ops/training.py:65 2019-01-17 03:04:53.716343: step 8444, loss = 0.67362 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:04:55.000259 ops/training.py:65 2019-01-17 03:04:55.000186: step 8445, loss = 0.61689 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 03:04:56.285017 ops/training.py:65 2019-01-17 03:04:56.284939: step 8446, loss = 0.71563 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:04:57.574699 ops/training.py:65 2019-01-17 03:04:57.574552: step 8447, loss = 0.68293 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:04:58.865784 ops/training.py:65 2019-01-17 03:04:58.865695: step 8448, loss = 0.70488 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:05:00.154949 ops/training.py:65 2019-01-17 03:05:00.154879: step 8449, loss = 0.69330 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:05:01.436049 ops/training.py:65 2019-01-17 03:05:01.435975: step 8450, loss = 0.64974 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:05:02.722381 ops/training.py:65 2019-01-17 03:05:02.722286: step 8451, loss = 0.68942 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:05:04.014355 ops/training.py:65 2019-01-17 03:05:04.014259: step 8452, loss = 0.66892 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:05:05.300587 ops/training.py:65 2019-01-17 03:05:05.300515: step 8453, loss = 0.64698 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 03:05:06.581771 ops/training.py:65 2019-01-17 03:05:06.581670: step 8454, loss = 0.70262 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:05:07.873310 ops/training.py:65 2019-01-17 03:05:07.873210: step 8455, loss = 0.71498 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:05:09.162475 ops/training.py:65 2019-01-17 03:05:09.162392: step 8456, loss = 0.67169 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:05:10.443933 ops/training.py:65 2019-01-17 03:05:10.443831: step 8457, loss = 0.61806 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:05:11.735365 ops/training.py:65 2019-01-17 03:05:11.735210: step 8458, loss = 0.64789 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:05:13.021636 ops/training.py:65 2019-01-17 03:05:13.021566: step 8459, loss = 0.72190 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:05:14.307697 ops/training.py:65 2019-01-17 03:05:14.307565: step 8460, loss = 0.63334 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:05:15.599449 ops/training.py:65 2019-01-17 03:05:15.599351: step 8461, loss = 0.71312 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:05:16.891424 ops/training.py:65 2019-01-17 03:05:16.891354: step 8462, loss = 0.68550 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:05:18.180788 ops/training.py:65 2019-01-17 03:05:18.180728: step 8463, loss = 0.72429 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:05:19.468078 ops/training.py:65 2019-01-17 03:05:19.468008: step 8464, loss = 0.68793 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:05:20.753837 ops/training.py:65 2019-01-17 03:05:20.753764: step 8465, loss = 0.70355 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:05:22.042297 ops/training.py:65 2019-01-17 03:05:22.042229: step 8466, loss = 0.62363 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:05:23.332878 ops/training.py:65 2019-01-17 03:05:23.332809: step 8467, loss = 0.71427 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:05:24.613621 ops/training.py:65 2019-01-17 03:05:24.613556: step 8468, loss = 0.71443 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:05:25.898906 ops/training.py:65 2019-01-17 03:05:25.898813: step 8469, loss = 0.66560 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:05:27.184149 ops/training.py:65 2019-01-17 03:05:27.184042: step 8470, loss = 0.70390 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:05:28.475598 ops/training.py:65 2019-01-17 03:05:28.475448: step 8471, loss = 0.65080 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:05:29.762128 ops/training.py:65 2019-01-17 03:05:29.762058: step 8472, loss = 0.68235 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:05:31.046254 ops/training.py:65 2019-01-17 03:05:31.046161: step 8473, loss = 0.75441 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 03:05:32.332359 ops/training.py:65 2019-01-17 03:05:32.332266: step 8474, loss = 0.70649 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:05:33.615935 ops/training.py:65 2019-01-17 03:05:33.615841: step 8475, loss = 0.69734 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:05:34.908000 ops/training.py:65 2019-01-17 03:05:34.907900: step 8476, loss = 0.66347 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:05:36.192418 ops/training.py:65 2019-01-17 03:05:36.192347: step 8477, loss = 0.68190 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:05:37.477844 ops/training.py:65 2019-01-17 03:05:37.477736: step 8478, loss = 0.71226 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:05:38.764196 ops/training.py:65 2019-01-17 03:05:38.764095: step 8479, loss = 0.73662 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:05:40.045319 ops/training.py:65 2019-01-17 03:05:40.045216: step 8480, loss = 0.73263 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:05:41.337315 ops/training.py:65 2019-01-17 03:05:41.337204: step 8481, loss = 0.70092 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:05:42.628815 ops/training.py:65 2019-01-17 03:05:42.628742: step 8482, loss = 0.66519 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:05:43.912717 ops/training.py:65 2019-01-17 03:05:43.912642: step 8483, loss = 0.70928 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:05:45.198908 ops/training.py:65 2019-01-17 03:05:45.198808: step 8484, loss = 0.70108 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:05:46.484250 ops/training.py:65 2019-01-17 03:05:46.484134: step 8485, loss = 0.67761 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:05:47.774145 ops/training.py:65 2019-01-17 03:05:47.774059: step 8486, loss = 0.68280 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:05:49.063018 ops/training.py:65 2019-01-17 03:05:49.062951: step 8487, loss = 0.69257 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:05:50.351187 ops/training.py:65 2019-01-17 03:05:50.351119: step 8488, loss = 0.75743 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:05:51.639547 ops/training.py:65 2019-01-17 03:05:51.639458: step 8489, loss = 0.66912 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:05:52.926764 ops/training.py:65 2019-01-17 03:05:52.926693: step 8490, loss = 0.67722 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:05:54.209467 ops/training.py:65 2019-01-17 03:05:54.209389: step 8491, loss = 0.64429 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:05:55.490203 ops/training.py:65 2019-01-17 03:05:55.490111: step 8492, loss = 0.67528 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:05:56.774040 ops/training.py:65 2019-01-17 03:05:56.773928: step 8493, loss = 0.69376 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:05:58.064578 ops/training.py:65 2019-01-17 03:05:58.064473: step 8494, loss = 0.70123 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:05:59.351009 ops/training.py:65 2019-01-17 03:05:59.350948: step 8495, loss = 0.67090 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:06:00.636579 ops/training.py:65 2019-01-17 03:06:00.636479: step 8496, loss = 0.67646 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:06:01.923319 ops/training.py:65 2019-01-17 03:06:01.923228: step 8497, loss = 0.68006 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:06:03.211679 ops/training.py:65 2019-01-17 03:06:03.211571: step 8498, loss = 0.72221 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:06:04.497480 ops/training.py:65 2019-01-17 03:06:04.497415: step 8499, loss = 0.67814 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:06:05.781946 ops/training.py:65 2019-01-17 03:06:05.781845: step 8500, loss = 0.61453 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 03:06:07.070612 ops/training.py:65 2019-01-17 03:06:07.070508: step 8501, loss = 0.69962 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:06:08.356496 ops/training.py:65 2019-01-17 03:06:08.356395: step 8502, loss = 0.66119 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:06:09.648157 ops/training.py:65 2019-01-17 03:06:09.648059: step 8503, loss = 0.68101 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:06:10.933075 ops/training.py:65 2019-01-17 03:06:10.933004: step 8504, loss = 0.65712 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:06:12.217830 ops/training.py:65 2019-01-17 03:06:12.217722: step 8505, loss = 0.64754 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:06:13.499703 ops/training.py:65 2019-01-17 03:06:13.499597: step 8506, loss = 0.71301 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:06:14.785050 ops/training.py:65 2019-01-17 03:06:14.784949: step 8507, loss = 0.71310 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:06:16.073905 ops/training.py:65 2019-01-17 03:06:16.073802: step 8508, loss = 0.64465 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:06:17.363999 ops/training.py:65 2019-01-17 03:06:17.363908: step 8509, loss = 0.70303 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:06:18.648783 ops/training.py:65 2019-01-17 03:06:18.648712: step 8510, loss = 0.64158 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:06:19.930737 ops/training.py:65 2019-01-17 03:06:19.930640: step 8511, loss = 0.64710 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:06:21.216321 ops/training.py:65 2019-01-17 03:06:21.216224: step 8512, loss = 0.65272 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:06:22.501000 ops/training.py:65 2019-01-17 03:06:22.500911: step 8513, loss = 0.70264 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:06:23.786422 ops/training.py:65 2019-01-17 03:06:23.786319: step 8514, loss = 0.71528 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:06:25.070884 ops/training.py:65 2019-01-17 03:06:25.070795: step 8515, loss = 0.61706 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:06:26.363767 ops/training.py:65 2019-01-17 03:06:26.363672: step 8516, loss = 0.68964 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:06:27.651796 ops/training.py:65 2019-01-17 03:06:27.651732: step 8517, loss = 0.73270 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:06:28.936077 ops/training.py:65 2019-01-17 03:06:28.936016: step 8518, loss = 0.65085 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:06:30.226548 ops/training.py:65 2019-01-17 03:06:30.226459: step 8519, loss = 0.71023 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:06:31.515411 ops/training.py:65 2019-01-17 03:06:31.515260: step 8520, loss = 0.70971 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:06:32.806278 ops/training.py:65 2019-01-17 03:06:32.806214: step 8521, loss = 0.72560 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:06:34.094278 ops/training.py:65 2019-01-17 03:06:34.094175: step 8522, loss = 0.68627 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:06:35.383199 ops/training.py:65 2019-01-17 03:06:35.383098: step 8523, loss = 0.64373 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:06:36.674246 ops/training.py:65 2019-01-17 03:06:36.674152: step 8524, loss = 0.66224 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:06:37.963035 ops/training.py:65 2019-01-17 03:06:37.962959: step 8525, loss = 0.69713 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:06:39.247141 ops/training.py:65 2019-01-17 03:06:39.247082: step 8526, loss = 0.68679 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:06:40.530771 ops/training.py:65 2019-01-17 03:06:40.530619: step 8527, loss = 0.75154 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:06:41.822681 ops/training.py:65 2019-01-17 03:06:41.822575: step 8528, loss = 0.66779 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:06:43.113981 ops/training.py:65 2019-01-17 03:06:43.113909: step 8529, loss = 0.68120 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:06:44.402915 ops/training.py:65 2019-01-17 03:06:44.402856: step 8530, loss = 0.66900 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:06:45.691792 ops/training.py:65 2019-01-17 03:06:45.691721: step 8531, loss = 0.72364 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:06:46.979780 ops/training.py:65 2019-01-17 03:06:46.979708: step 8532, loss = 0.73664 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:06:48.269732 ops/training.py:65 2019-01-17 03:06:48.269663: step 8533, loss = 0.67842 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:06:49.556016 ops/training.py:65 2019-01-17 03:06:49.555929: step 8534, loss = 0.77692 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:06:50.840976 ops/training.py:65 2019-01-17 03:06:50.840908: step 8535, loss = 0.72868 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:06:52.123500 ops/training.py:65 2019-01-17 03:06:52.123400: step 8536, loss = 0.75567 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:06:53.412253 ops/training.py:65 2019-01-17 03:06:53.412157: step 8537, loss = 0.69663 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:06:54.699694 ops/training.py:65 2019-01-17 03:06:54.699628: step 8538, loss = 0.70960 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:06:55.985794 ops/training.py:65 2019-01-17 03:06:55.985687: step 8539, loss = 0.64659 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:06:57.272752 ops/training.py:65 2019-01-17 03:06:57.272604: step 8540, loss = 0.64688 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:06:58.557620 ops/training.py:65 2019-01-17 03:06:58.557522: step 8541, loss = 0.71652 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:06:59.849437 ops/training.py:65 2019-01-17 03:06:59.849341: step 8542, loss = 0.76023 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 03:07:01.131031 ops/training.py:65 2019-01-17 03:07:01.130901: step 8543, loss = 0.69148 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:07:02.416843 ops/training.py:65 2019-01-17 03:07:02.416728: step 8544, loss = 0.65528 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:07:03.707435 ops/training.py:65 2019-01-17 03:07:03.707340: step 8545, loss = 0.69962 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:07:04.996491 ops/training.py:65 2019-01-17 03:07:04.996399: step 8546, loss = 0.68339 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:07:06.276585 ops/training.py:65 2019-01-17 03:07:06.276512: step 8547, loss = 0.69993 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:07:07.563180 ops/training.py:65 2019-01-17 03:07:07.563082: step 8548, loss = 0.70159 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:07:08.851044 ops/training.py:65 2019-01-17 03:07:08.850937: step 8549, loss = 0.70678 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:07:10.140219 ops/training.py:65 2019-01-17 03:07:10.140068: step 8550, loss = 0.69103 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:07:11.428743 ops/training.py:65 2019-01-17 03:07:11.428678: step 8551, loss = 0.68563 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:07:12.716984 ops/training.py:65 2019-01-17 03:07:12.716912: step 8552, loss = 0.70880 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:07:14.005911 ops/training.py:65 2019-01-17 03:07:14.005840: step 8553, loss = 0.65418 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:07:15.289068 ops/training.py:65 2019-01-17 03:07:15.289002: step 8554, loss = 0.66880 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:07:16.572881 ops/training.py:65 2019-01-17 03:07:16.572775: step 8555, loss = 0.64966 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:07:17.861798 ops/training.py:65 2019-01-17 03:07:17.861706: step 8556, loss = 0.65579 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:07:19.145403 ops/training.py:65 2019-01-17 03:07:19.145325: step 8557, loss = 0.65385 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:07:20.435938 ops/training.py:65 2019-01-17 03:07:20.435827: step 8558, loss = 0.72913 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:07:21.726582 ops/training.py:65 2019-01-17 03:07:21.726511: step 8559, loss = 0.70726 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:07:23.016715 ops/training.py:65 2019-01-17 03:07:23.016646: step 8560, loss = 0.71385 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:07:24.306231 ops/training.py:65 2019-01-17 03:07:24.306157: step 8561, loss = 0.66812 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:07:25.595614 ops/training.py:65 2019-01-17 03:07:25.595526: step 8562, loss = 0.68189 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:07:26.884327 ops/training.py:65 2019-01-17 03:07:26.884253: step 8563, loss = 0.65309 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:07:28.172815 ops/training.py:65 2019-01-17 03:07:28.172719: step 8564, loss = 0.71353 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:07:29.462502 ops/training.py:65 2019-01-17 03:07:29.462436: step 8565, loss = 0.65477 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:07:30.751113 ops/training.py:65 2019-01-17 03:07:30.751040: step 8566, loss = 0.71182 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:07:32.039863 ops/training.py:65 2019-01-17 03:07:32.039794: step 8567, loss = 0.65718 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:07:33.328598 ops/training.py:65 2019-01-17 03:07:33.328521: step 8568, loss = 0.66774 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:07:34.612750 ops/training.py:65 2019-01-17 03:07:34.612686: step 8569, loss = 0.73490 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:07:35.901775 ops/training.py:65 2019-01-17 03:07:35.901713: step 8570, loss = 0.66570 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:07:37.190805 ops/training.py:65 2019-01-17 03:07:37.190737: step 8571, loss = 0.67075 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:07:38.476129 ops/training.py:65 2019-01-17 03:07:38.476059: step 8572, loss = 0.70183 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:07:39.759376 ops/training.py:65 2019-01-17 03:07:39.759273: step 8573, loss = 0.69947 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:07:41.051587 ops/training.py:65 2019-01-17 03:07:41.051486: step 8574, loss = 0.66373 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:07:42.343120 ops/training.py:65 2019-01-17 03:07:42.343019: step 8575, loss = 0.63667 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:07:43.634452 ops/training.py:65 2019-01-17 03:07:43.634353: step 8576, loss = 0.66645 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:07:44.929367 ops/training.py:65 2019-01-17 03:07:44.929297: step 8577, loss = 0.68229 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:07:46.214534 ops/training.py:65 2019-01-17 03:07:46.214425: step 8578, loss = 0.71845 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:07:47.506752 ops/training.py:65 2019-01-17 03:07:47.506651: step 8579, loss = 0.69685 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:07:48.792802 ops/training.py:65 2019-01-17 03:07:48.792730: step 8580, loss = 0.68615 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:07:50.077854 ops/training.py:65 2019-01-17 03:07:50.077697: step 8581, loss = 0.64412 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:07:51.360711 ops/training.py:65 2019-01-17 03:07:51.360610: step 8582, loss = 0.67389 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:07:52.641177 ops/training.py:65 2019-01-17 03:07:52.641064: step 8583, loss = 0.69457 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:07:53.923597 ops/training.py:65 2019-01-17 03:07:53.923492: step 8584, loss = 0.63206 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:07:55.212888 ops/training.py:65 2019-01-17 03:07:55.212748: step 8585, loss = 0.69429 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:07:56.504123 ops/training.py:65 2019-01-17 03:07:56.504013: step 8586, loss = 0.65412 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:07:57.793728 ops/training.py:65 2019-01-17 03:07:57.793630: step 8587, loss = 0.66816 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:07:59.082114 ops/training.py:65 2019-01-17 03:07:59.082040: step 8588, loss = 0.68779 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:08:00.369704 ops/training.py:65 2019-01-17 03:08:00.369617: step 8589, loss = 0.67978 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:08:01.657648 ops/training.py:65 2019-01-17 03:08:01.657578: step 8590, loss = 0.69047 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:08:02.942654 ops/training.py:65 2019-01-17 03:08:02.942587: step 8591, loss = 0.68130 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:08:04.231321 ops/training.py:65 2019-01-17 03:08:04.231248: step 8592, loss = 0.64440 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:08:05.520405 ops/training.py:65 2019-01-17 03:08:05.520332: step 8593, loss = 0.69062 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:08:06.808948 ops/training.py:65 2019-01-17 03:08:06.808875: step 8594, loss = 0.68213 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:08:08.098634 ops/training.py:65 2019-01-17 03:08:08.098544: step 8595, loss = 0.64368 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 03:08:09.386152 ops/training.py:65 2019-01-17 03:08:09.386083: step 8596, loss = 0.62262 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:08:10.674813 ops/training.py:65 2019-01-17 03:08:10.674743: step 8597, loss = 0.65979 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:08:11.963200 ops/training.py:65 2019-01-17 03:08:11.963123: step 8598, loss = 0.70832 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:08:13.250481 ops/training.py:65 2019-01-17 03:08:13.250407: step 8599, loss = 0.73215 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:08:14.540419 ops/training.py:65 2019-01-17 03:08:14.540349: step 8600, loss = 0.70911 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:08:15.828799 ops/training.py:65 2019-01-17 03:08:15.828702: step 8601, loss = 0.74409 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 03:08:17.118217 ops/training.py:65 2019-01-17 03:08:17.118145: step 8602, loss = 0.75786 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 03:08:18.407384 ops/training.py:65 2019-01-17 03:08:18.407296: step 8603, loss = 0.68566 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:08:19.695891 ops/training.py:65 2019-01-17 03:08:19.695827: step 8604, loss = 0.69941 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:08:20.975414 ops/training.py:65 2019-01-17 03:08:20.975351: step 8605, loss = 0.67925 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:08:22.265073 ops/training.py:65 2019-01-17 03:08:22.264967: step 8606, loss = 0.64953 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:08:23.546965 ops/training.py:65 2019-01-17 03:08:23.546898: step 8607, loss = 0.73448 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:08:24.830546 ops/training.py:65 2019-01-17 03:08:24.830476: step 8608, loss = 0.65876 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:08:26.122899 ops/training.py:65 2019-01-17 03:08:26.122789: step 8609, loss = 0.63220 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:08:27.415255 ops/training.py:65 2019-01-17 03:08:27.415182: step 8610, loss = 0.70986 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:08:28.701354 ops/training.py:65 2019-01-17 03:08:28.701269: step 8611, loss = 0.62260 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:08:29.991439 ops/training.py:65 2019-01-17 03:08:29.991367: step 8612, loss = 0.62601 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:08:31.280615 ops/training.py:65 2019-01-17 03:08:31.280543: step 8613, loss = 0.70108 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:08:32.568911 ops/training.py:65 2019-01-17 03:08:32.568820: step 8614, loss = 0.71993 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:08:33.858858 ops/training.py:65 2019-01-17 03:08:33.858786: step 8615, loss = 0.71928 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:08:35.148636 ops/training.py:65 2019-01-17 03:08:35.148546: step 8616, loss = 0.65159 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:08:36.437721 ops/training.py:65 2019-01-17 03:08:36.437645: step 8617, loss = 0.66185 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:08:37.725095 ops/training.py:65 2019-01-17 03:08:37.725023: step 8618, loss = 0.68804 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:08:39.014510 ops/training.py:65 2019-01-17 03:08:39.014441: step 8619, loss = 0.68334 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:08:40.300137 ops/training.py:65 2019-01-17 03:08:40.300058: step 8620, loss = 0.65305 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:08:41.589946 ops/training.py:65 2019-01-17 03:08:41.589877: step 8621, loss = 0.72907 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:08:42.878314 ops/training.py:65 2019-01-17 03:08:42.878219: step 8622, loss = 0.67574 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:08:44.169030 ops/training.py:65 2019-01-17 03:08:44.168959: step 8623, loss = 0.68484 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:08:45.454835 ops/training.py:65 2019-01-17 03:08:45.454762: step 8624, loss = 0.73296 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:08:46.743437 ops/training.py:65 2019-01-17 03:08:46.743364: step 8625, loss = 0.71292 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:08:48.028948 ops/training.py:65 2019-01-17 03:08:48.028874: step 8626, loss = 0.68505 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:08:49.317341 ops/training.py:65 2019-01-17 03:08:49.317280: step 8627, loss = 0.69552 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:08:50.601246 ops/training.py:65 2019-01-17 03:08:50.601181: step 8628, loss = 0.70707 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:08:51.889681 ops/training.py:65 2019-01-17 03:08:51.889526: step 8629, loss = 0.66900 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:08:53.179329 ops/training.py:65 2019-01-17 03:08:53.179261: step 8630, loss = 0.63738 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:08:54.467705 ops/training.py:65 2019-01-17 03:08:54.467624: step 8631, loss = 0.68799 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:08:55.756571 ops/training.py:65 2019-01-17 03:08:55.756497: step 8632, loss = 0.68527 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:08:57.043122 ops/training.py:65 2019-01-17 03:08:57.043030: step 8633, loss = 0.69550 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:08:58.331445 ops/training.py:65 2019-01-17 03:08:58.331368: step 8634, loss = 0.65961 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:08:59.620554 ops/training.py:65 2019-01-17 03:08:59.620479: step 8635, loss = 0.67969 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:09:00.903832 ops/training.py:65 2019-01-17 03:09:00.903762: step 8636, loss = 0.70157 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:09:02.188444 ops/training.py:65 2019-01-17 03:09:02.188351: step 8637, loss = 0.65160 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:09:03.476248 ops/training.py:65 2019-01-17 03:09:03.476149: step 8638, loss = 0.70644 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:09:04.768582 ops/training.py:65 2019-01-17 03:09:04.768428: step 8639, loss = 0.70224 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:09:06.059715 ops/training.py:65 2019-01-17 03:09:06.059613: step 8640, loss = 0.67511 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:09:07.350177 ops/training.py:65 2019-01-17 03:09:07.350096: step 8641, loss = 0.71969 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:09:08.639063 ops/training.py:65 2019-01-17 03:09:08.638989: step 8642, loss = 0.66546 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:09:09.927215 ops/training.py:65 2019-01-17 03:09:09.927148: step 8643, loss = 0.74041 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:09:11.216040 ops/training.py:65 2019-01-17 03:09:11.215975: step 8644, loss = 0.71479 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:09:12.504173 ops/training.py:65 2019-01-17 03:09:12.504099: step 8645, loss = 0.70071 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:09:13.788290 ops/training.py:65 2019-01-17 03:09:13.788210: step 8646, loss = 0.63682 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:09:15.072667 ops/training.py:65 2019-01-17 03:09:15.072558: step 8647, loss = 0.65622 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:09:16.359969 ops/training.py:65 2019-01-17 03:09:16.359817: step 8648, loss = 0.68179 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:09:17.652826 ops/training.py:65 2019-01-17 03:09:17.652684: step 8649, loss = 0.74299 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:09:18.943182 ops/training.py:65 2019-01-17 03:09:18.943112: step 8650, loss = 0.72501 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:09:20.232041 ops/training.py:65 2019-01-17 03:09:20.231971: step 8651, loss = 0.78592 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:09:21.520661 ops/training.py:65 2019-01-17 03:09:21.520593: step 8652, loss = 0.72628 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:09:22.809217 ops/training.py:65 2019-01-17 03:09:22.809116: step 8653, loss = 0.66174 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:09:24.095359 ops/training.py:65 2019-01-17 03:09:24.095284: step 8654, loss = 0.72836 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:09:25.380308 ops/training.py:65 2019-01-17 03:09:25.380226: step 8655, loss = 0.65456 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:09:26.662192 ops/training.py:65 2019-01-17 03:09:26.662124: step 8656, loss = 0.71096 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:09:27.948806 ops/training.py:65 2019-01-17 03:09:27.948700: step 8657, loss = 0.70013 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:09:29.240418 ops/training.py:65 2019-01-17 03:09:29.240271: step 8658, loss = 0.71345 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:09:30.531821 ops/training.py:65 2019-01-17 03:09:30.531756: step 8659, loss = 0.70483 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:09:31.816015 ops/training.py:65 2019-01-17 03:09:31.815952: step 8660, loss = 0.67822 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:09:33.100586 ops/training.py:65 2019-01-17 03:09:33.100502: step 8661, loss = 0.67695 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:09:34.387618 ops/training.py:65 2019-01-17 03:09:34.387518: step 8662, loss = 0.62991 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:09:35.673937 ops/training.py:65 2019-01-17 03:09:35.673832: step 8663, loss = 0.66933 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:09:36.960907 ops/training.py:65 2019-01-17 03:09:36.960760: step 8664, loss = 0.70373 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:09:38.246348 ops/training.py:65 2019-01-17 03:09:38.246239: step 8665, loss = 0.70592 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:09:39.539779 ops/training.py:65 2019-01-17 03:09:39.539675: step 8666, loss = 0.62171 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:09:40.825029 ops/training.py:65 2019-01-17 03:09:40.824963: step 8667, loss = 0.67256 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:09:42.105060 ops/training.py:65 2019-01-17 03:09:42.104956: step 8668, loss = 0.66764 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:09:43.390334 ops/training.py:65 2019-01-17 03:09:43.390237: step 8669, loss = 0.71939 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:09:44.677050 ops/training.py:65 2019-01-17 03:09:44.676949: step 8670, loss = 0.65508 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:09:45.968778 ops/training.py:65 2019-01-17 03:09:45.968677: step 8671, loss = 0.82596 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 03:09:47.255688 ops/training.py:65 2019-01-17 03:09:47.255598: step 8672, loss = 0.70631 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:09:48.541176 ops/training.py:65 2019-01-17 03:09:48.541029: step 8673, loss = 0.66649 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:09:49.835927 ops/training.py:65 2019-01-17 03:09:49.835774: step 8674, loss = 0.70947 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:09:51.125444 ops/training.py:65 2019-01-17 03:09:51.125359: step 8675, loss = 0.71444 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:09:52.414376 ops/training.py:65 2019-01-17 03:09:52.414314: step 8676, loss = 0.67768 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:09:53.700007 ops/training.py:65 2019-01-17 03:09:53.699929: step 8677, loss = 0.75873 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:09:54.980658 ops/training.py:65 2019-01-17 03:09:54.980554: step 8678, loss = 0.65846 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:09:56.265186 ops/training.py:65 2019-01-17 03:09:56.265088: step 8679, loss = 0.68489 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:09:57.552208 ops/training.py:65 2019-01-17 03:09:57.552108: step 8680, loss = 0.66795 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:09:58.841455 ops/training.py:65 2019-01-17 03:09:58.841347: step 8681, loss = 0.62490 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:10:00.126041 ops/training.py:65 2019-01-17 03:10:00.125922: step 8682, loss = 0.68581 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:10:01.407505 ops/training.py:65 2019-01-17 03:10:01.407400: step 8683, loss = 0.70674 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:10:02.698400 ops/training.py:65 2019-01-17 03:10:02.698314: step 8684, loss = 0.68721 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:10:03.982161 ops/training.py:65 2019-01-17 03:10:03.982054: step 8685, loss = 0.69037 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:10:05.266684 ops/training.py:65 2019-01-17 03:10:05.266581: step 8686, loss = 0.69210 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:10:06.553780 ops/training.py:65 2019-01-17 03:10:06.553676: step 8687, loss = 0.67175 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:10:07.839341 ops/training.py:65 2019-01-17 03:10:07.839241: step 8688, loss = 0.68649 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:10:09.132824 ops/training.py:65 2019-01-17 03:10:09.132724: step 8689, loss = 0.69665 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:10:10.418314 ops/training.py:65 2019-01-17 03:10:10.418252: step 8690, loss = 0.71642 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:10:11.703673 ops/training.py:65 2019-01-17 03:10:11.703573: step 8691, loss = 0.68360 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:10:12.988865 ops/training.py:65 2019-01-17 03:10:12.988773: step 8692, loss = 0.68780 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:10:14.278448 ops/training.py:65 2019-01-17 03:10:14.278344: step 8693, loss = 0.69064 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:10:15.565008 ops/training.py:65 2019-01-17 03:10:15.564901: step 8694, loss = 0.67774 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:10:16.852840 ops/training.py:65 2019-01-17 03:10:16.852776: step 8695, loss = 0.70539 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:10:18.136414 ops/training.py:65 2019-01-17 03:10:18.136343: step 8696, loss = 0.64492 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:10:19.421165 ops/training.py:65 2019-01-17 03:10:19.421058: step 8697, loss = 0.70298 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:10:20.714273 ops/training.py:65 2019-01-17 03:10:20.714167: step 8698, loss = 0.62400 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:10:22.001225 ops/training.py:65 2019-01-17 03:10:22.001149: step 8699, loss = 0.68410 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:10:23.286374 ops/training.py:65 2019-01-17 03:10:23.286278: step 8700, loss = 0.69731 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:10:24.577444 ops/training.py:65 2019-01-17 03:10:24.577344: step 8701, loss = 0.70424 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:10:25.863233 ops/training.py:65 2019-01-17 03:10:25.863158: step 8702, loss = 0.62117 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:10:27.151714 ops/training.py:65 2019-01-17 03:10:27.151643: step 8703, loss = 0.66241 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:10:28.436218 ops/training.py:65 2019-01-17 03:10:28.436147: step 8704, loss = 0.69899 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:10:29.722048 ops/training.py:65 2019-01-17 03:10:29.721948: step 8705, loss = 0.75349 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:10:31.006977 ops/training.py:65 2019-01-17 03:10:31.006869: step 8706, loss = 0.68062 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:10:32.294101 ops/training.py:65 2019-01-17 03:10:32.294017: step 8707, loss = 0.66218 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:10:33.581771 ops/training.py:65 2019-01-17 03:10:33.581681: step 8708, loss = 0.69698 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:10:34.871448 ops/training.py:65 2019-01-17 03:10:34.871382: step 8709, loss = 0.66006 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:10:36.156264 ops/training.py:65 2019-01-17 03:10:36.156188: step 8710, loss = 0.65238 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:10:37.447378 ops/training.py:65 2019-01-17 03:10:37.447275: step 8711, loss = 0.68874 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:10:38.735416 ops/training.py:65 2019-01-17 03:10:38.735335: step 8712, loss = 0.70417 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 03:10:40.024798 ops/training.py:65 2019-01-17 03:10:40.024656: step 8713, loss = 0.67935 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:10:41.314760 ops/training.py:65 2019-01-17 03:10:41.314690: step 8714, loss = 0.65151 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:10:42.599633 ops/training.py:65 2019-01-17 03:10:42.599562: step 8715, loss = 0.71276 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:10:43.892601 ops/training.py:65 2019-01-17 03:10:43.892507: step 8716, loss = 0.66122 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:10:45.183515 ops/training.py:65 2019-01-17 03:10:45.183440: step 8717, loss = 0.63404 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:10:46.466464 ops/training.py:65 2019-01-17 03:10:46.466400: step 8718, loss = 0.67375 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:10:47.745770 ops/training.py:65 2019-01-17 03:10:47.745681: step 8719, loss = 0.63762 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:10:49.038608 ops/training.py:65 2019-01-17 03:10:49.038512: step 8720, loss = 0.66813 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:10:50.328666 ops/training.py:65 2019-01-17 03:10:50.328511: step 8721, loss = 0.68761 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:10:51.618299 ops/training.py:65 2019-01-17 03:10:51.618218: step 8722, loss = 0.62936 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:10:52.903803 ops/training.py:65 2019-01-17 03:10:52.903740: step 8723, loss = 0.67864 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:10:54.192979 ops/training.py:65 2019-01-17 03:10:54.192904: step 8724, loss = 0.73818 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:10:55.480668 ops/training.py:65 2019-01-17 03:10:55.480599: step 8725, loss = 0.70135 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:10:56.770060 ops/training.py:65 2019-01-17 03:10:56.770001: step 8726, loss = 0.67235 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:10:58.055540 ops/training.py:65 2019-01-17 03:10:58.055456: step 8727, loss = 0.71471 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:10:59.343010 ops/training.py:65 2019-01-17 03:10:59.342913: step 8728, loss = 0.70434 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:11:00.627430 ops/training.py:65 2019-01-17 03:11:00.627325: step 8729, loss = 0.67439 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:11:01.919077 ops/training.py:65 2019-01-17 03:11:01.918939: step 8730, loss = 0.64657 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:11:03.204691 ops/training.py:65 2019-01-17 03:11:03.204627: step 8731, loss = 0.64915 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:11:04.488363 ops/training.py:65 2019-01-17 03:11:04.488260: step 8732, loss = 0.70679 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:11:05.781434 ops/training.py:65 2019-01-17 03:11:05.781331: step 8733, loss = 0.64606 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:11:07.071498 ops/training.py:65 2019-01-17 03:11:07.071433: step 8734, loss = 0.64694 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:11:08.361060 ops/training.py:65 2019-01-17 03:11:08.360986: step 8735, loss = 0.70351 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:11:09.649782 ops/training.py:65 2019-01-17 03:11:09.649715: step 8736, loss = 0.65861 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:11:10.931369 ops/training.py:65 2019-01-17 03:11:10.931308: step 8737, loss = 0.70138 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:11:12.215366 ops/training.py:65 2019-01-17 03:11:12.215257: step 8738, loss = 0.67484 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:11:13.506001 ops/training.py:65 2019-01-17 03:11:13.505900: step 8739, loss = 0.67418 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:11:14.795188 ops/training.py:65 2019-01-17 03:11:14.795118: step 8740, loss = 0.68269 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:11:16.083947 ops/training.py:65 2019-01-17 03:11:16.083879: step 8741, loss = 0.66303 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:11:17.368307 ops/training.py:65 2019-01-17 03:11:17.368242: step 8742, loss = 0.65073 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:11:18.654840 ops/training.py:65 2019-01-17 03:11:18.654762: step 8743, loss = 0.70361 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:11:19.947506 ops/training.py:65 2019-01-17 03:11:19.947397: step 8744, loss = 0.67632 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:11:21.231913 ops/training.py:65 2019-01-17 03:11:21.231848: step 8745, loss = 0.66882 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:11:22.514930 ops/training.py:65 2019-01-17 03:11:22.514826: step 8746, loss = 0.71373 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:11:23.798768 ops/training.py:65 2019-01-17 03:11:23.798673: step 8747, loss = 0.71732 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:11:25.090003 ops/training.py:65 2019-01-17 03:11:25.089840: step 8748, loss = 0.68461 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:11:26.380274 ops/training.py:65 2019-01-17 03:11:26.380209: step 8749, loss = 0.77300 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-17 03:11:27.669899 ops/training.py:65 2019-01-17 03:11:27.669834: step 8750, loss = 0.65820 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:11:28.953950 ops/training.py:65 2019-01-17 03:11:28.953875: step 8751, loss = 0.73766 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:11:30.243638 ops/training.py:65 2019-01-17 03:11:30.243539: step 8752, loss = 0.74500 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:11:31.531723 ops/training.py:65 2019-01-17 03:11:31.531661: step 8753, loss = 0.61735 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:11:32.819733 ops/training.py:65 2019-01-17 03:11:32.819669: step 8754, loss = 0.67948 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:11:34.107497 ops/training.py:65 2019-01-17 03:11:34.107428: step 8755, loss = 0.65475 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:11:35.391260 ops/training.py:65 2019-01-17 03:11:35.391198: step 8756, loss = 0.72413 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:11:36.674485 ops/training.py:65 2019-01-17 03:11:36.674386: step 8757, loss = 0.75863 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:11:37.965333 ops/training.py:65 2019-01-17 03:11:37.965217: step 8758, loss = 0.65987 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:11:39.252321 ops/training.py:65 2019-01-17 03:11:39.252256: step 8759, loss = 0.70205 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:11:40.540269 ops/training.py:65 2019-01-17 03:11:40.540203: step 8760, loss = 0.68979 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:11:41.829374 ops/training.py:65 2019-01-17 03:11:41.829305: step 8761, loss = 0.66622 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:11:43.120039 ops/training.py:65 2019-01-17 03:11:43.119943: step 8762, loss = 0.72416 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:11:44.404847 ops/training.py:65 2019-01-17 03:11:44.404774: step 8763, loss = 0.72770 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:11:45.691281 ops/training.py:65 2019-01-17 03:11:45.691173: step 8764, loss = 0.75867 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:11:46.982356 ops/training.py:65 2019-01-17 03:11:46.982255: step 8765, loss = 0.71838 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:11:48.271549 ops/training.py:65 2019-01-17 03:11:48.271407: step 8766, loss = 0.65871 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:11:49.560760 ops/training.py:65 2019-01-17 03:11:49.560607: step 8767, loss = 0.71417 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:11:50.850951 ops/training.py:65 2019-01-17 03:11:50.850888: step 8768, loss = 0.70519 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:11:52.134500 ops/training.py:65 2019-01-17 03:11:52.134441: step 8769, loss = 0.68512 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:11:53.422569 ops/training.py:65 2019-01-17 03:11:53.422467: step 8770, loss = 0.69546 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:11:54.712724 ops/training.py:65 2019-01-17 03:11:54.712631: step 8771, loss = 0.67508 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:11:56.001082 ops/training.py:65 2019-01-17 03:11:56.001014: step 8772, loss = 0.66668 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:11:57.282581 ops/training.py:65 2019-01-17 03:11:57.282504: step 8773, loss = 0.64774 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:11:58.568795 ops/training.py:65 2019-01-17 03:11:58.568646: step 8774, loss = 0.70314 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:11:59.852190 ops/training.py:65 2019-01-17 03:11:59.852081: step 8775, loss = 0.74393 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:12:01.139563 ops/training.py:65 2019-01-17 03:12:01.139463: step 8776, loss = 0.66836 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:12:02.432267 ops/training.py:65 2019-01-17 03:12:02.432181: step 8777, loss = 0.65251 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:12:03.717330 ops/training.py:65 2019-01-17 03:12:03.717263: step 8778, loss = 0.71059 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:12:05.002138 ops/training.py:65 2019-01-17 03:12:05.002040: step 8779, loss = 0.68812 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:12:06.294333 ops/training.py:65 2019-01-17 03:12:06.294229: step 8780, loss = 0.67570 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:12:07.584719 ops/training.py:65 2019-01-17 03:12:07.584656: step 8781, loss = 0.61113 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 03:12:08.870531 ops/training.py:65 2019-01-17 03:12:08.870473: step 8782, loss = 0.62921 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:12:10.157938 ops/training.py:65 2019-01-17 03:12:10.157834: step 8783, loss = 0.68218 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:12:11.447258 ops/training.py:65 2019-01-17 03:12:11.447191: step 8784, loss = 0.67006 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:12:12.732045 ops/training.py:65 2019-01-17 03:12:12.731973: step 8785, loss = 0.71817 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:12:14.021064 ops/training.py:65 2019-01-17 03:12:14.020994: step 8786, loss = 0.68538 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:12:15.310682 ops/training.py:65 2019-01-17 03:12:15.310619: step 8787, loss = 0.69623 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:12:16.600140 ops/training.py:65 2019-01-17 03:12:16.600075: step 8788, loss = 0.65760 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:12:17.888892 ops/training.py:65 2019-01-17 03:12:17.888830: step 8789, loss = 0.61676 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:12:19.177567 ops/training.py:65 2019-01-17 03:12:19.177505: step 8790, loss = 0.68773 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:12:20.465000 ops/training.py:65 2019-01-17 03:12:20.464929: step 8791, loss = 0.71304 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:12:21.746240 ops/training.py:65 2019-01-17 03:12:21.746167: step 8792, loss = 0.66514 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:12:23.034101 ops/training.py:65 2019-01-17 03:12:23.033995: step 8793, loss = 0.65530 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:12:24.319380 ops/training.py:65 2019-01-17 03:12:24.319275: step 8794, loss = 0.68352 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:12:25.606089 ops/training.py:65 2019-01-17 03:12:25.605982: step 8795, loss = 0.69442 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:12:26.896359 ops/training.py:65 2019-01-17 03:12:26.896250: step 8796, loss = 0.68726 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:12:28.186443 ops/training.py:65 2019-01-17 03:12:28.186342: step 8797, loss = 0.65986 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:12:29.474574 ops/training.py:65 2019-01-17 03:12:29.474509: step 8798, loss = 0.70518 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:12:30.762119 ops/training.py:65 2019-01-17 03:12:30.762039: step 8799, loss = 0.67033 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:12:32.049503 ops/training.py:65 2019-01-17 03:12:32.049402: step 8800, loss = 0.70847 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:12:33.333417 ops/training.py:65 2019-01-17 03:12:33.333351: step 8801, loss = 0.61308 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:12:34.616311 ops/training.py:65 2019-01-17 03:12:34.616203: step 8802, loss = 0.71817 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:12:35.900167 ops/training.py:65 2019-01-17 03:12:35.900066: step 8803, loss = 0.67392 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:12:37.192385 ops/training.py:65 2019-01-17 03:12:37.192285: step 8804, loss = 0.68861 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:12:38.483400 ops/training.py:65 2019-01-17 03:12:38.483296: step 8805, loss = 0.65541 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:12:39.768236 ops/training.py:65 2019-01-17 03:12:39.768170: step 8806, loss = 0.64816 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:12:41.056680 ops/training.py:65 2019-01-17 03:12:41.056613: step 8807, loss = 0.76702 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:12:42.344718 ops/training.py:65 2019-01-17 03:12:42.344627: step 8808, loss = 0.62703 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:12:43.634899 ops/training.py:65 2019-01-17 03:12:43.634826: step 8809, loss = 0.69759 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:12:44.923593 ops/training.py:65 2019-01-17 03:12:44.923523: step 8810, loss = 0.73327 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:12:46.206901 ops/training.py:65 2019-01-17 03:12:46.206832: step 8811, loss = 0.69525 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:12:47.492379 ops/training.py:65 2019-01-17 03:12:47.492283: step 8812, loss = 0.71938 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:12:48.785395 ops/training.py:65 2019-01-17 03:12:48.785290: step 8813, loss = 0.65806 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:12:50.071734 ops/training.py:65 2019-01-17 03:12:50.071626: step 8814, loss = 0.68228 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:12:51.357063 ops/training.py:65 2019-01-17 03:12:51.356967: step 8815, loss = 0.66100 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:12:52.644173 ops/training.py:65 2019-01-17 03:12:52.644030: step 8816, loss = 0.72185 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:12:53.934979 ops/training.py:65 2019-01-17 03:12:53.934876: step 8817, loss = 0.68275 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:12:55.223342 ops/training.py:65 2019-01-17 03:12:55.223276: step 8818, loss = 0.68233 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:12:56.508729 ops/training.py:65 2019-01-17 03:12:56.508662: step 8819, loss = 0.70386 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:12:57.792193 ops/training.py:65 2019-01-17 03:12:57.792131: step 8820, loss = 0.72950 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:12:59.081507 ops/training.py:65 2019-01-17 03:12:59.081407: step 8821, loss = 0.69633 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:13:00.367694 ops/training.py:65 2019-01-17 03:13:00.367611: step 8822, loss = 0.70600 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:13:01.655002 ops/training.py:65 2019-01-17 03:13:01.654894: step 8823, loss = 0.66530 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:13:02.945355 ops/training.py:65 2019-01-17 03:13:02.945261: step 8824, loss = 0.69852 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:13:04.229570 ops/training.py:65 2019-01-17 03:13:04.229504: step 8825, loss = 0.65489 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:13:05.517875 ops/training.py:65 2019-01-17 03:13:05.517780: step 8826, loss = 0.71890 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:13:06.803780 ops/training.py:65 2019-01-17 03:13:06.803701: step 8827, loss = 0.68413 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:13:08.088042 ops/training.py:65 2019-01-17 03:13:08.087978: step 8828, loss = 0.67479 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:13:09.370253 ops/training.py:65 2019-01-17 03:13:09.370151: step 8829, loss = 0.63706 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:13:10.662207 ops/training.py:65 2019-01-17 03:13:10.662048: step 8830, loss = 0.68991 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:13:11.953588 ops/training.py:65 2019-01-17 03:13:11.953500: step 8831, loss = 0.71037 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:13:13.238410 ops/training.py:65 2019-01-17 03:13:13.238337: step 8832, loss = 0.68911 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:13:14.524302 ops/training.py:65 2019-01-17 03:13:14.524196: step 8833, loss = 0.71412 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:13:15.807266 ops/training.py:65 2019-01-17 03:13:15.807164: step 8834, loss = 0.67975 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:13:17.089753 ops/training.py:65 2019-01-17 03:13:17.089593: step 8835, loss = 0.65068 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:13:18.381829 ops/training.py:65 2019-01-17 03:13:18.381729: step 8836, loss = 0.66166 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:13:19.672112 ops/training.py:65 2019-01-17 03:13:19.672050: step 8837, loss = 0.64289 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:13:20.960656 ops/training.py:65 2019-01-17 03:13:20.960590: step 8838, loss = 0.71024 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:13:22.248681 ops/training.py:65 2019-01-17 03:13:22.248593: step 8839, loss = 0.67869 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:13:23.536645 ops/training.py:65 2019-01-17 03:13:23.536574: step 8840, loss = 0.65971 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:13:24.820472 ops/training.py:65 2019-01-17 03:13:24.820396: step 8841, loss = 0.64552 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:13:26.101279 ops/training.py:65 2019-01-17 03:13:26.101212: step 8842, loss = 0.72437 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:13:27.385849 ops/training.py:65 2019-01-17 03:13:27.385744: step 8843, loss = 0.67089 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:13:28.677605 ops/training.py:65 2019-01-17 03:13:28.677503: step 8844, loss = 0.69450 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:13:29.969853 ops/training.py:65 2019-01-17 03:13:29.969788: step 8845, loss = 0.70049 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:13:31.253205 ops/training.py:65 2019-01-17 03:13:31.253143: step 8846, loss = 0.62228 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:13:32.534606 ops/training.py:65 2019-01-17 03:13:32.534512: step 8847, loss = 0.66408 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:13:33.826065 ops/training.py:65 2019-01-17 03:13:33.825921: step 8848, loss = 0.70446 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:13:35.118290 ops/training.py:65 2019-01-17 03:13:35.118183: step 8849, loss = 0.70667 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:13:36.403825 ops/training.py:65 2019-01-17 03:13:36.403763: step 8850, loss = 0.69303 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:13:37.686635 ops/training.py:65 2019-01-17 03:13:37.686526: step 8851, loss = 0.69471 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:13:38.969413 ops/training.py:65 2019-01-17 03:13:38.969300: step 8852, loss = 0.70218 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:13:40.261136 ops/training.py:65 2019-01-17 03:13:40.260976: step 8853, loss = 0.69198 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:13:41.547237 ops/training.py:65 2019-01-17 03:13:41.547175: step 8854, loss = 0.62058 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:13:42.832932 ops/training.py:65 2019-01-17 03:13:42.832828: step 8855, loss = 0.65693 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:13:44.117559 ops/training.py:65 2019-01-17 03:13:44.117458: step 8856, loss = 0.64881 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:13:45.410010 ops/training.py:65 2019-01-17 03:13:45.409906: step 8857, loss = 0.61054 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:13:46.696669 ops/training.py:65 2019-01-17 03:13:46.696590: step 8858, loss = 0.70048 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:13:47.985088 ops/training.py:65 2019-01-17 03:13:47.985026: step 8859, loss = 0.65805 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:13:49.269471 ops/training.py:65 2019-01-17 03:13:49.269412: step 8860, loss = 0.68307 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:13:50.557989 ops/training.py:65 2019-01-17 03:13:50.557886: step 8861, loss = 0.72646 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:13:51.845364 ops/training.py:65 2019-01-17 03:13:51.845278: step 8862, loss = 0.64336 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:13:53.131929 ops/training.py:65 2019-01-17 03:13:53.131827: step 8863, loss = 0.60995 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:13:54.417424 ops/training.py:65 2019-01-17 03:13:54.417323: step 8864, loss = 0.68283 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:13:55.697763 ops/training.py:65 2019-01-17 03:13:55.697660: step 8865, loss = 0.68299 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:13:56.989160 ops/training.py:65 2019-01-17 03:13:56.989045: step 8866, loss = 0.65592 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:13:58.279681 ops/training.py:65 2019-01-17 03:13:58.279613: step 8867, loss = 0.68627 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:13:59.569597 ops/training.py:65 2019-01-17 03:13:59.569523: step 8868, loss = 0.64300 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:14:00.855679 ops/training.py:65 2019-01-17 03:14:00.855607: step 8869, loss = 0.65689 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:14:02.147358 ops/training.py:65 2019-01-17 03:14:02.147249: step 8870, loss = 0.68028 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:14:03.431496 ops/training.py:65 2019-01-17 03:14:03.431417: step 8871, loss = 0.70278 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:14:04.718165 ops/training.py:65 2019-01-17 03:14:04.718051: step 8872, loss = 0.63434 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:14:06.003829 ops/training.py:65 2019-01-17 03:14:06.003714: step 8873, loss = 0.71405 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:14:07.287199 ops/training.py:65 2019-01-17 03:14:07.287098: step 8874, loss = 0.71541 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 03:14:08.577727 ops/training.py:65 2019-01-17 03:14:08.577572: step 8875, loss = 0.68576 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:14:09.868206 ops/training.py:65 2019-01-17 03:14:09.868140: step 8876, loss = 0.66608 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:14:11.156329 ops/training.py:65 2019-01-17 03:14:11.156268: step 8877, loss = 0.67915 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:14:12.439216 ops/training.py:65 2019-01-17 03:14:12.439139: step 8878, loss = 0.69374 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:14:13.727572 ops/training.py:65 2019-01-17 03:14:13.727473: step 8879, loss = 0.74208 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:14:15.013364 ops/training.py:65 2019-01-17 03:14:15.013259: step 8880, loss = 0.70503 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:14:16.302069 ops/training.py:65 2019-01-17 03:14:16.301968: step 8881, loss = 0.66073 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:14:17.590506 ops/training.py:65 2019-01-17 03:14:17.590409: step 8882, loss = 0.69070 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:14:18.875886 ops/training.py:65 2019-01-17 03:14:18.875828: step 8883, loss = 0.69992 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:14:20.162101 ops/training.py:65 2019-01-17 03:14:20.161996: step 8884, loss = 0.64866 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:14:21.444361 ops/training.py:65 2019-01-17 03:14:21.444250: step 8885, loss = 0.63602 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:14:22.727634 ops/training.py:65 2019-01-17 03:14:22.727529: step 8886, loss = 0.72865 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:14:24.015513 ops/training.py:65 2019-01-17 03:14:24.015410: step 8887, loss = 0.67043 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:14:25.304412 ops/training.py:65 2019-01-17 03:14:25.304309: step 8888, loss = 0.70042 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:14:26.592022 ops/training.py:65 2019-01-17 03:14:26.591958: step 8889, loss = 0.69264 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:14:27.877328 ops/training.py:65 2019-01-17 03:14:27.877266: step 8890, loss = 0.66432 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:14:29.162963 ops/training.py:65 2019-01-17 03:14:29.162889: step 8891, loss = 0.61352 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 03:14:30.451901 ops/training.py:65 2019-01-17 03:14:30.451798: step 8892, loss = 0.71941 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:14:31.749584 ops/training.py:65 2019-01-17 03:14:31.749480: step 8893, loss = 0.69599 (24.7 examples/sec; 1.296 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:14:33.035865 ops/training.py:65 2019-01-17 03:14:33.035800: step 8894, loss = 0.65492 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:14:34.320983 ops/training.py:65 2019-01-17 03:14:34.320882: step 8895, loss = 0.70225 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:14:35.606432 ops/training.py:65 2019-01-17 03:14:35.606366: step 8896, loss = 0.68542 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:14:36.891648 ops/training.py:65 2019-01-17 03:14:36.891548: step 8897, loss = 0.69851 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:14:38.176826 ops/training.py:65 2019-01-17 03:14:38.176747: step 8898, loss = 0.70852 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:14:39.461140 ops/training.py:65 2019-01-17 03:14:39.461034: step 8899, loss = 0.65234 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:14:40.746629 ops/training.py:65 2019-01-17 03:14:40.746525: step 8900, loss = 0.69884 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:14:42.039222 ops/training.py:65 2019-01-17 03:14:42.039115: step 8901, loss = 0.62403 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:14:43.324042 ops/training.py:65 2019-01-17 03:14:43.323964: step 8902, loss = 0.67903 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:14:44.615920 ops/training.py:65 2019-01-17 03:14:44.615818: step 8903, loss = 0.70807 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:14:45.903127 ops/training.py:65 2019-01-17 03:14:45.903064: step 8904, loss = 0.68995 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:14:47.189092 ops/training.py:65 2019-01-17 03:14:47.188979: step 8905, loss = 0.67260 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:14:48.481566 ops/training.py:65 2019-01-17 03:14:48.481472: step 8906, loss = 0.68283 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:14:49.767984 ops/training.py:65 2019-01-17 03:14:49.767921: step 8907, loss = 0.68480 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:14:51.058255 ops/training.py:65 2019-01-17 03:14:51.058152: step 8908, loss = 0.67868 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:14:52.349155 ops/training.py:65 2019-01-17 03:14:52.349089: step 8909, loss = 0.67782 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:14:53.637056 ops/training.py:65 2019-01-17 03:14:53.636987: step 8910, loss = 0.67024 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:14:54.917985 ops/training.py:65 2019-01-17 03:14:54.917923: step 8911, loss = 0.78084 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:14:56.202643 ops/training.py:65 2019-01-17 03:14:56.202587: step 8912, loss = 0.70477 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:14:57.492777 ops/training.py:65 2019-01-17 03:14:57.492671: step 8913, loss = 0.68180 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:14:58.775727 ops/training.py:65 2019-01-17 03:14:58.775651: step 8914, loss = 0.67393 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:15:00.063271 ops/training.py:65 2019-01-17 03:15:00.063175: step 8915, loss = 0.70834 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:15:01.346817 ops/training.py:65 2019-01-17 03:15:01.346743: step 8916, loss = 0.66866 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:15:02.632702 ops/training.py:65 2019-01-17 03:15:02.632606: step 8917, loss = 0.69689 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:15:03.920055 ops/training.py:65 2019-01-17 03:15:03.919949: step 8918, loss = 0.65371 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:15:05.206655 ops/training.py:65 2019-01-17 03:15:05.206560: step 8919, loss = 0.66199 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:15:06.496265 ops/training.py:65 2019-01-17 03:15:06.496167: step 8920, loss = 0.68190 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:15:07.785260 ops/training.py:65 2019-01-17 03:15:07.785187: step 8921, loss = 0.61608 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:15:09.071562 ops/training.py:65 2019-01-17 03:15:09.071495: step 8922, loss = 0.71365 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:15:10.360069 ops/training.py:65 2019-01-17 03:15:10.359997: step 8923, loss = 0.75136 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 03:15:11.648042 ops/training.py:65 2019-01-17 03:15:11.647973: step 8924, loss = 0.67354 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:15:12.936894 ops/training.py:65 2019-01-17 03:15:12.936809: step 8925, loss = 0.65853 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:15:14.224772 ops/training.py:65 2019-01-17 03:15:14.224678: step 8926, loss = 0.64901 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:15:15.512798 ops/training.py:65 2019-01-17 03:15:15.512726: step 8927, loss = 0.69140 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:15:16.800863 ops/training.py:65 2019-01-17 03:15:16.800771: step 8928, loss = 0.71068 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:15:18.089860 ops/training.py:65 2019-01-17 03:15:18.089787: step 8929, loss = 0.65042 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:15:19.378957 ops/training.py:65 2019-01-17 03:15:19.378893: step 8930, loss = 0.67994 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:15:20.666579 ops/training.py:65 2019-01-17 03:15:20.666509: step 8931, loss = 0.61410 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:15:21.953967 ops/training.py:65 2019-01-17 03:15:21.953894: step 8932, loss = 0.69652 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:15:23.236966 ops/training.py:65 2019-01-17 03:15:23.236887: step 8933, loss = 0.71419 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:15:24.523128 ops/training.py:65 2019-01-17 03:15:24.523029: step 8934, loss = 0.69586 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:15:25.806285 ops/training.py:65 2019-01-17 03:15:25.806177: step 8935, loss = 0.62581 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:15:27.098165 ops/training.py:65 2019-01-17 03:15:27.098054: step 8936, loss = 0.66508 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:15:28.389196 ops/training.py:65 2019-01-17 03:15:28.389099: step 8937, loss = 0.72541 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:15:29.673958 ops/training.py:65 2019-01-17 03:15:29.673889: step 8938, loss = 0.62045 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:15:30.952263 ops/training.py:65 2019-01-17 03:15:30.952163: step 8939, loss = 0.65263 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:15:32.236208 ops/training.py:65 2019-01-17 03:15:32.236103: step 8940, loss = 0.64123 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:15:33.525475 ops/training.py:65 2019-01-17 03:15:33.525382: step 8941, loss = 0.63473 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:15:34.807923 ops/training.py:65 2019-01-17 03:15:34.807816: step 8942, loss = 0.66415 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:15:36.099505 ops/training.py:65 2019-01-17 03:15:36.099405: step 8943, loss = 0.58558 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 03:15:37.389995 ops/training.py:65 2019-01-17 03:15:37.389899: step 8944, loss = 0.63957 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:15:38.679957 ops/training.py:65 2019-01-17 03:15:38.679894: step 8945, loss = 0.66626 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:15:39.967948 ops/training.py:65 2019-01-17 03:15:39.967873: step 8946, loss = 0.69775 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:15:41.256868 ops/training.py:65 2019-01-17 03:15:41.256781: step 8947, loss = 0.66189 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:15:42.546910 ops/training.py:65 2019-01-17 03:15:42.546816: step 8948, loss = 0.66385 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:15:43.831231 ops/training.py:65 2019-01-17 03:15:43.831156: step 8949, loss = 0.65847 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:15:45.117757 ops/training.py:65 2019-01-17 03:15:45.117691: step 8950, loss = 0.72061 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:15:46.406058 ops/training.py:65 2019-01-17 03:15:46.405976: step 8951, loss = 0.71570 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:15:47.691369 ops/training.py:65 2019-01-17 03:15:47.691302: step 8952, loss = 0.67685 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:15:48.975990 ops/training.py:65 2019-01-17 03:15:48.975885: step 8953, loss = 0.64409 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:15:50.267266 ops/training.py:65 2019-01-17 03:15:50.267163: step 8954, loss = 0.66212 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:15:51.554014 ops/training.py:65 2019-01-17 03:15:51.553950: step 8955, loss = 0.65958 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:15:52.834360 ops/training.py:65 2019-01-17 03:15:52.834294: step 8956, loss = 0.67413 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:15:54.119017 ops/training.py:65 2019-01-17 03:15:54.118926: step 8957, loss = 0.72853 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:15:55.404302 ops/training.py:65 2019-01-17 03:15:55.404197: step 8958, loss = 0.67221 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:15:56.693505 ops/training.py:65 2019-01-17 03:15:56.693400: step 8959, loss = 0.74129 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:15:57.983285 ops/training.py:65 2019-01-17 03:15:57.983188: step 8960, loss = 0.65694 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:15:59.274920 ops/training.py:65 2019-01-17 03:15:59.274855: step 8961, loss = 0.66801 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:16:00.563835 ops/training.py:65 2019-01-17 03:16:00.563765: step 8962, loss = 0.64977 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:16:01.851917 ops/training.py:65 2019-01-17 03:16:01.851852: step 8963, loss = 0.66364 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:16:03.134800 ops/training.py:65 2019-01-17 03:16:03.134735: step 8964, loss = 0.63161 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:16:04.417137 ops/training.py:65 2019-01-17 03:16:04.417039: step 8965, loss = 0.64223 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:16:05.703458 ops/training.py:65 2019-01-17 03:16:05.703356: step 8966, loss = 0.66824 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:16:06.983701 ops/training.py:65 2019-01-17 03:16:06.983601: step 8967, loss = 0.66192 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:16:08.267605 ops/training.py:65 2019-01-17 03:16:08.267504: step 8968, loss = 0.70529 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:16:09.554152 ops/training.py:65 2019-01-17 03:16:09.554051: step 8969, loss = 0.66223 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:16:10.844462 ops/training.py:65 2019-01-17 03:16:10.844363: step 8970, loss = 0.67703 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:16:12.125391 ops/training.py:65 2019-01-17 03:16:12.125323: step 8971, loss = 0.62874 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:16:13.406894 ops/training.py:65 2019-01-17 03:16:13.406797: step 8972, loss = 0.69835 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:16:14.694875 ops/training.py:65 2019-01-17 03:16:14.694768: step 8973, loss = 0.68569 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:16:15.976075 ops/training.py:65 2019-01-17 03:16:15.975971: step 8974, loss = 0.66930 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:16:17.260905 ops/training.py:65 2019-01-17 03:16:17.260799: step 8975, loss = 0.62831 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:16:18.544219 ops/training.py:65 2019-01-17 03:16:18.544129: step 8976, loss = 0.71627 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:16:19.825130 ops/training.py:65 2019-01-17 03:16:19.825033: step 8977, loss = 0.73566 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 03:16:21.114824 ops/training.py:65 2019-01-17 03:16:21.114726: step 8978, loss = 0.65962 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:16:22.399451 ops/training.py:65 2019-01-17 03:16:22.399388: step 8979, loss = 0.66049 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:16:23.682591 ops/training.py:65 2019-01-17 03:16:23.682491: step 8980, loss = 0.66242 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:16:24.970087 ops/training.py:65 2019-01-17 03:16:24.969984: step 8981, loss = 0.61863 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:16:26.255724 ops/training.py:65 2019-01-17 03:16:26.255621: step 8982, loss = 0.68153 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:16:27.538310 ops/training.py:65 2019-01-17 03:16:27.538209: step 8983, loss = 0.66939 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:16:28.830359 ops/training.py:65 2019-01-17 03:16:28.830261: step 8984, loss = 0.62110 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:16:30.121258 ops/training.py:65 2019-01-17 03:16:30.121185: step 8985, loss = 0.63151 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:16:31.405347 ops/training.py:65 2019-01-17 03:16:31.405277: step 8986, loss = 0.68802 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:16:32.689266 ops/training.py:65 2019-01-17 03:16:32.689183: step 8987, loss = 0.63848 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:16:33.975578 ops/training.py:65 2019-01-17 03:16:33.975491: step 8988, loss = 0.68480 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:16:35.262939 ops/training.py:65 2019-01-17 03:16:35.262827: step 8989, loss = 0.66339 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:16:36.547740 ops/training.py:65 2019-01-17 03:16:36.547632: step 8990, loss = 0.77895 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 03:16:37.839269 ops/training.py:65 2019-01-17 03:16:37.839173: step 8991, loss = 0.67150 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:16:39.122590 ops/training.py:65 2019-01-17 03:16:39.122516: step 8992, loss = 0.67486 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:16:40.407337 ops/training.py:65 2019-01-17 03:16:40.407236: step 8993, loss = 0.65619 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:16:41.693632 ops/training.py:65 2019-01-17 03:16:41.693534: step 8994, loss = 0.64173 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:16:42.974883 ops/training.py:65 2019-01-17 03:16:42.974788: step 8995, loss = 0.70618 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:16:44.263029 ops/training.py:65 2019-01-17 03:16:44.262925: step 8996, loss = 0.70853 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:16:45.543881 ops/training.py:65 2019-01-17 03:16:45.543771: step 8997, loss = 0.70316 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:16:46.836101 ops/training.py:65 2019-01-17 03:16:46.836005: step 8998, loss = 0.66619 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:16:48.126542 ops/training.py:65 2019-01-17 03:16:48.126478: step 8999, loss = 0.67011 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:16:49.416123 ops/training.py:65 2019-01-17 03:16:49.416051: step 9000, loss = 0.65365 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:16:50.700395 ops/training.py:65 2019-01-17 03:16:50.700329: step 9001, loss = 0.66848 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:16:51.980995 ops/training.py:65 2019-01-17 03:16:51.980890: step 9002, loss = 0.64625 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:16:53.273008 ops/training.py:65 2019-01-17 03:16:53.272913: step 9003, loss = 0.65697 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:16:54.557911 ops/training.py:65 2019-01-17 03:16:54.557850: step 9004, loss = 0.64024 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:16:55.841448 ops/training.py:65 2019-01-17 03:16:55.841340: step 9005, loss = 0.67682 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:16:57.128042 ops/training.py:65 2019-01-17 03:16:57.127943: step 9006, loss = 0.71033 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:16:58.409636 ops/training.py:65 2019-01-17 03:16:58.409529: step 9007, loss = 0.70591 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:16:59.694728 ops/training.py:65 2019-01-17 03:16:59.694625: step 9008, loss = 0.73780 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:17:00.979916 ops/training.py:65 2019-01-17 03:17:00.979811: step 9009, loss = 0.66503 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:17:02.262449 ops/training.py:65 2019-01-17 03:17:02.262303: step 9010, loss = 0.77833 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:17:03.550189 ops/training.py:65 2019-01-17 03:17:03.550104: step 9011, loss = 0.62861 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:17:04.834039 ops/training.py:65 2019-01-17 03:17:04.833940: step 9012, loss = 0.69466 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:17:06.125396 ops/training.py:65 2019-01-17 03:17:06.125248: step 9013, loss = 0.61616 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:17:07.414772 ops/training.py:65 2019-01-17 03:17:07.414705: step 9014, loss = 0.65681 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:17:08.704990 ops/training.py:65 2019-01-17 03:17:08.704923: step 9015, loss = 0.75075 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:17:09.989428 ops/training.py:65 2019-01-17 03:17:09.989364: step 9016, loss = 0.65680 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:17:11.277091 ops/training.py:65 2019-01-17 03:17:11.276984: step 9017, loss = 0.64829 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:17:12.566977 ops/training.py:65 2019-01-17 03:17:12.566911: step 9018, loss = 0.64371 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:17:13.855797 ops/training.py:65 2019-01-17 03:17:13.855715: step 9019, loss = 0.67735 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:17:15.138646 ops/training.py:65 2019-01-17 03:17:15.138586: step 9020, loss = 0.72653 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:17:16.425827 ops/training.py:65 2019-01-17 03:17:16.425743: step 9021, loss = 0.71403 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:17:17.717584 ops/training.py:65 2019-01-17 03:17:17.717458: step 9022, loss = 0.67228 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:17:19.007247 ops/training.py:65 2019-01-17 03:17:19.007174: step 9023, loss = 0.71986 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:17:20.295756 ops/training.py:65 2019-01-17 03:17:20.295689: step 9024, loss = 0.66389 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:17:21.578798 ops/training.py:65 2019-01-17 03:17:21.578734: step 9025, loss = 0.64560 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:17:22.867606 ops/training.py:65 2019-01-17 03:17:22.867540: step 9026, loss = 0.78182 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:17:24.150678 ops/training.py:65 2019-01-17 03:17:24.150614: step 9027, loss = 0.69489 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:17:25.434811 ops/training.py:65 2019-01-17 03:17:25.434713: step 9028, loss = 0.68360 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:17:26.725644 ops/training.py:65 2019-01-17 03:17:26.725538: step 9029, loss = 0.67878 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:17:28.016029 ops/training.py:65 2019-01-17 03:17:28.015963: step 9030, loss = 0.63787 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:17:29.304912 ops/training.py:65 2019-01-17 03:17:29.304821: step 9031, loss = 0.67677 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:17:30.594177 ops/training.py:65 2019-01-17 03:17:30.594110: step 9032, loss = 0.63345 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:17:31.882160 ops/training.py:65 2019-01-17 03:17:31.882082: step 9033, loss = 0.65674 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:17:33.170164 ops/training.py:65 2019-01-17 03:17:33.170094: step 9034, loss = 0.61047 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:17:34.454769 ops/training.py:65 2019-01-17 03:17:34.454669: step 9035, loss = 0.69105 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:17:35.741429 ops/training.py:65 2019-01-17 03:17:35.741328: step 9036, loss = 0.73509 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:17:37.021706 ops/training.py:65 2019-01-17 03:17:37.021607: step 9037, loss = 0.66931 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:17:38.307243 ops/training.py:65 2019-01-17 03:17:38.307140: step 9038, loss = 0.66965 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:17:39.592191 ops/training.py:65 2019-01-17 03:17:39.592085: step 9039, loss = 0.69499 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:17:40.883484 ops/training.py:65 2019-01-17 03:17:40.883379: step 9040, loss = 0.64882 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:17:42.168535 ops/training.py:65 2019-01-17 03:17:42.168471: step 9041, loss = 0.75586 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:17:43.456660 ops/training.py:65 2019-01-17 03:17:43.456583: step 9042, loss = 0.66765 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:17:44.740625 ops/training.py:65 2019-01-17 03:17:44.740565: step 9043, loss = 0.70560 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:17:46.022339 ops/training.py:65 2019-01-17 03:17:46.022245: step 9044, loss = 0.64640 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:17:47.308430 ops/training.py:65 2019-01-17 03:17:47.308322: step 9045, loss = 0.69757 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:17:48.590585 ops/training.py:65 2019-01-17 03:17:48.590487: step 9046, loss = 0.65437 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:17:49.876086 ops/training.py:65 2019-01-17 03:17:49.875980: step 9047, loss = 0.61799 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:17:51.167997 ops/training.py:65 2019-01-17 03:17:51.167896: step 9048, loss = 0.67025 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:17:52.459460 ops/training.py:65 2019-01-17 03:17:52.459385: step 9049, loss = 0.70040 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:17:53.743336 ops/training.py:65 2019-01-17 03:17:53.743274: step 9050, loss = 0.62270 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:17:55.030997 ops/training.py:65 2019-01-17 03:17:55.030843: step 9051, loss = 0.66124 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:17:56.315681 ops/training.py:65 2019-01-17 03:17:56.315614: step 9052, loss = 0.71494 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:17:57.605774 ops/training.py:65 2019-01-17 03:17:57.605697: step 9053, loss = 0.68369 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:17:58.893977 ops/training.py:65 2019-01-17 03:17:58.893870: step 9054, loss = 0.68099 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:18:00.177182 ops/training.py:65 2019-01-17 03:18:00.177082: step 9055, loss = 0.59021 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:18:01.461125 ops/training.py:65 2019-01-17 03:18:01.461034: step 9056, loss = 0.68355 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:18:02.743457 ops/training.py:65 2019-01-17 03:18:02.743363: step 9057, loss = 0.71507 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:18:04.034853 ops/training.py:65 2019-01-17 03:18:04.034748: step 9058, loss = 0.63163 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:18:05.320787 ops/training.py:65 2019-01-17 03:18:05.320720: step 9059, loss = 0.71422 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:18:06.604123 ops/training.py:65 2019-01-17 03:18:06.604014: step 9060, loss = 0.69276 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:18:07.894117 ops/training.py:65 2019-01-17 03:18:07.894048: step 9061, loss = 0.64036 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:18:09.182348 ops/training.py:65 2019-01-17 03:18:09.182287: step 9062, loss = 0.66159 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:18:10.465789 ops/training.py:65 2019-01-17 03:18:10.465675: step 9063, loss = 0.64460 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:18:11.758949 ops/training.py:65 2019-01-17 03:18:11.758843: step 9064, loss = 0.70365 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:18:13.045333 ops/training.py:65 2019-01-17 03:18:13.045258: step 9065, loss = 0.66553 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:18:14.332251 ops/training.py:65 2019-01-17 03:18:14.332093: step 9066, loss = 0.62561 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:18:15.618680 ops/training.py:65 2019-01-17 03:18:15.618569: step 9067, loss = 0.65812 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:18:16.910944 ops/training.py:65 2019-01-17 03:18:16.910791: step 9068, loss = 0.63970 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:18:18.203634 ops/training.py:65 2019-01-17 03:18:18.203532: step 9069, loss = 0.75342 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:18:19.493472 ops/training.py:65 2019-01-17 03:18:19.493384: step 9070, loss = 0.66593 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:18:20.779521 ops/training.py:65 2019-01-17 03:18:20.779453: step 9071, loss = 0.70560 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:18:22.067703 ops/training.py:65 2019-01-17 03:18:22.067633: step 9072, loss = 0.64047 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:18:23.358132 ops/training.py:65 2019-01-17 03:18:23.358056: step 9073, loss = 0.61897 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:18:24.641832 ops/training.py:65 2019-01-17 03:18:24.641766: step 9074, loss = 0.62637 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:18:25.923756 ops/training.py:65 2019-01-17 03:18:25.923647: step 9075, loss = 0.67710 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:18:27.206744 ops/training.py:65 2019-01-17 03:18:27.206635: step 9076, loss = 0.65407 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:18:28.494156 ops/training.py:65 2019-01-17 03:18:28.494046: step 9077, loss = 0.71955 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:18:29.785719 ops/training.py:65 2019-01-17 03:18:29.785610: step 9078, loss = 0.63704 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:18:31.076209 ops/training.py:65 2019-01-17 03:18:31.076138: step 9079, loss = 0.74915 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:18:32.364006 ops/training.py:65 2019-01-17 03:18:32.363925: step 9080, loss = 0.74837 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:18:33.649016 ops/training.py:65 2019-01-17 03:18:33.648950: step 9081, loss = 0.72391 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:18:34.937146 ops/training.py:65 2019-01-17 03:18:34.937081: step 9082, loss = 0.71318 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:18:36.220421 ops/training.py:65 2019-01-17 03:18:36.220360: step 9083, loss = 0.76147 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:18:37.508404 ops/training.py:65 2019-01-17 03:18:37.508340: step 9084, loss = 0.66337 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:18:38.791268 ops/training.py:65 2019-01-17 03:18:38.791202: step 9085, loss = 0.69975 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:18:40.077022 ops/training.py:65 2019-01-17 03:18:40.076911: step 9086, loss = 0.74035 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:18:41.364176 ops/training.py:65 2019-01-17 03:18:41.364070: step 9087, loss = 0.71398 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:18:42.652150 ops/training.py:65 2019-01-17 03:18:42.652022: step 9088, loss = 0.69970 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:18:43.936984 ops/training.py:65 2019-01-17 03:18:43.936887: step 9089, loss = 0.66728 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:18:45.225439 ops/training.py:65 2019-01-17 03:18:45.225333: step 9090, loss = 0.69820 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:18:46.509456 ops/training.py:65 2019-01-17 03:18:46.509311: step 9091, loss = 0.67979 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:18:47.798333 ops/training.py:65 2019-01-17 03:18:47.798236: step 9092, loss = 0.69420 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:18:49.085329 ops/training.py:65 2019-01-17 03:18:49.085230: step 9093, loss = 0.67121 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:18:50.369476 ops/training.py:65 2019-01-17 03:18:50.369370: step 9094, loss = 0.69545 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:18:51.659384 ops/training.py:65 2019-01-17 03:18:51.659277: step 9095, loss = 0.68250 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:18:52.951744 ops/training.py:65 2019-01-17 03:18:52.951646: step 9096, loss = 0.70222 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:18:54.234974 ops/training.py:65 2019-01-17 03:18:54.234877: step 9097, loss = 0.66813 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:18:55.527743 ops/training.py:65 2019-01-17 03:18:55.527636: step 9098, loss = 0.68404 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:18:56.816692 ops/training.py:65 2019-01-17 03:18:56.816629: step 9099, loss = 0.63169 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:18:58.105021 ops/training.py:65 2019-01-17 03:18:58.104955: step 9100, loss = 0.63475 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:18:59.393511 ops/training.py:65 2019-01-17 03:18:59.393439: step 9101, loss = 0.67460 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:19:00.677177 ops/training.py:65 2019-01-17 03:19:00.677113: step 9102, loss = 0.63565 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:19:01.960327 ops/training.py:65 2019-01-17 03:19:01.960248: step 9103, loss = 0.70784 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:19:03.252686 ops/training.py:65 2019-01-17 03:19:03.252593: step 9104, loss = 0.65968 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:19:04.545449 ops/training.py:65 2019-01-17 03:19:04.545371: step 9105, loss = 0.66756 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:19:05.828602 ops/training.py:65 2019-01-17 03:19:05.828529: step 9106, loss = 0.61062 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:19:07.117718 ops/training.py:65 2019-01-17 03:19:07.117614: step 9107, loss = 0.71818 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:19:08.406691 ops/training.py:65 2019-01-17 03:19:08.406616: step 9108, loss = 0.72887 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:19:09.695701 ops/training.py:65 2019-01-17 03:19:09.695623: step 9109, loss = 0.71132 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:19:10.985193 ops/training.py:65 2019-01-17 03:19:10.985117: step 9110, loss = 0.64972 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:19:12.269987 ops/training.py:65 2019-01-17 03:19:12.269908: step 9111, loss = 0.65045 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:19:13.549825 ops/training.py:65 2019-01-17 03:19:13.549742: step 9112, loss = 0.71097 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:19:14.840688 ops/training.py:65 2019-01-17 03:19:14.840590: step 9113, loss = 0.65153 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:19:16.123607 ops/training.py:65 2019-01-17 03:19:16.123528: step 9114, loss = 0.64772 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:19:17.406667 ops/training.py:65 2019-01-17 03:19:17.406564: step 9115, loss = 0.70130 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:19:18.690838 ops/training.py:65 2019-01-17 03:19:18.690749: step 9116, loss = 0.68007 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:19:19.982258 ops/training.py:65 2019-01-17 03:19:19.982157: step 9117, loss = 0.71578 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:19:21.270809 ops/training.py:65 2019-01-17 03:19:21.270703: step 9118, loss = 0.67132 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:19:22.559565 ops/training.py:65 2019-01-17 03:19:22.559477: step 9119, loss = 0.65552 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:19:23.848523 ops/training.py:65 2019-01-17 03:19:23.848449: step 9120, loss = 0.73418 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:19:25.136975 ops/training.py:65 2019-01-17 03:19:25.136896: step 9121, loss = 0.68249 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:19:26.420869 ops/training.py:65 2019-01-17 03:19:26.420797: step 9122, loss = 0.70057 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:19:27.709416 ops/training.py:65 2019-01-17 03:19:27.709305: step 9123, loss = 0.71446 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:19:28.998174 ops/training.py:65 2019-01-17 03:19:28.998093: step 9124, loss = 0.69537 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:19:30.287397 ops/training.py:65 2019-01-17 03:19:30.287321: step 9125, loss = 0.68381 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:19:31.576110 ops/training.py:65 2019-01-17 03:19:31.576015: step 9126, loss = 0.65333 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:19:32.865536 ops/training.py:65 2019-01-17 03:19:32.865457: step 9127, loss = 0.67958 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:19:34.154768 ops/training.py:65 2019-01-17 03:19:34.154674: step 9128, loss = 0.71287 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:19:35.439024 ops/training.py:65 2019-01-17 03:19:35.438952: step 9129, loss = 0.64240 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:19:36.721830 ops/training.py:65 2019-01-17 03:19:36.721766: step 9130, loss = 0.65955 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:19:38.020846 ops/training.py:65 2019-01-17 03:19:38.020690: step 9131, loss = 0.74731 (24.7 examples/sec; 1.298 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:19:39.308263 ops/training.py:65 2019-01-17 03:19:39.308193: step 9132, loss = 0.64074 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:19:40.596744 ops/training.py:65 2019-01-17 03:19:40.596640: step 9133, loss = 0.68132 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:19:41.886678 ops/training.py:65 2019-01-17 03:19:41.886596: step 9134, loss = 0.57179 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 03:19:43.175077 ops/training.py:65 2019-01-17 03:19:43.175004: step 9135, loss = 0.67818 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:19:44.463999 ops/training.py:65 2019-01-17 03:19:44.463913: step 9136, loss = 0.66786 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:19:45.753331 ops/training.py:65 2019-01-17 03:19:45.753260: step 9137, loss = 0.68370 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:19:47.037373 ops/training.py:65 2019-01-17 03:19:47.037308: step 9138, loss = 0.74070 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:19:48.325591 ops/training.py:65 2019-01-17 03:19:48.325527: step 9139, loss = 0.60178 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:19:49.612484 ops/training.py:65 2019-01-17 03:19:49.612400: step 9140, loss = 0.69508 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:19:50.896913 ops/training.py:65 2019-01-17 03:19:50.896844: step 9141, loss = 0.65224 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:19:52.179915 ops/training.py:65 2019-01-17 03:19:52.179810: step 9142, loss = 0.73040 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:19:53.468914 ops/training.py:65 2019-01-17 03:19:53.468813: step 9143, loss = 0.64867 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:19:54.760801 ops/training.py:65 2019-01-17 03:19:54.760708: step 9144, loss = 0.65813 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:19:56.047159 ops/training.py:65 2019-01-17 03:19:56.047084: step 9145, loss = 0.76563 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:19:57.339844 ops/training.py:65 2019-01-17 03:19:57.339739: step 9146, loss = 0.70462 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:19:58.630193 ops/training.py:65 2019-01-17 03:19:58.630126: step 9147, loss = 0.71853 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:19:59.919900 ops/training.py:65 2019-01-17 03:19:59.919837: step 9148, loss = 0.67463 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:20:01.207940 ops/training.py:65 2019-01-17 03:20:01.207877: step 9149, loss = 0.66455 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:20:02.493355 ops/training.py:65 2019-01-17 03:20:02.493295: step 9150, loss = 0.62570 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:20:03.777389 ops/training.py:65 2019-01-17 03:20:03.777299: step 9151, loss = 0.71201 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:20:05.069041 ops/training.py:65 2019-01-17 03:20:05.068934: step 9152, loss = 0.65274 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:20:06.355309 ops/training.py:65 2019-01-17 03:20:06.355245: step 9153, loss = 0.71823 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:20:07.638879 ops/training.py:65 2019-01-17 03:20:07.638784: step 9154, loss = 0.71105 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:20:08.923716 ops/training.py:65 2019-01-17 03:20:08.923619: step 9155, loss = 0.74032 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:20:10.211820 ops/training.py:65 2019-01-17 03:20:10.211722: step 9156, loss = 0.61599 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:20:11.494447 ops/training.py:65 2019-01-17 03:20:11.494351: step 9157, loss = 0.69353 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:20:12.787378 ops/training.py:65 2019-01-17 03:20:12.787269: step 9158, loss = 0.73044 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:20:14.074743 ops/training.py:65 2019-01-17 03:20:14.074643: step 9159, loss = 0.72951 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:20:15.360536 ops/training.py:65 2019-01-17 03:20:15.360471: step 9160, loss = 0.63658 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:20:16.648821 ops/training.py:65 2019-01-17 03:20:16.648751: step 9161, loss = 0.68672 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:20:17.934404 ops/training.py:65 2019-01-17 03:20:17.934341: step 9162, loss = 0.64943 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:20:19.223682 ops/training.py:65 2019-01-17 03:20:19.223619: step 9163, loss = 0.66380 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:20:20.511573 ops/training.py:65 2019-01-17 03:20:20.511490: step 9164, loss = 0.66587 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:20:21.799743 ops/training.py:65 2019-01-17 03:20:21.799677: step 9165, loss = 0.66733 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:20:23.089371 ops/training.py:65 2019-01-17 03:20:23.089294: step 9166, loss = 0.69817 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:20:24.377552 ops/training.py:65 2019-01-17 03:20:24.377462: step 9167, loss = 0.71401 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:20:25.664912 ops/training.py:65 2019-01-17 03:20:25.664841: step 9168, loss = 0.64455 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:20:26.947008 ops/training.py:65 2019-01-17 03:20:26.946939: step 9169, loss = 0.63207 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:20:28.231263 ops/training.py:65 2019-01-17 03:20:28.231197: step 9170, loss = 0.60326 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:20:29.519829 ops/training.py:65 2019-01-17 03:20:29.519724: step 9171, loss = 0.67477 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:20:30.808205 ops/training.py:65 2019-01-17 03:20:30.808118: step 9172, loss = 0.73709 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:20:32.096985 ops/training.py:65 2019-01-17 03:20:32.096917: step 9173, loss = 0.62920 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:20:33.381287 ops/training.py:65 2019-01-17 03:20:33.381220: step 9174, loss = 0.67088 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:20:34.667620 ops/training.py:65 2019-01-17 03:20:34.667509: step 9175, loss = 0.65078 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:20:35.951836 ops/training.py:65 2019-01-17 03:20:35.951701: step 9176, loss = 0.72472 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:20:37.237459 ops/training.py:65 2019-01-17 03:20:37.237358: step 9177, loss = 0.65011 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:20:38.528424 ops/training.py:65 2019-01-17 03:20:38.528322: step 9178, loss = 0.70347 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:20:39.815171 ops/training.py:65 2019-01-17 03:20:39.815060: step 9179, loss = 0.70592 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:20:41.102144 ops/training.py:65 2019-01-17 03:20:41.102045: step 9180, loss = 0.58731 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:20:42.391011 ops/training.py:65 2019-01-17 03:20:42.390915: step 9181, loss = 0.67415 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:20:43.680684 ops/training.py:65 2019-01-17 03:20:43.680610: step 9182, loss = 0.65098 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:20:44.964297 ops/training.py:65 2019-01-17 03:20:44.964228: step 9183, loss = 0.66989 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:20:46.252000 ops/training.py:65 2019-01-17 03:20:46.251895: step 9184, loss = 0.65163 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:20:47.538521 ops/training.py:65 2019-01-17 03:20:47.538413: step 9185, loss = 0.77778 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:20:48.830653 ops/training.py:65 2019-01-17 03:20:48.830559: step 9186, loss = 0.72648 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:20:50.121657 ops/training.py:65 2019-01-17 03:20:50.121594: step 9187, loss = 0.72113 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:20:51.406992 ops/training.py:65 2019-01-17 03:20:51.406921: step 9188, loss = 0.66315 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:20:52.690831 ops/training.py:65 2019-01-17 03:20:52.690721: step 9189, loss = 0.66545 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:20:53.979633 ops/training.py:65 2019-01-17 03:20:53.979532: step 9190, loss = 0.68791 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:20:55.270957 ops/training.py:65 2019-01-17 03:20:55.270851: step 9191, loss = 0.71694 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:20:56.561482 ops/training.py:65 2019-01-17 03:20:56.561404: step 9192, loss = 0.65055 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:20:57.851357 ops/training.py:65 2019-01-17 03:20:57.851272: step 9193, loss = 0.65288 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:20:59.141044 ops/training.py:65 2019-01-17 03:20:59.140977: step 9194, loss = 0.69538 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:21:00.430415 ops/training.py:65 2019-01-17 03:21:00.430325: step 9195, loss = 0.72618 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:21:01.717651 ops/training.py:65 2019-01-17 03:21:01.717585: step 9196, loss = 0.65523 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:21:03.006818 ops/training.py:65 2019-01-17 03:21:03.006745: step 9197, loss = 0.67176 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:21:04.295870 ops/training.py:65 2019-01-17 03:21:04.295797: step 9198, loss = 0.70598 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:21:05.584732 ops/training.py:65 2019-01-17 03:21:05.584647: step 9199, loss = 0.67061 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:21:06.875094 ops/training.py:65 2019-01-17 03:21:06.874935: step 9200, loss = 0.70266 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:21:08.167680 ops/training.py:65 2019-01-17 03:21:08.167581: step 9201, loss = 0.68885 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:21:09.457137 ops/training.py:65 2019-01-17 03:21:09.457067: step 9202, loss = 0.66914 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:21:10.745014 ops/training.py:65 2019-01-17 03:21:10.744949: step 9203, loss = 0.73987 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:21:12.028820 ops/training.py:65 2019-01-17 03:21:12.028753: step 9204, loss = 0.65198 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:21:13.313361 ops/training.py:65 2019-01-17 03:21:13.313260: step 9205, loss = 0.64382 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:21:14.606865 ops/training.py:65 2019-01-17 03:21:14.606705: step 9206, loss = 0.71348 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:21:15.898325 ops/training.py:65 2019-01-17 03:21:15.898257: step 9207, loss = 0.69857 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:21:17.183504 ops/training.py:65 2019-01-17 03:21:17.183437: step 9208, loss = 0.69097 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:21:18.473587 ops/training.py:65 2019-01-17 03:21:18.473521: step 9209, loss = 0.71556 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:21:19.762262 ops/training.py:65 2019-01-17 03:21:19.762193: step 9210, loss = 0.66051 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:21:21.051625 ops/training.py:65 2019-01-17 03:21:21.051535: step 9211, loss = 0.68649 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:21:22.341893 ops/training.py:65 2019-01-17 03:21:22.341809: step 9212, loss = 0.71147 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:21:23.631164 ops/training.py:65 2019-01-17 03:21:23.631095: step 9213, loss = 0.68154 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:21:24.920085 ops/training.py:65 2019-01-17 03:21:24.919980: step 9214, loss = 0.64403 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:21:26.210599 ops/training.py:65 2019-01-17 03:21:26.210527: step 9215, loss = 0.67237 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:21:27.498976 ops/training.py:65 2019-01-17 03:21:27.498910: step 9216, loss = 0.69594 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:21:28.786912 ops/training.py:65 2019-01-17 03:21:28.786842: step 9217, loss = 0.68580 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:21:30.075626 ops/training.py:65 2019-01-17 03:21:30.075553: step 9218, loss = 0.71301 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:21:31.360564 ops/training.py:65 2019-01-17 03:21:31.360485: step 9219, loss = 0.64781 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:21:32.640051 ops/training.py:65 2019-01-17 03:21:32.639930: step 9220, loss = 0.66300 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:21:33.931110 ops/training.py:65 2019-01-17 03:21:33.931010: step 9221, loss = 0.73621 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:21:35.215876 ops/training.py:65 2019-01-17 03:21:35.215800: step 9222, loss = 0.55254 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 03:21:36.508403 ops/training.py:65 2019-01-17 03:21:36.508299: step 9223, loss = 0.68073 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:21:37.794036 ops/training.py:65 2019-01-17 03:21:37.793966: step 9224, loss = 0.71456 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:21:39.081956 ops/training.py:65 2019-01-17 03:21:39.081875: step 9225, loss = 0.69252 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:21:40.365931 ops/training.py:65 2019-01-17 03:21:40.365872: step 9226, loss = 0.69050 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:21:41.653567 ops/training.py:65 2019-01-17 03:21:41.653505: step 9227, loss = 0.71083 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:21:42.943139 ops/training.py:65 2019-01-17 03:21:42.943077: step 9228, loss = 0.71767 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:21:44.227344 ops/training.py:65 2019-01-17 03:21:44.227276: step 9229, loss = 0.55777 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:21:45.510286 ops/training.py:65 2019-01-17 03:21:45.510134: step 9230, loss = 0.58410 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 03:21:46.803224 ops/training.py:65 2019-01-17 03:21:46.803119: step 9231, loss = 0.69433 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:21:48.090352 ops/training.py:65 2019-01-17 03:21:48.090292: step 9232, loss = 0.58490 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 03:21:49.370047 ops/training.py:65 2019-01-17 03:21:49.369967: step 9233, loss = 0.63497 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:21:50.654057 ops/training.py:65 2019-01-17 03:21:50.653953: step 9234, loss = 0.70402 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:21:51.938662 ops/training.py:65 2019-01-17 03:21:51.938558: step 9235, loss = 0.73756 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:21:53.223398 ops/training.py:65 2019-01-17 03:21:53.223255: step 9236, loss = 0.61107 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:21:54.511139 ops/training.py:65 2019-01-17 03:21:54.511039: step 9237, loss = 0.63089 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:21:55.802693 ops/training.py:65 2019-01-17 03:21:55.802549: step 9238, loss = 0.68405 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:21:57.089848 ops/training.py:65 2019-01-17 03:21:57.089778: step 9239, loss = 0.67854 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:21:58.374112 ops/training.py:65 2019-01-17 03:21:58.374047: step 9240, loss = 0.69653 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:21:59.658351 ops/training.py:65 2019-01-17 03:21:59.658240: step 9241, loss = 0.69214 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:22:00.949505 ops/training.py:65 2019-01-17 03:22:00.949405: step 9242, loss = 0.69951 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:22:02.239667 ops/training.py:65 2019-01-17 03:22:02.239602: step 9243, loss = 0.73859 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:22:03.523817 ops/training.py:65 2019-01-17 03:22:03.523745: step 9244, loss = 0.70740 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:22:04.812759 ops/training.py:65 2019-01-17 03:22:04.812649: step 9245, loss = 0.66812 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:22:06.102906 ops/training.py:65 2019-01-17 03:22:06.102836: step 9246, loss = 0.66391 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:22:07.387383 ops/training.py:65 2019-01-17 03:22:07.387311: step 9247, loss = 0.75081 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:22:08.671863 ops/training.py:65 2019-01-17 03:22:08.671711: step 9248, loss = 0.68038 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:22:09.962003 ops/training.py:65 2019-01-17 03:22:09.961915: step 9249, loss = 0.67909 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:22:11.250499 ops/training.py:65 2019-01-17 03:22:11.250412: step 9250, loss = 0.61689 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:22:12.537508 ops/training.py:65 2019-01-17 03:22:12.537395: step 9251, loss = 0.64164 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:22:13.826319 ops/training.py:65 2019-01-17 03:22:13.826240: step 9252, loss = 0.73789 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:22:15.106492 ops/training.py:65 2019-01-17 03:22:15.106409: step 9253, loss = 0.68409 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:22:16.392496 ops/training.py:65 2019-01-17 03:22:16.392422: step 9254, loss = 0.69562 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:22:17.677795 ops/training.py:65 2019-01-17 03:22:17.677695: step 9255, loss = 0.62569 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:22:18.969998 ops/training.py:65 2019-01-17 03:22:18.969906: step 9256, loss = 0.68727 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:22:20.256681 ops/training.py:65 2019-01-17 03:22:20.256604: step 9257, loss = 0.66779 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:22:21.540718 ops/training.py:65 2019-01-17 03:22:21.540569: step 9258, loss = 0.65456 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:22:22.827758 ops/training.py:65 2019-01-17 03:22:22.827648: step 9259, loss = 0.71446 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:22:24.117205 ops/training.py:65 2019-01-17 03:22:24.117074: step 9260, loss = 0.66861 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:22:25.406427 ops/training.py:65 2019-01-17 03:22:25.406361: step 9261, loss = 0.66330 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:22:26.689673 ops/training.py:65 2019-01-17 03:22:26.689605: step 9262, loss = 0.64974 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:22:27.977461 ops/training.py:65 2019-01-17 03:22:27.977366: step 9263, loss = 0.70108 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:22:29.265070 ops/training.py:65 2019-01-17 03:22:29.264997: step 9264, loss = 0.66563 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:22:30.549362 ops/training.py:65 2019-01-17 03:22:30.549284: step 9265, loss = 0.72161 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:22:31.832768 ops/training.py:65 2019-01-17 03:22:31.832664: step 9266, loss = 0.63729 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:22:33.130546 ops/training.py:65 2019-01-17 03:22:33.130415: step 9267, loss = 0.66636 (24.7 examples/sec; 1.296 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:22:34.417597 ops/training.py:65 2019-01-17 03:22:34.417529: step 9268, loss = 0.65538 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:22:35.700203 ops/training.py:65 2019-01-17 03:22:35.700105: step 9269, loss = 0.66515 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:22:36.985763 ops/training.py:65 2019-01-17 03:22:36.985661: step 9270, loss = 0.72906 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:22:38.274562 ops/training.py:65 2019-01-17 03:22:38.274409: step 9271, loss = 0.74168 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:22:39.561625 ops/training.py:65 2019-01-17 03:22:39.561526: step 9272, loss = 0.74338 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:22:40.848081 ops/training.py:65 2019-01-17 03:22:40.847984: step 9273, loss = 0.61340 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:22:42.137110 ops/training.py:65 2019-01-17 03:22:42.137024: step 9274, loss = 0.71969 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:22:43.425854 ops/training.py:65 2019-01-17 03:22:43.425785: step 9275, loss = 0.68652 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:22:44.709137 ops/training.py:65 2019-01-17 03:22:44.709075: step 9276, loss = 0.69093 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:22:45.994800 ops/training.py:65 2019-01-17 03:22:45.994693: step 9277, loss = 0.74621 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:22:47.281695 ops/training.py:65 2019-01-17 03:22:47.281580: step 9278, loss = 0.62494 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:22:48.568704 ops/training.py:65 2019-01-17 03:22:48.568615: step 9279, loss = 0.70043 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:22:49.847989 ops/training.py:65 2019-01-17 03:22:49.847882: step 9280, loss = 0.63417 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:22:51.130243 ops/training.py:65 2019-01-17 03:22:51.130145: step 9281, loss = 0.67148 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:22:52.418538 ops/training.py:65 2019-01-17 03:22:52.418429: step 9282, loss = 0.61153 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 03:22:53.709786 ops/training.py:65 2019-01-17 03:22:53.709637: step 9283, loss = 0.63676 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:22:55.001328 ops/training.py:65 2019-01-17 03:22:55.001248: step 9284, loss = 0.76590 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:22:56.286349 ops/training.py:65 2019-01-17 03:22:56.286283: step 9285, loss = 0.65074 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:22:57.569615 ops/training.py:65 2019-01-17 03:22:57.569509: step 9286, loss = 0.63344 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:22:58.861193 ops/training.py:65 2019-01-17 03:22:58.861085: step 9287, loss = 0.61254 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:23:00.147607 ops/training.py:65 2019-01-17 03:23:00.147542: step 9288, loss = 0.71404 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:23:01.428507 ops/training.py:65 2019-01-17 03:23:01.428369: step 9289, loss = 0.74016 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:23:02.719809 ops/training.py:65 2019-01-17 03:23:02.719705: step 9290, loss = 0.63170 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:23:04.007060 ops/training.py:65 2019-01-17 03:23:04.006955: step 9291, loss = 0.71320 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:23:05.297085 ops/training.py:65 2019-01-17 03:23:05.297001: step 9292, loss = 0.63430 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:23:06.587195 ops/training.py:65 2019-01-17 03:23:06.587118: step 9293, loss = 0.70958 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:23:07.872883 ops/training.py:65 2019-01-17 03:23:07.872811: step 9294, loss = 0.63830 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:23:09.161058 ops/training.py:65 2019-01-17 03:23:09.160969: step 9295, loss = 0.65530 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:23:10.449250 ops/training.py:65 2019-01-17 03:23:10.449177: step 9296, loss = 0.61158 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:23:11.739538 ops/training.py:65 2019-01-17 03:23:11.739462: step 9297, loss = 0.65889 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:23:13.027965 ops/training.py:65 2019-01-17 03:23:13.027893: step 9298, loss = 0.66595 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:23:14.314921 ops/training.py:65 2019-01-17 03:23:14.314855: step 9299, loss = 0.70601 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:23:15.602804 ops/training.py:65 2019-01-17 03:23:15.602739: step 9300, loss = 0.66945 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:23:16.891277 ops/training.py:65 2019-01-17 03:23:16.891187: step 9301, loss = 0.66688 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:23:18.174067 ops/training.py:65 2019-01-17 03:23:18.174000: step 9302, loss = 0.73550 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:23:19.463236 ops/training.py:65 2019-01-17 03:23:19.463134: step 9303, loss = 0.70868 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:23:20.752162 ops/training.py:65 2019-01-17 03:23:20.752100: step 9304, loss = 0.60729 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:23:22.040694 ops/training.py:65 2019-01-17 03:23:22.040602: step 9305, loss = 0.63835 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:23:23.326554 ops/training.py:65 2019-01-17 03:23:23.326479: step 9306, loss = 0.63915 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:23:24.615148 ops/training.py:65 2019-01-17 03:23:24.615077: step 9307, loss = 0.67218 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:23:25.903540 ops/training.py:65 2019-01-17 03:23:25.903469: step 9308, loss = 0.66050 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:23:27.192419 ops/training.py:65 2019-01-17 03:23:27.192359: step 9309, loss = 0.68770 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:23:28.481477 ops/training.py:65 2019-01-17 03:23:28.481403: step 9310, loss = 0.64860 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:23:29.769982 ops/training.py:65 2019-01-17 03:23:29.769914: step 9311, loss = 0.67851 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:23:31.058878 ops/training.py:65 2019-01-17 03:23:31.058811: step 9312, loss = 0.66245 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:23:32.347312 ops/training.py:65 2019-01-17 03:23:32.347242: step 9313, loss = 0.64813 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:23:33.635337 ops/training.py:65 2019-01-17 03:23:33.635239: step 9314, loss = 0.69231 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:23:34.923331 ops/training.py:65 2019-01-17 03:23:34.923243: step 9315, loss = 0.68208 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:23:36.207923 ops/training.py:65 2019-01-17 03:23:36.207850: step 9316, loss = 0.67143 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:23:37.493719 ops/training.py:65 2019-01-17 03:23:37.493613: step 9317, loss = 0.73219 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:23:38.780779 ops/training.py:65 2019-01-17 03:23:38.780715: step 9318, loss = 0.60177 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:23:40.064085 ops/training.py:65 2019-01-17 03:23:40.064015: step 9319, loss = 0.59174 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:23:41.356504 ops/training.py:65 2019-01-17 03:23:41.356395: step 9320, loss = 0.71350 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:23:42.648890 ops/training.py:65 2019-01-17 03:23:42.648824: step 9321, loss = 0.62368 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:23:43.937959 ops/training.py:65 2019-01-17 03:23:43.937894: step 9322, loss = 0.67608 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:23:45.226681 ops/training.py:65 2019-01-17 03:23:45.226615: step 9323, loss = 0.65979 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:23:46.514407 ops/training.py:65 2019-01-17 03:23:46.514344: step 9324, loss = 0.73558 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:23:47.801462 ops/training.py:65 2019-01-17 03:23:47.801382: step 9325, loss = 0.65629 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:23:49.088789 ops/training.py:65 2019-01-17 03:23:49.088687: step 9326, loss = 0.62826 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:23:50.378929 ops/training.py:65 2019-01-17 03:23:50.378814: step 9327, loss = 0.79717 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 03:23:51.666316 ops/training.py:65 2019-01-17 03:23:51.666203: step 9328, loss = 0.68512 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:23:52.954889 ops/training.py:65 2019-01-17 03:23:52.954795: step 9329, loss = 0.69399 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:23:54.245934 ops/training.py:65 2019-01-17 03:23:54.245869: step 9330, loss = 0.67967 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:23:55.534669 ops/training.py:65 2019-01-17 03:23:55.534578: step 9331, loss = 0.77561 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:23:56.823094 ops/training.py:65 2019-01-17 03:23:56.823023: step 9332, loss = 0.69622 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:23:58.108699 ops/training.py:65 2019-01-17 03:23:58.108642: step 9333, loss = 0.68224 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:23:59.393483 ops/training.py:65 2019-01-17 03:23:59.393402: step 9334, loss = 0.75031 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:24:00.682538 ops/training.py:65 2019-01-17 03:24:00.682432: step 9335, loss = 0.67929 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:24:01.972050 ops/training.py:65 2019-01-17 03:24:01.971977: step 9336, loss = 0.70535 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:24:03.256778 ops/training.py:65 2019-01-17 03:24:03.256705: step 9337, loss = 0.62143 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:24:04.546984 ops/training.py:65 2019-01-17 03:24:04.546907: step 9338, loss = 0.63167 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:24:05.835345 ops/training.py:65 2019-01-17 03:24:05.835276: step 9339, loss = 0.71409 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:24:07.124862 ops/training.py:65 2019-01-17 03:24:07.124767: step 9340, loss = 0.72292 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:24:08.410024 ops/training.py:65 2019-01-17 03:24:08.409956: step 9341, loss = 0.63975 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:24:09.699617 ops/training.py:65 2019-01-17 03:24:09.699525: step 9342, loss = 0.74903 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:24:10.988591 ops/training.py:65 2019-01-17 03:24:10.988519: step 9343, loss = 0.63383 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:24:12.272921 ops/training.py:65 2019-01-17 03:24:12.272852: step 9344, loss = 0.69469 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:24:13.553342 ops/training.py:65 2019-01-17 03:24:13.553266: step 9345, loss = 0.59862 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:24:14.841590 ops/training.py:65 2019-01-17 03:24:14.841486: step 9346, loss = 0.67916 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:24:16.128083 ops/training.py:65 2019-01-17 03:24:16.128017: step 9347, loss = 0.65819 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:24:17.417434 ops/training.py:65 2019-01-17 03:24:17.417297: step 9348, loss = 0.66422 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:24:18.702034 ops/training.py:65 2019-01-17 03:24:18.701969: step 9349, loss = 0.66948 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:24:19.985036 ops/training.py:65 2019-01-17 03:24:19.984943: step 9350, loss = 0.69323 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:24:21.273731 ops/training.py:65 2019-01-17 03:24:21.273617: step 9351, loss = 0.66162 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:24:22.557680 ops/training.py:65 2019-01-17 03:24:22.557610: step 9352, loss = 0.67639 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:24:23.849470 ops/training.py:65 2019-01-17 03:24:23.849372: step 9353, loss = 0.70034 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:24:25.135575 ops/training.py:65 2019-01-17 03:24:25.135506: step 9354, loss = 0.68332 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:24:26.419301 ops/training.py:65 2019-01-17 03:24:26.419201: step 9355, loss = 0.69677 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:24:27.708562 ops/training.py:65 2019-01-17 03:24:27.708453: step 9356, loss = 0.71571 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:24:28.992845 ops/training.py:65 2019-01-17 03:24:28.992685: step 9357, loss = 0.66645 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:24:30.281309 ops/training.py:65 2019-01-17 03:24:30.281199: step 9358, loss = 0.67820 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:24:31.570946 ops/training.py:65 2019-01-17 03:24:31.570834: step 9359, loss = 0.69103 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:24:32.857019 ops/training.py:65 2019-01-17 03:24:32.856943: step 9360, loss = 0.64622 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:24:34.146813 ops/training.py:65 2019-01-17 03:24:34.146672: step 9361, loss = 0.66984 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:24:35.438155 ops/training.py:65 2019-01-17 03:24:35.438052: step 9362, loss = 0.70691 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:24:36.728319 ops/training.py:65 2019-01-17 03:24:36.728242: step 9363, loss = 0.64909 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:24:38.014703 ops/training.py:65 2019-01-17 03:24:38.014603: step 9364, loss = 0.64365 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:24:39.303447 ops/training.py:65 2019-01-17 03:24:39.303371: step 9365, loss = 0.65328 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:24:40.587492 ops/training.py:65 2019-01-17 03:24:40.587423: step 9366, loss = 0.63363 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:24:41.871081 ops/training.py:65 2019-01-17 03:24:41.870985: step 9367, loss = 0.63989 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:24:43.159308 ops/training.py:65 2019-01-17 03:24:43.159205: step 9368, loss = 0.69283 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:24:44.450618 ops/training.py:65 2019-01-17 03:24:44.450549: step 9369, loss = 0.64571 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:24:45.739918 ops/training.py:65 2019-01-17 03:24:45.739849: step 9370, loss = 0.72559 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:24:47.030126 ops/training.py:65 2019-01-17 03:24:47.030068: step 9371, loss = 0.66314 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:24:48.319653 ops/training.py:65 2019-01-17 03:24:48.319586: step 9372, loss = 0.63195 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:24:49.608352 ops/training.py:65 2019-01-17 03:24:49.608255: step 9373, loss = 0.65115 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:24:50.897877 ops/training.py:65 2019-01-17 03:24:50.897796: step 9374, loss = 0.63294 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:24:52.181883 ops/training.py:65 2019-01-17 03:24:52.181815: step 9375, loss = 0.68401 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:24:53.467523 ops/training.py:65 2019-01-17 03:24:53.467425: step 9376, loss = 0.77722 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:24:54.758007 ops/training.py:65 2019-01-17 03:24:54.757902: step 9377, loss = 0.65504 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:24:56.048321 ops/training.py:65 2019-01-17 03:24:56.048242: step 9378, loss = 0.63538 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:24:57.337333 ops/training.py:65 2019-01-17 03:24:57.337246: step 9379, loss = 0.62311 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:24:58.628375 ops/training.py:65 2019-01-17 03:24:58.628280: step 9380, loss = 0.72711 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:24:59.919726 ops/training.py:65 2019-01-17 03:24:59.919657: step 9381, loss = 0.67590 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:25:01.208102 ops/training.py:65 2019-01-17 03:25:01.208033: step 9382, loss = 0.67188 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:25:02.496200 ops/training.py:65 2019-01-17 03:25:02.496132: step 9383, loss = 0.63006 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:25:03.784942 ops/training.py:65 2019-01-17 03:25:03.784853: step 9384, loss = 0.68095 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:25:05.074782 ops/training.py:65 2019-01-17 03:25:05.074696: step 9385, loss = 0.64454 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:25:06.363960 ops/training.py:65 2019-01-17 03:25:06.363889: step 9386, loss = 0.67958 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:25:07.652546 ops/training.py:65 2019-01-17 03:25:07.652469: step 9387, loss = 0.70939 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:25:08.940741 ops/training.py:65 2019-01-17 03:25:08.940678: step 9388, loss = 0.66871 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:25:10.229610 ops/training.py:65 2019-01-17 03:25:10.229518: step 9389, loss = 0.68538 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:25:11.519259 ops/training.py:65 2019-01-17 03:25:11.519189: step 9390, loss = 0.73786 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:25:12.807525 ops/training.py:65 2019-01-17 03:25:12.807457: step 9391, loss = 0.69587 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:25:14.096741 ops/training.py:65 2019-01-17 03:25:14.096668: step 9392, loss = 0.70477 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:25:15.387058 ops/training.py:65 2019-01-17 03:25:15.386979: step 9393, loss = 0.71206 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:25:16.673584 ops/training.py:65 2019-01-17 03:25:16.673514: step 9394, loss = 0.70890 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:25:17.961877 ops/training.py:65 2019-01-17 03:25:17.961792: step 9395, loss = 0.69542 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:25:19.250718 ops/training.py:65 2019-01-17 03:25:19.250632: step 9396, loss = 0.64084 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:25:20.540183 ops/training.py:65 2019-01-17 03:25:20.540113: step 9397, loss = 0.67325 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:25:21.825030 ops/training.py:65 2019-01-17 03:25:21.824967: step 9398, loss = 0.68853 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:25:23.112317 ops/training.py:65 2019-01-17 03:25:23.112246: step 9399, loss = 0.65609 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:25:24.397417 ops/training.py:65 2019-01-17 03:25:24.397348: step 9400, loss = 0.71932 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:25:25.686235 ops/training.py:65 2019-01-17 03:25:25.686168: step 9401, loss = 0.59083 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 03:25:26.974400 ops/training.py:65 2019-01-17 03:25:26.974311: step 9402, loss = 0.67283 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:25:28.264769 ops/training.py:65 2019-01-17 03:25:28.264677: step 9403, loss = 0.68443 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:25:29.550107 ops/training.py:65 2019-01-17 03:25:29.550044: step 9404, loss = 0.64917 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:25:30.837838 ops/training.py:65 2019-01-17 03:25:30.837768: step 9405, loss = 0.70672 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:25:32.125235 ops/training.py:65 2019-01-17 03:25:32.125157: step 9406, loss = 0.64143 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:25:33.412973 ops/training.py:65 2019-01-17 03:25:33.412897: step 9407, loss = 0.70868 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:25:34.702772 ops/training.py:65 2019-01-17 03:25:34.702703: step 9408, loss = 0.67292 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:25:35.991326 ops/training.py:65 2019-01-17 03:25:35.991254: step 9409, loss = 0.65341 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:25:37.279582 ops/training.py:65 2019-01-17 03:25:37.279512: step 9410, loss = 0.70516 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:25:38.567859 ops/training.py:65 2019-01-17 03:25:38.567790: step 9411, loss = 0.70468 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:25:39.856723 ops/training.py:65 2019-01-17 03:25:39.856656: step 9412, loss = 0.67957 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:25:41.145294 ops/training.py:65 2019-01-17 03:25:41.145207: step 9413, loss = 0.66002 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:25:42.432116 ops/training.py:65 2019-01-17 03:25:42.432055: step 9414, loss = 0.68507 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:25:43.720149 ops/training.py:65 2019-01-17 03:25:43.720074: step 9415, loss = 0.64255 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:25:45.010369 ops/training.py:65 2019-01-17 03:25:45.010302: step 9416, loss = 0.69374 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:25:46.298871 ops/training.py:65 2019-01-17 03:25:46.298802: step 9417, loss = 0.64033 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:25:47.587607 ops/training.py:65 2019-01-17 03:25:47.587510: step 9418, loss = 0.66755 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:25:48.874933 ops/training.py:65 2019-01-17 03:25:48.874861: step 9419, loss = 0.71473 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:25:50.164402 ops/training.py:65 2019-01-17 03:25:50.164324: step 9420, loss = 0.73070 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:25:51.448440 ops/training.py:65 2019-01-17 03:25:51.448371: step 9421, loss = 0.69535 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:25:52.734659 ops/training.py:65 2019-01-17 03:25:52.734572: step 9422, loss = 0.63503 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:25:54.022576 ops/training.py:65 2019-01-17 03:25:54.022479: step 9423, loss = 0.62968 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:25:55.311637 ops/training.py:65 2019-01-17 03:25:55.311566: step 9424, loss = 0.65365 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:25:56.599381 ops/training.py:65 2019-01-17 03:25:56.599317: step 9425, loss = 0.65894 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:25:57.888157 ops/training.py:65 2019-01-17 03:25:57.888085: step 9426, loss = 0.70199 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:25:59.173658 ops/training.py:65 2019-01-17 03:25:59.173584: step 9427, loss = 0.69391 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:26:00.463962 ops/training.py:65 2019-01-17 03:26:00.463893: step 9428, loss = 0.61353 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:26:01.752466 ops/training.py:65 2019-01-17 03:26:01.752375: step 9429, loss = 0.66882 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:26:03.041225 ops/training.py:65 2019-01-17 03:26:03.041151: step 9430, loss = 0.66068 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:26:04.330129 ops/training.py:65 2019-01-17 03:26:04.330055: step 9431, loss = 0.61773 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 03:26:05.619764 ops/training.py:65 2019-01-17 03:26:05.619661: step 9432, loss = 0.70276 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:26:06.910103 ops/training.py:65 2019-01-17 03:26:06.909935: step 9433, loss = 0.62154 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:26:08.199181 ops/training.py:65 2019-01-17 03:26:08.199073: step 9434, loss = 0.71821 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:26:09.488337 ops/training.py:65 2019-01-17 03:26:09.488224: step 9435, loss = 0.71271 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:26:10.777686 ops/training.py:65 2019-01-17 03:26:10.777604: step 9436, loss = 0.73064 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:26:12.065540 ops/training.py:65 2019-01-17 03:26:12.065433: step 9437, loss = 0.61852 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:26:13.349810 ops/training.py:65 2019-01-17 03:26:13.349717: step 9438, loss = 0.66122 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:26:14.639336 ops/training.py:65 2019-01-17 03:26:14.639238: step 9439, loss = 0.64871 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:26:15.928711 ops/training.py:65 2019-01-17 03:26:15.928640: step 9440, loss = 0.71673 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:26:17.215628 ops/training.py:65 2019-01-17 03:26:17.215559: step 9441, loss = 0.66396 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:26:18.499125 ops/training.py:65 2019-01-17 03:26:18.499048: step 9442, loss = 0.68206 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:26:19.787895 ops/training.py:65 2019-01-17 03:26:19.787786: step 9443, loss = 0.67794 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:26:21.075828 ops/training.py:65 2019-01-17 03:26:21.075753: step 9444, loss = 0.69844 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:26:22.364850 ops/training.py:65 2019-01-17 03:26:22.364783: step 9445, loss = 0.67909 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:26:23.651555 ops/training.py:65 2019-01-17 03:26:23.651482: step 9446, loss = 0.59015 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:26:24.939851 ops/training.py:65 2019-01-17 03:26:24.939770: step 9447, loss = 0.67959 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:26:26.229383 ops/training.py:65 2019-01-17 03:26:26.229315: step 9448, loss = 0.79825 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:26:27.518912 ops/training.py:65 2019-01-17 03:26:27.518846: step 9449, loss = 0.71330 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:26:28.807106 ops/training.py:65 2019-01-17 03:26:28.807037: step 9450, loss = 0.67697 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:26:30.097118 ops/training.py:65 2019-01-17 03:26:30.097042: step 9451, loss = 0.70325 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:26:31.393846 ops/training.py:65 2019-01-17 03:26:31.393784: step 9452, loss = 0.68808 (24.7 examples/sec; 1.296 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:26:32.681553 ops/training.py:65 2019-01-17 03:26:32.681484: step 9453, loss = 0.76564 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:26:33.969992 ops/training.py:65 2019-01-17 03:26:33.969912: step 9454, loss = 0.70743 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:26:35.258886 ops/training.py:65 2019-01-17 03:26:35.258809: step 9455, loss = 0.69370 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:26:36.548299 ops/training.py:65 2019-01-17 03:26:36.548219: step 9456, loss = 0.62501 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:26:37.833046 ops/training.py:65 2019-01-17 03:26:37.832969: step 9457, loss = 0.73264 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:26:39.121906 ops/training.py:65 2019-01-17 03:26:39.121799: step 9458, loss = 0.76861 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 03:26:40.407178 ops/training.py:65 2019-01-17 03:26:40.407111: step 9459, loss = 0.60189 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:26:41.694639 ops/training.py:65 2019-01-17 03:26:41.694568: step 9460, loss = 0.76847 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:26:42.980214 ops/training.py:65 2019-01-17 03:26:42.980148: step 9461, loss = 0.61954 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:26:44.269390 ops/training.py:65 2019-01-17 03:26:44.269319: step 9462, loss = 0.73354 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:26:45.555002 ops/training.py:65 2019-01-17 03:26:45.554915: step 9463, loss = 0.66407 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:26:46.839747 ops/training.py:65 2019-01-17 03:26:46.839658: step 9464, loss = 0.71538 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:26:48.124036 ops/training.py:65 2019-01-17 03:26:48.123972: step 9465, loss = 0.63284 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:26:49.412077 ops/training.py:65 2019-01-17 03:26:49.411980: step 9466, loss = 0.65085 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:26:50.701237 ops/training.py:65 2019-01-17 03:26:50.701162: step 9467, loss = 0.68818 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:26:51.991640 ops/training.py:65 2019-01-17 03:26:51.991574: step 9468, loss = 0.73589 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:26:53.276892 ops/training.py:65 2019-01-17 03:26:53.276816: step 9469, loss = 0.72476 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:26:54.566702 ops/training.py:65 2019-01-17 03:26:54.566596: step 9470, loss = 0.65550 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:26:55.851217 ops/training.py:65 2019-01-17 03:26:55.851138: step 9471, loss = 0.71348 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:26:57.142055 ops/training.py:65 2019-01-17 03:26:57.141954: step 9472, loss = 0.62552 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:26:58.431774 ops/training.py:65 2019-01-17 03:26:58.431678: step 9473, loss = 0.72072 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:26:59.720906 ops/training.py:65 2019-01-17 03:26:59.720808: step 9474, loss = 0.67727 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:27:01.007952 ops/training.py:65 2019-01-17 03:27:01.007876: step 9475, loss = 0.63537 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:27:02.293491 ops/training.py:65 2019-01-17 03:27:02.293424: step 9476, loss = 0.68162 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:27:03.578023 ops/training.py:65 2019-01-17 03:27:03.577946: step 9477, loss = 0.72125 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:27:04.866070 ops/training.py:65 2019-01-17 03:27:04.865995: step 9478, loss = 0.66829 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:27:06.150151 ops/training.py:65 2019-01-17 03:27:06.150074: step 9479, loss = 0.73537 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:27:07.433453 ops/training.py:65 2019-01-17 03:27:07.433375: step 9480, loss = 0.70423 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:27:08.721341 ops/training.py:65 2019-01-17 03:27:08.721240: step 9481, loss = 0.67638 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:27:10.007485 ops/training.py:65 2019-01-17 03:27:10.007374: step 9482, loss = 0.70402 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:27:11.297186 ops/training.py:65 2019-01-17 03:27:11.297102: step 9483, loss = 0.66025 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:27:12.585794 ops/training.py:65 2019-01-17 03:27:12.585689: step 9484, loss = 0.68284 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:27:13.873765 ops/training.py:65 2019-01-17 03:27:13.873675: step 9485, loss = 0.72090 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:27:15.162320 ops/training.py:65 2019-01-17 03:27:15.162233: step 9486, loss = 0.67733 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:27:16.451340 ops/training.py:65 2019-01-17 03:27:16.451268: step 9487, loss = 0.68551 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:27:17.740299 ops/training.py:65 2019-01-17 03:27:17.740226: step 9488, loss = 0.68924 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:27:19.029089 ops/training.py:65 2019-01-17 03:27:19.029018: step 9489, loss = 0.66840 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:27:20.317667 ops/training.py:65 2019-01-17 03:27:20.317593: step 9490, loss = 0.70786 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:27:21.602374 ops/training.py:65 2019-01-17 03:27:21.602313: step 9491, loss = 0.64352 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:27:22.890920 ops/training.py:65 2019-01-17 03:27:22.890850: step 9492, loss = 0.66871 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:27:24.179177 ops/training.py:65 2019-01-17 03:27:24.179108: step 9493, loss = 0.71568 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:27:25.464222 ops/training.py:65 2019-01-17 03:27:25.464135: step 9494, loss = 0.65129 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:27:26.748352 ops/training.py:65 2019-01-17 03:27:26.748285: step 9495, loss = 0.71786 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:27:28.031674 ops/training.py:65 2019-01-17 03:27:28.031576: step 9496, loss = 0.67849 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:27:29.323899 ops/training.py:65 2019-01-17 03:27:29.323793: step 9497, loss = 0.64863 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:27:30.614146 ops/training.py:65 2019-01-17 03:27:30.614085: step 9498, loss = 0.63906 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:27:31.902289 ops/training.py:65 2019-01-17 03:27:31.902229: step 9499, loss = 0.69623 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:27:33.186508 ops/training.py:65 2019-01-17 03:27:33.186432: step 9500, loss = 0.71863 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:27:34.475010 ops/training.py:65 2019-01-17 03:27:34.474941: step 9501, loss = 0.79137 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 03:27:35.764550 ops/training.py:65 2019-01-17 03:27:35.764483: step 9502, loss = 0.61223 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:27:37.052011 ops/training.py:65 2019-01-17 03:27:37.051920: step 9503, loss = 0.65633 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:27:38.337161 ops/training.py:65 2019-01-17 03:27:38.337086: step 9504, loss = 0.65357 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:27:39.625961 ops/training.py:65 2019-01-17 03:27:39.625888: step 9505, loss = 0.60532 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:27:40.915786 ops/training.py:65 2019-01-17 03:27:40.915711: step 9506, loss = 0.75211 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:27:42.196745 ops/training.py:65 2019-01-17 03:27:42.196675: step 9507, loss = 0.75335 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:27:43.485761 ops/training.py:65 2019-01-17 03:27:43.485632: step 9508, loss = 0.69756 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:27:44.775424 ops/training.py:65 2019-01-17 03:27:44.775350: step 9509, loss = 0.63578 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:27:46.060187 ops/training.py:65 2019-01-17 03:27:46.060120: step 9510, loss = 0.62978 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:27:47.349185 ops/training.py:65 2019-01-17 03:27:47.349090: step 9511, loss = 0.62989 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:27:48.637460 ops/training.py:65 2019-01-17 03:27:48.637359: step 9512, loss = 0.67507 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:27:49.926404 ops/training.py:65 2019-01-17 03:27:49.926333: step 9513, loss = 0.67588 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:27:51.212887 ops/training.py:65 2019-01-17 03:27:51.212815: step 9514, loss = 0.56881 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:27:52.497596 ops/training.py:65 2019-01-17 03:27:52.497529: step 9515, loss = 0.65058 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:27:53.780279 ops/training.py:65 2019-01-17 03:27:53.780182: step 9516, loss = 0.71833 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:27:55.070525 ops/training.py:65 2019-01-17 03:27:55.070424: step 9517, loss = 0.64805 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:27:56.357143 ops/training.py:65 2019-01-17 03:27:56.357043: step 9518, loss = 0.67609 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:27:57.646997 ops/training.py:65 2019-01-17 03:27:57.646894: step 9519, loss = 0.66577 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:27:58.934547 ops/training.py:65 2019-01-17 03:27:58.934431: step 9520, loss = 0.65401 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:28:00.217941 ops/training.py:65 2019-01-17 03:28:00.217825: step 9521, loss = 0.65857 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:28:01.507132 ops/training.py:65 2019-01-17 03:28:01.507042: step 9522, loss = 0.61402 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:28:02.792642 ops/training.py:65 2019-01-17 03:28:02.792573: step 9523, loss = 0.70251 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:28:04.081873 ops/training.py:65 2019-01-17 03:28:04.081810: step 9524, loss = 0.75710 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 03:28:05.369217 ops/training.py:65 2019-01-17 03:28:05.369147: step 9525, loss = 0.74728 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:28:06.653150 ops/training.py:65 2019-01-17 03:28:06.653081: step 9526, loss = 0.63959 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:28:07.940376 ops/training.py:65 2019-01-17 03:28:07.940284: step 9527, loss = 0.65080 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:28:09.221410 ops/training.py:65 2019-01-17 03:28:09.221344: step 9528, loss = 0.66438 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:28:10.508883 ops/training.py:65 2019-01-17 03:28:10.508793: step 9529, loss = 0.63612 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:28:11.798169 ops/training.py:65 2019-01-17 03:28:11.798104: step 9530, loss = 0.69042 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:28:13.086823 ops/training.py:65 2019-01-17 03:28:13.086741: step 9531, loss = 0.64165 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:28:14.371419 ops/training.py:65 2019-01-17 03:28:14.371349: step 9532, loss = 0.64661 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:28:15.660146 ops/training.py:65 2019-01-17 03:28:15.660074: step 9533, loss = 0.72130 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:28:16.942440 ops/training.py:65 2019-01-17 03:28:16.942366: step 9534, loss = 0.68346 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:28:18.227078 ops/training.py:65 2019-01-17 03:28:18.227001: step 9535, loss = 0.68476 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:28:19.513297 ops/training.py:65 2019-01-17 03:28:19.513232: step 9536, loss = 0.66763 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:28:20.796660 ops/training.py:65 2019-01-17 03:28:20.796588: step 9537, loss = 0.62922 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:28:22.084136 ops/training.py:65 2019-01-17 03:28:22.084031: step 9538, loss = 0.72440 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:28:23.369354 ops/training.py:65 2019-01-17 03:28:23.369288: step 9539, loss = 0.67264 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:28:24.657636 ops/training.py:65 2019-01-17 03:28:24.657573: step 9540, loss = 0.65452 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:28:25.946079 ops/training.py:65 2019-01-17 03:28:25.946009: step 9541, loss = 0.59867 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:28:27.229778 ops/training.py:65 2019-01-17 03:28:27.229716: step 9542, loss = 0.65062 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:28:28.512873 ops/training.py:65 2019-01-17 03:28:28.512786: step 9543, loss = 0.71834 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:28:29.805541 ops/training.py:65 2019-01-17 03:28:29.805433: step 9544, loss = 0.69476 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:28:31.096052 ops/training.py:65 2019-01-17 03:28:31.095992: step 9545, loss = 0.69427 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:28:32.385017 ops/training.py:65 2019-01-17 03:28:32.384944: step 9546, loss = 0.59227 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:28:33.668148 ops/training.py:65 2019-01-17 03:28:33.668055: step 9547, loss = 0.70002 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:28:34.960303 ops/training.py:65 2019-01-17 03:28:34.960205: step 9548, loss = 0.64768 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:28:36.251011 ops/training.py:65 2019-01-17 03:28:36.250941: step 9549, loss = 0.74193 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:28:37.540606 ops/training.py:65 2019-01-17 03:28:37.540501: step 9550, loss = 0.80259 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 03:28:38.831275 ops/training.py:65 2019-01-17 03:28:38.831187: step 9551, loss = 0.72085 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:28:40.116023 ops/training.py:65 2019-01-17 03:28:40.115951: step 9552, loss = 0.68612 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:28:41.403943 ops/training.py:65 2019-01-17 03:28:41.403871: step 9553, loss = 0.63815 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:28:42.692759 ops/training.py:65 2019-01-17 03:28:42.692688: step 9554, loss = 0.67996 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:28:43.976374 ops/training.py:65 2019-01-17 03:28:43.976296: step 9555, loss = 0.79837 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-17 03:28:45.264911 ops/training.py:65 2019-01-17 03:28:45.264805: step 9556, loss = 0.72520 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:28:46.554766 ops/training.py:65 2019-01-17 03:28:46.554688: step 9557, loss = 0.66957 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:28:47.842801 ops/training.py:65 2019-01-17 03:28:47.842733: step 9558, loss = 0.65674 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:28:49.127092 ops/training.py:65 2019-01-17 03:28:49.127024: step 9559, loss = 0.70810 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:28:50.416325 ops/training.py:65 2019-01-17 03:28:50.416233: step 9560, loss = 0.68837 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:28:51.705109 ops/training.py:65 2019-01-17 03:28:51.705032: step 9561, loss = 0.66832 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:28:52.989761 ops/training.py:65 2019-01-17 03:28:52.989689: step 9562, loss = 0.63635 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:28:54.277970 ops/training.py:65 2019-01-17 03:28:54.277877: step 9563, loss = 0.69836 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:28:55.568057 ops/training.py:65 2019-01-17 03:28:55.567972: step 9564, loss = 0.67959 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:28:56.860215 ops/training.py:65 2019-01-17 03:28:56.860067: step 9565, loss = 0.66733 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:28:58.150428 ops/training.py:65 2019-01-17 03:28:58.150321: step 9566, loss = 0.68047 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:28:59.436340 ops/training.py:65 2019-01-17 03:28:59.436255: step 9567, loss = 0.62645 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:29:00.724554 ops/training.py:65 2019-01-17 03:29:00.724480: step 9568, loss = 0.72215 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:29:02.012500 ops/training.py:65 2019-01-17 03:29:02.012428: step 9569, loss = 0.65764 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:29:03.301375 ops/training.py:65 2019-01-17 03:29:03.301305: step 9570, loss = 0.66815 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:29:04.590232 ops/training.py:65 2019-01-17 03:29:04.590157: step 9571, loss = 0.65419 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:29:05.878693 ops/training.py:65 2019-01-17 03:29:05.878621: step 9572, loss = 0.64462 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:29:07.167770 ops/training.py:65 2019-01-17 03:29:07.167690: step 9573, loss = 0.59063 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:29:08.456700 ops/training.py:65 2019-01-17 03:29:08.456620: step 9574, loss = 0.57391 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:29:09.745441 ops/training.py:65 2019-01-17 03:29:09.745367: step 9575, loss = 0.67009 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:29:11.032490 ops/training.py:65 2019-01-17 03:29:11.032425: step 9576, loss = 0.66576 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:29:12.320098 ops/training.py:65 2019-01-17 03:29:12.320026: step 9577, loss = 0.63860 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:29:13.607820 ops/training.py:65 2019-01-17 03:29:13.607751: step 9578, loss = 0.64034 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:29:14.897182 ops/training.py:65 2019-01-17 03:29:14.897097: step 9579, loss = 0.63461 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:29:16.184924 ops/training.py:65 2019-01-17 03:29:16.184841: step 9580, loss = 0.77770 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:29:17.473303 ops/training.py:65 2019-01-17 03:29:17.473226: step 9581, loss = 0.70197 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:29:18.763062 ops/training.py:65 2019-01-17 03:29:18.762970: step 9582, loss = 0.68800 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:29:20.051772 ops/training.py:65 2019-01-17 03:29:20.051683: step 9583, loss = 0.61973 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:29:21.340494 ops/training.py:65 2019-01-17 03:29:21.340417: step 9584, loss = 0.65747 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:29:22.623958 ops/training.py:65 2019-01-17 03:29:22.623891: step 9585, loss = 0.66894 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:29:23.908164 ops/training.py:65 2019-01-17 03:29:23.908095: step 9586, loss = 0.65273 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:29:25.190863 ops/training.py:65 2019-01-17 03:29:25.190787: step 9587, loss = 0.60238 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:29:26.480025 ops/training.py:65 2019-01-17 03:29:26.479916: step 9588, loss = 0.68634 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:29:27.768534 ops/training.py:65 2019-01-17 03:29:27.768456: step 9589, loss = 0.75626 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:29:29.057909 ops/training.py:65 2019-01-17 03:29:29.057854: step 9590, loss = 0.62188 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:29:30.345950 ops/training.py:65 2019-01-17 03:29:30.345872: step 9591, loss = 0.64542 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:29:31.634628 ops/training.py:65 2019-01-17 03:29:31.634524: step 9592, loss = 0.71435 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:29:32.921889 ops/training.py:65 2019-01-17 03:29:32.921815: step 9593, loss = 0.73333 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:29:34.212506 ops/training.py:65 2019-01-17 03:29:34.212430: step 9594, loss = 0.71865 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:29:35.500684 ops/training.py:65 2019-01-17 03:29:35.500600: step 9595, loss = 0.68972 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:29:36.788165 ops/training.py:65 2019-01-17 03:29:36.788088: step 9596, loss = 0.73022 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:29:38.078451 ops/training.py:65 2019-01-17 03:29:38.078369: step 9597, loss = 0.63800 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:29:39.367486 ops/training.py:65 2019-01-17 03:29:39.367415: step 9598, loss = 0.73275 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:29:40.651481 ops/training.py:65 2019-01-17 03:29:40.651417: step 9599, loss = 0.69343 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:29:41.937905 ops/training.py:65 2019-01-17 03:29:41.937823: step 9600, loss = 0.62633 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:29:43.220226 ops/training.py:65 2019-01-17 03:29:43.220134: step 9601, loss = 0.72589 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:29:44.507400 ops/training.py:65 2019-01-17 03:29:44.507299: step 9602, loss = 0.67067 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:29:45.798066 ops/training.py:65 2019-01-17 03:29:45.797997: step 9603, loss = 0.61220 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:29:47.081674 ops/training.py:65 2019-01-17 03:29:47.081604: step 9604, loss = 0.74170 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:29:48.368322 ops/training.py:65 2019-01-17 03:29:48.368243: step 9605, loss = 0.70202 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:29:49.655614 ops/training.py:65 2019-01-17 03:29:49.655545: step 9606, loss = 0.64471 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:29:50.936060 ops/training.py:65 2019-01-17 03:29:50.935994: step 9607, loss = 0.65033 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:29:52.225026 ops/training.py:65 2019-01-17 03:29:52.224949: step 9608, loss = 0.63893 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:29:53.512554 ops/training.py:65 2019-01-17 03:29:53.512484: step 9609, loss = 0.61007 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:29:54.800418 ops/training.py:65 2019-01-17 03:29:54.800347: step 9610, loss = 0.68762 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:29:56.089396 ops/training.py:65 2019-01-17 03:29:56.089315: step 9611, loss = 0.71666 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:29:57.377017 ops/training.py:65 2019-01-17 03:29:57.376927: step 9612, loss = 0.68520 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:29:58.664680 ops/training.py:65 2019-01-17 03:29:58.664606: step 9613, loss = 0.72284 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:29:59.952038 ops/training.py:65 2019-01-17 03:29:59.951973: step 9614, loss = 0.67619 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:30:01.240009 ops/training.py:65 2019-01-17 03:30:01.239932: step 9615, loss = 0.60862 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:30:02.528059 ops/training.py:65 2019-01-17 03:30:02.527993: step 9616, loss = 0.68938 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:30:03.813970 ops/training.py:65 2019-01-17 03:30:03.813888: step 9617, loss = 0.65618 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:30:05.102722 ops/training.py:65 2019-01-17 03:30:05.102635: step 9618, loss = 0.69737 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:30:06.388564 ops/training.py:65 2019-01-17 03:30:06.388500: step 9619, loss = 0.59935 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 03:30:07.676150 ops/training.py:65 2019-01-17 03:30:07.676045: step 9620, loss = 0.61753 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:30:08.965408 ops/training.py:65 2019-01-17 03:30:08.965340: step 9621, loss = 0.72081 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:30:10.255339 ops/training.py:65 2019-01-17 03:30:10.255266: step 9622, loss = 0.68713 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:30:11.544585 ops/training.py:65 2019-01-17 03:30:11.544511: step 9623, loss = 0.60294 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:30:12.831866 ops/training.py:65 2019-01-17 03:30:12.831802: step 9624, loss = 0.67999 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:30:14.122027 ops/training.py:65 2019-01-17 03:30:14.121954: step 9625, loss = 0.67106 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:30:15.406455 ops/training.py:65 2019-01-17 03:30:15.406390: step 9626, loss = 0.65117 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:30:16.690760 ops/training.py:65 2019-01-17 03:30:16.690686: step 9627, loss = 0.68875 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:30:17.982069 ops/training.py:65 2019-01-17 03:30:17.981961: step 9628, loss = 0.63078 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 03:30:19.273041 ops/training.py:65 2019-01-17 03:30:19.272968: step 9629, loss = 0.65156 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:30:20.560704 ops/training.py:65 2019-01-17 03:30:20.560639: step 9630, loss = 0.65793 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:30:21.849443 ops/training.py:65 2019-01-17 03:30:21.849352: step 9631, loss = 0.65521 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:30:23.139057 ops/training.py:65 2019-01-17 03:30:23.138985: step 9632, loss = 0.63278 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:30:24.426510 ops/training.py:65 2019-01-17 03:30:24.426432: step 9633, loss = 0.64938 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:30:25.715073 ops/training.py:65 2019-01-17 03:30:25.715007: step 9634, loss = 0.68127 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:30:27.003257 ops/training.py:65 2019-01-17 03:30:27.003187: step 9635, loss = 0.65152 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:30:28.285889 ops/training.py:65 2019-01-17 03:30:28.285820: step 9636, loss = 0.65400 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:30:29.567773 ops/training.py:65 2019-01-17 03:30:29.567668: step 9637, loss = 0.69691 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:30:30.855180 ops/training.py:65 2019-01-17 03:30:30.855071: step 9638, loss = 0.60420 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:30:32.145818 ops/training.py:65 2019-01-17 03:30:32.145720: step 9639, loss = 0.69516 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:30:33.437773 ops/training.py:65 2019-01-17 03:30:33.437697: step 9640, loss = 0.72828 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:30:34.726693 ops/training.py:65 2019-01-17 03:30:34.726602: step 9641, loss = 0.65454 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:30:36.013015 ops/training.py:65 2019-01-17 03:30:36.012944: step 9642, loss = 0.68266 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:30:37.301720 ops/training.py:65 2019-01-17 03:30:37.301647: step 9643, loss = 0.75957 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:30:38.586722 ops/training.py:65 2019-01-17 03:30:38.586652: step 9644, loss = 0.61003 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:30:39.874865 ops/training.py:65 2019-01-17 03:30:39.874767: step 9645, loss = 0.64387 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:30:41.163315 ops/training.py:65 2019-01-17 03:30:41.163242: step 9646, loss = 0.68417 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:30:42.451701 ops/training.py:65 2019-01-17 03:30:42.451625: step 9647, loss = 0.65782 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:30:43.736662 ops/training.py:65 2019-01-17 03:30:43.736584: step 9648, loss = 0.64812 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:30:45.024725 ops/training.py:65 2019-01-17 03:30:45.024657: step 9649, loss = 0.64274 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:30:46.308813 ops/training.py:65 2019-01-17 03:30:46.308742: step 9650, loss = 0.65986 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:30:47.591597 ops/training.py:65 2019-01-17 03:30:47.591494: step 9651, loss = 0.77028 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:30:48.877585 ops/training.py:65 2019-01-17 03:30:48.877487: step 9652, loss = 0.66558 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:30:50.164721 ops/training.py:65 2019-01-17 03:30:50.164616: step 9653, loss = 0.74379 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:30:51.456283 ops/training.py:65 2019-01-17 03:30:51.456129: step 9654, loss = 0.66793 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:30:52.747644 ops/training.py:65 2019-01-17 03:30:52.747579: step 9655, loss = 0.74656 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:30:54.035048 ops/training.py:65 2019-01-17 03:30:54.034976: step 9656, loss = 0.71672 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:30:55.321358 ops/training.py:65 2019-01-17 03:30:55.321291: step 9657, loss = 0.72232 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:30:56.604726 ops/training.py:65 2019-01-17 03:30:56.604629: step 9658, loss = 0.69016 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:30:57.896570 ops/training.py:65 2019-01-17 03:30:57.896440: step 9659, loss = 0.66968 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:30:59.184597 ops/training.py:65 2019-01-17 03:30:59.184527: step 9660, loss = 0.72804 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:31:00.467616 ops/training.py:65 2019-01-17 03:31:00.467519: step 9661, loss = 0.63147 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:31:01.751329 ops/training.py:65 2019-01-17 03:31:01.751225: step 9662, loss = 0.62021 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:31:03.044327 ops/training.py:65 2019-01-17 03:31:03.044196: step 9663, loss = 0.72191 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:31:04.336737 ops/training.py:65 2019-01-17 03:31:04.336663: step 9664, loss = 0.60121 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:31:05.631098 ops/training.py:65 2019-01-17 03:31:05.631026: step 9665, loss = 0.66605 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:31:06.920568 ops/training.py:65 2019-01-17 03:31:06.920484: step 9666, loss = 0.64963 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:31:08.205566 ops/training.py:65 2019-01-17 03:31:08.205498: step 9667, loss = 0.67963 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:31:09.493996 ops/training.py:65 2019-01-17 03:31:09.493921: step 9668, loss = 0.65269 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:31:10.781955 ops/training.py:65 2019-01-17 03:31:10.781871: step 9669, loss = 0.70280 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:31:12.070570 ops/training.py:65 2019-01-17 03:31:12.070495: step 9670, loss = 0.66563 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:31:13.357164 ops/training.py:65 2019-01-17 03:31:13.357085: step 9671, loss = 0.63960 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:31:14.646034 ops/training.py:65 2019-01-17 03:31:14.645966: step 9672, loss = 0.78122 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:31:15.933730 ops/training.py:65 2019-01-17 03:31:15.933663: step 9673, loss = 0.66543 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:31:17.223499 ops/training.py:65 2019-01-17 03:31:17.223429: step 9674, loss = 0.76965 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:31:18.511661 ops/training.py:65 2019-01-17 03:31:18.511588: step 9675, loss = 0.66056 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:31:19.801075 ops/training.py:65 2019-01-17 03:31:19.801005: step 9676, loss = 0.62144 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:31:21.089768 ops/training.py:65 2019-01-17 03:31:21.089677: step 9677, loss = 0.73090 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:31:22.375304 ops/training.py:65 2019-01-17 03:31:22.375231: step 9678, loss = 0.72363 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:31:23.664021 ops/training.py:65 2019-01-17 03:31:23.663917: step 9679, loss = 0.74678 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:31:24.951758 ops/training.py:65 2019-01-17 03:31:24.951687: step 9680, loss = 0.67233 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:31:26.240166 ops/training.py:65 2019-01-17 03:31:26.240099: step 9681, loss = 0.61219 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:31:27.529264 ops/training.py:65 2019-01-17 03:31:27.529195: step 9682, loss = 0.73622 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:31:28.818222 ops/training.py:65 2019-01-17 03:31:28.818154: step 9683, loss = 0.69751 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:31:30.102863 ops/training.py:65 2019-01-17 03:31:30.102796: step 9684, loss = 0.74370 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:31:31.391295 ops/training.py:65 2019-01-17 03:31:31.391187: step 9685, loss = 0.70664 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:31:32.679173 ops/training.py:65 2019-01-17 03:31:32.679101: step 9686, loss = 0.70578 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:31:33.967784 ops/training.py:65 2019-01-17 03:31:33.967709: step 9687, loss = 0.70452 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:31:35.257337 ops/training.py:65 2019-01-17 03:31:35.257265: step 9688, loss = 0.69436 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:31:36.541407 ops/training.py:65 2019-01-17 03:31:36.541319: step 9689, loss = 0.71675 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:31:37.827262 ops/training.py:65 2019-01-17 03:31:37.827127: step 9690, loss = 0.73198 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:31:39.116453 ops/training.py:65 2019-01-17 03:31:39.116376: step 9691, loss = 0.69386 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:31:40.401815 ops/training.py:65 2019-01-17 03:31:40.401732: step 9692, loss = 0.72735 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:31:41.689761 ops/training.py:65 2019-01-17 03:31:41.689682: step 9693, loss = 0.67971 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:31:42.976931 ops/training.py:65 2019-01-17 03:31:42.976859: step 9694, loss = 0.72739 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:31:44.263779 ops/training.py:65 2019-01-17 03:31:44.263706: step 9695, loss = 0.65791 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:31:45.552934 ops/training.py:65 2019-01-17 03:31:45.552858: step 9696, loss = 0.63992 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:31:46.841211 ops/training.py:65 2019-01-17 03:31:46.841145: step 9697, loss = 0.61150 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:31:48.130234 ops/training.py:65 2019-01-17 03:31:48.130163: step 9698, loss = 0.67662 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:31:49.418598 ops/training.py:65 2019-01-17 03:31:49.418532: step 9699, loss = 0.60829 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:31:50.707988 ops/training.py:65 2019-01-17 03:31:50.707923: step 9700, loss = 0.64145 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:31:51.992594 ops/training.py:65 2019-01-17 03:31:51.992524: step 9701, loss = 0.66426 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:31:53.280664 ops/training.py:65 2019-01-17 03:31:53.280568: step 9702, loss = 0.61414 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:31:54.565706 ops/training.py:65 2019-01-17 03:31:54.565631: step 9703, loss = 0.68272 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:31:55.853563 ops/training.py:65 2019-01-17 03:31:55.853487: step 9704, loss = 0.71440 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:31:57.138832 ops/training.py:65 2019-01-17 03:31:57.138751: step 9705, loss = 0.64151 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:31:58.427531 ops/training.py:65 2019-01-17 03:31:58.427433: step 9706, loss = 0.69488 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:31:59.711428 ops/training.py:65 2019-01-17 03:31:59.711366: step 9707, loss = 0.67093 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:32:00.995080 ops/training.py:65 2019-01-17 03:32:00.995003: step 9708, loss = 0.64732 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:32:02.283083 ops/training.py:65 2019-01-17 03:32:02.283016: step 9709, loss = 0.61154 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:32:03.562782 ops/training.py:65 2019-01-17 03:32:03.562701: step 9710, loss = 0.61365 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:32:04.842881 ops/training.py:65 2019-01-17 03:32:04.842753: step 9711, loss = 0.62762 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:32:06.129497 ops/training.py:65 2019-01-17 03:32:06.129391: step 9712, loss = 0.76238 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:32:07.420942 ops/training.py:65 2019-01-17 03:32:07.420789: step 9713, loss = 0.62903 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:32:08.706626 ops/training.py:65 2019-01-17 03:32:08.706560: step 9714, loss = 0.66028 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:32:09.989919 ops/training.py:65 2019-01-17 03:32:09.989816: step 9715, loss = 0.63470 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:32:11.281681 ops/training.py:65 2019-01-17 03:32:11.281568: step 9716, loss = 0.64422 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:32:12.572870 ops/training.py:65 2019-01-17 03:32:12.572802: step 9717, loss = 0.65658 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:32:13.861692 ops/training.py:65 2019-01-17 03:32:13.861624: step 9718, loss = 0.57360 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 03:32:15.145200 ops/training.py:65 2019-01-17 03:32:15.145135: step 9719, loss = 0.68772 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:32:16.429015 ops/training.py:65 2019-01-17 03:32:16.428906: step 9720, loss = 0.67553 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:32:17.715186 ops/training.py:65 2019-01-17 03:32:17.715032: step 9721, loss = 0.64038 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:32:18.999530 ops/training.py:65 2019-01-17 03:32:18.999431: step 9722, loss = 0.60125 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 03:32:20.290773 ops/training.py:65 2019-01-17 03:32:20.290666: step 9723, loss = 0.67699 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:32:21.575960 ops/training.py:65 2019-01-17 03:32:21.575895: step 9724, loss = 0.63562 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:32:22.859967 ops/training.py:65 2019-01-17 03:32:22.859859: step 9725, loss = 0.63082 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:32:24.145615 ops/training.py:65 2019-01-17 03:32:24.145473: step 9726, loss = 0.69770 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:32:25.431549 ops/training.py:65 2019-01-17 03:32:25.431452: step 9727, loss = 0.67876 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:32:26.723751 ops/training.py:65 2019-01-17 03:32:26.723650: step 9728, loss = 0.68371 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:32:28.006897 ops/training.py:65 2019-01-17 03:32:28.006788: step 9729, loss = 0.67647 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:32:29.298410 ops/training.py:65 2019-01-17 03:32:29.298304: step 9730, loss = 0.71203 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:32:30.586780 ops/training.py:65 2019-01-17 03:32:30.586710: step 9731, loss = 0.57809 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:32:31.875092 ops/training.py:65 2019-01-17 03:32:31.875007: step 9732, loss = 0.62318 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:32:33.158976 ops/training.py:65 2019-01-17 03:32:33.158901: step 9733, loss = 0.65032 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:32:34.448223 ops/training.py:65 2019-01-17 03:32:34.448135: step 9734, loss = 0.65334 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:32:35.734124 ops/training.py:65 2019-01-17 03:32:35.734036: step 9735, loss = 0.74645 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:32:37.025090 ops/training.py:65 2019-01-17 03:32:37.024940: step 9736, loss = 0.57969 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:32:38.312072 ops/training.py:65 2019-01-17 03:32:38.311979: step 9737, loss = 0.64833 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:32:39.592445 ops/training.py:65 2019-01-17 03:32:39.592374: step 9738, loss = 0.71732 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:32:40.880192 ops/training.py:65 2019-01-17 03:32:40.880126: step 9739, loss = 0.72718 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:32:42.169509 ops/training.py:65 2019-01-17 03:32:42.169438: step 9740, loss = 0.63217 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:32:43.452687 ops/training.py:65 2019-01-17 03:32:43.452615: step 9741, loss = 0.75900 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:32:44.736174 ops/training.py:65 2019-01-17 03:32:44.736077: step 9742, loss = 0.68211 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:32:46.028959 ops/training.py:65 2019-01-17 03:32:46.028849: step 9743, loss = 0.71617 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:32:47.320961 ops/training.py:65 2019-01-17 03:32:47.320869: step 9744, loss = 0.75031 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:32:48.609309 ops/training.py:65 2019-01-17 03:32:48.609225: step 9745, loss = 0.63493 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:32:49.897939 ops/training.py:65 2019-01-17 03:32:49.897847: step 9746, loss = 0.64157 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:32:51.186954 ops/training.py:65 2019-01-17 03:32:51.186873: step 9747, loss = 0.65941 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:32:52.470489 ops/training.py:65 2019-01-17 03:32:52.470411: step 9748, loss = 0.64948 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:32:53.754829 ops/training.py:65 2019-01-17 03:32:53.754737: step 9749, loss = 0.70930 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:32:55.041611 ops/training.py:65 2019-01-17 03:32:55.041457: step 9750, loss = 0.74566 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:32:56.326019 ops/training.py:65 2019-01-17 03:32:56.325917: step 9751, loss = 0.68772 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:32:57.612104 ops/training.py:65 2019-01-17 03:32:57.611991: step 9752, loss = 0.70447 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:32:58.902598 ops/training.py:65 2019-01-17 03:32:58.902494: step 9753, loss = 0.62659 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:33:00.186176 ops/training.py:65 2019-01-17 03:33:00.186101: step 9754, loss = 0.73799 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:33:01.465751 ops/training.py:65 2019-01-17 03:33:01.465623: step 9755, loss = 0.68889 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:33:02.752006 ops/training.py:65 2019-01-17 03:33:02.751901: step 9756, loss = 0.63053 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:33:04.047347 ops/training.py:65 2019-01-17 03:33:04.047255: step 9757, loss = 0.67825 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:33:05.339162 ops/training.py:65 2019-01-17 03:33:05.339061: step 9758, loss = 0.61715 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:33:06.632630 ops/training.py:65 2019-01-17 03:33:06.632529: step 9759, loss = 0.72737 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:33:07.918471 ops/training.py:65 2019-01-17 03:33:07.918397: step 9760, loss = 0.66997 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:33:09.202637 ops/training.py:65 2019-01-17 03:33:09.202574: step 9761, loss = 0.61994 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:33:10.490473 ops/training.py:65 2019-01-17 03:33:10.490400: step 9762, loss = 0.65519 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:33:11.773838 ops/training.py:65 2019-01-17 03:33:11.773775: step 9763, loss = 0.67481 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:33:13.053701 ops/training.py:65 2019-01-17 03:33:13.053563: step 9764, loss = 0.76009 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:33:14.345818 ops/training.py:65 2019-01-17 03:33:14.345668: step 9765, loss = 0.63771 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:33:15.636114 ops/training.py:65 2019-01-17 03:33:15.636043: step 9766, loss = 0.66510 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:33:16.924401 ops/training.py:65 2019-01-17 03:33:16.924331: step 9767, loss = 0.64630 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:33:18.208496 ops/training.py:65 2019-01-17 03:33:18.208427: step 9768, loss = 0.64842 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:33:19.495295 ops/training.py:65 2019-01-17 03:33:19.495202: step 9769, loss = 0.64099 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:33:20.779627 ops/training.py:65 2019-01-17 03:33:20.779567: step 9770, loss = 0.69218 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:33:22.069050 ops/training.py:65 2019-01-17 03:33:22.068897: step 9771, loss = 0.64609 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:33:23.358739 ops/training.py:65 2019-01-17 03:33:23.358663: step 9772, loss = 0.63730 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:33:24.647000 ops/training.py:65 2019-01-17 03:33:24.646915: step 9773, loss = 0.66442 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:33:25.935518 ops/training.py:65 2019-01-17 03:33:25.935445: step 9774, loss = 0.65612 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:33:27.217910 ops/training.py:65 2019-01-17 03:33:27.217811: step 9775, loss = 0.63829 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:33:28.496393 ops/training.py:65 2019-01-17 03:33:28.496291: step 9776, loss = 0.64695 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:33:29.774512 ops/training.py:65 2019-01-17 03:33:29.774401: step 9777, loss = 0.68506 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:33:31.064467 ops/training.py:65 2019-01-17 03:33:31.064362: step 9778, loss = 0.69634 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:33:32.347821 ops/training.py:65 2019-01-17 03:33:32.347730: step 9779, loss = 0.62691 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:33:33.638748 ops/training.py:65 2019-01-17 03:33:33.638659: step 9780, loss = 0.65346 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:33:34.929736 ops/training.py:65 2019-01-17 03:33:34.929651: step 9781, loss = 0.66414 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:33:36.218464 ops/training.py:65 2019-01-17 03:33:36.218357: step 9782, loss = 0.67197 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:33:37.504152 ops/training.py:65 2019-01-17 03:33:37.504069: step 9783, loss = 0.72811 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:33:38.791717 ops/training.py:65 2019-01-17 03:33:38.791615: step 9784, loss = 0.58721 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:33:40.075338 ops/training.py:65 2019-01-17 03:33:40.075270: step 9785, loss = 0.64240 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:33:41.364395 ops/training.py:65 2019-01-17 03:33:41.364296: step 9786, loss = 0.66076 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:33:42.652650 ops/training.py:65 2019-01-17 03:33:42.652579: step 9787, loss = 0.76691 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:33:43.940888 ops/training.py:65 2019-01-17 03:33:43.940795: step 9788, loss = 0.70238 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:33:45.230174 ops/training.py:65 2019-01-17 03:33:45.230103: step 9789, loss = 0.67850 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:33:46.518435 ops/training.py:65 2019-01-17 03:33:46.518348: step 9790, loss = 0.60004 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:33:47.807394 ops/training.py:65 2019-01-17 03:33:47.807318: step 9791, loss = 0.65573 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:33:49.097326 ops/training.py:65 2019-01-17 03:33:49.097255: step 9792, loss = 0.64844 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:33:50.381743 ops/training.py:65 2019-01-17 03:33:50.381674: step 9793, loss = 0.70136 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:33:51.670650 ops/training.py:65 2019-01-17 03:33:51.670545: step 9794, loss = 0.62764 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:33:52.953377 ops/training.py:65 2019-01-17 03:33:52.953303: step 9795, loss = 0.66870 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:33:54.244507 ops/training.py:65 2019-01-17 03:33:54.244420: step 9796, loss = 0.68508 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:33:55.529776 ops/training.py:65 2019-01-17 03:33:55.529711: step 9797, loss = 0.65323 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:33:56.813581 ops/training.py:65 2019-01-17 03:33:56.813481: step 9798, loss = 0.65445 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:33:58.102969 ops/training.py:65 2019-01-17 03:33:58.102822: step 9799, loss = 0.66035 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:33:59.388500 ops/training.py:65 2019-01-17 03:33:59.388424: step 9800, loss = 0.64794 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:34:00.677233 ops/training.py:65 2019-01-17 03:34:00.677162: step 9801, loss = 0.66661 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:34:01.965760 ops/training.py:65 2019-01-17 03:34:01.965689: step 9802, loss = 0.62637 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:34:03.254953 ops/training.py:65 2019-01-17 03:34:03.254852: step 9803, loss = 0.62993 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:34:04.544059 ops/training.py:65 2019-01-17 03:34:04.543967: step 9804, loss = 0.68526 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:34:05.833510 ops/training.py:65 2019-01-17 03:34:05.833443: step 9805, loss = 0.64373 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:34:07.118986 ops/training.py:65 2019-01-17 03:34:07.118895: step 9806, loss = 0.64196 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:34:08.408851 ops/training.py:65 2019-01-17 03:34:08.408781: step 9807, loss = 0.69967 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:34:09.697869 ops/training.py:65 2019-01-17 03:34:09.697796: step 9808, loss = 0.66817 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:34:10.989791 ops/training.py:65 2019-01-17 03:34:10.989693: step 9809, loss = 0.63624 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:34:12.280211 ops/training.py:65 2019-01-17 03:34:12.280137: step 9810, loss = 0.71918 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:34:13.568866 ops/training.py:65 2019-01-17 03:34:13.568791: step 9811, loss = 0.66790 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:34:14.858427 ops/training.py:65 2019-01-17 03:34:14.858350: step 9812, loss = 0.76293 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 03:34:16.148052 ops/training.py:65 2019-01-17 03:34:16.147980: step 9813, loss = 0.65797 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:34:17.437037 ops/training.py:65 2019-01-17 03:34:17.436959: step 9814, loss = 0.73138 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:34:18.727792 ops/training.py:65 2019-01-17 03:34:18.727699: step 9815, loss = 0.75740 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:34:20.013243 ops/training.py:65 2019-01-17 03:34:20.013154: step 9816, loss = 0.65407 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:34:21.302217 ops/training.py:65 2019-01-17 03:34:21.302132: step 9817, loss = 0.67061 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:34:22.591545 ops/training.py:65 2019-01-17 03:34:22.591469: step 9818, loss = 0.67430 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:34:23.880727 ops/training.py:65 2019-01-17 03:34:23.880648: step 9819, loss = 0.62608 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:34:25.169290 ops/training.py:65 2019-01-17 03:34:25.169216: step 9820, loss = 0.64755 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:34:26.456190 ops/training.py:65 2019-01-17 03:34:26.456108: step 9821, loss = 0.68209 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:34:27.743702 ops/training.py:65 2019-01-17 03:34:27.743639: step 9822, loss = 0.63663 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:34:29.032310 ops/training.py:65 2019-01-17 03:34:29.032245: step 9823, loss = 0.63770 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:34:30.320204 ops/training.py:65 2019-01-17 03:34:30.320129: step 9824, loss = 0.65899 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:34:31.606075 ops/training.py:65 2019-01-17 03:34:31.606007: step 9825, loss = 0.65284 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:34:32.889506 ops/training.py:65 2019-01-17 03:34:32.889405: step 9826, loss = 0.59998 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:34:34.180480 ops/training.py:65 2019-01-17 03:34:34.180384: step 9827, loss = 0.68103 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:34:35.472856 ops/training.py:65 2019-01-17 03:34:35.472787: step 9828, loss = 0.69354 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:34:36.759744 ops/training.py:65 2019-01-17 03:34:36.759672: step 9829, loss = 0.72347 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:34:38.045157 ops/training.py:65 2019-01-17 03:34:38.045057: step 9830, loss = 0.68775 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:34:39.335208 ops/training.py:65 2019-01-17 03:34:39.335127: step 9831, loss = 0.62814 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:34:40.622861 ops/training.py:65 2019-01-17 03:34:40.622790: step 9832, loss = 0.68655 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:34:41.907681 ops/training.py:65 2019-01-17 03:34:41.907603: step 9833, loss = 0.68029 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:34:43.197106 ops/training.py:65 2019-01-17 03:34:43.197013: step 9834, loss = 0.67290 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:34:44.483182 ops/training.py:65 2019-01-17 03:34:44.483111: step 9835, loss = 0.72180 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:34:45.772023 ops/training.py:65 2019-01-17 03:34:45.771956: step 9836, loss = 0.68092 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:34:47.060038 ops/training.py:65 2019-01-17 03:34:47.059963: step 9837, loss = 0.76232 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.28125
I4672 2019-01-17 03:34:48.348987 ops/training.py:65 2019-01-17 03:34:48.348912: step 9838, loss = 0.65070 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:34:49.638329 ops/training.py:65 2019-01-17 03:34:49.638230: step 9839, loss = 0.67570 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:34:50.927131 ops/training.py:65 2019-01-17 03:34:50.927032: step 9840, loss = 0.69422 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:34:52.215918 ops/training.py:65 2019-01-17 03:34:52.215830: step 9841, loss = 0.58681 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:34:53.505824 ops/training.py:65 2019-01-17 03:34:53.505749: step 9842, loss = 0.64516 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:34:54.789645 ops/training.py:65 2019-01-17 03:34:54.789575: step 9843, loss = 0.73071 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:34:56.075265 ops/training.py:65 2019-01-17 03:34:56.075160: step 9844, loss = 0.62515 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:34:57.364566 ops/training.py:65 2019-01-17 03:34:57.364461: step 9845, loss = 0.69129 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:34:58.656412 ops/training.py:65 2019-01-17 03:34:58.656264: step 9846, loss = 0.69659 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:34:59.946749 ops/training.py:65 2019-01-17 03:34:59.946688: step 9847, loss = 0.60666 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:35:01.236246 ops/training.py:65 2019-01-17 03:35:01.236172: step 9848, loss = 0.63070 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:35:02.522145 ops/training.py:65 2019-01-17 03:35:02.522073: step 9849, loss = 0.66363 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:35:03.810213 ops/training.py:65 2019-01-17 03:35:03.810147: step 9850, loss = 0.72090 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:35:05.099258 ops/training.py:65 2019-01-17 03:35:05.099186: step 9851, loss = 0.63367 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:35:06.389032 ops/training.py:65 2019-01-17 03:35:06.388967: step 9852, loss = 0.61530 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:35:07.677683 ops/training.py:65 2019-01-17 03:35:07.677614: step 9853, loss = 0.67220 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:35:08.967579 ops/training.py:65 2019-01-17 03:35:08.967506: step 9854, loss = 0.72669 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:35:10.262611 ops/training.py:65 2019-01-17 03:35:10.262532: step 9855, loss = 0.65988 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:35:11.551739 ops/training.py:65 2019-01-17 03:35:11.551670: step 9856, loss = 0.67744 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:35:12.839826 ops/training.py:65 2019-01-17 03:35:12.839764: step 9857, loss = 0.67501 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:35:14.127057 ops/training.py:65 2019-01-17 03:35:14.126981: step 9858, loss = 0.68344 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:35:15.415849 ops/training.py:65 2019-01-17 03:35:15.415764: step 9859, loss = 0.67495 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:35:16.700653 ops/training.py:65 2019-01-17 03:35:16.700582: step 9860, loss = 0.65678 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:35:17.983718 ops/training.py:65 2019-01-17 03:35:17.983651: step 9861, loss = 0.62364 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:35:19.270397 ops/training.py:65 2019-01-17 03:35:19.270290: step 9862, loss = 0.67149 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:35:20.554707 ops/training.py:65 2019-01-17 03:35:20.554609: step 9863, loss = 0.77481 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:35:21.842856 ops/training.py:65 2019-01-17 03:35:21.842741: step 9864, loss = 0.69000 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:35:23.135008 ops/training.py:65 2019-01-17 03:35:23.134908: step 9865, loss = 0.60994 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:35:24.425537 ops/training.py:65 2019-01-17 03:35:24.425472: step 9866, loss = 0.71021 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:35:25.714641 ops/training.py:65 2019-01-17 03:35:25.714568: step 9867, loss = 0.70427 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:35:26.994865 ops/training.py:65 2019-01-17 03:35:26.994768: step 9868, loss = 0.73908 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:35:28.279012 ops/training.py:65 2019-01-17 03:35:28.278857: step 9869, loss = 0.63864 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:35:29.569921 ops/training.py:65 2019-01-17 03:35:29.569813: step 9870, loss = 0.68624 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:35:30.860191 ops/training.py:65 2019-01-17 03:35:30.860096: step 9871, loss = 0.69424 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:35:32.149512 ops/training.py:65 2019-01-17 03:35:32.149423: step 9872, loss = 0.69394 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:35:33.438167 ops/training.py:65 2019-01-17 03:35:33.438074: step 9873, loss = 0.65138 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:35:34.725683 ops/training.py:65 2019-01-17 03:35:34.725611: step 9874, loss = 0.67820 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:35:36.013413 ops/training.py:65 2019-01-17 03:35:36.013309: step 9875, loss = 0.63688 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:35:37.302739 ops/training.py:65 2019-01-17 03:35:37.302661: step 9876, loss = 0.64280 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:35:38.594204 ops/training.py:65 2019-01-17 03:35:38.594097: step 9877, loss = 0.60667 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:35:39.884350 ops/training.py:65 2019-01-17 03:35:39.884279: step 9878, loss = 0.65862 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:35:41.173127 ops/training.py:65 2019-01-17 03:35:41.173061: step 9879, loss = 0.69048 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:35:42.462865 ops/training.py:65 2019-01-17 03:35:42.462798: step 9880, loss = 0.70224 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:35:43.751652 ops/training.py:65 2019-01-17 03:35:43.751578: step 9881, loss = 0.70475 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:35:45.039549 ops/training.py:65 2019-01-17 03:35:45.039482: step 9882, loss = 0.64459 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:35:46.326074 ops/training.py:65 2019-01-17 03:35:46.325996: step 9883, loss = 0.63471 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:35:47.614543 ops/training.py:65 2019-01-17 03:35:47.614477: step 9884, loss = 0.66438 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:35:48.903403 ops/training.py:65 2019-01-17 03:35:48.903309: step 9885, loss = 0.68488 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:35:50.192297 ops/training.py:65 2019-01-17 03:35:50.192225: step 9886, loss = 0.71710 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:35:51.482470 ops/training.py:65 2019-01-17 03:35:51.482399: step 9887, loss = 0.69942 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:35:52.770515 ops/training.py:65 2019-01-17 03:35:52.770451: step 9888, loss = 0.69084 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:35:54.058889 ops/training.py:65 2019-01-17 03:35:54.058812: step 9889, loss = 0.67538 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:35:55.348150 ops/training.py:65 2019-01-17 03:35:55.348080: step 9890, loss = 0.68102 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:35:56.637050 ops/training.py:65 2019-01-17 03:35:56.636957: step 9891, loss = 0.72211 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:35:57.924503 ops/training.py:65 2019-01-17 03:35:57.924430: step 9892, loss = 0.67660 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:35:59.213694 ops/training.py:65 2019-01-17 03:35:59.213611: step 9893, loss = 0.63048 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:36:00.502870 ops/training.py:65 2019-01-17 03:36:00.502779: step 9894, loss = 0.72146 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:36:01.792229 ops/training.py:65 2019-01-17 03:36:01.792154: step 9895, loss = 0.70063 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:36:03.082438 ops/training.py:65 2019-01-17 03:36:03.082365: step 9896, loss = 0.69345 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:36:04.372128 ops/training.py:65 2019-01-17 03:36:04.372048: step 9897, loss = 0.72134 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:36:05.661257 ops/training.py:65 2019-01-17 03:36:05.661150: step 9898, loss = 0.73399 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:36:06.952106 ops/training.py:65 2019-01-17 03:36:06.952031: step 9899, loss = 0.75449 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:36:08.241689 ops/training.py:65 2019-01-17 03:36:08.241613: step 9900, loss = 0.69561 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:36:09.530121 ops/training.py:65 2019-01-17 03:36:09.530046: step 9901, loss = 0.71491 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:36:10.814698 ops/training.py:65 2019-01-17 03:36:10.814628: step 9902, loss = 0.64827 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:36:12.102127 ops/training.py:65 2019-01-17 03:36:12.102014: step 9903, loss = 0.74572 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:36:13.387519 ops/training.py:65 2019-01-17 03:36:13.387452: step 9904, loss = 0.66404 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:36:14.671123 ops/training.py:65 2019-01-17 03:36:14.671015: step 9905, loss = 0.72881 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:36:15.964482 ops/training.py:65 2019-01-17 03:36:15.964380: step 9906, loss = 0.65764 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:36:17.255713 ops/training.py:65 2019-01-17 03:36:17.255639: step 9907, loss = 0.66097 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:36:18.546786 ops/training.py:65 2019-01-17 03:36:18.546721: step 9908, loss = 0.67655 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:36:19.832547 ops/training.py:65 2019-01-17 03:36:19.832476: step 9909, loss = 0.63016 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:36:21.120929 ops/training.py:65 2019-01-17 03:36:21.120832: step 9910, loss = 0.66991 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:36:22.411488 ops/training.py:65 2019-01-17 03:36:22.411386: step 9911, loss = 0.65766 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:36:23.698270 ops/training.py:65 2019-01-17 03:36:23.698193: step 9912, loss = 0.61179 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:36:24.986530 ops/training.py:65 2019-01-17 03:36:24.986431: step 9913, loss = 0.68393 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:36:26.276020 ops/training.py:65 2019-01-17 03:36:26.275946: step 9914, loss = 0.74634 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:36:27.564922 ops/training.py:65 2019-01-17 03:36:27.564824: step 9915, loss = 0.63945 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:36:28.854803 ops/training.py:65 2019-01-17 03:36:28.854742: step 9916, loss = 0.62642 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:36:30.142787 ops/training.py:65 2019-01-17 03:36:30.142720: step 9917, loss = 0.61368 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:36:31.427199 ops/training.py:65 2019-01-17 03:36:31.427116: step 9918, loss = 0.68868 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:36:32.716723 ops/training.py:65 2019-01-17 03:36:32.716576: step 9919, loss = 0.66393 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:36:34.006216 ops/training.py:65 2019-01-17 03:36:34.006143: step 9920, loss = 0.60996 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:36:35.294838 ops/training.py:65 2019-01-17 03:36:35.294771: step 9921, loss = 0.70341 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:36:36.583031 ops/training.py:65 2019-01-17 03:36:36.582970: step 9922, loss = 0.63348 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:36:37.865984 ops/training.py:65 2019-01-17 03:36:37.865923: step 9923, loss = 0.58287 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:36:39.153353 ops/training.py:65 2019-01-17 03:36:39.153284: step 9924, loss = 0.72863 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:36:40.440269 ops/training.py:65 2019-01-17 03:36:40.440186: step 9925, loss = 0.67660 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:36:41.729887 ops/training.py:65 2019-01-17 03:36:41.729821: step 9926, loss = 0.65551 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:36:43.017875 ops/training.py:65 2019-01-17 03:36:43.017809: step 9927, loss = 0.60219 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:36:44.301640 ops/training.py:65 2019-01-17 03:36:44.301563: step 9928, loss = 0.66565 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:36:45.590055 ops/training.py:65 2019-01-17 03:36:45.589947: step 9929, loss = 0.68551 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:36:46.880895 ops/training.py:65 2019-01-17 03:36:46.880789: step 9930, loss = 0.64289 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:36:48.173130 ops/training.py:65 2019-01-17 03:36:48.173055: step 9931, loss = 0.66136 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:36:49.461857 ops/training.py:65 2019-01-17 03:36:49.461799: step 9932, loss = 0.64585 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:36:50.751125 ops/training.py:65 2019-01-17 03:36:50.751056: step 9933, loss = 0.77282 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 03:36:52.035545 ops/training.py:65 2019-01-17 03:36:52.035480: step 9934, loss = 0.58456 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:36:53.327365 ops/training.py:65 2019-01-17 03:36:53.327240: step 9935, loss = 0.67464 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:36:54.618984 ops/training.py:65 2019-01-17 03:36:54.618894: step 9936, loss = 0.64501 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:36:55.908697 ops/training.py:65 2019-01-17 03:36:55.908625: step 9937, loss = 0.65215 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:36:57.197295 ops/training.py:65 2019-01-17 03:36:57.197224: step 9938, loss = 0.66009 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:36:58.476343 ops/training.py:65 2019-01-17 03:36:58.476279: step 9939, loss = 0.63224 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:36:59.758696 ops/training.py:65 2019-01-17 03:36:59.758593: step 9940, loss = 0.72865 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:37:01.047007 ops/training.py:65 2019-01-17 03:37:01.046909: step 9941, loss = 0.64011 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:37:02.338102 ops/training.py:65 2019-01-17 03:37:02.338032: step 9942, loss = 0.64742 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:37:03.625012 ops/training.py:65 2019-01-17 03:37:03.624946: step 9943, loss = 0.65294 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:37:04.908649 ops/training.py:65 2019-01-17 03:37:04.908580: step 9944, loss = 0.66751 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:37:06.188887 ops/training.py:65 2019-01-17 03:37:06.188788: step 9945, loss = 0.72071 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:37:07.480947 ops/training.py:65 2019-01-17 03:37:07.480844: step 9946, loss = 0.63761 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:37:08.771376 ops/training.py:65 2019-01-17 03:37:08.771303: step 9947, loss = 0.66080 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:37:10.058012 ops/training.py:65 2019-01-17 03:37:10.057942: step 9948, loss = 0.69511 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:37:11.345725 ops/training.py:65 2019-01-17 03:37:11.345658: step 9949, loss = 0.72598 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:37:12.633890 ops/training.py:65 2019-01-17 03:37:12.633820: step 9950, loss = 0.69176 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:37:13.917097 ops/training.py:65 2019-01-17 03:37:13.917028: step 9951, loss = 0.70238 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:37:15.202218 ops/training.py:65 2019-01-17 03:37:15.202120: step 9952, loss = 0.65441 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:37:16.493062 ops/training.py:65 2019-01-17 03:37:16.492958: step 9953, loss = 0.58491 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:37:17.778393 ops/training.py:65 2019-01-17 03:37:17.778327: step 9954, loss = 0.69075 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:37:19.063888 ops/training.py:65 2019-01-17 03:37:19.063792: step 9955, loss = 0.66124 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:37:20.350175 ops/training.py:65 2019-01-17 03:37:20.350071: step 9956, loss = 0.67784 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:37:21.631080 ops/training.py:65 2019-01-17 03:37:21.630978: step 9957, loss = 0.62665 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:37:22.923172 ops/training.py:65 2019-01-17 03:37:22.923066: step 9958, loss = 0.66474 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:37:24.207944 ops/training.py:65 2019-01-17 03:37:24.207878: step 9959, loss = 0.64756 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:37:25.487786 ops/training.py:65 2019-01-17 03:37:25.487690: step 9960, loss = 0.64635 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:37:26.779872 ops/training.py:65 2019-01-17 03:37:26.779768: step 9961, loss = 0.66283 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:37:28.066294 ops/training.py:65 2019-01-17 03:37:28.066224: step 9962, loss = 0.65076 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:37:29.355211 ops/training.py:65 2019-01-17 03:37:29.355149: step 9963, loss = 0.68866 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:37:30.643809 ops/training.py:65 2019-01-17 03:37:30.643738: step 9964, loss = 0.73465 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:37:31.932449 ops/training.py:65 2019-01-17 03:37:31.932381: step 9965, loss = 0.61090 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:37:33.220796 ops/training.py:65 2019-01-17 03:37:33.220737: step 9966, loss = 0.64272 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:37:34.504761 ops/training.py:65 2019-01-17 03:37:34.504700: step 9967, loss = 0.71710 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:37:35.792576 ops/training.py:65 2019-01-17 03:37:35.792508: step 9968, loss = 0.70496 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:37:37.081514 ops/training.py:65 2019-01-17 03:37:37.081433: step 9969, loss = 0.68965 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:37:38.370284 ops/training.py:65 2019-01-17 03:37:38.370221: step 9970, loss = 0.69937 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:37:39.657802 ops/training.py:65 2019-01-17 03:37:39.657732: step 9971, loss = 0.70672 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:37:40.941755 ops/training.py:65 2019-01-17 03:37:40.941682: step 9972, loss = 0.67728 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:37:42.228962 ops/training.py:65 2019-01-17 03:37:42.228896: step 9973, loss = 0.63423 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:37:43.517656 ops/training.py:65 2019-01-17 03:37:43.517561: step 9974, loss = 0.70155 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:37:44.807000 ops/training.py:65 2019-01-17 03:37:44.806917: step 9975, loss = 0.65585 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:37:46.095827 ops/training.py:65 2019-01-17 03:37:46.095756: step 9976, loss = 0.71302 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:37:47.385595 ops/training.py:65 2019-01-17 03:37:47.385525: step 9977, loss = 0.61745 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:37:48.673165 ops/training.py:65 2019-01-17 03:37:48.673082: step 9978, loss = 0.70070 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:37:49.953359 ops/training.py:65 2019-01-17 03:37:49.953303: step 9979, loss = 0.67610 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:37:51.242031 ops/training.py:65 2019-01-17 03:37:51.241939: step 9980, loss = 0.67743 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:37:52.531887 ops/training.py:65 2019-01-17 03:37:52.531813: step 9981, loss = 0.66064 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:37:53.820380 ops/training.py:65 2019-01-17 03:37:53.820281: step 9982, loss = 0.67444 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:37:55.109662 ops/training.py:65 2019-01-17 03:37:55.109593: step 9983, loss = 0.68185 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:37:56.405456 ops/training.py:65 2019-01-17 03:37:56.405388: step 9984, loss = 0.67270 (24.7 examples/sec; 1.295 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:37:57.689989 ops/training.py:65 2019-01-17 03:37:57.689919: step 9985, loss = 0.68618 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:37:58.974029 ops/training.py:65 2019-01-17 03:37:58.973960: step 9986, loss = 0.65831 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:38:00.259118 ops/training.py:65 2019-01-17 03:38:00.259056: step 9987, loss = 0.67183 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:38:01.543056 ops/training.py:65 2019-01-17 03:38:01.542954: step 9988, loss = 0.67659 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:38:02.826420 ops/training.py:65 2019-01-17 03:38:02.826310: step 9989, loss = 0.67576 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:38:04.112661 ops/training.py:65 2019-01-17 03:38:04.112561: step 9990, loss = 0.57836 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:38:05.392509 ops/training.py:65 2019-01-17 03:38:05.392400: step 9991, loss = 0.62327 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:38:06.676180 ops/training.py:65 2019-01-17 03:38:06.676068: step 9992, loss = 0.65048 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:38:07.958948 ops/training.py:65 2019-01-17 03:38:07.958839: step 9993, loss = 0.64276 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:38:09.245902 ops/training.py:65 2019-01-17 03:38:09.245794: step 9994, loss = 0.67293 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:38:10.536100 ops/training.py:65 2019-01-17 03:38:10.535987: step 9995, loss = 0.60543 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:38:11.823029 ops/training.py:65 2019-01-17 03:38:11.822934: step 9996, loss = 0.74210 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:38:13.112440 ops/training.py:65 2019-01-17 03:38:13.112366: step 9997, loss = 0.66698 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:38:14.402092 ops/training.py:65 2019-01-17 03:38:14.402006: step 9998, loss = 0.70287 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:38:15.692365 ops/training.py:65 2019-01-17 03:38:15.692271: step 9999, loss = 0.66650 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:44:21.208972 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I4672 2019-01-17 03:44:21.210148 ops/training.py:41 2019-01-17 03:44:21.210078: step 10000, loss = 0.56 (0.1 examples/sec; 364.228 sec/batch) | Training accuracy = 0.8125 | Validation accuracy = 0.51835 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_23_33_01_706250
I4672 2019-01-17 03:44:22.501571 ops/training.py:65 2019-01-17 03:44:22.501431: step 10001, loss = 0.70190 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:44:23.786570 ops/training.py:65 2019-01-17 03:44:23.786472: step 10002, loss = 0.68978 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:44:25.076225 ops/training.py:65 2019-01-17 03:44:25.076069: step 10003, loss = 0.72977 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:44:26.367057 ops/training.py:65 2019-01-17 03:44:26.366987: step 10004, loss = 0.68480 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:44:27.652287 ops/training.py:65 2019-01-17 03:44:27.652182: step 10005, loss = 0.68182 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:44:28.936042 ops/training.py:65 2019-01-17 03:44:28.935978: step 10006, loss = 0.65326 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:44:30.222128 ops/training.py:65 2019-01-17 03:44:30.222013: step 10007, loss = 0.70428 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:44:31.515094 ops/training.py:65 2019-01-17 03:44:31.514986: step 10008, loss = 0.73304 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:44:32.808039 ops/training.py:65 2019-01-17 03:44:32.807969: step 10009, loss = 0.67076 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:44:34.093812 ops/training.py:65 2019-01-17 03:44:34.093738: step 10010, loss = 0.62554 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:44:35.384345 ops/training.py:65 2019-01-17 03:44:35.384249: step 10011, loss = 0.78876 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:44:36.674082 ops/training.py:65 2019-01-17 03:44:36.674016: step 10012, loss = 0.75281 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:44:37.962319 ops/training.py:65 2019-01-17 03:44:37.962235: step 10013, loss = 0.75916 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:44:39.250075 ops/training.py:65 2019-01-17 03:44:39.250010: step 10014, loss = 0.70107 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:44:40.537714 ops/training.py:65 2019-01-17 03:44:40.537641: step 10015, loss = 0.72106 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:44:41.825101 ops/training.py:65 2019-01-17 03:44:41.825021: step 10016, loss = 0.65565 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:44:43.109496 ops/training.py:65 2019-01-17 03:44:43.109428: step 10017, loss = 0.69420 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:44:44.395010 ops/training.py:65 2019-01-17 03:44:44.394899: step 10018, loss = 0.70117 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:44:45.685355 ops/training.py:65 2019-01-17 03:44:45.685285: step 10019, loss = 0.65396 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:44:46.973693 ops/training.py:65 2019-01-17 03:44:46.973623: step 10020, loss = 0.66748 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:44:48.262438 ops/training.py:65 2019-01-17 03:44:48.262372: step 10021, loss = 0.63987 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:44:49.550752 ops/training.py:65 2019-01-17 03:44:49.550689: step 10022, loss = 0.68757 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:44:50.839472 ops/training.py:65 2019-01-17 03:44:50.839404: step 10023, loss = 0.70386 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:44:52.129124 ops/training.py:65 2019-01-17 03:44:52.129051: step 10024, loss = 0.63761 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:44:53.414111 ops/training.py:65 2019-01-17 03:44:53.414047: step 10025, loss = 0.64936 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:44:54.702217 ops/training.py:65 2019-01-17 03:44:54.702120: step 10026, loss = 0.75887 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:44:55.986353 ops/training.py:65 2019-01-17 03:44:55.986284: step 10027, loss = 0.67730 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:44:57.270900 ops/training.py:65 2019-01-17 03:44:57.270792: step 10028, loss = 0.71893 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:44:58.564252 ops/training.py:65 2019-01-17 03:44:58.564146: step 10029, loss = 0.63398 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:44:59.854518 ops/training.py:65 2019-01-17 03:44:59.854449: step 10030, loss = 0.70517 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:45:01.144536 ops/training.py:65 2019-01-17 03:45:01.144472: step 10031, loss = 0.64052 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:45:02.432021 ops/training.py:65 2019-01-17 03:45:02.431951: step 10032, loss = 0.61522 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:45:03.711805 ops/training.py:65 2019-01-17 03:45:03.711742: step 10033, loss = 0.68759 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:45:05.000434 ops/training.py:65 2019-01-17 03:45:05.000360: step 10034, loss = 0.68354 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:45:06.288988 ops/training.py:65 2019-01-17 03:45:06.288875: step 10035, loss = 0.71340 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:45:07.577499 ops/training.py:65 2019-01-17 03:45:07.577417: step 10036, loss = 0.62893 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:45:08.861782 ops/training.py:65 2019-01-17 03:45:08.861705: step 10037, loss = 0.69944 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:45:10.147161 ops/training.py:65 2019-01-17 03:45:10.147062: step 10038, loss = 0.68524 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:45:11.434255 ops/training.py:65 2019-01-17 03:45:11.434146: step 10039, loss = 0.68579 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:45:12.720942 ops/training.py:65 2019-01-17 03:45:12.720783: step 10040, loss = 0.63081 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:45:14.013413 ops/training.py:65 2019-01-17 03:45:14.013306: step 10041, loss = 0.65393 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:45:15.301363 ops/training.py:65 2019-01-17 03:45:15.301291: step 10042, loss = 0.65985 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:45:16.586681 ops/training.py:65 2019-01-17 03:45:16.586614: step 10043, loss = 0.69523 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:45:17.870259 ops/training.py:65 2019-01-17 03:45:17.870109: step 10044, loss = 0.63833 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:45:19.167679 ops/training.py:65 2019-01-17 03:45:19.167539: step 10045, loss = 0.58085 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:45:20.455987 ops/training.py:65 2019-01-17 03:45:20.455900: step 10046, loss = 0.70270 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:45:21.746636 ops/training.py:65 2019-01-17 03:45:21.746562: step 10047, loss = 0.75645 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:45:23.034615 ops/training.py:65 2019-01-17 03:45:23.034521: step 10048, loss = 0.67822 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:45:24.323246 ops/training.py:65 2019-01-17 03:45:24.323177: step 10049, loss = 0.64587 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:45:25.612644 ops/training.py:65 2019-01-17 03:45:25.612537: step 10050, loss = 0.59911 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:45:26.897760 ops/training.py:65 2019-01-17 03:45:26.897679: step 10051, loss = 0.63366 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:45:28.182999 ops/training.py:65 2019-01-17 03:45:28.182912: step 10052, loss = 0.69882 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:45:29.469944 ops/training.py:65 2019-01-17 03:45:29.469831: step 10053, loss = 0.64348 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:45:30.755136 ops/training.py:65 2019-01-17 03:45:30.755061: step 10054, loss = 0.66715 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:45:32.042249 ops/training.py:65 2019-01-17 03:45:32.042143: step 10055, loss = 0.59651 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:45:33.329474 ops/training.py:65 2019-01-17 03:45:33.329410: step 10056, loss = 0.63886 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:45:34.620052 ops/training.py:65 2019-01-17 03:45:34.619941: step 10057, loss = 0.61519 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:45:35.910340 ops/training.py:65 2019-01-17 03:45:35.910277: step 10058, loss = 0.64493 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:45:37.199966 ops/training.py:65 2019-01-17 03:45:37.199892: step 10059, loss = 0.56042 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 03:45:38.483747 ops/training.py:65 2019-01-17 03:45:38.483684: step 10060, loss = 0.64195 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:45:39.764478 ops/training.py:65 2019-01-17 03:45:39.764374: step 10061, loss = 0.74201 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:45:41.055990 ops/training.py:65 2019-01-17 03:45:41.055889: step 10062, loss = 0.67714 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:45:42.347926 ops/training.py:65 2019-01-17 03:45:42.347839: step 10063, loss = 0.69546 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:45:43.631590 ops/training.py:65 2019-01-17 03:45:43.631518: step 10064, loss = 0.64201 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:45:44.915488 ops/training.py:65 2019-01-17 03:45:44.915384: step 10065, loss = 0.65283 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:45:46.207404 ops/training.py:65 2019-01-17 03:45:46.207296: step 10066, loss = 0.65274 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:45:47.498703 ops/training.py:65 2019-01-17 03:45:47.498621: step 10067, loss = 0.73965 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:45:48.788460 ops/training.py:65 2019-01-17 03:45:48.788395: step 10068, loss = 0.65138 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:45:50.077740 ops/training.py:65 2019-01-17 03:45:50.077668: step 10069, loss = 0.64713 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:45:51.361669 ops/training.py:65 2019-01-17 03:45:51.361607: step 10070, loss = 0.66406 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:45:52.646114 ops/training.py:65 2019-01-17 03:45:52.646007: step 10071, loss = 0.66642 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:45:53.933483 ops/training.py:65 2019-01-17 03:45:53.933387: step 10072, loss = 0.62781 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:45:55.220519 ops/training.py:65 2019-01-17 03:45:55.220411: step 10073, loss = 0.65854 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:45:56.508854 ops/training.py:65 2019-01-17 03:45:56.508742: step 10074, loss = 0.65902 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:45:57.800809 ops/training.py:65 2019-01-17 03:45:57.800676: step 10075, loss = 0.63549 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:45:59.091720 ops/training.py:65 2019-01-17 03:45:59.091658: step 10076, loss = 0.58555 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:46:00.381085 ops/training.py:65 2019-01-17 03:46:00.380995: step 10077, loss = 0.63911 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:46:01.665717 ops/training.py:65 2019-01-17 03:46:01.665657: step 10078, loss = 0.68727 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:46:02.953461 ops/training.py:65 2019-01-17 03:46:02.953354: step 10079, loss = 0.65189 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:46:04.244703 ops/training.py:65 2019-01-17 03:46:04.244608: step 10080, loss = 0.63427 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:46:05.533776 ops/training.py:65 2019-01-17 03:46:05.533697: step 10081, loss = 0.65507 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:46:06.819033 ops/training.py:65 2019-01-17 03:46:06.818963: step 10082, loss = 0.66027 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:46:08.106636 ops/training.py:65 2019-01-17 03:46:08.106567: step 10083, loss = 0.71437 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:46:09.395026 ops/training.py:65 2019-01-17 03:46:09.394960: step 10084, loss = 0.69203 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:46:10.684414 ops/training.py:65 2019-01-17 03:46:10.684331: step 10085, loss = 0.68928 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:46:11.974608 ops/training.py:65 2019-01-17 03:46:11.974524: step 10086, loss = 0.72532 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:46:13.259785 ops/training.py:65 2019-01-17 03:46:13.259715: step 10087, loss = 0.65584 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:46:14.550415 ops/training.py:65 2019-01-17 03:46:14.550317: step 10088, loss = 0.63729 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:46:15.839517 ops/training.py:65 2019-01-17 03:46:15.839449: step 10089, loss = 0.67081 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:46:17.128516 ops/training.py:65 2019-01-17 03:46:17.128439: step 10090, loss = 0.70169 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:46:18.418407 ops/training.py:65 2019-01-17 03:46:18.418348: step 10091, loss = 0.66951 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:46:19.704499 ops/training.py:65 2019-01-17 03:46:19.704410: step 10092, loss = 0.75462 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:46:20.991714 ops/training.py:65 2019-01-17 03:46:20.991616: step 10093, loss = 0.78053 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:46:22.277475 ops/training.py:65 2019-01-17 03:46:22.277368: step 10094, loss = 0.67638 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:46:23.570002 ops/training.py:65 2019-01-17 03:46:23.569888: step 10095, loss = 0.76722 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:46:24.859152 ops/training.py:65 2019-01-17 03:46:24.859092: step 10096, loss = 0.78383 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:46:26.148310 ops/training.py:65 2019-01-17 03:46:26.148244: step 10097, loss = 0.71972 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:46:27.436113 ops/training.py:65 2019-01-17 03:46:27.436029: step 10098, loss = 0.76110 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:46:28.724897 ops/training.py:65 2019-01-17 03:46:28.724826: step 10099, loss = 0.62489 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:46:30.013235 ops/training.py:65 2019-01-17 03:46:30.013166: step 10100, loss = 0.62240 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:46:31.301878 ops/training.py:65 2019-01-17 03:46:31.301811: step 10101, loss = 0.63081 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:46:32.590995 ops/training.py:65 2019-01-17 03:46:32.590918: step 10102, loss = 0.59084 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:46:33.880585 ops/training.py:65 2019-01-17 03:46:33.880513: step 10103, loss = 0.62035 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:46:35.162018 ops/training.py:65 2019-01-17 03:46:35.161950: step 10104, loss = 0.59989 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:46:36.451413 ops/training.py:65 2019-01-17 03:46:36.451257: step 10105, loss = 0.60475 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:46:37.740750 ops/training.py:65 2019-01-17 03:46:37.740681: step 10106, loss = 0.64443 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:46:39.029257 ops/training.py:65 2019-01-17 03:46:39.029194: step 10107, loss = 0.62728 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:46:40.318446 ops/training.py:65 2019-01-17 03:46:40.318373: step 10108, loss = 0.69214 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:46:41.601328 ops/training.py:65 2019-01-17 03:46:41.601266: step 10109, loss = 0.68285 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:46:42.884949 ops/training.py:65 2019-01-17 03:46:42.884845: step 10110, loss = 0.60548 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:46:44.178556 ops/training.py:65 2019-01-17 03:46:44.178408: step 10111, loss = 0.65931 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:46:45.470918 ops/training.py:65 2019-01-17 03:46:45.470850: step 10112, loss = 0.71608 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:46:46.755362 ops/training.py:65 2019-01-17 03:46:46.755283: step 10113, loss = 0.62230 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:46:48.044588 ops/training.py:65 2019-01-17 03:46:48.044486: step 10114, loss = 0.68921 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:46:49.335357 ops/training.py:65 2019-01-17 03:46:49.335271: step 10115, loss = 0.65636 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:46:50.623028 ops/training.py:65 2019-01-17 03:46:50.622965: step 10116, loss = 0.67639 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:46:51.910740 ops/training.py:65 2019-01-17 03:46:51.910675: step 10117, loss = 0.67174 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:46:53.198031 ops/training.py:65 2019-01-17 03:46:53.197965: step 10118, loss = 0.68091 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:46:54.479424 ops/training.py:65 2019-01-17 03:46:54.479361: step 10119, loss = 0.64136 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:46:55.768542 ops/training.py:65 2019-01-17 03:46:55.768434: step 10120, loss = 0.66648 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:46:57.057824 ops/training.py:65 2019-01-17 03:46:57.057757: step 10121, loss = 0.62818 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:46:58.346562 ops/training.py:65 2019-01-17 03:46:58.346497: step 10122, loss = 0.71340 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:46:59.635018 ops/training.py:65 2019-01-17 03:46:59.634958: step 10123, loss = 0.64061 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:47:00.924320 ops/training.py:65 2019-01-17 03:47:00.924261: step 10124, loss = 0.61530 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:47:02.211367 ops/training.py:65 2019-01-17 03:47:02.211296: step 10125, loss = 0.69700 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:47:03.499547 ops/training.py:65 2019-01-17 03:47:03.499479: step 10126, loss = 0.72293 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:47:04.788118 ops/training.py:65 2019-01-17 03:47:04.788047: step 10127, loss = 0.69428 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:47:06.068510 ops/training.py:65 2019-01-17 03:47:06.068446: step 10128, loss = 0.63699 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:47:07.357471 ops/training.py:65 2019-01-17 03:47:07.357393: step 10129, loss = 0.63355 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:47:08.642377 ops/training.py:65 2019-01-17 03:47:08.642308: step 10130, loss = 0.70045 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:47:09.928666 ops/training.py:65 2019-01-17 03:47:09.928555: step 10131, loss = 0.65575 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:47:11.222961 ops/training.py:65 2019-01-17 03:47:11.222860: step 10132, loss = 0.63022 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:47:12.507656 ops/training.py:65 2019-01-17 03:47:12.507595: step 10133, loss = 0.63582 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:47:13.791710 ops/training.py:65 2019-01-17 03:47:13.791644: step 10134, loss = 0.64764 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:47:15.080587 ops/training.py:65 2019-01-17 03:47:15.080484: step 10135, loss = 0.61004 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:47:16.369403 ops/training.py:65 2019-01-17 03:47:16.369334: step 10136, loss = 0.61818 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:47:17.658345 ops/training.py:65 2019-01-17 03:47:17.658281: step 10137, loss = 0.68141 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:47:18.942841 ops/training.py:65 2019-01-17 03:47:18.942776: step 10138, loss = 0.64926 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:47:20.233345 ops/training.py:65 2019-01-17 03:47:20.233225: step 10139, loss = 0.63108 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:47:21.522842 ops/training.py:65 2019-01-17 03:47:21.522758: step 10140, loss = 0.64146 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:47:22.811805 ops/training.py:65 2019-01-17 03:47:22.811745: step 10141, loss = 0.65104 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:47:24.100166 ops/training.py:65 2019-01-17 03:47:24.100093: step 10142, loss = 0.61408 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:47:25.384567 ops/training.py:65 2019-01-17 03:47:25.384506: step 10143, loss = 0.65567 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:47:26.672355 ops/training.py:65 2019-01-17 03:47:26.672249: step 10144, loss = 0.65706 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:47:27.962104 ops/training.py:65 2019-01-17 03:47:27.962034: step 10145, loss = 0.58266 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:47:29.245728 ops/training.py:65 2019-01-17 03:47:29.245668: step 10146, loss = 0.62794 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:47:30.529930 ops/training.py:65 2019-01-17 03:47:30.529863: step 10147, loss = 0.58560 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:47:31.816959 ops/training.py:65 2019-01-17 03:47:31.816898: step 10148, loss = 0.65808 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:47:33.106496 ops/training.py:65 2019-01-17 03:47:33.106400: step 10149, loss = 0.75990 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.3125
I4672 2019-01-17 03:47:34.395696 ops/training.py:65 2019-01-17 03:47:34.395599: step 10150, loss = 0.64191 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:47:35.684201 ops/training.py:65 2019-01-17 03:47:35.684138: step 10151, loss = 0.65692 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:47:36.964593 ops/training.py:65 2019-01-17 03:47:36.964529: step 10152, loss = 0.62297 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:47:38.252051 ops/training.py:65 2019-01-17 03:47:38.251992: step 10153, loss = 0.64676 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:47:39.537174 ops/training.py:65 2019-01-17 03:47:39.537113: step 10154, loss = 0.63654 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:47:40.821081 ops/training.py:65 2019-01-17 03:47:40.820979: step 10155, loss = 0.60876 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:47:42.109857 ops/training.py:65 2019-01-17 03:47:42.109757: step 10156, loss = 0.61083 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:47:43.400652 ops/training.py:65 2019-01-17 03:47:43.400550: step 10157, loss = 0.67914 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:47:44.686476 ops/training.py:65 2019-01-17 03:47:44.686412: step 10158, loss = 0.70305 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:47:45.969556 ops/training.py:65 2019-01-17 03:47:45.969456: step 10159, loss = 0.65656 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:47:47.261490 ops/training.py:65 2019-01-17 03:47:47.261381: step 10160, loss = 0.65433 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:47:48.547436 ops/training.py:65 2019-01-17 03:47:48.547372: step 10161, loss = 0.76561 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:47:49.833245 ops/training.py:65 2019-01-17 03:47:49.833144: step 10162, loss = 0.67757 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:47:51.119178 ops/training.py:65 2019-01-17 03:47:51.119114: step 10163, loss = 0.69215 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:47:52.407767 ops/training.py:65 2019-01-17 03:47:52.407664: step 10164, loss = 0.66198 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:47:53.696621 ops/training.py:65 2019-01-17 03:47:53.696548: step 10165, loss = 0.65905 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:47:54.980348 ops/training.py:65 2019-01-17 03:47:54.980284: step 10166, loss = 0.65996 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:47:56.270123 ops/training.py:65 2019-01-17 03:47:56.270021: step 10167, loss = 0.63681 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:47:57.558849 ops/training.py:65 2019-01-17 03:47:57.558785: step 10168, loss = 0.57542 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:47:58.846872 ops/training.py:65 2019-01-17 03:47:58.846799: step 10169, loss = 0.60437 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:48:00.133351 ops/training.py:65 2019-01-17 03:48:00.133291: step 10170, loss = 0.62481 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:48:01.423616 ops/training.py:65 2019-01-17 03:48:01.423524: step 10171, loss = 0.72158 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:48:02.711591 ops/training.py:65 2019-01-17 03:48:02.711515: step 10172, loss = 0.71729 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:48:03.998963 ops/training.py:65 2019-01-17 03:48:03.998888: step 10173, loss = 0.62059 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:48:05.283064 ops/training.py:65 2019-01-17 03:48:05.283001: step 10174, loss = 0.59274 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:48:06.568341 ops/training.py:65 2019-01-17 03:48:06.568243: step 10175, loss = 0.61987 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:48:07.854737 ops/training.py:65 2019-01-17 03:48:07.854639: step 10176, loss = 0.71043 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:48:09.136013 ops/training.py:65 2019-01-17 03:48:09.135907: step 10177, loss = 0.69254 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:48:10.428081 ops/training.py:65 2019-01-17 03:48:10.427933: step 10178, loss = 0.65059 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:48:11.715541 ops/training.py:65 2019-01-17 03:48:11.715478: step 10179, loss = 0.69116 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:48:12.996907 ops/training.py:65 2019-01-17 03:48:12.996793: step 10180, loss = 0.72337 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:48:14.282966 ops/training.py:65 2019-01-17 03:48:14.282827: step 10181, loss = 0.65345 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:48:15.573193 ops/training.py:65 2019-01-17 03:48:15.573041: step 10182, loss = 0.69608 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:48:16.864818 ops/training.py:65 2019-01-17 03:48:16.864734: step 10183, loss = 0.68783 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:48:18.149261 ops/training.py:65 2019-01-17 03:48:18.149180: step 10184, loss = 0.63247 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:48:19.439664 ops/training.py:65 2019-01-17 03:48:19.439560: step 10185, loss = 0.65161 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:48:20.729681 ops/training.py:65 2019-01-17 03:48:20.729620: step 10186, loss = 0.75158 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:48:22.015327 ops/training.py:65 2019-01-17 03:48:22.015215: step 10187, loss = 0.60445 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 03:48:23.298261 ops/training.py:65 2019-01-17 03:48:23.298162: step 10188, loss = 0.69197 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:48:24.581323 ops/training.py:65 2019-01-17 03:48:24.581215: step 10189, loss = 0.66491 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:48:25.871783 ops/training.py:65 2019-01-17 03:48:25.871673: step 10190, loss = 0.66685 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:48:27.162490 ops/training.py:65 2019-01-17 03:48:27.162415: step 10191, loss = 0.82147 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 03:48:28.450494 ops/training.py:65 2019-01-17 03:48:28.450430: step 10192, loss = 0.68426 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:48:29.734852 ops/training.py:65 2019-01-17 03:48:29.734782: step 10193, loss = 0.61445 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:48:31.018665 ops/training.py:65 2019-01-17 03:48:31.018565: step 10194, loss = 0.62872 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:48:32.306781 ops/training.py:65 2019-01-17 03:48:32.306666: step 10195, loss = 0.70548 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:48:33.593955 ops/training.py:65 2019-01-17 03:48:33.593857: step 10196, loss = 0.67095 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:48:34.885597 ops/training.py:65 2019-01-17 03:48:34.885499: step 10197, loss = 0.66220 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:48:36.175875 ops/training.py:65 2019-01-17 03:48:36.175783: step 10198, loss = 0.68009 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:48:37.464729 ops/training.py:65 2019-01-17 03:48:37.464661: step 10199, loss = 0.55948 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 03:48:38.753360 ops/training.py:65 2019-01-17 03:48:38.753289: step 10200, loss = 0.82535 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 03:48:40.037750 ops/training.py:65 2019-01-17 03:48:40.037685: step 10201, loss = 0.64343 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:48:41.324216 ops/training.py:65 2019-01-17 03:48:41.324088: step 10202, loss = 0.68603 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:48:42.613208 ops/training.py:65 2019-01-17 03:48:42.613139: step 10203, loss = 0.65641 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:48:43.902521 ops/training.py:65 2019-01-17 03:48:43.902452: step 10204, loss = 0.68274 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:48:45.186617 ops/training.py:65 2019-01-17 03:48:45.186554: step 10205, loss = 0.67037 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:48:46.474990 ops/training.py:65 2019-01-17 03:48:46.474929: step 10206, loss = 0.64258 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:48:47.759148 ops/training.py:65 2019-01-17 03:48:47.759084: step 10207, loss = 0.73103 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:48:49.048235 ops/training.py:65 2019-01-17 03:48:49.048171: step 10208, loss = 0.63498 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:48:50.331325 ops/training.py:65 2019-01-17 03:48:50.331262: step 10209, loss = 0.71692 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:48:51.616577 ops/training.py:65 2019-01-17 03:48:51.616508: step 10210, loss = 0.65765 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:48:52.904669 ops/training.py:65 2019-01-17 03:48:52.904610: step 10211, loss = 0.71926 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:48:54.193352 ops/training.py:65 2019-01-17 03:48:54.193288: step 10212, loss = 0.68765 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:48:55.483086 ops/training.py:65 2019-01-17 03:48:55.482993: step 10213, loss = 0.68553 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:48:56.768428 ops/training.py:65 2019-01-17 03:48:56.768361: step 10214, loss = 0.60735 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:48:58.053161 ops/training.py:65 2019-01-17 03:48:58.053053: step 10215, loss = 0.67098 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:48:59.341882 ops/training.py:65 2019-01-17 03:48:59.341775: step 10216, loss = 0.58916 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:49:00.626381 ops/training.py:65 2019-01-17 03:49:00.626279: step 10217, loss = 0.65344 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:49:01.913447 ops/training.py:65 2019-01-17 03:49:01.913335: step 10218, loss = 0.68474 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:49:03.197490 ops/training.py:65 2019-01-17 03:49:03.197389: step 10219, loss = 0.65101 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:49:04.485246 ops/training.py:65 2019-01-17 03:49:04.485140: step 10220, loss = 0.66895 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:49:05.776264 ops/training.py:65 2019-01-17 03:49:05.776199: step 10221, loss = 0.75494 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:49:07.061083 ops/training.py:65 2019-01-17 03:49:07.061016: step 10222, loss = 0.61482 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:49:08.349261 ops/training.py:65 2019-01-17 03:49:08.349198: step 10223, loss = 0.65872 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:49:09.639548 ops/training.py:65 2019-01-17 03:49:09.639475: step 10224, loss = 0.65838 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:49:10.924859 ops/training.py:65 2019-01-17 03:49:10.924793: step 10225, loss = 0.65744 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:49:12.209765 ops/training.py:65 2019-01-17 03:49:12.209661: step 10226, loss = 0.73475 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:49:13.496181 ops/training.py:65 2019-01-17 03:49:13.496089: step 10227, loss = 0.71573 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:49:14.782840 ops/training.py:65 2019-01-17 03:49:14.782739: step 10228, loss = 0.58379 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:49:16.068874 ops/training.py:65 2019-01-17 03:49:16.068771: step 10229, loss = 0.68018 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:49:17.355573 ops/training.py:65 2019-01-17 03:49:17.355429: step 10230, loss = 0.64353 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:49:18.641190 ops/training.py:65 2019-01-17 03:49:18.641106: step 10231, loss = 0.61394 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:49:19.934216 ops/training.py:65 2019-01-17 03:49:19.934126: step 10232, loss = 0.57372 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:49:21.224100 ops/training.py:65 2019-01-17 03:49:21.224023: step 10233, loss = 0.57706 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:49:22.509572 ops/training.py:65 2019-01-17 03:49:22.509461: step 10234, loss = 0.63253 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:49:23.793938 ops/training.py:65 2019-01-17 03:49:23.793843: step 10235, loss = 0.68784 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:49:25.081773 ops/training.py:65 2019-01-17 03:49:25.081673: step 10236, loss = 0.58123 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:49:26.366140 ops/training.py:65 2019-01-17 03:49:26.366076: step 10237, loss = 0.68738 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:49:27.650478 ops/training.py:65 2019-01-17 03:49:27.650417: step 10238, loss = 0.66629 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:49:28.934791 ops/training.py:65 2019-01-17 03:49:28.934691: step 10239, loss = 0.68153 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:49:30.222673 ops/training.py:65 2019-01-17 03:49:30.222567: step 10240, loss = 0.59839 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:49:31.511923 ops/training.py:65 2019-01-17 03:49:31.511817: step 10241, loss = 0.66442 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:49:32.802155 ops/training.py:65 2019-01-17 03:49:32.802045: step 10242, loss = 0.65830 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:49:34.091581 ops/training.py:65 2019-01-17 03:49:34.091507: step 10243, loss = 0.64387 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:49:35.375443 ops/training.py:65 2019-01-17 03:49:35.375383: step 10244, loss = 0.70226 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:49:36.664824 ops/training.py:65 2019-01-17 03:49:36.664753: step 10245, loss = 0.59793 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:49:37.953777 ops/training.py:65 2019-01-17 03:49:37.953708: step 10246, loss = 0.72648 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:49:39.239557 ops/training.py:65 2019-01-17 03:49:39.239479: step 10247, loss = 0.64519 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:49:40.530064 ops/training.py:65 2019-01-17 03:49:40.530001: step 10248, loss = 0.66364 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:49:41.819418 ops/training.py:65 2019-01-17 03:49:41.819331: step 10249, loss = 0.61354 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:49:43.104335 ops/training.py:65 2019-01-17 03:49:43.104269: step 10250, loss = 0.58180 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:49:44.393377 ops/training.py:65 2019-01-17 03:49:44.393287: step 10251, loss = 0.70171 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:49:45.677515 ops/training.py:65 2019-01-17 03:49:45.677456: step 10252, loss = 0.65392 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:49:46.959381 ops/training.py:65 2019-01-17 03:49:46.959278: step 10253, loss = 0.71163 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:49:48.247250 ops/training.py:65 2019-01-17 03:49:48.247148: step 10254, loss = 0.63590 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:49:49.538456 ops/training.py:65 2019-01-17 03:49:49.538347: step 10255, loss = 0.69567 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:49:50.830294 ops/training.py:65 2019-01-17 03:49:50.830231: step 10256, loss = 0.68833 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:49:52.119635 ops/training.py:65 2019-01-17 03:49:52.119567: step 10257, loss = 0.76057 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:49:53.405402 ops/training.py:65 2019-01-17 03:49:53.405339: step 10258, loss = 0.60810 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:49:54.691046 ops/training.py:65 2019-01-17 03:49:54.690980: step 10259, loss = 0.72081 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:49:55.978295 ops/training.py:65 2019-01-17 03:49:55.978208: step 10260, loss = 0.62341 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:49:57.262466 ops/training.py:65 2019-01-17 03:49:57.262423: step 10261, loss = 0.68729 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:49:58.548935 ops/training.py:65 2019-01-17 03:49:58.548850: step 10262, loss = 0.63864 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:49:59.838647 ops/training.py:65 2019-01-17 03:49:59.838575: step 10263, loss = 0.68506 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:50:01.127416 ops/training.py:65 2019-01-17 03:50:01.127351: step 10264, loss = 0.68449 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:50:02.412674 ops/training.py:65 2019-01-17 03:50:02.412594: step 10265, loss = 0.66652 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:50:03.706364 ops/training.py:65 2019-01-17 03:50:03.706286: step 10266, loss = 0.69119 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:50:04.990739 ops/training.py:65 2019-01-17 03:50:04.990653: step 10267, loss = 0.68311 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:50:06.277016 ops/training.py:65 2019-01-17 03:50:06.276935: step 10268, loss = 0.67282 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:50:07.569915 ops/training.py:65 2019-01-17 03:50:07.569815: step 10269, loss = 0.65200 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:50:08.860627 ops/training.py:65 2019-01-17 03:50:08.860553: step 10270, loss = 0.69937 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:50:10.150923 ops/training.py:65 2019-01-17 03:50:10.150856: step 10271, loss = 0.60778 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:50:11.439930 ops/training.py:65 2019-01-17 03:50:11.439865: step 10272, loss = 0.65605 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:50:12.729626 ops/training.py:65 2019-01-17 03:50:12.729527: step 10273, loss = 0.57398 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 03:50:14.018901 ops/training.py:65 2019-01-17 03:50:14.018834: step 10274, loss = 0.66814 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:50:15.304230 ops/training.py:65 2019-01-17 03:50:15.304156: step 10275, loss = 0.58316 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:50:16.591363 ops/training.py:65 2019-01-17 03:50:16.591291: step 10276, loss = 0.60819 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:50:17.880243 ops/training.py:65 2019-01-17 03:50:17.880167: step 10277, loss = 0.62844 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:50:19.168475 ops/training.py:65 2019-01-17 03:50:19.168403: step 10278, loss = 0.68106 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:50:20.458304 ops/training.py:65 2019-01-17 03:50:20.458231: step 10279, loss = 0.64040 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:50:21.746322 ops/training.py:65 2019-01-17 03:50:21.746257: step 10280, loss = 0.61586 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:50:23.035876 ops/training.py:65 2019-01-17 03:50:23.035801: step 10281, loss = 0.70344 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:50:24.324931 ops/training.py:65 2019-01-17 03:50:24.324864: step 10282, loss = 0.65432 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:50:25.614542 ops/training.py:65 2019-01-17 03:50:25.614472: step 10283, loss = 0.62095 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:50:26.903738 ops/training.py:65 2019-01-17 03:50:26.903679: step 10284, loss = 0.61732 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:50:28.192740 ops/training.py:65 2019-01-17 03:50:28.192670: step 10285, loss = 0.73088 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:50:29.481660 ops/training.py:65 2019-01-17 03:50:29.481593: step 10286, loss = 0.66002 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:50:30.770556 ops/training.py:65 2019-01-17 03:50:30.770460: step 10287, loss = 0.70980 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:50:32.060798 ops/training.py:65 2019-01-17 03:50:32.060720: step 10288, loss = 0.64553 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:50:33.348877 ops/training.py:65 2019-01-17 03:50:33.348801: step 10289, loss = 0.64656 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:50:34.634254 ops/training.py:65 2019-01-17 03:50:34.634183: step 10290, loss = 0.66426 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:50:35.923117 ops/training.py:65 2019-01-17 03:50:35.923050: step 10291, loss = 0.65203 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:50:37.211531 ops/training.py:65 2019-01-17 03:50:37.211439: step 10292, loss = 0.68034 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:50:38.501106 ops/training.py:65 2019-01-17 03:50:38.501032: step 10293, loss = 0.67407 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:50:39.790063 ops/training.py:65 2019-01-17 03:50:39.789989: step 10294, loss = 0.66120 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:50:41.078010 ops/training.py:65 2019-01-17 03:50:41.077925: step 10295, loss = 0.67940 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:50:42.362210 ops/training.py:65 2019-01-17 03:50:42.362148: step 10296, loss = 0.62126 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:50:43.646001 ops/training.py:65 2019-01-17 03:50:43.645907: step 10297, loss = 0.73782 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:50:44.937810 ops/training.py:65 2019-01-17 03:50:44.937657: step 10298, loss = 0.62828 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:50:46.229384 ops/training.py:65 2019-01-17 03:50:46.229313: step 10299, loss = 0.72720 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:50:47.519339 ops/training.py:65 2019-01-17 03:50:47.519270: step 10300, loss = 0.78293 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:50:48.809574 ops/training.py:65 2019-01-17 03:50:48.809480: step 10301, loss = 0.64197 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:50:50.095002 ops/training.py:65 2019-01-17 03:50:50.094939: step 10302, loss = 0.78037 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:50:51.375147 ops/training.py:65 2019-01-17 03:50:51.375041: step 10303, loss = 0.62354 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:50:52.663030 ops/training.py:65 2019-01-17 03:50:52.662920: step 10304, loss = 0.66751 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:50:53.955306 ops/training.py:65 2019-01-17 03:50:53.955183: step 10305, loss = 0.67512 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:50:55.242466 ops/training.py:65 2019-01-17 03:50:55.242404: step 10306, loss = 0.60023 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:50:56.532901 ops/training.py:65 2019-01-17 03:50:56.532750: step 10307, loss = 0.61292 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:50:57.824599 ops/training.py:65 2019-01-17 03:50:57.824514: step 10308, loss = 0.68420 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:50:59.109792 ops/training.py:65 2019-01-17 03:50:59.109727: step 10309, loss = 0.68391 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:51:00.394097 ops/training.py:65 2019-01-17 03:51:00.393999: step 10310, loss = 0.64763 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:51:01.681391 ops/training.py:65 2019-01-17 03:51:01.681289: step 10311, loss = 0.63844 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:51:02.970159 ops/training.py:65 2019-01-17 03:51:02.970002: step 10312, loss = 0.67230 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:51:04.261880 ops/training.py:65 2019-01-17 03:51:04.261805: step 10313, loss = 0.63585 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:51:05.550247 ops/training.py:65 2019-01-17 03:51:05.550182: step 10314, loss = 0.72674 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:51:06.835015 ops/training.py:65 2019-01-17 03:51:06.834946: step 10315, loss = 0.61876 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:51:08.123682 ops/training.py:65 2019-01-17 03:51:08.123618: step 10316, loss = 0.66178 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:51:09.412897 ops/training.py:65 2019-01-17 03:51:09.412814: step 10317, loss = 0.71596 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:51:10.698227 ops/training.py:65 2019-01-17 03:51:10.698166: step 10318, loss = 0.69845 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:51:11.986505 ops/training.py:65 2019-01-17 03:51:11.986435: step 10319, loss = 0.62757 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:51:13.275767 ops/training.py:65 2019-01-17 03:51:13.275698: step 10320, loss = 0.69955 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:51:14.564409 ops/training.py:65 2019-01-17 03:51:14.564313: step 10321, loss = 0.67064 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:51:15.854378 ops/training.py:65 2019-01-17 03:51:15.854273: step 10322, loss = 0.75925 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:51:17.139922 ops/training.py:65 2019-01-17 03:51:17.139827: step 10323, loss = 0.61247 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:51:18.426206 ops/training.py:65 2019-01-17 03:51:18.426127: step 10324, loss = 0.62084 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:51:19.716155 ops/training.py:65 2019-01-17 03:51:19.716095: step 10325, loss = 0.63426 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:51:21.000058 ops/training.py:65 2019-01-17 03:51:20.999981: step 10326, loss = 0.65606 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:51:22.287797 ops/training.py:65 2019-01-17 03:51:22.287689: step 10327, loss = 0.60437 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:51:23.578722 ops/training.py:65 2019-01-17 03:51:23.578643: step 10328, loss = 0.63388 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:51:24.866166 ops/training.py:65 2019-01-17 03:51:24.866096: step 10329, loss = 0.64165 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:51:26.154584 ops/training.py:65 2019-01-17 03:51:26.154490: step 10330, loss = 0.64953 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:51:27.442767 ops/training.py:65 2019-01-17 03:51:27.442691: step 10331, loss = 0.59616 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 03:51:28.731138 ops/training.py:65 2019-01-17 03:51:28.731066: step 10332, loss = 0.67645 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:51:30.014842 ops/training.py:65 2019-01-17 03:51:30.014774: step 10333, loss = 0.68863 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:51:31.298672 ops/training.py:65 2019-01-17 03:51:31.298520: step 10334, loss = 0.54692 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:51:32.591744 ops/training.py:65 2019-01-17 03:51:32.591644: step 10335, loss = 0.62658 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:51:33.882227 ops/training.py:65 2019-01-17 03:51:33.882154: step 10336, loss = 0.68078 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:51:35.167308 ops/training.py:65 2019-01-17 03:51:35.167244: step 10337, loss = 0.63437 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:51:36.451608 ops/training.py:65 2019-01-17 03:51:36.451504: step 10338, loss = 0.64589 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:51:37.743886 ops/training.py:65 2019-01-17 03:51:37.743776: step 10339, loss = 0.69735 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:51:39.034385 ops/training.py:65 2019-01-17 03:51:39.034300: step 10340, loss = 0.66104 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:51:40.324046 ops/training.py:65 2019-01-17 03:51:40.323974: step 10341, loss = 0.64733 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:51:41.608665 ops/training.py:65 2019-01-17 03:51:41.608593: step 10342, loss = 0.70302 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:51:42.892693 ops/training.py:65 2019-01-17 03:51:42.892548: step 10343, loss = 0.64545 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:51:44.181556 ops/training.py:65 2019-01-17 03:51:44.181459: step 10344, loss = 0.75047 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:51:45.472921 ops/training.py:65 2019-01-17 03:51:45.472824: step 10345, loss = 0.63695 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:51:46.758445 ops/training.py:65 2019-01-17 03:51:46.758372: step 10346, loss = 0.55580 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:51:48.045365 ops/training.py:65 2019-01-17 03:51:48.045258: step 10347, loss = 0.63231 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:51:49.326878 ops/training.py:65 2019-01-17 03:51:49.326773: step 10348, loss = 0.67251 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:51:50.618881 ops/training.py:65 2019-01-17 03:51:50.618790: step 10349, loss = 0.69681 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:51:51.909642 ops/training.py:65 2019-01-17 03:51:51.909578: step 10350, loss = 0.70706 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:51:53.194206 ops/training.py:65 2019-01-17 03:51:53.194138: step 10351, loss = 0.58533 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:51:54.483573 ops/training.py:65 2019-01-17 03:51:54.483424: step 10352, loss = 0.62637 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:51:55.769445 ops/training.py:65 2019-01-17 03:51:55.769351: step 10353, loss = 0.60459 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:51:57.058905 ops/training.py:65 2019-01-17 03:51:57.058799: step 10354, loss = 0.67971 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:51:58.343478 ops/training.py:65 2019-01-17 03:51:58.343405: step 10355, loss = 0.69134 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:51:59.627384 ops/training.py:65 2019-01-17 03:51:59.627323: step 10356, loss = 0.61655 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:52:00.908663 ops/training.py:65 2019-01-17 03:52:00.908512: step 10357, loss = 0.59452 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:52:02.201290 ops/training.py:65 2019-01-17 03:52:02.201133: step 10358, loss = 0.67849 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:52:03.494763 ops/training.py:65 2019-01-17 03:52:03.494672: step 10359, loss = 0.69239 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:52:04.785490 ops/training.py:65 2019-01-17 03:52:04.785401: step 10360, loss = 0.69598 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:52:06.075358 ops/training.py:65 2019-01-17 03:52:06.075291: step 10361, loss = 0.68756 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:52:07.364684 ops/training.py:65 2019-01-17 03:52:07.364581: step 10362, loss = 0.67233 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:52:08.654197 ops/training.py:65 2019-01-17 03:52:08.654127: step 10363, loss = 0.66044 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:52:09.943124 ops/training.py:65 2019-01-17 03:52:09.943047: step 10364, loss = 0.71912 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:52:11.232887 ops/training.py:65 2019-01-17 03:52:11.232816: step 10365, loss = 0.69764 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:52:12.522293 ops/training.py:65 2019-01-17 03:52:12.522229: step 10366, loss = 0.76787 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:52:13.811159 ops/training.py:65 2019-01-17 03:52:13.811059: step 10367, loss = 0.76882 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:52:15.100611 ops/training.py:65 2019-01-17 03:52:15.100525: step 10368, loss = 0.67508 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:52:16.389860 ops/training.py:65 2019-01-17 03:52:16.389773: step 10369, loss = 0.73283 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:52:17.679170 ops/training.py:65 2019-01-17 03:52:17.679100: step 10370, loss = 0.68918 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:52:18.969068 ops/training.py:65 2019-01-17 03:52:18.968976: step 10371, loss = 0.54838 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 03:52:20.259228 ops/training.py:65 2019-01-17 03:52:20.259163: step 10372, loss = 0.72993 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:52:21.548457 ops/training.py:65 2019-01-17 03:52:21.548387: step 10373, loss = 0.69767 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:52:22.837079 ops/training.py:65 2019-01-17 03:52:22.837008: step 10374, loss = 0.70807 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:52:24.132167 ops/training.py:65 2019-01-17 03:52:24.132096: step 10375, loss = 0.62789 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:52:25.424349 ops/training.py:65 2019-01-17 03:52:25.424265: step 10376, loss = 0.66806 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:52:26.711986 ops/training.py:65 2019-01-17 03:52:26.711915: step 10377, loss = 0.67759 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:52:28.000572 ops/training.py:65 2019-01-17 03:52:28.000494: step 10378, loss = 0.64473 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:52:29.288388 ops/training.py:65 2019-01-17 03:52:29.288313: step 10379, loss = 0.67168 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:52:30.573586 ops/training.py:65 2019-01-17 03:52:30.573521: step 10380, loss = 0.64513 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:52:31.856829 ops/training.py:65 2019-01-17 03:52:31.856760: step 10381, loss = 0.66387 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:52:33.143469 ops/training.py:65 2019-01-17 03:52:33.143373: step 10382, loss = 0.70816 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:52:34.429050 ops/training.py:65 2019-01-17 03:52:34.428944: step 10383, loss = 0.67709 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:52:35.715242 ops/training.py:65 2019-01-17 03:52:35.715150: step 10384, loss = 0.71231 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:52:37.006562 ops/training.py:65 2019-01-17 03:52:37.006457: step 10385, loss = 0.68987 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:52:38.292205 ops/training.py:65 2019-01-17 03:52:38.292139: step 10386, loss = 0.71772 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:52:39.575797 ops/training.py:65 2019-01-17 03:52:39.575697: step 10387, loss = 0.69219 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:52:40.867208 ops/training.py:65 2019-01-17 03:52:40.867100: step 10388, loss = 0.68763 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:52:42.154742 ops/training.py:65 2019-01-17 03:52:42.154675: step 10389, loss = 0.64139 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:52:43.440207 ops/training.py:65 2019-01-17 03:52:43.440104: step 10390, loss = 0.71417 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:52:44.731745 ops/training.py:65 2019-01-17 03:52:44.731642: step 10391, loss = 0.69415 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:52:46.017302 ops/training.py:65 2019-01-17 03:52:46.017241: step 10392, loss = 0.64434 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:52:47.301740 ops/training.py:65 2019-01-17 03:52:47.301678: step 10393, loss = 0.68633 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:52:48.591926 ops/training.py:65 2019-01-17 03:52:48.591818: step 10394, loss = 0.70581 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:52:49.882080 ops/training.py:65 2019-01-17 03:52:49.881977: step 10395, loss = 0.55163 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 03:52:51.166752 ops/training.py:65 2019-01-17 03:52:51.166688: step 10396, loss = 0.64704 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:52:52.450574 ops/training.py:65 2019-01-17 03:52:52.450490: step 10397, loss = 0.70666 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:52:53.742912 ops/training.py:65 2019-01-17 03:52:53.742819: step 10398, loss = 0.70111 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:52:55.029265 ops/training.py:65 2019-01-17 03:52:55.029198: step 10399, loss = 0.69772 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:52:56.313400 ops/training.py:65 2019-01-17 03:52:56.313296: step 10400, loss = 0.65728 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:52:57.604669 ops/training.py:65 2019-01-17 03:52:57.604512: step 10401, loss = 0.64901 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:52:58.896079 ops/training.py:65 2019-01-17 03:52:58.896013: step 10402, loss = 0.67575 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:53:00.179491 ops/training.py:65 2019-01-17 03:53:00.179404: step 10403, loss = 0.62960 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:53:01.470752 ops/training.py:65 2019-01-17 03:53:01.470649: step 10404, loss = 0.56757 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 03:53:02.761122 ops/training.py:65 2019-01-17 03:53:02.761051: step 10405, loss = 0.62448 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:53:04.049895 ops/training.py:65 2019-01-17 03:53:04.049821: step 10406, loss = 0.61963 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:53:05.339846 ops/training.py:65 2019-01-17 03:53:05.339775: step 10407, loss = 0.65755 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:53:06.628431 ops/training.py:65 2019-01-17 03:53:06.628324: step 10408, loss = 0.70214 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:53:07.915176 ops/training.py:65 2019-01-17 03:53:07.915107: step 10409, loss = 0.65329 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:53:09.199751 ops/training.py:65 2019-01-17 03:53:09.199666: step 10410, loss = 0.64580 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:53:10.491857 ops/training.py:65 2019-01-17 03:53:10.491757: step 10411, loss = 0.63502 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:53:11.782237 ops/training.py:65 2019-01-17 03:53:11.782161: step 10412, loss = 0.57798 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 03:53:13.071349 ops/training.py:65 2019-01-17 03:53:13.071277: step 10413, loss = 0.71288 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:53:14.357923 ops/training.py:65 2019-01-17 03:53:14.357840: step 10414, loss = 0.64652 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:53:15.641599 ops/training.py:65 2019-01-17 03:53:15.641494: step 10415, loss = 0.70538 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:53:16.929377 ops/training.py:65 2019-01-17 03:53:16.929269: step 10416, loss = 0.68606 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:53:18.219264 ops/training.py:65 2019-01-17 03:53:18.219151: step 10417, loss = 0.65805 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:53:19.505608 ops/training.py:65 2019-01-17 03:53:19.505536: step 10418, loss = 0.70281 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:53:20.788542 ops/training.py:65 2019-01-17 03:53:20.788476: step 10419, loss = 0.65750 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:53:22.073609 ops/training.py:65 2019-01-17 03:53:22.073498: step 10420, loss = 0.67627 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:53:23.362617 ops/training.py:65 2019-01-17 03:53:23.362526: step 10421, loss = 0.65002 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:53:24.650779 ops/training.py:65 2019-01-17 03:53:24.650689: step 10422, loss = 0.63949 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:53:25.938635 ops/training.py:65 2019-01-17 03:53:25.938554: step 10423, loss = 0.66854 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:53:27.223911 ops/training.py:65 2019-01-17 03:53:27.223844: step 10424, loss = 0.57461 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:53:28.512203 ops/training.py:65 2019-01-17 03:53:28.512140: step 10425, loss = 0.66643 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:53:29.796614 ops/training.py:65 2019-01-17 03:53:29.796544: step 10426, loss = 0.65000 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:53:31.083998 ops/training.py:65 2019-01-17 03:53:31.083847: step 10427, loss = 0.75903 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:53:32.369238 ops/training.py:65 2019-01-17 03:53:32.369168: step 10428, loss = 0.62949 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:53:33.659495 ops/training.py:65 2019-01-17 03:53:33.659398: step 10429, loss = 0.69209 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:53:34.948413 ops/training.py:65 2019-01-17 03:53:34.948331: step 10430, loss = 0.58006 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:53:36.232972 ops/training.py:65 2019-01-17 03:53:36.232904: step 10431, loss = 0.67604 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:53:37.516308 ops/training.py:65 2019-01-17 03:53:37.516203: step 10432, loss = 0.62145 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:53:38.807447 ops/training.py:65 2019-01-17 03:53:38.807340: step 10433, loss = 0.68349 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:53:40.094570 ops/training.py:65 2019-01-17 03:53:40.094497: step 10434, loss = 0.66048 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:53:41.381255 ops/training.py:65 2019-01-17 03:53:41.381190: step 10435, loss = 0.55370 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:53:42.665595 ops/training.py:65 2019-01-17 03:53:42.665519: step 10436, loss = 0.70439 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:53:43.955070 ops/training.py:65 2019-01-17 03:53:43.954994: step 10437, loss = 0.72279 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:53:45.244267 ops/training.py:65 2019-01-17 03:53:45.244200: step 10438, loss = 0.73271 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:53:46.532572 ops/training.py:65 2019-01-17 03:53:46.532510: step 10439, loss = 0.60401 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:53:47.816039 ops/training.py:65 2019-01-17 03:53:47.815976: step 10440, loss = 0.70616 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:53:49.097774 ops/training.py:65 2019-01-17 03:53:49.097661: step 10441, loss = 0.71590 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:53:50.385078 ops/training.py:65 2019-01-17 03:53:50.384985: step 10442, loss = 0.64251 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:53:51.669193 ops/training.py:65 2019-01-17 03:53:51.669081: step 10443, loss = 0.68370 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:53:52.956251 ops/training.py:65 2019-01-17 03:53:52.956151: step 10444, loss = 0.62258 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:53:54.246670 ops/training.py:65 2019-01-17 03:53:54.246599: step 10445, loss = 0.81002 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:53:55.531786 ops/training.py:65 2019-01-17 03:53:55.531722: step 10446, loss = 0.66732 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:53:56.812884 ops/training.py:65 2019-01-17 03:53:56.812774: step 10447, loss = 0.66595 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:53:58.104373 ops/training.py:65 2019-01-17 03:53:58.104266: step 10448, loss = 0.73509 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:53:59.395035 ops/training.py:65 2019-01-17 03:53:59.394961: step 10449, loss = 0.66214 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:54:00.683789 ops/training.py:65 2019-01-17 03:54:00.683726: step 10450, loss = 0.59082 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:54:01.973061 ops/training.py:65 2019-01-17 03:54:01.972996: step 10451, loss = 0.60482 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:54:03.257575 ops/training.py:65 2019-01-17 03:54:03.257505: step 10452, loss = 0.62426 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:54:04.541502 ops/training.py:65 2019-01-17 03:54:04.541424: step 10453, loss = 0.78451 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:54:05.832244 ops/training.py:65 2019-01-17 03:54:05.832147: step 10454, loss = 0.55977 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:54:07.120923 ops/training.py:65 2019-01-17 03:54:07.120857: step 10455, loss = 0.69494 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:54:08.409246 ops/training.py:65 2019-01-17 03:54:08.409192: step 10456, loss = 0.68679 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:54:09.697950 ops/training.py:65 2019-01-17 03:54:09.697886: step 10457, loss = 0.65264 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:54:10.987299 ops/training.py:65 2019-01-17 03:54:10.987242: step 10458, loss = 0.71236 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:54:12.271582 ops/training.py:65 2019-01-17 03:54:12.271511: step 10459, loss = 0.61980 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:54:13.556728 ops/training.py:65 2019-01-17 03:54:13.556670: step 10460, loss = 0.69052 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:54:14.844374 ops/training.py:65 2019-01-17 03:54:14.844317: step 10461, loss = 0.62601 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:54:16.132650 ops/training.py:65 2019-01-17 03:54:16.132583: step 10462, loss = 0.65417 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:54:17.417706 ops/training.py:65 2019-01-17 03:54:17.417637: step 10463, loss = 0.56809 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:54:18.703902 ops/training.py:65 2019-01-17 03:54:18.703837: step 10464, loss = 0.68231 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:54:19.988522 ops/training.py:65 2019-01-17 03:54:19.988485: step 10465, loss = 0.74029 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:54:21.279743 ops/training.py:65 2019-01-17 03:54:21.279693: step 10466, loss = 0.62833 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:54:22.568874 ops/training.py:65 2019-01-17 03:54:22.568825: step 10467, loss = 0.63052 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:54:23.857572 ops/training.py:65 2019-01-17 03:54:23.857508: step 10468, loss = 0.64767 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:54:25.145778 ops/training.py:65 2019-01-17 03:54:25.145676: step 10469, loss = 0.68760 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:54:26.430992 ops/training.py:65 2019-01-17 03:54:26.430917: step 10470, loss = 0.67808 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:54:27.717444 ops/training.py:65 2019-01-17 03:54:27.717367: step 10471, loss = 0.65472 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:54:29.008126 ops/training.py:65 2019-01-17 03:54:29.008039: step 10472, loss = 0.67850 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:54:30.292906 ops/training.py:65 2019-01-17 03:54:30.292837: step 10473, loss = 0.65140 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:54:31.579772 ops/training.py:65 2019-01-17 03:54:31.579676: step 10474, loss = 0.64815 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:54:32.866978 ops/training.py:65 2019-01-17 03:54:32.866913: step 10475, loss = 0.63005 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:54:34.156098 ops/training.py:65 2019-01-17 03:54:34.156048: step 10476, loss = 0.69236 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:54:35.446034 ops/training.py:65 2019-01-17 03:54:35.445964: step 10477, loss = 0.63781 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:54:36.734622 ops/training.py:65 2019-01-17 03:54:36.734571: step 10478, loss = 0.67865 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:54:38.024366 ops/training.py:65 2019-01-17 03:54:38.024313: step 10479, loss = 0.57012 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:54:39.309806 ops/training.py:65 2019-01-17 03:54:39.309740: step 10480, loss = 0.70181 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:54:40.593663 ops/training.py:65 2019-01-17 03:54:40.593603: step 10481, loss = 0.62931 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:54:41.882643 ops/training.py:65 2019-01-17 03:54:41.882580: step 10482, loss = 0.66084 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:54:43.171189 ops/training.py:65 2019-01-17 03:54:43.171113: step 10483, loss = 0.63740 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:54:44.460999 ops/training.py:65 2019-01-17 03:54:44.460933: step 10484, loss = 0.71510 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:54:45.749685 ops/training.py:65 2019-01-17 03:54:45.749615: step 10485, loss = 0.79218 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:54:47.033249 ops/training.py:65 2019-01-17 03:54:47.033211: step 10486, loss = 0.65065 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:54:48.319781 ops/training.py:65 2019-01-17 03:54:48.319745: step 10487, loss = 0.78534 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:54:49.610337 ops/training.py:65 2019-01-17 03:54:49.610286: step 10488, loss = 0.70358 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:54:50.898206 ops/training.py:65 2019-01-17 03:54:50.898142: step 10489, loss = 0.72313 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:54:52.186029 ops/training.py:65 2019-01-17 03:54:52.185963: step 10490, loss = 0.58401 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:54:53.473771 ops/training.py:65 2019-01-17 03:54:53.473694: step 10491, loss = 0.69086 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:54:54.762133 ops/training.py:65 2019-01-17 03:54:54.762077: step 10492, loss = 0.60130 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:54:56.050942 ops/training.py:65 2019-01-17 03:54:56.050870: step 10493, loss = 0.63471 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:54:57.339162 ops/training.py:65 2019-01-17 03:54:57.339118: step 10494, loss = 0.69003 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:54:58.628716 ops/training.py:65 2019-01-17 03:54:58.628651: step 10495, loss = 0.72767 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:54:59.917691 ops/training.py:65 2019-01-17 03:54:59.917632: step 10496, loss = 0.72311 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:55:01.205712 ops/training.py:65 2019-01-17 03:55:01.205644: step 10497, loss = 0.61135 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:55:02.494713 ops/training.py:65 2019-01-17 03:55:02.494644: step 10498, loss = 0.63324 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:55:03.778680 ops/training.py:65 2019-01-17 03:55:03.778633: step 10499, loss = 0.58874 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:55:05.062255 ops/training.py:65 2019-01-17 03:55:05.062216: step 10500, loss = 0.66886 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:55:06.346513 ops/training.py:65 2019-01-17 03:55:06.346477: step 10501, loss = 0.64309 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:55:07.629285 ops/training.py:65 2019-01-17 03:55:07.629256: step 10502, loss = 0.65214 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:55:08.917155 ops/training.py:65 2019-01-17 03:55:08.917122: step 10503, loss = 0.67816 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:55:10.200798 ops/training.py:65 2019-01-17 03:55:10.200769: step 10504, loss = 0.71514 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:55:11.490375 ops/training.py:65 2019-01-17 03:55:11.490343: step 10505, loss = 0.70181 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:55:12.773727 ops/training.py:65 2019-01-17 03:55:12.773683: step 10506, loss = 0.65337 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:55:14.065221 ops/training.py:65 2019-01-17 03:55:14.065186: step 10507, loss = 0.74754 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:55:15.352860 ops/training.py:65 2019-01-17 03:55:15.352789: step 10508, loss = 0.71537 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:55:16.638514 ops/training.py:65 2019-01-17 03:55:16.638421: step 10509, loss = 0.65947 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:55:17.923698 ops/training.py:65 2019-01-17 03:55:17.923629: step 10510, loss = 0.65872 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:55:19.207411 ops/training.py:65 2019-01-17 03:55:19.207280: step 10511, loss = 0.72848 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:55:20.492403 ops/training.py:65 2019-01-17 03:55:20.492308: step 10512, loss = 0.64802 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:55:21.779799 ops/training.py:65 2019-01-17 03:55:21.779697: step 10513, loss = 0.68453 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:55:23.065099 ops/training.py:65 2019-01-17 03:55:23.064964: step 10514, loss = 0.59794 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:55:24.350154 ops/training.py:65 2019-01-17 03:55:24.350045: step 10515, loss = 0.70296 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:55:25.640875 ops/training.py:65 2019-01-17 03:55:25.640770: step 10516, loss = 0.67359 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:55:26.922730 ops/training.py:65 2019-01-17 03:55:26.922659: step 10517, loss = 0.69065 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:55:28.214950 ops/training.py:65 2019-01-17 03:55:28.214847: step 10518, loss = 0.59605 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:55:29.504444 ops/training.py:65 2019-01-17 03:55:29.504385: step 10519, loss = 0.64743 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:55:30.792721 ops/training.py:65 2019-01-17 03:55:30.792659: step 10520, loss = 0.62789 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:55:32.081142 ops/training.py:65 2019-01-17 03:55:32.081068: step 10521, loss = 0.54578 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:55:33.365260 ops/training.py:65 2019-01-17 03:55:33.365193: step 10522, loss = 0.63579 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:55:34.653349 ops/training.py:65 2019-01-17 03:55:34.653265: step 10523, loss = 0.71493 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:55:35.942668 ops/training.py:65 2019-01-17 03:55:35.942569: step 10524, loss = 0.64771 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:55:37.226852 ops/training.py:65 2019-01-17 03:55:37.226777: step 10525, loss = 0.61698 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:55:38.511790 ops/training.py:65 2019-01-17 03:55:38.511716: step 10526, loss = 0.71713 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:55:39.799154 ops/training.py:65 2019-01-17 03:55:39.799088: step 10527, loss = 0.65394 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:55:41.085084 ops/training.py:65 2019-01-17 03:55:41.085015: step 10528, loss = 0.70024 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:55:42.368523 ops/training.py:65 2019-01-17 03:55:42.368383: step 10529, loss = 0.67316 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:55:43.657371 ops/training.py:65 2019-01-17 03:55:43.657274: step 10530, loss = 0.63209 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:55:44.945547 ops/training.py:65 2019-01-17 03:55:44.945439: step 10531, loss = 0.65246 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:55:46.233889 ops/training.py:65 2019-01-17 03:55:46.233817: step 10532, loss = 0.68570 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:55:47.522530 ops/training.py:65 2019-01-17 03:55:47.522431: step 10533, loss = 0.67855 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:55:48.808730 ops/training.py:65 2019-01-17 03:55:48.808657: step 10534, loss = 0.67338 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:55:50.096067 ops/training.py:65 2019-01-17 03:55:50.096007: step 10535, loss = 0.68206 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:55:51.384618 ops/training.py:65 2019-01-17 03:55:51.384545: step 10536, loss = 0.61080 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:55:52.672267 ops/training.py:65 2019-01-17 03:55:52.672199: step 10537, loss = 0.61404 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:55:53.956457 ops/training.py:65 2019-01-17 03:55:53.956389: step 10538, loss = 0.62031 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:55:55.239833 ops/training.py:65 2019-01-17 03:55:55.239733: step 10539, loss = 0.61019 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:55:56.531292 ops/training.py:65 2019-01-17 03:55:56.531137: step 10540, loss = 0.64987 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:55:57.824403 ops/training.py:65 2019-01-17 03:55:57.824329: step 10541, loss = 0.58685 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 03:55:59.113646 ops/training.py:65 2019-01-17 03:55:59.113565: step 10542, loss = 0.64910 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:56:00.402870 ops/training.py:65 2019-01-17 03:56:00.402779: step 10543, loss = 0.71018 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:56:01.692126 ops/training.py:65 2019-01-17 03:56:01.692052: step 10544, loss = 0.55813 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:56:02.977929 ops/training.py:65 2019-01-17 03:56:02.977861: step 10545, loss = 0.65935 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:56:04.267422 ops/training.py:65 2019-01-17 03:56:04.267322: step 10546, loss = 0.61811 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:56:05.558723 ops/training.py:65 2019-01-17 03:56:05.558630: step 10547, loss = 0.69591 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:56:06.849587 ops/training.py:65 2019-01-17 03:56:06.849508: step 10548, loss = 0.66412 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:56:08.138058 ops/training.py:65 2019-01-17 03:56:08.137991: step 10549, loss = 0.69739 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:56:09.421537 ops/training.py:65 2019-01-17 03:56:09.421465: step 10550, loss = 0.66445 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:56:10.710233 ops/training.py:65 2019-01-17 03:56:10.710151: step 10551, loss = 0.70536 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:56:11.994593 ops/training.py:65 2019-01-17 03:56:11.994533: step 10552, loss = 0.61748 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:56:13.277600 ops/training.py:65 2019-01-17 03:56:13.277497: step 10553, loss = 0.61793 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:56:14.568668 ops/training.py:65 2019-01-17 03:56:14.568558: step 10554, loss = 0.65438 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:56:15.860893 ops/training.py:65 2019-01-17 03:56:15.860819: step 10555, loss = 0.72836 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:56:17.146066 ops/training.py:65 2019-01-17 03:56:17.145994: step 10556, loss = 0.73471 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:56:18.434586 ops/training.py:65 2019-01-17 03:56:18.434491: step 10557, loss = 0.59805 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:56:19.723711 ops/training.py:65 2019-01-17 03:56:19.723637: step 10558, loss = 0.60580 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:56:21.013521 ops/training.py:65 2019-01-17 03:56:21.013449: step 10559, loss = 0.70748 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:56:22.302519 ops/training.py:65 2019-01-17 03:56:22.302422: step 10560, loss = 0.71433 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:56:23.591638 ops/training.py:65 2019-01-17 03:56:23.591560: step 10561, loss = 0.68925 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:56:24.881538 ops/training.py:65 2019-01-17 03:56:24.881443: step 10562, loss = 0.62143 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:56:26.171718 ops/training.py:65 2019-01-17 03:56:26.171648: step 10563, loss = 0.70841 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:56:27.456855 ops/training.py:65 2019-01-17 03:56:27.456799: step 10564, loss = 0.61396 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:56:28.740442 ops/training.py:65 2019-01-17 03:56:28.740349: step 10565, loss = 0.61924 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:56:30.031871 ops/training.py:65 2019-01-17 03:56:30.031768: step 10566, loss = 0.62823 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:56:31.322515 ops/training.py:65 2019-01-17 03:56:31.322445: step 10567, loss = 0.63134 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:56:32.611168 ops/training.py:65 2019-01-17 03:56:32.611095: step 10568, loss = 0.63503 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:56:33.898648 ops/training.py:65 2019-01-17 03:56:33.898555: step 10569, loss = 0.62147 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:56:35.187696 ops/training.py:65 2019-01-17 03:56:35.187627: step 10570, loss = 0.60443 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:56:36.477085 ops/training.py:65 2019-01-17 03:56:36.476997: step 10571, loss = 0.56994 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:56:37.766160 ops/training.py:65 2019-01-17 03:56:37.766093: step 10572, loss = 0.58547 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 03:56:39.054315 ops/training.py:65 2019-01-17 03:56:39.054244: step 10573, loss = 0.63897 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:56:40.342899 ops/training.py:65 2019-01-17 03:56:40.342808: step 10574, loss = 0.59600 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:56:41.628268 ops/training.py:65 2019-01-17 03:56:41.628195: step 10575, loss = 0.73886 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:56:42.910822 ops/training.py:65 2019-01-17 03:56:42.910733: step 10576, loss = 0.65374 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:56:44.201709 ops/training.py:65 2019-01-17 03:56:44.201564: step 10577, loss = 0.74496 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:56:45.492091 ops/training.py:65 2019-01-17 03:56:45.491994: step 10578, loss = 0.67007 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:56:46.778267 ops/training.py:65 2019-01-17 03:56:46.778199: step 10579, loss = 0.68441 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:56:48.063901 ops/training.py:65 2019-01-17 03:56:48.063823: step 10580, loss = 0.65194 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:56:49.353174 ops/training.py:65 2019-01-17 03:56:49.353059: step 10581, loss = 0.60545 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:56:50.643120 ops/training.py:65 2019-01-17 03:56:50.643022: step 10582, loss = 0.66281 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:56:51.932993 ops/training.py:65 2019-01-17 03:56:51.932923: step 10583, loss = 0.68823 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:56:53.221372 ops/training.py:65 2019-01-17 03:56:53.221291: step 10584, loss = 0.67752 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:56:54.510545 ops/training.py:65 2019-01-17 03:56:54.510461: step 10585, loss = 0.63258 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:56:55.799812 ops/training.py:65 2019-01-17 03:56:55.799719: step 10586, loss = 0.63908 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:56:57.085220 ops/training.py:65 2019-01-17 03:56:57.085155: step 10587, loss = 0.57798 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 03:56:58.373803 ops/training.py:65 2019-01-17 03:56:58.373738: step 10588, loss = 0.60108 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:56:59.662569 ops/training.py:65 2019-01-17 03:56:59.662504: step 10589, loss = 0.67363 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:57:00.951475 ops/training.py:65 2019-01-17 03:57:00.951400: step 10590, loss = 0.61764 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:57:02.240491 ops/training.py:65 2019-01-17 03:57:02.240424: step 10591, loss = 0.58947 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 03:57:03.530543 ops/training.py:65 2019-01-17 03:57:03.530469: step 10592, loss = 0.74083 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:57:04.820400 ops/training.py:65 2019-01-17 03:57:04.820335: step 10593, loss = 0.73857 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:57:06.108546 ops/training.py:65 2019-01-17 03:57:06.108483: step 10594, loss = 0.59239 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:57:07.397217 ops/training.py:65 2019-01-17 03:57:07.397144: step 10595, loss = 0.63482 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:57:08.683305 ops/training.py:65 2019-01-17 03:57:08.683233: step 10596, loss = 0.66897 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:57:09.972075 ops/training.py:65 2019-01-17 03:57:09.972007: step 10597, loss = 0.67969 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:57:11.260572 ops/training.py:65 2019-01-17 03:57:11.260504: step 10598, loss = 0.66635 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:57:12.548982 ops/training.py:65 2019-01-17 03:57:12.548912: step 10599, loss = 0.59313 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:57:13.838329 ops/training.py:65 2019-01-17 03:57:13.838253: step 10600, loss = 0.67638 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:57:15.127450 ops/training.py:65 2019-01-17 03:57:15.127381: step 10601, loss = 0.58189 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:57:16.419079 ops/training.py:65 2019-01-17 03:57:16.419005: step 10602, loss = 0.66655 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:57:17.708137 ops/training.py:65 2019-01-17 03:57:17.708047: step 10603, loss = 0.68605 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:57:18.993188 ops/training.py:65 2019-01-17 03:57:18.993119: step 10604, loss = 0.59080 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 03:57:20.277724 ops/training.py:65 2019-01-17 03:57:20.277654: step 10605, loss = 0.65447 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:57:21.566122 ops/training.py:65 2019-01-17 03:57:21.566034: step 10606, loss = 0.66269 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:57:22.856219 ops/training.py:65 2019-01-17 03:57:22.856147: step 10607, loss = 0.65123 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:57:24.143787 ops/training.py:65 2019-01-17 03:57:24.143711: step 10608, loss = 0.75892 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:57:25.432756 ops/training.py:65 2019-01-17 03:57:25.432693: step 10609, loss = 0.70808 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:57:26.721492 ops/training.py:65 2019-01-17 03:57:26.721420: step 10610, loss = 0.73832 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:57:28.011926 ops/training.py:65 2019-01-17 03:57:28.011848: step 10611, loss = 0.76162 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:57:29.300382 ops/training.py:65 2019-01-17 03:57:29.300286: step 10612, loss = 0.62453 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:57:30.586328 ops/training.py:65 2019-01-17 03:57:30.586257: step 10613, loss = 0.69193 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:57:31.875264 ops/training.py:65 2019-01-17 03:57:31.875179: step 10614, loss = 0.67955 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:57:33.163134 ops/training.py:65 2019-01-17 03:57:33.163062: step 10615, loss = 0.73975 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:57:34.451218 ops/training.py:65 2019-01-17 03:57:34.451144: step 10616, loss = 0.65110 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:57:35.740421 ops/training.py:65 2019-01-17 03:57:35.740343: step 10617, loss = 0.70655 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:57:37.031519 ops/training.py:65 2019-01-17 03:57:37.031447: step 10618, loss = 0.57589 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 03:57:38.321481 ops/training.py:65 2019-01-17 03:57:38.321404: step 10619, loss = 0.63621 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:57:39.610280 ops/training.py:65 2019-01-17 03:57:39.610209: step 10620, loss = 0.61257 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:57:40.899938 ops/training.py:65 2019-01-17 03:57:40.899846: step 10621, loss = 0.72732 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:57:42.188445 ops/training.py:65 2019-01-17 03:57:42.188355: step 10622, loss = 0.78769 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:57:43.477455 ops/training.py:65 2019-01-17 03:57:43.477379: step 10623, loss = 0.64494 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:57:44.766248 ops/training.py:65 2019-01-17 03:57:44.766179: step 10624, loss = 0.65870 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:57:46.055605 ops/training.py:65 2019-01-17 03:57:46.055528: step 10625, loss = 0.60177 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:57:47.345233 ops/training.py:65 2019-01-17 03:57:47.345154: step 10626, loss = 0.68120 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:57:48.634176 ops/training.py:65 2019-01-17 03:57:48.634099: step 10627, loss = 0.61924 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:57:49.923610 ops/training.py:65 2019-01-17 03:57:49.923539: step 10628, loss = 0.65148 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:57:51.213078 ops/training.py:65 2019-01-17 03:57:51.213005: step 10629, loss = 0.61203 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:57:52.501344 ops/training.py:65 2019-01-17 03:57:52.501272: step 10630, loss = 0.57516 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 03:57:53.787304 ops/training.py:65 2019-01-17 03:57:53.787214: step 10631, loss = 0.65685 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:57:55.075178 ops/training.py:65 2019-01-17 03:57:55.075085: step 10632, loss = 0.66056 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:57:56.364304 ops/training.py:65 2019-01-17 03:57:56.364222: step 10633, loss = 0.64856 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:57:57.653850 ops/training.py:65 2019-01-17 03:57:57.653782: step 10634, loss = 0.68303 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:57:58.938355 ops/training.py:65 2019-01-17 03:57:58.938290: step 10635, loss = 0.66618 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:58:00.220622 ops/training.py:65 2019-01-17 03:58:00.220540: step 10636, loss = 0.65784 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:58:01.512408 ops/training.py:65 2019-01-17 03:58:01.512300: step 10637, loss = 0.66550 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:58:02.804224 ops/training.py:65 2019-01-17 03:58:02.804147: step 10638, loss = 0.64035 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:58:04.087845 ops/training.py:65 2019-01-17 03:58:04.087772: step 10639, loss = 0.63831 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:58:05.372103 ops/training.py:65 2019-01-17 03:58:05.372028: step 10640, loss = 0.63572 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:58:06.659585 ops/training.py:65 2019-01-17 03:58:06.659521: step 10641, loss = 0.62003 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:58:07.948327 ops/training.py:65 2019-01-17 03:58:07.948251: step 10642, loss = 0.68245 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:58:09.233626 ops/training.py:65 2019-01-17 03:58:09.233564: step 10643, loss = 0.63747 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:58:10.517765 ops/training.py:65 2019-01-17 03:58:10.517692: step 10644, loss = 0.63801 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:58:11.796629 ops/training.py:65 2019-01-17 03:58:11.796548: step 10645, loss = 0.66204 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:58:13.084226 ops/training.py:65 2019-01-17 03:58:13.084120: step 10646, loss = 0.72614 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:58:14.368663 ops/training.py:65 2019-01-17 03:58:14.368511: step 10647, loss = 0.60190 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:58:15.655314 ops/training.py:65 2019-01-17 03:58:15.655207: step 10648, loss = 0.57855 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:58:16.941716 ops/training.py:65 2019-01-17 03:58:16.941606: step 10649, loss = 0.68754 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:58:18.233020 ops/training.py:65 2019-01-17 03:58:18.232910: step 10650, loss = 0.65544 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:58:19.518758 ops/training.py:65 2019-01-17 03:58:19.518698: step 10651, loss = 0.63022 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:58:20.807769 ops/training.py:65 2019-01-17 03:58:20.807697: step 10652, loss = 0.65457 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:58:22.092373 ops/training.py:65 2019-01-17 03:58:22.092314: step 10653, loss = 0.68544 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:58:23.381805 ops/training.py:65 2019-01-17 03:58:23.381729: step 10654, loss = 0.64637 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:58:24.671683 ops/training.py:65 2019-01-17 03:58:24.671611: step 10655, loss = 0.68985 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:58:25.960291 ops/training.py:65 2019-01-17 03:58:25.960226: step 10656, loss = 0.65605 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:58:27.248875 ops/training.py:65 2019-01-17 03:58:27.248776: step 10657, loss = 0.55745 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:58:28.532724 ops/training.py:65 2019-01-17 03:58:28.532648: step 10658, loss = 0.72385 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:58:29.820644 ops/training.py:65 2019-01-17 03:58:29.820532: step 10659, loss = 0.62719 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:58:31.110581 ops/training.py:65 2019-01-17 03:58:31.110504: step 10660, loss = 0.62588 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:58:32.399763 ops/training.py:65 2019-01-17 03:58:32.399684: step 10661, loss = 0.60409 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:58:33.685382 ops/training.py:65 2019-01-17 03:58:33.685314: step 10662, loss = 0.59889 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:58:34.974080 ops/training.py:65 2019-01-17 03:58:34.973996: step 10663, loss = 0.56157 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:58:36.264683 ops/training.py:65 2019-01-17 03:58:36.264606: step 10664, loss = 0.68306 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:58:37.555215 ops/training.py:65 2019-01-17 03:58:37.555133: step 10665, loss = 0.72146 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 03:58:38.845050 ops/training.py:65 2019-01-17 03:58:38.844968: step 10666, loss = 0.72927 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:58:40.134610 ops/training.py:65 2019-01-17 03:58:40.134526: step 10667, loss = 0.70188 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:58:41.415630 ops/training.py:65 2019-01-17 03:58:41.415547: step 10668, loss = 0.61434 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:58:42.699120 ops/training.py:65 2019-01-17 03:58:42.699051: step 10669, loss = 0.59787 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 03:58:43.989792 ops/training.py:65 2019-01-17 03:58:43.989708: step 10670, loss = 0.59375 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:58:45.277712 ops/training.py:65 2019-01-17 03:58:45.277618: step 10671, loss = 0.71362 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:58:46.567846 ops/training.py:65 2019-01-17 03:58:46.567764: step 10672, loss = 0.58012 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 03:58:47.857143 ops/training.py:65 2019-01-17 03:58:47.857057: step 10673, loss = 0.76434 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 03:58:49.147018 ops/training.py:65 2019-01-17 03:58:49.146933: step 10674, loss = 0.57480 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:58:50.436133 ops/training.py:65 2019-01-17 03:58:50.436051: step 10675, loss = 0.67515 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:58:51.726572 ops/training.py:65 2019-01-17 03:58:51.726490: step 10676, loss = 0.64501 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:58:53.011921 ops/training.py:65 2019-01-17 03:58:53.011839: step 10677, loss = 0.59009 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:58:54.302702 ops/training.py:65 2019-01-17 03:58:54.302593: step 10678, loss = 0.65744 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:58:55.592513 ops/training.py:65 2019-01-17 03:58:55.592426: step 10679, loss = 0.68113 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:58:56.878908 ops/training.py:65 2019-01-17 03:58:56.878827: step 10680, loss = 0.66021 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:58:58.159808 ops/training.py:65 2019-01-17 03:58:58.159749: step 10681, loss = 0.62094 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:58:59.452608 ops/training.py:65 2019-01-17 03:58:59.452502: step 10682, loss = 0.74842 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:59:00.743462 ops/training.py:65 2019-01-17 03:59:00.743377: step 10683, loss = 0.61617 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:59:02.029842 ops/training.py:65 2019-01-17 03:59:02.029766: step 10684, loss = 0.68175 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:59:03.310932 ops/training.py:65 2019-01-17 03:59:03.310859: step 10685, loss = 0.58004 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:59:04.602135 ops/training.py:65 2019-01-17 03:59:04.602023: step 10686, loss = 0.65109 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:59:05.887717 ops/training.py:65 2019-01-17 03:59:05.887637: step 10687, loss = 0.65045 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:59:07.175955 ops/training.py:65 2019-01-17 03:59:07.175804: step 10688, loss = 0.64206 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:59:08.461265 ops/training.py:65 2019-01-17 03:59:08.461167: step 10689, loss = 0.76193 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 03:59:09.745097 ops/training.py:65 2019-01-17 03:59:09.744999: step 10690, loss = 0.66789 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:59:11.037221 ops/training.py:65 2019-01-17 03:59:11.037123: step 10691, loss = 0.69174 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:59:12.318034 ops/training.py:65 2019-01-17 03:59:12.317972: step 10692, loss = 0.70973 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:59:13.596515 ops/training.py:65 2019-01-17 03:59:13.596410: step 10693, loss = 0.66857 (25.0 examples/sec; 1.277 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:59:14.884676 ops/training.py:65 2019-01-17 03:59:14.884575: step 10694, loss = 0.53067 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 03:59:16.171068 ops/training.py:65 2019-01-17 03:59:16.170963: step 10695, loss = 0.70026 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:59:17.462012 ops/training.py:65 2019-01-17 03:59:17.461854: step 10696, loss = 0.67882 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:59:18.750538 ops/training.py:65 2019-01-17 03:59:18.750430: step 10697, loss = 0.68269 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:59:20.036550 ops/training.py:65 2019-01-17 03:59:20.036466: step 10698, loss = 0.65242 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:59:21.325018 ops/training.py:65 2019-01-17 03:59:21.324915: step 10699, loss = 0.71057 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:59:22.615825 ops/training.py:65 2019-01-17 03:59:22.615745: step 10700, loss = 0.61592 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:59:23.902569 ops/training.py:65 2019-01-17 03:59:23.902497: step 10701, loss = 0.61475 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:59:25.186367 ops/training.py:65 2019-01-17 03:59:25.186288: step 10702, loss = 0.60771 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 03:59:26.469551 ops/training.py:65 2019-01-17 03:59:26.469481: step 10703, loss = 0.65879 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:59:27.760928 ops/training.py:65 2019-01-17 03:59:27.760827: step 10704, loss = 0.63420 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:59:29.051075 ops/training.py:65 2019-01-17 03:59:29.050997: step 10705, loss = 0.66311 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:59:30.334951 ops/training.py:65 2019-01-17 03:59:30.334880: step 10706, loss = 0.69294 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:59:31.624417 ops/training.py:65 2019-01-17 03:59:31.624333: step 10707, loss = 0.57304 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 03:59:32.914035 ops/training.py:65 2019-01-17 03:59:32.913939: step 10708, loss = 0.74406 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 03:59:34.200464 ops/training.py:65 2019-01-17 03:59:34.200397: step 10709, loss = 0.57672 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:59:35.488427 ops/training.py:65 2019-01-17 03:59:35.488359: step 10710, loss = 0.61744 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:59:36.771659 ops/training.py:65 2019-01-17 03:59:36.771584: step 10711, loss = 0.58084 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 03:59:38.061265 ops/training.py:65 2019-01-17 03:59:38.061190: step 10712, loss = 0.55590 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:59:39.348632 ops/training.py:65 2019-01-17 03:59:39.348561: step 10713, loss = 0.70413 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 03:59:40.638513 ops/training.py:65 2019-01-17 03:59:40.638444: step 10714, loss = 0.69458 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:59:41.923225 ops/training.py:65 2019-01-17 03:59:41.923154: step 10715, loss = 0.68399 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:59:43.207064 ops/training.py:65 2019-01-17 03:59:43.206992: step 10716, loss = 0.67588 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:59:44.484274 ops/training.py:65 2019-01-17 03:59:44.484163: step 10717, loss = 0.67317 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:59:45.769026 ops/training.py:65 2019-01-17 03:59:45.768919: step 10718, loss = 0.74898 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 03:59:47.059280 ops/training.py:65 2019-01-17 03:59:47.059168: step 10719, loss = 0.64808 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:59:48.351571 ops/training.py:65 2019-01-17 03:59:48.351489: step 10720, loss = 0.57380 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:59:49.636754 ops/training.py:65 2019-01-17 03:59:49.636680: step 10721, loss = 0.66612 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:59:50.926424 ops/training.py:65 2019-01-17 03:59:50.926330: step 10722, loss = 0.64898 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:59:52.213708 ops/training.py:65 2019-01-17 03:59:52.213600: step 10723, loss = 0.59665 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:59:53.503404 ops/training.py:65 2019-01-17 03:59:53.503304: step 10724, loss = 0.66843 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 03:59:54.794653 ops/training.py:65 2019-01-17 03:59:54.794575: step 10725, loss = 0.68244 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:59:56.080092 ops/training.py:65 2019-01-17 03:59:56.080015: step 10726, loss = 0.65912 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 03:59:57.362530 ops/training.py:65 2019-01-17 03:59:57.362433: step 10727, loss = 0.61528 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 03:59:58.653161 ops/training.py:65 2019-01-17 03:59:58.653064: step 10728, loss = 0.63895 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 03:59:59.943808 ops/training.py:65 2019-01-17 03:59:59.943744: step 10729, loss = 0.65895 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:00:01.226642 ops/training.py:65 2019-01-17 04:00:01.226582: step 10730, loss = 0.64989 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:00:02.517590 ops/training.py:65 2019-01-17 04:00:02.517509: step 10731, loss = 0.67260 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:00:03.807563 ops/training.py:65 2019-01-17 04:00:03.807483: step 10732, loss = 0.66259 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:00:05.096001 ops/training.py:65 2019-01-17 04:00:05.095927: step 10733, loss = 0.67570 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:00:06.384262 ops/training.py:65 2019-01-17 04:00:06.384198: step 10734, loss = 0.72374 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 04:00:07.672941 ops/training.py:65 2019-01-17 04:00:07.672879: step 10735, loss = 0.79752 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 04:00:08.960205 ops/training.py:65 2019-01-17 04:00:08.960133: step 10736, loss = 0.63477 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:00:10.247699 ops/training.py:65 2019-01-17 04:00:10.247607: step 10737, loss = 0.64824 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:00:11.531124 ops/training.py:65 2019-01-17 04:00:11.531041: step 10738, loss = 0.65250 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:00:12.823217 ops/training.py:65 2019-01-17 04:00:12.823111: step 10739, loss = 0.64317 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:00:14.109593 ops/training.py:65 2019-01-17 04:00:14.109498: step 10740, loss = 0.57580 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:00:15.393600 ops/training.py:65 2019-01-17 04:00:15.393505: step 10741, loss = 0.75524 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:00:16.677924 ops/training.py:65 2019-01-17 04:00:16.677814: step 10742, loss = 0.61032 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:00:17.969407 ops/training.py:65 2019-01-17 04:00:17.969328: step 10743, loss = 0.72244 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:00:19.253499 ops/training.py:65 2019-01-17 04:00:19.253425: step 10744, loss = 0.54600 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:00:20.537948 ops/training.py:65 2019-01-17 04:00:20.537858: step 10745, loss = 0.63420 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:00:21.822045 ops/training.py:65 2019-01-17 04:00:21.821902: step 10746, loss = 0.65270 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:00:23.115319 ops/training.py:65 2019-01-17 04:00:23.115230: step 10747, loss = 0.64450 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:00:24.404434 ops/training.py:65 2019-01-17 04:00:24.404328: step 10748, loss = 0.64490 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:00:25.688763 ops/training.py:65 2019-01-17 04:00:25.688687: step 10749, loss = 0.69956 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:00:26.981745 ops/training.py:65 2019-01-17 04:00:26.981587: step 10750, loss = 0.70750 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:00:28.266587 ops/training.py:65 2019-01-17 04:00:28.266513: step 10751, loss = 0.59064 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:00:29.554417 ops/training.py:65 2019-01-17 04:00:29.554309: step 10752, loss = 0.72735 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:00:30.846166 ops/training.py:65 2019-01-17 04:00:30.846071: step 10753, loss = 0.65274 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:00:32.126539 ops/training.py:65 2019-01-17 04:00:32.126453: step 10754, loss = 0.64372 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:00:33.412129 ops/training.py:65 2019-01-17 04:00:33.412028: step 10755, loss = 0.60574 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:00:34.696607 ops/training.py:65 2019-01-17 04:00:34.696501: step 10756, loss = 0.59573 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:00:35.986590 ops/training.py:65 2019-01-17 04:00:35.986496: step 10757, loss = 0.77130 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:00:37.278054 ops/training.py:65 2019-01-17 04:00:37.277973: step 10758, loss = 0.59373 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:00:38.567699 ops/training.py:65 2019-01-17 04:00:38.567631: step 10759, loss = 0.62996 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:00:39.856492 ops/training.py:65 2019-01-17 04:00:39.856398: step 10760, loss = 0.57907 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:00:41.140916 ops/training.py:65 2019-01-17 04:00:41.140833: step 10761, loss = 0.62306 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:00:42.433626 ops/training.py:65 2019-01-17 04:00:42.433472: step 10762, loss = 0.63756 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:00:43.723905 ops/training.py:65 2019-01-17 04:00:43.723820: step 10763, loss = 0.68965 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:00:45.008399 ops/training.py:65 2019-01-17 04:00:45.008326: step 10764, loss = 0.70690 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:00:46.299319 ops/training.py:65 2019-01-17 04:00:46.299173: step 10765, loss = 0.73396 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:00:47.590704 ops/training.py:65 2019-01-17 04:00:47.590615: step 10766, loss = 0.64861 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:00:48.879105 ops/training.py:65 2019-01-17 04:00:48.879023: step 10767, loss = 0.59017 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:00:50.169585 ops/training.py:65 2019-01-17 04:00:50.169509: step 10768, loss = 0.62629 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:00:51.460236 ops/training.py:65 2019-01-17 04:00:51.460154: step 10769, loss = 0.66646 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:00:52.746372 ops/training.py:65 2019-01-17 04:00:52.746294: step 10770, loss = 0.61371 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:00:54.036363 ops/training.py:65 2019-01-17 04:00:54.036279: step 10771, loss = 0.61836 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:00:55.320592 ops/training.py:65 2019-01-17 04:00:55.320523: step 10772, loss = 0.65510 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:00:56.609147 ops/training.py:65 2019-01-17 04:00:56.609038: step 10773, loss = 0.68564 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:00:57.901554 ops/training.py:65 2019-01-17 04:00:57.901409: step 10774, loss = 0.63711 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:00:59.188770 ops/training.py:65 2019-01-17 04:00:59.188697: step 10775, loss = 0.66499 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:01:00.467718 ops/training.py:65 2019-01-17 04:01:00.467653: step 10776, loss = 0.65734 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:01:01.760460 ops/training.py:65 2019-01-17 04:01:01.760322: step 10777, loss = 0.64525 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:01:03.046963 ops/training.py:65 2019-01-17 04:01:03.046894: step 10778, loss = 0.71348 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:01:04.326698 ops/training.py:65 2019-01-17 04:01:04.326620: step 10779, loss = 0.68692 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:01:05.613150 ops/training.py:65 2019-01-17 04:01:05.613072: step 10780, loss = 0.67355 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:01:06.903464 ops/training.py:65 2019-01-17 04:01:06.903381: step 10781, loss = 0.54770 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:01:08.192937 ops/training.py:65 2019-01-17 04:01:08.192862: step 10782, loss = 0.67417 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:01:09.483559 ops/training.py:65 2019-01-17 04:01:09.483479: step 10783, loss = 0.64940 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:01:10.767225 ops/training.py:65 2019-01-17 04:01:10.767136: step 10784, loss = 0.70915 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:01:12.057961 ops/training.py:65 2019-01-17 04:01:12.057884: step 10785, loss = 0.67531 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:01:13.345750 ops/training.py:65 2019-01-17 04:01:13.345654: step 10786, loss = 0.69607 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:01:14.637580 ops/training.py:65 2019-01-17 04:01:14.637480: step 10787, loss = 0.67753 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:01:15.929325 ops/training.py:65 2019-01-17 04:01:15.929253: step 10788, loss = 0.67250 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:01:17.215269 ops/training.py:65 2019-01-17 04:01:17.215196: step 10789, loss = 0.73522 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:01:18.498730 ops/training.py:65 2019-01-17 04:01:18.498673: step 10790, loss = 0.65664 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:01:19.792532 ops/training.py:65 2019-01-17 04:01:19.792376: step 10791, loss = 0.71592 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:01:21.084679 ops/training.py:65 2019-01-17 04:01:21.084610: step 10792, loss = 0.61629 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:01:22.374842 ops/training.py:65 2019-01-17 04:01:22.374770: step 10793, loss = 0.65815 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:01:23.660048 ops/training.py:65 2019-01-17 04:01:23.659977: step 10794, loss = 0.73878 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:01:24.948805 ops/training.py:65 2019-01-17 04:01:24.948710: step 10795, loss = 0.78418 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 04:01:26.237228 ops/training.py:65 2019-01-17 04:01:26.237131: step 10796, loss = 0.67435 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:01:27.526462 ops/training.py:65 2019-01-17 04:01:27.526353: step 10797, loss = 0.67410 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:01:28.816199 ops/training.py:65 2019-01-17 04:01:28.816130: step 10798, loss = 0.74508 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:01:30.106051 ops/training.py:65 2019-01-17 04:01:30.105981: step 10799, loss = 0.74554 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:01:31.395735 ops/training.py:65 2019-01-17 04:01:31.395641: step 10800, loss = 0.72235 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:01:32.685869 ops/training.py:65 2019-01-17 04:01:32.685784: step 10801, loss = 0.71680 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 04:01:33.976162 ops/training.py:65 2019-01-17 04:01:33.976089: step 10802, loss = 0.67128 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:01:35.264546 ops/training.py:65 2019-01-17 04:01:35.264447: step 10803, loss = 0.76895 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:01:36.550042 ops/training.py:65 2019-01-17 04:01:36.549956: step 10804, loss = 0.72280 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:01:37.838838 ops/training.py:65 2019-01-17 04:01:37.838723: step 10805, loss = 0.68155 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:01:39.128935 ops/training.py:65 2019-01-17 04:01:39.128858: step 10806, loss = 0.66121 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:01:40.413940 ops/training.py:65 2019-01-17 04:01:40.413870: step 10807, loss = 0.63555 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:01:41.697933 ops/training.py:65 2019-01-17 04:01:41.697865: step 10808, loss = 0.68886 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:01:42.987486 ops/training.py:65 2019-01-17 04:01:42.987390: step 10809, loss = 0.69826 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:01:44.271370 ops/training.py:65 2019-01-17 04:01:44.271293: step 10810, loss = 0.64984 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:01:45.560952 ops/training.py:65 2019-01-17 04:01:45.560847: step 10811, loss = 0.63946 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:01:46.845664 ops/training.py:65 2019-01-17 04:01:46.845599: step 10812, loss = 0.68154 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:01:48.134033 ops/training.py:65 2019-01-17 04:01:48.133961: step 10813, loss = 0.64847 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:01:49.418344 ops/training.py:65 2019-01-17 04:01:49.418276: step 10814, loss = 0.57747 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:01:50.703562 ops/training.py:65 2019-01-17 04:01:50.703477: step 10815, loss = 0.64371 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:01:51.987444 ops/training.py:65 2019-01-17 04:01:51.987344: step 10816, loss = 0.59114 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:01:53.275314 ops/training.py:65 2019-01-17 04:01:53.275207: step 10817, loss = 0.70948 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:01:54.558205 ops/training.py:65 2019-01-17 04:01:54.558110: step 10818, loss = 0.78736 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:01:55.850312 ops/training.py:65 2019-01-17 04:01:55.850212: step 10819, loss = 0.65561 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:01:57.140619 ops/training.py:65 2019-01-17 04:01:57.140550: step 10820, loss = 0.70413 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:01:58.430699 ops/training.py:65 2019-01-17 04:01:58.430604: step 10821, loss = 0.66262 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:01:59.720383 ops/training.py:65 2019-01-17 04:01:59.720283: step 10822, loss = 0.70319 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:02:01.009437 ops/training.py:65 2019-01-17 04:02:01.009340: step 10823, loss = 0.75416 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:02:02.298657 ops/training.py:65 2019-01-17 04:02:02.298556: step 10824, loss = 0.62372 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:02:03.586589 ops/training.py:65 2019-01-17 04:02:03.586507: step 10825, loss = 0.88088 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.34375
I4672 2019-01-17 04:02:04.876067 ops/training.py:65 2019-01-17 04:02:04.875970: step 10826, loss = 0.52469 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:02:06.165634 ops/training.py:65 2019-01-17 04:02:06.165553: step 10827, loss = 0.72742 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:02:07.451881 ops/training.py:65 2019-01-17 04:02:07.451804: step 10828, loss = 0.73684 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:02:08.739908 ops/training.py:65 2019-01-17 04:02:08.739802: step 10829, loss = 0.59980 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:02:10.028776 ops/training.py:65 2019-01-17 04:02:10.028657: step 10830, loss = 0.65955 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:02:11.317605 ops/training.py:65 2019-01-17 04:02:11.317498: step 10831, loss = 0.70511 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:02:12.603556 ops/training.py:65 2019-01-17 04:02:12.603485: step 10832, loss = 0.71542 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:02:13.893263 ops/training.py:65 2019-01-17 04:02:13.893190: step 10833, loss = 0.69091 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:02:15.182348 ops/training.py:65 2019-01-17 04:02:15.182268: step 10834, loss = 0.67618 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:02:16.471999 ops/training.py:65 2019-01-17 04:02:16.471927: step 10835, loss = 0.66447 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:02:17.761018 ops/training.py:65 2019-01-17 04:02:17.760949: step 10836, loss = 0.68865 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:02:19.047890 ops/training.py:65 2019-01-17 04:02:19.047817: step 10837, loss = 0.64071 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:02:20.333059 ops/training.py:65 2019-01-17 04:02:20.332988: step 10838, loss = 0.71916 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:02:21.620997 ops/training.py:65 2019-01-17 04:02:21.620929: step 10839, loss = 0.69213 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:02:22.903725 ops/training.py:65 2019-01-17 04:02:22.903665: step 10840, loss = 0.72136 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:02:24.187021 ops/training.py:65 2019-01-17 04:02:24.186923: step 10841, loss = 0.74934 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:02:25.479515 ops/training.py:65 2019-01-17 04:02:25.479403: step 10842, loss = 0.66015 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:02:26.770885 ops/training.py:65 2019-01-17 04:02:26.770813: step 10843, loss = 0.72237 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:02:28.059789 ops/training.py:65 2019-01-17 04:02:28.059715: step 10844, loss = 0.68749 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:02:29.347878 ops/training.py:65 2019-01-17 04:02:29.347812: step 10845, loss = 0.67789 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:02:30.637812 ops/training.py:65 2019-01-17 04:02:30.637722: step 10846, loss = 0.65125 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:02:31.922010 ops/training.py:65 2019-01-17 04:02:31.921928: step 10847, loss = 0.64702 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:02:33.207611 ops/training.py:65 2019-01-17 04:02:33.207514: step 10848, loss = 0.64990 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:02:34.492463 ops/training.py:65 2019-01-17 04:02:34.492391: step 10849, loss = 0.63660 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:02:35.779734 ops/training.py:65 2019-01-17 04:02:35.779655: step 10850, loss = 0.58678 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:02:37.071660 ops/training.py:65 2019-01-17 04:02:37.071565: step 10851, loss = 0.64958 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:02:38.358223 ops/training.py:65 2019-01-17 04:02:38.358154: step 10852, loss = 0.68064 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 04:02:39.643746 ops/training.py:65 2019-01-17 04:02:39.643685: step 10853, loss = 0.71462 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:02:40.926766 ops/training.py:65 2019-01-17 04:02:40.926664: step 10854, loss = 0.64364 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:02:42.218639 ops/training.py:65 2019-01-17 04:02:42.218483: step 10855, loss = 0.63018 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:02:43.504851 ops/training.py:65 2019-01-17 04:02:43.504787: step 10856, loss = 0.56676 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:02:44.789279 ops/training.py:65 2019-01-17 04:02:44.789188: step 10857, loss = 0.72439 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:02:46.077954 ops/training.py:65 2019-01-17 04:02:46.077881: step 10858, loss = 0.56381 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:02:47.367361 ops/training.py:65 2019-01-17 04:02:47.367287: step 10859, loss = 0.63227 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:02:48.656761 ops/training.py:65 2019-01-17 04:02:48.656689: step 10860, loss = 0.66329 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:02:49.946778 ops/training.py:65 2019-01-17 04:02:49.946713: step 10861, loss = 0.58704 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:02:51.237030 ops/training.py:65 2019-01-17 04:02:51.236967: step 10862, loss = 0.64492 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:02:52.526189 ops/training.py:65 2019-01-17 04:02:52.526119: step 10863, loss = 0.71019 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:02:53.814566 ops/training.py:65 2019-01-17 04:02:53.814492: step 10864, loss = 0.67458 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:02:55.102800 ops/training.py:65 2019-01-17 04:02:55.102707: step 10865, loss = 0.66336 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:02:56.391674 ops/training.py:65 2019-01-17 04:02:56.391599: step 10866, loss = 0.59412 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:02:57.679423 ops/training.py:65 2019-01-17 04:02:57.679357: step 10867, loss = 0.68295 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:02:58.962919 ops/training.py:65 2019-01-17 04:02:58.962843: step 10868, loss = 0.56201 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:03:00.251857 ops/training.py:65 2019-01-17 04:03:00.251761: step 10869, loss = 0.62792 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:03:01.537210 ops/training.py:65 2019-01-17 04:03:01.537140: step 10870, loss = 0.64985 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:03:02.825624 ops/training.py:65 2019-01-17 04:03:02.825525: step 10871, loss = 0.62572 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:03:04.114410 ops/training.py:65 2019-01-17 04:03:04.114342: step 10872, loss = 0.65271 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:03:05.401670 ops/training.py:65 2019-01-17 04:03:05.401605: step 10873, loss = 0.66575 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:03:06.686086 ops/training.py:65 2019-01-17 04:03:06.686015: step 10874, loss = 0.67847 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:03:07.969590 ops/training.py:65 2019-01-17 04:03:07.969483: step 10875, loss = 0.67613 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:03:09.255892 ops/training.py:65 2019-01-17 04:03:09.255780: step 10876, loss = 0.59602 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:03:10.548525 ops/training.py:65 2019-01-17 04:03:10.548379: step 10877, loss = 0.62144 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:03:11.833615 ops/training.py:65 2019-01-17 04:03:11.833529: step 10878, loss = 0.66849 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:03:13.126039 ops/training.py:65 2019-01-17 04:03:13.125940: step 10879, loss = 0.64103 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:03:14.412194 ops/training.py:65 2019-01-17 04:03:14.412122: step 10880, loss = 0.68789 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:03:15.700802 ops/training.py:65 2019-01-17 04:03:15.700729: step 10881, loss = 0.63663 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:03:16.991825 ops/training.py:65 2019-01-17 04:03:16.991760: step 10882, loss = 0.64140 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:03:18.279590 ops/training.py:65 2019-01-17 04:03:18.279518: step 10883, loss = 0.65854 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:03:19.563606 ops/training.py:65 2019-01-17 04:03:19.563538: step 10884, loss = 0.68212 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:03:20.850067 ops/training.py:65 2019-01-17 04:03:20.849920: step 10885, loss = 0.63572 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:03:22.139413 ops/training.py:65 2019-01-17 04:03:22.139322: step 10886, loss = 0.59646 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:03:23.429207 ops/training.py:65 2019-01-17 04:03:23.429125: step 10887, loss = 0.73038 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 04:03:24.718855 ops/training.py:65 2019-01-17 04:03:24.718784: step 10888, loss = 0.69916 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:03:26.008144 ops/training.py:65 2019-01-17 04:03:26.008073: step 10889, loss = 0.65401 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:03:27.293211 ops/training.py:65 2019-01-17 04:03:27.293138: step 10890, loss = 0.60305 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:03:28.581045 ops/training.py:65 2019-01-17 04:03:28.580981: step 10891, loss = 0.66713 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:03:29.866274 ops/training.py:65 2019-01-17 04:03:29.866201: step 10892, loss = 0.70099 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:03:31.154195 ops/training.py:65 2019-01-17 04:03:31.154129: step 10893, loss = 0.65054 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:03:32.438559 ops/training.py:65 2019-01-17 04:03:32.438493: step 10894, loss = 0.62970 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:03:33.722287 ops/training.py:65 2019-01-17 04:03:33.722212: step 10895, loss = 0.69478 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:03:35.009833 ops/training.py:65 2019-01-17 04:03:35.009732: step 10896, loss = 0.63454 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:03:36.297347 ops/training.py:65 2019-01-17 04:03:36.297261: step 10897, loss = 0.64131 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:03:37.589038 ops/training.py:65 2019-01-17 04:03:37.588938: step 10898, loss = 0.62340 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:03:38.873936 ops/training.py:65 2019-01-17 04:03:38.873872: step 10899, loss = 0.58304 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:03:40.157804 ops/training.py:65 2019-01-17 04:03:40.157740: step 10900, loss = 0.69077 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:03:41.434025 ops/training.py:65 2019-01-17 04:03:41.433943: step 10901, loss = 0.58612 (25.1 examples/sec; 1.275 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:03:42.717702 ops/training.py:65 2019-01-17 04:03:42.717599: step 10902, loss = 0.65173 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:03:44.006430 ops/training.py:65 2019-01-17 04:03:44.006330: step 10903, loss = 0.63267 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:03:45.290822 ops/training.py:65 2019-01-17 04:03:45.290715: step 10904, loss = 0.70643 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:03:46.582795 ops/training.py:65 2019-01-17 04:03:46.582691: step 10905, loss = 0.70362 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:03:47.869611 ops/training.py:65 2019-01-17 04:03:47.869535: step 10906, loss = 0.51186 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:03:49.153577 ops/training.py:65 2019-01-17 04:03:49.153477: step 10907, loss = 0.55182 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:03:50.440445 ops/training.py:65 2019-01-17 04:03:50.440335: step 10908, loss = 0.76834 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:03:51.723929 ops/training.py:65 2019-01-17 04:03:51.723837: step 10909, loss = 0.58633 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:03:53.011304 ops/training.py:65 2019-01-17 04:03:53.011195: step 10910, loss = 0.72229 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:03:54.298434 ops/training.py:65 2019-01-17 04:03:54.298332: step 10911, loss = 0.67242 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:03:55.583992 ops/training.py:65 2019-01-17 04:03:55.583929: step 10912, loss = 0.57741 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:03:56.869480 ops/training.py:65 2019-01-17 04:03:56.869393: step 10913, loss = 0.84377 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 04:03:58.149143 ops/training.py:65 2019-01-17 04:03:58.149037: step 10914, loss = 0.63286 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:03:59.439730 ops/training.py:65 2019-01-17 04:03:59.439621: step 10915, loss = 0.64210 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:04:00.724054 ops/training.py:65 2019-01-17 04:04:00.723987: step 10916, loss = 0.71083 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:04:02.008916 ops/training.py:65 2019-01-17 04:04:02.008810: step 10917, loss = 0.57272 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:04:03.297675 ops/training.py:65 2019-01-17 04:04:03.297601: step 10918, loss = 0.73487 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:04:04.585674 ops/training.py:65 2019-01-17 04:04:04.585573: step 10919, loss = 0.61359 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:04:05.868427 ops/training.py:65 2019-01-17 04:04:05.868355: step 10920, loss = 0.63483 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:04:07.150081 ops/training.py:65 2019-01-17 04:04:07.149983: step 10921, loss = 0.64174 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:04:08.441880 ops/training.py:65 2019-01-17 04:04:08.441724: step 10922, loss = 0.58556 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:04:09.732102 ops/training.py:65 2019-01-17 04:04:09.732007: step 10923, loss = 0.59120 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:04:11.016424 ops/training.py:65 2019-01-17 04:04:11.016361: step 10924, loss = 0.69118 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:04:12.304292 ops/training.py:65 2019-01-17 04:04:12.304199: step 10925, loss = 0.56600 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:04:13.589749 ops/training.py:65 2019-01-17 04:04:13.589683: step 10926, loss = 0.67316 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:04:14.873401 ops/training.py:65 2019-01-17 04:04:14.873299: step 10927, loss = 0.54302 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:04:16.165105 ops/training.py:65 2019-01-17 04:04:16.165005: step 10928, loss = 0.72360 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:04:17.450915 ops/training.py:65 2019-01-17 04:04:17.450842: step 10929, loss = 0.59759 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:04:18.739548 ops/training.py:65 2019-01-17 04:04:18.739472: step 10930, loss = 0.67061 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:04:20.029900 ops/training.py:65 2019-01-17 04:04:20.029813: step 10931, loss = 0.68214 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:04:21.315378 ops/training.py:65 2019-01-17 04:04:21.315303: step 10932, loss = 0.57244 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:04:22.605505 ops/training.py:65 2019-01-17 04:04:22.605431: step 10933, loss = 0.68117 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:04:23.890348 ops/training.py:65 2019-01-17 04:04:23.890278: step 10934, loss = 0.54899 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:04:25.175756 ops/training.py:65 2019-01-17 04:04:25.175654: step 10935, loss = 0.63006 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:04:26.462556 ops/training.py:65 2019-01-17 04:04:26.462446: step 10936, loss = 0.70905 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:04:27.749236 ops/training.py:65 2019-01-17 04:04:27.749124: step 10937, loss = 0.68847 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:04:29.036715 ops/training.py:65 2019-01-17 04:04:29.036601: step 10938, loss = 0.61032 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:04:30.326960 ops/training.py:65 2019-01-17 04:04:30.326869: step 10939, loss = 0.69286 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:04:31.612467 ops/training.py:65 2019-01-17 04:04:31.612394: step 10940, loss = 0.67098 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:04:32.904514 ops/training.py:65 2019-01-17 04:04:32.904444: step 10941, loss = 0.66801 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:04:34.193055 ops/training.py:65 2019-01-17 04:04:34.192986: step 10942, loss = 0.63057 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:04:35.482119 ops/training.py:65 2019-01-17 04:04:35.482016: step 10943, loss = 0.58898 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:04:36.773311 ops/training.py:65 2019-01-17 04:04:36.773213: step 10944, loss = 0.60815 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:04:38.063152 ops/training.py:65 2019-01-17 04:04:38.063076: step 10945, loss = 0.62203 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:04:39.353550 ops/training.py:65 2019-01-17 04:04:39.353436: step 10946, loss = 0.61362 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:04:40.642490 ops/training.py:65 2019-01-17 04:04:40.642422: step 10947, loss = 0.62638 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:04:41.932050 ops/training.py:65 2019-01-17 04:04:41.931950: step 10948, loss = 0.54287 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:04:43.221403 ops/training.py:65 2019-01-17 04:04:43.221278: step 10949, loss = 0.61639 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:04:44.511457 ops/training.py:65 2019-01-17 04:04:44.511390: step 10950, loss = 0.62268 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:04:45.800566 ops/training.py:65 2019-01-17 04:04:45.800496: step 10951, loss = 0.60884 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:04:47.089698 ops/training.py:65 2019-01-17 04:04:47.089626: step 10952, loss = 0.59090 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:04:48.377366 ops/training.py:65 2019-01-17 04:04:48.377295: step 10953, loss = 0.60226 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:04:49.665962 ops/training.py:65 2019-01-17 04:04:49.665897: step 10954, loss = 0.70636 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:04:50.950227 ops/training.py:65 2019-01-17 04:04:50.950166: step 10955, loss = 0.70811 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:04:52.238894 ops/training.py:65 2019-01-17 04:04:52.238827: step 10956, loss = 0.71367 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:04:53.523530 ops/training.py:65 2019-01-17 04:04:53.523459: step 10957, loss = 0.65187 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:04:54.814227 ops/training.py:65 2019-01-17 04:04:54.814124: step 10958, loss = 0.64695 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:04:56.103043 ops/training.py:65 2019-01-17 04:04:56.102978: step 10959, loss = 0.67756 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:04:57.391234 ops/training.py:65 2019-01-17 04:04:57.391162: step 10960, loss = 0.66139 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:04:58.678822 ops/training.py:65 2019-01-17 04:04:58.678743: step 10961, loss = 0.61118 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:04:59.963629 ops/training.py:65 2019-01-17 04:04:59.963559: step 10962, loss = 0.61693 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:05:01.246756 ops/training.py:65 2019-01-17 04:05:01.246694: step 10963, loss = 0.58774 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:05:02.528526 ops/training.py:65 2019-01-17 04:05:02.528445: step 10964, loss = 0.63049 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:05:03.820203 ops/training.py:65 2019-01-17 04:05:03.820059: step 10965, loss = 0.67467 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:05:05.111397 ops/training.py:65 2019-01-17 04:05:05.111334: step 10966, loss = 0.74571 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:05:06.401315 ops/training.py:65 2019-01-17 04:05:06.401249: step 10967, loss = 0.65418 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:05:07.689422 ops/training.py:65 2019-01-17 04:05:07.689341: step 10968, loss = 0.80062 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 04:05:08.978748 ops/training.py:65 2019-01-17 04:05:08.978673: step 10969, loss = 0.57172 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:05:10.267527 ops/training.py:65 2019-01-17 04:05:10.267451: step 10970, loss = 0.72319 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:05:11.551716 ops/training.py:65 2019-01-17 04:05:11.551647: step 10971, loss = 0.61656 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:05:12.840093 ops/training.py:65 2019-01-17 04:05:12.840006: step 10972, loss = 0.66172 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:05:14.124589 ops/training.py:65 2019-01-17 04:05:14.124520: step 10973, loss = 0.69446 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:05:15.413478 ops/training.py:65 2019-01-17 04:05:15.413372: step 10974, loss = 0.62615 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:05:16.698864 ops/training.py:65 2019-01-17 04:05:16.698791: step 10975, loss = 0.63207 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:05:17.983439 ops/training.py:65 2019-01-17 04:05:17.983364: step 10976, loss = 0.72101 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:05:19.265834 ops/training.py:65 2019-01-17 04:05:19.265752: step 10977, loss = 0.69580 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:05:20.549569 ops/training.py:65 2019-01-17 04:05:20.549464: step 10978, loss = 0.61590 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:05:21.836570 ops/training.py:65 2019-01-17 04:05:21.836476: step 10979, loss = 0.70084 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:05:23.124181 ops/training.py:65 2019-01-17 04:05:23.124078: step 10980, loss = 0.70598 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:05:24.416012 ops/training.py:65 2019-01-17 04:05:24.415948: step 10981, loss = 0.74169 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 04:05:25.706274 ops/training.py:65 2019-01-17 04:05:25.706201: step 10982, loss = 0.64995 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:05:26.990759 ops/training.py:65 2019-01-17 04:05:26.990700: step 10983, loss = 0.67691 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:05:28.273430 ops/training.py:65 2019-01-17 04:05:28.273368: step 10984, loss = 0.64854 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:05:29.554606 ops/training.py:65 2019-01-17 04:05:29.554510: step 10985, loss = 0.67040 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:05:30.841085 ops/training.py:65 2019-01-17 04:05:30.840976: step 10986, loss = 0.66961 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:05:32.126368 ops/training.py:65 2019-01-17 04:05:32.126265: step 10987, loss = 0.64074 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:05:33.417086 ops/training.py:65 2019-01-17 04:05:33.417015: step 10988, loss = 0.60849 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:05:34.701629 ops/training.py:65 2019-01-17 04:05:34.701566: step 10989, loss = 0.63521 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:05:35.985503 ops/training.py:65 2019-01-17 04:05:35.985432: step 10990, loss = 0.68800 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:05:37.277957 ops/training.py:65 2019-01-17 04:05:37.277832: step 10991, loss = 0.70338 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:05:38.569716 ops/training.py:65 2019-01-17 04:05:38.569629: step 10992, loss = 0.62903 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:05:39.859629 ops/training.py:65 2019-01-17 04:05:39.859545: step 10993, loss = 0.68060 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:05:41.145204 ops/training.py:65 2019-01-17 04:05:41.145129: step 10994, loss = 0.66089 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:05:42.434537 ops/training.py:65 2019-01-17 04:05:42.434462: step 10995, loss = 0.71763 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:05:43.720035 ops/training.py:65 2019-01-17 04:05:43.719953: step 10996, loss = 0.67591 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:05:45.006587 ops/training.py:65 2019-01-17 04:05:45.006470: step 10997, loss = 0.61986 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:05:46.298419 ops/training.py:65 2019-01-17 04:05:46.298315: step 10998, loss = 0.60292 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:05:47.589406 ops/training.py:65 2019-01-17 04:05:47.589326: step 10999, loss = 0.66395 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:05:48.873531 ops/training.py:65 2019-01-17 04:05:48.873439: step 11000, loss = 0.60705 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:05:50.163318 ops/training.py:65 2019-01-17 04:05:50.163159: step 11001, loss = 0.61934 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:05:51.454154 ops/training.py:65 2019-01-17 04:05:51.454077: step 11002, loss = 0.66944 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:05:52.742924 ops/training.py:65 2019-01-17 04:05:52.742861: step 11003, loss = 0.68778 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:05:54.028741 ops/training.py:65 2019-01-17 04:05:54.028671: step 11004, loss = 0.71014 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:05:55.319890 ops/training.py:65 2019-01-17 04:05:55.319794: step 11005, loss = 0.62018 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:05:56.610194 ops/training.py:65 2019-01-17 04:05:56.610080: step 11006, loss = 0.63151 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:05:57.900044 ops/training.py:65 2019-01-17 04:05:57.899956: step 11007, loss = 0.57658 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:05:59.188273 ops/training.py:65 2019-01-17 04:05:59.188168: step 11008, loss = 0.57383 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:06:00.473331 ops/training.py:65 2019-01-17 04:06:00.473265: step 11009, loss = 0.69723 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:06:01.760142 ops/training.py:65 2019-01-17 04:06:01.760023: step 11010, loss = 0.66434 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:06:03.048863 ops/training.py:65 2019-01-17 04:06:03.048771: step 11011, loss = 0.62860 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:06:04.329474 ops/training.py:65 2019-01-17 04:06:04.329371: step 11012, loss = 0.72640 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:06:05.616001 ops/training.py:65 2019-01-17 04:06:05.615902: step 11013, loss = 0.64662 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:06:06.902027 ops/training.py:65 2019-01-17 04:06:06.901934: step 11014, loss = 0.63346 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:06:08.193001 ops/training.py:65 2019-01-17 04:06:08.192840: step 11015, loss = 0.66714 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:06:09.479403 ops/training.py:65 2019-01-17 04:06:09.479330: step 11016, loss = 0.57454 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:06:10.765729 ops/training.py:65 2019-01-17 04:06:10.765635: step 11017, loss = 0.57455 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:06:12.054413 ops/training.py:65 2019-01-17 04:06:12.054313: step 11018, loss = 0.63017 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:06:13.346793 ops/training.py:65 2019-01-17 04:06:13.346699: step 11019, loss = 0.58986 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:06:14.632992 ops/training.py:65 2019-01-17 04:06:14.632915: step 11020, loss = 0.65038 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:06:15.918147 ops/training.py:65 2019-01-17 04:06:15.918074: step 11021, loss = 0.67441 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:06:17.207085 ops/training.py:65 2019-01-17 04:06:17.206980: step 11022, loss = 0.71725 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:06:18.496692 ops/training.py:65 2019-01-17 04:06:18.496630: step 11023, loss = 0.55174 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:06:19.780556 ops/training.py:65 2019-01-17 04:06:19.780492: step 11024, loss = 0.59228 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:06:21.065295 ops/training.py:65 2019-01-17 04:06:21.065196: step 11025, loss = 0.74075 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:06:22.352348 ops/training.py:65 2019-01-17 04:06:22.352238: step 11026, loss = 0.68169 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:06:23.637192 ops/training.py:65 2019-01-17 04:06:23.637098: step 11027, loss = 0.59911 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:06:24.924909 ops/training.py:65 2019-01-17 04:06:24.924799: step 11028, loss = 0.62646 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:06:26.215922 ops/training.py:65 2019-01-17 04:06:26.215818: step 11029, loss = 0.67180 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:06:27.505621 ops/training.py:65 2019-01-17 04:06:27.505529: step 11030, loss = 0.66743 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:06:28.793356 ops/training.py:65 2019-01-17 04:06:28.793292: step 11031, loss = 0.61059 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:06:30.077474 ops/training.py:65 2019-01-17 04:06:30.077410: step 11032, loss = 0.67604 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:06:31.362217 ops/training.py:65 2019-01-17 04:06:31.362154: step 11033, loss = 0.59394 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:06:32.649352 ops/training.py:65 2019-01-17 04:06:32.649245: step 11034, loss = 0.68411 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:06:33.940510 ops/training.py:65 2019-01-17 04:06:33.940441: step 11035, loss = 0.69874 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:06:35.233502 ops/training.py:65 2019-01-17 04:06:35.233425: step 11036, loss = 0.73548 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:06:36.522257 ops/training.py:65 2019-01-17 04:06:36.522184: step 11037, loss = 0.68310 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:06:37.811242 ops/training.py:65 2019-01-17 04:06:37.811167: step 11038, loss = 0.63734 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:06:39.096247 ops/training.py:65 2019-01-17 04:06:39.096180: step 11039, loss = 0.63115 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:06:40.376142 ops/training.py:65 2019-01-17 04:06:40.376049: step 11040, loss = 0.59953 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:06:41.660556 ops/training.py:65 2019-01-17 04:06:41.660398: step 11041, loss = 0.62277 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:06:42.946574 ops/training.py:65 2019-01-17 04:06:42.946461: step 11042, loss = 0.63164 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:06:44.235893 ops/training.py:65 2019-01-17 04:06:44.235816: step 11043, loss = 0.76289 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:06:45.524610 ops/training.py:65 2019-01-17 04:06:45.524508: step 11044, loss = 0.56173 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:06:46.814367 ops/training.py:65 2019-01-17 04:06:46.814302: step 11045, loss = 0.69786 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:06:48.103628 ops/training.py:65 2019-01-17 04:06:48.103534: step 11046, loss = 0.69262 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:06:49.393051 ops/training.py:65 2019-01-17 04:06:49.392957: step 11047, loss = 0.56043 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:06:50.677278 ops/training.py:65 2019-01-17 04:06:50.677201: step 11048, loss = 0.67019 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:06:51.961144 ops/training.py:65 2019-01-17 04:06:51.961043: step 11049, loss = 0.62187 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:06:53.250190 ops/training.py:65 2019-01-17 04:06:53.250086: step 11050, loss = 0.71481 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 04:06:54.540273 ops/training.py:65 2019-01-17 04:06:54.540173: step 11051, loss = 0.62636 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:06:55.832782 ops/training.py:65 2019-01-17 04:06:55.832700: step 11052, loss = 0.56299 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:06:57.121501 ops/training.py:65 2019-01-17 04:06:57.121420: step 11053, loss = 0.56531 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:06:58.411480 ops/training.py:65 2019-01-17 04:06:58.411403: step 11054, loss = 0.62384 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:06:59.700504 ops/training.py:65 2019-01-17 04:06:59.700434: step 11055, loss = 0.56571 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:07:00.988985 ops/training.py:65 2019-01-17 04:07:00.988920: step 11056, loss = 0.65219 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:07:02.277868 ops/training.py:65 2019-01-17 04:07:02.277803: step 11057, loss = 0.63970 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:07:03.566764 ops/training.py:65 2019-01-17 04:07:03.566688: step 11058, loss = 0.61470 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:07:04.855048 ops/training.py:65 2019-01-17 04:07:04.854956: step 11059, loss = 0.61727 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:07:06.144231 ops/training.py:65 2019-01-17 04:07:06.144161: step 11060, loss = 0.64194 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:07:07.430495 ops/training.py:65 2019-01-17 04:07:07.430426: step 11061, loss = 0.65675 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:07:08.711335 ops/training.py:65 2019-01-17 04:07:08.711222: step 11062, loss = 0.69887 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:07:10.002942 ops/training.py:65 2019-01-17 04:07:10.002838: step 11063, loss = 0.65861 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:07:11.287430 ops/training.py:65 2019-01-17 04:07:11.287351: step 11064, loss = 0.67622 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:07:12.572539 ops/training.py:65 2019-01-17 04:07:12.572434: step 11065, loss = 0.56126 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:07:13.863543 ops/training.py:65 2019-01-17 04:07:13.863442: step 11066, loss = 0.58259 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:07:15.153007 ops/training.py:65 2019-01-17 04:07:15.152933: step 11067, loss = 0.65071 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:07:16.442131 ops/training.py:65 2019-01-17 04:07:16.442045: step 11068, loss = 0.52050 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:07:17.731892 ops/training.py:65 2019-01-17 04:07:17.731804: step 11069, loss = 0.67278 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:07:19.019774 ops/training.py:65 2019-01-17 04:07:19.019704: step 11070, loss = 0.62940 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:07:20.309418 ops/training.py:65 2019-01-17 04:07:20.309345: step 11071, loss = 0.60365 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:07:21.600818 ops/training.py:65 2019-01-17 04:07:21.600741: step 11072, loss = 0.60530 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:07:22.888959 ops/training.py:65 2019-01-17 04:07:22.888868: step 11073, loss = 0.59976 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:07:24.178865 ops/training.py:65 2019-01-17 04:07:24.178792: step 11074, loss = 0.77977 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:07:25.460069 ops/training.py:65 2019-01-17 04:07:25.459998: step 11075, loss = 0.66091 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:07:26.744456 ops/training.py:65 2019-01-17 04:07:26.744388: step 11076, loss = 0.65609 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:07:28.034023 ops/training.py:65 2019-01-17 04:07:28.033928: step 11077, loss = 0.66508 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:07:29.325433 ops/training.py:65 2019-01-17 04:07:29.325354: step 11078, loss = 0.51867 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:07:30.613775 ops/training.py:65 2019-01-17 04:07:30.613683: step 11079, loss = 0.59903 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:07:31.903873 ops/training.py:65 2019-01-17 04:07:31.903810: step 11080, loss = 0.62926 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:07:33.189599 ops/training.py:65 2019-01-17 04:07:33.189520: step 11081, loss = 0.69873 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:07:34.479712 ops/training.py:65 2019-01-17 04:07:34.479641: step 11082, loss = 0.71693 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:07:35.763858 ops/training.py:65 2019-01-17 04:07:35.763785: step 11083, loss = 0.57568 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:07:37.052617 ops/training.py:65 2019-01-17 04:07:37.052540: step 11084, loss = 0.69313 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:07:38.338164 ops/training.py:65 2019-01-17 04:07:38.338096: step 11085, loss = 0.69811 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:07:39.624113 ops/training.py:65 2019-01-17 04:07:39.624048: step 11086, loss = 0.70990 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:07:40.915023 ops/training.py:65 2019-01-17 04:07:40.914919: step 11087, loss = 0.59594 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:07:42.205913 ops/training.py:65 2019-01-17 04:07:42.205845: step 11088, loss = 0.67991 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:07:43.491239 ops/training.py:65 2019-01-17 04:07:43.491166: step 11089, loss = 0.70937 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:07:44.783201 ops/training.py:65 2019-01-17 04:07:44.783090: step 11090, loss = 0.56593 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:07:46.073842 ops/training.py:65 2019-01-17 04:07:46.073767: step 11091, loss = 0.71774 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:07:47.362327 ops/training.py:65 2019-01-17 04:07:47.362246: step 11092, loss = 0.57179 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:07:48.650650 ops/training.py:65 2019-01-17 04:07:48.650559: step 11093, loss = 0.65738 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:07:49.939715 ops/training.py:65 2019-01-17 04:07:49.939623: step 11094, loss = 0.58724 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:07:51.229220 ops/training.py:65 2019-01-17 04:07:51.229129: step 11095, loss = 0.62392 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:07:52.513846 ops/training.py:65 2019-01-17 04:07:52.513778: step 11096, loss = 0.54656 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:07:53.798140 ops/training.py:65 2019-01-17 04:07:53.798069: step 11097, loss = 0.65600 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:07:55.083324 ops/training.py:65 2019-01-17 04:07:55.083248: step 11098, loss = 0.68883 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:07:56.375329 ops/training.py:65 2019-01-17 04:07:56.375226: step 11099, loss = 0.76952 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:07:57.665872 ops/training.py:65 2019-01-17 04:07:57.665799: step 11100, loss = 0.67692 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:07:58.950268 ops/training.py:65 2019-01-17 04:07:58.950198: step 11101, loss = 0.65699 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:08:00.233936 ops/training.py:65 2019-01-17 04:08:00.233868: step 11102, loss = 0.61156 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:08:01.524059 ops/training.py:65 2019-01-17 04:08:01.523917: step 11103, loss = 0.60949 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:08:02.813487 ops/training.py:65 2019-01-17 04:08:02.813391: step 11104, loss = 0.69164 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:08:04.101806 ops/training.py:65 2019-01-17 04:08:04.101730: step 11105, loss = 0.64744 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:08:05.386303 ops/training.py:65 2019-01-17 04:08:05.386234: step 11106, loss = 0.65586 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:08:06.677891 ops/training.py:65 2019-01-17 04:08:06.677795: step 11107, loss = 0.62059 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:08:07.968456 ops/training.py:65 2019-01-17 04:08:07.968388: step 11108, loss = 0.67310 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:08:09.257500 ops/training.py:65 2019-01-17 04:08:09.257427: step 11109, loss = 0.68757 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:08:10.542483 ops/training.py:65 2019-01-17 04:08:10.542418: step 11110, loss = 0.61320 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:08:11.832108 ops/training.py:65 2019-01-17 04:08:11.831998: step 11111, loss = 0.59347 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:08:13.116208 ops/training.py:65 2019-01-17 04:08:13.116139: step 11112, loss = 0.70628 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:08:14.402352 ops/training.py:65 2019-01-17 04:08:14.402291: step 11113, loss = 0.58080 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:08:15.686461 ops/training.py:65 2019-01-17 04:08:15.686356: step 11114, loss = 0.62912 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:08:16.976457 ops/training.py:65 2019-01-17 04:08:16.976352: step 11115, loss = 0.65338 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:08:18.260560 ops/training.py:65 2019-01-17 04:08:18.260485: step 11116, loss = 0.65572 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:08:19.546270 ops/training.py:65 2019-01-17 04:08:19.546157: step 11117, loss = 0.76707 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:08:20.838698 ops/training.py:65 2019-01-17 04:08:20.838537: step 11118, loss = 0.69525 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:08:22.130541 ops/training.py:65 2019-01-17 04:08:22.130476: step 11119, loss = 0.70517 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:08:23.414678 ops/training.py:65 2019-01-17 04:08:23.414616: step 11120, loss = 0.70006 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:08:24.698419 ops/training.py:65 2019-01-17 04:08:24.698346: step 11121, loss = 0.67319 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:08:25.986848 ops/training.py:65 2019-01-17 04:08:25.986734: step 11122, loss = 0.63244 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:08:27.273383 ops/training.py:65 2019-01-17 04:08:27.273321: step 11123, loss = 0.64923 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:08:28.558158 ops/training.py:65 2019-01-17 04:08:28.558055: step 11124, loss = 0.71096 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:08:29.849001 ops/training.py:65 2019-01-17 04:08:29.848890: step 11125, loss = 0.64830 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:08:31.134717 ops/training.py:65 2019-01-17 04:08:31.134649: step 11126, loss = 0.54883 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:08:32.423949 ops/training.py:65 2019-01-17 04:08:32.423880: step 11127, loss = 0.69362 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:08:33.708428 ops/training.py:65 2019-01-17 04:08:33.708357: step 11128, loss = 0.68055 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:08:34.989804 ops/training.py:65 2019-01-17 04:08:34.989718: step 11129, loss = 0.61437 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:08:36.274112 ops/training.py:65 2019-01-17 04:08:36.274016: step 11130, loss = 0.61465 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:08:37.566405 ops/training.py:65 2019-01-17 04:08:37.566248: step 11131, loss = 0.65434 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:08:38.852778 ops/training.py:65 2019-01-17 04:08:38.852713: step 11132, loss = 0.66493 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:08:40.137916 ops/training.py:65 2019-01-17 04:08:40.137834: step 11133, loss = 0.58182 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:08:41.425018 ops/training.py:65 2019-01-17 04:08:41.424878: step 11134, loss = 0.68188 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:08:42.717269 ops/training.py:65 2019-01-17 04:08:42.717160: step 11135, loss = 0.61621 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:08:44.008570 ops/training.py:65 2019-01-17 04:08:44.008497: step 11136, loss = 0.63238 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:08:45.297768 ops/training.py:65 2019-01-17 04:08:45.297669: step 11137, loss = 0.63084 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:08:46.587970 ops/training.py:65 2019-01-17 04:08:46.587901: step 11138, loss = 0.72994 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:08:47.876286 ops/training.py:65 2019-01-17 04:08:47.876193: step 11139, loss = 0.64596 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:08:49.161232 ops/training.py:65 2019-01-17 04:08:49.161171: step 11140, loss = 0.59185 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:08:50.449521 ops/training.py:65 2019-01-17 04:08:50.449452: step 11141, loss = 0.65328 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:08:51.737671 ops/training.py:65 2019-01-17 04:08:51.737584: step 11142, loss = 0.58597 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:08:53.025293 ops/training.py:65 2019-01-17 04:08:53.025196: step 11143, loss = 0.63282 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:08:54.314913 ops/training.py:65 2019-01-17 04:08:54.314842: step 11144, loss = 0.61373 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:08:55.603575 ops/training.py:65 2019-01-17 04:08:55.603502: step 11145, loss = 0.71508 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:08:56.893436 ops/training.py:65 2019-01-17 04:08:56.893337: step 11146, loss = 0.63028 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:08:58.182513 ops/training.py:65 2019-01-17 04:08:58.182439: step 11147, loss = 0.63806 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:08:59.471373 ops/training.py:65 2019-01-17 04:08:59.471283: step 11148, loss = 0.60169 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:09:00.759209 ops/training.py:65 2019-01-17 04:09:00.759142: step 11149, loss = 0.64084 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:09:02.046664 ops/training.py:65 2019-01-17 04:09:02.046592: step 11150, loss = 0.58883 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:09:03.333817 ops/training.py:65 2019-01-17 04:09:03.333745: step 11151, loss = 0.61365 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:09:04.623210 ops/training.py:65 2019-01-17 04:09:04.623147: step 11152, loss = 0.69078 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:09:05.911295 ops/training.py:65 2019-01-17 04:09:05.911221: step 11153, loss = 0.63342 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:09:07.200198 ops/training.py:65 2019-01-17 04:09:07.200123: step 11154, loss = 0.64914 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:09:08.488405 ops/training.py:65 2019-01-17 04:09:08.488336: step 11155, loss = 0.61997 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:09:09.776426 ops/training.py:65 2019-01-17 04:09:09.776326: step 11156, loss = 0.69177 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:09:11.061976 ops/training.py:65 2019-01-17 04:09:11.061914: step 11157, loss = 0.67076 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:09:12.345543 ops/training.py:65 2019-01-17 04:09:12.345462: step 11158, loss = 0.54204 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:09:13.631829 ops/training.py:65 2019-01-17 04:09:13.631679: step 11159, loss = 0.58909 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:09:14.924505 ops/training.py:65 2019-01-17 04:09:14.924343: step 11160, loss = 0.67046 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:09:16.216330 ops/training.py:65 2019-01-17 04:09:16.216170: step 11161, loss = 0.58067 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:09:17.504359 ops/training.py:65 2019-01-17 04:09:17.504282: step 11162, loss = 0.56436 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:09:18.793717 ops/training.py:65 2019-01-17 04:09:18.793642: step 11163, loss = 0.75648 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:09:20.081950 ops/training.py:65 2019-01-17 04:09:20.081877: step 11164, loss = 0.58500 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:09:21.370051 ops/training.py:65 2019-01-17 04:09:21.369977: step 11165, loss = 0.60014 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:09:22.655054 ops/training.py:65 2019-01-17 04:09:22.654985: step 11166, loss = 0.67888 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:09:23.943395 ops/training.py:65 2019-01-17 04:09:23.943314: step 11167, loss = 0.65949 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:09:25.231882 ops/training.py:65 2019-01-17 04:09:25.231812: step 11168, loss = 0.76310 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:09:26.521569 ops/training.py:65 2019-01-17 04:09:26.521490: step 11169, loss = 0.68216 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:09:27.810738 ops/training.py:65 2019-01-17 04:09:27.810646: step 11170, loss = 0.68324 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:09:29.101479 ops/training.py:65 2019-01-17 04:09:29.101379: step 11171, loss = 0.57320 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:09:30.390069 ops/training.py:65 2019-01-17 04:09:30.390000: step 11172, loss = 0.57910 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:09:31.679352 ops/training.py:65 2019-01-17 04:09:31.679277: step 11173, loss = 0.70030 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:09:32.969180 ops/training.py:65 2019-01-17 04:09:32.969115: step 11174, loss = 0.60910 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:09:34.256899 ops/training.py:65 2019-01-17 04:09:34.256826: step 11175, loss = 0.63632 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:09:35.545710 ops/training.py:65 2019-01-17 04:09:35.545638: step 11176, loss = 0.62567 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:09:36.834598 ops/training.py:65 2019-01-17 04:09:36.834505: step 11177, loss = 0.68251 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:09:38.119820 ops/training.py:65 2019-01-17 04:09:38.119754: step 11178, loss = 0.64526 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:09:39.407863 ops/training.py:65 2019-01-17 04:09:39.407771: step 11179, loss = 0.64818 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:09:40.696696 ops/training.py:65 2019-01-17 04:09:40.696597: step 11180, loss = 0.64244 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:09:41.987898 ops/training.py:65 2019-01-17 04:09:41.987824: step 11181, loss = 0.59096 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:09:43.277208 ops/training.py:65 2019-01-17 04:09:43.277137: step 11182, loss = 0.59986 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:09:44.565580 ops/training.py:65 2019-01-17 04:09:44.565511: step 11183, loss = 0.55321 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:09:45.854997 ops/training.py:65 2019-01-17 04:09:45.854924: step 11184, loss = 0.56374 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:09:47.142611 ops/training.py:65 2019-01-17 04:09:47.142542: step 11185, loss = 0.61820 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:09:48.426918 ops/training.py:65 2019-01-17 04:09:48.426844: step 11186, loss = 0.62319 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:09:49.711561 ops/training.py:65 2019-01-17 04:09:49.711489: step 11187, loss = 0.64316 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:09:50.994110 ops/training.py:65 2019-01-17 04:09:50.994005: step 11188, loss = 0.67684 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:09:52.286737 ops/training.py:65 2019-01-17 04:09:52.286598: step 11189, loss = 0.64744 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:09:53.578016 ops/training.py:65 2019-01-17 04:09:53.577938: step 11190, loss = 0.58718 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:09:54.867950 ops/training.py:65 2019-01-17 04:09:54.867873: step 11191, loss = 0.59984 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:09:56.152969 ops/training.py:65 2019-01-17 04:09:56.152902: step 11192, loss = 0.67032 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:09:57.435578 ops/training.py:65 2019-01-17 04:09:57.435478: step 11193, loss = 0.60998 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:09:58.725597 ops/training.py:65 2019-01-17 04:09:58.725477: step 11194, loss = 0.59574 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:10:00.016489 ops/training.py:65 2019-01-17 04:10:00.016416: step 11195, loss = 0.67092 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:10:01.305309 ops/training.py:65 2019-01-17 04:10:01.305231: step 11196, loss = 0.61409 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:10:02.593577 ops/training.py:65 2019-01-17 04:10:02.593511: step 11197, loss = 0.64897 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:10:03.879014 ops/training.py:65 2019-01-17 04:10:03.878941: step 11198, loss = 0.66764 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 04:10:05.168601 ops/training.py:65 2019-01-17 04:10:05.168495: step 11199, loss = 0.62682 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:10:06.458674 ops/training.py:65 2019-01-17 04:10:06.458531: step 11200, loss = 0.59219 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:10:07.750912 ops/training.py:65 2019-01-17 04:10:07.750810: step 11201, loss = 0.67687 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:10:09.035130 ops/training.py:65 2019-01-17 04:10:09.035068: step 11202, loss = 0.67740 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:10:10.322188 ops/training.py:65 2019-01-17 04:10:10.322089: step 11203, loss = 0.53097 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:10:11.611531 ops/training.py:65 2019-01-17 04:10:11.611442: step 11204, loss = 0.66161 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:10:12.899657 ops/training.py:65 2019-01-17 04:10:12.899581: step 11205, loss = 0.64803 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:10:14.188254 ops/training.py:65 2019-01-17 04:10:14.188174: step 11206, loss = 0.66720 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:10:15.476128 ops/training.py:65 2019-01-17 04:10:15.476060: step 11207, loss = 0.58441 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:10:16.764358 ops/training.py:65 2019-01-17 04:10:16.764286: step 11208, loss = 0.59510 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:10:18.052964 ops/training.py:65 2019-01-17 04:10:18.052883: step 11209, loss = 0.62341 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:10:19.334978 ops/training.py:65 2019-01-17 04:10:19.334910: step 11210, loss = 0.56918 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:10:20.622542 ops/training.py:65 2019-01-17 04:10:20.622463: step 11211, loss = 0.75116 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:10:21.910991 ops/training.py:65 2019-01-17 04:10:21.910922: step 11212, loss = 0.72654 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:10:23.199311 ops/training.py:65 2019-01-17 04:10:23.199235: step 11213, loss = 0.63754 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:10:24.483803 ops/training.py:65 2019-01-17 04:10:24.483724: step 11214, loss = 0.62801 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:10:25.772420 ops/training.py:65 2019-01-17 04:10:25.772317: step 11215, loss = 0.63591 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:10:27.057902 ops/training.py:65 2019-01-17 04:10:27.057804: step 11216, loss = 0.58725 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:10:28.343309 ops/training.py:65 2019-01-17 04:10:28.343241: step 11217, loss = 0.57604 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:10:29.627370 ops/training.py:65 2019-01-17 04:10:29.627261: step 11218, loss = 0.56235 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:10:30.915291 ops/training.py:65 2019-01-17 04:10:30.915186: step 11219, loss = 0.66625 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:10:32.207148 ops/training.py:65 2019-01-17 04:10:32.207084: step 11220, loss = 0.63347 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:10:33.496592 ops/training.py:65 2019-01-17 04:10:33.496500: step 11221, loss = 0.59394 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:10:34.786427 ops/training.py:65 2019-01-17 04:10:34.786336: step 11222, loss = 0.57968 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:10:36.077411 ops/training.py:65 2019-01-17 04:10:36.077317: step 11223, loss = 0.60060 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:10:37.367240 ops/training.py:65 2019-01-17 04:10:37.367139: step 11224, loss = 0.65658 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:10:38.657063 ops/training.py:65 2019-01-17 04:10:38.656960: step 11225, loss = 0.72608 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:10:39.947214 ops/training.py:65 2019-01-17 04:10:39.947135: step 11226, loss = 0.71559 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:10:41.236766 ops/training.py:65 2019-01-17 04:10:41.236664: step 11227, loss = 0.59987 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:10:42.528050 ops/training.py:65 2019-01-17 04:10:42.527963: step 11228, loss = 0.65097 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:10:43.816748 ops/training.py:65 2019-01-17 04:10:43.816652: step 11229, loss = 0.67324 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:10:45.109696 ops/training.py:65 2019-01-17 04:10:45.109627: step 11230, loss = 0.64674 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:10:46.400070 ops/training.py:65 2019-01-17 04:10:46.399982: step 11231, loss = 0.58579 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:10:47.689820 ops/training.py:65 2019-01-17 04:10:47.689747: step 11232, loss = 0.72962 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:10:48.979548 ops/training.py:65 2019-01-17 04:10:48.979449: step 11233, loss = 0.67354 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:10:50.269045 ops/training.py:65 2019-01-17 04:10:50.268964: step 11234, loss = 0.66462 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:10:51.558088 ops/training.py:65 2019-01-17 04:10:51.558009: step 11235, loss = 0.62297 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:10:52.847871 ops/training.py:65 2019-01-17 04:10:52.847811: step 11236, loss = 0.60324 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:10:54.132644 ops/training.py:65 2019-01-17 04:10:54.132568: step 11237, loss = 0.60024 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:10:55.416536 ops/training.py:65 2019-01-17 04:10:55.416451: step 11238, loss = 0.60927 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:10:56.706702 ops/training.py:65 2019-01-17 04:10:56.706547: step 11239, loss = 0.64319 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:10:57.994246 ops/training.py:65 2019-01-17 04:10:57.994136: step 11240, loss = 0.69010 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:10:59.278857 ops/training.py:65 2019-01-17 04:10:59.278785: step 11241, loss = 0.61323 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:11:00.570424 ops/training.py:65 2019-01-17 04:11:00.570317: step 11242, loss = 0.67950 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:11:01.857071 ops/training.py:65 2019-01-17 04:11:01.857003: step 11243, loss = 0.63111 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:11:03.141004 ops/training.py:65 2019-01-17 04:11:03.140928: step 11244, loss = 0.56777 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:11:04.432838 ops/training.py:65 2019-01-17 04:11:04.432734: step 11245, loss = 0.59898 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:11:05.723073 ops/training.py:65 2019-01-17 04:11:05.722998: step 11246, loss = 0.54772 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:11:07.013276 ops/training.py:65 2019-01-17 04:11:07.013199: step 11247, loss = 0.51495 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:11:08.302884 ops/training.py:65 2019-01-17 04:11:08.302803: step 11248, loss = 0.66103 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:11:09.592362 ops/training.py:65 2019-01-17 04:11:09.592266: step 11249, loss = 0.60923 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:11:10.876368 ops/training.py:65 2019-01-17 04:11:10.876281: step 11250, loss = 0.62810 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:11:12.158267 ops/training.py:65 2019-01-17 04:11:12.158161: step 11251, loss = 0.62227 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:11:13.450808 ops/training.py:65 2019-01-17 04:11:13.450709: step 11252, loss = 0.63721 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:11:14.741424 ops/training.py:65 2019-01-17 04:11:14.741361: step 11253, loss = 0.62507 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:11:16.026746 ops/training.py:65 2019-01-17 04:11:16.026644: step 11254, loss = 0.64873 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:11:17.318164 ops/training.py:65 2019-01-17 04:11:17.318008: step 11255, loss = 0.63374 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:11:18.616603 ops/training.py:65 2019-01-17 04:11:18.616524: step 11256, loss = 0.60116 (24.7 examples/sec; 1.297 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:11:19.904931 ops/training.py:65 2019-01-17 04:11:19.904862: step 11257, loss = 0.68422 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:11:21.193648 ops/training.py:65 2019-01-17 04:11:21.193567: step 11258, loss = 0.62205 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:11:22.483004 ops/training.py:65 2019-01-17 04:11:22.482908: step 11259, loss = 0.63445 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:11:23.774074 ops/training.py:65 2019-01-17 04:11:23.773994: step 11260, loss = 0.62631 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:11:25.063383 ops/training.py:65 2019-01-17 04:11:25.063300: step 11261, loss = 0.69903 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:11:26.352172 ops/training.py:65 2019-01-17 04:11:26.352067: step 11262, loss = 0.55743 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:11:27.641293 ops/training.py:65 2019-01-17 04:11:27.641204: step 11263, loss = 0.55451 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:11:28.929912 ops/training.py:65 2019-01-17 04:11:28.929806: step 11264, loss = 0.62088 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:11:30.214386 ops/training.py:65 2019-01-17 04:11:30.214313: step 11265, loss = 0.69507 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:11:31.502829 ops/training.py:65 2019-01-17 04:11:31.502744: step 11266, loss = 0.67736 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:11:32.792208 ops/training.py:65 2019-01-17 04:11:32.792134: step 11267, loss = 0.54259 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:11:34.081997 ops/training.py:65 2019-01-17 04:11:34.081886: step 11268, loss = 0.56606 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:11:35.370546 ops/training.py:65 2019-01-17 04:11:35.370473: step 11269, loss = 0.53648 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:11:36.659680 ops/training.py:65 2019-01-17 04:11:36.659610: step 11270, loss = 0.68112 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:11:37.947929 ops/training.py:65 2019-01-17 04:11:37.947824: step 11271, loss = 0.59523 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:11:39.236084 ops/training.py:65 2019-01-17 04:11:39.236015: step 11272, loss = 0.54759 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:11:40.519376 ops/training.py:65 2019-01-17 04:11:40.519303: step 11273, loss = 0.56262 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:11:41.808722 ops/training.py:65 2019-01-17 04:11:41.808647: step 11274, loss = 0.61798 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:11:43.097418 ops/training.py:65 2019-01-17 04:11:43.097323: step 11275, loss = 0.58576 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:11:44.387258 ops/training.py:65 2019-01-17 04:11:44.387179: step 11276, loss = 0.65442 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:11:45.676684 ops/training.py:65 2019-01-17 04:11:45.676608: step 11277, loss = 0.64659 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:11:46.966093 ops/training.py:65 2019-01-17 04:11:46.966017: step 11278, loss = 0.66417 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:11:48.255365 ops/training.py:65 2019-01-17 04:11:48.255284: step 11279, loss = 0.63908 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:11:49.544926 ops/training.py:65 2019-01-17 04:11:49.544823: step 11280, loss = 0.60082 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:11:50.834990 ops/training.py:65 2019-01-17 04:11:50.834917: step 11281, loss = 0.64419 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:11:52.123778 ops/training.py:65 2019-01-17 04:11:52.123681: step 11282, loss = 0.61826 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:11:53.413602 ops/training.py:65 2019-01-17 04:11:53.413525: step 11283, loss = 0.61232 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:11:54.702242 ops/training.py:65 2019-01-17 04:11:54.702167: step 11284, loss = 0.73012 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 04:11:55.991393 ops/training.py:65 2019-01-17 04:11:55.991298: step 11285, loss = 0.64023 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:11:57.280125 ops/training.py:65 2019-01-17 04:11:57.280037: step 11286, loss = 0.62872 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:11:58.569724 ops/training.py:65 2019-01-17 04:11:58.569634: step 11287, loss = 0.58508 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:11:59.858793 ops/training.py:65 2019-01-17 04:11:59.858714: step 11288, loss = 0.57421 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:12:01.148470 ops/training.py:65 2019-01-17 04:12:01.148398: step 11289, loss = 0.59181 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:12:02.437825 ops/training.py:65 2019-01-17 04:12:02.437745: step 11290, loss = 0.58598 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:12:03.727531 ops/training.py:65 2019-01-17 04:12:03.727425: step 11291, loss = 0.63985 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:12:05.017061 ops/training.py:65 2019-01-17 04:12:05.016991: step 11292, loss = 0.67304 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:12:06.304945 ops/training.py:65 2019-01-17 04:12:06.304869: step 11293, loss = 0.61015 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:12:07.594706 ops/training.py:65 2019-01-17 04:12:07.594616: step 11294, loss = 0.65350 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:12:08.883328 ops/training.py:65 2019-01-17 04:12:08.883255: step 11295, loss = 0.66509 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:12:10.172672 ops/training.py:65 2019-01-17 04:12:10.172552: step 11296, loss = 0.67559 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:12:11.463025 ops/training.py:65 2019-01-17 04:12:11.462942: step 11297, loss = 0.52484 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:12:12.750538 ops/training.py:65 2019-01-17 04:12:12.750432: step 11298, loss = 0.65856 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:12:14.040540 ops/training.py:65 2019-01-17 04:12:14.040423: step 11299, loss = 0.63091 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:12:15.330588 ops/training.py:65 2019-01-17 04:12:15.330499: step 11300, loss = 0.64229 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:12:16.620417 ops/training.py:65 2019-01-17 04:12:16.620302: step 11301, loss = 0.80475 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:12:17.910295 ops/training.py:65 2019-01-17 04:12:17.910216: step 11302, loss = 0.70439 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:12:19.198707 ops/training.py:65 2019-01-17 04:12:19.198629: step 11303, loss = 0.65697 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:12:20.486989 ops/training.py:65 2019-01-17 04:12:20.486914: step 11304, loss = 0.72786 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:12:21.777094 ops/training.py:65 2019-01-17 04:12:21.777025: step 11305, loss = 0.65669 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:12:23.066672 ops/training.py:65 2019-01-17 04:12:23.066593: step 11306, loss = 0.54426 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:12:24.355721 ops/training.py:65 2019-01-17 04:12:24.355622: step 11307, loss = 0.71312 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:12:25.650921 ops/training.py:65 2019-01-17 04:12:25.650842: step 11308, loss = 0.72442 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:12:26.940312 ops/training.py:65 2019-01-17 04:12:26.940240: step 11309, loss = 0.56418 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:12:28.229907 ops/training.py:65 2019-01-17 04:12:28.229828: step 11310, loss = 0.61625 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:12:29.518351 ops/training.py:65 2019-01-17 04:12:29.518258: step 11311, loss = 0.59791 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:12:30.808889 ops/training.py:65 2019-01-17 04:12:30.808816: step 11312, loss = 0.55376 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:12:32.098357 ops/training.py:65 2019-01-17 04:12:32.098279: step 11313, loss = 0.58290 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:12:33.387244 ops/training.py:65 2019-01-17 04:12:33.387143: step 11314, loss = 0.74711 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:12:34.677807 ops/training.py:65 2019-01-17 04:12:34.677732: step 11315, loss = 0.54425 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:12:35.966966 ops/training.py:65 2019-01-17 04:12:35.966880: step 11316, loss = 0.69941 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:12:37.255820 ops/training.py:65 2019-01-17 04:12:37.255749: step 11317, loss = 0.57358 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:12:38.545866 ops/training.py:65 2019-01-17 04:12:38.545771: step 11318, loss = 0.63071 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:12:39.835408 ops/training.py:65 2019-01-17 04:12:39.835332: step 11319, loss = 0.67795 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:12:41.123835 ops/training.py:65 2019-01-17 04:12:41.123731: step 11320, loss = 0.73932 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:12:42.413279 ops/training.py:65 2019-01-17 04:12:42.413203: step 11321, loss = 0.70846 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:12:43.701730 ops/training.py:65 2019-01-17 04:12:43.701655: step 11322, loss = 0.54799 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:12:44.990536 ops/training.py:65 2019-01-17 04:12:44.990449: step 11323, loss = 0.67181 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:12:46.278725 ops/training.py:65 2019-01-17 04:12:46.278652: step 11324, loss = 0.68889 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:12:47.567963 ops/training.py:65 2019-01-17 04:12:47.567855: step 11325, loss = 0.56351 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:12:48.858003 ops/training.py:65 2019-01-17 04:12:48.857925: step 11326, loss = 0.58060 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:12:50.146252 ops/training.py:65 2019-01-17 04:12:50.146178: step 11327, loss = 0.61064 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:12:51.432467 ops/training.py:65 2019-01-17 04:12:51.432388: step 11328, loss = 0.68290 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:12:52.721642 ops/training.py:65 2019-01-17 04:12:52.721562: step 11329, loss = 0.71466 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:12:54.005864 ops/training.py:65 2019-01-17 04:12:54.005789: step 11330, loss = 0.75551 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 04:12:55.295192 ops/training.py:65 2019-01-17 04:12:55.295115: step 11331, loss = 0.53950 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:12:56.584073 ops/training.py:65 2019-01-17 04:12:56.583996: step 11332, loss = 0.60586 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:12:57.866941 ops/training.py:65 2019-01-17 04:12:57.866873: step 11333, loss = 0.56593 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:12:59.150695 ops/training.py:65 2019-01-17 04:12:59.150626: step 11334, loss = 0.61030 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:13:00.441683 ops/training.py:65 2019-01-17 04:13:00.441527: step 11335, loss = 0.74030 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 04:13:01.728773 ops/training.py:65 2019-01-17 04:13:01.728703: step 11336, loss = 0.68358 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:13:03.013016 ops/training.py:65 2019-01-17 04:13:03.012954: step 11337, loss = 0.55672 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:13:04.303475 ops/training.py:65 2019-01-17 04:13:04.303375: step 11338, loss = 0.57699 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:13:05.593185 ops/training.py:65 2019-01-17 04:13:05.593102: step 11339, loss = 0.70041 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:13:06.882399 ops/training.py:65 2019-01-17 04:13:06.882327: step 11340, loss = 0.68628 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:13:08.166521 ops/training.py:65 2019-01-17 04:13:08.166449: step 11341, loss = 0.61287 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:13:09.446926 ops/training.py:65 2019-01-17 04:13:09.446820: step 11342, loss = 0.60335 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:13:10.731413 ops/training.py:65 2019-01-17 04:13:10.731306: step 11343, loss = 0.68087 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:13:12.017997 ops/training.py:65 2019-01-17 04:13:12.017884: step 11344, loss = 0.71697 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:13:13.302050 ops/training.py:65 2019-01-17 04:13:13.301955: step 11345, loss = 0.53222 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:13:14.593744 ops/training.py:65 2019-01-17 04:13:14.593641: step 11346, loss = 0.75335 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 04:13:15.885295 ops/training.py:65 2019-01-17 04:13:15.885222: step 11347, loss = 0.71538 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:13:17.173877 ops/training.py:65 2019-01-17 04:13:17.173810: step 11348, loss = 0.64723 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:13:18.462450 ops/training.py:65 2019-01-17 04:13:18.462381: step 11349, loss = 0.71859 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:13:19.750015 ops/training.py:65 2019-01-17 04:13:19.749940: step 11350, loss = 0.60106 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:13:21.039215 ops/training.py:65 2019-01-17 04:13:21.039120: step 11351, loss = 0.61877 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:13:22.324053 ops/training.py:65 2019-01-17 04:13:22.323991: step 11352, loss = 0.64039 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:13:23.614356 ops/training.py:65 2019-01-17 04:13:23.614252: step 11353, loss = 0.63844 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:13:24.899879 ops/training.py:65 2019-01-17 04:13:24.899815: step 11354, loss = 0.57504 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:13:26.183283 ops/training.py:65 2019-01-17 04:13:26.183210: step 11355, loss = 0.56894 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:13:27.474518 ops/training.py:65 2019-01-17 04:13:27.474406: step 11356, loss = 0.60150 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:13:28.765155 ops/training.py:65 2019-01-17 04:13:28.765087: step 11357, loss = 0.63392 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:13:30.053606 ops/training.py:65 2019-01-17 04:13:30.053530: step 11358, loss = 0.53486 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:13:31.338663 ops/training.py:65 2019-01-17 04:13:31.338597: step 11359, loss = 0.65405 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:13:32.622511 ops/training.py:65 2019-01-17 04:13:32.622430: step 11360, loss = 0.66053 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:13:33.909553 ops/training.py:65 2019-01-17 04:13:33.909454: step 11361, loss = 0.48646 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:13:35.193867 ops/training.py:65 2019-01-17 04:13:35.193767: step 11362, loss = 0.57266 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:13:36.485207 ops/training.py:65 2019-01-17 04:13:36.485095: step 11363, loss = 0.58927 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:13:37.771479 ops/training.py:65 2019-01-17 04:13:37.771413: step 11364, loss = 0.70468 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:13:39.055440 ops/training.py:65 2019-01-17 04:13:39.055333: step 11365, loss = 0.60591 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:13:40.345603 ops/training.py:65 2019-01-17 04:13:40.345503: step 11366, loss = 0.65030 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:13:41.636584 ops/training.py:65 2019-01-17 04:13:41.636491: step 11367, loss = 0.68835 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:13:42.926526 ops/training.py:65 2019-01-17 04:13:42.926448: step 11368, loss = 0.62612 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:13:44.215609 ops/training.py:65 2019-01-17 04:13:44.215542: step 11369, loss = 0.64294 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:13:45.505327 ops/training.py:65 2019-01-17 04:13:45.505266: step 11370, loss = 0.62648 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:13:46.794223 ops/training.py:65 2019-01-17 04:13:46.794145: step 11371, loss = 0.58252 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:13:48.078448 ops/training.py:65 2019-01-17 04:13:48.078380: step 11372, loss = 0.60533 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:13:49.361766 ops/training.py:65 2019-01-17 04:13:49.361701: step 11373, loss = 0.66799 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:13:50.653183 ops/training.py:65 2019-01-17 04:13:50.653079: step 11374, loss = 0.65335 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:13:51.943470 ops/training.py:65 2019-01-17 04:13:51.943381: step 11375, loss = 0.55592 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:13:53.233579 ops/training.py:65 2019-01-17 04:13:53.233502: step 11376, loss = 0.70286 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:13:54.518874 ops/training.py:65 2019-01-17 04:13:54.518811: step 11377, loss = 0.71464 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:13:55.803890 ops/training.py:65 2019-01-17 04:13:55.803813: step 11378, loss = 0.53328 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:13:57.097106 ops/training.py:65 2019-01-17 04:13:57.096957: step 11379, loss = 0.60226 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:13:58.388482 ops/training.py:65 2019-01-17 04:13:58.388411: step 11380, loss = 0.53192 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:13:59.677833 ops/training.py:65 2019-01-17 04:13:59.677758: step 11381, loss = 0.58689 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:14:00.966559 ops/training.py:65 2019-01-17 04:14:00.966489: step 11382, loss = 0.46265 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:14:02.256001 ops/training.py:65 2019-01-17 04:14:02.255925: step 11383, loss = 0.60404 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:14:03.545789 ops/training.py:65 2019-01-17 04:14:03.545719: step 11384, loss = 0.57812 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:14:04.828744 ops/training.py:65 2019-01-17 04:14:04.828680: step 11385, loss = 0.67281 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:14:06.117865 ops/training.py:65 2019-01-17 04:14:06.117802: step 11386, loss = 0.65333 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:14:07.407067 ops/training.py:65 2019-01-17 04:14:07.406997: step 11387, loss = 0.59918 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:14:08.691630 ops/training.py:65 2019-01-17 04:14:08.691555: step 11388, loss = 0.64427 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:14:09.976287 ops/training.py:65 2019-01-17 04:14:09.976214: step 11389, loss = 0.66643 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:14:11.268094 ops/training.py:65 2019-01-17 04:14:11.267988: step 11390, loss = 0.66478 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:14:12.555020 ops/training.py:65 2019-01-17 04:14:12.554950: step 11391, loss = 0.61587 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:14:13.844720 ops/training.py:65 2019-01-17 04:14:13.844643: step 11392, loss = 0.54570 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:14:15.133768 ops/training.py:65 2019-01-17 04:14:15.133702: step 11393, loss = 0.61651 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:14:16.418800 ops/training.py:65 2019-01-17 04:14:16.418721: step 11394, loss = 0.56238 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:14:17.710933 ops/training.py:65 2019-01-17 04:14:17.710827: step 11395, loss = 0.68338 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:14:19.002281 ops/training.py:65 2019-01-17 04:14:19.002204: step 11396, loss = 0.57660 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:14:20.292289 ops/training.py:65 2019-01-17 04:14:20.292216: step 11397, loss = 0.59941 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:14:21.580964 ops/training.py:65 2019-01-17 04:14:21.580890: step 11398, loss = 0.55463 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:14:22.865547 ops/training.py:65 2019-01-17 04:14:22.865482: step 11399, loss = 0.55340 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:14:24.150774 ops/training.py:65 2019-01-17 04:14:24.150670: step 11400, loss = 0.56979 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:14:25.442857 ops/training.py:65 2019-01-17 04:14:25.442746: step 11401, loss = 0.58225 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:14:26.733759 ops/training.py:65 2019-01-17 04:14:26.733686: step 11402, loss = 0.64849 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:14:28.023020 ops/training.py:65 2019-01-17 04:14:28.022947: step 11403, loss = 0.60858 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:14:29.303675 ops/training.py:65 2019-01-17 04:14:29.303607: step 11404, loss = 0.72969 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:14:30.592523 ops/training.py:65 2019-01-17 04:14:30.592457: step 11405, loss = 0.59193 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:14:31.882286 ops/training.py:65 2019-01-17 04:14:31.882211: step 11406, loss = 0.64178 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:14:33.165941 ops/training.py:65 2019-01-17 04:14:33.165878: step 11407, loss = 0.63174 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:14:34.454814 ops/training.py:65 2019-01-17 04:14:34.454720: step 11408, loss = 0.62378 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:14:35.740394 ops/training.py:65 2019-01-17 04:14:35.740328: step 11409, loss = 0.56909 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:14:37.024969 ops/training.py:65 2019-01-17 04:14:37.024834: step 11410, loss = 0.61151 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:14:38.317307 ops/training.py:65 2019-01-17 04:14:38.317200: step 11411, loss = 0.62286 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:14:39.608133 ops/training.py:65 2019-01-17 04:14:39.608062: step 11412, loss = 0.65937 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:14:40.896975 ops/training.py:65 2019-01-17 04:14:40.896898: step 11413, loss = 0.55934 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:14:42.187479 ops/training.py:65 2019-01-17 04:14:42.187409: step 11414, loss = 0.60385 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:14:43.475525 ops/training.py:65 2019-01-17 04:14:43.475454: step 11415, loss = 0.53642 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:14:44.765100 ops/training.py:65 2019-01-17 04:14:44.765027: step 11416, loss = 0.63080 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:14:46.053204 ops/training.py:65 2019-01-17 04:14:46.053134: step 11417, loss = 0.53885 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:14:47.342973 ops/training.py:65 2019-01-17 04:14:47.342881: step 11418, loss = 0.64064 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:14:48.627716 ops/training.py:65 2019-01-17 04:14:48.627621: step 11419, loss = 0.63838 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:14:49.917556 ops/training.py:65 2019-01-17 04:14:49.917488: step 11420, loss = 0.69449 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:14:51.202365 ops/training.py:65 2019-01-17 04:14:51.202295: step 11421, loss = 0.62585 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:14:52.494060 ops/training.py:65 2019-01-17 04:14:52.493958: step 11422, loss = 0.66872 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:14:53.785073 ops/training.py:65 2019-01-17 04:14:53.785003: step 11423, loss = 0.62209 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:14:55.069470 ops/training.py:65 2019-01-17 04:14:55.069409: step 11424, loss = 0.56520 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:14:56.353773 ops/training.py:65 2019-01-17 04:14:56.353662: step 11425, loss = 0.65280 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:14:57.639792 ops/training.py:65 2019-01-17 04:14:57.639689: step 11426, loss = 0.56436 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:14:58.924799 ops/training.py:65 2019-01-17 04:14:58.924719: step 11427, loss = 0.63558 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:15:00.215526 ops/training.py:65 2019-01-17 04:15:00.215418: step 11428, loss = 0.64933 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:15:01.506301 ops/training.py:65 2019-01-17 04:15:01.506230: step 11429, loss = 0.61428 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:15:02.795236 ops/training.py:65 2019-01-17 04:15:02.795165: step 11430, loss = 0.64265 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:15:04.084425 ops/training.py:65 2019-01-17 04:15:04.084350: step 11431, loss = 0.72705 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:15:05.373685 ops/training.py:65 2019-01-17 04:15:05.373617: step 11432, loss = 0.62780 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:15:06.661373 ops/training.py:65 2019-01-17 04:15:06.661305: step 11433, loss = 0.66268 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:15:07.950739 ops/training.py:65 2019-01-17 04:15:07.950662: step 11434, loss = 0.66029 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:15:09.239475 ops/training.py:65 2019-01-17 04:15:09.239399: step 11435, loss = 0.68814 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:15:10.527852 ops/training.py:65 2019-01-17 04:15:10.527786: step 11436, loss = 0.61771 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:15:11.815606 ops/training.py:65 2019-01-17 04:15:11.815535: step 11437, loss = 0.62609 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:15:13.100227 ops/training.py:65 2019-01-17 04:15:13.100155: step 11438, loss = 0.52347 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:15:14.389339 ops/training.py:65 2019-01-17 04:15:14.389258: step 11439, loss = 0.66561 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:15:15.678435 ops/training.py:65 2019-01-17 04:15:15.678350: step 11440, loss = 0.66764 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:15:16.968689 ops/training.py:65 2019-01-17 04:15:16.968614: step 11441, loss = 0.63496 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:15:18.258823 ops/training.py:65 2019-01-17 04:15:18.258745: step 11442, loss = 0.75140 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:15:19.548079 ops/training.py:65 2019-01-17 04:15:19.548005: step 11443, loss = 0.62298 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:15:20.836331 ops/training.py:65 2019-01-17 04:15:20.836260: step 11444, loss = 0.65820 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:15:22.124735 ops/training.py:65 2019-01-17 04:15:22.124661: step 11445, loss = 0.58661 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:15:23.413512 ops/training.py:65 2019-01-17 04:15:23.413433: step 11446, loss = 0.69892 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:15:24.702459 ops/training.py:65 2019-01-17 04:15:24.702363: step 11447, loss = 0.56345 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:15:25.991406 ops/training.py:65 2019-01-17 04:15:25.991327: step 11448, loss = 0.57650 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:15:27.276382 ops/training.py:65 2019-01-17 04:15:27.276312: step 11449, loss = 0.61610 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:15:28.565198 ops/training.py:65 2019-01-17 04:15:28.565129: step 11450, loss = 0.58332 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:15:29.845568 ops/training.py:65 2019-01-17 04:15:29.845493: step 11451, loss = 0.58292 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:15:31.136734 ops/training.py:65 2019-01-17 04:15:31.136576: step 11452, loss = 0.63628 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:15:32.427896 ops/training.py:65 2019-01-17 04:15:32.427827: step 11453, loss = 0.69557 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:15:33.713082 ops/training.py:65 2019-01-17 04:15:33.713018: step 11454, loss = 0.56494 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:15:35.002668 ops/training.py:65 2019-01-17 04:15:35.002600: step 11455, loss = 0.47811 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:15:36.292004 ops/training.py:65 2019-01-17 04:15:36.291902: step 11456, loss = 0.71712 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:15:37.576584 ops/training.py:65 2019-01-17 04:15:37.576519: step 11457, loss = 0.66982 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:15:38.860187 ops/training.py:65 2019-01-17 04:15:38.860107: step 11458, loss = 0.75184 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:15:40.152665 ops/training.py:65 2019-01-17 04:15:40.152504: step 11459, loss = 0.63667 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:15:41.443458 ops/training.py:65 2019-01-17 04:15:41.443361: step 11460, loss = 0.57418 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:15:42.732411 ops/training.py:65 2019-01-17 04:15:42.732340: step 11461, loss = 0.63244 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:15:44.022058 ops/training.py:65 2019-01-17 04:15:44.021989: step 11462, loss = 0.54983 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:15:45.311895 ops/training.py:65 2019-01-17 04:15:45.311816: step 11463, loss = 0.64055 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:15:46.601034 ops/training.py:65 2019-01-17 04:15:46.600955: step 11464, loss = 0.64137 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:15:47.890254 ops/training.py:65 2019-01-17 04:15:47.890176: step 11465, loss = 0.54713 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:15:49.181153 ops/training.py:65 2019-01-17 04:15:49.181081: step 11466, loss = 0.63524 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:15:50.465374 ops/training.py:65 2019-01-17 04:15:50.465315: step 11467, loss = 0.68247 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:15:51.753367 ops/training.py:65 2019-01-17 04:15:51.753302: step 11468, loss = 0.68172 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:15:53.043440 ops/training.py:65 2019-01-17 04:15:53.043364: step 11469, loss = 0.63182 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:15:54.333607 ops/training.py:65 2019-01-17 04:15:54.333531: step 11470, loss = 0.62723 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:15:55.622592 ops/training.py:65 2019-01-17 04:15:55.622519: step 11471, loss = 0.78899 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 04:15:56.906748 ops/training.py:65 2019-01-17 04:15:56.906686: step 11472, loss = 0.60481 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:15:58.195820 ops/training.py:65 2019-01-17 04:15:58.195741: step 11473, loss = 0.66329 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:15:59.484954 ops/training.py:65 2019-01-17 04:15:59.484888: step 11474, loss = 0.60693 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:16:00.770607 ops/training.py:65 2019-01-17 04:16:00.770540: step 11475, loss = 0.60911 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:16:02.053073 ops/training.py:65 2019-01-17 04:16:02.052989: step 11476, loss = 0.67008 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:16:03.344652 ops/training.py:65 2019-01-17 04:16:03.344521: step 11477, loss = 0.63093 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:16:04.635845 ops/training.py:65 2019-01-17 04:16:04.635769: step 11478, loss = 0.61084 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:16:05.921095 ops/training.py:65 2019-01-17 04:16:05.921024: step 11479, loss = 0.61954 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:16:07.207367 ops/training.py:65 2019-01-17 04:16:07.207279: step 11480, loss = 0.53581 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:16:08.498276 ops/training.py:65 2019-01-17 04:16:08.498205: step 11481, loss = 0.67719 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:16:09.788290 ops/training.py:65 2019-01-17 04:16:09.788219: step 11482, loss = 0.57810 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:16:11.078686 ops/training.py:65 2019-01-17 04:16:11.078608: step 11483, loss = 0.65789 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:16:12.368790 ops/training.py:65 2019-01-17 04:16:12.368714: step 11484, loss = 0.60407 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:16:13.657643 ops/training.py:65 2019-01-17 04:16:13.657547: step 11485, loss = 0.68846 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:16:14.946823 ops/training.py:65 2019-01-17 04:16:14.946732: step 11486, loss = 0.65140 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:16:16.235615 ops/training.py:65 2019-01-17 04:16:16.235542: step 11487, loss = 0.61976 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:16:17.524491 ops/training.py:65 2019-01-17 04:16:17.524418: step 11488, loss = 0.67796 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:16:18.814194 ops/training.py:65 2019-01-17 04:16:18.814091: step 11489, loss = 0.75540 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:16:20.103623 ops/training.py:65 2019-01-17 04:16:20.103537: step 11490, loss = 0.55103 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:16:21.392585 ops/training.py:65 2019-01-17 04:16:21.392500: step 11491, loss = 0.57713 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:16:22.680707 ops/training.py:65 2019-01-17 04:16:22.680636: step 11492, loss = 0.64030 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:16:23.968996 ops/training.py:65 2019-01-17 04:16:23.968907: step 11493, loss = 0.74894 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:16:25.259056 ops/training.py:65 2019-01-17 04:16:25.258978: step 11494, loss = 0.66499 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:16:26.554344 ops/training.py:65 2019-01-17 04:16:26.554270: step 11495, loss = 0.58031 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:16:27.844462 ops/training.py:65 2019-01-17 04:16:27.844384: step 11496, loss = 0.63107 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:16:29.133513 ops/training.py:65 2019-01-17 04:16:29.133440: step 11497, loss = 0.64554 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:16:30.420918 ops/training.py:65 2019-01-17 04:16:30.420849: step 11498, loss = 0.61183 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:16:31.710918 ops/training.py:65 2019-01-17 04:16:31.710809: step 11499, loss = 0.61674 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:16:33.000037 ops/training.py:65 2019-01-17 04:16:32.999948: step 11500, loss = 0.61001 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:16:34.288222 ops/training.py:65 2019-01-17 04:16:34.288119: step 11501, loss = 0.66560 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:16:35.578135 ops/training.py:65 2019-01-17 04:16:35.578036: step 11502, loss = 0.62936 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:16:36.867405 ops/training.py:65 2019-01-17 04:16:36.867308: step 11503, loss = 0.64000 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:16:38.157220 ops/training.py:65 2019-01-17 04:16:38.157137: step 11504, loss = 0.58206 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:16:39.445880 ops/training.py:65 2019-01-17 04:16:39.445800: step 11505, loss = 0.61351 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:16:40.735898 ops/training.py:65 2019-01-17 04:16:40.735813: step 11506, loss = 0.63502 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:16:42.024594 ops/training.py:65 2019-01-17 04:16:42.024490: step 11507, loss = 0.73012 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:16:43.314064 ops/training.py:65 2019-01-17 04:16:43.313979: step 11508, loss = 0.61564 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:16:44.603348 ops/training.py:65 2019-01-17 04:16:44.603236: step 11509, loss = 0.61227 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:16:45.893259 ops/training.py:65 2019-01-17 04:16:45.893183: step 11510, loss = 0.66899 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:16:47.182459 ops/training.py:65 2019-01-17 04:16:47.182378: step 11511, loss = 0.51784 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:16:48.471837 ops/training.py:65 2019-01-17 04:16:48.471762: step 11512, loss = 0.64372 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:16:49.760623 ops/training.py:65 2019-01-17 04:16:49.760543: step 11513, loss = 0.63611 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:16:51.048872 ops/training.py:65 2019-01-17 04:16:51.048793: step 11514, loss = 0.54763 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:16:52.338346 ops/training.py:65 2019-01-17 04:16:52.338245: step 11515, loss = 0.60619 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:16:53.633369 ops/training.py:65 2019-01-17 04:16:53.633291: step 11516, loss = 0.54571 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:16:54.922486 ops/training.py:65 2019-01-17 04:16:54.922401: step 11517, loss = 0.64685 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:16:56.210484 ops/training.py:65 2019-01-17 04:16:56.210409: step 11518, loss = 0.65579 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:16:57.499948 ops/training.py:65 2019-01-17 04:16:57.499873: step 11519, loss = 0.67186 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:16:58.788994 ops/training.py:65 2019-01-17 04:16:58.788915: step 11520, loss = 0.63671 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:17:00.079378 ops/training.py:65 2019-01-17 04:17:00.079303: step 11521, loss = 0.65817 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:17:01.368902 ops/training.py:65 2019-01-17 04:17:01.368826: step 11522, loss = 0.65122 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:17:02.658106 ops/training.py:65 2019-01-17 04:17:02.658037: step 11523, loss = 0.57951 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:17:03.948091 ops/training.py:65 2019-01-17 04:17:03.948016: step 11524, loss = 0.60984 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:17:05.236705 ops/training.py:65 2019-01-17 04:17:05.236629: step 11525, loss = 0.59913 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:17:06.532058 ops/training.py:65 2019-01-17 04:17:06.531983: step 11526, loss = 0.59816 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:17:07.822203 ops/training.py:65 2019-01-17 04:17:07.822124: step 11527, loss = 0.52359 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:17:09.111765 ops/training.py:65 2019-01-17 04:17:09.111687: step 11528, loss = 0.58925 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:17:10.402272 ops/training.py:65 2019-01-17 04:17:10.402197: step 11529, loss = 0.61832 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:17:11.690689 ops/training.py:65 2019-01-17 04:17:11.690609: step 11530, loss = 0.50491 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:17:12.979662 ops/training.py:65 2019-01-17 04:17:12.979581: step 11531, loss = 0.72227 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:17:14.268643 ops/training.py:65 2019-01-17 04:17:14.268568: step 11532, loss = 0.73986 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:17:15.557799 ops/training.py:65 2019-01-17 04:17:15.557716: step 11533, loss = 0.56303 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:17:16.846914 ops/training.py:65 2019-01-17 04:17:16.846841: step 11534, loss = 0.68736 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:17:18.135065 ops/training.py:65 2019-01-17 04:17:18.134970: step 11535, loss = 0.68235 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:17:19.423937 ops/training.py:65 2019-01-17 04:17:19.423862: step 11536, loss = 0.59460 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:17:20.713255 ops/training.py:65 2019-01-17 04:17:20.713181: step 11537, loss = 0.58646 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:17:22.002203 ops/training.py:65 2019-01-17 04:17:22.002124: step 11538, loss = 0.68864 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:17:23.290550 ops/training.py:65 2019-01-17 04:17:23.290475: step 11539, loss = 0.61841 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:17:24.581312 ops/training.py:65 2019-01-17 04:17:24.581231: step 11540, loss = 0.56583 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:17:25.871686 ops/training.py:65 2019-01-17 04:17:25.871603: step 11541, loss = 0.67450 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:17:27.161049 ops/training.py:65 2019-01-17 04:17:27.160969: step 11542, loss = 0.58374 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:17:28.449292 ops/training.py:65 2019-01-17 04:17:28.449198: step 11543, loss = 0.61271 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:17:29.738161 ops/training.py:65 2019-01-17 04:17:29.738087: step 11544, loss = 0.64147 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:17:31.027362 ops/training.py:65 2019-01-17 04:17:31.027275: step 11545, loss = 0.55194 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:17:32.315082 ops/training.py:65 2019-01-17 04:17:32.315013: step 11546, loss = 0.57231 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:17:33.603390 ops/training.py:65 2019-01-17 04:17:33.603314: step 11547, loss = 0.58267 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:17:34.892356 ops/training.py:65 2019-01-17 04:17:34.892292: step 11548, loss = 0.72222 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:17:36.181606 ops/training.py:65 2019-01-17 04:17:36.181530: step 11549, loss = 0.57573 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:17:37.470497 ops/training.py:65 2019-01-17 04:17:37.470398: step 11550, loss = 0.49983 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:17:38.760820 ops/training.py:65 2019-01-17 04:17:38.760743: step 11551, loss = 0.59099 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:17:40.050132 ops/training.py:65 2019-01-17 04:17:40.050052: step 11552, loss = 0.61377 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:17:41.340008 ops/training.py:65 2019-01-17 04:17:41.339908: step 11553, loss = 0.71977 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:17:42.628549 ops/training.py:65 2019-01-17 04:17:42.628474: step 11554, loss = 0.55066 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:17:43.917668 ops/training.py:65 2019-01-17 04:17:43.917590: step 11555, loss = 0.59468 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:17:45.205782 ops/training.py:65 2019-01-17 04:17:45.205705: step 11556, loss = 0.60571 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:17:46.495829 ops/training.py:65 2019-01-17 04:17:46.495757: step 11557, loss = 0.73578 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:17:47.784527 ops/training.py:65 2019-01-17 04:17:47.784421: step 11558, loss = 0.63058 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:17:49.075573 ops/training.py:65 2019-01-17 04:17:49.075498: step 11559, loss = 0.61829 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:17:50.366143 ops/training.py:65 2019-01-17 04:17:50.366063: step 11560, loss = 0.62318 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:17:51.654042 ops/training.py:65 2019-01-17 04:17:51.653944: step 11561, loss = 0.58435 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:17:52.944173 ops/training.py:65 2019-01-17 04:17:52.944078: step 11562, loss = 0.59739 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:17:54.231650 ops/training.py:65 2019-01-17 04:17:54.231581: step 11563, loss = 0.61247 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:17:55.519572 ops/training.py:65 2019-01-17 04:17:55.519476: step 11564, loss = 0.62942 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:17:56.807960 ops/training.py:65 2019-01-17 04:17:56.807882: step 11565, loss = 0.67225 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:17:58.097024 ops/training.py:65 2019-01-17 04:17:58.096945: step 11566, loss = 0.59793 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:17:59.386434 ops/training.py:65 2019-01-17 04:17:59.386353: step 11567, loss = 0.54097 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:18:00.677260 ops/training.py:65 2019-01-17 04:18:00.677182: step 11568, loss = 0.59278 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:18:01.967876 ops/training.py:65 2019-01-17 04:18:01.967777: step 11569, loss = 0.66105 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:18:03.257544 ops/training.py:65 2019-01-17 04:18:03.257444: step 11570, loss = 0.57080 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:18:04.547640 ops/training.py:65 2019-01-17 04:18:04.547550: step 11571, loss = 0.61623 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:18:05.838016 ops/training.py:65 2019-01-17 04:18:05.837943: step 11572, loss = 0.70403 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:18:07.127466 ops/training.py:65 2019-01-17 04:18:07.127385: step 11573, loss = 0.57874 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:18:08.417051 ops/training.py:65 2019-01-17 04:18:08.416986: step 11574, loss = 0.59456 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:18:09.706551 ops/training.py:65 2019-01-17 04:18:09.706448: step 11575, loss = 0.75683 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:18:10.995886 ops/training.py:65 2019-01-17 04:18:10.995817: step 11576, loss = 0.67316 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:18:12.285141 ops/training.py:65 2019-01-17 04:18:12.285042: step 11577, loss = 0.56972 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:18:13.574315 ops/training.py:65 2019-01-17 04:18:13.574242: step 11578, loss = 0.62338 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:18:14.864736 ops/training.py:65 2019-01-17 04:18:14.864657: step 11579, loss = 0.71224 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:18:16.159702 ops/training.py:65 2019-01-17 04:18:16.159629: step 11580, loss = 0.69462 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:18:17.448637 ops/training.py:65 2019-01-17 04:18:17.448568: step 11581, loss = 0.67035 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:18:18.737277 ops/training.py:65 2019-01-17 04:18:18.737205: step 11582, loss = 0.54776 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:18:20.026407 ops/training.py:65 2019-01-17 04:18:20.026306: step 11583, loss = 0.68136 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:18:21.316868 ops/training.py:65 2019-01-17 04:18:21.316795: step 11584, loss = 0.60512 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:18:22.607330 ops/training.py:65 2019-01-17 04:18:22.607230: step 11585, loss = 0.60607 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:18:23.897600 ops/training.py:65 2019-01-17 04:18:23.897489: step 11586, loss = 0.55816 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:18:25.188179 ops/training.py:65 2019-01-17 04:18:25.188095: step 11587, loss = 0.63107 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:18:26.476804 ops/training.py:65 2019-01-17 04:18:26.476726: step 11588, loss = 0.63793 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:18:27.766174 ops/training.py:65 2019-01-17 04:18:27.766101: step 11589, loss = 0.57242 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:18:29.054598 ops/training.py:65 2019-01-17 04:18:29.054529: step 11590, loss = 0.71364 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:18:30.342629 ops/training.py:65 2019-01-17 04:18:30.342530: step 11591, loss = 0.59703 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:18:31.631511 ops/training.py:65 2019-01-17 04:18:31.631434: step 11592, loss = 0.55594 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:18:32.921694 ops/training.py:65 2019-01-17 04:18:32.921626: step 11593, loss = 0.68516 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:18:34.210011 ops/training.py:65 2019-01-17 04:18:34.209932: step 11594, loss = 0.70720 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:18:35.499028 ops/training.py:65 2019-01-17 04:18:35.498957: step 11595, loss = 0.67036 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:18:36.788475 ops/training.py:65 2019-01-17 04:18:36.788402: step 11596, loss = 0.58986 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:18:38.077967 ops/training.py:65 2019-01-17 04:18:38.077894: step 11597, loss = 0.65049 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:18:39.366940 ops/training.py:65 2019-01-17 04:18:39.366844: step 11598, loss = 0.63696 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:18:40.657326 ops/training.py:65 2019-01-17 04:18:40.657254: step 11599, loss = 0.65308 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:18:41.947735 ops/training.py:65 2019-01-17 04:18:41.947648: step 11600, loss = 0.60390 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:18:43.236383 ops/training.py:65 2019-01-17 04:18:43.236289: step 11601, loss = 0.54605 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:18:44.525329 ops/training.py:65 2019-01-17 04:18:44.525258: step 11602, loss = 0.59879 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:18:45.813992 ops/training.py:65 2019-01-17 04:18:45.813914: step 11603, loss = 0.61706 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:18:47.109765 ops/training.py:65 2019-01-17 04:18:47.109675: step 11604, loss = 0.66942 (24.7 examples/sec; 1.295 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:18:48.399162 ops/training.py:65 2019-01-17 04:18:48.399086: step 11605, loss = 0.64746 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:18:49.689531 ops/training.py:65 2019-01-17 04:18:49.689454: step 11606, loss = 0.55439 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:18:50.979824 ops/training.py:65 2019-01-17 04:18:50.979734: step 11607, loss = 0.65696 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:18:52.270142 ops/training.py:65 2019-01-17 04:18:52.270041: step 11608, loss = 0.61871 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:18:53.559788 ops/training.py:65 2019-01-17 04:18:53.559702: step 11609, loss = 0.63631 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:18:54.849076 ops/training.py:65 2019-01-17 04:18:54.848994: step 11610, loss = 0.67780 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:18:56.139089 ops/training.py:65 2019-01-17 04:18:56.138997: step 11611, loss = 0.73410 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:18:57.423652 ops/training.py:65 2019-01-17 04:18:57.423580: step 11612, loss = 0.65501 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:18:58.708836 ops/training.py:65 2019-01-17 04:18:58.708756: step 11613, loss = 0.60999 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:18:59.993464 ops/training.py:65 2019-01-17 04:18:59.993322: step 11614, loss = 0.56582 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:19:01.282120 ops/training.py:65 2019-01-17 04:19:01.281961: step 11615, loss = 0.53267 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:19:02.570303 ops/training.py:65 2019-01-17 04:19:02.570198: step 11616, loss = 0.58421 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:19:03.861361 ops/training.py:65 2019-01-17 04:19:03.861215: step 11617, loss = 0.71992 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:19:05.152130 ops/training.py:65 2019-01-17 04:19:05.152052: step 11618, loss = 0.56831 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:19:06.436781 ops/training.py:65 2019-01-17 04:19:06.436713: step 11619, loss = 0.70392 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:19:07.721601 ops/training.py:65 2019-01-17 04:19:07.721543: step 11620, loss = 0.62022 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:19:09.003516 ops/training.py:65 2019-01-17 04:19:09.003409: step 11621, loss = 0.66145 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:19:10.295221 ops/training.py:65 2019-01-17 04:19:10.295111: step 11622, loss = 0.66550 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:19:11.586414 ops/training.py:65 2019-01-17 04:19:11.586342: step 11623, loss = 0.63829 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:19:12.870980 ops/training.py:65 2019-01-17 04:19:12.870903: step 11624, loss = 0.58683 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:19:14.157047 ops/training.py:65 2019-01-17 04:19:14.156903: step 11625, loss = 0.56115 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:19:15.449358 ops/training.py:65 2019-01-17 04:19:15.449242: step 11626, loss = 0.58003 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:19:16.740210 ops/training.py:65 2019-01-17 04:19:16.740132: step 11627, loss = 0.60378 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:19:18.035012 ops/training.py:65 2019-01-17 04:19:18.034938: step 11628, loss = 0.53042 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:19:19.323899 ops/training.py:65 2019-01-17 04:19:19.323806: step 11629, loss = 0.67648 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:19:20.612932 ops/training.py:65 2019-01-17 04:19:20.612858: step 11630, loss = 0.64911 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:19:21.898652 ops/training.py:65 2019-01-17 04:19:21.898541: step 11631, loss = 0.63932 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:19:23.191342 ops/training.py:65 2019-01-17 04:19:23.191219: step 11632, loss = 0.48840 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:19:24.482091 ops/training.py:65 2019-01-17 04:19:24.482015: step 11633, loss = 0.59908 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:19:25.771096 ops/training.py:65 2019-01-17 04:19:25.771003: step 11634, loss = 0.66918 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:19:27.059506 ops/training.py:65 2019-01-17 04:19:27.059435: step 11635, loss = 0.71430 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:19:28.344464 ops/training.py:65 2019-01-17 04:19:28.344398: step 11636, loss = 0.59553 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:19:29.632952 ops/training.py:65 2019-01-17 04:19:29.632862: step 11637, loss = 0.69742 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 04:19:30.918122 ops/training.py:65 2019-01-17 04:19:30.918040: step 11638, loss = 0.65033 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:19:32.201924 ops/training.py:65 2019-01-17 04:19:32.201852: step 11639, loss = 0.56863 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:19:33.491821 ops/training.py:65 2019-01-17 04:19:33.491715: step 11640, loss = 0.63200 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:19:34.778203 ops/training.py:65 2019-01-17 04:19:34.778141: step 11641, loss = 0.62891 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:19:36.063146 ops/training.py:65 2019-01-17 04:19:36.063042: step 11642, loss = 0.57426 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:19:37.354112 ops/training.py:65 2019-01-17 04:19:37.354015: step 11643, loss = 0.70307 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:19:38.642968 ops/training.py:65 2019-01-17 04:19:38.642851: step 11644, loss = 0.61884 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:19:39.926731 ops/training.py:65 2019-01-17 04:19:39.926662: step 11645, loss = 0.60592 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:19:41.213209 ops/training.py:65 2019-01-17 04:19:41.213103: step 11646, loss = 0.65079 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:19:42.497300 ops/training.py:65 2019-01-17 04:19:42.497191: step 11647, loss = 0.57916 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:19:43.789111 ops/training.py:65 2019-01-17 04:19:43.789004: step 11648, loss = 0.68443 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:19:45.085445 ops/training.py:65 2019-01-17 04:19:45.085373: step 11649, loss = 0.63881 (24.7 examples/sec; 1.295 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:19:46.374591 ops/training.py:65 2019-01-17 04:19:46.374504: step 11650, loss = 0.56169 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:19:47.664946 ops/training.py:65 2019-01-17 04:19:47.664881: step 11651, loss = 0.57206 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:19:48.949367 ops/training.py:65 2019-01-17 04:19:48.949300: step 11652, loss = 0.56479 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:19:50.229174 ops/training.py:65 2019-01-17 04:19:50.229068: step 11653, loss = 0.61014 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:19:51.518360 ops/training.py:65 2019-01-17 04:19:51.518253: step 11654, loss = 0.64804 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:19:52.802333 ops/training.py:65 2019-01-17 04:19:52.802236: step 11655, loss = 0.58263 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:19:54.093568 ops/training.py:65 2019-01-17 04:19:54.093470: step 11656, loss = 0.60354 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:19:55.380178 ops/training.py:65 2019-01-17 04:19:55.380112: step 11657, loss = 0.71275 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:19:56.667082 ops/training.py:65 2019-01-17 04:19:56.667000: step 11658, loss = 0.52387 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:19:57.955082 ops/training.py:65 2019-01-17 04:19:57.954970: step 11659, loss = 0.49717 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:19:59.245990 ops/training.py:65 2019-01-17 04:19:59.245882: step 11660, loss = 0.57321 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:20:00.536501 ops/training.py:65 2019-01-17 04:20:00.536430: step 11661, loss = 0.62768 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:20:01.824581 ops/training.py:65 2019-01-17 04:20:01.824513: step 11662, loss = 0.53243 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:20:03.113584 ops/training.py:65 2019-01-17 04:20:03.113509: step 11663, loss = 0.63590 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:20:04.403701 ops/training.py:65 2019-01-17 04:20:04.403628: step 11664, loss = 0.58554 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:20:05.692705 ops/training.py:65 2019-01-17 04:20:05.692634: step 11665, loss = 0.71188 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:20:06.982619 ops/training.py:65 2019-01-17 04:20:06.982548: step 11666, loss = 0.60042 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:20:08.272153 ops/training.py:65 2019-01-17 04:20:08.272080: step 11667, loss = 0.58461 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:20:09.561541 ops/training.py:65 2019-01-17 04:20:09.561473: step 11668, loss = 0.75368 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:20:10.850073 ops/training.py:65 2019-01-17 04:20:10.850004: step 11669, loss = 0.54258 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:20:12.134477 ops/training.py:65 2019-01-17 04:20:12.134388: step 11670, loss = 0.69514 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:20:13.423113 ops/training.py:65 2019-01-17 04:20:13.423018: step 11671, loss = 0.66265 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:20:14.712453 ops/training.py:65 2019-01-17 04:20:14.712384: step 11672, loss = 0.59035 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:20:16.001687 ops/training.py:65 2019-01-17 04:20:16.001610: step 11673, loss = 0.62865 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:20:17.291695 ops/training.py:65 2019-01-17 04:20:17.291602: step 11674, loss = 0.62046 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:20:18.576383 ops/training.py:65 2019-01-17 04:20:18.576319: step 11675, loss = 0.57056 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:20:19.865017 ops/training.py:65 2019-01-17 04:20:19.864854: step 11676, loss = 0.59228 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:20:21.161233 ops/training.py:65 2019-01-17 04:20:21.161158: step 11677, loss = 0.65881 (24.7 examples/sec; 1.295 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:20:22.449036 ops/training.py:65 2019-01-17 04:20:22.448966: step 11678, loss = 0.57430 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:20:23.737622 ops/training.py:65 2019-01-17 04:20:23.737546: step 11679, loss = 0.67965 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:20:25.027638 ops/training.py:65 2019-01-17 04:20:25.027564: step 11680, loss = 0.73043 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:20:26.313638 ops/training.py:65 2019-01-17 04:20:26.313559: step 11681, loss = 0.66190 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:20:27.601732 ops/training.py:65 2019-01-17 04:20:27.601658: step 11682, loss = 0.62811 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:20:28.891079 ops/training.py:65 2019-01-17 04:20:28.890992: step 11683, loss = 0.68041 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:20:30.181878 ops/training.py:65 2019-01-17 04:20:30.181810: step 11684, loss = 0.69273 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:20:31.471474 ops/training.py:65 2019-01-17 04:20:31.471393: step 11685, loss = 0.61219 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:20:32.761748 ops/training.py:65 2019-01-17 04:20:32.761650: step 11686, loss = 0.53213 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:20:34.046360 ops/training.py:65 2019-01-17 04:20:34.046296: step 11687, loss = 0.70047 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:20:35.330638 ops/training.py:65 2019-01-17 04:20:35.330576: step 11688, loss = 0.52671 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:20:36.620948 ops/training.py:65 2019-01-17 04:20:36.620870: step 11689, loss = 0.71011 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:20:37.911508 ops/training.py:65 2019-01-17 04:20:37.911437: step 11690, loss = 0.69152 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:20:39.199283 ops/training.py:65 2019-01-17 04:20:39.199220: step 11691, loss = 0.66239 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:20:40.488642 ops/training.py:65 2019-01-17 04:20:40.488566: step 11692, loss = 0.59999 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:20:41.773061 ops/training.py:65 2019-01-17 04:20:41.772992: step 11693, loss = 0.52405 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:20:43.059425 ops/training.py:65 2019-01-17 04:20:43.059283: step 11694, loss = 0.62998 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:20:44.345925 ops/training.py:65 2019-01-17 04:20:44.345857: step 11695, loss = 0.62130 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:20:45.635150 ops/training.py:65 2019-01-17 04:20:45.635048: step 11696, loss = 0.61428 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:20:46.923687 ops/training.py:65 2019-01-17 04:20:46.923618: step 11697, loss = 0.55837 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:20:48.213118 ops/training.py:65 2019-01-17 04:20:48.213048: step 11698, loss = 0.64132 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:20:49.501514 ops/training.py:65 2019-01-17 04:20:49.501437: step 11699, loss = 0.63105 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:20:50.790717 ops/training.py:65 2019-01-17 04:20:50.790632: step 11700, loss = 0.69286 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:20:52.081094 ops/training.py:65 2019-01-17 04:20:52.081022: step 11701, loss = 0.58958 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:20:53.370563 ops/training.py:65 2019-01-17 04:20:53.370484: step 11702, loss = 0.58111 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:20:54.658999 ops/training.py:65 2019-01-17 04:20:54.658932: step 11703, loss = 0.66086 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:20:55.948689 ops/training.py:65 2019-01-17 04:20:55.948616: step 11704, loss = 0.64453 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:20:57.238428 ops/training.py:65 2019-01-17 04:20:57.238340: step 11705, loss = 0.70640 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:20:58.527376 ops/training.py:65 2019-01-17 04:20:58.527303: step 11706, loss = 0.63310 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:20:59.812902 ops/training.py:65 2019-01-17 04:20:59.812834: step 11707, loss = 0.60199 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:21:01.102502 ops/training.py:65 2019-01-17 04:21:01.102430: step 11708, loss = 0.65449 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:21:02.392577 ops/training.py:65 2019-01-17 04:21:02.392507: step 11709, loss = 0.64023 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:21:03.681930 ops/training.py:65 2019-01-17 04:21:03.681850: step 11710, loss = 0.65663 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:21:04.971002 ops/training.py:65 2019-01-17 04:21:04.970903: step 11711, loss = 0.56167 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:21:06.254028 ops/training.py:65 2019-01-17 04:21:06.253960: step 11712, loss = 0.57710 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:21:07.537869 ops/training.py:65 2019-01-17 04:21:07.537789: step 11713, loss = 0.55017 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:21:08.827211 ops/training.py:65 2019-01-17 04:21:08.827129: step 11714, loss = 0.61611 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:21:10.116107 ops/training.py:65 2019-01-17 04:21:10.115997: step 11715, loss = 0.74729 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:21:11.405440 ops/training.py:65 2019-01-17 04:21:11.405359: step 11716, loss = 0.56420 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:21:12.689104 ops/training.py:65 2019-01-17 04:21:12.689040: step 11717, loss = 0.59977 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:21:13.977349 ops/training.py:65 2019-01-17 04:21:13.977275: step 11718, loss = 0.67808 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:21:15.266841 ops/training.py:65 2019-01-17 04:21:15.266743: step 11719, loss = 0.60866 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:21:16.554872 ops/training.py:65 2019-01-17 04:21:16.554792: step 11720, loss = 0.53988 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:21:17.838893 ops/training.py:65 2019-01-17 04:21:17.838825: step 11721, loss = 0.63734 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:21:19.127243 ops/training.py:65 2019-01-17 04:21:19.127171: step 11722, loss = 0.66634 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:21:20.415399 ops/training.py:65 2019-01-17 04:21:20.415319: step 11723, loss = 0.54222 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:21:21.710783 ops/training.py:65 2019-01-17 04:21:21.710704: step 11724, loss = 0.55367 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:21:22.999713 ops/training.py:65 2019-01-17 04:21:22.999639: step 11725, loss = 0.74778 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:21:24.294689 ops/training.py:65 2019-01-17 04:21:24.294611: step 11726, loss = 0.64632 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:21:25.583312 ops/training.py:65 2019-01-17 04:21:25.583241: step 11727, loss = 0.68296 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:21:26.871726 ops/training.py:65 2019-01-17 04:21:26.871650: step 11728, loss = 0.62058 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:21:28.156327 ops/training.py:65 2019-01-17 04:21:28.156256: step 11729, loss = 0.65720 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:21:29.439110 ops/training.py:65 2019-01-17 04:21:29.439010: step 11730, loss = 0.70065 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:21:30.731991 ops/training.py:65 2019-01-17 04:21:30.731879: step 11731, loss = 0.66316 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:21:32.024161 ops/training.py:65 2019-01-17 04:21:32.024069: step 11732, loss = 0.84084 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 04:21:33.313089 ops/training.py:65 2019-01-17 04:21:33.313014: step 11733, loss = 0.67908 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:21:34.602261 ops/training.py:65 2019-01-17 04:21:34.602188: step 11734, loss = 0.66130 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:21:35.893009 ops/training.py:65 2019-01-17 04:21:35.892917: step 11735, loss = 0.65402 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:21:37.189184 ops/training.py:65 2019-01-17 04:21:37.189113: step 11736, loss = 0.53738 (24.7 examples/sec; 1.295 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:21:38.478245 ops/training.py:65 2019-01-17 04:21:38.478172: step 11737, loss = 0.65504 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:21:39.767992 ops/training.py:65 2019-01-17 04:21:39.767919: step 11738, loss = 0.66067 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:21:41.056744 ops/training.py:65 2019-01-17 04:21:41.056672: step 11739, loss = 0.67120 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:21:42.341406 ops/training.py:65 2019-01-17 04:21:42.341340: step 11740, loss = 0.67021 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:21:43.630051 ops/training.py:65 2019-01-17 04:21:43.629979: step 11741, loss = 0.54632 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:21:44.917909 ops/training.py:65 2019-01-17 04:21:44.917832: step 11742, loss = 0.65858 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:21:46.206770 ops/training.py:65 2019-01-17 04:21:46.206665: step 11743, loss = 0.61141 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:21:47.495554 ops/training.py:65 2019-01-17 04:21:47.495475: step 11744, loss = 0.56887 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:21:48.784949 ops/training.py:65 2019-01-17 04:21:48.784872: step 11745, loss = 0.73627 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:21:50.074940 ops/training.py:65 2019-01-17 04:21:50.074848: step 11746, loss = 0.81641 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:21:51.363864 ops/training.py:65 2019-01-17 04:21:51.363790: step 11747, loss = 0.64436 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:21:52.652010 ops/training.py:65 2019-01-17 04:21:52.651942: step 11748, loss = 0.65410 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:21:53.936487 ops/training.py:65 2019-01-17 04:21:53.936419: step 11749, loss = 0.71803 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:21:55.224511 ops/training.py:65 2019-01-17 04:21:55.224443: step 11750, loss = 0.67295 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:21:56.511623 ops/training.py:65 2019-01-17 04:21:56.511548: step 11751, loss = 0.72920 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 04:21:57.800097 ops/training.py:65 2019-01-17 04:21:57.800015: step 11752, loss = 0.63667 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:21:59.088396 ops/training.py:65 2019-01-17 04:21:59.088319: step 11753, loss = 0.58212 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:22:00.377170 ops/training.py:65 2019-01-17 04:22:00.377099: step 11754, loss = 0.63832 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:22:01.665391 ops/training.py:65 2019-01-17 04:22:01.665323: step 11755, loss = 0.54019 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:22:02.954869 ops/training.py:65 2019-01-17 04:22:02.954794: step 11756, loss = 0.62627 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:22:04.243275 ops/training.py:65 2019-01-17 04:22:04.243203: step 11757, loss = 0.63873 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:22:05.528968 ops/training.py:65 2019-01-17 04:22:05.528901: step 11758, loss = 0.67927 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:22:06.817573 ops/training.py:65 2019-01-17 04:22:06.817498: step 11759, loss = 0.64076 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:22:08.106628 ops/training.py:65 2019-01-17 04:22:08.106556: step 11760, loss = 0.65936 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:22:09.395094 ops/training.py:65 2019-01-17 04:22:09.395019: step 11761, loss = 0.58652 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:22:10.684925 ops/training.py:65 2019-01-17 04:22:10.684839: step 11762, loss = 0.56435 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:22:11.974680 ops/training.py:65 2019-01-17 04:22:11.974577: step 11763, loss = 0.55537 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:22:13.263431 ops/training.py:65 2019-01-17 04:22:13.263346: step 11764, loss = 0.61503 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:22:14.552950 ops/training.py:65 2019-01-17 04:22:14.552836: step 11765, loss = 0.67570 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:22:15.842539 ops/training.py:65 2019-01-17 04:22:15.842460: step 11766, loss = 0.56858 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:22:17.131522 ops/training.py:65 2019-01-17 04:22:17.131439: step 11767, loss = 0.52959 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:22:18.420597 ops/training.py:65 2019-01-17 04:22:18.420517: step 11768, loss = 0.75520 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:22:19.710234 ops/training.py:65 2019-01-17 04:22:19.710161: step 11769, loss = 0.65055 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:22:20.998931 ops/training.py:65 2019-01-17 04:22:20.998855: step 11770, loss = 0.52762 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:22:22.287812 ops/training.py:65 2019-01-17 04:22:22.287735: step 11771, loss = 0.61551 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:22:23.576429 ops/training.py:65 2019-01-17 04:22:23.576347: step 11772, loss = 0.73334 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:22:24.860848 ops/training.py:65 2019-01-17 04:22:24.860783: step 11773, loss = 0.53748 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:22:26.149491 ops/training.py:65 2019-01-17 04:22:26.149419: step 11774, loss = 0.61664 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:22:27.438647 ops/training.py:65 2019-01-17 04:22:27.438558: step 11775, loss = 0.62258 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:22:28.728774 ops/training.py:65 2019-01-17 04:22:28.728695: step 11776, loss = 0.72240 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:22:30.018634 ops/training.py:65 2019-01-17 04:22:30.018556: step 11777, loss = 0.68469 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:22:31.307083 ops/training.py:65 2019-01-17 04:22:31.307014: step 11778, loss = 0.65608 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:22:32.602281 ops/training.py:65 2019-01-17 04:22:32.602200: step 11779, loss = 0.66739 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:22:33.891991 ops/training.py:65 2019-01-17 04:22:33.891923: step 11780, loss = 0.71104 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:22:35.178720 ops/training.py:65 2019-01-17 04:22:35.178611: step 11781, loss = 0.62480 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:22:36.469216 ops/training.py:65 2019-01-17 04:22:36.469145: step 11782, loss = 0.57316 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:22:37.753974 ops/training.py:65 2019-01-17 04:22:37.753904: step 11783, loss = 0.57158 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:22:39.037594 ops/training.py:65 2019-01-17 04:22:39.037526: step 11784, loss = 0.58294 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:22:40.327152 ops/training.py:65 2019-01-17 04:22:40.327040: step 11785, loss = 0.65069 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:22:41.617466 ops/training.py:65 2019-01-17 04:22:41.617392: step 11786, loss = 0.67780 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:22:42.907502 ops/training.py:65 2019-01-17 04:22:42.907429: step 11787, loss = 0.63721 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:22:44.196242 ops/training.py:65 2019-01-17 04:22:44.196165: step 11788, loss = 0.66229 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:22:45.487972 ops/training.py:65 2019-01-17 04:22:45.487900: step 11789, loss = 0.55191 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:22:46.776839 ops/training.py:65 2019-01-17 04:22:46.776774: step 11790, loss = 0.47584 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:22:48.065590 ops/training.py:65 2019-01-17 04:22:48.065501: step 11791, loss = 0.64943 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:22:49.353587 ops/training.py:65 2019-01-17 04:22:49.353511: step 11792, loss = 0.73463 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:22:50.642746 ops/training.py:65 2019-01-17 04:22:50.642683: step 11793, loss = 0.64982 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:22:51.927046 ops/training.py:65 2019-01-17 04:22:51.926976: step 11794, loss = 0.62563 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:22:53.210916 ops/training.py:65 2019-01-17 04:22:53.210823: step 11795, loss = 0.75105 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:22:54.511996 ops/training.py:65 2019-01-17 04:22:54.511885: step 11796, loss = 0.66180 (24.7 examples/sec; 1.298 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:22:55.803960 ops/training.py:65 2019-01-17 04:22:55.803881: step 11797, loss = 0.67167 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:22:57.091200 ops/training.py:65 2019-01-17 04:22:57.091097: step 11798, loss = 0.65352 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:22:58.380101 ops/training.py:65 2019-01-17 04:22:58.379995: step 11799, loss = 0.70557 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:22:59.670743 ops/training.py:65 2019-01-17 04:22:59.670667: step 11800, loss = 0.64081 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:23:00.952776 ops/training.py:65 2019-01-17 04:23:00.952700: step 11801, loss = 0.87810 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:23:02.241988 ops/training.py:65 2019-01-17 04:23:02.241862: step 11802, loss = 0.67253 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:23:03.532189 ops/training.py:65 2019-01-17 04:23:03.532080: step 11803, loss = 0.68185 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:23:04.821697 ops/training.py:65 2019-01-17 04:23:04.821602: step 11804, loss = 0.51485 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:23:06.111488 ops/training.py:65 2019-01-17 04:23:06.111419: step 11805, loss = 0.51613 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:23:07.399678 ops/training.py:65 2019-01-17 04:23:07.399588: step 11806, loss = 0.66138 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:23:08.688731 ops/training.py:65 2019-01-17 04:23:08.688646: step 11807, loss = 0.61555 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:23:09.977104 ops/training.py:65 2019-01-17 04:23:09.977012: step 11808, loss = 0.59962 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:23:11.266725 ops/training.py:65 2019-01-17 04:23:11.266620: step 11809, loss = 0.55971 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:23:12.556075 ops/training.py:65 2019-01-17 04:23:12.555996: step 11810, loss = 0.62209 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:23:13.839035 ops/training.py:65 2019-01-17 04:23:13.838971: step 11811, loss = 0.54914 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:23:15.121964 ops/training.py:65 2019-01-17 04:23:15.121855: step 11812, loss = 0.59144 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:23:16.411995 ops/training.py:65 2019-01-17 04:23:16.411887: step 11813, loss = 0.62458 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:23:17.700813 ops/training.py:65 2019-01-17 04:23:17.700744: step 11814, loss = 0.66999 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:23:18.988636 ops/training.py:65 2019-01-17 04:23:18.988538: step 11815, loss = 0.51562 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:23:20.277568 ops/training.py:65 2019-01-17 04:23:20.277498: step 11816, loss = 0.61772 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:23:21.565986 ops/training.py:65 2019-01-17 04:23:21.565912: step 11817, loss = 0.67215 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:23:22.855046 ops/training.py:65 2019-01-17 04:23:22.854962: step 11818, loss = 0.58863 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:23:24.144340 ops/training.py:65 2019-01-17 04:23:24.144261: step 11819, loss = 0.66009 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:23:25.434202 ops/training.py:65 2019-01-17 04:23:25.434124: step 11820, loss = 0.57086 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:23:26.722256 ops/training.py:65 2019-01-17 04:23:26.722185: step 11821, loss = 0.54092 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:23:28.006498 ops/training.py:65 2019-01-17 04:23:28.006432: step 11822, loss = 0.52604 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:23:29.289511 ops/training.py:65 2019-01-17 04:23:29.289435: step 11823, loss = 0.53771 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:23:30.580671 ops/training.py:65 2019-01-17 04:23:30.580568: step 11824, loss = 0.72844 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:23:31.870757 ops/training.py:65 2019-01-17 04:23:31.870663: step 11825, loss = 0.62739 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:23:33.159394 ops/training.py:65 2019-01-17 04:23:33.159313: step 11826, loss = 0.50028 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:23:34.448152 ops/training.py:65 2019-01-17 04:23:34.448082: step 11827, loss = 0.79130 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:23:35.738135 ops/training.py:65 2019-01-17 04:23:35.738059: step 11828, loss = 0.72602 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:23:37.025585 ops/training.py:65 2019-01-17 04:23:37.025512: step 11829, loss = 0.64691 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:23:38.315070 ops/training.py:65 2019-01-17 04:23:38.314988: step 11830, loss = 0.66255 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:23:39.603856 ops/training.py:65 2019-01-17 04:23:39.603763: step 11831, loss = 0.66688 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:23:40.892125 ops/training.py:65 2019-01-17 04:23:40.892025: step 11832, loss = 0.68554 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:23:42.181281 ops/training.py:65 2019-01-17 04:23:42.181208: step 11833, loss = 0.72913 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:23:43.471652 ops/training.py:65 2019-01-17 04:23:43.471579: step 11834, loss = 0.59262 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:23:44.761352 ops/training.py:65 2019-01-17 04:23:44.761278: step 11835, loss = 0.52469 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:23:46.051444 ops/training.py:65 2019-01-17 04:23:46.051316: step 11836, loss = 0.66077 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:23:47.340566 ops/training.py:65 2019-01-17 04:23:47.340477: step 11837, loss = 0.65375 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:23:48.625313 ops/training.py:65 2019-01-17 04:23:48.625243: step 11838, loss = 0.51726 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:23:49.908890 ops/training.py:65 2019-01-17 04:23:49.908784: step 11839, loss = 0.69810 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:23:51.200197 ops/training.py:65 2019-01-17 04:23:51.200088: step 11840, loss = 0.73878 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:23:52.489207 ops/training.py:65 2019-01-17 04:23:52.489132: step 11841, loss = 0.50926 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:23:53.777528 ops/training.py:65 2019-01-17 04:23:53.777457: step 11842, loss = 0.49686 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:23:55.066565 ops/training.py:65 2019-01-17 04:23:55.066487: step 11843, loss = 0.66983 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:23:56.356205 ops/training.py:65 2019-01-17 04:23:56.356118: step 11844, loss = 0.67729 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:23:57.639997 ops/training.py:65 2019-01-17 04:23:57.639920: step 11845, loss = 0.57600 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:23:58.929068 ops/training.py:65 2019-01-17 04:23:58.928968: step 11846, loss = 0.60745 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:24:00.218703 ops/training.py:65 2019-01-17 04:24:00.218632: step 11847, loss = 0.58539 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:24:01.502594 ops/training.py:65 2019-01-17 04:24:01.502521: step 11848, loss = 0.74333 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:24:02.783712 ops/training.py:65 2019-01-17 04:24:02.783574: step 11849, loss = 0.60789 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:24:04.071074 ops/training.py:65 2019-01-17 04:24:04.070979: step 11850, loss = 0.65677 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:24:05.358369 ops/training.py:65 2019-01-17 04:24:05.358255: step 11851, loss = 0.63581 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:24:06.642253 ops/training.py:65 2019-01-17 04:24:06.642142: step 11852, loss = 0.57554 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:24:07.926652 ops/training.py:65 2019-01-17 04:24:07.926550: step 11853, loss = 0.71454 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:24:09.210193 ops/training.py:65 2019-01-17 04:24:09.210081: step 11854, loss = 0.60533 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:24:10.496891 ops/training.py:65 2019-01-17 04:24:10.496780: step 11855, loss = 0.55735 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:24:11.788347 ops/training.py:65 2019-01-17 04:24:11.788235: step 11856, loss = 0.57933 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:24:13.079099 ops/training.py:65 2019-01-17 04:24:13.079025: step 11857, loss = 0.59399 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:24:14.368607 ops/training.py:65 2019-01-17 04:24:14.368525: step 11858, loss = 0.55513 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:24:15.658189 ops/training.py:65 2019-01-17 04:24:15.658116: step 11859, loss = 0.64898 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:24:16.945094 ops/training.py:65 2019-01-17 04:24:16.945021: step 11860, loss = 0.67053 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:24:18.229619 ops/training.py:65 2019-01-17 04:24:18.229549: step 11861, loss = 0.51066 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:24:19.519046 ops/training.py:65 2019-01-17 04:24:19.518948: step 11862, loss = 0.66438 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:24:20.807210 ops/training.py:65 2019-01-17 04:24:20.807137: step 11863, loss = 0.72352 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:24:22.095939 ops/training.py:65 2019-01-17 04:24:22.095870: step 11864, loss = 0.61919 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:24:23.385294 ops/training.py:65 2019-01-17 04:24:23.385226: step 11865, loss = 0.64362 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:24:24.673921 ops/training.py:65 2019-01-17 04:24:24.673824: step 11866, loss = 0.66305 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:24:25.959166 ops/training.py:65 2019-01-17 04:24:25.959099: step 11867, loss = 0.61005 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:24:27.241614 ops/training.py:65 2019-01-17 04:24:27.241539: step 11868, loss = 0.65237 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:24:28.525705 ops/training.py:65 2019-01-17 04:24:28.525593: step 11869, loss = 0.78078 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 04:24:29.817294 ops/training.py:65 2019-01-17 04:24:29.817184: step 11870, loss = 0.69519 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:24:31.107881 ops/training.py:65 2019-01-17 04:24:31.107816: step 11871, loss = 0.60181 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:24:32.391809 ops/training.py:65 2019-01-17 04:24:32.391735: step 11872, loss = 0.53628 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:24:33.676899 ops/training.py:65 2019-01-17 04:24:33.676804: step 11873, loss = 0.64841 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:24:34.960842 ops/training.py:65 2019-01-17 04:24:34.960772: step 11874, loss = 0.66883 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:24:36.249965 ops/training.py:65 2019-01-17 04:24:36.249871: step 11875, loss = 0.83520 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:24:37.539537 ops/training.py:65 2019-01-17 04:24:37.539466: step 11876, loss = 0.71944 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:24:38.828005 ops/training.py:65 2019-01-17 04:24:38.827909: step 11877, loss = 0.61060 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:24:40.118975 ops/training.py:65 2019-01-17 04:24:40.118906: step 11878, loss = 0.70777 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:24:41.407417 ops/training.py:65 2019-01-17 04:24:41.407324: step 11879, loss = 0.71100 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:24:42.696817 ops/training.py:65 2019-01-17 04:24:42.696725: step 11880, loss = 0.77593 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:24:43.985510 ops/training.py:65 2019-01-17 04:24:43.985421: step 11881, loss = 0.60138 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:24:45.275110 ops/training.py:65 2019-01-17 04:24:45.275035: step 11882, loss = 0.73297 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:24:46.564774 ops/training.py:65 2019-01-17 04:24:46.564694: step 11883, loss = 0.72261 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:24:47.853201 ops/training.py:65 2019-01-17 04:24:47.853120: step 11884, loss = 0.79062 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 04:24:49.142144 ops/training.py:65 2019-01-17 04:24:49.142056: step 11885, loss = 0.63779 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:24:50.431562 ops/training.py:65 2019-01-17 04:24:50.431477: step 11886, loss = 0.58781 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:24:51.721727 ops/training.py:65 2019-01-17 04:24:51.721639: step 11887, loss = 0.54448 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:24:53.011632 ops/training.py:65 2019-01-17 04:24:53.011545: step 11888, loss = 0.66259 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:24:54.300039 ops/training.py:65 2019-01-17 04:24:54.299947: step 11889, loss = 0.54013 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:24:55.585543 ops/training.py:65 2019-01-17 04:24:55.585463: step 11890, loss = 0.57104 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:24:56.875810 ops/training.py:65 2019-01-17 04:24:56.875741: step 11891, loss = 0.66305 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:24:58.164247 ops/training.py:65 2019-01-17 04:24:58.164147: step 11892, loss = 0.58077 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:24:59.453532 ops/training.py:65 2019-01-17 04:24:59.453465: step 11893, loss = 0.50635 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:25:00.742380 ops/training.py:65 2019-01-17 04:25:00.742289: step 11894, loss = 0.66950 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:25:02.031601 ops/training.py:65 2019-01-17 04:25:02.031511: step 11895, loss = 0.64414 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:25:03.319854 ops/training.py:65 2019-01-17 04:25:03.319781: step 11896, loss = 0.64911 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:25:04.607739 ops/training.py:65 2019-01-17 04:25:04.607641: step 11897, loss = 0.66279 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:25:05.897860 ops/training.py:65 2019-01-17 04:25:05.897784: step 11898, loss = 0.61558 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:25:07.186874 ops/training.py:65 2019-01-17 04:25:07.186804: step 11899, loss = 0.48393 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:25:08.475490 ops/training.py:65 2019-01-17 04:25:08.475415: step 11900, loss = 0.57056 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:25:09.764275 ops/training.py:65 2019-01-17 04:25:09.764196: step 11901, loss = 0.62376 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:25:11.054123 ops/training.py:65 2019-01-17 04:25:11.054024: step 11902, loss = 0.66498 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:25:12.342228 ops/training.py:65 2019-01-17 04:25:12.342139: step 11903, loss = 0.66327 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:25:13.631701 ops/training.py:65 2019-01-17 04:25:13.631628: step 11904, loss = 0.65031 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:25:14.920826 ops/training.py:65 2019-01-17 04:25:14.920745: step 11905, loss = 0.64471 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:25:16.205577 ops/training.py:65 2019-01-17 04:25:16.205505: step 11906, loss = 0.52891 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:25:17.493485 ops/training.py:65 2019-01-17 04:25:17.493407: step 11907, loss = 0.63756 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:25:18.783459 ops/training.py:65 2019-01-17 04:25:18.783391: step 11908, loss = 0.63316 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:25:20.072077 ops/training.py:65 2019-01-17 04:25:20.071978: step 11909, loss = 0.59269 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:25:21.359805 ops/training.py:65 2019-01-17 04:25:21.359731: step 11910, loss = 0.65186 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:25:22.648684 ops/training.py:65 2019-01-17 04:25:22.648601: step 11911, loss = 0.77702 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:25:23.938712 ops/training.py:65 2019-01-17 04:25:23.938635: step 11912, loss = 0.62167 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:25:25.229718 ops/training.py:65 2019-01-17 04:25:25.229614: step 11913, loss = 0.60447 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:25:26.519908 ops/training.py:65 2019-01-17 04:25:26.519829: step 11914, loss = 0.58217 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:25:27.807996 ops/training.py:65 2019-01-17 04:25:27.807917: step 11915, loss = 0.67605 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:25:29.096586 ops/training.py:65 2019-01-17 04:25:29.096516: step 11916, loss = 0.48987 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:25:30.384573 ops/training.py:65 2019-01-17 04:25:30.384477: step 11917, loss = 0.64206 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:25:31.672416 ops/training.py:65 2019-01-17 04:25:31.672316: step 11918, loss = 0.55697 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:25:32.957601 ops/training.py:65 2019-01-17 04:25:32.957532: step 11919, loss = 0.63681 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:25:34.245108 ops/training.py:65 2019-01-17 04:25:34.245041: step 11920, loss = 0.53517 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:25:35.534322 ops/training.py:65 2019-01-17 04:25:35.534251: step 11921, loss = 0.53439 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:25:36.823817 ops/training.py:65 2019-01-17 04:25:36.823739: step 11922, loss = 0.67880 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:25:38.108481 ops/training.py:65 2019-01-17 04:25:38.108413: step 11923, loss = 0.71760 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:25:39.396537 ops/training.py:65 2019-01-17 04:25:39.396446: step 11924, loss = 0.55870 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:25:40.684685 ops/training.py:65 2019-01-17 04:25:40.684612: step 11925, loss = 0.50920 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:25:41.973839 ops/training.py:65 2019-01-17 04:25:41.973764: step 11926, loss = 0.62404 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:25:43.263104 ops/training.py:65 2019-01-17 04:25:43.263029: step 11927, loss = 0.61530 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:25:44.552009 ops/training.py:65 2019-01-17 04:25:44.551932: step 11928, loss = 0.64750 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:25:45.840263 ops/training.py:65 2019-01-17 04:25:45.840178: step 11929, loss = 0.60700 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:25:47.130281 ops/training.py:65 2019-01-17 04:25:47.130203: step 11930, loss = 0.54471 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:25:48.419861 ops/training.py:65 2019-01-17 04:25:48.419764: step 11931, loss = 0.58372 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:25:49.709138 ops/training.py:65 2019-01-17 04:25:49.709036: step 11932, loss = 0.56586 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:25:50.997517 ops/training.py:65 2019-01-17 04:25:50.997424: step 11933, loss = 0.58940 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:25:52.286514 ops/training.py:65 2019-01-17 04:25:52.286438: step 11934, loss = 0.59903 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:25:53.575524 ops/training.py:65 2019-01-17 04:25:53.575428: step 11935, loss = 0.60259 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:25:54.864031 ops/training.py:65 2019-01-17 04:25:54.863936: step 11936, loss = 0.70228 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:25:56.153673 ops/training.py:65 2019-01-17 04:25:56.153571: step 11937, loss = 0.76702 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:25:57.450878 ops/training.py:65 2019-01-17 04:25:57.450772: step 11938, loss = 0.57764 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:25:58.741677 ops/training.py:65 2019-01-17 04:25:58.741573: step 11939, loss = 0.64303 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:26:00.030642 ops/training.py:65 2019-01-17 04:26:00.030570: step 11940, loss = 0.60651 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:26:01.318375 ops/training.py:65 2019-01-17 04:26:01.318279: step 11941, loss = 0.61605 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:26:02.606308 ops/training.py:65 2019-01-17 04:26:02.606203: step 11942, loss = 0.63717 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:26:03.896654 ops/training.py:65 2019-01-17 04:26:03.896572: step 11943, loss = 0.65303 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:26:05.187440 ops/training.py:65 2019-01-17 04:26:05.187369: step 11944, loss = 0.75712 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:26:06.475461 ops/training.py:65 2019-01-17 04:26:06.475382: step 11945, loss = 0.47210 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:26:07.766131 ops/training.py:65 2019-01-17 04:26:07.766056: step 11946, loss = 0.60911 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:26:09.054506 ops/training.py:65 2019-01-17 04:26:09.054404: step 11947, loss = 0.61398 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:26:10.344798 ops/training.py:65 2019-01-17 04:26:10.344725: step 11948, loss = 0.71352 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:26:11.628292 ops/training.py:65 2019-01-17 04:26:11.628231: step 11949, loss = 0.66819 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:26:12.918066 ops/training.py:65 2019-01-17 04:26:12.917959: step 11950, loss = 0.66986 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:26:14.209151 ops/training.py:65 2019-01-17 04:26:14.209077: step 11951, loss = 0.55772 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:26:15.498666 ops/training.py:65 2019-01-17 04:26:15.498595: step 11952, loss = 0.65109 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:26:16.786524 ops/training.py:65 2019-01-17 04:26:16.786455: step 11953, loss = 0.73817 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 04:26:18.075812 ops/training.py:65 2019-01-17 04:26:18.075747: step 11954, loss = 0.65928 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:26:19.359552 ops/training.py:65 2019-01-17 04:26:19.359489: step 11955, loss = 0.54407 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:26:20.644834 ops/training.py:65 2019-01-17 04:26:20.644676: step 11956, loss = 0.54842 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:26:21.935056 ops/training.py:65 2019-01-17 04:26:21.934901: step 11957, loss = 0.65719 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:26:23.225360 ops/training.py:65 2019-01-17 04:26:23.225286: step 11958, loss = 0.58380 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:26:24.513896 ops/training.py:65 2019-01-17 04:26:24.513828: step 11959, loss = 0.67114 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:26:25.802779 ops/training.py:65 2019-01-17 04:26:25.802715: step 11960, loss = 0.60917 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:26:27.092228 ops/training.py:65 2019-01-17 04:26:27.092160: step 11961, loss = 0.63848 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:26:28.376543 ops/training.py:65 2019-01-17 04:26:28.376467: step 11962, loss = 0.61201 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:26:29.660727 ops/training.py:65 2019-01-17 04:26:29.660618: step 11963, loss = 0.71308 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:26:30.952296 ops/training.py:65 2019-01-17 04:26:30.952187: step 11964, loss = 0.59476 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:26:32.242880 ops/training.py:65 2019-01-17 04:26:32.242810: step 11965, loss = 0.77370 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:26:33.533074 ops/training.py:65 2019-01-17 04:26:33.532999: step 11966, loss = 0.65295 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:26:34.822234 ops/training.py:65 2019-01-17 04:26:34.822160: step 11967, loss = 0.66836 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:26:36.111905 ops/training.py:65 2019-01-17 04:26:36.111834: step 11968, loss = 0.66201 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:26:37.401340 ops/training.py:65 2019-01-17 04:26:37.401274: step 11969, loss = 0.72372 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:26:38.692019 ops/training.py:65 2019-01-17 04:26:38.691949: step 11970, loss = 0.60727 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:26:39.981817 ops/training.py:65 2019-01-17 04:26:39.981745: step 11971, loss = 0.76033 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:26:41.269132 ops/training.py:65 2019-01-17 04:26:41.269039: step 11972, loss = 0.59034 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:26:42.559446 ops/training.py:65 2019-01-17 04:26:42.559352: step 11973, loss = 0.65159 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:26:43.844311 ops/training.py:65 2019-01-17 04:26:43.844241: step 11974, loss = 0.67542 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:26:45.133018 ops/training.py:65 2019-01-17 04:26:45.132947: step 11975, loss = 0.75797 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:26:46.422160 ops/training.py:65 2019-01-17 04:26:46.422098: step 11976, loss = 0.75053 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:26:47.710880 ops/training.py:65 2019-01-17 04:26:47.710814: step 11977, loss = 0.52832 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:26:48.999005 ops/training.py:65 2019-01-17 04:26:48.998937: step 11978, loss = 0.61239 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:26:50.288288 ops/training.py:65 2019-01-17 04:26:50.288213: step 11979, loss = 0.68872 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:26:51.572680 ops/training.py:65 2019-01-17 04:26:51.572595: step 11980, loss = 0.76445 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:26:52.861188 ops/training.py:65 2019-01-17 04:26:52.861124: step 11981, loss = 0.66537 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:26:54.148708 ops/training.py:65 2019-01-17 04:26:54.148632: step 11982, loss = 0.59880 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:26:55.437239 ops/training.py:65 2019-01-17 04:26:55.437168: step 11983, loss = 0.54844 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:26:56.720501 ops/training.py:65 2019-01-17 04:26:56.720416: step 11984, loss = 0.56481 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:26:58.004060 ops/training.py:65 2019-01-17 04:26:58.003953: step 11985, loss = 0.65701 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:26:59.289354 ops/training.py:65 2019-01-17 04:26:59.289252: step 11986, loss = 0.64126 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:27:00.580166 ops/training.py:65 2019-01-17 04:27:00.580053: step 11987, loss = 0.57370 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:27:01.871083 ops/training.py:65 2019-01-17 04:27:01.871008: step 11988, loss = 0.66073 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:27:03.156132 ops/training.py:65 2019-01-17 04:27:03.156060: step 11989, loss = 0.55015 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:27:04.445254 ops/training.py:65 2019-01-17 04:27:04.445181: step 11990, loss = 0.61685 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:27:05.733398 ops/training.py:65 2019-01-17 04:27:05.733318: step 11991, loss = 0.60302 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:27:07.018787 ops/training.py:65 2019-01-17 04:27:07.018689: step 11992, loss = 0.63110 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:27:08.309125 ops/training.py:65 2019-01-17 04:27:08.309063: step 11993, loss = 0.56740 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:27:09.598488 ops/training.py:65 2019-01-17 04:27:09.598386: step 11994, loss = 0.65724 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:27:10.883038 ops/training.py:65 2019-01-17 04:27:10.882979: step 11995, loss = 0.59653 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:27:12.172098 ops/training.py:65 2019-01-17 04:27:12.171936: step 11996, loss = 0.50923 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:27:13.462902 ops/training.py:65 2019-01-17 04:27:13.462813: step 11997, loss = 0.58361 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:27:14.747420 ops/training.py:65 2019-01-17 04:27:14.747340: step 11998, loss = 0.62761 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:27:16.030488 ops/training.py:65 2019-01-17 04:27:16.030409: step 11999, loss = 0.59297 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:33:21.781123 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I4672 2019-01-17 04:33:21.782276 ops/training.py:41 2019-01-17 04:33:21.782209: step 12000, loss = 0.64 (0.1 examples/sec; 364.459 sec/batch) | Training accuracy = 0.65625 | Validation accuracy = 0.51345 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_23_33_01_706250
I4672 2019-01-17 04:33:23.072686 ops/training.py:65 2019-01-17 04:33:23.072589: step 12001, loss = 0.57632 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:33:24.361958 ops/training.py:65 2019-01-17 04:33:24.361873: step 12002, loss = 0.64986 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:33:25.649559 ops/training.py:65 2019-01-17 04:33:25.649448: step 12003, loss = 0.58200 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:33:26.934705 ops/training.py:65 2019-01-17 04:33:26.934635: step 12004, loss = 0.60004 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:33:28.223566 ops/training.py:65 2019-01-17 04:33:28.223487: step 12005, loss = 0.68725 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:33:29.511608 ops/training.py:65 2019-01-17 04:33:29.511543: step 12006, loss = 0.64903 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:33:30.796702 ops/training.py:65 2019-01-17 04:33:30.796632: step 12007, loss = 0.74188 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:33:32.080965 ops/training.py:65 2019-01-17 04:33:32.080894: step 12008, loss = 0.76150 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:33:33.372933 ops/training.py:65 2019-01-17 04:33:33.372839: step 12009, loss = 0.52913 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:33:34.663898 ops/training.py:65 2019-01-17 04:33:34.663822: step 12010, loss = 0.69097 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:33:35.952933 ops/training.py:65 2019-01-17 04:33:35.952864: step 12011, loss = 0.56058 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:33:37.241608 ops/training.py:65 2019-01-17 04:33:37.241530: step 12012, loss = 0.64352 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:33:38.526519 ops/training.py:65 2019-01-17 04:33:38.526445: step 12013, loss = 0.51781 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:33:39.819783 ops/training.py:65 2019-01-17 04:33:39.819626: step 12014, loss = 0.61695 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:33:41.111301 ops/training.py:65 2019-01-17 04:33:41.111235: step 12015, loss = 0.59847 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:33:42.406022 ops/training.py:65 2019-01-17 04:33:42.405930: step 12016, loss = 0.71403 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:33:43.690388 ops/training.py:65 2019-01-17 04:33:43.690311: step 12017, loss = 0.58560 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:33:44.975653 ops/training.py:65 2019-01-17 04:33:44.975582: step 12018, loss = 0.57787 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:33:46.264895 ops/training.py:65 2019-01-17 04:33:46.264789: step 12019, loss = 0.79363 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 04:33:47.554797 ops/training.py:65 2019-01-17 04:33:47.554711: step 12020, loss = 0.51357 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:33:48.840315 ops/training.py:65 2019-01-17 04:33:48.840241: step 12021, loss = 0.61814 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:33:50.128588 ops/training.py:65 2019-01-17 04:33:50.128490: step 12022, loss = 0.60682 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:33:51.417968 ops/training.py:65 2019-01-17 04:33:51.417873: step 12023, loss = 0.51139 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:33:52.705732 ops/training.py:65 2019-01-17 04:33:52.705664: step 12024, loss = 0.51849 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:33:53.996075 ops/training.py:65 2019-01-17 04:33:53.995997: step 12025, loss = 0.53764 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:33:55.286561 ops/training.py:65 2019-01-17 04:33:55.286466: step 12026, loss = 0.61670 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:33:56.571813 ops/training.py:65 2019-01-17 04:33:56.571750: step 12027, loss = 0.61268 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:33:57.861436 ops/training.py:65 2019-01-17 04:33:57.861362: step 12028, loss = 0.61016 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:33:59.149349 ops/training.py:65 2019-01-17 04:33:59.149276: step 12029, loss = 0.68423 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:34:00.433909 ops/training.py:65 2019-01-17 04:34:00.433845: step 12030, loss = 0.46404 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:34:01.719789 ops/training.py:65 2019-01-17 04:34:01.719678: step 12031, loss = 0.58352 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:34:03.007280 ops/training.py:65 2019-01-17 04:34:03.007177: step 12032, loss = 0.55550 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:34:04.295340 ops/training.py:65 2019-01-17 04:34:04.295269: step 12033, loss = 0.56819 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:34:05.578991 ops/training.py:65 2019-01-17 04:34:05.578911: step 12034, loss = 0.50785 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:34:06.871384 ops/training.py:65 2019-01-17 04:34:06.871278: step 12035, loss = 0.60359 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:34:08.156670 ops/training.py:65 2019-01-17 04:34:08.156596: step 12036, loss = 0.67098 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:34:09.439951 ops/training.py:65 2019-01-17 04:34:09.439872: step 12037, loss = 0.60548 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:34:10.727791 ops/training.py:65 2019-01-17 04:34:10.727690: step 12038, loss = 0.57807 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:34:12.012413 ops/training.py:65 2019-01-17 04:34:12.012312: step 12039, loss = 0.63356 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:34:13.305276 ops/training.py:65 2019-01-17 04:34:13.305133: step 12040, loss = 0.58171 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:34:14.592087 ops/training.py:65 2019-01-17 04:34:14.592018: step 12041, loss = 0.65427 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:34:15.877005 ops/training.py:65 2019-01-17 04:34:15.876930: step 12042, loss = 0.64395 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:34:17.166046 ops/training.py:65 2019-01-17 04:34:17.165974: step 12043, loss = 0.62607 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:34:18.455039 ops/training.py:65 2019-01-17 04:34:18.454936: step 12044, loss = 0.60828 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:34:19.744716 ops/training.py:65 2019-01-17 04:34:19.744642: step 12045, loss = 0.68395 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:34:21.032871 ops/training.py:65 2019-01-17 04:34:21.032766: step 12046, loss = 0.60092 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:34:22.320707 ops/training.py:65 2019-01-17 04:34:22.320636: step 12047, loss = 0.66394 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:34:23.608549 ops/training.py:65 2019-01-17 04:34:23.608473: step 12048, loss = 0.55748 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:34:24.897923 ops/training.py:65 2019-01-17 04:34:24.897845: step 12049, loss = 0.55965 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:34:26.186493 ops/training.py:65 2019-01-17 04:34:26.186410: step 12050, loss = 0.80055 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:34:27.475808 ops/training.py:65 2019-01-17 04:34:27.475732: step 12051, loss = 0.68449 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:34:28.761109 ops/training.py:65 2019-01-17 04:34:28.761045: step 12052, loss = 0.72818 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:34:30.051175 ops/training.py:65 2019-01-17 04:34:30.051079: step 12053, loss = 0.61554 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:34:31.334616 ops/training.py:65 2019-01-17 04:34:31.334544: step 12054, loss = 0.61701 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:34:32.626012 ops/training.py:65 2019-01-17 04:34:32.625902: step 12055, loss = 0.63323 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:34:33.916886 ops/training.py:65 2019-01-17 04:34:33.916789: step 12056, loss = 0.60188 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:34:35.205797 ops/training.py:65 2019-01-17 04:34:35.205701: step 12057, loss = 0.53009 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:34:36.496096 ops/training.py:65 2019-01-17 04:34:36.496026: step 12058, loss = 0.62380 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:34:37.783895 ops/training.py:65 2019-01-17 04:34:37.783808: step 12059, loss = 0.66667 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:34:39.074822 ops/training.py:65 2019-01-17 04:34:39.074747: step 12060, loss = 0.54527 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:34:40.364474 ops/training.py:65 2019-01-17 04:34:40.364394: step 12061, loss = 0.65951 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:34:41.654032 ops/training.py:65 2019-01-17 04:34:41.653955: step 12062, loss = 0.65273 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:34:42.939491 ops/training.py:65 2019-01-17 04:34:42.939418: step 12063, loss = 0.61680 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:34:44.228671 ops/training.py:65 2019-01-17 04:34:44.228596: step 12064, loss = 0.62723 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:34:45.517232 ops/training.py:65 2019-01-17 04:34:45.517153: step 12065, loss = 0.60297 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:34:46.806062 ops/training.py:65 2019-01-17 04:34:46.805983: step 12066, loss = 0.59362 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:34:48.090495 ops/training.py:65 2019-01-17 04:34:48.090414: step 12067, loss = 0.71636 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:34:49.379459 ops/training.py:65 2019-01-17 04:34:49.379378: step 12068, loss = 0.58681 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:34:50.668997 ops/training.py:65 2019-01-17 04:34:50.668899: step 12069, loss = 0.62607 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:34:51.958583 ops/training.py:65 2019-01-17 04:34:51.958504: step 12070, loss = 0.61061 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:34:53.247813 ops/training.py:65 2019-01-17 04:34:53.247743: step 12071, loss = 0.53850 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:34:54.537709 ops/training.py:65 2019-01-17 04:34:54.537644: step 12072, loss = 0.62147 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:34:55.822088 ops/training.py:65 2019-01-17 04:34:55.822019: step 12073, loss = 0.53406 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:34:57.111925 ops/training.py:65 2019-01-17 04:34:57.111855: step 12074, loss = 0.70234 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:34:58.401678 ops/training.py:65 2019-01-17 04:34:58.401603: step 12075, loss = 0.53510 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:34:59.690475 ops/training.py:65 2019-01-17 04:34:59.690368: step 12076, loss = 0.61639 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:35:00.979199 ops/training.py:65 2019-01-17 04:35:00.979101: step 12077, loss = 0.58169 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:35:02.269070 ops/training.py:65 2019-01-17 04:35:02.268976: step 12078, loss = 0.59209 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:35:03.558343 ops/training.py:65 2019-01-17 04:35:03.558247: step 12079, loss = 0.58878 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:35:04.848603 ops/training.py:65 2019-01-17 04:35:04.848502: step 12080, loss = 0.64530 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:35:06.139862 ops/training.py:65 2019-01-17 04:35:06.139781: step 12081, loss = 0.67509 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:35:07.429721 ops/training.py:65 2019-01-17 04:35:07.429615: step 12082, loss = 0.69279 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:35:08.719217 ops/training.py:65 2019-01-17 04:35:08.719123: step 12083, loss = 0.60400 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:35:10.008858 ops/training.py:65 2019-01-17 04:35:10.008753: step 12084, loss = 0.62215 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:35:11.298221 ops/training.py:65 2019-01-17 04:35:11.298152: step 12085, loss = 0.76458 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:35:12.586714 ops/training.py:65 2019-01-17 04:35:12.586641: step 12086, loss = 0.69226 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:35:13.877981 ops/training.py:65 2019-01-17 04:35:13.877908: step 12087, loss = 0.53104 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:35:15.166768 ops/training.py:65 2019-01-17 04:35:15.166693: step 12088, loss = 0.69175 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:35:16.455805 ops/training.py:65 2019-01-17 04:35:16.455730: step 12089, loss = 0.57504 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:35:17.744547 ops/training.py:65 2019-01-17 04:35:17.744480: step 12090, loss = 0.66776 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:35:19.034421 ops/training.py:65 2019-01-17 04:35:19.034342: step 12091, loss = 0.59443 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:35:20.323928 ops/training.py:65 2019-01-17 04:35:20.323847: step 12092, loss = 0.67881 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:35:21.613542 ops/training.py:65 2019-01-17 04:35:21.613463: step 12093, loss = 0.69722 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:35:22.899414 ops/training.py:65 2019-01-17 04:35:22.899354: step 12094, loss = 0.46000 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 04:35:24.187837 ops/training.py:65 2019-01-17 04:35:24.187763: step 12095, loss = 0.59628 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:35:25.476629 ops/training.py:65 2019-01-17 04:35:25.476548: step 12096, loss = 0.66052 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:35:26.764022 ops/training.py:65 2019-01-17 04:35:26.763940: step 12097, loss = 0.60969 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:35:28.049421 ops/training.py:65 2019-01-17 04:35:28.049339: step 12098, loss = 0.72071 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:35:29.337367 ops/training.py:65 2019-01-17 04:35:29.337264: step 12099, loss = 0.59763 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:35:30.629119 ops/training.py:65 2019-01-17 04:35:30.629005: step 12100, loss = 0.65282 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:35:31.918976 ops/training.py:65 2019-01-17 04:35:31.918899: step 12101, loss = 0.72105 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:35:33.208567 ops/training.py:65 2019-01-17 04:35:33.208482: step 12102, loss = 0.67870 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:35:34.498067 ops/training.py:65 2019-01-17 04:35:34.497993: step 12103, loss = 0.65617 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:35:35.786806 ops/training.py:65 2019-01-17 04:35:35.786707: step 12104, loss = 0.52824 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:35:37.077436 ops/training.py:65 2019-01-17 04:35:37.077359: step 12105, loss = 0.50201 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:35:38.367822 ops/training.py:65 2019-01-17 04:35:38.367745: step 12106, loss = 0.67378 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:35:39.656874 ops/training.py:65 2019-01-17 04:35:39.656789: step 12107, loss = 0.54874 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:35:40.941791 ops/training.py:65 2019-01-17 04:35:40.941709: step 12108, loss = 0.64484 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:35:42.226001 ops/training.py:65 2019-01-17 04:35:42.225900: step 12109, loss = 0.62407 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:35:43.519873 ops/training.py:65 2019-01-17 04:35:43.519731: step 12110, loss = 0.49966 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:35:44.807855 ops/training.py:65 2019-01-17 04:35:44.807783: step 12111, loss = 0.66565 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:35:46.096577 ops/training.py:65 2019-01-17 04:35:46.096498: step 12112, loss = 0.57081 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:35:47.385060 ops/training.py:65 2019-01-17 04:35:47.384976: step 12113, loss = 0.59109 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:35:48.670155 ops/training.py:65 2019-01-17 04:35:48.670080: step 12114, loss = 0.55320 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:35:49.952259 ops/training.py:65 2019-01-17 04:35:49.952186: step 12115, loss = 0.55726 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:35:51.244678 ops/training.py:65 2019-01-17 04:35:51.244527: step 12116, loss = 0.57915 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:35:52.536275 ops/training.py:65 2019-01-17 04:35:52.536211: step 12117, loss = 0.62730 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:35:53.826049 ops/training.py:65 2019-01-17 04:35:53.825971: step 12118, loss = 0.59169 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:35:55.116066 ops/training.py:65 2019-01-17 04:35:55.115982: step 12119, loss = 0.59360 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:35:56.407054 ops/training.py:65 2019-01-17 04:35:56.406960: step 12120, loss = 0.60409 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:35:57.695395 ops/training.py:65 2019-01-17 04:35:57.695327: step 12121, loss = 0.66208 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:35:58.984425 ops/training.py:65 2019-01-17 04:35:58.984351: step 12122, loss = 0.66821 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:36:00.272949 ops/training.py:65 2019-01-17 04:36:00.272871: step 12123, loss = 0.61729 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:36:01.561989 ops/training.py:65 2019-01-17 04:36:01.561915: step 12124, loss = 0.57705 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:36:02.847563 ops/training.py:65 2019-01-17 04:36:02.847493: step 12125, loss = 0.61913 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:36:04.137587 ops/training.py:65 2019-01-17 04:36:04.137483: step 12126, loss = 0.68994 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:36:05.421543 ops/training.py:65 2019-01-17 04:36:05.421472: step 12127, loss = 0.64811 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:36:06.712011 ops/training.py:65 2019-01-17 04:36:06.711909: step 12128, loss = 0.52355 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:36:07.998775 ops/training.py:65 2019-01-17 04:36:07.998710: step 12129, loss = 0.60030 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:36:09.285051 ops/training.py:65 2019-01-17 04:36:09.284979: step 12130, loss = 0.71896 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:36:10.573817 ops/training.py:65 2019-01-17 04:36:10.573710: step 12131, loss = 0.66366 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:36:11.861263 ops/training.py:65 2019-01-17 04:36:11.861182: step 12132, loss = 0.63797 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:36:13.149732 ops/training.py:65 2019-01-17 04:36:13.149629: step 12133, loss = 0.65571 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:36:14.435062 ops/training.py:65 2019-01-17 04:36:14.434998: step 12134, loss = 0.59922 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:36:15.719646 ops/training.py:65 2019-01-17 04:36:15.719543: step 12135, loss = 0.51306 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:36:17.012065 ops/training.py:65 2019-01-17 04:36:17.011954: step 12136, loss = 0.69247 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:36:18.300113 ops/training.py:65 2019-01-17 04:36:18.300048: step 12137, loss = 0.50575 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:36:19.587868 ops/training.py:65 2019-01-17 04:36:19.587712: step 12138, loss = 0.62491 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:36:20.873480 ops/training.py:65 2019-01-17 04:36:20.873414: step 12139, loss = 0.59431 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:36:22.158319 ops/training.py:65 2019-01-17 04:36:22.158161: step 12140, loss = 0.54218 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:36:23.447683 ops/training.py:65 2019-01-17 04:36:23.447587: step 12141, loss = 0.68332 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:36:24.739334 ops/training.py:65 2019-01-17 04:36:24.739229: step 12142, loss = 0.50873 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:36:26.030955 ops/training.py:65 2019-01-17 04:36:26.030883: step 12143, loss = 0.51418 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:36:27.315565 ops/training.py:65 2019-01-17 04:36:27.315499: step 12144, loss = 0.52289 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:36:28.603471 ops/training.py:65 2019-01-17 04:36:28.603404: step 12145, loss = 0.55126 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:36:29.897320 ops/training.py:65 2019-01-17 04:36:29.897234: step 12146, loss = 0.57979 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:36:31.186445 ops/training.py:65 2019-01-17 04:36:31.186340: step 12147, loss = 0.57672 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:36:32.474908 ops/training.py:65 2019-01-17 04:36:32.474839: step 12148, loss = 0.62754 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:36:33.762955 ops/training.py:65 2019-01-17 04:36:33.762886: step 12149, loss = 0.70025 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:36:35.050333 ops/training.py:65 2019-01-17 04:36:35.050258: step 12150, loss = 0.63681 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:36:36.339427 ops/training.py:65 2019-01-17 04:36:36.339336: step 12151, loss = 0.62730 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:36:37.641308 ops/training.py:65 2019-01-17 04:36:37.641241: step 12152, loss = 0.52395 (24.6 examples/sec; 1.301 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:36:38.929841 ops/training.py:65 2019-01-17 04:36:38.929766: step 12153, loss = 0.67357 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:36:40.217647 ops/training.py:65 2019-01-17 04:36:40.217576: step 12154, loss = 0.57122 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:36:41.503266 ops/training.py:65 2019-01-17 04:36:41.503194: step 12155, loss = 0.71346 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:36:42.792826 ops/training.py:65 2019-01-17 04:36:42.792727: step 12156, loss = 0.55053 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:36:44.082320 ops/training.py:65 2019-01-17 04:36:44.082237: step 12157, loss = 0.63029 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:36:45.371560 ops/training.py:65 2019-01-17 04:36:45.371475: step 12158, loss = 0.64797 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:36:46.660828 ops/training.py:65 2019-01-17 04:36:46.660747: step 12159, loss = 0.51107 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:36:47.950287 ops/training.py:65 2019-01-17 04:36:47.950191: step 12160, loss = 0.65343 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:36:49.235922 ops/training.py:65 2019-01-17 04:36:49.235850: step 12161, loss = 0.57471 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:36:50.524410 ops/training.py:65 2019-01-17 04:36:50.524339: step 12162, loss = 0.54451 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:36:51.813730 ops/training.py:65 2019-01-17 04:36:51.813628: step 12163, loss = 0.52631 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:36:53.103326 ops/training.py:65 2019-01-17 04:36:53.103246: step 12164, loss = 0.55670 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:36:54.393191 ops/training.py:65 2019-01-17 04:36:54.393083: step 12165, loss = 0.57510 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:36:55.683573 ops/training.py:65 2019-01-17 04:36:55.683467: step 12166, loss = 0.59266 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:36:56.973010 ops/training.py:65 2019-01-17 04:36:56.972915: step 12167, loss = 0.63170 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:36:58.263927 ops/training.py:65 2019-01-17 04:36:58.263854: step 12168, loss = 0.63247 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:36:59.553033 ops/training.py:65 2019-01-17 04:36:59.552960: step 12169, loss = 0.48774 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:37:00.843105 ops/training.py:65 2019-01-17 04:37:00.843033: step 12170, loss = 0.64727 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:37:02.133968 ops/training.py:65 2019-01-17 04:37:02.133899: step 12171, loss = 0.57239 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:37:03.423053 ops/training.py:65 2019-01-17 04:37:03.422954: step 12172, loss = 0.72159 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:37:04.714031 ops/training.py:65 2019-01-17 04:37:04.713935: step 12173, loss = 0.50401 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:37:06.002939 ops/training.py:65 2019-01-17 04:37:06.002865: step 12174, loss = 0.71129 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:37:07.292183 ops/training.py:65 2019-01-17 04:37:07.292083: step 12175, loss = 0.59860 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:37:08.580322 ops/training.py:65 2019-01-17 04:37:08.580260: step 12176, loss = 0.66212 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:37:09.869668 ops/training.py:65 2019-01-17 04:37:09.869587: step 12177, loss = 0.52658 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:37:11.158864 ops/training.py:65 2019-01-17 04:37:11.158795: step 12178, loss = 0.61239 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:37:12.446836 ops/training.py:65 2019-01-17 04:37:12.446738: step 12179, loss = 0.63193 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:37:13.736244 ops/training.py:65 2019-01-17 04:37:13.736177: step 12180, loss = 0.65508 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:37:15.025504 ops/training.py:65 2019-01-17 04:37:15.025424: step 12181, loss = 0.55720 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:37:16.316013 ops/training.py:65 2019-01-17 04:37:16.315937: step 12182, loss = 0.50824 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:37:17.604617 ops/training.py:65 2019-01-17 04:37:17.604538: step 12183, loss = 0.63379 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:37:18.891183 ops/training.py:65 2019-01-17 04:37:18.891098: step 12184, loss = 0.58152 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:37:20.183401 ops/training.py:65 2019-01-17 04:37:20.183238: step 12185, loss = 0.52137 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:37:21.476231 ops/training.py:65 2019-01-17 04:37:21.476131: step 12186, loss = 0.61594 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:37:22.767034 ops/training.py:65 2019-01-17 04:37:22.766957: step 12187, loss = 0.67130 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:37:24.056296 ops/training.py:65 2019-01-17 04:37:24.056221: step 12188, loss = 0.74702 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:37:25.344974 ops/training.py:65 2019-01-17 04:37:25.344906: step 12189, loss = 0.69661 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:37:26.633384 ops/training.py:65 2019-01-17 04:37:26.633281: step 12190, loss = 0.63892 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:37:27.922951 ops/training.py:65 2019-01-17 04:37:27.922876: step 12191, loss = 0.63017 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:37:29.212644 ops/training.py:65 2019-01-17 04:37:29.212574: step 12192, loss = 0.55681 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:37:30.502410 ops/training.py:65 2019-01-17 04:37:30.502332: step 12193, loss = 0.52916 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:37:31.786348 ops/training.py:65 2019-01-17 04:37:31.786281: step 12194, loss = 0.52149 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:37:33.073701 ops/training.py:65 2019-01-17 04:37:33.073624: step 12195, loss = 0.78119 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:37:34.361563 ops/training.py:65 2019-01-17 04:37:34.361465: step 12196, loss = 0.54636 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:37:35.649378 ops/training.py:65 2019-01-17 04:37:35.649308: step 12197, loss = 0.50906 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:37:36.938873 ops/training.py:65 2019-01-17 04:37:36.938795: step 12198, loss = 0.58286 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:37:38.228721 ops/training.py:65 2019-01-17 04:37:38.228653: step 12199, loss = 0.61557 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:37:39.518262 ops/training.py:65 2019-01-17 04:37:39.518194: step 12200, loss = 0.50086 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:37:40.804184 ops/training.py:65 2019-01-17 04:37:40.804111: step 12201, loss = 0.68730 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:37:42.090528 ops/training.py:65 2019-01-17 04:37:42.090369: step 12202, loss = 0.66879 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:37:43.382839 ops/training.py:65 2019-01-17 04:37:43.382743: step 12203, loss = 0.65357 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:37:44.674182 ops/training.py:65 2019-01-17 04:37:44.674111: step 12204, loss = 0.67864 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:37:45.963768 ops/training.py:65 2019-01-17 04:37:45.963695: step 12205, loss = 0.62603 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:37:47.253124 ops/training.py:65 2019-01-17 04:37:47.253028: step 12206, loss = 0.73350 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:37:48.543401 ops/training.py:65 2019-01-17 04:37:48.543315: step 12207, loss = 0.93865 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:37:49.831962 ops/training.py:65 2019-01-17 04:37:49.831892: step 12208, loss = 0.87721 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 04:37:51.121638 ops/training.py:65 2019-01-17 04:37:51.121563: step 12209, loss = 0.54668 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:37:52.407129 ops/training.py:65 2019-01-17 04:37:52.407056: step 12210, loss = 0.71165 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:37:53.696449 ops/training.py:65 2019-01-17 04:37:53.696353: step 12211, loss = 0.92081 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 04:37:54.984998 ops/training.py:65 2019-01-17 04:37:54.984932: step 12212, loss = 0.80809 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:37:56.273817 ops/training.py:65 2019-01-17 04:37:56.273733: step 12213, loss = 0.93752 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 04:37:57.559427 ops/training.py:65 2019-01-17 04:37:57.559360: step 12214, loss = 0.69816 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:37:58.845507 ops/training.py:65 2019-01-17 04:37:58.845435: step 12215, loss = 0.72279 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:38:00.138434 ops/training.py:65 2019-01-17 04:38:00.138346: step 12216, loss = 0.77680 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 04:38:01.424626 ops/training.py:65 2019-01-17 04:38:01.424552: step 12217, loss = 0.74556 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:38:02.713584 ops/training.py:65 2019-01-17 04:38:02.713515: step 12218, loss = 0.63523 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:38:04.003172 ops/training.py:65 2019-01-17 04:38:04.003068: step 12219, loss = 0.60854 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:38:05.293508 ops/training.py:65 2019-01-17 04:38:05.293439: step 12220, loss = 0.58721 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:38:06.578408 ops/training.py:65 2019-01-17 04:38:06.578326: step 12221, loss = 0.57041 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:38:07.866374 ops/training.py:65 2019-01-17 04:38:07.866292: step 12222, loss = 0.53919 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:38:09.155442 ops/training.py:65 2019-01-17 04:38:09.155345: step 12223, loss = 0.53630 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:38:10.441626 ops/training.py:65 2019-01-17 04:38:10.441547: step 12224, loss = 0.60470 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:38:11.731319 ops/training.py:65 2019-01-17 04:38:11.731246: step 12225, loss = 0.63694 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:38:13.019487 ops/training.py:65 2019-01-17 04:38:13.019394: step 12226, loss = 0.53212 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:38:14.308999 ops/training.py:65 2019-01-17 04:38:14.308924: step 12227, loss = 0.63334 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:38:15.599454 ops/training.py:65 2019-01-17 04:38:15.599378: step 12228, loss = 0.63824 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:38:16.888778 ops/training.py:65 2019-01-17 04:38:16.888709: step 12229, loss = 0.59266 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:38:18.178945 ops/training.py:65 2019-01-17 04:38:18.178873: step 12230, loss = 0.53464 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:38:19.467937 ops/training.py:65 2019-01-17 04:38:19.467839: step 12231, loss = 0.57544 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:38:20.757002 ops/training.py:65 2019-01-17 04:38:20.756929: step 12232, loss = 0.56349 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:38:22.045587 ops/training.py:65 2019-01-17 04:38:22.045513: step 12233, loss = 0.61298 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:38:23.333728 ops/training.py:65 2019-01-17 04:38:23.333652: step 12234, loss = 0.57779 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:38:24.622847 ops/training.py:65 2019-01-17 04:38:24.622779: step 12235, loss = 0.64377 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:38:25.908736 ops/training.py:65 2019-01-17 04:38:25.908644: step 12236, loss = 0.60384 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:38:27.198795 ops/training.py:65 2019-01-17 04:38:27.198713: step 12237, loss = 0.57112 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:38:28.487505 ops/training.py:65 2019-01-17 04:38:28.487434: step 12238, loss = 0.60854 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:38:29.776468 ops/training.py:65 2019-01-17 04:38:29.776397: step 12239, loss = 0.63314 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:38:31.057677 ops/training.py:65 2019-01-17 04:38:31.057611: step 12240, loss = 0.60243 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:38:32.345666 ops/training.py:65 2019-01-17 04:38:32.345593: step 12241, loss = 0.52639 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:38:33.634480 ops/training.py:65 2019-01-17 04:38:33.634405: step 12242, loss = 0.70309 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 04:38:34.923049 ops/training.py:65 2019-01-17 04:38:34.922949: step 12243, loss = 0.51837 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:38:36.211528 ops/training.py:65 2019-01-17 04:38:36.211448: step 12244, loss = 0.59067 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:38:37.500876 ops/training.py:65 2019-01-17 04:38:37.500769: step 12245, loss = 0.67385 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:38:38.785990 ops/training.py:65 2019-01-17 04:38:38.785920: step 12246, loss = 0.63160 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:38:40.075261 ops/training.py:65 2019-01-17 04:38:40.075157: step 12247, loss = 0.66950 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:38:41.365143 ops/training.py:65 2019-01-17 04:38:41.365064: step 12248, loss = 0.69068 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:38:42.661181 ops/training.py:65 2019-01-17 04:38:42.661104: step 12249, loss = 0.64257 (24.7 examples/sec; 1.295 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:38:43.950009 ops/training.py:65 2019-01-17 04:38:43.949893: step 12250, loss = 0.62612 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:38:45.238980 ops/training.py:65 2019-01-17 04:38:45.238906: step 12251, loss = 0.58089 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:38:46.528058 ops/training.py:65 2019-01-17 04:38:46.527965: step 12252, loss = 0.60249 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:38:47.817464 ops/training.py:65 2019-01-17 04:38:47.817383: step 12253, loss = 0.51578 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:38:49.102906 ops/training.py:65 2019-01-17 04:38:49.102835: step 12254, loss = 0.58848 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:38:50.391878 ops/training.py:65 2019-01-17 04:38:50.391794: step 12255, loss = 0.59549 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:38:51.681338 ops/training.py:65 2019-01-17 04:38:51.681262: step 12256, loss = 0.58948 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:38:52.970975 ops/training.py:65 2019-01-17 04:38:52.970905: step 12257, loss = 0.50110 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:38:54.260277 ops/training.py:65 2019-01-17 04:38:54.260203: step 12258, loss = 0.64218 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:38:55.547864 ops/training.py:65 2019-01-17 04:38:55.547778: step 12259, loss = 0.63790 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:38:56.836542 ops/training.py:65 2019-01-17 04:38:56.836455: step 12260, loss = 0.50028 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:38:58.125878 ops/training.py:65 2019-01-17 04:38:58.125805: step 12261, loss = 0.50974 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:38:59.413768 ops/training.py:65 2019-01-17 04:38:59.413691: step 12262, loss = 0.68653 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:39:00.703361 ops/training.py:65 2019-01-17 04:39:00.703263: step 12263, loss = 0.75973 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:39:01.994554 ops/training.py:65 2019-01-17 04:39:01.994481: step 12264, loss = 0.60191 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:39:03.283093 ops/training.py:65 2019-01-17 04:39:03.283018: step 12265, loss = 0.65056 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:39:04.568823 ops/training.py:65 2019-01-17 04:39:04.568756: step 12266, loss = 0.52713 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:39:05.857026 ops/training.py:65 2019-01-17 04:39:05.856951: step 12267, loss = 0.64469 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:39:07.145132 ops/training.py:65 2019-01-17 04:39:07.145060: step 12268, loss = 0.50829 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:39:08.434484 ops/training.py:65 2019-01-17 04:39:08.434411: step 12269, loss = 0.57517 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:39:09.719332 ops/training.py:65 2019-01-17 04:39:09.719237: step 12270, loss = 0.70301 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:39:11.007872 ops/training.py:65 2019-01-17 04:39:11.007793: step 12271, loss = 0.46969 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:39:12.295916 ops/training.py:65 2019-01-17 04:39:12.295842: step 12272, loss = 0.57739 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:39:13.585311 ops/training.py:65 2019-01-17 04:39:13.585226: step 12273, loss = 0.73688 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:39:14.874365 ops/training.py:65 2019-01-17 04:39:14.874296: step 12274, loss = 0.58292 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:39:16.162641 ops/training.py:65 2019-01-17 04:39:16.162565: step 12275, loss = 0.53508 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:39:17.446938 ops/training.py:65 2019-01-17 04:39:17.446869: step 12276, loss = 0.72301 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 04:39:18.735564 ops/training.py:65 2019-01-17 04:39:18.735485: step 12277, loss = 0.57282 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:39:20.020191 ops/training.py:65 2019-01-17 04:39:20.020116: step 12278, loss = 0.60707 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:39:21.308098 ops/training.py:65 2019-01-17 04:39:21.308020: step 12279, loss = 0.55014 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:39:22.595895 ops/training.py:65 2019-01-17 04:39:22.595817: step 12280, loss = 0.61950 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:39:23.880966 ops/training.py:65 2019-01-17 04:39:23.880895: step 12281, loss = 0.65849 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:39:25.168618 ops/training.py:65 2019-01-17 04:39:25.168514: step 12282, loss = 0.55633 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:39:26.456036 ops/training.py:65 2019-01-17 04:39:26.455958: step 12283, loss = 0.66701 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:39:27.744074 ops/training.py:65 2019-01-17 04:39:27.743977: step 12284, loss = 0.63141 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:39:29.029647 ops/training.py:65 2019-01-17 04:39:29.029568: step 12285, loss = 0.49865 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:39:30.318156 ops/training.py:65 2019-01-17 04:39:30.318086: step 12286, loss = 0.52017 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:39:31.606528 ops/training.py:65 2019-01-17 04:39:31.606449: step 12287, loss = 0.65564 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:39:32.895788 ops/training.py:65 2019-01-17 04:39:32.895689: step 12288, loss = 0.63937 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:39:34.185703 ops/training.py:65 2019-01-17 04:39:34.185609: step 12289, loss = 0.91610 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.375
I4672 2019-01-17 04:39:35.472448 ops/training.py:65 2019-01-17 04:39:35.472351: step 12290, loss = 0.55290 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:39:36.761979 ops/training.py:65 2019-01-17 04:39:36.761910: step 12291, loss = 0.76102 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:39:38.046100 ops/training.py:65 2019-01-17 04:39:38.046031: step 12292, loss = 0.57020 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:39:39.329728 ops/training.py:65 2019-01-17 04:39:39.329602: step 12293, loss = 0.67372 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:39:40.621642 ops/training.py:65 2019-01-17 04:39:40.621528: step 12294, loss = 0.69914 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:39:41.911688 ops/training.py:65 2019-01-17 04:39:41.911587: step 12295, loss = 0.63428 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:39:43.202475 ops/training.py:65 2019-01-17 04:39:43.202395: step 12296, loss = 0.53483 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:39:44.491028 ops/training.py:65 2019-01-17 04:39:44.490918: step 12297, loss = 0.53013 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:39:45.779466 ops/training.py:65 2019-01-17 04:39:45.779379: step 12298, loss = 0.66486 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:39:47.064343 ops/training.py:65 2019-01-17 04:39:47.064240: step 12299, loss = 0.56525 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:39:48.359630 ops/training.py:65 2019-01-17 04:39:48.359535: step 12300, loss = 0.55406 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:39:49.649276 ops/training.py:65 2019-01-17 04:39:49.649183: step 12301, loss = 0.58947 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:39:50.938735 ops/training.py:65 2019-01-17 04:39:50.938640: step 12302, loss = 0.63958 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:39:52.227359 ops/training.py:65 2019-01-17 04:39:52.227268: step 12303, loss = 0.54810 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:39:53.515967 ops/training.py:65 2019-01-17 04:39:53.515893: step 12304, loss = 0.68365 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:39:54.804914 ops/training.py:65 2019-01-17 04:39:54.804820: step 12305, loss = 0.53101 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:39:56.094347 ops/training.py:65 2019-01-17 04:39:56.094240: step 12306, loss = 0.58192 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:39:57.383672 ops/training.py:65 2019-01-17 04:39:57.383604: step 12307, loss = 0.54721 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:39:58.664030 ops/training.py:65 2019-01-17 04:39:58.663929: step 12308, loss = 0.55339 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:39:59.955423 ops/training.py:65 2019-01-17 04:39:59.955357: step 12309, loss = 0.73046 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:40:01.245647 ops/training.py:65 2019-01-17 04:40:01.245564: step 12310, loss = 0.57383 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:40:02.534115 ops/training.py:65 2019-01-17 04:40:02.534033: step 12311, loss = 0.52082 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:40:03.824873 ops/training.py:65 2019-01-17 04:40:03.824796: step 12312, loss = 0.55946 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:40:05.120192 ops/training.py:65 2019-01-17 04:40:05.120116: step 12313, loss = 0.56736 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:40:06.410118 ops/training.py:65 2019-01-17 04:40:06.410048: step 12314, loss = 0.57348 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:40:07.700094 ops/training.py:65 2019-01-17 04:40:07.700012: step 12315, loss = 0.55006 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:40:08.986271 ops/training.py:65 2019-01-17 04:40:08.986201: step 12316, loss = 0.63519 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:40:10.275473 ops/training.py:65 2019-01-17 04:40:10.275374: step 12317, loss = 0.56746 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:40:11.565212 ops/training.py:65 2019-01-17 04:40:11.565136: step 12318, loss = 0.60665 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:40:12.853386 ops/training.py:65 2019-01-17 04:40:12.853304: step 12319, loss = 0.53884 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:40:14.142762 ops/training.py:65 2019-01-17 04:40:14.142662: step 12320, loss = 0.60340 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:40:15.432922 ops/training.py:65 2019-01-17 04:40:15.432849: step 12321, loss = 0.49934 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:40:16.722743 ops/training.py:65 2019-01-17 04:40:16.722651: step 12322, loss = 0.64135 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:40:18.007259 ops/training.py:65 2019-01-17 04:40:18.007188: step 12323, loss = 0.55785 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:40:19.290961 ops/training.py:65 2019-01-17 04:40:19.290893: step 12324, loss = 0.53219 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:40:20.574049 ops/training.py:65 2019-01-17 04:40:20.573936: step 12325, loss = 0.51008 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:40:21.872416 ops/training.py:65 2019-01-17 04:40:21.872307: step 12326, loss = 0.49023 (24.7 examples/sec; 1.297 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 04:40:23.160697 ops/training.py:65 2019-01-17 04:40:23.160603: step 12327, loss = 0.49940 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:40:24.450296 ops/training.py:65 2019-01-17 04:40:24.450159: step 12328, loss = 0.49798 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:40:25.741126 ops/training.py:65 2019-01-17 04:40:25.741050: step 12329, loss = 0.59123 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:40:27.030163 ops/training.py:65 2019-01-17 04:40:27.030084: step 12330, loss = 0.61189 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:40:28.321133 ops/training.py:65 2019-01-17 04:40:28.321049: step 12331, loss = 0.61106 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:40:29.606200 ops/training.py:65 2019-01-17 04:40:29.606136: step 12332, loss = 0.74428 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:40:30.889078 ops/training.py:65 2019-01-17 04:40:30.889002: step 12333, loss = 0.54883 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:40:32.173460 ops/training.py:65 2019-01-17 04:40:32.173346: step 12334, loss = 0.83109 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:40:33.457570 ops/training.py:65 2019-01-17 04:40:33.457475: step 12335, loss = 0.58341 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:40:34.744668 ops/training.py:65 2019-01-17 04:40:34.744567: step 12336, loss = 0.70965 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:40:36.035779 ops/training.py:65 2019-01-17 04:40:36.035677: step 12337, loss = 0.61997 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:40:37.325809 ops/training.py:65 2019-01-17 04:40:37.325736: step 12338, loss = 0.65241 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:40:38.613863 ops/training.py:65 2019-01-17 04:40:38.613790: step 12339, loss = 0.62362 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:40:39.900624 ops/training.py:65 2019-01-17 04:40:39.900559: step 12340, loss = 0.53862 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:40:41.184891 ops/training.py:65 2019-01-17 04:40:41.184785: step 12341, loss = 0.69718 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:40:42.467249 ops/training.py:65 2019-01-17 04:40:42.467163: step 12342, loss = 0.57315 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:40:43.757892 ops/training.py:65 2019-01-17 04:40:43.757796: step 12343, loss = 0.65123 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:40:45.043250 ops/training.py:65 2019-01-17 04:40:45.043169: step 12344, loss = 0.47980 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:40:46.327498 ops/training.py:65 2019-01-17 04:40:46.327396: step 12345, loss = 0.66192 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:40:47.618994 ops/training.py:65 2019-01-17 04:40:47.618886: step 12346, loss = 0.54697 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:40:48.909607 ops/training.py:65 2019-01-17 04:40:48.909504: step 12347, loss = 0.76789 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:40:50.194562 ops/training.py:65 2019-01-17 04:40:50.194487: step 12348, loss = 0.56365 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:40:51.484022 ops/training.py:65 2019-01-17 04:40:51.483867: step 12349, loss = 0.52289 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:40:52.770515 ops/training.py:65 2019-01-17 04:40:52.770439: step 12350, loss = 0.50586 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:40:54.057134 ops/training.py:65 2019-01-17 04:40:54.057056: step 12351, loss = 0.59463 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:40:55.345245 ops/training.py:65 2019-01-17 04:40:55.345157: step 12352, loss = 0.63879 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:40:56.634929 ops/training.py:65 2019-01-17 04:40:56.634848: step 12353, loss = 0.49490 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:40:57.924443 ops/training.py:65 2019-01-17 04:40:57.924369: step 12354, loss = 0.61967 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:40:59.212705 ops/training.py:65 2019-01-17 04:40:59.212635: step 12355, loss = 0.59640 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:41:00.500736 ops/training.py:65 2019-01-17 04:41:00.500634: step 12356, loss = 0.71188 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:41:01.789649 ops/training.py:65 2019-01-17 04:41:01.789545: step 12357, loss = 0.56787 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:41:03.080444 ops/training.py:65 2019-01-17 04:41:03.080341: step 12358, loss = 0.68876 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:41:04.370226 ops/training.py:65 2019-01-17 04:41:04.370148: step 12359, loss = 0.50299 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:41:05.660658 ops/training.py:65 2019-01-17 04:41:05.660589: step 12360, loss = 0.57298 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:41:06.949467 ops/training.py:65 2019-01-17 04:41:06.949372: step 12361, loss = 0.62598 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:41:08.238799 ops/training.py:65 2019-01-17 04:41:08.238696: step 12362, loss = 0.67464 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:41:09.526937 ops/training.py:65 2019-01-17 04:41:09.526848: step 12363, loss = 0.49947 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:41:10.817205 ops/training.py:65 2019-01-17 04:41:10.817127: step 12364, loss = 0.65700 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:41:12.106562 ops/training.py:65 2019-01-17 04:41:12.106474: step 12365, loss = 0.67647 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:41:13.396122 ops/training.py:65 2019-01-17 04:41:13.396026: step 12366, loss = 0.55456 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:41:14.685466 ops/training.py:65 2019-01-17 04:41:14.685373: step 12367, loss = 0.56188 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:41:15.974688 ops/training.py:65 2019-01-17 04:41:15.974591: step 12368, loss = 0.58209 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:41:17.263426 ops/training.py:65 2019-01-17 04:41:17.263337: step 12369, loss = 0.56658 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:41:18.552124 ops/training.py:65 2019-01-17 04:41:18.552052: step 12370, loss = 0.57300 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:41:19.841427 ops/training.py:65 2019-01-17 04:41:19.841353: step 12371, loss = 0.57250 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:41:21.130508 ops/training.py:65 2019-01-17 04:41:21.130440: step 12372, loss = 0.66155 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:41:22.419051 ops/training.py:65 2019-01-17 04:41:22.418953: step 12373, loss = 0.56009 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:41:23.709030 ops/training.py:65 2019-01-17 04:41:23.708955: step 12374, loss = 0.66106 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:41:24.997534 ops/training.py:65 2019-01-17 04:41:24.997460: step 12375, loss = 0.54927 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:41:26.286655 ops/training.py:65 2019-01-17 04:41:26.286584: step 12376, loss = 0.55897 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:41:27.576329 ops/training.py:65 2019-01-17 04:41:27.576244: step 12377, loss = 0.60291 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:41:28.863212 ops/training.py:65 2019-01-17 04:41:28.863138: step 12378, loss = 0.53062 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:41:30.151986 ops/training.py:65 2019-01-17 04:41:30.151914: step 12379, loss = 0.60566 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:41:31.438616 ops/training.py:65 2019-01-17 04:41:31.438554: step 12380, loss = 0.60228 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:41:32.728940 ops/training.py:65 2019-01-17 04:41:32.728863: step 12381, loss = 0.49102 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:41:34.016397 ops/training.py:65 2019-01-17 04:41:34.016299: step 12382, loss = 0.61916 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:41:35.306088 ops/training.py:65 2019-01-17 04:41:35.305997: step 12383, loss = 0.67771 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:41:36.594070 ops/training.py:65 2019-01-17 04:41:36.594003: step 12384, loss = 0.57953 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:41:37.883242 ops/training.py:65 2019-01-17 04:41:37.883149: step 12385, loss = 0.72901 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:41:39.173005 ops/training.py:65 2019-01-17 04:41:39.172927: step 12386, loss = 0.64290 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:41:40.461997 ops/training.py:65 2019-01-17 04:41:40.461918: step 12387, loss = 0.54214 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:41:41.749344 ops/training.py:65 2019-01-17 04:41:41.749267: step 12388, loss = 0.66891 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:41:43.038758 ops/training.py:65 2019-01-17 04:41:43.038675: step 12389, loss = 0.56761 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:41:44.326876 ops/training.py:65 2019-01-17 04:41:44.326806: step 12390, loss = 0.56257 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:41:45.616153 ops/training.py:65 2019-01-17 04:41:45.616085: step 12391, loss = 0.61741 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:41:46.905572 ops/training.py:65 2019-01-17 04:41:46.905495: step 12392, loss = 0.52787 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:41:48.189807 ops/training.py:65 2019-01-17 04:41:48.189736: step 12393, loss = 0.66151 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:41:49.472949 ops/training.py:65 2019-01-17 04:41:49.472870: step 12394, loss = 0.62754 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:41:50.765141 ops/training.py:65 2019-01-17 04:41:50.764984: step 12395, loss = 0.56216 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:41:52.056426 ops/training.py:65 2019-01-17 04:41:52.056342: step 12396, loss = 0.63248 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:41:53.345137 ops/training.py:65 2019-01-17 04:41:53.345040: step 12397, loss = 0.68104 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:41:54.631401 ops/training.py:65 2019-01-17 04:41:54.631331: step 12398, loss = 0.65891 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:41:55.919224 ops/training.py:65 2019-01-17 04:41:55.919149: step 12399, loss = 0.65676 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:41:57.207853 ops/training.py:65 2019-01-17 04:41:57.207762: step 12400, loss = 0.44574 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:41:58.496520 ops/training.py:65 2019-01-17 04:41:58.496437: step 12401, loss = 0.46892 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 04:41:59.779810 ops/training.py:65 2019-01-17 04:41:59.779742: step 12402, loss = 0.55401 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:42:01.063737 ops/training.py:65 2019-01-17 04:42:01.063673: step 12403, loss = 0.55672 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:42:02.352042 ops/training.py:65 2019-01-17 04:42:02.351946: step 12404, loss = 0.73771 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:42:03.640940 ops/training.py:65 2019-01-17 04:42:03.640866: step 12405, loss = 0.48372 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:42:04.926266 ops/training.py:65 2019-01-17 04:42:04.926193: step 12406, loss = 0.60147 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:42:06.213945 ops/training.py:65 2019-01-17 04:42:06.213866: step 12407, loss = 0.49536 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:42:07.503839 ops/training.py:65 2019-01-17 04:42:07.503745: step 12408, loss = 0.48534 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:42:08.794537 ops/training.py:65 2019-01-17 04:42:08.794457: step 12409, loss = 0.52881 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:42:10.084140 ops/training.py:65 2019-01-17 04:42:10.084064: step 12410, loss = 0.54314 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:42:11.373514 ops/training.py:65 2019-01-17 04:42:11.373438: step 12411, loss = 0.68726 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:42:12.668613 ops/training.py:65 2019-01-17 04:42:12.668517: step 12412, loss = 0.54182 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:42:13.958567 ops/training.py:65 2019-01-17 04:42:13.958470: step 12413, loss = 0.59894 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:42:15.247968 ops/training.py:65 2019-01-17 04:42:15.247870: step 12414, loss = 0.57982 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:42:16.537296 ops/training.py:65 2019-01-17 04:42:16.537221: step 12415, loss = 0.59025 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:42:17.825818 ops/training.py:65 2019-01-17 04:42:17.825750: step 12416, loss = 0.62712 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:42:19.110755 ops/training.py:65 2019-01-17 04:42:19.110686: step 12417, loss = 0.55283 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:42:20.394134 ops/training.py:65 2019-01-17 04:42:20.394026: step 12418, loss = 0.74272 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:42:21.687083 ops/training.py:65 2019-01-17 04:42:21.686929: step 12419, loss = 0.50374 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:42:22.975243 ops/training.py:65 2019-01-17 04:42:22.975171: step 12420, loss = 0.60564 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:42:24.265016 ops/training.py:65 2019-01-17 04:42:24.264940: step 12421, loss = 0.46995 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:42:25.554421 ops/training.py:65 2019-01-17 04:42:25.554351: step 12422, loss = 0.64043 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:42:26.838020 ops/training.py:65 2019-01-17 04:42:26.837948: step 12423, loss = 0.63593 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:42:28.123501 ops/training.py:65 2019-01-17 04:42:28.123442: step 12424, loss = 0.61869 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:42:29.403802 ops/training.py:65 2019-01-17 04:42:29.403654: step 12425, loss = 0.61951 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:42:30.696674 ops/training.py:65 2019-01-17 04:42:30.696520: step 12426, loss = 0.48389 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:42:31.989877 ops/training.py:65 2019-01-17 04:42:31.989808: step 12427, loss = 0.61146 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:42:33.279280 ops/training.py:65 2019-01-17 04:42:33.279207: step 12428, loss = 0.64968 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:42:34.568289 ops/training.py:65 2019-01-17 04:42:34.568227: step 12429, loss = 0.65185 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:42:35.856797 ops/training.py:65 2019-01-17 04:42:35.856728: step 12430, loss = 0.70700 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:42:37.145830 ops/training.py:65 2019-01-17 04:42:37.145759: step 12431, loss = 0.70705 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:42:38.433757 ops/training.py:65 2019-01-17 04:42:38.433687: step 12432, loss = 0.63636 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:42:39.723541 ops/training.py:65 2019-01-17 04:42:39.723465: step 12433, loss = 0.82252 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:42:41.011050 ops/training.py:65 2019-01-17 04:42:41.010985: step 12434, loss = 0.64304 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:42:42.295856 ops/training.py:65 2019-01-17 04:42:42.295784: step 12435, loss = 0.51945 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:42:43.584616 ops/training.py:65 2019-01-17 04:42:43.584541: step 12436, loss = 0.57581 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:42:44.873898 ops/training.py:65 2019-01-17 04:42:44.873818: step 12437, loss = 0.64535 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:42:46.159299 ops/training.py:65 2019-01-17 04:42:46.159227: step 12438, loss = 0.58427 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:42:47.446992 ops/training.py:65 2019-01-17 04:42:47.446913: step 12439, loss = 0.60645 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:42:48.735461 ops/training.py:65 2019-01-17 04:42:48.735399: step 12440, loss = 0.56531 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:42:50.022539 ops/training.py:65 2019-01-17 04:42:50.022467: step 12441, loss = 0.57552 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:42:51.310521 ops/training.py:65 2019-01-17 04:42:51.310449: step 12442, loss = 0.52959 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:42:52.598663 ops/training.py:65 2019-01-17 04:42:52.598583: step 12443, loss = 0.59446 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:42:53.887966 ops/training.py:65 2019-01-17 04:42:53.887870: step 12444, loss = 0.63694 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:42:55.178001 ops/training.py:65 2019-01-17 04:42:55.177916: step 12445, loss = 0.62637 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:42:56.467682 ops/training.py:65 2019-01-17 04:42:56.467604: step 12446, loss = 0.55446 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:42:57.756164 ops/training.py:65 2019-01-17 04:42:57.756097: step 12447, loss = 0.49786 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:42:59.045555 ops/training.py:65 2019-01-17 04:42:59.045491: step 12448, loss = 0.52702 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:43:00.333520 ops/training.py:65 2019-01-17 04:43:00.333425: step 12449, loss = 0.42991 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 04:43:01.622086 ops/training.py:65 2019-01-17 04:43:01.621994: step 12450, loss = 0.57993 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:43:02.911425 ops/training.py:65 2019-01-17 04:43:02.911339: step 12451, loss = 0.68106 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:43:04.201806 ops/training.py:65 2019-01-17 04:43:04.201732: step 12452, loss = 0.48898 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:43:05.489933 ops/training.py:65 2019-01-17 04:43:05.489860: step 12453, loss = 0.62221 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:43:06.773815 ops/training.py:65 2019-01-17 04:43:06.773739: step 12454, loss = 0.73469 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:43:08.058510 ops/training.py:65 2019-01-17 04:43:08.058426: step 12455, loss = 0.57731 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:43:09.347270 ops/training.py:65 2019-01-17 04:43:09.347201: step 12456, loss = 0.71048 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:43:10.634323 ops/training.py:65 2019-01-17 04:43:10.634252: step 12457, loss = 0.52519 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:43:11.925354 ops/training.py:65 2019-01-17 04:43:11.925274: step 12458, loss = 0.51979 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:43:13.215146 ops/training.py:65 2019-01-17 04:43:13.215075: step 12459, loss = 0.56776 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:43:14.504779 ops/training.py:65 2019-01-17 04:43:14.504706: step 12460, loss = 0.63872 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:43:15.789098 ops/training.py:65 2019-01-17 04:43:15.789031: step 12461, loss = 0.64981 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:43:17.073483 ops/training.py:65 2019-01-17 04:43:17.073413: step 12462, loss = 0.57027 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:43:18.355946 ops/training.py:65 2019-01-17 04:43:18.355838: step 12463, loss = 0.55012 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:43:19.647720 ops/training.py:65 2019-01-17 04:43:19.647611: step 12464, loss = 0.60667 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:43:20.940001 ops/training.py:65 2019-01-17 04:43:20.939900: step 12465, loss = 0.58060 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:43:22.229041 ops/training.py:65 2019-01-17 04:43:22.228972: step 12466, loss = 0.54450 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:43:23.516840 ops/training.py:65 2019-01-17 04:43:23.516733: step 12467, loss = 0.54668 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:43:24.806650 ops/training.py:65 2019-01-17 04:43:24.806579: step 12468, loss = 0.58538 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:43:26.094425 ops/training.py:65 2019-01-17 04:43:26.094354: step 12469, loss = 0.53605 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:43:27.379042 ops/training.py:65 2019-01-17 04:43:27.378971: step 12470, loss = 0.61827 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:43:28.662634 ops/training.py:65 2019-01-17 04:43:28.662560: step 12471, loss = 0.47439 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:43:29.948816 ops/training.py:65 2019-01-17 04:43:29.948717: step 12472, loss = 0.55714 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:43:31.239133 ops/training.py:65 2019-01-17 04:43:31.239069: step 12473, loss = 0.63130 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:43:32.528977 ops/training.py:65 2019-01-17 04:43:32.528902: step 12474, loss = 0.52229 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:43:33.819228 ops/training.py:65 2019-01-17 04:43:33.819153: step 12475, loss = 0.54009 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:43:35.108308 ops/training.py:65 2019-01-17 04:43:35.108237: step 12476, loss = 0.61115 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:43:36.396075 ops/training.py:65 2019-01-17 04:43:36.396000: step 12477, loss = 0.59761 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:43:37.684119 ops/training.py:65 2019-01-17 04:43:37.684052: step 12478, loss = 0.58013 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:43:38.968180 ops/training.py:65 2019-01-17 04:43:38.968111: step 12479, loss = 0.62960 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:43:40.257908 ops/training.py:65 2019-01-17 04:43:40.257797: step 12480, loss = 0.56628 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:43:41.546751 ops/training.py:65 2019-01-17 04:43:41.546678: step 12481, loss = 0.53048 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:43:42.830819 ops/training.py:65 2019-01-17 04:43:42.830757: step 12482, loss = 0.60977 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:43:44.120019 ops/training.py:65 2019-01-17 04:43:44.119915: step 12483, loss = 0.59280 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:43:45.407636 ops/training.py:65 2019-01-17 04:43:45.407563: step 12484, loss = 0.56180 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:43:46.692047 ops/training.py:65 2019-01-17 04:43:46.691984: step 12485, loss = 0.59600 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:43:47.979339 ops/training.py:65 2019-01-17 04:43:47.979273: step 12486, loss = 0.52672 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:43:49.267334 ops/training.py:65 2019-01-17 04:43:49.267257: step 12487, loss = 0.56474 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:43:50.556927 ops/training.py:65 2019-01-17 04:43:50.556840: step 12488, loss = 0.58934 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:43:51.845951 ops/training.py:65 2019-01-17 04:43:51.845854: step 12489, loss = 0.52578 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:43:53.135367 ops/training.py:65 2019-01-17 04:43:53.135263: step 12490, loss = 0.52843 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:43:54.426032 ops/training.py:65 2019-01-17 04:43:54.425930: step 12491, loss = 0.74048 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:43:55.715896 ops/training.py:65 2019-01-17 04:43:55.715826: step 12492, loss = 0.44303 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 04:43:57.004452 ops/training.py:65 2019-01-17 04:43:57.004382: step 12493, loss = 0.62100 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:43:58.293226 ops/training.py:65 2019-01-17 04:43:58.293151: step 12494, loss = 0.55148 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:43:59.582750 ops/training.py:65 2019-01-17 04:43:59.582673: step 12495, loss = 0.59324 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:44:00.870635 ops/training.py:65 2019-01-17 04:44:00.870546: step 12496, loss = 0.61747 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:44:02.160466 ops/training.py:65 2019-01-17 04:44:02.160392: step 12497, loss = 0.57719 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:44:03.449228 ops/training.py:65 2019-01-17 04:44:03.449137: step 12498, loss = 0.65871 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:44:04.738099 ops/training.py:65 2019-01-17 04:44:04.738034: step 12499, loss = 0.54451 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:44:06.027319 ops/training.py:65 2019-01-17 04:44:06.027241: step 12500, loss = 0.57928 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:44:07.315178 ops/training.py:65 2019-01-17 04:44:07.315098: step 12501, loss = 0.49591 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:44:08.605344 ops/training.py:65 2019-01-17 04:44:08.605271: step 12502, loss = 0.42516 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:44:09.895598 ops/training.py:65 2019-01-17 04:44:09.895490: step 12503, loss = 0.59894 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:44:11.186266 ops/training.py:65 2019-01-17 04:44:11.186171: step 12504, loss = 0.67660 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:44:12.474532 ops/training.py:65 2019-01-17 04:44:12.474459: step 12505, loss = 0.59034 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:44:13.769825 ops/training.py:65 2019-01-17 04:44:13.769746: step 12506, loss = 0.73555 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:44:15.059412 ops/training.py:65 2019-01-17 04:44:15.059341: step 12507, loss = 0.49179 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:44:16.348151 ops/training.py:65 2019-01-17 04:44:16.348054: step 12508, loss = 0.60103 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:44:17.637809 ops/training.py:65 2019-01-17 04:44:17.637740: step 12509, loss = 0.52828 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:44:18.925208 ops/training.py:65 2019-01-17 04:44:18.925128: step 12510, loss = 0.54381 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:44:20.214845 ops/training.py:65 2019-01-17 04:44:20.214772: step 12511, loss = 0.57589 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:44:21.500105 ops/training.py:65 2019-01-17 04:44:21.500025: step 12512, loss = 0.41920 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:44:22.785948 ops/training.py:65 2019-01-17 04:44:22.785867: step 12513, loss = 0.61248 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:44:24.074338 ops/training.py:65 2019-01-17 04:44:24.074260: step 12514, loss = 0.64700 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:44:25.364359 ops/training.py:65 2019-01-17 04:44:25.364280: step 12515, loss = 0.55125 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:44:26.653588 ops/training.py:65 2019-01-17 04:44:26.653515: step 12516, loss = 0.57922 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:44:27.943592 ops/training.py:65 2019-01-17 04:44:27.943518: step 12517, loss = 0.58948 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:44:29.234713 ops/training.py:65 2019-01-17 04:44:29.234633: step 12518, loss = 0.66877 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:44:30.523213 ops/training.py:65 2019-01-17 04:44:30.523127: step 12519, loss = 0.69867 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:44:31.813129 ops/training.py:65 2019-01-17 04:44:31.813053: step 12520, loss = 0.64653 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:44:33.100241 ops/training.py:65 2019-01-17 04:44:33.100165: step 12521, loss = 0.60782 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:44:34.389330 ops/training.py:65 2019-01-17 04:44:34.389254: step 12522, loss = 0.74115 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:44:35.676772 ops/training.py:65 2019-01-17 04:44:35.676689: step 12523, loss = 0.65580 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:44:36.965335 ops/training.py:65 2019-01-17 04:44:36.965242: step 12524, loss = 0.54300 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:44:38.254414 ops/training.py:65 2019-01-17 04:44:38.254331: step 12525, loss = 0.56740 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:44:39.543795 ops/training.py:65 2019-01-17 04:44:39.543720: step 12526, loss = 0.50309 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:44:40.830106 ops/training.py:65 2019-01-17 04:44:40.830039: step 12527, loss = 0.53389 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:44:42.113755 ops/training.py:65 2019-01-17 04:44:42.113684: step 12528, loss = 0.57845 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:44:43.405649 ops/training.py:65 2019-01-17 04:44:43.405506: step 12529, loss = 0.57150 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:44:44.692558 ops/training.py:65 2019-01-17 04:44:44.692485: step 12530, loss = 0.54203 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:44:45.975121 ops/training.py:65 2019-01-17 04:44:45.975015: step 12531, loss = 0.55461 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:44:47.266059 ops/training.py:65 2019-01-17 04:44:47.265953: step 12532, loss = 0.40260 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 04:44:48.552902 ops/training.py:65 2019-01-17 04:44:48.552837: step 12533, loss = 0.52187 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:44:49.842830 ops/training.py:65 2019-01-17 04:44:49.842719: step 12534, loss = 0.59326 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:44:51.134761 ops/training.py:65 2019-01-17 04:44:51.134695: step 12535, loss = 0.67829 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:44:52.423259 ops/training.py:65 2019-01-17 04:44:52.423179: step 12536, loss = 0.55852 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:44:53.707258 ops/training.py:65 2019-01-17 04:44:53.707198: step 12537, loss = 0.61489 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:44:54.993557 ops/training.py:65 2019-01-17 04:44:54.993463: step 12538, loss = 0.62764 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:44:56.276934 ops/training.py:65 2019-01-17 04:44:56.276833: step 12539, loss = 0.62248 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:44:57.568153 ops/training.py:65 2019-01-17 04:44:57.568052: step 12540, loss = 0.59411 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:44:58.852029 ops/training.py:65 2019-01-17 04:44:58.851947: step 12541, loss = 0.55090 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:45:00.144811 ops/training.py:65 2019-01-17 04:45:00.144700: step 12542, loss = 0.57531 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:45:01.433524 ops/training.py:65 2019-01-17 04:45:01.433448: step 12543, loss = 0.52632 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:45:02.722174 ops/training.py:65 2019-01-17 04:45:02.722094: step 12544, loss = 0.48916 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:45:04.010764 ops/training.py:65 2019-01-17 04:45:04.010691: step 12545, loss = 0.57096 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:45:05.301297 ops/training.py:65 2019-01-17 04:45:05.301229: step 12546, loss = 0.59543 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:45:06.590303 ops/training.py:65 2019-01-17 04:45:06.590213: step 12547, loss = 0.51915 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:45:07.878422 ops/training.py:65 2019-01-17 04:45:07.878348: step 12548, loss = 0.53136 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:45:09.166965 ops/training.py:65 2019-01-17 04:45:09.166870: step 12549, loss = 0.63683 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:45:10.455824 ops/training.py:65 2019-01-17 04:45:10.455743: step 12550, loss = 0.50912 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:45:11.744067 ops/training.py:65 2019-01-17 04:45:11.743998: step 12551, loss = 0.52414 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:45:13.032623 ops/training.py:65 2019-01-17 04:45:13.032551: step 12552, loss = 0.62350 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:45:14.321389 ops/training.py:65 2019-01-17 04:45:14.321287: step 12553, loss = 0.69625 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:45:15.611375 ops/training.py:65 2019-01-17 04:45:15.611299: step 12554, loss = 0.50636 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:45:16.896787 ops/training.py:65 2019-01-17 04:45:16.896712: step 12555, loss = 0.52977 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:45:18.184243 ops/training.py:65 2019-01-17 04:45:18.184170: step 12556, loss = 0.56244 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:45:19.473113 ops/training.py:65 2019-01-17 04:45:19.473044: step 12557, loss = 0.51400 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:45:20.760917 ops/training.py:65 2019-01-17 04:45:20.760848: step 12558, loss = 0.40449 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 04:45:22.046076 ops/training.py:65 2019-01-17 04:45:22.045999: step 12559, loss = 0.55176 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:45:23.329800 ops/training.py:65 2019-01-17 04:45:23.329727: step 12560, loss = 0.55959 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:45:24.613309 ops/training.py:65 2019-01-17 04:45:24.613215: step 12561, loss = 0.72331 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:45:25.901496 ops/training.py:65 2019-01-17 04:45:25.901397: step 12562, loss = 0.60926 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:45:27.185471 ops/training.py:65 2019-01-17 04:45:27.185362: step 12563, loss = 0.48919 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:45:28.474791 ops/training.py:65 2019-01-17 04:45:28.474639: step 12564, loss = 0.56188 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:45:29.766316 ops/training.py:65 2019-01-17 04:45:29.766216: step 12565, loss = 0.65211 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:45:31.055860 ops/training.py:65 2019-01-17 04:45:31.055793: step 12566, loss = 0.61336 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:45:32.340795 ops/training.py:65 2019-01-17 04:45:32.340732: step 12567, loss = 0.62308 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:45:33.630953 ops/training.py:65 2019-01-17 04:45:33.630878: step 12568, loss = 0.62685 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:45:34.919621 ops/training.py:65 2019-01-17 04:45:34.919531: step 12569, loss = 0.53792 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:45:36.208397 ops/training.py:65 2019-01-17 04:45:36.208312: step 12570, loss = 0.55876 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:45:37.494505 ops/training.py:65 2019-01-17 04:45:37.494419: step 12571, loss = 0.55925 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:45:38.783603 ops/training.py:65 2019-01-17 04:45:38.783525: step 12572, loss = 0.50730 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:45:40.069163 ops/training.py:65 2019-01-17 04:45:40.069069: step 12573, loss = 0.55438 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:45:41.354387 ops/training.py:65 2019-01-17 04:45:41.354317: step 12574, loss = 0.53306 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:45:42.638646 ops/training.py:65 2019-01-17 04:45:42.638579: step 12575, loss = 0.58985 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:45:43.921680 ops/training.py:65 2019-01-17 04:45:43.921594: step 12576, loss = 0.80282 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 04:45:45.214353 ops/training.py:65 2019-01-17 04:45:45.214246: step 12577, loss = 0.52388 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:45:46.500895 ops/training.py:65 2019-01-17 04:45:46.500829: step 12578, loss = 0.60957 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:45:47.790038 ops/training.py:65 2019-01-17 04:45:47.789917: step 12579, loss = 0.56890 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:45:49.080796 ops/training.py:65 2019-01-17 04:45:49.080730: step 12580, loss = 0.45806 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:45:50.369449 ops/training.py:65 2019-01-17 04:45:50.369375: step 12581, loss = 0.52658 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:45:51.655544 ops/training.py:65 2019-01-17 04:45:51.655467: step 12582, loss = 0.58258 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:45:52.943867 ops/training.py:65 2019-01-17 04:45:52.943799: step 12583, loss = 0.64955 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:45:54.233014 ops/training.py:65 2019-01-17 04:45:54.232915: step 12584, loss = 0.63590 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:45:55.521531 ops/training.py:65 2019-01-17 04:45:55.521464: step 12585, loss = 0.59815 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:45:56.805788 ops/training.py:65 2019-01-17 04:45:56.805725: step 12586, loss = 0.69999 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:45:58.095323 ops/training.py:65 2019-01-17 04:45:58.095266: step 12587, loss = 0.57008 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:45:59.383681 ops/training.py:65 2019-01-17 04:45:59.383595: step 12588, loss = 0.61532 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:46:00.673352 ops/training.py:65 2019-01-17 04:46:00.673272: step 12589, loss = 0.47661 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:46:01.957597 ops/training.py:65 2019-01-17 04:46:01.957537: step 12590, loss = 0.60142 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:46:03.247396 ops/training.py:65 2019-01-17 04:46:03.247307: step 12591, loss = 0.56472 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:46:04.532341 ops/training.py:65 2019-01-17 04:46:04.532270: step 12592, loss = 0.50736 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:46:05.815078 ops/training.py:65 2019-01-17 04:46:05.814969: step 12593, loss = 0.74645 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:46:07.105729 ops/training.py:65 2019-01-17 04:46:07.105627: step 12594, loss = 0.52576 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:46:08.392302 ops/training.py:65 2019-01-17 04:46:08.392217: step 12595, loss = 0.55583 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:46:09.682615 ops/training.py:65 2019-01-17 04:46:09.682483: step 12596, loss = 0.52985 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:46:10.972110 ops/training.py:65 2019-01-17 04:46:10.972034: step 12597, loss = 0.58922 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:46:12.260447 ops/training.py:65 2019-01-17 04:46:12.260380: step 12598, loss = 0.62886 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:46:13.549516 ops/training.py:65 2019-01-17 04:46:13.549446: step 12599, loss = 0.67186 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:46:14.838678 ops/training.py:65 2019-01-17 04:46:14.838614: step 12600, loss = 0.59935 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:46:16.123775 ops/training.py:65 2019-01-17 04:46:16.123702: step 12601, loss = 0.71692 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:46:17.407274 ops/training.py:65 2019-01-17 04:46:17.407196: step 12602, loss = 0.56217 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:46:18.700101 ops/training.py:65 2019-01-17 04:46:18.699988: step 12603, loss = 0.55327 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:46:19.991913 ops/training.py:65 2019-01-17 04:46:19.991845: step 12604, loss = 0.62335 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:46:21.281061 ops/training.py:65 2019-01-17 04:46:21.280993: step 12605, loss = 0.74901 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:46:22.570440 ops/training.py:65 2019-01-17 04:46:22.570367: step 12606, loss = 0.52991 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:46:23.859297 ops/training.py:65 2019-01-17 04:46:23.859224: step 12607, loss = 0.62620 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:46:25.149270 ops/training.py:65 2019-01-17 04:46:25.149193: step 12608, loss = 0.59366 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:46:26.439553 ops/training.py:65 2019-01-17 04:46:26.439459: step 12609, loss = 0.55466 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:46:27.728549 ops/training.py:65 2019-01-17 04:46:27.728481: step 12610, loss = 0.62704 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:46:29.016293 ops/training.py:65 2019-01-17 04:46:29.016227: step 12611, loss = 0.63221 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:46:30.306601 ops/training.py:65 2019-01-17 04:46:30.306525: step 12612, loss = 0.56278 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:46:31.591662 ops/training.py:65 2019-01-17 04:46:31.591595: step 12613, loss = 0.67519 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:46:32.876905 ops/training.py:65 2019-01-17 04:46:32.876794: step 12614, loss = 0.63009 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:46:34.161194 ops/training.py:65 2019-01-17 04:46:34.161090: step 12615, loss = 0.46654 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:46:35.453698 ops/training.py:65 2019-01-17 04:46:35.453600: step 12616, loss = 0.52996 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:46:36.744427 ops/training.py:65 2019-01-17 04:46:36.744359: step 12617, loss = 0.58946 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:46:38.032919 ops/training.py:65 2019-01-17 04:46:38.032842: step 12618, loss = 0.64982 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:46:39.319579 ops/training.py:65 2019-01-17 04:46:39.319502: step 12619, loss = 0.56347 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:46:40.602291 ops/training.py:65 2019-01-17 04:46:40.602205: step 12620, loss = 0.51586 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:46:41.897053 ops/training.py:65 2019-01-17 04:46:41.896944: step 12621, loss = 0.65661 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:46:43.182375 ops/training.py:65 2019-01-17 04:46:43.182276: step 12622, loss = 0.60907 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:46:44.461249 ops/training.py:65 2019-01-17 04:46:44.461089: step 12623, loss = 0.54920 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:46:45.753116 ops/training.py:65 2019-01-17 04:46:45.753020: step 12624, loss = 0.48841 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:46:47.037979 ops/training.py:65 2019-01-17 04:46:47.037828: step 12625, loss = 0.66800 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:46:48.328236 ops/training.py:65 2019-01-17 04:46:48.328129: step 12626, loss = 0.52411 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:46:49.619428 ops/training.py:65 2019-01-17 04:46:49.619318: step 12627, loss = 0.59805 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:46:50.904732 ops/training.py:65 2019-01-17 04:46:50.904640: step 12628, loss = 0.65587 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:46:52.193304 ops/training.py:65 2019-01-17 04:46:52.193200: step 12629, loss = 0.67332 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:46:53.482267 ops/training.py:65 2019-01-17 04:46:53.482191: step 12630, loss = 0.55411 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:46:54.771365 ops/training.py:65 2019-01-17 04:46:54.771273: step 12631, loss = 0.59174 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:46:56.061851 ops/training.py:65 2019-01-17 04:46:56.061774: step 12632, loss = 0.46827 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:46:57.350083 ops/training.py:65 2019-01-17 04:46:57.350017: step 12633, loss = 0.55560 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:46:58.638503 ops/training.py:65 2019-01-17 04:46:58.638439: step 12634, loss = 0.52804 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:46:59.928888 ops/training.py:65 2019-01-17 04:46:59.928804: step 12635, loss = 0.55582 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:47:01.216748 ops/training.py:65 2019-01-17 04:47:01.216674: step 12636, loss = 0.62292 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:47:02.504574 ops/training.py:65 2019-01-17 04:47:02.504507: step 12637, loss = 0.63618 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:47:03.793073 ops/training.py:65 2019-01-17 04:47:03.792997: step 12638, loss = 0.52495 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:47:05.082063 ops/training.py:65 2019-01-17 04:47:05.081962: step 12639, loss = 0.67076 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:47:06.369768 ops/training.py:65 2019-01-17 04:47:06.369615: step 12640, loss = 0.44591 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 04:47:07.658754 ops/training.py:65 2019-01-17 04:47:07.658662: step 12641, loss = 0.53748 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:47:08.946532 ops/training.py:65 2019-01-17 04:47:08.946421: step 12642, loss = 0.52532 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:47:10.236989 ops/training.py:65 2019-01-17 04:47:10.236875: step 12643, loss = 0.49906 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:47:11.526225 ops/training.py:65 2019-01-17 04:47:11.526100: step 12644, loss = 0.62738 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:47:12.815771 ops/training.py:65 2019-01-17 04:47:12.815672: step 12645, loss = 0.63613 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:47:14.112855 ops/training.py:65 2019-01-17 04:47:14.112778: step 12646, loss = 0.56949 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:47:15.402429 ops/training.py:65 2019-01-17 04:47:15.402348: step 12647, loss = 0.67755 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:47:16.691012 ops/training.py:65 2019-01-17 04:47:16.690937: step 12648, loss = 0.67333 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:47:17.980926 ops/training.py:65 2019-01-17 04:47:17.980845: step 12649, loss = 0.55038 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:47:19.270807 ops/training.py:65 2019-01-17 04:47:19.270726: step 12650, loss = 0.59243 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:47:20.553012 ops/training.py:65 2019-01-17 04:47:20.552945: step 12651, loss = 0.52625 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:47:21.836608 ops/training.py:65 2019-01-17 04:47:21.836496: step 12652, loss = 0.53501 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:47:23.129140 ops/training.py:65 2019-01-17 04:47:23.129038: step 12653, loss = 0.52781 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:47:24.419280 ops/training.py:65 2019-01-17 04:47:24.419206: step 12654, loss = 0.64979 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:47:25.704333 ops/training.py:65 2019-01-17 04:47:25.704268: step 12655, loss = 0.63369 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:47:26.989199 ops/training.py:65 2019-01-17 04:47:26.989118: step 12656, loss = 0.50113 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:47:28.280576 ops/training.py:65 2019-01-17 04:47:28.280467: step 12657, loss = 0.65524 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:47:29.563337 ops/training.py:65 2019-01-17 04:47:29.563265: step 12658, loss = 0.69561 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:47:30.852511 ops/training.py:65 2019-01-17 04:47:30.852398: step 12659, loss = 0.75173 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:47:32.143364 ops/training.py:65 2019-01-17 04:47:32.143269: step 12660, loss = 0.56969 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:47:33.429932 ops/training.py:65 2019-01-17 04:47:33.429841: step 12661, loss = 0.65674 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:47:34.718824 ops/training.py:65 2019-01-17 04:47:34.718755: step 12662, loss = 0.77732 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:47:36.006476 ops/training.py:65 2019-01-17 04:47:36.006408: step 12663, loss = 0.69926 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:47:37.295354 ops/training.py:65 2019-01-17 04:47:37.295274: step 12664, loss = 0.61871 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:47:38.579011 ops/training.py:65 2019-01-17 04:47:38.578942: step 12665, loss = 0.60869 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:47:39.863775 ops/training.py:65 2019-01-17 04:47:39.863654: step 12666, loss = 0.72287 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:47:41.152207 ops/training.py:65 2019-01-17 04:47:41.152095: step 12667, loss = 0.52602 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:47:42.440088 ops/training.py:65 2019-01-17 04:47:42.439984: step 12668, loss = 0.46137 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:47:43.732240 ops/training.py:65 2019-01-17 04:47:43.732096: step 12669, loss = 0.63440 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:47:45.019471 ops/training.py:65 2019-01-17 04:47:45.019395: step 12670, loss = 0.59969 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:47:46.305053 ops/training.py:65 2019-01-17 04:47:46.304944: step 12671, loss = 0.53290 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:47:47.603249 ops/training.py:65 2019-01-17 04:47:47.603146: step 12672, loss = 0.63648 (24.7 examples/sec; 1.297 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:47:48.894545 ops/training.py:65 2019-01-17 04:47:48.894470: step 12673, loss = 0.58934 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:47:50.179557 ops/training.py:65 2019-01-17 04:47:50.179485: step 12674, loss = 0.62622 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:47:51.467888 ops/training.py:65 2019-01-17 04:47:51.467784: step 12675, loss = 0.56684 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:47:52.753004 ops/training.py:65 2019-01-17 04:47:52.752927: step 12676, loss = 0.54044 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:47:54.039224 ops/training.py:65 2019-01-17 04:47:54.039124: step 12677, loss = 0.46079 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:47:55.330470 ops/training.py:65 2019-01-17 04:47:55.330372: step 12678, loss = 0.52842 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:47:56.622050 ops/training.py:65 2019-01-17 04:47:56.621978: step 12679, loss = 0.63803 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:47:57.906842 ops/training.py:65 2019-01-17 04:47:57.906749: step 12680, loss = 0.50233 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:47:59.197857 ops/training.py:65 2019-01-17 04:47:59.197748: step 12681, loss = 0.72738 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:48:00.487726 ops/training.py:65 2019-01-17 04:48:00.487645: step 12682, loss = 0.55336 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:48:01.772075 ops/training.py:65 2019-01-17 04:48:01.772006: step 12683, loss = 0.52384 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:48:03.060022 ops/training.py:65 2019-01-17 04:48:03.059945: step 12684, loss = 0.58891 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:48:04.347967 ops/training.py:65 2019-01-17 04:48:04.347853: step 12685, loss = 0.53569 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:48:05.638437 ops/training.py:65 2019-01-17 04:48:05.638354: step 12686, loss = 0.47292 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:48:06.927945 ops/training.py:65 2019-01-17 04:48:06.927871: step 12687, loss = 0.60975 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:48:08.215819 ops/training.py:65 2019-01-17 04:48:08.215731: step 12688, loss = 0.62565 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:48:09.503283 ops/training.py:65 2019-01-17 04:48:09.503203: step 12689, loss = 0.46594 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:48:10.791784 ops/training.py:65 2019-01-17 04:48:10.791706: step 12690, loss = 0.69040 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:48:12.080742 ops/training.py:65 2019-01-17 04:48:12.080676: step 12691, loss = 0.49492 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:48:13.368764 ops/training.py:65 2019-01-17 04:48:13.368684: step 12692, loss = 0.65768 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:48:14.656876 ops/training.py:65 2019-01-17 04:48:14.656797: step 12693, loss = 0.63201 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:48:15.947005 ops/training.py:65 2019-01-17 04:48:15.946922: step 12694, loss = 0.64173 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:48:17.235253 ops/training.py:65 2019-01-17 04:48:17.235174: step 12695, loss = 0.45884 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:48:18.519039 ops/training.py:65 2019-01-17 04:48:18.518967: step 12696, loss = 0.67011 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:48:19.808954 ops/training.py:65 2019-01-17 04:48:19.808843: step 12697, loss = 0.50724 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:48:21.098908 ops/training.py:65 2019-01-17 04:48:21.098822: step 12698, loss = 0.56614 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:48:22.388406 ops/training.py:65 2019-01-17 04:48:22.388313: step 12699, loss = 0.69154 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:48:23.673707 ops/training.py:65 2019-01-17 04:48:23.673627: step 12700, loss = 0.54359 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:48:24.962342 ops/training.py:65 2019-01-17 04:48:24.962265: step 12701, loss = 0.52136 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:48:26.246142 ops/training.py:65 2019-01-17 04:48:26.246056: step 12702, loss = 0.59038 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:48:27.537022 ops/training.py:65 2019-01-17 04:48:27.536915: step 12703, loss = 0.60061 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:48:28.826601 ops/training.py:65 2019-01-17 04:48:28.826513: step 12704, loss = 0.62235 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:48:30.111650 ops/training.py:65 2019-01-17 04:48:30.111572: step 12705, loss = 0.64561 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:48:31.399936 ops/training.py:65 2019-01-17 04:48:31.399833: step 12706, loss = 0.70247 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:48:32.687056 ops/training.py:65 2019-01-17 04:48:32.686962: step 12707, loss = 0.65599 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:48:33.972691 ops/training.py:65 2019-01-17 04:48:33.972619: step 12708, loss = 0.51066 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:48:35.258733 ops/training.py:65 2019-01-17 04:48:35.258627: step 12709, loss = 0.66618 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:48:36.547009 ops/training.py:65 2019-01-17 04:48:36.546920: step 12710, loss = 0.51966 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:48:37.836354 ops/training.py:65 2019-01-17 04:48:37.836285: step 12711, loss = 0.42136 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 04:48:39.125978 ops/training.py:65 2019-01-17 04:48:39.125896: step 12712, loss = 0.60281 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:48:40.411244 ops/training.py:65 2019-01-17 04:48:40.411161: step 12713, loss = 0.51378 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:48:41.702684 ops/training.py:65 2019-01-17 04:48:41.702529: step 12714, loss = 0.58675 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:48:42.992734 ops/training.py:65 2019-01-17 04:48:42.992627: step 12715, loss = 0.51349 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:48:44.280503 ops/training.py:65 2019-01-17 04:48:44.280431: step 12716, loss = 0.53587 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:48:45.568940 ops/training.py:65 2019-01-17 04:48:45.568866: step 12717, loss = 0.51524 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:48:46.851868 ops/training.py:65 2019-01-17 04:48:46.851800: step 12718, loss = 0.50049 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:48:48.141321 ops/training.py:65 2019-01-17 04:48:48.141211: step 12719, loss = 0.59023 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:48:49.427178 ops/training.py:65 2019-01-17 04:48:49.427099: step 12720, loss = 0.45625 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:48:50.716342 ops/training.py:65 2019-01-17 04:48:50.716236: step 12721, loss = 0.56333 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:48:52.002886 ops/training.py:65 2019-01-17 04:48:52.002803: step 12722, loss = 0.56859 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:48:53.290841 ops/training.py:65 2019-01-17 04:48:53.290762: step 12723, loss = 0.49303 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:48:54.575076 ops/training.py:65 2019-01-17 04:48:54.575007: step 12724, loss = 0.54630 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:48:55.859507 ops/training.py:65 2019-01-17 04:48:55.859396: step 12725, loss = 0.64845 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:48:57.140013 ops/training.py:65 2019-01-17 04:48:57.139900: step 12726, loss = 0.51964 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:48:58.432575 ops/training.py:65 2019-01-17 04:48:58.432466: step 12727, loss = 0.53465 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:48:59.723553 ops/training.py:65 2019-01-17 04:48:59.723485: step 12728, loss = 0.60401 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:49:01.008321 ops/training.py:65 2019-01-17 04:49:01.008257: step 12729, loss = 0.49950 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:49:02.296368 ops/training.py:65 2019-01-17 04:49:02.296298: step 12730, loss = 0.53318 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:49:03.585841 ops/training.py:65 2019-01-17 04:49:03.585739: step 12731, loss = 0.63425 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:49:04.874973 ops/training.py:65 2019-01-17 04:49:04.874901: step 12732, loss = 0.68830 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:49:06.159393 ops/training.py:65 2019-01-17 04:49:06.159321: step 12733, loss = 0.46450 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:49:07.442720 ops/training.py:65 2019-01-17 04:49:07.442608: step 12734, loss = 0.59323 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:49:08.730024 ops/training.py:65 2019-01-17 04:49:08.729915: step 12735, loss = 0.54657 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:49:10.015919 ops/training.py:65 2019-01-17 04:49:10.015789: step 12736, loss = 0.63638 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:49:11.300641 ops/training.py:65 2019-01-17 04:49:11.300543: step 12737, loss = 0.55162 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:49:12.592840 ops/training.py:65 2019-01-17 04:49:12.592734: step 12738, loss = 0.43202 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 04:49:13.881521 ops/training.py:65 2019-01-17 04:49:13.881440: step 12739, loss = 0.62025 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:49:15.170169 ops/training.py:65 2019-01-17 04:49:15.170088: step 12740, loss = 0.50855 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:49:16.460073 ops/training.py:65 2019-01-17 04:49:16.459946: step 12741, loss = 0.66805 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:49:17.745496 ops/training.py:65 2019-01-17 04:49:17.745411: step 12742, loss = 0.58309 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:49:19.031313 ops/training.py:65 2019-01-17 04:49:19.031172: step 12743, loss = 0.63239 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:49:20.320412 ops/training.py:65 2019-01-17 04:49:20.320318: step 12744, loss = 0.50754 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:49:21.609693 ops/training.py:65 2019-01-17 04:49:21.609623: step 12745, loss = 0.57597 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:49:22.897396 ops/training.py:65 2019-01-17 04:49:22.897322: step 12746, loss = 0.48882 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:49:24.179771 ops/training.py:65 2019-01-17 04:49:24.179671: step 12747, loss = 0.47696 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:49:25.467604 ops/training.py:65 2019-01-17 04:49:25.467509: step 12748, loss = 0.58859 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:49:26.756008 ops/training.py:65 2019-01-17 04:49:26.755930: step 12749, loss = 0.57479 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:49:28.045154 ops/training.py:65 2019-01-17 04:49:28.045077: step 12750, loss = 0.55830 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:49:29.334984 ops/training.py:65 2019-01-17 04:49:29.334915: step 12751, loss = 0.37453 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 04:49:30.619096 ops/training.py:65 2019-01-17 04:49:30.619022: step 12752, loss = 0.61165 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:49:31.906897 ops/training.py:65 2019-01-17 04:49:31.906744: step 12753, loss = 0.58571 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:49:33.192247 ops/training.py:65 2019-01-17 04:49:33.192175: step 12754, loss = 0.67485 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:49:34.475480 ops/training.py:65 2019-01-17 04:49:34.475367: step 12755, loss = 0.53642 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:49:35.767456 ops/training.py:65 2019-01-17 04:49:35.767344: step 12756, loss = 0.50516 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:49:37.057833 ops/training.py:65 2019-01-17 04:49:37.057762: step 12757, loss = 0.51307 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:49:38.345958 ops/training.py:65 2019-01-17 04:49:38.345859: step 12758, loss = 0.53865 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:49:39.634760 ops/training.py:65 2019-01-17 04:49:39.634674: step 12759, loss = 0.56831 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:49:40.924477 ops/training.py:65 2019-01-17 04:49:40.924369: step 12760, loss = 0.59388 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:49:42.209482 ops/training.py:65 2019-01-17 04:49:42.209403: step 12761, loss = 0.67101 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:49:43.493979 ops/training.py:65 2019-01-17 04:49:43.493905: step 12762, loss = 0.65547 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:49:44.776315 ops/training.py:65 2019-01-17 04:49:44.776207: step 12763, loss = 0.50518 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:49:46.059497 ops/training.py:65 2019-01-17 04:49:46.059390: step 12764, loss = 0.53529 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:49:47.351189 ops/training.py:65 2019-01-17 04:49:47.351039: step 12765, loss = 0.58554 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:49:48.637990 ops/training.py:65 2019-01-17 04:49:48.637878: step 12766, loss = 0.67317 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:49:49.917630 ops/training.py:65 2019-01-17 04:49:49.917516: step 12767, loss = 0.63275 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:49:51.200647 ops/training.py:65 2019-01-17 04:49:51.200542: step 12768, loss = 0.56089 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:49:52.490662 ops/training.py:65 2019-01-17 04:49:52.490500: step 12769, loss = 0.56020 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:49:53.780998 ops/training.py:65 2019-01-17 04:49:53.780924: step 12770, loss = 0.52323 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:49:55.066826 ops/training.py:65 2019-01-17 04:49:55.066747: step 12771, loss = 0.57812 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:49:56.354835 ops/training.py:65 2019-01-17 04:49:56.354737: step 12772, loss = 0.56277 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:49:57.642149 ops/training.py:65 2019-01-17 04:49:57.642052: step 12773, loss = 0.65721 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:49:58.932484 ops/training.py:65 2019-01-17 04:49:58.932387: step 12774, loss = 0.49646 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:50:00.218892 ops/training.py:65 2019-01-17 04:50:00.218829: step 12775, loss = 0.54297 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:50:01.503931 ops/training.py:65 2019-01-17 04:50:01.503885: step 12776, loss = 0.51356 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:50:02.783577 ops/training.py:65 2019-01-17 04:50:02.783524: step 12777, loss = 0.62762 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:50:04.074018 ops/training.py:65 2019-01-17 04:50:04.073955: step 12778, loss = 0.53992 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:50:05.358270 ops/training.py:65 2019-01-17 04:50:05.358207: step 12779, loss = 0.59602 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:50:06.638513 ops/training.py:65 2019-01-17 04:50:06.638452: step 12780, loss = 0.52197 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:50:07.927834 ops/training.py:65 2019-01-17 04:50:07.927752: step 12781, loss = 0.52364 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:50:09.217889 ops/training.py:65 2019-01-17 04:50:09.217810: step 12782, loss = 0.53637 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:50:10.498079 ops/training.py:65 2019-01-17 04:50:10.497991: step 12783, loss = 0.63465 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:50:11.789207 ops/training.py:65 2019-01-17 04:50:11.789114: step 12784, loss = 0.61886 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:50:13.073096 ops/training.py:65 2019-01-17 04:50:13.073036: step 12785, loss = 0.56232 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:50:14.356881 ops/training.py:65 2019-01-17 04:50:14.356798: step 12786, loss = 0.52629 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:50:15.643463 ops/training.py:65 2019-01-17 04:50:15.643370: step 12787, loss = 0.50653 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:50:16.934614 ops/training.py:65 2019-01-17 04:50:16.934581: step 12788, loss = 0.59368 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:50:18.223785 ops/training.py:65 2019-01-17 04:50:18.223705: step 12789, loss = 0.60980 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:50:19.512399 ops/training.py:65 2019-01-17 04:50:19.512341: step 12790, loss = 0.59116 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:50:20.798766 ops/training.py:65 2019-01-17 04:50:20.798718: step 12791, loss = 0.46860 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:50:22.087760 ops/training.py:65 2019-01-17 04:50:22.087682: step 12792, loss = 0.64695 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:50:23.374730 ops/training.py:65 2019-01-17 04:50:23.374637: step 12793, loss = 0.53896 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:50:24.662725 ops/training.py:65 2019-01-17 04:50:24.662646: step 12794, loss = 0.48508 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:50:25.942116 ops/training.py:65 2019-01-17 04:50:25.942016: step 12795, loss = 0.65206 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:50:27.226622 ops/training.py:65 2019-01-17 04:50:27.226515: step 12796, loss = 0.58987 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:50:28.519010 ops/training.py:65 2019-01-17 04:50:28.518899: step 12797, loss = 0.55109 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:50:29.808315 ops/training.py:65 2019-01-17 04:50:29.808232: step 12798, loss = 0.57410 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:50:31.090191 ops/training.py:65 2019-01-17 04:50:31.090106: step 12799, loss = 0.46099 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:50:32.379136 ops/training.py:65 2019-01-17 04:50:32.379061: step 12800, loss = 0.65585 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:50:33.665776 ops/training.py:65 2019-01-17 04:50:33.665694: step 12801, loss = 0.67345 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:50:34.951746 ops/training.py:65 2019-01-17 04:50:34.951635: step 12802, loss = 0.53227 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:50:36.242336 ops/training.py:65 2019-01-17 04:50:36.242231: step 12803, loss = 0.59130 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:50:37.533069 ops/training.py:65 2019-01-17 04:50:37.532999: step 12804, loss = 0.50467 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:50:38.817459 ops/training.py:65 2019-01-17 04:50:38.817392: step 12805, loss = 0.55924 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:50:40.103149 ops/training.py:65 2019-01-17 04:50:40.103103: step 12806, loss = 0.67772 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:50:41.388064 ops/training.py:65 2019-01-17 04:50:41.387995: step 12807, loss = 0.45190 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:50:42.678918 ops/training.py:65 2019-01-17 04:50:42.678849: step 12808, loss = 0.54376 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:50:43.968378 ops/training.py:65 2019-01-17 04:50:43.968342: step 12809, loss = 0.49077 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:50:45.256921 ops/training.py:65 2019-01-17 04:50:45.256879: step 12810, loss = 0.72592 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:50:46.545152 ops/training.py:65 2019-01-17 04:50:46.545066: step 12811, loss = 0.52011 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:50:47.828438 ops/training.py:65 2019-01-17 04:50:47.828379: step 12812, loss = 0.58306 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:50:49.117244 ops/training.py:65 2019-01-17 04:50:49.117166: step 12813, loss = 0.59274 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:50:50.406007 ops/training.py:65 2019-01-17 04:50:50.405914: step 12814, loss = 0.51015 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:50:51.690596 ops/training.py:65 2019-01-17 04:50:51.690556: step 12815, loss = 0.55634 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:50:52.974427 ops/training.py:65 2019-01-17 04:50:52.974387: step 12816, loss = 0.57579 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:50:54.260338 ops/training.py:65 2019-01-17 04:50:54.260261: step 12817, loss = 0.57584 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:50:55.542961 ops/training.py:65 2019-01-17 04:50:55.542900: step 12818, loss = 0.59313 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:50:56.835813 ops/training.py:65 2019-01-17 04:50:56.835725: step 12819, loss = 0.48661 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:50:58.120395 ops/training.py:65 2019-01-17 04:50:58.120319: step 12820, loss = 0.66072 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:50:59.409144 ops/training.py:65 2019-01-17 04:50:59.409057: step 12821, loss = 0.56067 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:51:00.697147 ops/training.py:65 2019-01-17 04:51:00.697064: step 12822, loss = 0.52183 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:51:01.986148 ops/training.py:65 2019-01-17 04:51:01.986044: step 12823, loss = 0.49159 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:51:03.276875 ops/training.py:65 2019-01-17 04:51:03.276777: step 12824, loss = 0.50597 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:51:04.567204 ops/training.py:65 2019-01-17 04:51:04.567121: step 12825, loss = 0.45170 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:51:05.850953 ops/training.py:65 2019-01-17 04:51:05.850852: step 12826, loss = 0.52488 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:51:07.136399 ops/training.py:65 2019-01-17 04:51:07.136339: step 12827, loss = 0.55371 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:51:08.415530 ops/training.py:65 2019-01-17 04:51:08.415434: step 12828, loss = 0.57309 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:51:09.707753 ops/training.py:65 2019-01-17 04:51:09.707707: step 12829, loss = 0.50029 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:51:10.989812 ops/training.py:65 2019-01-17 04:51:10.989747: step 12830, loss = 0.57695 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:51:12.280026 ops/training.py:65 2019-01-17 04:51:12.279926: step 12831, loss = 0.55606 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:51:13.564441 ops/training.py:65 2019-01-17 04:51:13.564368: step 12832, loss = 0.52328 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:51:14.847832 ops/training.py:65 2019-01-17 04:51:14.847785: step 12833, loss = 0.54903 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:51:16.133671 ops/training.py:65 2019-01-17 04:51:16.133637: step 12834, loss = 0.58831 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:51:17.413327 ops/training.py:65 2019-01-17 04:51:17.413299: step 12835, loss = 0.49697 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:51:18.697218 ops/training.py:65 2019-01-17 04:51:18.697188: step 12836, loss = 0.47936 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:51:19.983521 ops/training.py:65 2019-01-17 04:51:19.983492: step 12837, loss = 0.58535 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:51:21.268360 ops/training.py:65 2019-01-17 04:51:21.268315: step 12838, loss = 0.61014 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:51:22.552033 ops/training.py:65 2019-01-17 04:51:22.551926: step 12839, loss = 0.44080 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 04:51:23.838917 ops/training.py:65 2019-01-17 04:51:23.838814: step 12840, loss = 0.50701 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:51:25.118363 ops/training.py:65 2019-01-17 04:51:25.118332: step 12841, loss = 0.49834 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:51:26.406272 ops/training.py:65 2019-01-17 04:51:26.406243: step 12842, loss = 0.45918 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:51:27.694259 ops/training.py:65 2019-01-17 04:51:27.694195: step 12843, loss = 0.47422 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:51:28.979342 ops/training.py:65 2019-01-17 04:51:28.979257: step 12844, loss = 0.68214 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:51:30.266586 ops/training.py:65 2019-01-17 04:51:30.266498: step 12845, loss = 0.53120 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:51:31.556300 ops/training.py:65 2019-01-17 04:51:31.556221: step 12846, loss = 0.53744 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:51:32.840341 ops/training.py:65 2019-01-17 04:51:32.840265: step 12847, loss = 0.58242 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:51:34.129130 ops/training.py:65 2019-01-17 04:51:34.129080: step 12848, loss = 0.60485 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:51:35.412657 ops/training.py:65 2019-01-17 04:51:35.412625: step 12849, loss = 0.55608 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:51:36.702443 ops/training.py:65 2019-01-17 04:51:36.702414: step 12850, loss = 0.50602 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:51:37.992960 ops/training.py:65 2019-01-17 04:51:37.992910: step 12851, loss = 0.58952 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:51:39.281777 ops/training.py:65 2019-01-17 04:51:39.281716: step 12852, loss = 0.57077 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:51:40.570314 ops/training.py:65 2019-01-17 04:51:40.570253: step 12853, loss = 0.50046 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:51:41.860017 ops/training.py:65 2019-01-17 04:51:41.859944: step 12854, loss = 0.49931 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:51:43.150014 ops/training.py:65 2019-01-17 04:51:43.149940: step 12855, loss = 0.61383 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:51:44.444853 ops/training.py:65 2019-01-17 04:51:44.444772: step 12856, loss = 0.67954 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:51:45.727909 ops/training.py:65 2019-01-17 04:51:45.727822: step 12857, loss = 0.65706 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:51:47.012091 ops/training.py:65 2019-01-17 04:51:47.011931: step 12858, loss = 0.55375 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:51:48.304733 ops/training.py:65 2019-01-17 04:51:48.304623: step 12859, loss = 0.51592 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:51:49.590787 ops/training.py:65 2019-01-17 04:51:49.590720: step 12860, loss = 0.64082 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:51:50.880766 ops/training.py:65 2019-01-17 04:51:50.880687: step 12861, loss = 0.50623 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:51:52.165977 ops/training.py:65 2019-01-17 04:51:52.165913: step 12862, loss = 0.62396 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:51:53.442669 ops/training.py:65 2019-01-17 04:51:53.442565: step 12863, loss = 0.68159 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:51:54.728879 ops/training.py:65 2019-01-17 04:51:54.728778: step 12864, loss = 0.60656 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:51:56.016400 ops/training.py:65 2019-01-17 04:51:56.016289: step 12865, loss = 0.59250 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:51:57.296180 ops/training.py:65 2019-01-17 04:51:57.296075: step 12866, loss = 0.56182 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:51:58.579360 ops/training.py:65 2019-01-17 04:51:58.579243: step 12867, loss = 0.66362 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:51:59.863885 ops/training.py:65 2019-01-17 04:51:59.863777: step 12868, loss = 0.57806 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:52:01.151835 ops/training.py:65 2019-01-17 04:52:01.151722: step 12869, loss = 0.54963 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:52:02.437968 ops/training.py:65 2019-01-17 04:52:02.437813: step 12870, loss = 0.52481 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:52:03.725025 ops/training.py:65 2019-01-17 04:52:03.724912: step 12871, loss = 0.71198 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:52:05.010826 ops/training.py:65 2019-01-17 04:52:05.010717: step 12872, loss = 0.63854 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:52:06.298498 ops/training.py:65 2019-01-17 04:52:06.298389: step 12873, loss = 0.60051 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:52:07.580008 ops/training.py:65 2019-01-17 04:52:07.579887: step 12874, loss = 0.69242 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:52:08.874045 ops/training.py:65 2019-01-17 04:52:08.873886: step 12875, loss = 0.83172 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 0.46875
I4672 2019-01-17 04:52:10.160396 ops/training.py:65 2019-01-17 04:52:10.160332: step 12876, loss = 0.69748 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:52:11.445479 ops/training.py:65 2019-01-17 04:52:11.445367: step 12877, loss = 0.62471 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:52:12.733488 ops/training.py:65 2019-01-17 04:52:12.733379: step 12878, loss = 0.59073 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:52:14.023588 ops/training.py:65 2019-01-17 04:52:14.023518: step 12879, loss = 0.67788 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:52:15.313151 ops/training.py:65 2019-01-17 04:52:15.313081: step 12880, loss = 0.75025 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:52:16.595155 ops/training.py:65 2019-01-17 04:52:16.595065: step 12881, loss = 0.61000 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:52:17.881034 ops/training.py:65 2019-01-17 04:52:17.880890: step 12882, loss = 0.52824 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:52:19.175095 ops/training.py:65 2019-01-17 04:52:19.174933: step 12883, loss = 0.48316 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:52:20.465991 ops/training.py:65 2019-01-17 04:52:20.465925: step 12884, loss = 0.56661 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:52:21.754885 ops/training.py:65 2019-01-17 04:52:21.754802: step 12885, loss = 0.57167 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:52:23.044121 ops/training.py:65 2019-01-17 04:52:23.044029: step 12886, loss = 0.63287 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:52:24.334395 ops/training.py:65 2019-01-17 04:52:24.334317: step 12887, loss = 0.61254 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:52:25.623207 ops/training.py:65 2019-01-17 04:52:25.623138: step 12888, loss = 0.39675 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:52:26.906989 ops/training.py:65 2019-01-17 04:52:26.906925: step 12889, loss = 0.57174 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:52:28.196294 ops/training.py:65 2019-01-17 04:52:28.196193: step 12890, loss = 0.57997 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:52:29.486919 ops/training.py:65 2019-01-17 04:52:29.486854: step 12891, loss = 0.53130 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:52:30.775926 ops/training.py:65 2019-01-17 04:52:30.775859: step 12892, loss = 0.57158 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:52:32.060681 ops/training.py:65 2019-01-17 04:52:32.060617: step 12893, loss = 0.55622 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:52:33.344187 ops/training.py:65 2019-01-17 04:52:33.344103: step 12894, loss = 0.58190 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:52:34.635150 ops/training.py:65 2019-01-17 04:52:34.635038: step 12895, loss = 0.54755 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:52:35.920839 ops/training.py:65 2019-01-17 04:52:35.920777: step 12896, loss = 0.60053 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:52:37.204849 ops/training.py:65 2019-01-17 04:52:37.204776: step 12897, loss = 0.55503 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:52:38.496325 ops/training.py:65 2019-01-17 04:52:38.496214: step 12898, loss = 0.56776 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:52:39.787072 ops/training.py:65 2019-01-17 04:52:39.787004: step 12899, loss = 0.67546 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:52:41.070735 ops/training.py:65 2019-01-17 04:52:41.070667: step 12900, loss = 0.48178 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:52:42.358685 ops/training.py:65 2019-01-17 04:52:42.358621: step 12901, loss = 0.57225 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:52:43.645792 ops/training.py:65 2019-01-17 04:52:43.645724: step 12902, loss = 0.55089 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:52:44.932329 ops/training.py:65 2019-01-17 04:52:44.932221: step 12903, loss = 0.61589 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:52:46.219852 ops/training.py:65 2019-01-17 04:52:46.219749: step 12904, loss = 0.53511 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:52:47.505593 ops/training.py:65 2019-01-17 04:52:47.505493: step 12905, loss = 0.69208 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:52:48.797053 ops/training.py:65 2019-01-17 04:52:48.796947: step 12906, loss = 0.54681 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:52:50.083712 ops/training.py:65 2019-01-17 04:52:50.083645: step 12907, loss = 0.61185 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:52:51.368585 ops/training.py:65 2019-01-17 04:52:51.368513: step 12908, loss = 0.51299 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:52:52.659967 ops/training.py:65 2019-01-17 04:52:52.659864: step 12909, loss = 0.56229 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:52:53.947122 ops/training.py:65 2019-01-17 04:52:53.947054: step 12910, loss = 0.58628 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:52:55.237424 ops/training.py:65 2019-01-17 04:52:55.237327: step 12911, loss = 0.54737 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:52:56.523141 ops/training.py:65 2019-01-17 04:52:56.523068: step 12912, loss = 0.55945 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:52:57.811913 ops/training.py:65 2019-01-17 04:52:57.811840: step 12913, loss = 0.59873 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:52:59.096024 ops/training.py:65 2019-01-17 04:52:59.095940: step 12914, loss = 0.57084 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:53:00.387182 ops/training.py:65 2019-01-17 04:53:00.387076: step 12915, loss = 0.46433 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 04:53:01.672604 ops/training.py:65 2019-01-17 04:53:01.672538: step 12916, loss = 0.48400 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:53:02.958392 ops/training.py:65 2019-01-17 04:53:02.958320: step 12917, loss = 0.52545 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:53:04.245936 ops/training.py:65 2019-01-17 04:53:04.245793: step 12918, loss = 0.56242 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:53:05.535116 ops/training.py:65 2019-01-17 04:53:05.534974: step 12919, loss = 0.46245 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 04:53:06.821702 ops/training.py:65 2019-01-17 04:53:06.821588: step 12920, loss = 0.58333 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:53:08.107810 ops/training.py:65 2019-01-17 04:53:08.107705: step 12921, loss = 0.52940 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:53:09.400011 ops/training.py:65 2019-01-17 04:53:09.399901: step 12922, loss = 0.52462 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:53:10.685505 ops/training.py:65 2019-01-17 04:53:10.685435: step 12923, loss = 0.49274 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:53:11.970743 ops/training.py:65 2019-01-17 04:53:11.970680: step 12924, loss = 0.49267 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:53:13.255351 ops/training.py:65 2019-01-17 04:53:13.255277: step 12925, loss = 0.58044 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:53:14.533579 ops/training.py:65 2019-01-17 04:53:14.533509: step 12926, loss = 0.53406 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:53:15.818430 ops/training.py:65 2019-01-17 04:53:15.818318: step 12927, loss = 0.47397 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:53:17.105945 ops/training.py:65 2019-01-17 04:53:17.105829: step 12928, loss = 0.64897 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:53:18.396885 ops/training.py:65 2019-01-17 04:53:18.396730: step 12929, loss = 0.50699 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:53:19.685661 ops/training.py:65 2019-01-17 04:53:19.685597: step 12930, loss = 0.56505 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:53:20.966607 ops/training.py:65 2019-01-17 04:53:20.966544: step 12931, loss = 0.63238 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:53:22.250707 ops/training.py:65 2019-01-17 04:53:22.250646: step 12932, loss = 0.59360 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:53:23.539653 ops/training.py:65 2019-01-17 04:53:23.539556: step 12933, loss = 0.49401 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:53:24.825984 ops/training.py:65 2019-01-17 04:53:24.825902: step 12934, loss = 0.61010 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:53:26.112824 ops/training.py:65 2019-01-17 04:53:26.112680: step 12935, loss = 0.54147 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:53:27.405445 ops/training.py:65 2019-01-17 04:53:27.405337: step 12936, loss = 0.57342 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:53:28.696503 ops/training.py:65 2019-01-17 04:53:28.696435: step 12937, loss = 0.51250 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:53:29.986184 ops/training.py:65 2019-01-17 04:53:29.986109: step 12938, loss = 0.62335 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:53:31.275448 ops/training.py:65 2019-01-17 04:53:31.275371: step 12939, loss = 0.62936 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:53:32.565988 ops/training.py:65 2019-01-17 04:53:32.565920: step 12940, loss = 0.74894 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 04:53:33.852879 ops/training.py:65 2019-01-17 04:53:33.852805: step 12941, loss = 0.51027 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:53:35.142569 ops/training.py:65 2019-01-17 04:53:35.142501: step 12942, loss = 0.71732 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:53:36.431986 ops/training.py:65 2019-01-17 04:53:36.431924: step 12943, loss = 0.48924 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:53:37.720988 ops/training.py:65 2019-01-17 04:53:37.720894: step 12944, loss = 0.50014 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:53:39.006015 ops/training.py:65 2019-01-17 04:53:39.005953: step 12945, loss = 0.60394 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:53:40.294933 ops/training.py:65 2019-01-17 04:53:40.294865: step 12946, loss = 0.62414 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:53:41.583501 ops/training.py:65 2019-01-17 04:53:41.583431: step 12947, loss = 0.52415 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:53:42.871789 ops/training.py:65 2019-01-17 04:53:42.871715: step 12948, loss = 0.48521 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:53:44.157345 ops/training.py:65 2019-01-17 04:53:44.157250: step 12949, loss = 0.53328 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:53:45.443472 ops/training.py:65 2019-01-17 04:53:45.443408: step 12950, loss = 0.52525 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:53:46.727366 ops/training.py:65 2019-01-17 04:53:46.727257: step 12951, loss = 0.57372 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:53:48.014735 ops/training.py:65 2019-01-17 04:53:48.014630: step 12952, loss = 0.54511 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:53:49.302213 ops/training.py:65 2019-01-17 04:53:49.302101: step 12953, loss = 0.46268 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:53:50.593219 ops/training.py:65 2019-01-17 04:53:50.593106: step 12954, loss = 0.59844 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:53:51.884691 ops/training.py:65 2019-01-17 04:53:51.884622: step 12955, loss = 0.56576 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:53:53.174023 ops/training.py:65 2019-01-17 04:53:53.173952: step 12956, loss = 0.63537 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:53:54.454350 ops/training.py:65 2019-01-17 04:53:54.454282: step 12957, loss = 0.49416 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:53:55.735705 ops/training.py:65 2019-01-17 04:53:55.735632: step 12958, loss = 0.58044 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:53:57.020027 ops/training.py:65 2019-01-17 04:53:57.019922: step 12959, loss = 0.53223 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:53:58.307409 ops/training.py:65 2019-01-17 04:53:58.307307: step 12960, loss = 0.51437 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:53:59.588856 ops/training.py:65 2019-01-17 04:53:59.588750: step 12961, loss = 0.46057 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:54:00.881420 ops/training.py:65 2019-01-17 04:54:00.881308: step 12962, loss = 0.51777 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:54:02.173988 ops/training.py:65 2019-01-17 04:54:02.173919: step 12963, loss = 0.51078 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:54:03.457835 ops/training.py:65 2019-01-17 04:54:03.457757: step 12964, loss = 0.50865 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:54:04.749309 ops/training.py:65 2019-01-17 04:54:04.749206: step 12965, loss = 0.53169 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:54:06.035765 ops/training.py:65 2019-01-17 04:54:06.035702: step 12966, loss = 0.52223 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:54:07.319156 ops/training.py:65 2019-01-17 04:54:07.319093: step 12967, loss = 0.60745 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:54:08.603904 ops/training.py:65 2019-01-17 04:54:08.603834: step 12968, loss = 0.58005 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:54:09.891179 ops/training.py:65 2019-01-17 04:54:09.891073: step 12969, loss = 0.60385 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:54:11.178339 ops/training.py:65 2019-01-17 04:54:11.178223: step 12970, loss = 0.53947 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:54:12.459988 ops/training.py:65 2019-01-17 04:54:12.459842: step 12971, loss = 0.67282 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:54:13.747145 ops/training.py:65 2019-01-17 04:54:13.747044: step 12972, loss = 0.63090 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:54:15.038165 ops/training.py:65 2019-01-17 04:54:15.038094: step 12973, loss = 0.67855 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:54:16.323235 ops/training.py:65 2019-01-17 04:54:16.323157: step 12974, loss = 0.56829 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:54:17.609645 ops/training.py:65 2019-01-17 04:54:17.609532: step 12975, loss = 0.62965 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:54:18.897533 ops/training.py:65 2019-01-17 04:54:18.897430: step 12976, loss = 0.64277 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:54:20.189044 ops/training.py:65 2019-01-17 04:54:20.188947: step 12977, loss = 0.67935 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:54:21.471165 ops/training.py:65 2019-01-17 04:54:21.471098: step 12978, loss = 0.54102 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:54:22.755298 ops/training.py:65 2019-01-17 04:54:22.755188: step 12979, loss = 0.62625 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:54:24.043016 ops/training.py:65 2019-01-17 04:54:24.042914: step 12980, loss = 0.42055 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:54:25.331112 ops/training.py:65 2019-01-17 04:54:25.330971: step 12981, loss = 0.59622 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:54:26.622406 ops/training.py:65 2019-01-17 04:54:26.622332: step 12982, loss = 0.54181 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:54:27.910780 ops/training.py:65 2019-01-17 04:54:27.910701: step 12983, loss = 0.53032 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:54:29.201056 ops/training.py:65 2019-01-17 04:54:29.200980: step 12984, loss = 0.61653 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:54:30.484954 ops/training.py:65 2019-01-17 04:54:30.484884: step 12985, loss = 0.62241 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:54:31.771868 ops/training.py:65 2019-01-17 04:54:31.771761: step 12986, loss = 0.62798 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:54:33.055759 ops/training.py:65 2019-01-17 04:54:33.055666: step 12987, loss = 0.66982 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:54:34.346509 ops/training.py:65 2019-01-17 04:54:34.346398: step 12988, loss = 0.53212 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:54:35.637757 ops/training.py:65 2019-01-17 04:54:35.637673: step 12989, loss = 0.56752 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:54:36.927800 ops/training.py:65 2019-01-17 04:54:36.927728: step 12990, loss = 0.64700 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:54:38.211081 ops/training.py:65 2019-01-17 04:54:38.211003: step 12991, loss = 0.59311 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:54:39.502185 ops/training.py:65 2019-01-17 04:54:39.502032: step 12992, loss = 0.57744 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:54:40.794070 ops/training.py:65 2019-01-17 04:54:40.793998: step 12993, loss = 0.57156 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:54:42.089294 ops/training.py:65 2019-01-17 04:54:42.089226: step 12994, loss = 0.65523 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:54:43.374779 ops/training.py:65 2019-01-17 04:54:43.374706: step 12995, loss = 0.60848 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:54:44.655538 ops/training.py:65 2019-01-17 04:54:44.655469: step 12996, loss = 0.52016 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:54:45.946663 ops/training.py:65 2019-01-17 04:54:45.946518: step 12997, loss = 0.67318 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:54:47.232923 ops/training.py:65 2019-01-17 04:54:47.232858: step 12998, loss = 0.67926 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:54:48.523426 ops/training.py:65 2019-01-17 04:54:48.523315: step 12999, loss = 0.68005 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:54:49.814822 ops/training.py:65 2019-01-17 04:54:49.814707: step 13000, loss = 0.67732 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:54:51.105183 ops/training.py:65 2019-01-17 04:54:51.105113: step 13001, loss = 0.54635 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:54:52.389002 ops/training.py:65 2019-01-17 04:54:52.388934: step 13002, loss = 0.52831 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:54:53.675702 ops/training.py:65 2019-01-17 04:54:53.675637: step 13003, loss = 0.47977 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:54:54.965354 ops/training.py:65 2019-01-17 04:54:54.965262: step 13004, loss = 0.58731 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:54:56.256216 ops/training.py:65 2019-01-17 04:54:56.256135: step 13005, loss = 0.39840 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 04:54:57.541177 ops/training.py:65 2019-01-17 04:54:57.541113: step 13006, loss = 0.67915 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:54:58.826506 ops/training.py:65 2019-01-17 04:54:58.826396: step 13007, loss = 0.58212 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:55:00.110985 ops/training.py:65 2019-01-17 04:55:00.110931: step 13008, loss = 0.43286 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:55:01.394313 ops/training.py:65 2019-01-17 04:55:01.394243: step 13009, loss = 0.52125 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:55:02.684897 ops/training.py:65 2019-01-17 04:55:02.684785: step 13010, loss = 0.61359 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:55:03.976627 ops/training.py:65 2019-01-17 04:55:03.976531: step 13011, loss = 0.55349 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:55:05.263018 ops/training.py:65 2019-01-17 04:55:05.262952: step 13012, loss = 0.57910 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:55:06.552285 ops/training.py:65 2019-01-17 04:55:06.552127: step 13013, loss = 0.52482 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:55:07.842861 ops/training.py:65 2019-01-17 04:55:07.842788: step 13014, loss = 0.66226 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:55:09.127769 ops/training.py:65 2019-01-17 04:55:09.127675: step 13015, loss = 0.58534 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:55:10.412327 ops/training.py:65 2019-01-17 04:55:10.412237: step 13016, loss = 0.53205 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:55:11.704900 ops/training.py:65 2019-01-17 04:55:11.704751: step 13017, loss = 0.61938 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:55:12.995336 ops/training.py:65 2019-01-17 04:55:12.995263: step 13018, loss = 0.71722 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 04:55:14.284587 ops/training.py:65 2019-01-17 04:55:14.284486: step 13019, loss = 0.55743 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:55:15.568516 ops/training.py:65 2019-01-17 04:55:15.568445: step 13020, loss = 0.62720 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:55:16.854930 ops/training.py:65 2019-01-17 04:55:16.854830: step 13021, loss = 0.65824 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:55:18.138095 ops/training.py:65 2019-01-17 04:55:18.137988: step 13022, loss = 0.46645 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:55:19.430076 ops/training.py:65 2019-01-17 04:55:19.429961: step 13023, loss = 0.57069 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:55:20.711673 ops/training.py:65 2019-01-17 04:55:20.711610: step 13024, loss = 0.46150 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:55:22.000098 ops/training.py:65 2019-01-17 04:55:22.000027: step 13025, loss = 0.67409 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:55:23.288369 ops/training.py:65 2019-01-17 04:55:23.288296: step 13026, loss = 0.61120 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:55:24.576070 ops/training.py:65 2019-01-17 04:55:24.575996: step 13027, loss = 0.71880 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:55:25.864943 ops/training.py:65 2019-01-17 04:55:25.864873: step 13028, loss = 0.54996 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:55:27.150041 ops/training.py:65 2019-01-17 04:55:27.149967: step 13029, loss = 0.46211 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:55:28.433716 ops/training.py:65 2019-01-17 04:55:28.433651: step 13030, loss = 0.56638 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:55:29.713215 ops/training.py:65 2019-01-17 04:55:29.713107: step 13031, loss = 0.63719 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:55:30.998024 ops/training.py:65 2019-01-17 04:55:30.997915: step 13032, loss = 0.55007 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:55:32.286298 ops/training.py:65 2019-01-17 04:55:32.286189: step 13033, loss = 0.50931 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:55:33.578461 ops/training.py:65 2019-01-17 04:55:33.578358: step 13034, loss = 0.63164 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:55:34.866176 ops/training.py:65 2019-01-17 04:55:34.866104: step 13035, loss = 0.62319 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:55:36.150669 ops/training.py:65 2019-01-17 04:55:36.150587: step 13036, loss = 0.59003 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:55:37.439878 ops/training.py:65 2019-01-17 04:55:37.439808: step 13037, loss = 0.66504 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:55:38.719227 ops/training.py:65 2019-01-17 04:55:38.719149: step 13038, loss = 0.47634 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:55:40.000400 ops/training.py:65 2019-01-17 04:55:40.000304: step 13039, loss = 0.56478 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:55:41.283178 ops/training.py:65 2019-01-17 04:55:41.283071: step 13040, loss = 0.49759 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:55:42.565503 ops/training.py:65 2019-01-17 04:55:42.565390: step 13041, loss = 0.56635 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:55:43.856462 ops/training.py:65 2019-01-17 04:55:43.856354: step 13042, loss = 0.48979 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:55:45.147437 ops/training.py:65 2019-01-17 04:55:45.147366: step 13043, loss = 0.55881 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:55:46.437293 ops/training.py:65 2019-01-17 04:55:46.437224: step 13044, loss = 0.57161 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:55:47.727294 ops/training.py:65 2019-01-17 04:55:47.727232: step 13045, loss = 0.55455 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:55:49.012041 ops/training.py:65 2019-01-17 04:55:49.011968: step 13046, loss = 0.48087 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:55:50.302760 ops/training.py:65 2019-01-17 04:55:50.302655: step 13047, loss = 0.62816 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:55:51.593453 ops/training.py:65 2019-01-17 04:55:51.593377: step 13048, loss = 0.58509 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:55:52.881777 ops/training.py:65 2019-01-17 04:55:52.881710: step 13049, loss = 0.54099 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:55:54.166695 ops/training.py:65 2019-01-17 04:55:54.166622: step 13050, loss = 0.48202 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:55:55.451849 ops/training.py:65 2019-01-17 04:55:55.451754: step 13051, loss = 0.64038 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:55:56.743100 ops/training.py:65 2019-01-17 04:55:56.742990: step 13052, loss = 0.45769 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:55:58.030188 ops/training.py:65 2019-01-17 04:55:58.030124: step 13053, loss = 0.42615 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:55:59.312398 ops/training.py:65 2019-01-17 04:55:59.312287: step 13054, loss = 0.47486 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:56:00.603787 ops/training.py:65 2019-01-17 04:56:00.603679: step 13055, loss = 0.49493 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:56:01.890249 ops/training.py:65 2019-01-17 04:56:01.890181: step 13056, loss = 0.55730 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:56:03.178801 ops/training.py:65 2019-01-17 04:56:03.178738: step 13057, loss = 0.50411 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:56:04.468489 ops/training.py:65 2019-01-17 04:56:04.468410: step 13058, loss = 0.55726 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:56:05.751070 ops/training.py:65 2019-01-17 04:56:05.751007: step 13059, loss = 0.68451 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:56:07.040105 ops/training.py:65 2019-01-17 04:56:07.040041: step 13060, loss = 0.36893 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 04:56:08.324961 ops/training.py:65 2019-01-17 04:56:08.324888: step 13061, loss = 0.57800 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:56:09.613724 ops/training.py:65 2019-01-17 04:56:09.613655: step 13062, loss = 0.44424 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 04:56:10.902437 ops/training.py:65 2019-01-17 04:56:10.902374: step 13063, loss = 0.48707 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:56:12.192016 ops/training.py:65 2019-01-17 04:56:12.191943: step 13064, loss = 0.49848 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:56:13.481498 ops/training.py:65 2019-01-17 04:56:13.481423: step 13065, loss = 0.53585 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:56:14.769764 ops/training.py:65 2019-01-17 04:56:14.769678: step 13066, loss = 0.67356 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:56:16.058497 ops/training.py:65 2019-01-17 04:56:16.058412: step 13067, loss = 0.69435 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 04:56:17.342263 ops/training.py:65 2019-01-17 04:56:17.342199: step 13068, loss = 0.51678 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:56:18.628502 ops/training.py:65 2019-01-17 04:56:18.628391: step 13069, loss = 0.51088 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:56:19.925899 ops/training.py:65 2019-01-17 04:56:19.925742: step 13070, loss = 0.62576 (24.7 examples/sec; 1.296 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:56:21.217540 ops/training.py:65 2019-01-17 04:56:21.217467: step 13071, loss = 0.80334 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.4375
I4672 2019-01-17 04:56:22.507028 ops/training.py:65 2019-01-17 04:56:22.506958: step 13072, loss = 0.52637 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:56:23.796071 ops/training.py:65 2019-01-17 04:56:23.795978: step 13073, loss = 0.55826 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:56:25.085519 ops/training.py:65 2019-01-17 04:56:25.085438: step 13074, loss = 0.66920 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:56:26.372433 ops/training.py:65 2019-01-17 04:56:26.372326: step 13075, loss = 0.48143 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:56:27.663238 ops/training.py:65 2019-01-17 04:56:27.663126: step 13076, loss = 0.48912 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:56:28.954149 ops/training.py:65 2019-01-17 04:56:28.954073: step 13077, loss = 0.54523 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:56:30.242125 ops/training.py:65 2019-01-17 04:56:30.242053: step 13078, loss = 0.50227 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:56:31.527737 ops/training.py:65 2019-01-17 04:56:31.527665: step 13079, loss = 0.59486 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:56:32.815289 ops/training.py:65 2019-01-17 04:56:32.815187: step 13080, loss = 0.61565 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:56:34.104104 ops/training.py:65 2019-01-17 04:56:34.104033: step 13081, loss = 0.61750 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:56:35.392042 ops/training.py:65 2019-01-17 04:56:35.391972: step 13082, loss = 0.63446 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:56:36.676039 ops/training.py:65 2019-01-17 04:56:36.675951: step 13083, loss = 0.41767 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 04:56:37.959337 ops/training.py:65 2019-01-17 04:56:37.959262: step 13084, loss = 0.41510 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 04:56:39.250883 ops/training.py:65 2019-01-17 04:56:39.250774: step 13085, loss = 0.59903 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:56:40.541815 ops/training.py:65 2019-01-17 04:56:40.541726: step 13086, loss = 0.61359 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:56:41.831595 ops/training.py:65 2019-01-17 04:56:41.831524: step 13087, loss = 0.45796 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 04:56:43.115059 ops/training.py:65 2019-01-17 04:56:43.114996: step 13088, loss = 0.63639 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:56:44.398219 ops/training.py:65 2019-01-17 04:56:44.398155: step 13089, loss = 0.50160 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:56:45.689865 ops/training.py:65 2019-01-17 04:56:45.689762: step 13090, loss = 0.50415 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:56:46.980494 ops/training.py:65 2019-01-17 04:56:46.980424: step 13091, loss = 0.53343 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:56:48.265725 ops/training.py:65 2019-01-17 04:56:48.265653: step 13092, loss = 0.61300 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:56:49.553794 ops/training.py:65 2019-01-17 04:56:49.553720: step 13093, loss = 0.53092 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:56:50.838486 ops/training.py:65 2019-01-17 04:56:50.838418: step 13094, loss = 0.62283 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:56:52.122192 ops/training.py:65 2019-01-17 04:56:52.122119: step 13095, loss = 0.45025 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:56:53.402824 ops/training.py:65 2019-01-17 04:56:53.402719: step 13096, loss = 0.57761 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:56:54.691816 ops/training.py:65 2019-01-17 04:56:54.691710: step 13097, loss = 0.51231 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 04:56:55.975225 ops/training.py:65 2019-01-17 04:56:55.975154: step 13098, loss = 0.52465 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:56:57.262381 ops/training.py:65 2019-01-17 04:56:57.262272: step 13099, loss = 0.48449 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:56:58.553949 ops/training.py:65 2019-01-17 04:56:58.553845: step 13100, loss = 0.53489 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:56:59.844765 ops/training.py:65 2019-01-17 04:56:59.844700: step 13101, loss = 0.66863 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:57:01.131533 ops/training.py:65 2019-01-17 04:57:01.131467: step 13102, loss = 0.59321 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:57:02.419792 ops/training.py:65 2019-01-17 04:57:02.419731: step 13103, loss = 0.66779 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:57:03.701161 ops/training.py:65 2019-01-17 04:57:03.701087: step 13104, loss = 0.52587 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:57:04.988865 ops/training.py:65 2019-01-17 04:57:04.988763: step 13105, loss = 0.58215 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:57:06.277345 ops/training.py:65 2019-01-17 04:57:06.277280: step 13106, loss = 0.56162 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:57:07.565458 ops/training.py:65 2019-01-17 04:57:07.565362: step 13107, loss = 0.56770 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:57:08.853955 ops/training.py:65 2019-01-17 04:57:08.853882: step 13108, loss = 0.51473 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:57:10.147570 ops/training.py:65 2019-01-17 04:57:10.147478: step 13109, loss = 0.55318 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:57:11.436447 ops/training.py:65 2019-01-17 04:57:11.436358: step 13110, loss = 0.57123 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:57:12.724500 ops/training.py:65 2019-01-17 04:57:12.724435: step 13111, loss = 0.46143 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:57:14.012121 ops/training.py:65 2019-01-17 04:57:14.012056: step 13112, loss = 0.50329 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:57:15.301803 ops/training.py:65 2019-01-17 04:57:15.301728: step 13113, loss = 0.38400 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 04:57:16.590984 ops/training.py:65 2019-01-17 04:57:16.590892: step 13114, loss = 0.47228 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:57:17.877197 ops/training.py:65 2019-01-17 04:57:17.877134: step 13115, loss = 0.48478 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:57:19.162018 ops/training.py:65 2019-01-17 04:57:19.161959: step 13116, loss = 0.47140 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 04:57:20.446743 ops/training.py:65 2019-01-17 04:57:20.446581: step 13117, loss = 0.47744 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:57:21.738184 ops/training.py:65 2019-01-17 04:57:21.738075: step 13118, loss = 0.52385 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:57:23.031676 ops/training.py:65 2019-01-17 04:57:23.031605: step 13119, loss = 0.60037 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:57:24.316932 ops/training.py:65 2019-01-17 04:57:24.316865: step 13120, loss = 0.56884 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:57:25.606558 ops/training.py:65 2019-01-17 04:57:25.606464: step 13121, loss = 0.54900 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:57:26.895582 ops/training.py:65 2019-01-17 04:57:26.895517: step 13122, loss = 0.65368 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 04:57:28.184654 ops/training.py:65 2019-01-17 04:57:28.184585: step 13123, loss = 0.60308 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:57:29.474017 ops/training.py:65 2019-01-17 04:57:29.473941: step 13124, loss = 0.55957 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:57:30.758364 ops/training.py:65 2019-01-17 04:57:30.758304: step 13125, loss = 0.46187 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:57:32.043679 ops/training.py:65 2019-01-17 04:57:32.043610: step 13126, loss = 0.53670 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:57:33.329941 ops/training.py:65 2019-01-17 04:57:33.329867: step 13127, loss = 0.56664 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:57:34.622508 ops/training.py:65 2019-01-17 04:57:34.622398: step 13128, loss = 0.57786 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:57:35.910285 ops/training.py:65 2019-01-17 04:57:35.910217: step 13129, loss = 0.52355 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:57:37.199485 ops/training.py:65 2019-01-17 04:57:37.199414: step 13130, loss = 0.64078 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:57:38.487902 ops/training.py:65 2019-01-17 04:57:38.487841: step 13131, loss = 0.82737 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.40625
I4672 2019-01-17 04:57:39.775081 ops/training.py:65 2019-01-17 04:57:39.774995: step 13132, loss = 0.58934 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:57:41.059861 ops/training.py:65 2019-01-17 04:57:41.059798: step 13133, loss = 0.50650 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:57:42.344235 ops/training.py:65 2019-01-17 04:57:42.344171: step 13134, loss = 0.47327 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:57:43.633026 ops/training.py:65 2019-01-17 04:57:43.632943: step 13135, loss = 0.58370 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:57:44.920666 ops/training.py:65 2019-01-17 04:57:44.920576: step 13136, loss = 0.57095 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:57:46.209720 ops/training.py:65 2019-01-17 04:57:46.209654: step 13137, loss = 0.59700 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:57:47.500038 ops/training.py:65 2019-01-17 04:57:47.499950: step 13138, loss = 0.45931 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 04:57:48.788223 ops/training.py:65 2019-01-17 04:57:48.788133: step 13139, loss = 0.56156 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:57:50.076484 ops/training.py:65 2019-01-17 04:57:50.076418: step 13140, loss = 0.45726 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:57:51.364995 ops/training.py:65 2019-01-17 04:57:51.364923: step 13141, loss = 0.57349 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:57:52.654202 ops/training.py:65 2019-01-17 04:57:52.654131: step 13142, loss = 0.48926 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:57:53.938042 ops/training.py:65 2019-01-17 04:57:53.937970: step 13143, loss = 0.62651 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:57:55.223291 ops/training.py:65 2019-01-17 04:57:55.223221: step 13144, loss = 0.63110 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:57:56.508848 ops/training.py:65 2019-01-17 04:57:56.508742: step 13145, loss = 0.44977 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:57:57.801591 ops/training.py:65 2019-01-17 04:57:57.801485: step 13146, loss = 0.55651 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:57:59.092343 ops/training.py:65 2019-01-17 04:57:59.092248: step 13147, loss = 0.52725 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:58:00.376687 ops/training.py:65 2019-01-17 04:58:00.376615: step 13148, loss = 0.47959 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:58:01.662581 ops/training.py:65 2019-01-17 04:58:01.662511: step 13149, loss = 0.54696 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:58:02.951387 ops/training.py:65 2019-01-17 04:58:02.951292: step 13150, loss = 0.57575 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:58:04.241623 ops/training.py:65 2019-01-17 04:58:04.241549: step 13151, loss = 0.48824 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:58:05.525678 ops/training.py:65 2019-01-17 04:58:05.525611: step 13152, loss = 0.65207 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:58:06.809509 ops/training.py:65 2019-01-17 04:58:06.809437: step 13153, loss = 0.48333 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:58:08.102058 ops/training.py:65 2019-01-17 04:58:08.101955: step 13154, loss = 0.54542 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:58:09.393145 ops/training.py:65 2019-01-17 04:58:09.393073: step 13155, loss = 0.57427 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:58:10.681268 ops/training.py:65 2019-01-17 04:58:10.681195: step 13156, loss = 0.48163 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:58:11.970413 ops/training.py:65 2019-01-17 04:58:11.970338: step 13157, loss = 0.66305 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:58:13.259025 ops/training.py:65 2019-01-17 04:58:13.258953: step 13158, loss = 0.50852 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:58:14.546539 ops/training.py:65 2019-01-17 04:58:14.546471: step 13159, loss = 0.59512 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:58:15.835038 ops/training.py:65 2019-01-17 04:58:15.834961: step 13160, loss = 0.51187 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:58:17.124466 ops/training.py:65 2019-01-17 04:58:17.124395: step 13161, loss = 0.51936 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:58:18.413976 ops/training.py:65 2019-01-17 04:58:18.413888: step 13162, loss = 0.56225 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:58:19.702886 ops/training.py:65 2019-01-17 04:58:19.702813: step 13163, loss = 0.45942 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 04:58:20.991928 ops/training.py:65 2019-01-17 04:58:20.991865: step 13164, loss = 0.55867 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:58:22.279810 ops/training.py:65 2019-01-17 04:58:22.279742: step 13165, loss = 0.46519 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:58:23.569633 ops/training.py:65 2019-01-17 04:58:23.569561: step 13166, loss = 0.53852 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:58:24.855659 ops/training.py:65 2019-01-17 04:58:24.855593: step 13167, loss = 0.66272 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:58:26.136663 ops/training.py:65 2019-01-17 04:58:26.136589: step 13168, loss = 0.50166 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:58:27.428489 ops/training.py:65 2019-01-17 04:58:27.428386: step 13169, loss = 0.57339 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:58:28.718501 ops/training.py:65 2019-01-17 04:58:28.718438: step 13170, loss = 0.61497 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:58:30.001898 ops/training.py:65 2019-01-17 04:58:30.001826: step 13171, loss = 0.60333 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:58:31.291628 ops/training.py:65 2019-01-17 04:58:31.291468: step 13172, loss = 0.71494 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:58:32.583427 ops/training.py:65 2019-01-17 04:58:32.583336: step 13173, loss = 0.58089 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:58:33.872373 ops/training.py:65 2019-01-17 04:58:33.872275: step 13174, loss = 0.55407 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:58:35.163305 ops/training.py:65 2019-01-17 04:58:35.163217: step 13175, loss = 0.62394 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:58:36.452767 ops/training.py:65 2019-01-17 04:58:36.452700: step 13176, loss = 0.61898 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:58:37.738752 ops/training.py:65 2019-01-17 04:58:37.738683: step 13177, loss = 0.53440 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:58:39.028344 ops/training.py:65 2019-01-17 04:58:39.028239: step 13178, loss = 0.57659 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:58:40.318029 ops/training.py:65 2019-01-17 04:58:40.317967: step 13179, loss = 0.54784 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:58:41.605845 ops/training.py:65 2019-01-17 04:58:41.605775: step 13180, loss = 0.51092 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:58:42.893433 ops/training.py:65 2019-01-17 04:58:42.893370: step 13181, loss = 0.67572 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:58:44.180909 ops/training.py:65 2019-01-17 04:58:44.180839: step 13182, loss = 0.55412 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:58:45.465721 ops/training.py:65 2019-01-17 04:58:45.465650: step 13183, loss = 0.55118 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:58:46.753193 ops/training.py:65 2019-01-17 04:58:46.753116: step 13184, loss = 0.53117 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:58:48.043144 ops/training.py:65 2019-01-17 04:58:48.043077: step 13185, loss = 0.52518 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:58:49.332575 ops/training.py:65 2019-01-17 04:58:49.332501: step 13186, loss = 0.52182 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:58:50.620753 ops/training.py:65 2019-01-17 04:58:50.620654: step 13187, loss = 0.56400 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:58:51.911029 ops/training.py:65 2019-01-17 04:58:51.910935: step 13188, loss = 0.62652 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:58:53.200936 ops/training.py:65 2019-01-17 04:58:53.200845: step 13189, loss = 0.53448 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:58:54.489583 ops/training.py:65 2019-01-17 04:58:54.489508: step 13190, loss = 0.44134 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:58:55.774451 ops/training.py:65 2019-01-17 04:58:55.774385: step 13191, loss = 0.54999 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:58:57.062636 ops/training.py:65 2019-01-17 04:58:57.062538: step 13192, loss = 0.59021 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 04:58:58.351340 ops/training.py:65 2019-01-17 04:58:58.351271: step 13193, loss = 0.56465 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:58:59.639899 ops/training.py:65 2019-01-17 04:58:59.639799: step 13194, loss = 0.51708 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:59:00.925433 ops/training.py:65 2019-01-17 04:59:00.925364: step 13195, loss = 0.53756 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:59:02.209254 ops/training.py:65 2019-01-17 04:59:02.209147: step 13196, loss = 0.54725 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:59:03.500505 ops/training.py:65 2019-01-17 04:59:03.500407: step 13197, loss = 0.51942 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:59:04.786861 ops/training.py:65 2019-01-17 04:59:04.786796: step 13198, loss = 0.64180 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:59:06.073265 ops/training.py:65 2019-01-17 04:59:06.073126: step 13199, loss = 0.65682 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:59:07.357001 ops/training.py:65 2019-01-17 04:59:07.356899: step 13200, loss = 0.58159 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:59:08.648877 ops/training.py:65 2019-01-17 04:59:08.648722: step 13201, loss = 0.64781 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:59:09.940594 ops/training.py:65 2019-01-17 04:59:09.940504: step 13202, loss = 0.43658 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 04:59:11.226641 ops/training.py:65 2019-01-17 04:59:11.226546: step 13203, loss = 0.44325 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:59:12.511040 ops/training.py:65 2019-01-17 04:59:12.510932: step 13204, loss = 0.53358 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:59:13.803090 ops/training.py:65 2019-01-17 04:59:13.802954: step 13205, loss = 0.56279 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:59:15.094130 ops/training.py:65 2019-01-17 04:59:15.094067: step 13206, loss = 0.47548 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:59:16.383104 ops/training.py:65 2019-01-17 04:59:16.383032: step 13207, loss = 0.58296 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:59:17.671561 ops/training.py:65 2019-01-17 04:59:17.671498: step 13208, loss = 0.58079 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 04:59:18.960367 ops/training.py:65 2019-01-17 04:59:18.960296: step 13209, loss = 0.49314 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:59:20.249409 ops/training.py:65 2019-01-17 04:59:20.249334: step 13210, loss = 0.48301 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:59:21.538226 ops/training.py:65 2019-01-17 04:59:21.538131: step 13211, loss = 0.46023 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:59:22.827781 ops/training.py:65 2019-01-17 04:59:22.827711: step 13212, loss = 0.60730 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:59:24.112655 ops/training.py:65 2019-01-17 04:59:24.112586: step 13213, loss = 0.53152 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:59:25.402919 ops/training.py:65 2019-01-17 04:59:25.402826: step 13214, loss = 0.46103 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:59:26.687217 ops/training.py:65 2019-01-17 04:59:26.687144: step 13215, loss = 0.46175 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:59:27.966473 ops/training.py:65 2019-01-17 04:59:27.966367: step 13216, loss = 0.51720 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:59:29.259568 ops/training.py:65 2019-01-17 04:59:29.259415: step 13217, loss = 0.52347 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 04:59:30.551178 ops/training.py:65 2019-01-17 04:59:30.551108: step 13218, loss = 0.63419 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:59:31.835197 ops/training.py:65 2019-01-17 04:59:31.835129: step 13219, loss = 0.49058 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:59:33.122735 ops/training.py:65 2019-01-17 04:59:33.122668: step 13220, loss = 0.51153 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 04:59:34.411767 ops/training.py:65 2019-01-17 04:59:34.411708: step 13221, loss = 0.55541 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:59:35.700435 ops/training.py:65 2019-01-17 04:59:35.700369: step 13222, loss = 0.54767 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:59:36.989147 ops/training.py:65 2019-01-17 04:59:36.989074: step 13223, loss = 0.47104 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 04:59:38.278699 ops/training.py:65 2019-01-17 04:59:38.278607: step 13224, loss = 0.55231 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:59:39.564367 ops/training.py:65 2019-01-17 04:59:39.564297: step 13225, loss = 0.52275 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:59:40.849826 ops/training.py:65 2019-01-17 04:59:40.849758: step 13226, loss = 0.50785 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:59:42.137980 ops/training.py:65 2019-01-17 04:59:42.137915: step 13227, loss = 0.56730 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:59:43.424909 ops/training.py:65 2019-01-17 04:59:43.424804: step 13228, loss = 0.40698 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 04:59:44.708643 ops/training.py:65 2019-01-17 04:59:44.708578: step 13229, loss = 0.53766 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 04:59:45.996341 ops/training.py:65 2019-01-17 04:59:45.996245: step 13230, loss = 0.63328 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:59:47.280091 ops/training.py:65 2019-01-17 04:59:47.280007: step 13231, loss = 0.52921 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:59:48.563752 ops/training.py:65 2019-01-17 04:59:48.563693: step 13232, loss = 0.57864 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:59:49.846913 ops/training.py:65 2019-01-17 04:59:49.846839: step 13233, loss = 0.59833 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 04:59:51.137872 ops/training.py:65 2019-01-17 04:59:51.137760: step 13234, loss = 0.47648 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 04:59:52.427954 ops/training.py:65 2019-01-17 04:59:52.427886: step 13235, loss = 0.54241 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 04:59:53.717521 ops/training.py:65 2019-01-17 04:59:53.717451: step 13236, loss = 0.60406 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 04:59:55.007227 ops/training.py:65 2019-01-17 04:59:55.007164: step 13237, loss = 0.58819 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:59:56.296525 ops/training.py:65 2019-01-17 04:59:56.296446: step 13238, loss = 0.63736 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:59:57.580476 ops/training.py:65 2019-01-17 04:59:57.580405: step 13239, loss = 0.61525 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 04:59:58.864373 ops/training.py:65 2019-01-17 04:59:58.864310: step 13240, loss = 0.45757 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:00:00.151291 ops/training.py:65 2019-01-17 05:00:00.151175: step 13241, loss = 0.48105 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:00:01.441432 ops/training.py:65 2019-01-17 05:00:01.441361: step 13242, loss = 0.54942 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:00:02.728389 ops/training.py:65 2019-01-17 05:00:02.728320: step 13243, loss = 0.60167 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 05:00:04.013367 ops/training.py:65 2019-01-17 05:00:04.013297: step 13244, loss = 0.58539 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:00:05.302740 ops/training.py:65 2019-01-17 05:00:05.302640: step 13245, loss = 0.51498 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:00:06.591661 ops/training.py:65 2019-01-17 05:00:06.591592: step 13246, loss = 0.59920 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 05:00:07.876597 ops/training.py:65 2019-01-17 05:00:07.876529: step 13247, loss = 0.54385 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:00:09.159962 ops/training.py:65 2019-01-17 05:00:09.159856: step 13248, loss = 0.62681 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:00:10.452184 ops/training.py:65 2019-01-17 05:00:10.452090: step 13249, loss = 0.55543 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:00:11.742407 ops/training.py:65 2019-01-17 05:00:11.742311: step 13250, loss = 0.41562 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:00:13.031848 ops/training.py:65 2019-01-17 05:00:13.031770: step 13251, loss = 0.51657 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:00:14.316043 ops/training.py:65 2019-01-17 05:00:14.315978: step 13252, loss = 0.48798 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:00:15.605720 ops/training.py:65 2019-01-17 05:00:15.605610: step 13253, loss = 0.42604 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:00:16.891556 ops/training.py:65 2019-01-17 05:00:16.891473: step 13254, loss = 0.58819 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:00:18.186262 ops/training.py:65 2019-01-17 05:00:18.186167: step 13255, loss = 0.50242 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:00:19.474024 ops/training.py:65 2019-01-17 05:00:19.473950: step 13256, loss = 0.55845 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:00:20.762214 ops/training.py:65 2019-01-17 05:00:20.762146: step 13257, loss = 0.60278 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:00:22.049092 ops/training.py:65 2019-01-17 05:00:22.049021: step 13258, loss = 0.60394 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:00:23.336887 ops/training.py:65 2019-01-17 05:00:23.336817: step 13259, loss = 0.49194 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:00:24.624977 ops/training.py:65 2019-01-17 05:00:24.624876: step 13260, loss = 0.54374 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:00:25.914699 ops/training.py:65 2019-01-17 05:00:25.914609: step 13261, loss = 0.52573 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:00:27.200582 ops/training.py:65 2019-01-17 05:00:27.200513: step 13262, loss = 0.51772 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:00:28.488805 ops/training.py:65 2019-01-17 05:00:28.488728: step 13263, loss = 0.60779 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:00:29.775173 ops/training.py:65 2019-01-17 05:00:29.775103: step 13264, loss = 0.62494 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:00:31.062361 ops/training.py:65 2019-01-17 05:00:31.062291: step 13265, loss = 0.45474 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:00:32.352556 ops/training.py:65 2019-01-17 05:00:32.352486: step 13266, loss = 0.42972 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:00:33.641096 ops/training.py:65 2019-01-17 05:00:33.641016: step 13267, loss = 0.67161 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 05:00:34.925490 ops/training.py:65 2019-01-17 05:00:34.925409: step 13268, loss = 0.51664 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:00:36.213328 ops/training.py:65 2019-01-17 05:00:36.213251: step 13269, loss = 0.53624 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:00:37.499080 ops/training.py:65 2019-01-17 05:00:37.498999: step 13270, loss = 0.52561 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:00:38.788570 ops/training.py:65 2019-01-17 05:00:38.788498: step 13271, loss = 0.58574 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:00:40.067737 ops/training.py:65 2019-01-17 05:00:40.067670: step 13272, loss = 0.77943 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:00:41.346879 ops/training.py:65 2019-01-17 05:00:41.346796: step 13273, loss = 0.66963 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:00:42.630676 ops/training.py:65 2019-01-17 05:00:42.630569: step 13274, loss = 0.53456 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:00:43.917564 ops/training.py:65 2019-01-17 05:00:43.917456: step 13275, loss = 0.45316 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:00:45.215210 ops/training.py:65 2019-01-17 05:00:45.215099: step 13276, loss = 0.46340 (24.7 examples/sec; 1.296 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:00:46.501773 ops/training.py:65 2019-01-17 05:00:46.501704: step 13277, loss = 0.44070 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:00:47.789235 ops/training.py:65 2019-01-17 05:00:47.789126: step 13278, loss = 0.69754 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 05:00:49.078329 ops/training.py:65 2019-01-17 05:00:49.078245: step 13279, loss = 0.63988 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:00:50.361348 ops/training.py:65 2019-01-17 05:00:50.361276: step 13280, loss = 0.50184 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:00:51.642142 ops/training.py:65 2019-01-17 05:00:51.642032: step 13281, loss = 0.57258 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:00:52.927940 ops/training.py:65 2019-01-17 05:00:52.927833: step 13282, loss = 0.61753 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:00:54.214412 ops/training.py:65 2019-01-17 05:00:54.214347: step 13283, loss = 0.48915 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:00:55.499924 ops/training.py:65 2019-01-17 05:00:55.499832: step 13284, loss = 0.53729 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:00:56.783391 ops/training.py:65 2019-01-17 05:00:56.783291: step 13285, loss = 0.68813 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 05:00:58.075019 ops/training.py:65 2019-01-17 05:00:58.074864: step 13286, loss = 0.49093 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:00:59.365671 ops/training.py:65 2019-01-17 05:00:59.365599: step 13287, loss = 0.53262 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:01:00.650475 ops/training.py:65 2019-01-17 05:01:00.650410: step 13288, loss = 0.44088 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:01:01.935467 ops/training.py:65 2019-01-17 05:01:01.935388: step 13289, loss = 0.51938 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:01:03.219289 ops/training.py:65 2019-01-17 05:01:03.219206: step 13290, loss = 0.60469 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:01:04.512095 ops/training.py:65 2019-01-17 05:01:04.511983: step 13291, loss = 0.62256 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:01:05.803340 ops/training.py:65 2019-01-17 05:01:05.803266: step 13292, loss = 0.55080 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:01:07.091997 ops/training.py:65 2019-01-17 05:01:07.091923: step 13293, loss = 0.51104 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:01:08.380553 ops/training.py:65 2019-01-17 05:01:08.380474: step 13294, loss = 0.58231 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:01:09.668674 ops/training.py:65 2019-01-17 05:01:09.668591: step 13295, loss = 0.52405 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:01:10.956912 ops/training.py:65 2019-01-17 05:01:10.956824: step 13296, loss = 0.50755 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:01:12.242178 ops/training.py:65 2019-01-17 05:01:12.242114: step 13297, loss = 0.54832 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:01:13.531881 ops/training.py:65 2019-01-17 05:01:13.531804: step 13298, loss = 0.46998 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:01:14.817608 ops/training.py:65 2019-01-17 05:01:14.817519: step 13299, loss = 0.52404 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:01:16.104848 ops/training.py:65 2019-01-17 05:01:16.104757: step 13300, loss = 0.52620 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:01:17.393079 ops/training.py:65 2019-01-17 05:01:17.392978: step 13301, loss = 0.49758 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:01:18.676783 ops/training.py:65 2019-01-17 05:01:18.676715: step 13302, loss = 0.54027 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:01:19.967615 ops/training.py:65 2019-01-17 05:01:19.967527: step 13303, loss = 0.56663 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:01:21.255519 ops/training.py:65 2019-01-17 05:01:21.255427: step 13304, loss = 0.44403 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:01:22.544891 ops/training.py:65 2019-01-17 05:01:22.544822: step 13305, loss = 0.49572 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:01:23.828865 ops/training.py:65 2019-01-17 05:01:23.828776: step 13306, loss = 0.46855 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:01:25.115971 ops/training.py:65 2019-01-17 05:01:25.115909: step 13307, loss = 0.50076 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:01:26.404672 ops/training.py:65 2019-01-17 05:01:26.404519: step 13308, loss = 0.52280 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:01:27.692620 ops/training.py:65 2019-01-17 05:01:27.692542: step 13309, loss = 0.57117 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:01:28.980769 ops/training.py:65 2019-01-17 05:01:28.980697: step 13310, loss = 0.61571 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:01:30.270055 ops/training.py:65 2019-01-17 05:01:30.269969: step 13311, loss = 0.57336 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:01:31.552575 ops/training.py:65 2019-01-17 05:01:31.552496: step 13312, loss = 0.61874 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:01:32.843037 ops/training.py:65 2019-01-17 05:01:32.842886: step 13313, loss = 0.51640 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:01:34.132884 ops/training.py:65 2019-01-17 05:01:34.132784: step 13314, loss = 0.58249 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:01:35.421288 ops/training.py:65 2019-01-17 05:01:35.421203: step 13315, loss = 0.54753 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:01:36.710972 ops/training.py:65 2019-01-17 05:01:36.710873: step 13316, loss = 0.49687 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:01:38.000444 ops/training.py:65 2019-01-17 05:01:38.000356: step 13317, loss = 0.48752 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:01:39.289036 ops/training.py:65 2019-01-17 05:01:39.288954: step 13318, loss = 0.50309 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:01:40.577006 ops/training.py:65 2019-01-17 05:01:40.576938: step 13319, loss = 0.42686 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:01:41.860258 ops/training.py:65 2019-01-17 05:01:41.860192: step 13320, loss = 0.48253 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:01:43.148849 ops/training.py:65 2019-01-17 05:01:43.148763: step 13321, loss = 0.60340 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:01:44.437158 ops/training.py:65 2019-01-17 05:01:44.437075: step 13322, loss = 0.49725 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:01:45.724667 ops/training.py:65 2019-01-17 05:01:45.724582: step 13323, loss = 0.48045 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:01:47.013106 ops/training.py:65 2019-01-17 05:01:47.013006: step 13324, loss = 0.61888 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:01:48.298285 ops/training.py:65 2019-01-17 05:01:48.298202: step 13325, loss = 0.51241 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:01:49.583009 ops/training.py:65 2019-01-17 05:01:49.582910: step 13326, loss = 0.64205 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:01:50.873079 ops/training.py:65 2019-01-17 05:01:50.873009: step 13327, loss = 0.54671 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:01:52.161213 ops/training.py:65 2019-01-17 05:01:52.161139: step 13328, loss = 0.48922 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:01:53.449797 ops/training.py:65 2019-01-17 05:01:53.449729: step 13329, loss = 0.53246 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:01:54.738021 ops/training.py:65 2019-01-17 05:01:54.737950: step 13330, loss = 0.51411 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:01:56.027095 ops/training.py:65 2019-01-17 05:01:56.027019: step 13331, loss = 0.54030 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:01:57.316298 ops/training.py:65 2019-01-17 05:01:57.316218: step 13332, loss = 0.56592 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:01:58.602011 ops/training.py:65 2019-01-17 05:01:58.601944: step 13333, loss = 0.54778 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:01:59.887274 ops/training.py:65 2019-01-17 05:01:59.887161: step 13334, loss = 0.49314 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:02:01.178333 ops/training.py:65 2019-01-17 05:02:01.178189: step 13335, loss = 0.54082 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:02:02.468543 ops/training.py:65 2019-01-17 05:02:02.468464: step 13336, loss = 0.54458 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:02:03.758170 ops/training.py:65 2019-01-17 05:02:03.758086: step 13337, loss = 0.73239 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.5
I4672 2019-01-17 05:02:05.046835 ops/training.py:65 2019-01-17 05:02:05.046721: step 13338, loss = 0.52892 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:02:06.335260 ops/training.py:65 2019-01-17 05:02:06.335187: step 13339, loss = 0.56267 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:02:07.621558 ops/training.py:65 2019-01-17 05:02:07.621471: step 13340, loss = 0.49534 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:02:08.904887 ops/training.py:65 2019-01-17 05:02:08.904811: step 13341, loss = 0.59919 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:02:10.193530 ops/training.py:65 2019-01-17 05:02:10.193442: step 13342, loss = 0.60573 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:02:11.478865 ops/training.py:65 2019-01-17 05:02:11.478801: step 13343, loss = 0.55630 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:02:12.764455 ops/training.py:65 2019-01-17 05:02:12.764370: step 13344, loss = 0.53812 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:02:14.052736 ops/training.py:65 2019-01-17 05:02:14.052660: step 13345, loss = 0.45681 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:02:15.342406 ops/training.py:65 2019-01-17 05:02:15.342325: step 13346, loss = 0.58071 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:02:16.632232 ops/training.py:65 2019-01-17 05:02:16.632156: step 13347, loss = 0.56277 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:02:17.916106 ops/training.py:65 2019-01-17 05:02:17.916033: step 13348, loss = 0.51340 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:02:19.200481 ops/training.py:65 2019-01-17 05:02:19.200448: step 13349, loss = 0.50407 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:02:20.487610 ops/training.py:65 2019-01-17 05:02:20.487567: step 13350, loss = 0.51818 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:02:21.770715 ops/training.py:65 2019-01-17 05:02:21.770607: step 13351, loss = 0.53092 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:02:23.064791 ops/training.py:65 2019-01-17 05:02:23.064689: step 13352, loss = 0.56526 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:02:24.355075 ops/training.py:65 2019-01-17 05:02:24.355009: step 13353, loss = 0.47859 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:02:25.645055 ops/training.py:65 2019-01-17 05:02:25.644981: step 13354, loss = 0.57834 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:02:26.934285 ops/training.py:65 2019-01-17 05:02:26.934207: step 13355, loss = 0.56273 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:02:28.223303 ops/training.py:65 2019-01-17 05:02:28.223226: step 13356, loss = 0.43433 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:02:29.510665 ops/training.py:65 2019-01-17 05:02:29.510571: step 13357, loss = 0.42028 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:02:30.800494 ops/training.py:65 2019-01-17 05:02:30.800402: step 13358, loss = 0.52366 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:02:32.085487 ops/training.py:65 2019-01-17 05:02:32.085413: step 13359, loss = 0.51891 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:02:33.369298 ops/training.py:65 2019-01-17 05:02:33.369227: step 13360, loss = 0.61864 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:02:34.654209 ops/training.py:65 2019-01-17 05:02:34.654099: step 13361, loss = 0.48176 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:02:35.944399 ops/training.py:65 2019-01-17 05:02:35.944295: step 13362, loss = 0.60684 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:02:37.228778 ops/training.py:65 2019-01-17 05:02:37.228715: step 13363, loss = 0.51768 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:02:38.513468 ops/training.py:65 2019-01-17 05:02:38.513361: step 13364, loss = 0.57930 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:02:39.806177 ops/training.py:65 2019-01-17 05:02:39.806070: step 13365, loss = 0.50678 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:02:41.097777 ops/training.py:65 2019-01-17 05:02:41.097707: step 13366, loss = 0.55915 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:02:42.383768 ops/training.py:65 2019-01-17 05:02:42.383697: step 13367, loss = 0.56985 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:02:43.668370 ops/training.py:65 2019-01-17 05:02:43.668275: step 13368, loss = 0.46765 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:02:44.959902 ops/training.py:65 2019-01-17 05:02:44.959796: step 13369, loss = 0.45223 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:02:46.250325 ops/training.py:65 2019-01-17 05:02:46.250264: step 13370, loss = 0.48090 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:02:47.539686 ops/training.py:65 2019-01-17 05:02:47.539609: step 13371, loss = 0.44850 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:02:48.829099 ops/training.py:65 2019-01-17 05:02:48.829010: step 13372, loss = 0.65726 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:02:50.117619 ops/training.py:65 2019-01-17 05:02:50.117554: step 13373, loss = 0.51866 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:02:51.401210 ops/training.py:65 2019-01-17 05:02:51.401140: step 13374, loss = 0.47713 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:02:52.684750 ops/training.py:65 2019-01-17 05:02:52.684643: step 13375, loss = 0.50720 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:02:53.976008 ops/training.py:65 2019-01-17 05:02:53.975908: step 13376, loss = 0.56482 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:02:55.259254 ops/training.py:65 2019-01-17 05:02:55.259186: step 13377, loss = 0.57884 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:02:56.544628 ops/training.py:65 2019-01-17 05:02:56.544526: step 13378, loss = 0.48705 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:02:57.834679 ops/training.py:65 2019-01-17 05:02:57.834615: step 13379, loss = 0.53558 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:02:59.122570 ops/training.py:65 2019-01-17 05:02:59.122476: step 13380, loss = 0.52908 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:03:00.408482 ops/training.py:65 2019-01-17 05:03:00.408412: step 13381, loss = 0.59072 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:03:01.697442 ops/training.py:65 2019-01-17 05:03:01.697371: step 13382, loss = 0.52768 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:03:02.986821 ops/training.py:65 2019-01-17 05:03:02.986750: step 13383, loss = 0.42518 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:03:04.275807 ops/training.py:65 2019-01-17 05:03:04.275730: step 13384, loss = 0.56227 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:03:05.563470 ops/training.py:65 2019-01-17 05:03:05.563402: step 13385, loss = 0.52048 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:03:06.852853 ops/training.py:65 2019-01-17 05:03:06.852760: step 13386, loss = 0.50308 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:03:08.142033 ops/training.py:65 2019-01-17 05:03:08.141955: step 13387, loss = 0.46899 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:03:09.431061 ops/training.py:65 2019-01-17 05:03:09.430965: step 13388, loss = 0.50715 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:03:10.715822 ops/training.py:65 2019-01-17 05:03:10.715750: step 13389, loss = 0.41128 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:03:12.005877 ops/training.py:65 2019-01-17 05:03:12.005768: step 13390, loss = 0.40786 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:03:13.295020 ops/training.py:65 2019-01-17 05:03:13.294952: step 13391, loss = 0.59580 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:03:14.579234 ops/training.py:65 2019-01-17 05:03:14.579160: step 13392, loss = 0.56445 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:03:15.867488 ops/training.py:65 2019-01-17 05:03:15.867418: step 13393, loss = 0.50666 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:03:17.151725 ops/training.py:65 2019-01-17 05:03:17.151665: step 13394, loss = 0.53150 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:03:18.440887 ops/training.py:65 2019-01-17 05:03:18.440819: step 13395, loss = 0.56343 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:03:19.725720 ops/training.py:65 2019-01-17 05:03:19.725650: step 13396, loss = 0.51539 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:03:21.013335 ops/training.py:65 2019-01-17 05:03:21.013232: step 13397, loss = 0.58699 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:03:22.303635 ops/training.py:65 2019-01-17 05:03:22.303570: step 13398, loss = 0.49205 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:03:23.587591 ops/training.py:65 2019-01-17 05:03:23.587521: step 13399, loss = 0.52227 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:03:24.870570 ops/training.py:65 2019-01-17 05:03:24.870482: step 13400, loss = 0.50789 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:03:26.162826 ops/training.py:65 2019-01-17 05:03:26.162731: step 13401, loss = 0.44790 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:03:27.448359 ops/training.py:65 2019-01-17 05:03:27.448294: step 13402, loss = 0.70262 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:03:28.733504 ops/training.py:65 2019-01-17 05:03:28.733440: step 13403, loss = 0.48919 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:03:30.022000 ops/training.py:65 2019-01-17 05:03:30.021897: step 13404, loss = 0.61417 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:03:31.312886 ops/training.py:65 2019-01-17 05:03:31.312817: step 13405, loss = 0.53991 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:03:32.601879 ops/training.py:65 2019-01-17 05:03:32.601803: step 13406, loss = 0.56344 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:03:33.891123 ops/training.py:65 2019-01-17 05:03:33.891021: step 13407, loss = 0.57172 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:03:35.186038 ops/training.py:65 2019-01-17 05:03:35.185960: step 13408, loss = 0.54890 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:03:36.475038 ops/training.py:65 2019-01-17 05:03:36.474927: step 13409, loss = 0.52935 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:03:37.764198 ops/training.py:65 2019-01-17 05:03:37.764119: step 13410, loss = 0.54300 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:03:39.052942 ops/training.py:65 2019-01-17 05:03:39.052840: step 13411, loss = 0.55940 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:03:40.341666 ops/training.py:65 2019-01-17 05:03:40.341598: step 13412, loss = 0.53847 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:03:41.630647 ops/training.py:65 2019-01-17 05:03:41.630573: step 13413, loss = 0.53061 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:03:42.920041 ops/training.py:65 2019-01-17 05:03:42.919966: step 13414, loss = 0.51076 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:03:44.207946 ops/training.py:65 2019-01-17 05:03:44.207874: step 13415, loss = 0.55900 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:03:45.494833 ops/training.py:65 2019-01-17 05:03:45.494747: step 13416, loss = 0.53773 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:03:46.783398 ops/training.py:65 2019-01-17 05:03:46.783321: step 13417, loss = 0.47072 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:03:48.067151 ops/training.py:65 2019-01-17 05:03:48.067088: step 13418, loss = 0.62235 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 05:03:49.351074 ops/training.py:65 2019-01-17 05:03:49.350976: step 13419, loss = 0.67518 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:03:50.642409 ops/training.py:65 2019-01-17 05:03:50.642298: step 13420, loss = 0.47239 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:03:51.934529 ops/training.py:65 2019-01-17 05:03:51.934438: step 13421, loss = 0.53547 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:03:53.223443 ops/training.py:65 2019-01-17 05:03:53.223363: step 13422, loss = 0.44745 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:03:54.513003 ops/training.py:65 2019-01-17 05:03:54.512908: step 13423, loss = 0.46872 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:03:55.801937 ops/training.py:65 2019-01-17 05:03:55.801874: step 13424, loss = 0.59948 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:03:57.091014 ops/training.py:65 2019-01-17 05:03:57.090935: step 13425, loss = 0.46330 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:03:58.380414 ops/training.py:65 2019-01-17 05:03:58.380320: step 13426, loss = 0.42607 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:03:59.669134 ops/training.py:65 2019-01-17 05:03:59.669057: step 13427, loss = 0.54948 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:04:00.957432 ops/training.py:65 2019-01-17 05:04:00.957339: step 13428, loss = 0.52214 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:04:02.242730 ops/training.py:65 2019-01-17 05:04:02.242662: step 13429, loss = 0.45625 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:04:03.530524 ops/training.py:65 2019-01-17 05:04:03.530434: step 13430, loss = 0.57362 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:04:04.819072 ops/training.py:65 2019-01-17 05:04:04.818973: step 13431, loss = 0.58467 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:04:06.106718 ops/training.py:65 2019-01-17 05:04:06.106648: step 13432, loss = 0.52023 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:04:07.394764 ops/training.py:65 2019-01-17 05:04:07.394688: step 13433, loss = 0.47386 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:04:08.683267 ops/training.py:65 2019-01-17 05:04:08.683162: step 13434, loss = 0.55256 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:04:09.971879 ops/training.py:65 2019-01-17 05:04:09.971805: step 13435, loss = 0.51526 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:04:11.260117 ops/training.py:65 2019-01-17 05:04:11.260031: step 13436, loss = 0.55234 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:04:12.545495 ops/training.py:65 2019-01-17 05:04:12.545426: step 13437, loss = 0.46820 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:04:13.834085 ops/training.py:65 2019-01-17 05:04:13.834018: step 13438, loss = 0.46221 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:04:15.123871 ops/training.py:65 2019-01-17 05:04:15.123798: step 13439, loss = 0.61016 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:04:16.411841 ops/training.py:65 2019-01-17 05:04:16.411769: step 13440, loss = 0.53905 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:04:17.701118 ops/training.py:65 2019-01-17 05:04:17.701047: step 13441, loss = 0.60049 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:04:18.990185 ops/training.py:65 2019-01-17 05:04:18.990098: step 13442, loss = 0.64898 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:04:20.279162 ops/training.py:65 2019-01-17 05:04:20.279095: step 13443, loss = 0.53730 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:04:21.562784 ops/training.py:65 2019-01-17 05:04:21.562718: step 13444, loss = 0.81441 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 05:04:22.850767 ops/training.py:65 2019-01-17 05:04:22.850700: step 13445, loss = 0.67634 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:04:24.133475 ops/training.py:65 2019-01-17 05:04:24.133408: step 13446, loss = 0.37021 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:04:25.421139 ops/training.py:65 2019-01-17 05:04:25.421070: step 13447, loss = 0.78897 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:04:26.708513 ops/training.py:65 2019-01-17 05:04:26.708446: step 13448, loss = 0.67023 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 05:04:27.992568 ops/training.py:65 2019-01-17 05:04:27.992510: step 13449, loss = 0.57757 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:04:29.276590 ops/training.py:65 2019-01-17 05:04:29.276492: step 13450, loss = 0.60445 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:04:30.568895 ops/training.py:65 2019-01-17 05:04:30.568756: step 13451, loss = 0.60897 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:04:31.859976 ops/training.py:65 2019-01-17 05:04:31.859908: step 13452, loss = 0.61824 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 05:04:33.148485 ops/training.py:65 2019-01-17 05:04:33.148417: step 13453, loss = 0.56764 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:04:34.436655 ops/training.py:65 2019-01-17 05:04:34.436581: step 13454, loss = 0.60130 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:04:35.725477 ops/training.py:65 2019-01-17 05:04:35.725401: step 13455, loss = 0.50082 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:04:37.005749 ops/training.py:65 2019-01-17 05:04:37.005689: step 13456, loss = 0.61603 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:04:38.302829 ops/training.py:65 2019-01-17 05:04:38.302727: step 13457, loss = 0.52012 (24.7 examples/sec; 1.296 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:04:39.592689 ops/training.py:65 2019-01-17 05:04:39.592614: step 13458, loss = 0.54479 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:04:40.882003 ops/training.py:65 2019-01-17 05:04:40.881926: step 13459, loss = 0.49042 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:04:42.165276 ops/training.py:65 2019-01-17 05:04:42.165211: step 13460, loss = 0.52157 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:04:43.448817 ops/training.py:65 2019-01-17 05:04:43.448722: step 13461, loss = 0.49127 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:04:44.740032 ops/training.py:65 2019-01-17 05:04:44.739922: step 13462, loss = 0.61760 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:04:46.030156 ops/training.py:65 2019-01-17 05:04:46.030053: step 13463, loss = 0.41484 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:04:47.320445 ops/training.py:65 2019-01-17 05:04:47.320370: step 13464, loss = 0.48100 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:04:48.604960 ops/training.py:65 2019-01-17 05:04:48.604895: step 13465, loss = 0.60321 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:04:49.893766 ops/training.py:65 2019-01-17 05:04:49.893674: step 13466, loss = 0.63052 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:04:51.181734 ops/training.py:65 2019-01-17 05:04:51.181658: step 13467, loss = 0.60441 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:04:52.466129 ops/training.py:65 2019-01-17 05:04:52.466060: step 13468, loss = 0.40918 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:04:53.755554 ops/training.py:65 2019-01-17 05:04:53.755459: step 13469, loss = 0.52598 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:04:55.044040 ops/training.py:65 2019-01-17 05:04:55.043969: step 13470, loss = 0.56485 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:04:56.332982 ops/training.py:65 2019-01-17 05:04:56.332911: step 13471, loss = 0.41934 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:04:57.621232 ops/training.py:65 2019-01-17 05:04:57.621161: step 13472, loss = 0.68281 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 05:04:58.909089 ops/training.py:65 2019-01-17 05:04:58.908999: step 13473, loss = 0.46874 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:05:00.198439 ops/training.py:65 2019-01-17 05:05:00.198343: step 13474, loss = 0.62261 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:05:01.485922 ops/training.py:65 2019-01-17 05:05:01.485856: step 13475, loss = 0.50516 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:05:02.769763 ops/training.py:65 2019-01-17 05:05:02.769708: step 13476, loss = 0.48185 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:05:04.049384 ops/training.py:65 2019-01-17 05:05:04.049289: step 13477, loss = 0.49839 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:05:05.341372 ops/training.py:65 2019-01-17 05:05:05.341253: step 13478, loss = 0.49487 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:05:06.631986 ops/training.py:65 2019-01-17 05:05:06.631913: step 13479, loss = 0.47154 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:05:07.921898 ops/training.py:65 2019-01-17 05:05:07.921825: step 13480, loss = 0.49115 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:05:09.207220 ops/training.py:65 2019-01-17 05:05:09.207153: step 13481, loss = 0.47108 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:05:10.491959 ops/training.py:65 2019-01-17 05:05:10.491860: step 13482, loss = 0.54483 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:05:11.784208 ops/training.py:65 2019-01-17 05:05:11.784049: step 13483, loss = 0.55168 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:05:13.074975 ops/training.py:65 2019-01-17 05:05:13.074879: step 13484, loss = 0.49168 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:05:14.363548 ops/training.py:65 2019-01-17 05:05:14.363477: step 13485, loss = 0.45377 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:05:15.652471 ops/training.py:65 2019-01-17 05:05:15.652405: step 13486, loss = 0.45579 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:05:16.940904 ops/training.py:65 2019-01-17 05:05:16.940827: step 13487, loss = 0.50508 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:05:18.229680 ops/training.py:65 2019-01-17 05:05:18.229606: step 13488, loss = 0.49922 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:05:19.518642 ops/training.py:65 2019-01-17 05:05:19.518565: step 13489, loss = 0.46324 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:05:20.803329 ops/training.py:65 2019-01-17 05:05:20.803239: step 13490, loss = 0.60938 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:05:22.090698 ops/training.py:65 2019-01-17 05:05:22.090622: step 13491, loss = 0.48149 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:05:23.373930 ops/training.py:65 2019-01-17 05:05:23.373863: step 13492, loss = 0.53165 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:05:24.659377 ops/training.py:65 2019-01-17 05:05:24.659277: step 13493, loss = 0.56741 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:05:25.943137 ops/training.py:65 2019-01-17 05:05:25.943039: step 13494, loss = 0.49287 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:05:27.234707 ops/training.py:65 2019-01-17 05:05:27.234607: step 13495, loss = 0.60604 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 05:05:28.517865 ops/training.py:65 2019-01-17 05:05:28.517802: step 13496, loss = 0.59899 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:05:29.808641 ops/training.py:65 2019-01-17 05:05:29.808542: step 13497, loss = 0.52545 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:05:31.097924 ops/training.py:65 2019-01-17 05:05:31.097852: step 13498, loss = 0.66319 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:05:32.382269 ops/training.py:65 2019-01-17 05:05:32.382200: step 13499, loss = 0.49701 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:05:33.665145 ops/training.py:65 2019-01-17 05:05:33.665049: step 13500, loss = 0.48896 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:05:34.953601 ops/training.py:65 2019-01-17 05:05:34.953499: step 13501, loss = 0.45369 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:05:36.242536 ops/training.py:65 2019-01-17 05:05:36.242465: step 13502, loss = 0.46988 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:05:37.530787 ops/training.py:65 2019-01-17 05:05:37.530715: step 13503, loss = 0.64203 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:05:38.819410 ops/training.py:65 2019-01-17 05:05:38.819343: step 13504, loss = 0.43714 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:05:40.107787 ops/training.py:65 2019-01-17 05:05:40.107714: step 13505, loss = 0.58828 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:05:41.395507 ops/training.py:65 2019-01-17 05:05:41.395433: step 13506, loss = 0.58451 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:05:42.681933 ops/training.py:65 2019-01-17 05:05:42.681866: step 13507, loss = 0.46173 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:05:43.970589 ops/training.py:65 2019-01-17 05:05:43.970505: step 13508, loss = 0.49980 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:05:45.260410 ops/training.py:65 2019-01-17 05:05:45.260301: step 13509, loss = 0.55311 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:05:46.549622 ops/training.py:65 2019-01-17 05:05:46.549547: step 13510, loss = 0.58966 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:05:47.832977 ops/training.py:65 2019-01-17 05:05:47.832905: step 13511, loss = 0.51292 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:05:49.120997 ops/training.py:65 2019-01-17 05:05:49.120929: step 13512, loss = 0.50705 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:05:50.408942 ops/training.py:65 2019-01-17 05:05:50.408877: step 13513, loss = 0.57050 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:05:51.696616 ops/training.py:65 2019-01-17 05:05:51.696544: step 13514, loss = 0.48023 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:05:52.991791 ops/training.py:65 2019-01-17 05:05:52.991718: step 13515, loss = 0.54814 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:05:54.279690 ops/training.py:65 2019-01-17 05:05:54.279614: step 13516, loss = 0.60495 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:05:55.567407 ops/training.py:65 2019-01-17 05:05:55.567319: step 13517, loss = 0.59479 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:05:56.854979 ops/training.py:65 2019-01-17 05:05:56.854906: step 13518, loss = 0.51870 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:05:58.142896 ops/training.py:65 2019-01-17 05:05:58.142823: step 13519, loss = 0.61325 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:05:59.430726 ops/training.py:65 2019-01-17 05:05:59.430652: step 13520, loss = 0.60210 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:06:00.718728 ops/training.py:65 2019-01-17 05:06:00.718647: step 13521, loss = 0.47488 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:06:02.004237 ops/training.py:65 2019-01-17 05:06:02.004165: step 13522, loss = 0.55081 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:06:03.292953 ops/training.py:65 2019-01-17 05:06:03.292871: step 13523, loss = 0.50974 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:06:04.581302 ops/training.py:65 2019-01-17 05:06:04.581224: step 13524, loss = 0.61452 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:06:05.865037 ops/training.py:65 2019-01-17 05:06:05.864969: step 13525, loss = 0.58859 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:06:07.154516 ops/training.py:65 2019-01-17 05:06:07.154423: step 13526, loss = 0.48600 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:06:08.438744 ops/training.py:65 2019-01-17 05:06:08.438685: step 13527, loss = 0.48567 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:06:09.721379 ops/training.py:65 2019-01-17 05:06:09.721283: step 13528, loss = 0.56072 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:06:11.012291 ops/training.py:65 2019-01-17 05:06:11.012203: step 13529, loss = 0.51411 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:06:12.304211 ops/training.py:65 2019-01-17 05:06:12.304137: step 13530, loss = 0.53641 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:06:13.592022 ops/training.py:65 2019-01-17 05:06:13.591954: step 13531, loss = 0.54535 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:06:14.880554 ops/training.py:65 2019-01-17 05:06:14.880485: step 13532, loss = 0.59143 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:06:16.168234 ops/training.py:65 2019-01-17 05:06:16.168161: step 13533, loss = 0.51227 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:06:17.455547 ops/training.py:65 2019-01-17 05:06:17.455453: step 13534, loss = 0.44097 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:06:18.738992 ops/training.py:65 2019-01-17 05:06:18.738923: step 13535, loss = 0.61006 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:06:20.027665 ops/training.py:65 2019-01-17 05:06:20.027570: step 13536, loss = 0.48044 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:06:21.315838 ops/training.py:65 2019-01-17 05:06:21.315746: step 13537, loss = 0.53776 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:06:22.603714 ops/training.py:65 2019-01-17 05:06:22.603646: step 13538, loss = 0.63039 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:06:23.892006 ops/training.py:65 2019-01-17 05:06:23.891920: step 13539, loss = 0.53998 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:06:25.176060 ops/training.py:65 2019-01-17 05:06:25.175992: step 13540, loss = 0.55489 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:06:26.463386 ops/training.py:65 2019-01-17 05:06:26.463313: step 13541, loss = 0.54385 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:06:27.752198 ops/training.py:65 2019-01-17 05:06:27.752127: step 13542, loss = 0.37539 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:06:29.041005 ops/training.py:65 2019-01-17 05:06:29.040931: step 13543, loss = 0.43109 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:06:30.328629 ops/training.py:65 2019-01-17 05:06:30.328530: step 13544, loss = 0.63631 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 05:06:31.614613 ops/training.py:65 2019-01-17 05:06:31.614510: step 13545, loss = 0.38882 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:06:32.899681 ops/training.py:65 2019-01-17 05:06:32.899605: step 13546, loss = 0.51639 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:06:34.187491 ops/training.py:65 2019-01-17 05:06:34.187397: step 13547, loss = 0.41291 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:06:35.472199 ops/training.py:65 2019-01-17 05:06:35.472131: step 13548, loss = 0.52605 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:06:36.755561 ops/training.py:65 2019-01-17 05:06:36.755457: step 13549, loss = 0.52360 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:06:38.047508 ops/training.py:65 2019-01-17 05:06:38.047407: step 13550, loss = 0.51769 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:06:39.338053 ops/training.py:65 2019-01-17 05:06:39.337950: step 13551, loss = 0.61303 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:06:40.627091 ops/training.py:65 2019-01-17 05:06:40.627023: step 13552, loss = 0.57807 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:06:41.911209 ops/training.py:65 2019-01-17 05:06:41.911131: step 13553, loss = 0.59848 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:06:43.200357 ops/training.py:65 2019-01-17 05:06:43.200284: step 13554, loss = 0.45164 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:06:44.488306 ops/training.py:65 2019-01-17 05:06:44.488232: step 13555, loss = 0.52475 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:06:45.776284 ops/training.py:65 2019-01-17 05:06:45.776210: step 13556, loss = 0.54514 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:06:47.070384 ops/training.py:65 2019-01-17 05:06:47.070274: step 13557, loss = 0.53586 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:06:48.358553 ops/training.py:65 2019-01-17 05:06:48.358472: step 13558, loss = 0.48568 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:06:49.646034 ops/training.py:65 2019-01-17 05:06:49.645913: step 13559, loss = 0.39626 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:06:50.935722 ops/training.py:65 2019-01-17 05:06:50.935570: step 13560, loss = 0.64807 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:06:52.224018 ops/training.py:65 2019-01-17 05:06:52.223948: step 13561, loss = 0.42407 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:06:53.512135 ops/training.py:65 2019-01-17 05:06:53.512059: step 13562, loss = 0.43748 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:06:54.799915 ops/training.py:65 2019-01-17 05:06:54.799820: step 13563, loss = 0.44848 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:06:56.087388 ops/training.py:65 2019-01-17 05:06:56.087308: step 13564, loss = 0.50479 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:06:57.372389 ops/training.py:65 2019-01-17 05:06:57.372318: step 13565, loss = 0.56808 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:06:58.660953 ops/training.py:65 2019-01-17 05:06:58.660876: step 13566, loss = 0.53729 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:06:59.944807 ops/training.py:65 2019-01-17 05:06:59.944739: step 13567, loss = 0.50494 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:07:01.229926 ops/training.py:65 2019-01-17 05:07:01.229828: step 13568, loss = 0.58390 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:07:02.514200 ops/training.py:65 2019-01-17 05:07:02.514098: step 13569, loss = 0.53270 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:07:03.805944 ops/training.py:65 2019-01-17 05:07:03.805852: step 13570, loss = 0.56311 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:07:05.096131 ops/training.py:65 2019-01-17 05:07:05.096057: step 13571, loss = 0.47414 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:07:06.383737 ops/training.py:65 2019-01-17 05:07:06.383666: step 13572, loss = 0.44341 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:07:07.670973 ops/training.py:65 2019-01-17 05:07:07.670894: step 13573, loss = 0.62924 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:07:08.952049 ops/training.py:65 2019-01-17 05:07:08.951979: step 13574, loss = 0.53473 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:07:10.237410 ops/training.py:65 2019-01-17 05:07:10.237305: step 13575, loss = 0.46466 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:07:11.522254 ops/training.py:65 2019-01-17 05:07:11.522156: step 13576, loss = 0.47951 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:07:12.815098 ops/training.py:65 2019-01-17 05:07:12.814999: step 13577, loss = 0.53383 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:07:14.103908 ops/training.py:65 2019-01-17 05:07:14.103815: step 13578, loss = 0.54697 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:07:15.392666 ops/training.py:65 2019-01-17 05:07:15.392587: step 13579, loss = 0.49354 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:07:16.678204 ops/training.py:65 2019-01-17 05:07:16.678123: step 13580, loss = 0.48675 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:07:17.966429 ops/training.py:65 2019-01-17 05:07:17.966333: step 13581, loss = 0.39203 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:07:19.254942 ops/training.py:65 2019-01-17 05:07:19.254852: step 13582, loss = 0.61003 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:07:20.543712 ops/training.py:65 2019-01-17 05:07:20.543641: step 13583, loss = 0.63758 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:07:21.831608 ops/training.py:65 2019-01-17 05:07:21.831539: step 13584, loss = 0.54527 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:07:23.119193 ops/training.py:65 2019-01-17 05:07:23.119106: step 13585, loss = 0.48367 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:07:24.407286 ops/training.py:65 2019-01-17 05:07:24.407219: step 13586, loss = 0.47976 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:07:25.694882 ops/training.py:65 2019-01-17 05:07:25.694813: step 13587, loss = 0.54469 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:07:26.981819 ops/training.py:65 2019-01-17 05:07:26.981746: step 13588, loss = 0.55504 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:07:28.267875 ops/training.py:65 2019-01-17 05:07:28.267800: step 13589, loss = 0.51143 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:07:29.556492 ops/training.py:65 2019-01-17 05:07:29.556407: step 13590, loss = 0.48466 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:07:30.841447 ops/training.py:65 2019-01-17 05:07:30.841364: step 13591, loss = 0.53226 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:07:32.135240 ops/training.py:65 2019-01-17 05:07:32.135169: step 13592, loss = 0.49946 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:07:33.422822 ops/training.py:65 2019-01-17 05:07:33.422752: step 13593, loss = 0.63545 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:07:34.710752 ops/training.py:65 2019-01-17 05:07:34.710671: step 13594, loss = 0.56205 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:07:35.998686 ops/training.py:65 2019-01-17 05:07:35.998605: step 13595, loss = 0.59615 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:07:37.285793 ops/training.py:65 2019-01-17 05:07:37.285704: step 13596, loss = 0.57509 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:07:38.574030 ops/training.py:65 2019-01-17 05:07:38.573952: step 13597, loss = 0.44842 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:07:39.861950 ops/training.py:65 2019-01-17 05:07:39.861871: step 13598, loss = 0.50751 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:07:41.151181 ops/training.py:65 2019-01-17 05:07:41.151096: step 13599, loss = 0.54720 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:07:42.439282 ops/training.py:65 2019-01-17 05:07:42.439203: step 13600, loss = 0.48050 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:07:43.727603 ops/training.py:65 2019-01-17 05:07:43.727528: step 13601, loss = 0.46774 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:07:45.015505 ops/training.py:65 2019-01-17 05:07:45.015402: step 13602, loss = 0.51562 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:07:46.303783 ops/training.py:65 2019-01-17 05:07:46.303705: step 13603, loss = 0.49604 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:07:47.592853 ops/training.py:65 2019-01-17 05:07:47.592777: step 13604, loss = 0.67643 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:07:48.880894 ops/training.py:65 2019-01-17 05:07:48.880801: step 13605, loss = 0.50371 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:07:50.169636 ops/training.py:65 2019-01-17 05:07:50.169563: step 13606, loss = 0.55831 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:07:51.457849 ops/training.py:65 2019-01-17 05:07:51.457775: step 13607, loss = 0.39026 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:07:52.751976 ops/training.py:65 2019-01-17 05:07:52.751902: step 13608, loss = 0.48975 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:07:54.040754 ops/training.py:65 2019-01-17 05:07:54.040683: step 13609, loss = 0.57193 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:07:55.328807 ops/training.py:65 2019-01-17 05:07:55.328736: step 13610, loss = 0.46850 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:07:56.615856 ops/training.py:65 2019-01-17 05:07:56.615766: step 13611, loss = 0.56525 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:07:57.904328 ops/training.py:65 2019-01-17 05:07:57.904250: step 13612, loss = 0.48254 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:07:59.193334 ops/training.py:65 2019-01-17 05:07:59.193256: step 13613, loss = 0.46313 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:08:00.481516 ops/training.py:65 2019-01-17 05:08:00.481441: step 13614, loss = 0.54778 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:08:01.766588 ops/training.py:65 2019-01-17 05:08:01.766516: step 13615, loss = 0.52102 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:08:03.054390 ops/training.py:65 2019-01-17 05:08:03.054310: step 13616, loss = 0.48177 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:08:04.343988 ops/training.py:65 2019-01-17 05:08:04.343874: step 13617, loss = 0.52844 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:08:05.632179 ops/training.py:65 2019-01-17 05:08:05.632093: step 13618, loss = 0.44676 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:08:06.919753 ops/training.py:65 2019-01-17 05:08:06.919674: step 13619, loss = 0.52906 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:08:08.207987 ops/training.py:65 2019-01-17 05:08:08.207915: step 13620, loss = 0.57195 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:08:09.495834 ops/training.py:65 2019-01-17 05:08:09.495759: step 13621, loss = 0.47758 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:08:10.783761 ops/training.py:65 2019-01-17 05:08:10.783684: step 13622, loss = 0.41879 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:08:12.071178 ops/training.py:65 2019-01-17 05:08:12.071096: step 13623, loss = 0.62493 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:08:13.360190 ops/training.py:65 2019-01-17 05:08:13.360110: step 13624, loss = 0.45059 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:08:14.649361 ops/training.py:65 2019-01-17 05:08:14.649292: step 13625, loss = 0.63266 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:08:15.937468 ops/training.py:65 2019-01-17 05:08:15.937380: step 13626, loss = 0.47315 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:08:17.222128 ops/training.py:65 2019-01-17 05:08:17.222053: step 13627, loss = 0.61808 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:08:18.509990 ops/training.py:65 2019-01-17 05:08:18.509907: step 13628, loss = 0.62852 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:08:19.797751 ops/training.py:65 2019-01-17 05:08:19.797680: step 13629, loss = 0.62857 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:08:21.086085 ops/training.py:65 2019-01-17 05:08:21.086015: step 13630, loss = 0.50758 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:08:22.374469 ops/training.py:65 2019-01-17 05:08:22.374400: step 13631, loss = 0.58112 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:08:23.661935 ops/training.py:65 2019-01-17 05:08:23.661864: step 13632, loss = 0.48016 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:08:24.951615 ops/training.py:65 2019-01-17 05:08:24.951541: step 13633, loss = 0.57083 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:08:26.239989 ops/training.py:65 2019-01-17 05:08:26.239909: step 13634, loss = 0.54170 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:08:27.528398 ops/training.py:65 2019-01-17 05:08:27.528325: step 13635, loss = 0.47619 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:08:28.822801 ops/training.py:65 2019-01-17 05:08:28.822729: step 13636, loss = 0.54899 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:08:30.111250 ops/training.py:65 2019-01-17 05:08:30.111177: step 13637, loss = 0.55717 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:08:31.394405 ops/training.py:65 2019-01-17 05:08:31.394338: step 13638, loss = 0.62696 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:08:32.682709 ops/training.py:65 2019-01-17 05:08:32.682608: step 13639, loss = 0.52600 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:08:33.972338 ops/training.py:65 2019-01-17 05:08:33.972268: step 13640, loss = 0.51007 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:08:35.259753 ops/training.py:65 2019-01-17 05:08:35.259678: step 13641, loss = 0.55660 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:08:36.548228 ops/training.py:65 2019-01-17 05:08:36.548154: step 13642, loss = 0.66163 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:08:37.837331 ops/training.py:65 2019-01-17 05:08:37.837241: step 13643, loss = 0.50109 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:08:39.126052 ops/training.py:65 2019-01-17 05:08:39.125953: step 13644, loss = 0.60544 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:08:40.413383 ops/training.py:65 2019-01-17 05:08:40.413303: step 13645, loss = 0.41573 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:08:41.700589 ops/training.py:65 2019-01-17 05:08:41.700504: step 13646, loss = 0.47273 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:08:42.988300 ops/training.py:65 2019-01-17 05:08:42.988225: step 13647, loss = 0.56527 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:08:44.272043 ops/training.py:65 2019-01-17 05:08:44.271967: step 13648, loss = 0.49118 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:08:45.552774 ops/training.py:65 2019-01-17 05:08:45.552667: step 13649, loss = 0.46884 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:08:46.845841 ops/training.py:65 2019-01-17 05:08:46.845742: step 13650, loss = 0.54774 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:08:48.133296 ops/training.py:65 2019-01-17 05:08:48.133232: step 13651, loss = 0.49075 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:08:49.422403 ops/training.py:65 2019-01-17 05:08:49.422310: step 13652, loss = 0.50479 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:08:50.711192 ops/training.py:65 2019-01-17 05:08:50.711113: step 13653, loss = 0.43245 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:08:51.995005 ops/training.py:65 2019-01-17 05:08:51.994933: step 13654, loss = 0.55064 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:08:53.284364 ops/training.py:65 2019-01-17 05:08:53.284272: step 13655, loss = 0.40338 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:08:54.572407 ops/training.py:65 2019-01-17 05:08:54.572308: step 13656, loss = 0.52681 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:08:55.861295 ops/training.py:65 2019-01-17 05:08:55.861211: step 13657, loss = 0.62641 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:08:57.145318 ops/training.py:65 2019-01-17 05:08:57.145249: step 13658, loss = 0.55468 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:08:58.426213 ops/training.py:65 2019-01-17 05:08:58.426107: step 13659, loss = 0.53132 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:08:59.718083 ops/training.py:65 2019-01-17 05:08:59.717925: step 13660, loss = 0.44192 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:09:01.007915 ops/training.py:65 2019-01-17 05:09:01.007826: step 13661, loss = 0.54928 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:09:02.291656 ops/training.py:65 2019-01-17 05:09:02.291550: step 13662, loss = 0.45610 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:09:03.578783 ops/training.py:65 2019-01-17 05:09:03.578682: step 13663, loss = 0.39930 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:09:04.862354 ops/training.py:65 2019-01-17 05:09:04.862247: step 13664, loss = 0.50817 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:09:06.152287 ops/training.py:65 2019-01-17 05:09:06.152205: step 13665, loss = 0.56714 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:09:07.440438 ops/training.py:65 2019-01-17 05:09:07.440346: step 13666, loss = 0.54191 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:09:08.725804 ops/training.py:65 2019-01-17 05:09:08.725721: step 13667, loss = 0.57145 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:09:10.014354 ops/training.py:65 2019-01-17 05:09:10.014259: step 13668, loss = 0.47855 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:09:11.302733 ops/training.py:65 2019-01-17 05:09:11.302650: step 13669, loss = 0.48735 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:09:12.586420 ops/training.py:65 2019-01-17 05:09:12.586363: step 13670, loss = 0.46530 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:09:13.873097 ops/training.py:65 2019-01-17 05:09:13.873021: step 13671, loss = 0.59515 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:09:15.161578 ops/training.py:65 2019-01-17 05:09:15.161505: step 13672, loss = 0.55200 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:09:16.446100 ops/training.py:65 2019-01-17 05:09:16.446033: step 13673, loss = 0.49711 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:09:17.729929 ops/training.py:65 2019-01-17 05:09:17.729835: step 13674, loss = 0.51977 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:09:19.014738 ops/training.py:65 2019-01-17 05:09:19.014625: step 13675, loss = 0.39949 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:09:20.298530 ops/training.py:65 2019-01-17 05:09:20.298426: step 13676, loss = 0.51402 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:09:21.589704 ops/training.py:65 2019-01-17 05:09:21.589603: step 13677, loss = 0.54666 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:09:22.878101 ops/training.py:65 2019-01-17 05:09:22.878012: step 13678, loss = 0.53099 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:09:24.166621 ops/training.py:65 2019-01-17 05:09:24.166551: step 13679, loss = 0.57573 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:09:25.453678 ops/training.py:65 2019-01-17 05:09:25.453612: step 13680, loss = 0.48214 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:09:26.741408 ops/training.py:65 2019-01-17 05:09:26.741338: step 13681, loss = 0.50033 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:09:28.028855 ops/training.py:65 2019-01-17 05:09:28.028754: step 13682, loss = 0.41310 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:09:29.314365 ops/training.py:65 2019-01-17 05:09:29.314294: step 13683, loss = 0.53893 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:09:30.597485 ops/training.py:65 2019-01-17 05:09:30.597396: step 13684, loss = 0.50224 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:09:31.881466 ops/training.py:65 2019-01-17 05:09:31.881354: step 13685, loss = 0.48556 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:09:33.169044 ops/training.py:65 2019-01-17 05:09:33.168942: step 13686, loss = 0.58002 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:09:34.455807 ops/training.py:65 2019-01-17 05:09:34.455705: step 13687, loss = 0.44847 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:09:35.746847 ops/training.py:65 2019-01-17 05:09:35.746746: step 13688, loss = 0.44112 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:09:37.035651 ops/training.py:65 2019-01-17 05:09:37.035577: step 13689, loss = 0.60056 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:09:38.320329 ops/training.py:65 2019-01-17 05:09:38.320258: step 13690, loss = 0.45948 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:09:39.604483 ops/training.py:65 2019-01-17 05:09:39.604373: step 13691, loss = 0.52854 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:09:40.895561 ops/training.py:65 2019-01-17 05:09:40.895467: step 13692, loss = 0.55007 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:09:42.187578 ops/training.py:65 2019-01-17 05:09:42.187487: step 13693, loss = 0.44737 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:09:43.476679 ops/training.py:65 2019-01-17 05:09:43.476603: step 13694, loss = 0.43249 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:09:44.764360 ops/training.py:65 2019-01-17 05:09:44.764289: step 13695, loss = 0.48011 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:09:46.058623 ops/training.py:65 2019-01-17 05:09:46.058550: step 13696, loss = 0.54264 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:09:47.347105 ops/training.py:65 2019-01-17 05:09:47.347025: step 13697, loss = 0.53840 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:09:48.635037 ops/training.py:65 2019-01-17 05:09:48.634963: step 13698, loss = 0.55106 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:09:49.922315 ops/training.py:65 2019-01-17 05:09:49.922246: step 13699, loss = 0.61501 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:09:51.210339 ops/training.py:65 2019-01-17 05:09:51.210256: step 13700, loss = 0.52074 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:09:52.497474 ops/training.py:65 2019-01-17 05:09:52.497404: step 13701, loss = 0.56073 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:09:53.787041 ops/training.py:65 2019-01-17 05:09:53.786968: step 13702, loss = 0.55134 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:09:55.075222 ops/training.py:65 2019-01-17 05:09:55.075115: step 13703, loss = 0.59075 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:09:56.364942 ops/training.py:65 2019-01-17 05:09:56.364864: step 13704, loss = 0.40605 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:09:57.650544 ops/training.py:65 2019-01-17 05:09:57.650464: step 13705, loss = 0.44498 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:09:58.939218 ops/training.py:65 2019-01-17 05:09:58.939143: step 13706, loss = 0.52942 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:10:00.226699 ops/training.py:65 2019-01-17 05:10:00.226610: step 13707, loss = 0.52509 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:10:01.515288 ops/training.py:65 2019-01-17 05:10:01.515224: step 13708, loss = 0.47202 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:10:02.799091 ops/training.py:65 2019-01-17 05:10:02.799025: step 13709, loss = 0.44596 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:10:04.087876 ops/training.py:65 2019-01-17 05:10:04.087743: step 13710, loss = 0.47135 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:10:05.377002 ops/training.py:65 2019-01-17 05:10:05.376911: step 13711, loss = 0.54009 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:10:06.662470 ops/training.py:65 2019-01-17 05:10:06.662400: step 13712, loss = 0.59212 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:10:07.950000 ops/training.py:65 2019-01-17 05:10:07.949896: step 13713, loss = 0.43977 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:10:09.238349 ops/training.py:65 2019-01-17 05:10:09.238261: step 13714, loss = 0.51459 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:10:10.526445 ops/training.py:65 2019-01-17 05:10:10.526346: step 13715, loss = 0.48638 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:10:11.810747 ops/training.py:65 2019-01-17 05:10:11.810675: step 13716, loss = 0.50294 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:10:13.106836 ops/training.py:65 2019-01-17 05:10:13.106702: step 13717, loss = 0.42867 (24.7 examples/sec; 1.295 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:10:14.396135 ops/training.py:65 2019-01-17 05:10:14.396054: step 13718, loss = 0.57293 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:10:15.682917 ops/training.py:65 2019-01-17 05:10:15.682822: step 13719, loss = 0.52751 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:10:16.971705 ops/training.py:65 2019-01-17 05:10:16.971631: step 13720, loss = 0.45215 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:10:18.259105 ops/training.py:65 2019-01-17 05:10:18.259024: step 13721, loss = 0.64248 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:10:19.541991 ops/training.py:65 2019-01-17 05:10:19.541923: step 13722, loss = 0.56229 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:10:20.831364 ops/training.py:65 2019-01-17 05:10:20.831272: step 13723, loss = 0.42328 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:10:22.119835 ops/training.py:65 2019-01-17 05:10:22.119769: step 13724, loss = 0.53323 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:10:23.407768 ops/training.py:65 2019-01-17 05:10:23.407688: step 13725, loss = 0.46824 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:10:24.697357 ops/training.py:65 2019-01-17 05:10:24.697276: step 13726, loss = 0.63818 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:10:25.986179 ops/training.py:65 2019-01-17 05:10:25.986104: step 13727, loss = 0.38894 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:10:27.273389 ops/training.py:65 2019-01-17 05:10:27.273303: step 13728, loss = 0.53200 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:10:28.561343 ops/training.py:65 2019-01-17 05:10:28.561244: step 13729, loss = 0.54033 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:10:29.850510 ops/training.py:65 2019-01-17 05:10:29.850434: step 13730, loss = 0.52622 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:10:31.134195 ops/training.py:65 2019-01-17 05:10:31.134127: step 13731, loss = 0.49751 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:10:32.417504 ops/training.py:65 2019-01-17 05:10:32.417402: step 13732, loss = 0.42984 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:10:33.708325 ops/training.py:65 2019-01-17 05:10:33.708204: step 13733, loss = 0.45190 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:10:34.993431 ops/training.py:65 2019-01-17 05:10:34.993365: step 13734, loss = 0.45131 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:10:36.278360 ops/training.py:65 2019-01-17 05:10:36.278269: step 13735, loss = 0.58840 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:10:37.562372 ops/training.py:65 2019-01-17 05:10:37.562340: step 13736, loss = 0.53101 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:10:38.849802 ops/training.py:65 2019-01-17 05:10:38.849701: step 13737, loss = 0.43951 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:10:40.140689 ops/training.py:65 2019-01-17 05:10:40.140626: step 13738, loss = 0.53526 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:10:41.428469 ops/training.py:65 2019-01-17 05:10:41.428374: step 13739, loss = 0.52947 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:10:42.718771 ops/training.py:65 2019-01-17 05:10:42.718689: step 13740, loss = 0.54269 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:10:44.006633 ops/training.py:65 2019-01-17 05:10:44.006558: step 13741, loss = 0.57741 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:10:45.294823 ops/training.py:65 2019-01-17 05:10:45.294738: step 13742, loss = 0.58972 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:10:46.583398 ops/training.py:65 2019-01-17 05:10:46.583316: step 13743, loss = 0.62007 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:10:47.869960 ops/training.py:65 2019-01-17 05:10:47.869884: step 13744, loss = 0.62418 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 05:10:49.157093 ops/training.py:65 2019-01-17 05:10:49.157018: step 13745, loss = 0.67761 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 05:10:50.444405 ops/training.py:65 2019-01-17 05:10:50.444316: step 13746, loss = 0.52104 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:10:51.733181 ops/training.py:65 2019-01-17 05:10:51.733085: step 13747, loss = 0.41373 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:10:53.021366 ops/training.py:65 2019-01-17 05:10:53.021273: step 13748, loss = 0.56981 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:10:54.309254 ops/training.py:65 2019-01-17 05:10:54.309179: step 13749, loss = 0.48068 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:10:55.598119 ops/training.py:65 2019-01-17 05:10:55.598046: step 13750, loss = 0.56293 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:10:56.886063 ops/training.py:65 2019-01-17 05:10:56.885987: step 13751, loss = 0.57300 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:10:58.173561 ops/training.py:65 2019-01-17 05:10:58.173482: step 13752, loss = 0.54561 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:10:59.461349 ops/training.py:65 2019-01-17 05:10:59.461255: step 13753, loss = 0.50198 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:11:00.748825 ops/training.py:65 2019-01-17 05:11:00.748753: step 13754, loss = 0.39325 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:11:02.036659 ops/training.py:65 2019-01-17 05:11:02.036583: step 13755, loss = 0.55281 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:11:03.325369 ops/training.py:65 2019-01-17 05:11:03.325298: step 13756, loss = 0.57617 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:11:04.613008 ops/training.py:65 2019-01-17 05:11:04.612907: step 13757, loss = 0.44938 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:11:05.899722 ops/training.py:65 2019-01-17 05:11:05.899648: step 13758, loss = 0.48889 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:11:07.187397 ops/training.py:65 2019-01-17 05:11:07.187300: step 13759, loss = 0.50221 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:11:08.472370 ops/training.py:65 2019-01-17 05:11:08.472295: step 13760, loss = 0.56916 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:11:09.760790 ops/training.py:65 2019-01-17 05:11:09.760723: step 13761, loss = 0.56550 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:11:11.050041 ops/training.py:65 2019-01-17 05:11:11.049962: step 13762, loss = 0.50537 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:11:12.336729 ops/training.py:65 2019-01-17 05:11:12.336633: step 13763, loss = 0.48099 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:11:13.624929 ops/training.py:65 2019-01-17 05:11:13.624840: step 13764, loss = 0.40080 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:11:14.912560 ops/training.py:65 2019-01-17 05:11:14.912478: step 13765, loss = 0.55562 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:11:16.196117 ops/training.py:65 2019-01-17 05:11:16.196046: step 13766, loss = 0.48865 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:11:17.484785 ops/training.py:65 2019-01-17 05:11:17.484690: step 13767, loss = 0.56416 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:11:18.774142 ops/training.py:65 2019-01-17 05:11:18.774051: step 13768, loss = 0.49745 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:11:20.062877 ops/training.py:65 2019-01-17 05:11:20.062788: step 13769, loss = 0.59283 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:11:21.347150 ops/training.py:65 2019-01-17 05:11:21.347085: step 13770, loss = 0.47693 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:11:22.635458 ops/training.py:65 2019-01-17 05:11:22.635360: step 13771, loss = 0.52699 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:11:23.919914 ops/training.py:65 2019-01-17 05:11:23.919850: step 13772, loss = 0.43317 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:11:25.204285 ops/training.py:65 2019-01-17 05:11:25.204184: step 13773, loss = 0.36405 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:11:26.495591 ops/training.py:65 2019-01-17 05:11:26.495486: step 13774, loss = 0.49342 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:11:27.787114 ops/training.py:65 2019-01-17 05:11:27.787045: step 13775, loss = 0.53637 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:11:29.071863 ops/training.py:65 2019-01-17 05:11:29.071789: step 13776, loss = 0.49413 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:11:30.358515 ops/training.py:65 2019-01-17 05:11:30.358404: step 13777, loss = 0.40350 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:11:31.649880 ops/training.py:65 2019-01-17 05:11:31.649775: step 13778, loss = 0.54216 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:11:32.941468 ops/training.py:65 2019-01-17 05:11:32.941395: step 13779, loss = 0.47757 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:11:34.231680 ops/training.py:65 2019-01-17 05:11:34.231605: step 13780, loss = 0.55239 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:11:35.519954 ops/training.py:65 2019-01-17 05:11:35.519857: step 13781, loss = 0.53006 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:11:36.806531 ops/training.py:65 2019-01-17 05:11:36.806454: step 13782, loss = 0.54940 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:11:38.091179 ops/training.py:65 2019-01-17 05:11:38.091107: step 13783, loss = 0.45955 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:11:39.374577 ops/training.py:65 2019-01-17 05:11:39.374466: step 13784, loss = 0.57545 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:11:40.662609 ops/training.py:65 2019-01-17 05:11:40.662507: step 13785, loss = 0.55919 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:11:41.954329 ops/training.py:65 2019-01-17 05:11:41.954252: step 13786, loss = 0.50970 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:11:43.243225 ops/training.py:65 2019-01-17 05:11:43.243145: step 13787, loss = 0.41129 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:11:44.531444 ops/training.py:65 2019-01-17 05:11:44.531371: step 13788, loss = 0.54245 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:11:45.815923 ops/training.py:65 2019-01-17 05:11:45.815853: step 13789, loss = 0.49563 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:11:47.103805 ops/training.py:65 2019-01-17 05:11:47.103688: step 13790, loss = 0.53144 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:11:48.392044 ops/training.py:65 2019-01-17 05:11:48.391979: step 13791, loss = 0.49608 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:11:49.681433 ops/training.py:65 2019-01-17 05:11:49.681360: step 13792, loss = 0.49755 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:11:50.968923 ops/training.py:65 2019-01-17 05:11:50.968837: step 13793, loss = 0.47069 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:11:52.257075 ops/training.py:65 2019-01-17 05:11:52.256983: step 13794, loss = 0.57903 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:11:53.546242 ops/training.py:65 2019-01-17 05:11:53.546157: step 13795, loss = 0.50748 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:11:54.835018 ops/training.py:65 2019-01-17 05:11:54.834944: step 13796, loss = 0.53592 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:11:56.124270 ops/training.py:65 2019-01-17 05:11:56.124202: step 13797, loss = 0.48243 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:11:57.407923 ops/training.py:65 2019-01-17 05:11:57.407862: step 13798, loss = 0.57123 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:11:58.692619 ops/training.py:65 2019-01-17 05:11:58.692521: step 13799, loss = 0.46928 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:11:59.976072 ops/training.py:65 2019-01-17 05:11:59.976004: step 13800, loss = 0.52743 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:12:01.261734 ops/training.py:65 2019-01-17 05:12:01.261640: step 13801, loss = 0.41974 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:12:02.545659 ops/training.py:65 2019-01-17 05:12:02.545559: step 13802, loss = 0.47760 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:12:03.836612 ops/training.py:65 2019-01-17 05:12:03.836520: step 13803, loss = 0.59800 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:12:05.122968 ops/training.py:65 2019-01-17 05:12:05.122902: step 13804, loss = 0.52661 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:12:06.411032 ops/training.py:65 2019-01-17 05:12:06.410939: step 13805, loss = 0.64825 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:12:07.701205 ops/training.py:65 2019-01-17 05:12:07.701125: step 13806, loss = 0.55771 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:12:08.989406 ops/training.py:65 2019-01-17 05:12:08.989317: step 13807, loss = 0.50531 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:12:10.277516 ops/training.py:65 2019-01-17 05:12:10.277440: step 13808, loss = 0.51629 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:12:11.565544 ops/training.py:65 2019-01-17 05:12:11.565476: step 13809, loss = 0.44911 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:12:12.853298 ops/training.py:65 2019-01-17 05:12:12.853228: step 13810, loss = 0.51261 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:12:14.140935 ops/training.py:65 2019-01-17 05:12:14.140846: step 13811, loss = 0.55908 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:12:15.427838 ops/training.py:65 2019-01-17 05:12:15.427766: step 13812, loss = 0.52849 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:12:16.716827 ops/training.py:65 2019-01-17 05:12:16.716753: step 13813, loss = 0.58225 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:12:18.001274 ops/training.py:65 2019-01-17 05:12:18.001198: step 13814, loss = 0.45390 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:12:19.289342 ops/training.py:65 2019-01-17 05:12:19.289270: step 13815, loss = 0.61229 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:12:20.578105 ops/training.py:65 2019-01-17 05:12:20.578033: step 13816, loss = 0.54367 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:12:21.866408 ops/training.py:65 2019-01-17 05:12:21.866336: step 13817, loss = 0.60198 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:12:23.156114 ops/training.py:65 2019-01-17 05:12:23.156039: step 13818, loss = 0.51991 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:12:24.445177 ops/training.py:65 2019-01-17 05:12:24.445099: step 13819, loss = 0.46699 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:12:25.728471 ops/training.py:65 2019-01-17 05:12:25.728402: step 13820, loss = 0.53502 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:12:27.017040 ops/training.py:65 2019-01-17 05:12:27.016927: step 13821, loss = 0.45334 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:12:28.305882 ops/training.py:65 2019-01-17 05:12:28.305781: step 13822, loss = 0.57823 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:12:29.594643 ops/training.py:65 2019-01-17 05:12:29.594568: step 13823, loss = 0.51245 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:12:30.878039 ops/training.py:65 2019-01-17 05:12:30.877974: step 13824, loss = 0.55778 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:12:32.163820 ops/training.py:65 2019-01-17 05:12:32.163727: step 13825, loss = 0.52021 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:12:33.454146 ops/training.py:65 2019-01-17 05:12:33.454018: step 13826, loss = 0.54159 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:12:34.747178 ops/training.py:65 2019-01-17 05:12:34.747038: step 13827, loss = 0.51778 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:12:36.037572 ops/training.py:65 2019-01-17 05:12:36.037496: step 13828, loss = 0.52580 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:12:37.323619 ops/training.py:65 2019-01-17 05:12:37.323534: step 13829, loss = 0.44919 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:12:38.608261 ops/training.py:65 2019-01-17 05:12:38.608151: step 13830, loss = 0.49900 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:12:39.900217 ops/training.py:65 2019-01-17 05:12:39.900114: step 13831, loss = 0.53907 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:12:41.191603 ops/training.py:65 2019-01-17 05:12:41.191534: step 13832, loss = 0.53665 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:12:42.475598 ops/training.py:65 2019-01-17 05:12:42.475531: step 13833, loss = 0.44343 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:12:43.756029 ops/training.py:65 2019-01-17 05:12:43.755930: step 13834, loss = 0.49443 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:12:45.043162 ops/training.py:65 2019-01-17 05:12:45.043060: step 13835, loss = 0.49427 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:12:46.327178 ops/training.py:65 2019-01-17 05:12:46.327078: step 13836, loss = 0.55703 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:12:47.619295 ops/training.py:65 2019-01-17 05:12:47.619195: step 13837, loss = 0.52147 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:12:48.904801 ops/training.py:65 2019-01-17 05:12:48.904736: step 13838, loss = 0.44893 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:12:50.188809 ops/training.py:65 2019-01-17 05:12:50.188704: step 13839, loss = 0.56671 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:12:51.480367 ops/training.py:65 2019-01-17 05:12:51.480261: step 13840, loss = 0.63579 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:12:52.771514 ops/training.py:65 2019-01-17 05:12:52.771442: step 13841, loss = 0.53279 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:12:54.059655 ops/training.py:65 2019-01-17 05:12:54.059582: step 13842, loss = 0.46386 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:12:55.349257 ops/training.py:65 2019-01-17 05:12:55.349187: step 13843, loss = 0.50826 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:12:56.636720 ops/training.py:65 2019-01-17 05:12:56.636654: step 13844, loss = 0.49957 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:12:57.931473 ops/training.py:65 2019-01-17 05:12:57.931407: step 13845, loss = 0.51760 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:12:59.220237 ops/training.py:65 2019-01-17 05:12:59.220164: step 13846, loss = 0.43361 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:13:00.507941 ops/training.py:65 2019-01-17 05:13:00.507865: step 13847, loss = 0.52747 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:13:01.797085 ops/training.py:65 2019-01-17 05:13:01.797005: step 13848, loss = 0.54146 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:13:03.081523 ops/training.py:65 2019-01-17 05:13:03.081458: step 13849, loss = 0.64447 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:13:04.370150 ops/training.py:65 2019-01-17 05:13:04.370049: step 13850, loss = 0.47156 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:13:05.654681 ops/training.py:65 2019-01-17 05:13:05.654619: step 13851, loss = 0.52722 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:13:06.938293 ops/training.py:65 2019-01-17 05:13:06.938179: step 13852, loss = 0.49076 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:13:08.230349 ops/training.py:65 2019-01-17 05:13:08.230248: step 13853, loss = 0.52928 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:13:09.521158 ops/training.py:65 2019-01-17 05:13:09.521086: step 13854, loss = 0.43424 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:13:10.810795 ops/training.py:65 2019-01-17 05:13:10.810722: step 13855, loss = 0.52283 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:13:12.094056 ops/training.py:65 2019-01-17 05:13:12.093993: step 13856, loss = 0.45831 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:13:13.378723 ops/training.py:65 2019-01-17 05:13:13.378639: step 13857, loss = 0.47827 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:13:14.663118 ops/training.py:65 2019-01-17 05:13:14.663019: step 13858, loss = 0.58240 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:13:15.950020 ops/training.py:65 2019-01-17 05:13:15.949915: step 13859, loss = 0.58620 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:13:17.234395 ops/training.py:65 2019-01-17 05:13:17.234290: step 13860, loss = 0.54233 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:13:18.522128 ops/training.py:65 2019-01-17 05:13:18.522026: step 13861, loss = 0.39288 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:13:19.812359 ops/training.py:65 2019-01-17 05:13:19.812254: step 13862, loss = 0.66642 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:13:21.102700 ops/training.py:65 2019-01-17 05:13:21.102631: step 13863, loss = 0.50859 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:13:22.391190 ops/training.py:65 2019-01-17 05:13:22.391109: step 13864, loss = 0.51790 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:13:23.680217 ops/training.py:65 2019-01-17 05:13:23.680130: step 13865, loss = 0.46910 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:13:24.968077 ops/training.py:65 2019-01-17 05:13:24.968006: step 13866, loss = 0.46223 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:13:26.256531 ops/training.py:65 2019-01-17 05:13:26.256460: step 13867, loss = 0.51711 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:13:27.545338 ops/training.py:65 2019-01-17 05:13:27.545267: step 13868, loss = 0.41703 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:13:28.829292 ops/training.py:65 2019-01-17 05:13:28.829226: step 13869, loss = 0.49959 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:13:30.112785 ops/training.py:65 2019-01-17 05:13:30.112679: step 13870, loss = 0.54344 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:13:31.399810 ops/training.py:65 2019-01-17 05:13:31.399708: step 13871, loss = 0.43575 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:13:32.683340 ops/training.py:65 2019-01-17 05:13:32.683243: step 13872, loss = 0.44677 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:13:33.976017 ops/training.py:65 2019-01-17 05:13:33.975926: step 13873, loss = 0.46857 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:13:35.266189 ops/training.py:65 2019-01-17 05:13:35.266110: step 13874, loss = 0.57109 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:13:36.554671 ops/training.py:65 2019-01-17 05:13:36.554596: step 13875, loss = 0.53886 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:13:37.843149 ops/training.py:65 2019-01-17 05:13:37.843077: step 13876, loss = 0.44581 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:13:39.133562 ops/training.py:65 2019-01-17 05:13:39.133479: step 13877, loss = 0.53327 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:13:40.421170 ops/training.py:65 2019-01-17 05:13:40.421099: step 13878, loss = 0.48789 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:13:41.708860 ops/training.py:65 2019-01-17 05:13:41.708790: step 13879, loss = 0.39845 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:13:42.997796 ops/training.py:65 2019-01-17 05:13:42.997725: step 13880, loss = 0.54844 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:13:44.284810 ops/training.py:65 2019-01-17 05:13:44.284737: step 13881, loss = 0.50939 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:13:45.572312 ops/training.py:65 2019-01-17 05:13:45.572243: step 13882, loss = 0.48017 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:13:46.859742 ops/training.py:65 2019-01-17 05:13:46.859673: step 13883, loss = 0.59771 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:13:48.148470 ops/training.py:65 2019-01-17 05:13:48.148392: step 13884, loss = 0.39375 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:13:49.437435 ops/training.py:65 2019-01-17 05:13:49.437363: step 13885, loss = 0.50185 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:13:50.724616 ops/training.py:65 2019-01-17 05:13:50.724547: step 13886, loss = 0.49500 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:13:52.011112 ops/training.py:65 2019-01-17 05:13:52.011035: step 13887, loss = 0.48561 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:13:53.296800 ops/training.py:65 2019-01-17 05:13:53.296728: step 13888, loss = 0.53489 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:13:54.584414 ops/training.py:65 2019-01-17 05:13:54.584334: step 13889, loss = 0.40331 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:13:55.872918 ops/training.py:65 2019-01-17 05:13:55.872839: step 13890, loss = 0.46245 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:13:57.161815 ops/training.py:65 2019-01-17 05:13:57.161744: step 13891, loss = 0.57020 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:13:58.449840 ops/training.py:65 2019-01-17 05:13:58.449766: step 13892, loss = 0.43823 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:13:59.734189 ops/training.py:65 2019-01-17 05:13:59.734130: step 13893, loss = 0.55468 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:14:01.024745 ops/training.py:65 2019-01-17 05:14:01.024640: step 13894, loss = 0.51561 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:14:02.314425 ops/training.py:65 2019-01-17 05:14:02.314348: step 13895, loss = 0.56034 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:14:03.602199 ops/training.py:65 2019-01-17 05:14:03.602121: step 13896, loss = 0.49924 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:14:04.889602 ops/training.py:65 2019-01-17 05:14:04.889523: step 13897, loss = 0.51964 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:14:06.177144 ops/training.py:65 2019-01-17 05:14:06.177041: step 13898, loss = 0.51787 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:14:07.464711 ops/training.py:65 2019-01-17 05:14:07.464640: step 13899, loss = 0.56363 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:14:08.751657 ops/training.py:65 2019-01-17 05:14:08.751546: step 13900, loss = 0.50241 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:14:10.039208 ops/training.py:65 2019-01-17 05:14:10.039126: step 13901, loss = 0.63815 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:14:11.327348 ops/training.py:65 2019-01-17 05:14:11.327279: step 13902, loss = 0.40728 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:14:12.615260 ops/training.py:65 2019-01-17 05:14:12.615199: step 13903, loss = 0.58074 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:14:13.904018 ops/training.py:65 2019-01-17 05:14:13.903932: step 13904, loss = 0.47587 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:14:15.193089 ops/training.py:65 2019-01-17 05:14:15.193016: step 13905, loss = 0.48332 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:14:16.480670 ops/training.py:65 2019-01-17 05:14:16.480591: step 13906, loss = 0.66154 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:14:17.765210 ops/training.py:65 2019-01-17 05:14:17.765130: step 13907, loss = 0.49643 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:14:19.053256 ops/training.py:65 2019-01-17 05:14:19.053178: step 13908, loss = 0.61832 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:14:20.340438 ops/training.py:65 2019-01-17 05:14:20.340364: step 13909, loss = 0.49732 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:14:21.628536 ops/training.py:65 2019-01-17 05:14:21.628465: step 13910, loss = 0.47771 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:14:22.917015 ops/training.py:65 2019-01-17 05:14:22.916939: step 13911, loss = 0.45680 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:14:24.205831 ops/training.py:65 2019-01-17 05:14:24.205750: step 13912, loss = 0.55875 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:14:25.493800 ops/training.py:65 2019-01-17 05:14:25.493725: step 13913, loss = 0.53807 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:14:26.781594 ops/training.py:65 2019-01-17 05:14:26.781517: step 13914, loss = 0.47476 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:14:28.070095 ops/training.py:65 2019-01-17 05:14:28.070015: step 13915, loss = 0.53826 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:14:29.358854 ops/training.py:65 2019-01-17 05:14:29.358777: step 13916, loss = 0.47196 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:14:30.648688 ops/training.py:65 2019-01-17 05:14:30.648593: step 13917, loss = 0.52463 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:14:31.936831 ops/training.py:65 2019-01-17 05:14:31.936755: step 13918, loss = 0.54099 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:14:33.225116 ops/training.py:65 2019-01-17 05:14:33.225038: step 13919, loss = 0.53158 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:14:34.512066 ops/training.py:65 2019-01-17 05:14:34.511979: step 13920, loss = 0.42605 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:14:35.800074 ops/training.py:65 2019-01-17 05:14:35.799979: step 13921, loss = 0.59466 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:14:37.088232 ops/training.py:65 2019-01-17 05:14:37.088153: step 13922, loss = 0.44190 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:14:38.377687 ops/training.py:65 2019-01-17 05:14:38.377605: step 13923, loss = 0.57441 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:14:39.667203 ops/training.py:65 2019-01-17 05:14:39.667127: step 13924, loss = 0.45157 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:14:40.953290 ops/training.py:65 2019-01-17 05:14:40.953192: step 13925, loss = 0.47835 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:14:42.244159 ops/training.py:65 2019-01-17 05:14:42.244069: step 13926, loss = 0.55575 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:14:43.534855 ops/training.py:65 2019-01-17 05:14:43.534776: step 13927, loss = 0.59628 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:14:44.823521 ops/training.py:65 2019-01-17 05:14:44.823438: step 13928, loss = 0.46955 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:14:46.111951 ops/training.py:65 2019-01-17 05:14:46.111844: step 13929, loss = 0.51083 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:14:47.398112 ops/training.py:65 2019-01-17 05:14:47.398030: step 13930, loss = 0.50139 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:14:48.685860 ops/training.py:65 2019-01-17 05:14:48.685787: step 13931, loss = 0.54832 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:14:49.973698 ops/training.py:65 2019-01-17 05:14:49.973618: step 13932, loss = 0.45125 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:14:51.261606 ops/training.py:65 2019-01-17 05:14:51.261526: step 13933, loss = 0.44693 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:14:52.549961 ops/training.py:65 2019-01-17 05:14:52.549886: step 13934, loss = 0.55351 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:14:53.835033 ops/training.py:65 2019-01-17 05:14:53.834956: step 13935, loss = 0.62075 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:14:55.123728 ops/training.py:65 2019-01-17 05:14:55.123631: step 13936, loss = 0.50156 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:14:56.411868 ops/training.py:65 2019-01-17 05:14:56.411776: step 13937, loss = 0.46022 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:14:57.696422 ops/training.py:65 2019-01-17 05:14:57.696354: step 13938, loss = 0.44432 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:14:58.980276 ops/training.py:65 2019-01-17 05:14:58.980168: step 13939, loss = 0.49122 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:15:00.267337 ops/training.py:65 2019-01-17 05:15:00.267233: step 13940, loss = 0.40111 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:15:01.551969 ops/training.py:65 2019-01-17 05:15:01.551866: step 13941, loss = 0.58875 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:15:02.842983 ops/training.py:65 2019-01-17 05:15:02.842883: step 13942, loss = 0.43227 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:15:04.129523 ops/training.py:65 2019-01-17 05:15:04.129456: step 13943, loss = 0.49202 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:15:05.419122 ops/training.py:65 2019-01-17 05:15:05.419016: step 13944, loss = 0.57309 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:15:06.708781 ops/training.py:65 2019-01-17 05:15:06.708708: step 13945, loss = 0.55866 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:15:07.992409 ops/training.py:65 2019-01-17 05:15:07.992345: step 13946, loss = 0.40539 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:15:09.276713 ops/training.py:65 2019-01-17 05:15:09.276573: step 13947, loss = 0.51260 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:15:10.569053 ops/training.py:65 2019-01-17 05:15:10.568909: step 13948, loss = 0.50045 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:15:11.855194 ops/training.py:65 2019-01-17 05:15:11.855135: step 13949, loss = 0.48030 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:15:13.139372 ops/training.py:65 2019-01-17 05:15:13.139276: step 13950, loss = 0.39007 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:15:14.426742 ops/training.py:65 2019-01-17 05:15:14.426639: step 13951, loss = 0.57680 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:15:15.717141 ops/training.py:65 2019-01-17 05:15:15.717037: step 13952, loss = 0.47605 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:15:17.003053 ops/training.py:65 2019-01-17 05:15:17.002986: step 13953, loss = 0.42354 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:15:18.287794 ops/training.py:65 2019-01-17 05:15:18.287695: step 13954, loss = 0.44324 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:15:19.568770 ops/training.py:65 2019-01-17 05:15:19.568669: step 13955, loss = 0.60578 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:15:20.860362 ops/training.py:65 2019-01-17 05:15:20.860255: step 13956, loss = 0.51396 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:15:22.151310 ops/training.py:65 2019-01-17 05:15:22.151237: step 13957, loss = 0.51500 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:15:23.439770 ops/training.py:65 2019-01-17 05:15:23.439696: step 13958, loss = 0.55235 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:15:24.728466 ops/training.py:65 2019-01-17 05:15:24.728390: step 13959, loss = 0.61283 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:15:26.016978 ops/training.py:65 2019-01-17 05:15:26.016905: step 13960, loss = 0.45515 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:15:27.304917 ops/training.py:65 2019-01-17 05:15:27.304829: step 13961, loss = 0.59268 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:15:28.593603 ops/training.py:65 2019-01-17 05:15:28.593508: step 13962, loss = 0.36602 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:15:29.882135 ops/training.py:65 2019-01-17 05:15:29.882065: step 13963, loss = 0.52648 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:15:31.169683 ops/training.py:65 2019-01-17 05:15:31.169611: step 13964, loss = 0.51400 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:15:32.457905 ops/training.py:65 2019-01-17 05:15:32.457833: step 13965, loss = 0.54255 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:15:33.745910 ops/training.py:65 2019-01-17 05:15:33.745832: step 13966, loss = 0.50092 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:15:35.033985 ops/training.py:65 2019-01-17 05:15:35.033918: step 13967, loss = 0.55866 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:15:36.321992 ops/training.py:65 2019-01-17 05:15:36.321919: step 13968, loss = 0.47513 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:15:37.609807 ops/training.py:65 2019-01-17 05:15:37.609730: step 13969, loss = 0.53942 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:15:38.898224 ops/training.py:65 2019-01-17 05:15:38.898147: step 13970, loss = 0.45875 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:15:40.185918 ops/training.py:65 2019-01-17 05:15:40.185841: step 13971, loss = 0.48976 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:15:41.475517 ops/training.py:65 2019-01-17 05:15:41.475435: step 13972, loss = 0.59401 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:15:42.765363 ops/training.py:65 2019-01-17 05:15:42.765283: step 13973, loss = 0.52336 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:15:44.052317 ops/training.py:65 2019-01-17 05:15:44.052240: step 13974, loss = 0.56297 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:15:45.341949 ops/training.py:65 2019-01-17 05:15:45.341878: step 13975, loss = 0.49562 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:15:46.629836 ops/training.py:65 2019-01-17 05:15:46.629740: step 13976, loss = 0.57152 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:15:47.912978 ops/training.py:65 2019-01-17 05:15:47.912911: step 13977, loss = 0.44527 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:15:49.200194 ops/training.py:65 2019-01-17 05:15:49.200086: step 13978, loss = 0.42820 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:15:50.488248 ops/training.py:65 2019-01-17 05:15:50.488151: step 13979, loss = 0.45227 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:15:51.774193 ops/training.py:65 2019-01-17 05:15:51.774119: step 13980, loss = 0.55122 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:15:53.056676 ops/training.py:65 2019-01-17 05:15:53.056582: step 13981, loss = 0.55316 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:15:54.340254 ops/training.py:65 2019-01-17 05:15:54.340150: step 13982, loss = 0.46914 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:15:55.627569 ops/training.py:65 2019-01-17 05:15:55.627465: step 13983, loss = 0.61594 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:15:56.912302 ops/training.py:65 2019-01-17 05:15:56.912211: step 13984, loss = 0.53844 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:15:58.201597 ops/training.py:65 2019-01-17 05:15:58.201495: step 13985, loss = 0.51358 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:15:59.490072 ops/training.py:65 2019-01-17 05:15:59.489995: step 13986, loss = 0.53990 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:16:00.778172 ops/training.py:65 2019-01-17 05:16:00.778099: step 13987, loss = 0.46146 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:16:02.065925 ops/training.py:65 2019-01-17 05:16:02.065849: step 13988, loss = 0.51547 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:16:03.353741 ops/training.py:65 2019-01-17 05:16:03.353662: step 13989, loss = 0.51729 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:16:04.637333 ops/training.py:65 2019-01-17 05:16:04.637261: step 13990, loss = 0.50505 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:16:05.921116 ops/training.py:65 2019-01-17 05:16:05.921069: step 13991, loss = 0.52046 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:16:07.210526 ops/training.py:65 2019-01-17 05:16:07.210421: step 13992, loss = 0.49319 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:16:08.495277 ops/training.py:65 2019-01-17 05:16:08.495170: step 13993, loss = 0.53387 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:16:09.781026 ops/training.py:65 2019-01-17 05:16:09.780914: step 13994, loss = 0.60635 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:16:11.061201 ops/training.py:65 2019-01-17 05:16:11.061095: step 13995, loss = 0.74046 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 05:16:12.346397 ops/training.py:65 2019-01-17 05:16:12.346267: step 13996, loss = 0.42766 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:16:13.637896 ops/training.py:65 2019-01-17 05:16:13.637757: step 13997, loss = 0.50234 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:16:14.924197 ops/training.py:65 2019-01-17 05:16:14.924126: step 13998, loss = 0.59127 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:16:16.208465 ops/training.py:65 2019-01-17 05:16:16.208370: step 13999, loss = 0.54900 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:22:22.178262 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I4672 2019-01-17 05:22:22.179192 ops/training.py:41 2019-01-17 05:22:22.179141: step 14000, loss = 0.53 (0.1 examples/sec; 364.678 sec/batch) | Training accuracy = 0.71875 | Validation accuracy = 0.51215 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_23_33_01_706250
I4672 2019-01-17 05:22:23.464049 ops/training.py:65 2019-01-17 05:22:23.463918: step 14001, loss = 0.64893 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:22:24.746954 ops/training.py:65 2019-01-17 05:22:24.746829: step 14002, loss = 0.73071 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 05:22:26.034437 ops/training.py:65 2019-01-17 05:22:26.034330: step 14003, loss = 0.49816 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:22:27.322941 ops/training.py:65 2019-01-17 05:22:27.322844: step 14004, loss = 0.59622 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:22:28.606984 ops/training.py:65 2019-01-17 05:22:28.606914: step 14005, loss = 0.69039 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 05:22:29.890540 ops/training.py:65 2019-01-17 05:22:29.890465: step 14006, loss = 0.58505 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:22:31.180741 ops/training.py:65 2019-01-17 05:22:31.180634: step 14007, loss = 0.52536 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:22:32.473264 ops/training.py:65 2019-01-17 05:22:32.473192: step 14008, loss = 0.58549 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:22:33.760949 ops/training.py:65 2019-01-17 05:22:33.760880: step 14009, loss = 0.62038 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:22:35.049773 ops/training.py:65 2019-01-17 05:22:35.049697: step 14010, loss = 0.58462 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:22:36.338576 ops/training.py:65 2019-01-17 05:22:36.338498: step 14011, loss = 0.50959 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:22:37.626178 ops/training.py:65 2019-01-17 05:22:37.626097: step 14012, loss = 0.42934 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:22:38.913782 ops/training.py:65 2019-01-17 05:22:38.913698: step 14013, loss = 0.44190 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:22:40.197241 ops/training.py:65 2019-01-17 05:22:40.197174: step 14014, loss = 0.59784 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:22:41.477926 ops/training.py:65 2019-01-17 05:22:41.477852: step 14015, loss = 0.53474 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:22:42.766804 ops/training.py:65 2019-01-17 05:22:42.766700: step 14016, loss = 0.62027 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:22:44.059624 ops/training.py:65 2019-01-17 05:22:44.059520: step 14017, loss = 0.54202 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:22:45.349293 ops/training.py:65 2019-01-17 05:22:45.349239: step 14018, loss = 0.48702 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:22:46.638702 ops/training.py:65 2019-01-17 05:22:46.638658: step 14019, loss = 0.61805 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:22:47.927126 ops/training.py:65 2019-01-17 05:22:47.927071: step 14020, loss = 0.49339 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:22:49.210921 ops/training.py:65 2019-01-17 05:22:49.210847: step 14021, loss = 0.50962 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:22:50.496440 ops/training.py:65 2019-01-17 05:22:50.496334: step 14022, loss = 0.45505 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:22:51.780553 ops/training.py:65 2019-01-17 05:22:51.780453: step 14023, loss = 0.49760 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:22:53.067685 ops/training.py:65 2019-01-17 05:22:53.067605: step 14024, loss = 0.47856 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:22:54.351441 ops/training.py:65 2019-01-17 05:22:54.351342: step 14025, loss = 0.54679 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:22:55.638274 ops/training.py:65 2019-01-17 05:22:55.638241: step 14026, loss = 0.38849 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:22:56.926328 ops/training.py:65 2019-01-17 05:22:56.926294: step 14027, loss = 0.54865 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:22:58.209619 ops/training.py:65 2019-01-17 05:22:58.209521: step 14028, loss = 0.52926 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:22:59.496929 ops/training.py:65 2019-01-17 05:22:59.496837: step 14029, loss = 0.52303 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:23:00.783019 ops/training.py:65 2019-01-17 05:23:00.782980: step 14030, loss = 0.41033 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:23:02.066717 ops/training.py:65 2019-01-17 05:23:02.066657: step 14031, loss = 0.52589 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:23:03.353482 ops/training.py:65 2019-01-17 05:23:03.353345: step 14032, loss = 0.58293 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:23:04.637569 ops/training.py:65 2019-01-17 05:23:04.637498: step 14033, loss = 0.49228 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:23:05.926934 ops/training.py:65 2019-01-17 05:23:05.926828: step 14034, loss = 0.50044 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:23:07.211410 ops/training.py:65 2019-01-17 05:23:07.211346: step 14035, loss = 0.57549 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:23:08.495000 ops/training.py:65 2019-01-17 05:23:08.494907: step 14036, loss = 0.45538 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:23:09.779772 ops/training.py:65 2019-01-17 05:23:09.779657: step 14037, loss = 0.50992 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:23:11.070119 ops/training.py:65 2019-01-17 05:23:11.070043: step 14038, loss = 0.43080 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:23:12.354258 ops/training.py:65 2019-01-17 05:23:12.354187: step 14039, loss = 0.45708 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:23:13.635127 ops/training.py:65 2019-01-17 05:23:13.635038: step 14040, loss = 0.51416 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:23:14.921329 ops/training.py:65 2019-01-17 05:23:14.921184: step 14041, loss = 0.50100 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:23:16.208389 ops/training.py:65 2019-01-17 05:23:16.208276: step 14042, loss = 0.47034 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:23:17.495144 ops/training.py:65 2019-01-17 05:23:17.495046: step 14043, loss = 0.42772 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:23:18.783257 ops/training.py:65 2019-01-17 05:23:18.783101: step 14044, loss = 0.50171 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:23:20.069392 ops/training.py:65 2019-01-17 05:23:20.069286: step 14045, loss = 0.42543 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:23:21.355903 ops/training.py:65 2019-01-17 05:23:21.355800: step 14046, loss = 0.53390 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:23:22.640664 ops/training.py:65 2019-01-17 05:23:22.640553: step 14047, loss = 0.44063 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:23:23.928664 ops/training.py:65 2019-01-17 05:23:23.928560: step 14048, loss = 0.51173 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:23:25.211999 ops/training.py:65 2019-01-17 05:23:25.211898: step 14049, loss = 0.55874 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:23:26.499092 ops/training.py:65 2019-01-17 05:23:26.498933: step 14050, loss = 0.44595 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:23:27.786830 ops/training.py:65 2019-01-17 05:23:27.786735: step 14051, loss = 0.43734 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:23:29.073019 ops/training.py:65 2019-01-17 05:23:29.072917: step 14052, loss = 0.48304 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:23:30.359324 ops/training.py:65 2019-01-17 05:23:30.359219: step 14053, loss = 0.48563 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:23:31.636728 ops/training.py:65 2019-01-17 05:23:31.636632: step 14054, loss = 0.43920 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:23:32.918059 ops/training.py:65 2019-01-17 05:23:32.917952: step 14055, loss = 0.45684 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:23:34.204839 ops/training.py:65 2019-01-17 05:23:34.204740: step 14056, loss = 0.60386 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:23:35.493112 ops/training.py:65 2019-01-17 05:23:35.492996: step 14057, loss = 0.53415 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:23:36.778928 ops/training.py:65 2019-01-17 05:23:36.778822: step 14058, loss = 0.50021 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:23:38.066713 ops/training.py:65 2019-01-17 05:23:38.066608: step 14059, loss = 0.56307 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:23:39.351874 ops/training.py:65 2019-01-17 05:23:39.351774: step 14060, loss = 0.52408 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:23:40.638578 ops/training.py:65 2019-01-17 05:23:40.638469: step 14061, loss = 0.53230 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:23:41.924564 ops/training.py:65 2019-01-17 05:23:41.924472: step 14062, loss = 0.51299 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:23:43.211972 ops/training.py:65 2019-01-17 05:23:43.211862: step 14063, loss = 0.47625 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:23:44.501928 ops/training.py:65 2019-01-17 05:23:44.501824: step 14064, loss = 0.42245 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:23:45.787064 ops/training.py:65 2019-01-17 05:23:45.786995: step 14065, loss = 0.42083 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:23:47.071065 ops/training.py:65 2019-01-17 05:23:47.070994: step 14066, loss = 0.58005 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:23:48.353696 ops/training.py:65 2019-01-17 05:23:48.353588: step 14067, loss = 0.46486 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:23:49.635561 ops/training.py:65 2019-01-17 05:23:49.635453: step 14068, loss = 0.59334 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:23:50.919851 ops/training.py:65 2019-01-17 05:23:50.919754: step 14069, loss = 0.55387 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:23:52.207500 ops/training.py:65 2019-01-17 05:23:52.207389: step 14070, loss = 0.51010 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:23:53.494275 ops/training.py:65 2019-01-17 05:23:53.494176: step 14071, loss = 0.45062 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:23:54.786255 ops/training.py:65 2019-01-17 05:23:54.786142: step 14072, loss = 0.64942 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:23:56.072390 ops/training.py:65 2019-01-17 05:23:56.072329: step 14073, loss = 0.56614 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:23:57.357689 ops/training.py:65 2019-01-17 05:23:57.357591: step 14074, loss = 0.60007 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:23:58.645195 ops/training.py:65 2019-01-17 05:23:58.645087: step 14075, loss = 0.59712 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:23:59.937120 ops/training.py:65 2019-01-17 05:23:59.937009: step 14076, loss = 0.43762 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:24:01.227963 ops/training.py:65 2019-01-17 05:24:01.227899: step 14077, loss = 0.56361 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:24:02.523468 ops/training.py:65 2019-01-17 05:24:02.523406: step 14078, loss = 0.52498 (24.7 examples/sec; 1.295 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:24:03.810815 ops/training.py:65 2019-01-17 05:24:03.810740: step 14079, loss = 0.47114 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:24:05.100024 ops/training.py:65 2019-01-17 05:24:05.099960: step 14080, loss = 0.58717 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:24:06.390245 ops/training.py:65 2019-01-17 05:24:06.390183: step 14081, loss = 0.36384 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:24:07.678788 ops/training.py:65 2019-01-17 05:24:07.678716: step 14082, loss = 0.50010 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:24:08.964703 ops/training.py:65 2019-01-17 05:24:08.964623: step 14083, loss = 0.34947 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:24:10.250499 ops/training.py:65 2019-01-17 05:24:10.250441: step 14084, loss = 0.57081 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:24:11.536975 ops/training.py:65 2019-01-17 05:24:11.536866: step 14085, loss = 0.47491 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:24:12.829205 ops/training.py:65 2019-01-17 05:24:12.829105: step 14086, loss = 0.55478 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:24:14.120082 ops/training.py:65 2019-01-17 05:24:14.120016: step 14087, loss = 0.56726 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:24:15.404461 ops/training.py:65 2019-01-17 05:24:15.404397: step 14088, loss = 0.50970 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:24:16.689423 ops/training.py:65 2019-01-17 05:24:16.689324: step 14089, loss = 0.38618 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:24:17.979679 ops/training.py:65 2019-01-17 05:24:17.979517: step 14090, loss = 0.54257 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:24:19.267376 ops/training.py:65 2019-01-17 05:24:19.267314: step 14091, loss = 0.47012 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:24:20.553252 ops/training.py:65 2019-01-17 05:24:20.553145: step 14092, loss = 0.56467 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:24:21.844209 ops/training.py:65 2019-01-17 05:24:21.844053: step 14093, loss = 0.45073 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:24:23.132169 ops/training.py:65 2019-01-17 05:24:23.132106: step 14094, loss = 0.48852 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:24:24.416209 ops/training.py:65 2019-01-17 05:24:24.416134: step 14095, loss = 0.53240 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:24:25.708561 ops/training.py:65 2019-01-17 05:24:25.708458: step 14096, loss = 0.51491 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:24:26.994427 ops/training.py:65 2019-01-17 05:24:26.994360: step 14097, loss = 0.49900 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:24:28.283197 ops/training.py:65 2019-01-17 05:24:28.283038: step 14098, loss = 0.52617 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:24:29.564275 ops/training.py:65 2019-01-17 05:24:29.564164: step 14099, loss = 0.51346 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:24:30.857705 ops/training.py:65 2019-01-17 05:24:30.857601: step 14100, loss = 0.60668 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:24:32.147485 ops/training.py:65 2019-01-17 05:24:32.147418: step 14101, loss = 0.50457 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:24:33.431783 ops/training.py:65 2019-01-17 05:24:33.431721: step 14102, loss = 0.48712 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:24:34.720542 ops/training.py:65 2019-01-17 05:24:34.720457: step 14103, loss = 0.41783 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:24:36.014003 ops/training.py:65 2019-01-17 05:24:36.013893: step 14104, loss = 0.50794 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:24:37.300144 ops/training.py:65 2019-01-17 05:24:37.300084: step 14105, loss = 0.55866 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:24:38.590169 ops/training.py:65 2019-01-17 05:24:38.590102: step 14106, loss = 0.53605 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:24:39.879632 ops/training.py:65 2019-01-17 05:24:39.879557: step 14107, loss = 0.46571 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:24:41.160101 ops/training.py:65 2019-01-17 05:24:41.159993: step 14108, loss = 0.50172 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:24:42.447070 ops/training.py:65 2019-01-17 05:24:42.446923: step 14109, loss = 0.53386 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:24:43.730053 ops/training.py:65 2019-01-17 05:24:43.729940: step 14110, loss = 0.48981 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:24:45.019929 ops/training.py:65 2019-01-17 05:24:45.019776: step 14111, loss = 0.60768 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:24:46.308522 ops/training.py:65 2019-01-17 05:24:46.308462: step 14112, loss = 0.53504 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:24:47.598339 ops/training.py:65 2019-01-17 05:24:47.598244: step 14113, loss = 0.45005 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:24:48.888544 ops/training.py:65 2019-01-17 05:24:48.888483: step 14114, loss = 0.60843 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:24:50.173995 ops/training.py:65 2019-01-17 05:24:50.173928: step 14115, loss = 0.55963 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:24:51.451716 ops/training.py:65 2019-01-17 05:24:51.451623: step 14116, loss = 0.46854 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:24:52.736712 ops/training.py:65 2019-01-17 05:24:52.736608: step 14117, loss = 0.47154 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:24:54.016771 ops/training.py:65 2019-01-17 05:24:54.016675: step 14118, loss = 0.43153 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:24:55.307566 ops/training.py:65 2019-01-17 05:24:55.307457: step 14119, loss = 0.48037 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:24:56.597629 ops/training.py:65 2019-01-17 05:24:56.597567: step 14120, loss = 0.43487 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:24:57.881566 ops/training.py:65 2019-01-17 05:24:57.881511: step 14121, loss = 0.49587 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:24:59.166372 ops/training.py:65 2019-01-17 05:24:59.166290: step 14122, loss = 0.58150 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:25:00.454190 ops/training.py:65 2019-01-17 05:25:00.454084: step 14123, loss = 0.39528 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:25:01.740358 ops/training.py:65 2019-01-17 05:25:01.740250: step 14124, loss = 0.44180 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:25:03.024159 ops/training.py:65 2019-01-17 05:25:03.024053: step 14125, loss = 0.62771 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:25:04.317263 ops/training.py:65 2019-01-17 05:25:04.317166: step 14126, loss = 0.50426 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:25:05.608644 ops/training.py:65 2019-01-17 05:25:05.608565: step 14127, loss = 0.48597 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:25:06.896433 ops/training.py:65 2019-01-17 05:25:06.896368: step 14128, loss = 0.42534 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:25:08.180532 ops/training.py:65 2019-01-17 05:25:08.180471: step 14129, loss = 0.47963 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:25:09.464352 ops/training.py:65 2019-01-17 05:25:09.464246: step 14130, loss = 0.50073 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:25:10.745084 ops/training.py:65 2019-01-17 05:25:10.744933: step 14131, loss = 0.49566 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:25:12.037783 ops/training.py:65 2019-01-17 05:25:12.037685: step 14132, loss = 0.65543 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:25:13.324146 ops/training.py:65 2019-01-17 05:25:13.324086: step 14133, loss = 0.42718 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:25:14.604547 ops/training.py:65 2019-01-17 05:25:14.604440: step 14134, loss = 0.46120 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:25:15.896461 ops/training.py:65 2019-01-17 05:25:15.896348: step 14135, loss = 0.37269 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:25:17.187632 ops/training.py:65 2019-01-17 05:25:17.187567: step 14136, loss = 0.61609 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:25:18.477130 ops/training.py:65 2019-01-17 05:25:18.477034: step 14137, loss = 0.38626 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:25:19.767547 ops/training.py:65 2019-01-17 05:25:19.767479: step 14138, loss = 0.54878 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:25:21.056783 ops/training.py:65 2019-01-17 05:25:21.056718: step 14139, loss = 0.39760 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:25:22.341832 ops/training.py:65 2019-01-17 05:25:22.341765: step 14140, loss = 0.54598 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:25:23.626040 ops/training.py:65 2019-01-17 05:25:23.625978: step 14141, loss = 0.44158 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:25:24.911493 ops/training.py:65 2019-01-17 05:25:24.911334: step 14142, loss = 0.52882 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:25:26.202313 ops/training.py:65 2019-01-17 05:25:26.202206: step 14143, loss = 0.55732 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:25:27.494720 ops/training.py:65 2019-01-17 05:25:27.494576: step 14144, loss = 0.45622 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:25:28.784671 ops/training.py:65 2019-01-17 05:25:28.784603: step 14145, loss = 0.53086 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:25:30.068832 ops/training.py:65 2019-01-17 05:25:30.068766: step 14146, loss = 0.48818 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:25:31.352451 ops/training.py:65 2019-01-17 05:25:31.352350: step 14147, loss = 0.51379 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:25:32.636996 ops/training.py:65 2019-01-17 05:25:32.636897: step 14148, loss = 0.51700 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:25:33.924526 ops/training.py:65 2019-01-17 05:25:33.924425: step 14149, loss = 0.47128 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:25:35.202024 ops/training.py:65 2019-01-17 05:25:35.201915: step 14150, loss = 0.46121 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:25:36.494011 ops/training.py:65 2019-01-17 05:25:36.493908: step 14151, loss = 0.46726 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:25:37.785260 ops/training.py:65 2019-01-17 05:25:37.785197: step 14152, loss = 0.45934 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:25:39.069718 ops/training.py:65 2019-01-17 05:25:39.069656: step 14153, loss = 0.47844 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:25:40.359712 ops/training.py:65 2019-01-17 05:25:40.359611: step 14154, loss = 0.52545 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:25:41.645745 ops/training.py:65 2019-01-17 05:25:41.645684: step 14155, loss = 0.57348 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:25:42.929873 ops/training.py:65 2019-01-17 05:25:42.929780: step 14156, loss = 0.46476 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:25:44.222514 ops/training.py:65 2019-01-17 05:25:44.222378: step 14157, loss = 0.46981 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:25:45.513505 ops/training.py:65 2019-01-17 05:25:45.513441: step 14158, loss = 0.39630 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:25:46.797744 ops/training.py:65 2019-01-17 05:25:46.797689: step 14159, loss = 0.42640 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:25:48.090025 ops/training.py:65 2019-01-17 05:25:48.089905: step 14160, loss = 0.43306 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:25:49.377670 ops/training.py:65 2019-01-17 05:25:49.377564: step 14161, loss = 0.48042 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:25:50.669612 ops/training.py:65 2019-01-17 05:25:50.669454: step 14162, loss = 0.55613 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:25:51.954956 ops/training.py:65 2019-01-17 05:25:51.954877: step 14163, loss = 0.50341 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:25:53.240549 ops/training.py:65 2019-01-17 05:25:53.240412: step 14164, loss = 0.41750 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:25:54.526151 ops/training.py:65 2019-01-17 05:25:54.526038: step 14165, loss = 0.49988 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:25:55.816343 ops/training.py:65 2019-01-17 05:25:55.816246: step 14166, loss = 0.49215 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:25:57.102259 ops/training.py:65 2019-01-17 05:25:57.102175: step 14167, loss = 0.52159 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:25:58.391066 ops/training.py:65 2019-01-17 05:25:58.390997: step 14168, loss = 0.45572 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:25:59.675706 ops/training.py:65 2019-01-17 05:25:59.675643: step 14169, loss = 0.52903 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:26:00.958421 ops/training.py:65 2019-01-17 05:26:00.958271: step 14170, loss = 0.53442 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:26:02.245629 ops/training.py:65 2019-01-17 05:26:02.245518: step 14171, loss = 0.54158 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:26:03.537087 ops/training.py:65 2019-01-17 05:26:03.536965: step 14172, loss = 0.53631 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:26:04.823398 ops/training.py:65 2019-01-17 05:26:04.823339: step 14173, loss = 0.46484 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:26:06.102702 ops/training.py:65 2019-01-17 05:26:06.102603: step 14174, loss = 0.40777 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:26:07.394347 ops/training.py:65 2019-01-17 05:26:07.394193: step 14175, loss = 0.52359 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:26:08.680520 ops/training.py:65 2019-01-17 05:26:08.680462: step 14176, loss = 0.49837 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:26:09.965019 ops/training.py:65 2019-01-17 05:26:09.964936: step 14177, loss = 0.45690 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:26:11.249980 ops/training.py:65 2019-01-17 05:26:11.249871: step 14178, loss = 0.52140 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:26:12.539733 ops/training.py:65 2019-01-17 05:26:12.539629: step 14179, loss = 0.57523 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:26:13.827919 ops/training.py:65 2019-01-17 05:26:13.827816: step 14180, loss = 0.43236 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:26:15.120896 ops/training.py:65 2019-01-17 05:26:15.120741: step 14181, loss = 0.51556 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:26:16.405759 ops/training.py:65 2019-01-17 05:26:16.405689: step 14182, loss = 0.46932 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:26:17.692683 ops/training.py:65 2019-01-17 05:26:17.692520: step 14183, loss = 0.55179 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:26:18.977493 ops/training.py:65 2019-01-17 05:26:18.977391: step 14184, loss = 0.56727 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:26:20.269443 ops/training.py:65 2019-01-17 05:26:20.269340: step 14185, loss = 0.51816 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:26:21.554349 ops/training.py:65 2019-01-17 05:26:21.554263: step 14186, loss = 0.54073 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:26:22.846092 ops/training.py:65 2019-01-17 05:26:22.845987: step 14187, loss = 0.47231 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:26:24.131794 ops/training.py:65 2019-01-17 05:26:24.131726: step 14188, loss = 0.43876 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:26:25.411793 ops/training.py:65 2019-01-17 05:26:25.411684: step 14189, loss = 0.56951 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:26:26.699104 ops/training.py:65 2019-01-17 05:26:26.698989: step 14190, loss = 0.56608 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:26:27.985647 ops/training.py:65 2019-01-17 05:26:27.985545: step 14191, loss = 0.59478 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:26:29.265626 ops/training.py:65 2019-01-17 05:26:29.265461: step 14192, loss = 0.41730 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:26:30.559999 ops/training.py:65 2019-01-17 05:26:30.559884: step 14193, loss = 0.43950 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:26:31.852800 ops/training.py:65 2019-01-17 05:26:31.852729: step 14194, loss = 0.42651 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:26:33.143003 ops/training.py:65 2019-01-17 05:26:33.142934: step 14195, loss = 0.48378 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:26:34.431729 ops/training.py:65 2019-01-17 05:26:34.431667: step 14196, loss = 0.40907 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:26:35.719941 ops/training.py:65 2019-01-17 05:26:35.719873: step 14197, loss = 0.44835 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:26:37.008612 ops/training.py:65 2019-01-17 05:26:37.008546: step 14198, loss = 0.41948 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:26:38.297474 ops/training.py:65 2019-01-17 05:26:38.297411: step 14199, loss = 0.50860 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:26:39.586508 ops/training.py:65 2019-01-17 05:26:39.586450: step 14200, loss = 0.37287 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:26:40.870074 ops/training.py:65 2019-01-17 05:26:40.870012: step 14201, loss = 0.49594 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:26:42.154174 ops/training.py:65 2019-01-17 05:26:42.154086: step 14202, loss = 0.44307 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:26:43.446830 ops/training.py:65 2019-01-17 05:26:43.446727: step 14203, loss = 0.50291 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:26:44.734572 ops/training.py:65 2019-01-17 05:26:44.734509: step 14204, loss = 0.45981 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:26:46.024313 ops/training.py:65 2019-01-17 05:26:46.024247: step 14205, loss = 0.52564 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:26:47.310965 ops/training.py:65 2019-01-17 05:26:47.310887: step 14206, loss = 0.46241 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:26:48.599999 ops/training.py:65 2019-01-17 05:26:48.599932: step 14207, loss = 0.57827 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:26:49.887925 ops/training.py:65 2019-01-17 05:26:49.887867: step 14208, loss = 0.52485 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:26:51.177746 ops/training.py:65 2019-01-17 05:26:51.177686: step 14209, loss = 0.60950 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 05:26:52.462147 ops/training.py:65 2019-01-17 05:26:52.462061: step 14210, loss = 0.55042 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:26:53.751245 ops/training.py:65 2019-01-17 05:26:53.751153: step 14211, loss = 0.42912 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:26:55.041453 ops/training.py:65 2019-01-17 05:26:55.041351: step 14212, loss = 0.55315 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:26:56.330395 ops/training.py:65 2019-01-17 05:26:56.330330: step 14213, loss = 0.38745 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:26:57.614231 ops/training.py:65 2019-01-17 05:26:57.614156: step 14214, loss = 0.44971 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:26:58.898559 ops/training.py:65 2019-01-17 05:26:58.898462: step 14215, loss = 0.57847 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:27:00.182803 ops/training.py:65 2019-01-17 05:27:00.182701: step 14216, loss = 0.55376 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:27:01.476165 ops/training.py:65 2019-01-17 05:27:01.476059: step 14217, loss = 0.46379 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:27:02.764053 ops/training.py:65 2019-01-17 05:27:02.763969: step 14218, loss = 0.45873 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:27:04.044851 ops/training.py:65 2019-01-17 05:27:04.044774: step 14219, loss = 0.41256 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:27:05.333780 ops/training.py:65 2019-01-17 05:27:05.333715: step 14220, loss = 0.45950 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:27:06.618462 ops/training.py:65 2019-01-17 05:27:06.618396: step 14221, loss = 0.47633 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:27:07.902996 ops/training.py:65 2019-01-17 05:27:07.902912: step 14222, loss = 0.44798 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:27:09.194669 ops/training.py:65 2019-01-17 05:27:09.194509: step 14223, loss = 0.37609 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:27:10.480982 ops/training.py:65 2019-01-17 05:27:10.480916: step 14224, loss = 0.47703 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:27:11.771183 ops/training.py:65 2019-01-17 05:27:11.771041: step 14225, loss = 0.49200 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:27:13.056955 ops/training.py:65 2019-01-17 05:27:13.056890: step 14226, loss = 0.52366 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:27:14.346621 ops/training.py:65 2019-01-17 05:27:14.346552: step 14227, loss = 0.59308 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:27:15.634078 ops/training.py:65 2019-01-17 05:27:15.633989: step 14228, loss = 0.44375 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:27:16.923584 ops/training.py:65 2019-01-17 05:27:16.923505: step 14229, loss = 0.45800 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:27:18.208097 ops/training.py:65 2019-01-17 05:27:18.208019: step 14230, loss = 0.37760 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:27:19.491905 ops/training.py:65 2019-01-17 05:27:19.491828: step 14231, loss = 0.60842 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:27:20.784439 ops/training.py:65 2019-01-17 05:27:20.784338: step 14232, loss = 0.39667 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:27:22.069364 ops/training.py:65 2019-01-17 05:27:22.069285: step 14233, loss = 0.51548 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:27:23.357502 ops/training.py:65 2019-01-17 05:27:23.357406: step 14234, loss = 0.45914 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:27:24.648382 ops/training.py:65 2019-01-17 05:27:24.648315: step 14235, loss = 0.46964 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:27:25.933584 ops/training.py:65 2019-01-17 05:27:25.933489: step 14236, loss = 0.50642 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:27:27.217895 ops/training.py:65 2019-01-17 05:27:27.217833: step 14237, loss = 0.59023 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:27:28.499963 ops/training.py:65 2019-01-17 05:27:28.499857: step 14238, loss = 0.55150 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:27:29.792979 ops/training.py:65 2019-01-17 05:27:29.792879: step 14239, loss = 0.58263 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:27:31.084996 ops/training.py:65 2019-01-17 05:27:31.084924: step 14240, loss = 0.54660 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:27:32.375430 ops/training.py:65 2019-01-17 05:27:32.375368: step 14241, loss = 0.51230 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:27:33.661300 ops/training.py:65 2019-01-17 05:27:33.661233: step 14242, loss = 0.42181 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:27:34.948350 ops/training.py:65 2019-01-17 05:27:34.948264: step 14243, loss = 0.54970 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:27:36.234485 ops/training.py:65 2019-01-17 05:27:36.234379: step 14244, loss = 0.53284 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:27:37.518080 ops/training.py:65 2019-01-17 05:27:37.517985: step 14245, loss = 0.54468 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:27:38.805649 ops/training.py:65 2019-01-17 05:27:38.805547: step 14246, loss = 0.43912 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:27:40.093958 ops/training.py:65 2019-01-17 05:27:40.093821: step 14247, loss = 0.48493 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:27:41.376295 ops/training.py:65 2019-01-17 05:27:41.376224: step 14248, loss = 0.53206 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:27:42.666193 ops/training.py:65 2019-01-17 05:27:42.666103: step 14249, loss = 0.38941 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:27:43.951438 ops/training.py:65 2019-01-17 05:27:43.951337: step 14250, loss = 0.53879 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:27:45.235952 ops/training.py:65 2019-01-17 05:27:45.235845: step 14251, loss = 0.47551 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:27:46.529836 ops/training.py:65 2019-01-17 05:27:46.529727: step 14252, loss = 0.45166 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:27:47.815168 ops/training.py:65 2019-01-17 05:27:47.815097: step 14253, loss = 0.47994 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:27:49.099175 ops/training.py:65 2019-01-17 05:27:49.099089: step 14254, loss = 0.60585 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:27:50.386458 ops/training.py:65 2019-01-17 05:27:50.386348: step 14255, loss = 0.58855 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:27:51.678301 ops/training.py:65 2019-01-17 05:27:51.678202: step 14256, loss = 0.44018 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:27:52.964439 ops/training.py:65 2019-01-17 05:27:52.964375: step 14257, loss = 0.53565 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:27:54.247724 ops/training.py:65 2019-01-17 05:27:54.247648: step 14258, loss = 0.62126 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 05:27:55.532192 ops/training.py:65 2019-01-17 05:27:55.532091: step 14259, loss = 0.51937 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:27:56.825077 ops/training.py:65 2019-01-17 05:27:56.824978: step 14260, loss = 0.50033 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:27:58.115993 ops/training.py:65 2019-01-17 05:27:58.115922: step 14261, loss = 0.45239 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:27:59.401050 ops/training.py:65 2019-01-17 05:27:59.400984: step 14262, loss = 0.56518 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:28:00.687227 ops/training.py:65 2019-01-17 05:28:00.687117: step 14263, loss = 0.44376 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:28:01.973743 ops/training.py:65 2019-01-17 05:28:01.973644: step 14264, loss = 0.46415 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:28:03.261228 ops/training.py:65 2019-01-17 05:28:03.261134: step 14265, loss = 0.58317 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:28:04.543540 ops/training.py:65 2019-01-17 05:28:04.543431: step 14266, loss = 0.49949 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:28:05.830116 ops/training.py:65 2019-01-17 05:28:05.830007: step 14267, loss = 0.46304 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:28:07.117609 ops/training.py:65 2019-01-17 05:28:07.117497: step 14268, loss = 0.43750 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:28:08.403950 ops/training.py:65 2019-01-17 05:28:08.403849: step 14269, loss = 0.48952 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:28:09.689264 ops/training.py:65 2019-01-17 05:28:09.689195: step 14270, loss = 0.56950 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:28:10.969565 ops/training.py:65 2019-01-17 05:28:10.969498: step 14271, loss = 0.46996 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:28:12.255809 ops/training.py:65 2019-01-17 05:28:12.255713: step 14272, loss = 0.47014 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:28:13.543575 ops/training.py:65 2019-01-17 05:28:13.543475: step 14273, loss = 0.45846 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:28:14.830330 ops/training.py:65 2019-01-17 05:28:14.830223: step 14274, loss = 0.41641 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:28:16.118639 ops/training.py:65 2019-01-17 05:28:16.118530: step 14275, loss = 0.51872 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:28:17.401932 ops/training.py:65 2019-01-17 05:28:17.401831: step 14276, loss = 0.45748 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:28:18.687805 ops/training.py:65 2019-01-17 05:28:18.687702: step 14277, loss = 0.48676 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:28:19.969398 ops/training.py:65 2019-01-17 05:28:19.969294: step 14278, loss = 0.47813 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:28:21.257043 ops/training.py:65 2019-01-17 05:28:21.256941: step 14279, loss = 0.52486 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:28:22.540882 ops/training.py:65 2019-01-17 05:28:22.540777: step 14280, loss = 0.47875 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:28:23.826944 ops/training.py:65 2019-01-17 05:28:23.826846: step 14281, loss = 0.53348 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:28:25.111937 ops/training.py:65 2019-01-17 05:28:25.111854: step 14282, loss = 0.44110 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:28:26.402595 ops/training.py:65 2019-01-17 05:28:26.402494: step 14283, loss = 0.55553 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:28:27.692412 ops/training.py:65 2019-01-17 05:28:27.692347: step 14284, loss = 0.56551 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:28:28.975424 ops/training.py:65 2019-01-17 05:28:28.975352: step 14285, loss = 0.52712 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:28:30.262201 ops/training.py:65 2019-01-17 05:28:30.262105: step 14286, loss = 0.43236 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:28:31.552874 ops/training.py:65 2019-01-17 05:28:31.552810: step 14287, loss = 0.48654 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:28:32.841024 ops/training.py:65 2019-01-17 05:28:32.840963: step 14288, loss = 0.60023 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:28:34.129422 ops/training.py:65 2019-01-17 05:28:34.129339: step 14289, loss = 0.52160 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:28:35.417695 ops/training.py:65 2019-01-17 05:28:35.417625: step 14290, loss = 0.49921 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:28:36.702812 ops/training.py:65 2019-01-17 05:28:36.702741: step 14291, loss = 0.49120 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:28:37.987631 ops/training.py:65 2019-01-17 05:28:37.987522: step 14292, loss = 0.51833 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:28:39.273054 ops/training.py:65 2019-01-17 05:28:39.272962: step 14293, loss = 0.44897 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:28:40.553236 ops/training.py:65 2019-01-17 05:28:40.553146: step 14294, loss = 0.48179 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:28:41.844041 ops/training.py:65 2019-01-17 05:28:41.843886: step 14295, loss = 0.45283 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:28:43.132063 ops/training.py:65 2019-01-17 05:28:43.131983: step 14296, loss = 0.47783 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:28:44.417466 ops/training.py:65 2019-01-17 05:28:44.417325: step 14297, loss = 0.44221 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:28:45.705371 ops/training.py:65 2019-01-17 05:28:45.705264: step 14298, loss = 0.45623 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:28:46.989669 ops/training.py:65 2019-01-17 05:28:46.989567: step 14299, loss = 0.50958 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:28:48.276749 ops/training.py:65 2019-01-17 05:28:48.276640: step 14300, loss = 0.41400 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:28:49.565133 ops/training.py:65 2019-01-17 05:28:49.565025: step 14301, loss = 0.39769 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:28:50.854695 ops/training.py:65 2019-01-17 05:28:50.854610: step 14302, loss = 0.52267 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:28:52.143660 ops/training.py:65 2019-01-17 05:28:52.143585: step 14303, loss = 0.44674 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:28:53.428489 ops/training.py:65 2019-01-17 05:28:53.428413: step 14304, loss = 0.44508 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:28:54.717004 ops/training.py:65 2019-01-17 05:28:54.716895: step 14305, loss = 0.46812 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:28:56.005968 ops/training.py:65 2019-01-17 05:28:56.005854: step 14306, loss = 0.53163 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:28:57.293369 ops/training.py:65 2019-01-17 05:28:57.293278: step 14307, loss = 0.43588 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:28:58.578034 ops/training.py:65 2019-01-17 05:28:58.577928: step 14308, loss = 0.39757 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:28:59.869005 ops/training.py:65 2019-01-17 05:28:59.868897: step 14309, loss = 0.37900 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:29:01.156400 ops/training.py:65 2019-01-17 05:29:01.156333: step 14310, loss = 0.50633 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:29:02.444745 ops/training.py:65 2019-01-17 05:29:02.444636: step 14311, loss = 0.57564 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:29:03.735743 ops/training.py:65 2019-01-17 05:29:03.735669: step 14312, loss = 0.53167 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:29:05.025292 ops/training.py:65 2019-01-17 05:29:05.025191: step 14313, loss = 0.44573 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:29:06.320723 ops/training.py:65 2019-01-17 05:29:06.320636: step 14314, loss = 0.52764 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:29:07.610152 ops/training.py:65 2019-01-17 05:29:07.610087: step 14315, loss = 0.53826 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:29:08.898439 ops/training.py:65 2019-01-17 05:29:08.898369: step 14316, loss = 0.46366 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:29:10.186651 ops/training.py:65 2019-01-17 05:29:10.186589: step 14317, loss = 0.51527 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:29:11.476204 ops/training.py:65 2019-01-17 05:29:11.476135: step 14318, loss = 0.49284 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:29:12.765120 ops/training.py:65 2019-01-17 05:29:12.765054: step 14319, loss = 0.57794 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:29:14.052918 ops/training.py:65 2019-01-17 05:29:14.052850: step 14320, loss = 0.51791 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:29:15.342221 ops/training.py:65 2019-01-17 05:29:15.342132: step 14321, loss = 0.47319 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:29:16.631749 ops/training.py:65 2019-01-17 05:29:16.631659: step 14322, loss = 0.49196 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:29:17.921810 ops/training.py:65 2019-01-17 05:29:17.921742: step 14323, loss = 0.54018 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:29:19.211025 ops/training.py:65 2019-01-17 05:29:19.210962: step 14324, loss = 0.34124 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:29:20.496592 ops/training.py:65 2019-01-17 05:29:20.496525: step 14325, loss = 0.49725 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:29:21.786579 ops/training.py:65 2019-01-17 05:29:21.786466: step 14326, loss = 0.62594 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:29:23.075791 ops/training.py:65 2019-01-17 05:29:23.075724: step 14327, loss = 0.45617 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:29:24.359882 ops/training.py:65 2019-01-17 05:29:24.359814: step 14328, loss = 0.53865 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:29:25.649435 ops/training.py:65 2019-01-17 05:29:25.649327: step 14329, loss = 0.50319 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:29:26.945897 ops/training.py:65 2019-01-17 05:29:26.945821: step 14330, loss = 0.54087 (24.7 examples/sec; 1.295 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:29:28.230402 ops/training.py:65 2019-01-17 05:29:28.230336: step 14331, loss = 0.47525 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:29:29.518552 ops/training.py:65 2019-01-17 05:29:29.518458: step 14332, loss = 0.56224 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:29:30.804494 ops/training.py:65 2019-01-17 05:29:30.804424: step 14333, loss = 0.47956 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:29:32.088325 ops/training.py:65 2019-01-17 05:29:32.088256: step 14334, loss = 0.50075 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:29:33.373592 ops/training.py:65 2019-01-17 05:29:33.373504: step 14335, loss = 0.45989 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:29:34.660121 ops/training.py:65 2019-01-17 05:29:34.660010: step 14336, loss = 0.40780 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:29:35.945079 ops/training.py:65 2019-01-17 05:29:35.944973: step 14337, loss = 0.49794 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:29:37.236325 ops/training.py:65 2019-01-17 05:29:37.236226: step 14338, loss = 0.49771 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:29:38.517192 ops/training.py:65 2019-01-17 05:29:38.517094: step 14339, loss = 0.41885 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:29:39.801605 ops/training.py:65 2019-01-17 05:29:39.801501: step 14340, loss = 0.47122 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:29:41.094197 ops/training.py:65 2019-01-17 05:29:41.094093: step 14341, loss = 0.42050 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:29:42.381848 ops/training.py:65 2019-01-17 05:29:42.381783: step 14342, loss = 0.62667 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:29:43.671007 ops/training.py:65 2019-01-17 05:29:43.670927: step 14343, loss = 0.50120 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:29:44.958080 ops/training.py:65 2019-01-17 05:29:44.957984: step 14344, loss = 0.52856 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:29:46.247510 ops/training.py:65 2019-01-17 05:29:46.247434: step 14345, loss = 0.46958 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:29:47.537616 ops/training.py:65 2019-01-17 05:29:47.537521: step 14346, loss = 0.51319 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:29:48.825880 ops/training.py:65 2019-01-17 05:29:48.825814: step 14347, loss = 0.42890 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:29:50.116819 ops/training.py:65 2019-01-17 05:29:50.116748: step 14348, loss = 0.66671 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:29:51.405501 ops/training.py:65 2019-01-17 05:29:51.405425: step 14349, loss = 0.61149 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:29:52.694447 ops/training.py:65 2019-01-17 05:29:52.694373: step 14350, loss = 0.46888 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:29:53.984956 ops/training.py:65 2019-01-17 05:29:53.984883: step 14351, loss = 0.38980 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:29:55.273845 ops/training.py:65 2019-01-17 05:29:55.273767: step 14352, loss = 0.44209 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:29:56.565617 ops/training.py:65 2019-01-17 05:29:56.565512: step 14353, loss = 0.44354 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:29:57.856971 ops/training.py:65 2019-01-17 05:29:57.856907: step 14354, loss = 0.49209 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:29:59.145519 ops/training.py:65 2019-01-17 05:29:59.145446: step 14355, loss = 0.54140 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:30:00.435474 ops/training.py:65 2019-01-17 05:30:00.435390: step 14356, loss = 0.52770 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:30:01.719928 ops/training.py:65 2019-01-17 05:30:01.719864: step 14357, loss = 0.47111 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:30:03.005813 ops/training.py:65 2019-01-17 05:30:03.005710: step 14358, loss = 0.52634 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:30:04.295110 ops/training.py:65 2019-01-17 05:30:04.295007: step 14359, loss = 0.39641 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:30:05.582593 ops/training.py:65 2019-01-17 05:30:05.582484: step 14360, loss = 0.35994 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:30:06.867154 ops/training.py:65 2019-01-17 05:30:06.867001: step 14361, loss = 0.58845 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:30:08.159699 ops/training.py:65 2019-01-17 05:30:08.159550: step 14362, loss = 0.49553 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:30:09.448998 ops/training.py:65 2019-01-17 05:30:09.448921: step 14363, loss = 0.50979 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:30:10.735328 ops/training.py:65 2019-01-17 05:30:10.735219: step 14364, loss = 0.41925 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:30:12.025351 ops/training.py:65 2019-01-17 05:30:12.025249: step 14365, loss = 0.52602 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:30:13.315438 ops/training.py:65 2019-01-17 05:30:13.315366: step 14366, loss = 0.49118 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:30:14.603229 ops/training.py:65 2019-01-17 05:30:14.603160: step 14367, loss = 0.41911 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:30:15.891194 ops/training.py:65 2019-01-17 05:30:15.891125: step 14368, loss = 0.45453 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:30:17.174661 ops/training.py:65 2019-01-17 05:30:17.174597: step 14369, loss = 0.48465 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:30:18.459599 ops/training.py:65 2019-01-17 05:30:18.459487: step 14370, loss = 0.39905 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:30:19.746008 ops/training.py:65 2019-01-17 05:30:19.745907: step 14371, loss = 0.42792 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:30:21.037175 ops/training.py:65 2019-01-17 05:30:21.037022: step 14372, loss = 0.53124 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:30:22.323119 ops/training.py:65 2019-01-17 05:30:22.323009: step 14373, loss = 0.45595 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:30:23.608167 ops/training.py:65 2019-01-17 05:30:23.608098: step 14374, loss = 0.44634 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:30:24.893525 ops/training.py:65 2019-01-17 05:30:24.893454: step 14375, loss = 0.51513 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:30:26.177007 ops/training.py:65 2019-01-17 05:30:26.176907: step 14376, loss = 0.46672 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:30:27.467995 ops/training.py:65 2019-01-17 05:30:27.467855: step 14377, loss = 0.61011 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:30:28.759761 ops/training.py:65 2019-01-17 05:30:28.759688: step 14378, loss = 0.52003 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:30:30.044926 ops/training.py:65 2019-01-17 05:30:30.044861: step 14379, loss = 0.43440 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:30:31.332065 ops/training.py:65 2019-01-17 05:30:31.331999: step 14380, loss = 0.51331 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:30:32.620687 ops/training.py:65 2019-01-17 05:30:32.620595: step 14381, loss = 0.47646 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:30:33.910015 ops/training.py:65 2019-01-17 05:30:33.909940: step 14382, loss = 0.35194 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:30:35.194788 ops/training.py:65 2019-01-17 05:30:35.194721: step 14383, loss = 0.43068 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:30:36.480240 ops/training.py:65 2019-01-17 05:30:36.480142: step 14384, loss = 0.58501 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:30:37.768620 ops/training.py:65 2019-01-17 05:30:37.768505: step 14385, loss = 0.55260 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:30:39.058822 ops/training.py:65 2019-01-17 05:30:39.058758: step 14386, loss = 0.47996 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:30:40.348002 ops/training.py:65 2019-01-17 05:30:40.347917: step 14387, loss = 0.44535 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:30:41.636311 ops/training.py:65 2019-01-17 05:30:41.636240: step 14388, loss = 0.41660 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:30:42.926160 ops/training.py:65 2019-01-17 05:30:42.926065: step 14389, loss = 0.56015 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:30:44.216692 ops/training.py:65 2019-01-17 05:30:44.216619: step 14390, loss = 0.42777 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:30:45.507413 ops/training.py:65 2019-01-17 05:30:45.507338: step 14391, loss = 0.44305 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:30:46.793776 ops/training.py:65 2019-01-17 05:30:46.793693: step 14392, loss = 0.52458 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:30:48.082090 ops/training.py:65 2019-01-17 05:30:48.082018: step 14393, loss = 0.59318 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:30:49.370318 ops/training.py:65 2019-01-17 05:30:49.370257: step 14394, loss = 0.47942 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:30:50.659067 ops/training.py:65 2019-01-17 05:30:50.658997: step 14395, loss = 0.50979 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:30:51.951253 ops/training.py:65 2019-01-17 05:30:51.951147: step 14396, loss = 0.62153 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:30:53.244017 ops/training.py:65 2019-01-17 05:30:53.243928: step 14397, loss = 0.46408 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:30:54.534249 ops/training.py:65 2019-01-17 05:30:54.534176: step 14398, loss = 0.42795 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:30:55.826040 ops/training.py:65 2019-01-17 05:30:55.825958: step 14399, loss = 0.54652 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:30:57.117484 ops/training.py:65 2019-01-17 05:30:57.117377: step 14400, loss = 0.43826 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:30:58.403692 ops/training.py:65 2019-01-17 05:30:58.403626: step 14401, loss = 0.45381 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:30:59.686724 ops/training.py:65 2019-01-17 05:30:59.686614: step 14402, loss = 0.41617 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:31:00.973721 ops/training.py:65 2019-01-17 05:31:00.973618: step 14403, loss = 0.48920 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:31:02.264765 ops/training.py:65 2019-01-17 05:31:02.264661: step 14404, loss = 0.52234 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:31:03.557691 ops/training.py:65 2019-01-17 05:31:03.557617: step 14405, loss = 0.55781 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:31:04.846491 ops/training.py:65 2019-01-17 05:31:04.846407: step 14406, loss = 0.49828 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:31:06.136860 ops/training.py:65 2019-01-17 05:31:06.136797: step 14407, loss = 0.52904 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:31:07.426405 ops/training.py:65 2019-01-17 05:31:07.426337: step 14408, loss = 0.35911 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:31:08.709941 ops/training.py:65 2019-01-17 05:31:08.709876: step 14409, loss = 0.46065 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:31:09.997411 ops/training.py:65 2019-01-17 05:31:09.997352: step 14410, loss = 0.43702 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:31:11.282375 ops/training.py:65 2019-01-17 05:31:11.282309: step 14411, loss = 0.55451 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:31:12.569300 ops/training.py:65 2019-01-17 05:31:12.569217: step 14412, loss = 0.40902 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:31:13.860954 ops/training.py:65 2019-01-17 05:31:13.860828: step 14413, loss = 0.54275 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:31:15.152972 ops/training.py:65 2019-01-17 05:31:15.152905: step 14414, loss = 0.50219 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:31:16.440250 ops/training.py:65 2019-01-17 05:31:16.440180: step 14415, loss = 0.49633 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:31:17.727617 ops/training.py:65 2019-01-17 05:31:17.727548: step 14416, loss = 0.43401 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:31:19.015082 ops/training.py:65 2019-01-17 05:31:19.015011: step 14417, loss = 0.36375 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:31:20.304071 ops/training.py:65 2019-01-17 05:31:20.304007: step 14418, loss = 0.47122 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:31:21.591909 ops/training.py:65 2019-01-17 05:31:21.591845: step 14419, loss = 0.49427 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:31:22.881988 ops/training.py:65 2019-01-17 05:31:22.881919: step 14420, loss = 0.45847 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:31:24.173078 ops/training.py:65 2019-01-17 05:31:24.172994: step 14421, loss = 0.48272 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:31:25.460204 ops/training.py:65 2019-01-17 05:31:25.460052: step 14422, loss = 0.39750 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:31:26.751569 ops/training.py:65 2019-01-17 05:31:26.751488: step 14423, loss = 0.39925 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:31:28.039913 ops/training.py:65 2019-01-17 05:31:28.039817: step 14424, loss = 0.46896 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:31:29.330617 ops/training.py:65 2019-01-17 05:31:29.330514: step 14425, loss = 0.54558 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:31:30.621489 ops/training.py:65 2019-01-17 05:31:30.621425: step 14426, loss = 0.53995 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:31:31.906368 ops/training.py:65 2019-01-17 05:31:31.906301: step 14427, loss = 0.42444 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:31:33.189549 ops/training.py:65 2019-01-17 05:31:33.189479: step 14428, loss = 0.54577 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:31:34.482289 ops/training.py:65 2019-01-17 05:31:34.482139: step 14429, loss = 0.50094 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:31:35.773447 ops/training.py:65 2019-01-17 05:31:35.773374: step 14430, loss = 0.48947 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:31:37.056563 ops/training.py:65 2019-01-17 05:31:37.056488: step 14431, loss = 0.60161 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:31:38.347612 ops/training.py:65 2019-01-17 05:31:38.347511: step 14432, loss = 0.34545 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:31:39.638495 ops/training.py:65 2019-01-17 05:31:39.638427: step 14433, loss = 0.42083 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:31:40.927248 ops/training.py:65 2019-01-17 05:31:40.927149: step 14434, loss = 0.55771 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:31:42.216958 ops/training.py:65 2019-01-17 05:31:42.216893: step 14435, loss = 0.53883 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:31:43.506292 ops/training.py:65 2019-01-17 05:31:43.506191: step 14436, loss = 0.42393 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:31:44.791987 ops/training.py:65 2019-01-17 05:31:44.791917: step 14437, loss = 0.50394 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:31:46.078127 ops/training.py:65 2019-01-17 05:31:46.078018: step 14438, loss = 0.50044 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:31:47.364132 ops/training.py:65 2019-01-17 05:31:47.364036: step 14439, loss = 0.46992 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:31:48.653243 ops/training.py:65 2019-01-17 05:31:48.653149: step 14440, loss = 0.47629 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:31:49.941778 ops/training.py:65 2019-01-17 05:31:49.941684: step 14441, loss = 0.47545 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:31:51.226400 ops/training.py:65 2019-01-17 05:31:51.226334: step 14442, loss = 0.49139 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:31:52.504265 ops/training.py:65 2019-01-17 05:31:52.504151: step 14443, loss = 0.49414 (25.1 examples/sec; 1.275 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:31:53.786258 ops/training.py:65 2019-01-17 05:31:53.786153: step 14444, loss = 0.39199 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:31:55.069361 ops/training.py:65 2019-01-17 05:31:55.069259: step 14445, loss = 0.56333 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:31:56.359852 ops/training.py:65 2019-01-17 05:31:56.359747: step 14446, loss = 0.42007 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:31:57.647911 ops/training.py:65 2019-01-17 05:31:57.647849: step 14447, loss = 0.45249 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:31:58.933699 ops/training.py:65 2019-01-17 05:31:58.933538: step 14448, loss = 0.45732 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:32:00.221684 ops/training.py:65 2019-01-17 05:32:00.221571: step 14449, loss = 0.50906 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:32:01.509114 ops/training.py:65 2019-01-17 05:32:01.509002: step 14450, loss = 0.52364 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:32:02.789143 ops/training.py:65 2019-01-17 05:32:02.789029: step 14451, loss = 0.49077 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:32:04.076477 ops/training.py:65 2019-01-17 05:32:04.076377: step 14452, loss = 0.41241 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:32:05.364753 ops/training.py:65 2019-01-17 05:32:05.364605: step 14453, loss = 0.46561 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:32:06.644882 ops/training.py:65 2019-01-17 05:32:06.644774: step 14454, loss = 0.59696 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:32:07.931307 ops/training.py:65 2019-01-17 05:32:07.931203: step 14455, loss = 0.55596 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:32:09.211079 ops/training.py:65 2019-01-17 05:32:09.210972: step 14456, loss = 0.42973 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:32:10.494447 ops/training.py:65 2019-01-17 05:32:10.494341: step 14457, loss = 0.51252 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:32:11.782122 ops/training.py:65 2019-01-17 05:32:11.782009: step 14458, loss = 0.47853 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:32:13.067770 ops/training.py:65 2019-01-17 05:32:13.067671: step 14459, loss = 0.42290 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:32:14.355486 ops/training.py:65 2019-01-17 05:32:14.355379: step 14460, loss = 0.47924 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:32:15.641471 ops/training.py:65 2019-01-17 05:32:15.641403: step 14461, loss = 0.47560 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:32:16.921459 ops/training.py:65 2019-01-17 05:32:16.921348: step 14462, loss = 0.43545 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:32:18.208551 ops/training.py:65 2019-01-17 05:32:18.208445: step 14463, loss = 0.47070 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:32:19.490848 ops/training.py:65 2019-01-17 05:32:19.490755: step 14464, loss = 0.48247 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:32:20.781834 ops/training.py:65 2019-01-17 05:32:20.781673: step 14465, loss = 0.41174 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:32:22.067907 ops/training.py:65 2019-01-17 05:32:22.067814: step 14466, loss = 0.41679 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:32:23.352086 ops/training.py:65 2019-01-17 05:32:23.351987: step 14467, loss = 0.47762 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:32:24.643165 ops/training.py:65 2019-01-17 05:32:24.643061: step 14468, loss = 0.54188 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:32:25.928685 ops/training.py:65 2019-01-17 05:32:25.928612: step 14469, loss = 0.46350 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:32:27.215445 ops/training.py:65 2019-01-17 05:32:27.215332: step 14470, loss = 0.52065 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:32:28.506070 ops/training.py:65 2019-01-17 05:32:28.505977: step 14471, loss = 0.47561 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:32:29.793248 ops/training.py:65 2019-01-17 05:32:29.793180: step 14472, loss = 0.49538 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:32:31.079840 ops/training.py:65 2019-01-17 05:32:31.079768: step 14473, loss = 0.51071 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:32:32.359228 ops/training.py:65 2019-01-17 05:32:32.359129: step 14474, loss = 0.39483 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:32:33.649882 ops/training.py:65 2019-01-17 05:32:33.649786: step 14475, loss = 0.46756 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:32:34.940251 ops/training.py:65 2019-01-17 05:32:34.940153: step 14476, loss = 0.47823 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:32:36.226250 ops/training.py:65 2019-01-17 05:32:36.226175: step 14477, loss = 0.34545 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:32:37.516229 ops/training.py:65 2019-01-17 05:32:37.516132: step 14478, loss = 0.44777 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:32:38.800538 ops/training.py:65 2019-01-17 05:32:38.800461: step 14479, loss = 0.45680 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:32:40.086259 ops/training.py:65 2019-01-17 05:32:40.086119: step 14480, loss = 0.47367 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:32:41.364147 ops/training.py:65 2019-01-17 05:32:41.364046: step 14481, loss = 0.39295 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:32:42.651493 ops/training.py:65 2019-01-17 05:32:42.651391: step 14482, loss = 0.53626 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:32:43.931062 ops/training.py:65 2019-01-17 05:32:43.930960: step 14483, loss = 0.45628 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:32:45.215709 ops/training.py:65 2019-01-17 05:32:45.215553: step 14484, loss = 0.49107 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:32:46.500116 ops/training.py:65 2019-01-17 05:32:46.500023: step 14485, loss = 0.50023 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:32:47.783711 ops/training.py:65 2019-01-17 05:32:47.783608: step 14486, loss = 0.58172 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:32:49.074332 ops/training.py:65 2019-01-17 05:32:49.074226: step 14487, loss = 0.49210 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:32:50.360621 ops/training.py:65 2019-01-17 05:32:50.360561: step 14488, loss = 0.47752 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:32:51.644039 ops/training.py:65 2019-01-17 05:32:51.643969: step 14489, loss = 0.55070 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:32:52.932572 ops/training.py:65 2019-01-17 05:32:52.932471: step 14490, loss = 0.48779 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:32:54.219404 ops/training.py:65 2019-01-17 05:32:54.219301: step 14491, loss = 0.46414 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:32:55.508611 ops/training.py:65 2019-01-17 05:32:55.508510: step 14492, loss = 0.45027 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:32:56.792766 ops/training.py:65 2019-01-17 05:32:56.792668: step 14493, loss = 0.39961 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:32:58.077168 ops/training.py:65 2019-01-17 05:32:58.077078: step 14494, loss = 0.61594 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:32:59.363812 ops/training.py:65 2019-01-17 05:32:59.363711: step 14495, loss = 0.39372 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:33:00.647024 ops/training.py:65 2019-01-17 05:33:00.646947: step 14496, loss = 0.40313 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:33:01.933870 ops/training.py:65 2019-01-17 05:33:01.933767: step 14497, loss = 0.57474 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:33:03.223127 ops/training.py:65 2019-01-17 05:33:03.222990: step 14498, loss = 0.55630 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:33:04.514433 ops/training.py:65 2019-01-17 05:33:04.514334: step 14499, loss = 0.45461 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:33:05.798778 ops/training.py:65 2019-01-17 05:33:05.798712: step 14500, loss = 0.45205 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:33:07.087869 ops/training.py:65 2019-01-17 05:33:07.087795: step 14501, loss = 0.51282 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:33:08.375923 ops/training.py:65 2019-01-17 05:33:08.375853: step 14502, loss = 0.40450 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:33:09.663876 ops/training.py:65 2019-01-17 05:33:09.663811: step 14503, loss = 0.50401 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:33:10.951735 ops/training.py:65 2019-01-17 05:33:10.951646: step 14504, loss = 0.52668 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:33:12.247273 ops/training.py:65 2019-01-17 05:33:12.247208: step 14505, loss = 0.39596 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:33:13.529842 ops/training.py:65 2019-01-17 05:33:13.529766: step 14506, loss = 0.49814 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:33:14.815360 ops/training.py:65 2019-01-17 05:33:14.815286: step 14507, loss = 0.47759 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:33:16.096382 ops/training.py:65 2019-01-17 05:33:16.096279: step 14508, loss = 0.46226 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:33:17.388822 ops/training.py:65 2019-01-17 05:33:17.388715: step 14509, loss = 0.42411 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:33:18.678712 ops/training.py:65 2019-01-17 05:33:18.678646: step 14510, loss = 0.62251 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.53125
I4672 2019-01-17 05:33:19.967560 ops/training.py:65 2019-01-17 05:33:19.967481: step 14511, loss = 0.49702 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:33:21.255608 ops/training.py:65 2019-01-17 05:33:21.255542: step 14512, loss = 0.47609 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:33:22.544571 ops/training.py:65 2019-01-17 05:33:22.544504: step 14513, loss = 0.43098 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:33:23.827871 ops/training.py:65 2019-01-17 05:33:23.827807: step 14514, loss = 0.54866 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:33:25.114325 ops/training.py:65 2019-01-17 05:33:25.114235: step 14515, loss = 0.55253 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:33:26.405581 ops/training.py:65 2019-01-17 05:33:26.405484: step 14516, loss = 0.55064 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:33:27.695665 ops/training.py:65 2019-01-17 05:33:27.695606: step 14517, loss = 0.46899 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:33:28.979881 ops/training.py:65 2019-01-17 05:33:28.979817: step 14518, loss = 0.45341 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:33:30.263977 ops/training.py:65 2019-01-17 05:33:30.263910: step 14519, loss = 0.50579 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:33:31.550363 ops/training.py:65 2019-01-17 05:33:31.550258: step 14520, loss = 0.55631 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:33:32.835177 ops/training.py:65 2019-01-17 05:33:32.835110: step 14521, loss = 0.58633 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:33:34.119936 ops/training.py:65 2019-01-17 05:33:34.119845: step 14522, loss = 0.55851 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:33:35.408748 ops/training.py:65 2019-01-17 05:33:35.408671: step 14523, loss = 0.46224 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:33:36.692251 ops/training.py:65 2019-01-17 05:33:36.692185: step 14524, loss = 0.43978 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:33:37.976648 ops/training.py:65 2019-01-17 05:33:37.976577: step 14525, loss = 0.36158 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:33:39.257161 ops/training.py:65 2019-01-17 05:33:39.257082: step 14526, loss = 0.59254 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:33:40.543649 ops/training.py:65 2019-01-17 05:33:40.543544: step 14527, loss = 0.45285 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:33:41.827190 ops/training.py:65 2019-01-17 05:33:41.827089: step 14528, loss = 0.68465 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:33:43.118685 ops/training.py:65 2019-01-17 05:33:43.118592: step 14529, loss = 0.55410 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:33:44.403908 ops/training.py:65 2019-01-17 05:33:44.403833: step 14530, loss = 0.53629 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:33:45.695869 ops/training.py:65 2019-01-17 05:33:45.695772: step 14531, loss = 0.49740 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:33:46.986664 ops/training.py:65 2019-01-17 05:33:46.986597: step 14532, loss = 0.46646 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:33:48.275998 ops/training.py:65 2019-01-17 05:33:48.275910: step 14533, loss = 0.48089 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:33:49.565959 ops/training.py:65 2019-01-17 05:33:49.565889: step 14534, loss = 0.38817 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:33:50.846293 ops/training.py:65 2019-01-17 05:33:50.846204: step 14535, loss = 0.35556 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:33:52.129392 ops/training.py:65 2019-01-17 05:33:52.129329: step 14536, loss = 0.40639 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:33:53.412208 ops/training.py:65 2019-01-17 05:33:53.412107: step 14537, loss = 0.42571 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:33:54.699882 ops/training.py:65 2019-01-17 05:33:54.699778: step 14538, loss = 0.43878 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:33:55.979078 ops/training.py:65 2019-01-17 05:33:55.978972: step 14539, loss = 0.51697 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:33:57.265936 ops/training.py:65 2019-01-17 05:33:57.265780: step 14540, loss = 0.47155 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:33:58.556888 ops/training.py:65 2019-01-17 05:33:58.556799: step 14541, loss = 0.54501 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:33:59.846843 ops/training.py:65 2019-01-17 05:33:59.846768: step 14542, loss = 0.38791 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:34:01.135058 ops/training.py:65 2019-01-17 05:34:01.134995: step 14543, loss = 0.45512 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:34:02.424865 ops/training.py:65 2019-01-17 05:34:02.424795: step 14544, loss = 0.56477 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:34:03.709871 ops/training.py:65 2019-01-17 05:34:03.709808: step 14545, loss = 0.54235 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:34:04.995693 ops/training.py:65 2019-01-17 05:34:04.995592: step 14546, loss = 0.50120 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:34:06.280435 ops/training.py:65 2019-01-17 05:34:06.280335: step 14547, loss = 0.48881 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:34:07.571950 ops/training.py:65 2019-01-17 05:34:07.571852: step 14548, loss = 0.59534 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:34:08.861517 ops/training.py:65 2019-01-17 05:34:08.861446: step 14549, loss = 0.48232 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:34:10.150537 ops/training.py:65 2019-01-17 05:34:10.150474: step 14550, loss = 0.39225 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:34:11.435237 ops/training.py:65 2019-01-17 05:34:11.435174: step 14551, loss = 0.62555 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:34:12.721843 ops/training.py:65 2019-01-17 05:34:12.721754: step 14552, loss = 0.35120 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:34:14.009401 ops/training.py:65 2019-01-17 05:34:14.009298: step 14553, loss = 0.39397 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:34:15.299207 ops/training.py:65 2019-01-17 05:34:15.299125: step 14554, loss = 0.50101 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:34:16.588947 ops/training.py:65 2019-01-17 05:34:16.588844: step 14555, loss = 0.44149 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:34:17.877209 ops/training.py:65 2019-01-17 05:34:17.877097: step 14556, loss = 0.52488 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:34:19.158559 ops/training.py:65 2019-01-17 05:34:19.158450: step 14557, loss = 0.49819 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:34:20.447407 ops/training.py:65 2019-01-17 05:34:20.447309: step 14558, loss = 0.50372 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:34:21.730072 ops/training.py:65 2019-01-17 05:34:21.729949: step 14559, loss = 0.46417 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:34:23.021127 ops/training.py:65 2019-01-17 05:34:23.020982: step 14560, loss = 0.41088 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:34:24.311023 ops/training.py:65 2019-01-17 05:34:24.310921: step 14561, loss = 0.45604 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:34:25.600982 ops/training.py:65 2019-01-17 05:34:25.600904: step 14562, loss = 0.51144 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:34:26.885954 ops/training.py:65 2019-01-17 05:34:26.885887: step 14563, loss = 0.44878 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:34:28.168872 ops/training.py:65 2019-01-17 05:34:28.168777: step 14564, loss = 0.46050 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:34:29.461202 ops/training.py:65 2019-01-17 05:34:29.461093: step 14565, loss = 0.46678 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:34:30.748285 ops/training.py:65 2019-01-17 05:34:30.748222: step 14566, loss = 0.47582 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:34:32.034167 ops/training.py:65 2019-01-17 05:34:32.034004: step 14567, loss = 0.51029 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:34:33.321477 ops/training.py:65 2019-01-17 05:34:33.321371: step 14568, loss = 0.47868 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:34:34.610598 ops/training.py:65 2019-01-17 05:34:34.610442: step 14569, loss = 0.40217 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:34:35.902582 ops/training.py:65 2019-01-17 05:34:35.902434: step 14570, loss = 0.49199 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:34:37.195106 ops/training.py:65 2019-01-17 05:34:37.195013: step 14571, loss = 0.42062 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:34:38.484889 ops/training.py:65 2019-01-17 05:34:38.484825: step 14572, loss = 0.57783 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:34:39.770250 ops/training.py:65 2019-01-17 05:34:39.770156: step 14573, loss = 0.49243 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:34:41.062677 ops/training.py:65 2019-01-17 05:34:41.062578: step 14574, loss = 0.48852 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:34:42.346017 ops/training.py:65 2019-01-17 05:34:42.345944: step 14575, loss = 0.42917 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:34:43.637208 ops/training.py:65 2019-01-17 05:34:43.637085: step 14576, loss = 0.40616 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:34:44.928232 ops/training.py:65 2019-01-17 05:34:44.928157: step 14577, loss = 0.46892 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:34:46.218425 ops/training.py:65 2019-01-17 05:34:46.218354: step 14578, loss = 0.64348 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:34:47.506958 ops/training.py:65 2019-01-17 05:34:47.506881: step 14579, loss = 0.43238 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:34:48.788376 ops/training.py:65 2019-01-17 05:34:48.788312: step 14580, loss = 0.56919 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:34:50.074985 ops/training.py:65 2019-01-17 05:34:50.074873: step 14581, loss = 0.66071 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:34:51.359327 ops/training.py:65 2019-01-17 05:34:51.359216: step 14582, loss = 0.48559 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:34:52.647179 ops/training.py:65 2019-01-17 05:34:52.647066: step 14583, loss = 0.43913 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:34:53.931789 ops/training.py:65 2019-01-17 05:34:53.931641: step 14584, loss = 0.42772 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:34:55.225969 ops/training.py:65 2019-01-17 05:34:55.225859: step 14585, loss = 0.62704 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:34:56.511142 ops/training.py:65 2019-01-17 05:34:56.511075: step 14586, loss = 0.50060 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:34:57.801388 ops/training.py:65 2019-01-17 05:34:57.801297: step 14587, loss = 0.50461 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:34:59.091047 ops/training.py:65 2019-01-17 05:34:59.090953: step 14588, loss = 0.45825 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:35:00.375670 ops/training.py:65 2019-01-17 05:35:00.375600: step 14589, loss = 0.47074 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:35:01.665085 ops/training.py:65 2019-01-17 05:35:01.664986: step 14590, loss = 0.51336 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:35:02.956202 ops/training.py:65 2019-01-17 05:35:02.956096: step 14591, loss = 0.52805 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:35:04.240566 ops/training.py:65 2019-01-17 05:35:04.240492: step 14592, loss = 0.56861 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:35:05.525138 ops/training.py:65 2019-01-17 05:35:05.525034: step 14593, loss = 0.45949 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:35:06.817216 ops/training.py:65 2019-01-17 05:35:06.817120: step 14594, loss = 0.46146 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:35:08.103257 ops/training.py:65 2019-01-17 05:35:08.103191: step 14595, loss = 0.36483 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:35:09.385101 ops/training.py:65 2019-01-17 05:35:09.384996: step 14596, loss = 0.48522 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:35:10.670657 ops/training.py:65 2019-01-17 05:35:10.670548: step 14597, loss = 0.45007 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:35:11.963967 ops/training.py:65 2019-01-17 05:35:11.963865: step 14598, loss = 0.51103 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:35:13.257343 ops/training.py:65 2019-01-17 05:35:13.257272: step 14599, loss = 0.53582 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:35:14.548065 ops/training.py:65 2019-01-17 05:35:14.547993: step 14600, loss = 0.54218 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:35:15.836977 ops/training.py:65 2019-01-17 05:35:15.836912: step 14601, loss = 0.46444 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:35:17.125501 ops/training.py:65 2019-01-17 05:35:17.125436: step 14602, loss = 0.43553 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:35:18.414881 ops/training.py:65 2019-01-17 05:35:18.414809: step 14603, loss = 0.47757 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:35:19.704808 ops/training.py:65 2019-01-17 05:35:19.704709: step 14604, loss = 0.54887 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:35:20.993874 ops/training.py:65 2019-01-17 05:35:20.993781: step 14605, loss = 0.50680 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:35:22.283780 ops/training.py:65 2019-01-17 05:35:22.283698: step 14606, loss = 0.44713 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:35:23.575126 ops/training.py:65 2019-01-17 05:35:23.575057: step 14607, loss = 0.56674 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:35:24.870278 ops/training.py:65 2019-01-17 05:35:24.870182: step 14608, loss = 0.51294 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:35:26.159202 ops/training.py:65 2019-01-17 05:35:26.159112: step 14609, loss = 0.49682 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:35:27.448680 ops/training.py:65 2019-01-17 05:35:27.448584: step 14610, loss = 0.51234 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:35:28.745144 ops/training.py:65 2019-01-17 05:35:28.745062: step 14611, loss = 0.52044 (24.7 examples/sec; 1.295 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:35:30.028168 ops/training.py:65 2019-01-17 05:35:30.028098: step 14612, loss = 0.45355 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:35:31.313641 ops/training.py:65 2019-01-17 05:35:31.313534: step 14613, loss = 0.51786 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:35:32.605777 ops/training.py:65 2019-01-17 05:35:32.605678: step 14614, loss = 0.43533 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:35:33.892848 ops/training.py:65 2019-01-17 05:35:33.892780: step 14615, loss = 0.58738 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:35:35.183671 ops/training.py:65 2019-01-17 05:35:35.183560: step 14616, loss = 0.41806 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:35:36.474743 ops/training.py:65 2019-01-17 05:35:36.474669: step 14617, loss = 0.34303 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:35:37.764659 ops/training.py:65 2019-01-17 05:35:37.764583: step 14618, loss = 0.41076 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:35:39.052535 ops/training.py:65 2019-01-17 05:35:39.052471: step 14619, loss = 0.42447 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:35:40.340199 ops/training.py:65 2019-01-17 05:35:40.340130: step 14620, loss = 0.50832 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:35:41.630455 ops/training.py:65 2019-01-17 05:35:41.630346: step 14621, loss = 0.49609 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:35:42.925109 ops/training.py:65 2019-01-17 05:35:42.925038: step 14622, loss = 0.53436 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:35:44.213726 ops/training.py:65 2019-01-17 05:35:44.213662: step 14623, loss = 0.45560 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:35:45.502652 ops/training.py:65 2019-01-17 05:35:45.502580: step 14624, loss = 0.48766 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:35:46.787620 ops/training.py:65 2019-01-17 05:35:46.787553: step 14625, loss = 0.50279 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:35:48.076665 ops/training.py:65 2019-01-17 05:35:48.076600: step 14626, loss = 0.54158 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:35:49.365695 ops/training.py:65 2019-01-17 05:35:49.365630: step 14627, loss = 0.52316 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:35:50.654491 ops/training.py:65 2019-01-17 05:35:50.654416: step 14628, loss = 0.45089 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:35:51.950504 ops/training.py:65 2019-01-17 05:35:51.950411: step 14629, loss = 0.51556 (24.7 examples/sec; 1.295 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:35:53.240766 ops/training.py:65 2019-01-17 05:35:53.240701: step 14630, loss = 0.48714 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:35:54.525391 ops/training.py:65 2019-01-17 05:35:54.525321: step 14631, loss = 0.43927 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:35:55.812954 ops/training.py:65 2019-01-17 05:35:55.812846: step 14632, loss = 0.42907 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:35:57.105661 ops/training.py:65 2019-01-17 05:35:57.105551: step 14633, loss = 0.45659 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:35:58.396483 ops/training.py:65 2019-01-17 05:35:58.396416: step 14634, loss = 0.39191 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:35:59.681147 ops/training.py:65 2019-01-17 05:35:59.681076: step 14635, loss = 0.48407 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:36:00.966383 ops/training.py:65 2019-01-17 05:36:00.966283: step 14636, loss = 0.35484 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:36:02.257621 ops/training.py:65 2019-01-17 05:36:02.257510: step 14637, loss = 0.49344 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:36:03.549273 ops/training.py:65 2019-01-17 05:36:03.549200: step 14638, loss = 0.34358 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:36:04.834633 ops/training.py:65 2019-01-17 05:36:04.834542: step 14639, loss = 0.51299 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:36:06.119638 ops/training.py:65 2019-01-17 05:36:06.119527: step 14640, loss = 0.40747 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:36:07.413304 ops/training.py:65 2019-01-17 05:36:07.413197: step 14641, loss = 0.42546 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:36:08.699009 ops/training.py:65 2019-01-17 05:36:08.698947: step 14642, loss = 0.43232 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:36:09.984581 ops/training.py:65 2019-01-17 05:36:09.984479: step 14643, loss = 0.58771 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:36:11.279032 ops/training.py:65 2019-01-17 05:36:11.278927: step 14644, loss = 0.41076 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:36:12.570063 ops/training.py:65 2019-01-17 05:36:12.569964: step 14645, loss = 0.46555 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:36:13.856043 ops/training.py:65 2019-01-17 05:36:13.855972: step 14646, loss = 0.54280 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:36:15.140275 ops/training.py:65 2019-01-17 05:36:15.140173: step 14647, loss = 0.46771 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:36:16.432741 ops/training.py:65 2019-01-17 05:36:16.432640: step 14648, loss = 0.46747 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:36:17.724798 ops/training.py:65 2019-01-17 05:36:17.724723: step 14649, loss = 0.45328 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:36:19.015093 ops/training.py:65 2019-01-17 05:36:19.015024: step 14650, loss = 0.49427 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:36:20.300593 ops/training.py:65 2019-01-17 05:36:20.300527: step 14651, loss = 0.48943 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:36:21.590616 ops/training.py:65 2019-01-17 05:36:21.590493: step 14652, loss = 0.46769 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:36:22.873369 ops/training.py:65 2019-01-17 05:36:22.873310: step 14653, loss = 0.58297 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:36:24.162836 ops/training.py:65 2019-01-17 05:36:24.162744: step 14654, loss = 0.48389 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:36:25.451728 ops/training.py:65 2019-01-17 05:36:25.451656: step 14655, loss = 0.61601 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:36:26.741556 ops/training.py:65 2019-01-17 05:36:26.741485: step 14656, loss = 0.41647 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:36:28.029176 ops/training.py:65 2019-01-17 05:36:28.029068: step 14657, loss = 0.48470 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:36:29.314350 ops/training.py:65 2019-01-17 05:36:29.314256: step 14658, loss = 0.41511 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:36:30.598314 ops/training.py:65 2019-01-17 05:36:30.598242: step 14659, loss = 0.50503 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:36:31.885564 ops/training.py:65 2019-01-17 05:36:31.885455: step 14660, loss = 0.53818 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:36:33.167161 ops/training.py:65 2019-01-17 05:36:33.167054: step 14661, loss = 0.44385 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:36:34.448849 ops/training.py:65 2019-01-17 05:36:34.448731: step 14662, loss = 0.45398 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:36:35.732064 ops/training.py:65 2019-01-17 05:36:35.731963: step 14663, loss = 0.54473 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:36:37.029533 ops/training.py:65 2019-01-17 05:36:37.029428: step 14664, loss = 0.40811 (24.7 examples/sec; 1.296 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:36:38.316148 ops/training.py:65 2019-01-17 05:36:38.316058: step 14665, loss = 0.47646 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:36:39.606218 ops/training.py:65 2019-01-17 05:36:39.606113: step 14666, loss = 0.47567 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:36:40.893782 ops/training.py:65 2019-01-17 05:36:40.893701: step 14667, loss = 0.51552 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:36:42.182677 ops/training.py:65 2019-01-17 05:36:42.182604: step 14668, loss = 0.48249 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:36:43.472097 ops/training.py:65 2019-01-17 05:36:43.472025: step 14669, loss = 0.40429 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:36:44.759794 ops/training.py:65 2019-01-17 05:36:44.759725: step 14670, loss = 0.50960 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:36:46.044195 ops/training.py:65 2019-01-17 05:36:46.044118: step 14671, loss = 0.41732 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:36:47.336334 ops/training.py:65 2019-01-17 05:36:47.336201: step 14672, loss = 0.52878 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:36:48.627703 ops/training.py:65 2019-01-17 05:36:48.627635: step 14673, loss = 0.46630 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:36:49.912385 ops/training.py:65 2019-01-17 05:36:49.912315: step 14674, loss = 0.59822 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:36:51.196543 ops/training.py:65 2019-01-17 05:36:51.196472: step 14675, loss = 0.41424 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:36:52.485441 ops/training.py:65 2019-01-17 05:36:52.485339: step 14676, loss = 0.41264 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:36:53.776960 ops/training.py:65 2019-01-17 05:36:53.776886: step 14677, loss = 0.43095 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:36:55.065965 ops/training.py:65 2019-01-17 05:36:55.065893: step 14678, loss = 0.71326 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:36:56.355661 ops/training.py:65 2019-01-17 05:36:56.355585: step 14679, loss = 0.66933 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:36:57.642302 ops/training.py:65 2019-01-17 05:36:57.642225: step 14680, loss = 0.46633 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:36:58.931729 ops/training.py:65 2019-01-17 05:36:58.931655: step 14681, loss = 0.54114 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:37:00.220114 ops/training.py:65 2019-01-17 05:37:00.220047: step 14682, loss = 0.37822 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:37:01.509187 ops/training.py:65 2019-01-17 05:37:01.509116: step 14683, loss = 0.42325 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:37:02.798798 ops/training.py:65 2019-01-17 05:37:02.798727: step 14684, loss = 0.42979 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:37:04.089177 ops/training.py:65 2019-01-17 05:37:04.089106: step 14685, loss = 0.47816 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:37:05.378265 ops/training.py:65 2019-01-17 05:37:05.378199: step 14686, loss = 0.44490 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:37:06.666839 ops/training.py:65 2019-01-17 05:37:06.666772: step 14687, loss = 0.43370 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:37:07.950492 ops/training.py:65 2019-01-17 05:37:07.950433: step 14688, loss = 0.51189 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:37:09.235068 ops/training.py:65 2019-01-17 05:37:09.234993: step 14689, loss = 0.44013 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:37:10.527170 ops/training.py:65 2019-01-17 05:37:10.527062: step 14690, loss = 0.42132 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:37:11.819221 ops/training.py:65 2019-01-17 05:37:11.819132: step 14691, loss = 0.47951 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:37:13.104831 ops/training.py:65 2019-01-17 05:37:13.104767: step 14692, loss = 0.46641 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:37:14.392142 ops/training.py:65 2019-01-17 05:37:14.392037: step 14693, loss = 0.44179 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:37:15.685391 ops/training.py:65 2019-01-17 05:37:15.685282: step 14694, loss = 0.41647 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:37:16.972055 ops/training.py:65 2019-01-17 05:37:16.971982: step 14695, loss = 0.45969 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:37:18.258485 ops/training.py:65 2019-01-17 05:37:18.258401: step 14696, loss = 0.62099 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:37:19.550455 ops/training.py:65 2019-01-17 05:37:19.550347: step 14697, loss = 0.43827 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:37:20.842420 ops/training.py:65 2019-01-17 05:37:20.842348: step 14698, loss = 0.47159 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:37:22.132751 ops/training.py:65 2019-01-17 05:37:22.132648: step 14699, loss = 0.49952 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:37:23.421982 ops/training.py:65 2019-01-17 05:37:23.421902: step 14700, loss = 0.46292 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:37:24.711853 ops/training.py:65 2019-01-17 05:37:24.711779: step 14701, loss = 0.36807 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:37:26.000503 ops/training.py:65 2019-01-17 05:37:26.000442: step 14702, loss = 0.47058 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:37:27.289516 ops/training.py:65 2019-01-17 05:37:27.289444: step 14703, loss = 0.42790 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:37:28.574483 ops/training.py:65 2019-01-17 05:37:28.574388: step 14704, loss = 0.37720 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:37:29.858482 ops/training.py:65 2019-01-17 05:37:29.858377: step 14705, loss = 0.54194 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:37:31.150538 ops/training.py:65 2019-01-17 05:37:31.150429: step 14706, loss = 0.57581 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:37:32.440092 ops/training.py:65 2019-01-17 05:37:32.440028: step 14707, loss = 0.42068 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:37:33.724045 ops/training.py:65 2019-01-17 05:37:33.723969: step 14708, loss = 0.41905 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:37:35.009058 ops/training.py:65 2019-01-17 05:37:35.008962: step 14709, loss = 0.50728 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:37:36.297587 ops/training.py:65 2019-01-17 05:37:36.297512: step 14710, loss = 0.44508 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:37:37.582789 ops/training.py:65 2019-01-17 05:37:37.582718: step 14711, loss = 0.48568 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:37:38.869893 ops/training.py:65 2019-01-17 05:37:38.869822: step 14712, loss = 0.46329 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:37:40.158941 ops/training.py:65 2019-01-17 05:37:40.158875: step 14713, loss = 0.57974 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:37:41.443436 ops/training.py:65 2019-01-17 05:37:41.443369: step 14714, loss = 0.53430 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:37:42.726736 ops/training.py:65 2019-01-17 05:37:42.726658: step 14715, loss = 0.41273 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:37:44.018051 ops/training.py:65 2019-01-17 05:37:44.017950: step 14716, loss = 0.52883 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:37:45.305099 ops/training.py:65 2019-01-17 05:37:45.305037: step 14717, loss = 0.44388 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:37:46.594757 ops/training.py:65 2019-01-17 05:37:46.594650: step 14718, loss = 0.48465 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:37:47.884769 ops/training.py:65 2019-01-17 05:37:47.884655: step 14719, loss = 0.43924 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:37:49.174485 ops/training.py:65 2019-01-17 05:37:49.174406: step 14720, loss = 0.47704 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:37:50.458699 ops/training.py:65 2019-01-17 05:37:50.458627: step 14721, loss = 0.38688 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:37:51.750871 ops/training.py:65 2019-01-17 05:37:51.750710: step 14722, loss = 0.45106 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:37:53.041642 ops/training.py:65 2019-01-17 05:37:53.041566: step 14723, loss = 0.51212 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:37:54.329725 ops/training.py:65 2019-01-17 05:37:54.329621: step 14724, loss = 0.43952 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:37:55.618997 ops/training.py:65 2019-01-17 05:37:55.618933: step 14725, loss = 0.40837 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:37:56.908074 ops/training.py:65 2019-01-17 05:37:56.907976: step 14726, loss = 0.47114 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:37:58.202755 ops/training.py:65 2019-01-17 05:37:58.202676: step 14727, loss = 0.46992 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:37:59.491176 ops/training.py:65 2019-01-17 05:37:59.491105: step 14728, loss = 0.55618 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:38:00.776322 ops/training.py:65 2019-01-17 05:38:00.776253: step 14729, loss = 0.43318 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:38:02.066418 ops/training.py:65 2019-01-17 05:38:02.066311: step 14730, loss = 0.45687 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:38:03.356616 ops/training.py:65 2019-01-17 05:38:03.356470: step 14731, loss = 0.39196 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:38:04.642018 ops/training.py:65 2019-01-17 05:38:04.641945: step 14732, loss = 0.49497 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:38:05.930891 ops/training.py:65 2019-01-17 05:38:05.930812: step 14733, loss = 0.45875 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:38:07.219274 ops/training.py:65 2019-01-17 05:38:07.219208: step 14734, loss = 0.53946 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:38:08.509483 ops/training.py:65 2019-01-17 05:38:08.509411: step 14735, loss = 0.49228 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:38:09.798973 ops/training.py:65 2019-01-17 05:38:09.798875: step 14736, loss = 0.38131 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:38:11.088003 ops/training.py:65 2019-01-17 05:38:11.087903: step 14737, loss = 0.51904 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:38:12.372084 ops/training.py:65 2019-01-17 05:38:12.371978: step 14738, loss = 0.40753 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:38:13.663053 ops/training.py:65 2019-01-17 05:38:13.662967: step 14739, loss = 0.55432 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:38:14.953058 ops/training.py:65 2019-01-17 05:38:14.952987: step 14740, loss = 0.45154 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:38:16.241396 ops/training.py:65 2019-01-17 05:38:16.241329: step 14741, loss = 0.50164 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:38:17.531047 ops/training.py:65 2019-01-17 05:38:17.530953: step 14742, loss = 0.44852 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:38:18.820114 ops/training.py:65 2019-01-17 05:38:18.820048: step 14743, loss = 0.49481 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:38:20.107549 ops/training.py:65 2019-01-17 05:38:20.107483: step 14744, loss = 0.40412 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:38:21.396974 ops/training.py:65 2019-01-17 05:38:21.396898: step 14745, loss = 0.45405 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:38:22.681304 ops/training.py:65 2019-01-17 05:38:22.681240: step 14746, loss = 0.47631 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:38:23.966970 ops/training.py:65 2019-01-17 05:38:23.966867: step 14747, loss = 0.44599 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:38:25.260147 ops/training.py:65 2019-01-17 05:38:25.259989: step 14748, loss = 0.52641 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:38:26.551262 ops/training.py:65 2019-01-17 05:38:26.551187: step 14749, loss = 0.45943 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:38:27.839545 ops/training.py:65 2019-01-17 05:38:27.839474: step 14750, loss = 0.41984 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:38:29.128361 ops/training.py:65 2019-01-17 05:38:29.128296: step 14751, loss = 0.51969 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:38:30.417509 ops/training.py:65 2019-01-17 05:38:30.417436: step 14752, loss = 0.52161 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:38:31.706906 ops/training.py:65 2019-01-17 05:38:31.706828: step 14753, loss = 0.47095 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:38:32.990973 ops/training.py:65 2019-01-17 05:38:32.990901: step 14754, loss = 0.52877 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:38:34.279337 ops/training.py:65 2019-01-17 05:38:34.279268: step 14755, loss = 0.48657 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:38:35.568624 ops/training.py:65 2019-01-17 05:38:35.568529: step 14756, loss = 0.50160 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:38:36.855901 ops/training.py:65 2019-01-17 05:38:36.855802: step 14757, loss = 0.40207 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:38:38.140277 ops/training.py:65 2019-01-17 05:38:38.140207: step 14758, loss = 0.36970 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:38:39.429683 ops/training.py:65 2019-01-17 05:38:39.429587: step 14759, loss = 0.36804 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:38:40.715359 ops/training.py:65 2019-01-17 05:38:40.715289: step 14760, loss = 0.48473 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:38:42.004823 ops/training.py:65 2019-01-17 05:38:42.004761: step 14761, loss = 0.41758 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:38:43.294484 ops/training.py:65 2019-01-17 05:38:43.294404: step 14762, loss = 0.43893 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:38:44.584346 ops/training.py:65 2019-01-17 05:38:44.584273: step 14763, loss = 0.41298 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:38:45.873791 ops/training.py:65 2019-01-17 05:38:45.873717: step 14764, loss = 0.48458 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:38:47.162995 ops/training.py:65 2019-01-17 05:38:47.162918: step 14765, loss = 0.45012 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:38:48.452055 ops/training.py:65 2019-01-17 05:38:48.451980: step 14766, loss = 0.41462 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:38:49.740605 ops/training.py:65 2019-01-17 05:38:49.740528: step 14767, loss = 0.38394 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:38:51.028842 ops/training.py:65 2019-01-17 05:38:51.028772: step 14768, loss = 0.56923 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:38:52.312291 ops/training.py:65 2019-01-17 05:38:52.312226: step 14769, loss = 0.46766 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:38:53.597743 ops/training.py:65 2019-01-17 05:38:53.597651: step 14770, loss = 0.42621 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:38:54.885969 ops/training.py:65 2019-01-17 05:38:54.885822: step 14771, loss = 0.42912 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:38:56.174728 ops/training.py:65 2019-01-17 05:38:56.174619: step 14772, loss = 0.47583 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:38:57.466732 ops/training.py:65 2019-01-17 05:38:57.466624: step 14773, loss = 0.43793 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:38:58.755730 ops/training.py:65 2019-01-17 05:38:58.755659: step 14774, loss = 0.48245 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:39:00.040392 ops/training.py:65 2019-01-17 05:39:00.040281: step 14775, loss = 0.40747 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:39:01.327696 ops/training.py:65 2019-01-17 05:39:01.327582: step 14776, loss = 0.51445 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:39:02.608890 ops/training.py:65 2019-01-17 05:39:02.608783: step 14777, loss = 0.43258 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:39:03.889003 ops/training.py:65 2019-01-17 05:39:03.888896: step 14778, loss = 0.40020 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:39:05.170628 ops/training.py:65 2019-01-17 05:39:05.170518: step 14779, loss = 0.36343 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:39:06.460296 ops/training.py:65 2019-01-17 05:39:06.460199: step 14780, loss = 0.54478 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:39:07.751849 ops/training.py:65 2019-01-17 05:39:07.751743: step 14781, loss = 0.40784 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:39:09.038770 ops/training.py:65 2019-01-17 05:39:09.038705: step 14782, loss = 0.44254 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:39:10.317125 ops/training.py:65 2019-01-17 05:39:10.317042: step 14783, loss = 0.41948 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:39:11.599118 ops/training.py:65 2019-01-17 05:39:11.599008: step 14784, loss = 0.57762 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:39:12.880992 ops/training.py:65 2019-01-17 05:39:12.880891: step 14785, loss = 0.46105 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:39:14.158048 ops/training.py:65 2019-01-17 05:39:14.157960: step 14786, loss = 0.40417 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:39:15.441850 ops/training.py:65 2019-01-17 05:39:15.441702: step 14787, loss = 0.43414 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:39:16.728419 ops/training.py:65 2019-01-17 05:39:16.728257: step 14788, loss = 0.48312 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:39:18.015621 ops/training.py:65 2019-01-17 05:39:18.015517: step 14789, loss = 0.46428 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:39:19.302037 ops/training.py:65 2019-01-17 05:39:19.301928: step 14790, loss = 0.43238 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:39:20.582588 ops/training.py:65 2019-01-17 05:39:20.582479: step 14791, loss = 0.52494 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:39:21.867726 ops/training.py:65 2019-01-17 05:39:21.867620: step 14792, loss = 0.41982 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:39:23.160311 ops/training.py:65 2019-01-17 05:39:23.160202: step 14793, loss = 0.48374 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:39:24.450945 ops/training.py:65 2019-01-17 05:39:24.450855: step 14794, loss = 0.37364 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:39:25.740522 ops/training.py:65 2019-01-17 05:39:25.740453: step 14795, loss = 0.48475 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:39:27.030567 ops/training.py:65 2019-01-17 05:39:27.030468: step 14796, loss = 0.41943 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:39:28.320913 ops/training.py:65 2019-01-17 05:39:28.320818: step 14797, loss = 0.41098 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:39:29.610642 ops/training.py:65 2019-01-17 05:39:29.610551: step 14798, loss = 0.48612 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:39:30.898689 ops/training.py:65 2019-01-17 05:39:30.898614: step 14799, loss = 0.45404 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:39:32.182782 ops/training.py:65 2019-01-17 05:39:32.182714: step 14800, loss = 0.48308 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:39:33.465603 ops/training.py:65 2019-01-17 05:39:33.465536: step 14801, loss = 0.40571 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:39:34.755740 ops/training.py:65 2019-01-17 05:39:34.755632: step 14802, loss = 0.53566 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:39:36.048837 ops/training.py:65 2019-01-17 05:39:36.048729: step 14803, loss = 0.50358 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:39:37.335894 ops/training.py:65 2019-01-17 05:39:37.335798: step 14804, loss = 0.51414 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:39:38.626334 ops/training.py:65 2019-01-17 05:39:38.626225: step 14805, loss = 0.46455 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:39:39.907405 ops/training.py:65 2019-01-17 05:39:39.907324: step 14806, loss = 0.52351 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:39:41.192077 ops/training.py:65 2019-01-17 05:39:41.191965: step 14807, loss = 0.41046 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:39:42.480535 ops/training.py:65 2019-01-17 05:39:42.480428: step 14808, loss = 0.41046 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:39:43.766487 ops/training.py:65 2019-01-17 05:39:43.766388: step 14809, loss = 0.46820 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:39:45.051740 ops/training.py:65 2019-01-17 05:39:45.051627: step 14810, loss = 0.37997 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:39:46.342048 ops/training.py:65 2019-01-17 05:39:46.341941: step 14811, loss = 0.48286 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:39:47.626997 ops/training.py:65 2019-01-17 05:39:47.626890: step 14812, loss = 0.51057 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:39:48.919669 ops/training.py:65 2019-01-17 05:39:48.919556: step 14813, loss = 0.39116 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:39:50.203077 ops/training.py:65 2019-01-17 05:39:50.202973: step 14814, loss = 0.44199 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:39:51.497263 ops/training.py:65 2019-01-17 05:39:51.497155: step 14815, loss = 0.39931 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:39:52.787967 ops/training.py:65 2019-01-17 05:39:52.787892: step 14816, loss = 0.45777 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:39:54.072569 ops/training.py:65 2019-01-17 05:39:54.072495: step 14817, loss = 0.51060 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:39:55.353134 ops/training.py:65 2019-01-17 05:39:55.353016: step 14818, loss = 0.45788 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:39:56.646147 ops/training.py:65 2019-01-17 05:39:56.646039: step 14819, loss = 0.44908 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:39:57.936405 ops/training.py:65 2019-01-17 05:39:57.936335: step 14820, loss = 0.37867 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:39:59.226408 ops/training.py:65 2019-01-17 05:39:59.226343: step 14821, loss = 0.40957 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:40:00.514677 ops/training.py:65 2019-01-17 05:40:00.514606: step 14822, loss = 0.51406 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:40:01.803727 ops/training.py:65 2019-01-17 05:40:01.803662: step 14823, loss = 0.45135 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:40:03.093326 ops/training.py:65 2019-01-17 05:40:03.093248: step 14824, loss = 0.48211 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:40:04.377346 ops/training.py:65 2019-01-17 05:40:04.377265: step 14825, loss = 0.54491 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:40:05.672825 ops/training.py:65 2019-01-17 05:40:05.672719: step 14826, loss = 0.42648 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:40:06.963846 ops/training.py:65 2019-01-17 05:40:06.963757: step 14827, loss = 0.47306 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:40:08.252781 ops/training.py:65 2019-01-17 05:40:08.252705: step 14828, loss = 0.42496 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:40:09.543455 ops/training.py:65 2019-01-17 05:40:09.543365: step 14829, loss = 0.47219 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:40:10.828945 ops/training.py:65 2019-01-17 05:40:10.828872: step 14830, loss = 0.43483 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:40:12.112895 ops/training.py:65 2019-01-17 05:40:12.112785: step 14831, loss = 0.42842 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:40:13.398883 ops/training.py:65 2019-01-17 05:40:13.398785: step 14832, loss = 0.42255 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:40:14.685251 ops/training.py:65 2019-01-17 05:40:14.685146: step 14833, loss = 0.40030 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:40:15.978001 ops/training.py:65 2019-01-17 05:40:15.977856: step 14834, loss = 0.60030 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:40:17.269286 ops/training.py:65 2019-01-17 05:40:17.269220: step 14835, loss = 0.41883 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:40:18.559280 ops/training.py:65 2019-01-17 05:40:18.559212: step 14836, loss = 0.43166 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:40:19.849224 ops/training.py:65 2019-01-17 05:40:19.849158: step 14837, loss = 0.36518 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:40:21.134366 ops/training.py:65 2019-01-17 05:40:21.134301: step 14838, loss = 0.49228 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:40:22.420381 ops/training.py:65 2019-01-17 05:40:22.420270: step 14839, loss = 0.43281 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:40:23.710317 ops/training.py:65 2019-01-17 05:40:23.710217: step 14840, loss = 0.53934 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:40:24.993511 ops/training.py:65 2019-01-17 05:40:24.993357: step 14841, loss = 0.49617 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:40:26.286174 ops/training.py:65 2019-01-17 05:40:26.286017: step 14842, loss = 0.41936 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:40:27.574865 ops/training.py:65 2019-01-17 05:40:27.574799: step 14843, loss = 0.47547 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:40:28.857315 ops/training.py:65 2019-01-17 05:40:28.857173: step 14844, loss = 0.48441 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:40:30.146435 ops/training.py:65 2019-01-17 05:40:30.146325: step 14845, loss = 0.37959 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:40:31.433161 ops/training.py:65 2019-01-17 05:40:31.433051: step 14846, loss = 0.42481 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:40:32.724504 ops/training.py:65 2019-01-17 05:40:32.724397: step 14847, loss = 0.41136 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:40:34.010862 ops/training.py:65 2019-01-17 05:40:34.010790: step 14848, loss = 0.49275 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:40:35.290868 ops/training.py:65 2019-01-17 05:40:35.290757: step 14849, loss = 0.42055 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:40:36.580243 ops/training.py:65 2019-01-17 05:40:36.580085: step 14850, loss = 0.42640 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:40:37.869567 ops/training.py:65 2019-01-17 05:40:37.869458: step 14851, loss = 0.46583 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:40:39.154386 ops/training.py:65 2019-01-17 05:40:39.154277: step 14852, loss = 0.46065 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:40:40.443244 ops/training.py:65 2019-01-17 05:40:40.443093: step 14853, loss = 0.48791 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:40:41.729778 ops/training.py:65 2019-01-17 05:40:41.729673: step 14854, loss = 0.44970 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:40:43.016994 ops/training.py:65 2019-01-17 05:40:43.016898: step 14855, loss = 0.46696 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:40:44.300087 ops/training.py:65 2019-01-17 05:40:44.299985: step 14856, loss = 0.39448 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:40:45.591604 ops/training.py:65 2019-01-17 05:40:45.591500: step 14857, loss = 0.48295 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:40:46.883193 ops/training.py:65 2019-01-17 05:40:46.883129: step 14858, loss = 0.39074 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:40:48.167852 ops/training.py:65 2019-01-17 05:40:48.167792: step 14859, loss = 0.45641 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:40:49.451655 ops/training.py:65 2019-01-17 05:40:49.451545: step 14860, loss = 0.50705 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:40:50.737419 ops/training.py:65 2019-01-17 05:40:50.737317: step 14861, loss = 0.34029 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:40:52.034840 ops/training.py:65 2019-01-17 05:40:52.034733: step 14862, loss = 0.31000 (24.7 examples/sec; 1.296 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 05:40:53.325139 ops/training.py:65 2019-01-17 05:40:53.325062: step 14863, loss = 0.36204 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:40:54.611117 ops/training.py:65 2019-01-17 05:40:54.611039: step 14864, loss = 0.47120 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:40:55.903771 ops/training.py:65 2019-01-17 05:40:55.903661: step 14865, loss = 0.40826 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:40:57.195537 ops/training.py:65 2019-01-17 05:40:57.195466: step 14866, loss = 0.51205 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:40:58.483970 ops/training.py:65 2019-01-17 05:40:58.483881: step 14867, loss = 0.40700 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:40:59.774783 ops/training.py:65 2019-01-17 05:40:59.774711: step 14868, loss = 0.37720 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:41:01.063242 ops/training.py:65 2019-01-17 05:41:01.063172: step 14869, loss = 0.50464 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:41:02.350396 ops/training.py:65 2019-01-17 05:41:02.350333: step 14870, loss = 0.47633 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:41:03.639418 ops/training.py:65 2019-01-17 05:41:03.639351: step 14871, loss = 0.50798 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:41:04.927271 ops/training.py:65 2019-01-17 05:41:04.927199: step 14872, loss = 0.46808 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:41:06.215442 ops/training.py:65 2019-01-17 05:41:06.215371: step 14873, loss = 0.52464 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:41:07.505070 ops/training.py:65 2019-01-17 05:41:07.504999: step 14874, loss = 0.41705 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:41:08.794013 ops/training.py:65 2019-01-17 05:41:08.793945: step 14875, loss = 0.40166 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:41:10.082453 ops/training.py:65 2019-01-17 05:41:10.082371: step 14876, loss = 0.45907 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:41:11.371386 ops/training.py:65 2019-01-17 05:41:11.371319: step 14877, loss = 0.42883 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:41:12.653734 ops/training.py:65 2019-01-17 05:41:12.653654: step 14878, loss = 0.37664 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:41:13.937686 ops/training.py:65 2019-01-17 05:41:13.937584: step 14879, loss = 0.49010 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:41:15.224843 ops/training.py:65 2019-01-17 05:41:15.224737: step 14880, loss = 0.51128 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:41:16.511598 ops/training.py:65 2019-01-17 05:41:16.511500: step 14881, loss = 0.42530 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:41:17.798445 ops/training.py:65 2019-01-17 05:41:17.798346: step 14882, loss = 0.54656 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:41:19.090149 ops/training.py:65 2019-01-17 05:41:19.090041: step 14883, loss = 0.53057 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:41:20.376352 ops/training.py:65 2019-01-17 05:41:20.376282: step 14884, loss = 0.45236 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:41:21.661470 ops/training.py:65 2019-01-17 05:41:21.661387: step 14885, loss = 0.46348 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:41:22.949159 ops/training.py:65 2019-01-17 05:41:22.949050: step 14886, loss = 0.51550 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:41:24.234191 ops/training.py:65 2019-01-17 05:41:24.234041: step 14887, loss = 0.47635 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:41:25.521982 ops/training.py:65 2019-01-17 05:41:25.521869: step 14888, loss = 0.48439 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:41:26.804704 ops/training.py:65 2019-01-17 05:41:26.804598: step 14889, loss = 0.48825 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:41:28.093428 ops/training.py:65 2019-01-17 05:41:28.093327: step 14890, loss = 0.45222 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:41:29.380828 ops/training.py:65 2019-01-17 05:41:29.380718: step 14891, loss = 0.47983 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:41:30.671027 ops/training.py:65 2019-01-17 05:41:30.670927: step 14892, loss = 0.39052 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:41:31.962888 ops/training.py:65 2019-01-17 05:41:31.962812: step 14893, loss = 0.49248 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:41:33.252211 ops/training.py:65 2019-01-17 05:41:33.252137: step 14894, loss = 0.45863 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:41:34.540128 ops/training.py:65 2019-01-17 05:41:34.540062: step 14895, loss = 0.41705 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:41:35.825318 ops/training.py:65 2019-01-17 05:41:35.825248: step 14896, loss = 0.48455 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:41:37.113669 ops/training.py:65 2019-01-17 05:41:37.113610: step 14897, loss = 0.35861 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:41:38.401629 ops/training.py:65 2019-01-17 05:41:38.401560: step 14898, loss = 0.39752 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:41:39.686956 ops/training.py:65 2019-01-17 05:41:39.686895: step 14899, loss = 0.37496 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:41:40.972354 ops/training.py:65 2019-01-17 05:41:40.972246: step 14900, loss = 0.41034 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:41:42.260137 ops/training.py:65 2019-01-17 05:41:42.260036: step 14901, loss = 0.42396 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:41:43.545898 ops/training.py:65 2019-01-17 05:41:43.545804: step 14902, loss = 0.50457 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:41:44.840300 ops/training.py:65 2019-01-17 05:41:44.840196: step 14903, loss = 0.42484 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:41:46.131997 ops/training.py:65 2019-01-17 05:41:46.131921: step 14904, loss = 0.60246 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:41:47.420627 ops/training.py:65 2019-01-17 05:41:47.420555: step 14905, loss = 0.41451 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:41:48.705347 ops/training.py:65 2019-01-17 05:41:48.705282: step 14906, loss = 0.45959 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:41:49.995833 ops/training.py:65 2019-01-17 05:41:49.995742: step 14907, loss = 0.40126 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:41:51.281147 ops/training.py:65 2019-01-17 05:41:51.281083: step 14908, loss = 0.45256 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:41:52.570504 ops/training.py:65 2019-01-17 05:41:52.570396: step 14909, loss = 0.40276 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:41:53.859811 ops/training.py:65 2019-01-17 05:41:53.859729: step 14910, loss = 0.46374 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:41:55.141726 ops/training.py:65 2019-01-17 05:41:55.141654: step 14911, loss = 0.51110 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:41:56.429701 ops/training.py:65 2019-01-17 05:41:56.429640: step 14912, loss = 0.38463 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:41:57.719113 ops/training.py:65 2019-01-17 05:41:57.719032: step 14913, loss = 0.56783 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:41:59.004525 ops/training.py:65 2019-01-17 05:41:59.004446: step 14914, loss = 0.38606 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:42:00.289207 ops/training.py:65 2019-01-17 05:42:00.289096: step 14915, loss = 0.48170 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:42:01.582481 ops/training.py:65 2019-01-17 05:42:01.582384: step 14916, loss = 0.38827 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:42:02.869286 ops/training.py:65 2019-01-17 05:42:02.869214: step 14917, loss = 0.44468 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:42:04.154267 ops/training.py:65 2019-01-17 05:42:04.154186: step 14918, loss = 0.43634 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:42:05.436706 ops/training.py:65 2019-01-17 05:42:05.436601: step 14919, loss = 0.39019 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:42:06.718507 ops/training.py:65 2019-01-17 05:42:06.718396: step 14920, loss = 0.46593 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:42:08.010099 ops/training.py:65 2019-01-17 05:42:08.009988: step 14921, loss = 0.55096 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:42:09.301671 ops/training.py:65 2019-01-17 05:42:09.301578: step 14922, loss = 0.42920 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:42:10.591195 ops/training.py:65 2019-01-17 05:42:10.591121: step 14923, loss = 0.48343 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:42:11.875461 ops/training.py:65 2019-01-17 05:42:11.875390: step 14924, loss = 0.46351 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:42:13.159372 ops/training.py:65 2019-01-17 05:42:13.159287: step 14925, loss = 0.46088 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:42:14.446511 ops/training.py:65 2019-01-17 05:42:14.446360: step 14926, loss = 0.41849 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:42:15.734279 ops/training.py:65 2019-01-17 05:42:15.734123: step 14927, loss = 0.45765 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:42:17.024183 ops/training.py:65 2019-01-17 05:42:17.024075: step 14928, loss = 0.43706 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:42:18.306737 ops/training.py:65 2019-01-17 05:42:18.306627: step 14929, loss = 0.47565 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:42:19.594091 ops/training.py:65 2019-01-17 05:42:19.593985: step 14930, loss = 0.44569 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:42:20.882537 ops/training.py:65 2019-01-17 05:42:20.882377: step 14931, loss = 0.50697 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:42:22.166403 ops/training.py:65 2019-01-17 05:42:22.166244: step 14932, loss = 0.46759 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:42:23.459087 ops/training.py:65 2019-01-17 05:42:23.458934: step 14933, loss = 0.58377 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:42:24.746673 ops/training.py:65 2019-01-17 05:42:24.746585: step 14934, loss = 0.38080 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:42:26.037837 ops/training.py:65 2019-01-17 05:42:26.037770: step 14935, loss = 0.48754 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:42:27.325534 ops/training.py:65 2019-01-17 05:42:27.325456: step 14936, loss = 0.43746 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:42:28.610525 ops/training.py:65 2019-01-17 05:42:28.610423: step 14937, loss = 0.42544 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:42:29.899037 ops/training.py:65 2019-01-17 05:42:29.898932: step 14938, loss = 0.35750 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:42:31.184147 ops/training.py:65 2019-01-17 05:42:31.184039: step 14939, loss = 0.43684 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:42:32.477291 ops/training.py:65 2019-01-17 05:42:32.477181: step 14940, loss = 0.38803 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:42:33.767944 ops/training.py:65 2019-01-17 05:42:33.767849: step 14941, loss = 0.44481 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:42:35.056778 ops/training.py:65 2019-01-17 05:42:35.056710: step 14942, loss = 0.43077 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:42:36.342994 ops/training.py:65 2019-01-17 05:42:36.342925: step 14943, loss = 0.40996 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:42:37.631214 ops/training.py:65 2019-01-17 05:42:37.631149: step 14944, loss = 0.41797 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:42:38.916482 ops/training.py:65 2019-01-17 05:42:38.916389: step 14945, loss = 0.35887 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:42:40.203995 ops/training.py:65 2019-01-17 05:42:40.203884: step 14946, loss = 0.44147 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:42:41.488328 ops/training.py:65 2019-01-17 05:42:41.488224: step 14947, loss = 0.41246 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:42:42.777327 ops/training.py:65 2019-01-17 05:42:42.777220: step 14948, loss = 0.65814 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:42:44.062126 ops/training.py:65 2019-01-17 05:42:44.062035: step 14949, loss = 0.44036 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:42:45.350062 ops/training.py:65 2019-01-17 05:42:45.349945: step 14950, loss = 0.50458 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:42:46.635946 ops/training.py:65 2019-01-17 05:42:46.635839: step 14951, loss = 0.48947 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:42:47.928667 ops/training.py:65 2019-01-17 05:42:47.928562: step 14952, loss = 0.52607 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:42:49.214505 ops/training.py:65 2019-01-17 05:42:49.214438: step 14953, loss = 0.48693 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:42:50.496217 ops/training.py:65 2019-01-17 05:42:50.496061: step 14954, loss = 0.52358 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:42:51.787823 ops/training.py:65 2019-01-17 05:42:51.787677: step 14955, loss = 0.59703 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:42:53.074340 ops/training.py:65 2019-01-17 05:42:53.074259: step 14956, loss = 0.54643 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:42:54.367569 ops/training.py:65 2019-01-17 05:42:54.367425: step 14957, loss = 0.36743 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:42:55.659427 ops/training.py:65 2019-01-17 05:42:55.659356: step 14958, loss = 0.40966 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:42:56.945620 ops/training.py:65 2019-01-17 05:42:56.945547: step 14959, loss = 0.48575 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:42:58.236553 ops/training.py:65 2019-01-17 05:42:58.236456: step 14960, loss = 0.45285 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:42:59.523348 ops/training.py:65 2019-01-17 05:42:59.523283: step 14961, loss = 0.48791 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:43:00.809787 ops/training.py:65 2019-01-17 05:43:00.809686: step 14962, loss = 0.46470 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:43:02.101867 ops/training.py:65 2019-01-17 05:43:02.101759: step 14963, loss = 0.44415 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:43:03.390819 ops/training.py:65 2019-01-17 05:43:03.390740: step 14964, loss = 0.43381 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:43:04.675112 ops/training.py:65 2019-01-17 05:43:04.675037: step 14965, loss = 0.57342 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:43:05.968875 ops/training.py:65 2019-01-17 05:43:05.968767: step 14966, loss = 0.62480 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:43:07.256325 ops/training.py:65 2019-01-17 05:43:07.256259: step 14967, loss = 0.48932 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:43:08.546649 ops/training.py:65 2019-01-17 05:43:08.546583: step 14968, loss = 0.48312 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:43:09.834970 ops/training.py:65 2019-01-17 05:43:09.834903: step 14969, loss = 0.60454 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:43:11.125179 ops/training.py:65 2019-01-17 05:43:11.125111: step 14970, loss = 0.43996 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:43:12.409071 ops/training.py:65 2019-01-17 05:43:12.408994: step 14971, loss = 0.44020 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:43:13.698255 ops/training.py:65 2019-01-17 05:43:13.698146: step 14972, loss = 0.43855 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:43:14.987999 ops/training.py:65 2019-01-17 05:43:14.987894: step 14973, loss = 0.54606 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:43:16.278965 ops/training.py:65 2019-01-17 05:43:16.278876: step 14974, loss = 0.52736 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:43:17.566024 ops/training.py:65 2019-01-17 05:43:17.565955: step 14975, loss = 0.35995 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:43:18.856500 ops/training.py:65 2019-01-17 05:43:18.856398: step 14976, loss = 0.48964 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:43:20.148880 ops/training.py:65 2019-01-17 05:43:20.148813: step 14977, loss = 0.32782 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:43:21.437333 ops/training.py:65 2019-01-17 05:43:21.437264: step 14978, loss = 0.41312 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:43:22.725080 ops/training.py:65 2019-01-17 05:43:22.724993: step 14979, loss = 0.40792 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:43:24.013868 ops/training.py:65 2019-01-17 05:43:24.013801: step 14980, loss = 0.44848 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:43:25.299479 ops/training.py:65 2019-01-17 05:43:25.299403: step 14981, loss = 0.61267 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:43:26.589845 ops/training.py:65 2019-01-17 05:43:26.589738: step 14982, loss = 0.42597 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:43:27.878919 ops/training.py:65 2019-01-17 05:43:27.878850: step 14983, loss = 0.57150 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:43:29.168249 ops/training.py:65 2019-01-17 05:43:29.168180: step 14984, loss = 0.47522 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:43:30.454404 ops/training.py:65 2019-01-17 05:43:30.454294: step 14985, loss = 0.44782 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:43:31.747055 ops/training.py:65 2019-01-17 05:43:31.746960: step 14986, loss = 0.52983 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:43:33.037191 ops/training.py:65 2019-01-17 05:43:33.037123: step 14987, loss = 0.43452 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:43:34.326705 ops/training.py:65 2019-01-17 05:43:34.326630: step 14988, loss = 0.49538 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:43:35.611849 ops/training.py:65 2019-01-17 05:43:35.611789: step 14989, loss = 0.35952 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:43:36.897880 ops/training.py:65 2019-01-17 05:43:36.897776: step 14990, loss = 0.45482 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:43:38.191212 ops/training.py:65 2019-01-17 05:43:38.191107: step 14991, loss = 0.43431 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:43:39.481398 ops/training.py:65 2019-01-17 05:43:39.481335: step 14992, loss = 0.42289 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:43:40.767254 ops/training.py:65 2019-01-17 05:43:40.767184: step 14993, loss = 0.47766 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:43:42.053111 ops/training.py:65 2019-01-17 05:43:42.053004: step 14994, loss = 0.43379 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:43:43.341510 ops/training.py:65 2019-01-17 05:43:43.341407: step 14995, loss = 0.44666 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:43:44.630275 ops/training.py:65 2019-01-17 05:43:44.630167: step 14996, loss = 0.49731 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:43:45.918818 ops/training.py:65 2019-01-17 05:43:45.918707: step 14997, loss = 0.40361 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:43:47.206130 ops/training.py:65 2019-01-17 05:43:47.205973: step 14998, loss = 0.49613 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:43:48.492931 ops/training.py:65 2019-01-17 05:43:48.492824: step 14999, loss = 0.43432 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:43:49.786274 ops/training.py:65 2019-01-17 05:43:49.786161: step 15000, loss = 0.56666 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:43:51.073312 ops/training.py:65 2019-01-17 05:43:51.073247: step 15001, loss = 0.40816 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:43:52.363470 ops/training.py:65 2019-01-17 05:43:52.363362: step 15002, loss = 0.43778 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:43:53.649352 ops/training.py:65 2019-01-17 05:43:53.649281: step 15003, loss = 0.32189 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:43:54.938373 ops/training.py:65 2019-01-17 05:43:54.938313: step 15004, loss = 0.54756 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:43:56.224706 ops/training.py:65 2019-01-17 05:43:56.224627: step 15005, loss = 0.48707 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:43:57.516211 ops/training.py:65 2019-01-17 05:43:57.516054: step 15006, loss = 0.52253 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:43:58.803872 ops/training.py:65 2019-01-17 05:43:58.803783: step 15007, loss = 0.41885 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:44:00.094038 ops/training.py:65 2019-01-17 05:44:00.093926: step 15008, loss = 0.38950 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:44:01.379817 ops/training.py:65 2019-01-17 05:44:01.379755: step 15009, loss = 0.42263 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:44:02.667432 ops/training.py:65 2019-01-17 05:44:02.667366: step 15010, loss = 0.45714 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:44:03.956616 ops/training.py:65 2019-01-17 05:44:03.956542: step 15011, loss = 0.35942 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:44:05.246082 ops/training.py:65 2019-01-17 05:44:05.245999: step 15012, loss = 0.46516 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:44:06.532180 ops/training.py:65 2019-01-17 05:44:06.532095: step 15013, loss = 0.49217 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:44:07.819849 ops/training.py:65 2019-01-17 05:44:07.819745: step 15014, loss = 0.38303 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:44:09.112060 ops/training.py:65 2019-01-17 05:44:09.111960: step 15015, loss = 0.38339 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:44:10.397931 ops/training.py:65 2019-01-17 05:44:10.397871: step 15016, loss = 0.39240 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:44:11.682506 ops/training.py:65 2019-01-17 05:44:11.682372: step 15017, loss = 0.54662 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:44:12.974836 ops/training.py:65 2019-01-17 05:44:12.974728: step 15018, loss = 0.41403 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:44:14.266872 ops/training.py:65 2019-01-17 05:44:14.266803: step 15019, loss = 0.38994 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:44:15.555524 ops/training.py:65 2019-01-17 05:44:15.555454: step 15020, loss = 0.40023 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:44:16.842097 ops/training.py:65 2019-01-17 05:44:16.842006: step 15021, loss = 0.53520 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:44:18.127324 ops/training.py:65 2019-01-17 05:44:18.127219: step 15022, loss = 0.38327 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:44:19.407720 ops/training.py:65 2019-01-17 05:44:19.407571: step 15023, loss = 0.46118 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:44:20.698964 ops/training.py:65 2019-01-17 05:44:20.698853: step 15024, loss = 0.43957 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:44:21.990348 ops/training.py:65 2019-01-17 05:44:21.990281: step 15025, loss = 0.54437 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:44:23.274083 ops/training.py:65 2019-01-17 05:44:23.274007: step 15026, loss = 0.39296 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:44:24.559716 ops/training.py:65 2019-01-17 05:44:24.559606: step 15027, loss = 0.43413 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:44:25.844148 ops/training.py:65 2019-01-17 05:44:25.844042: step 15028, loss = 0.43109 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:44:27.133015 ops/training.py:65 2019-01-17 05:44:27.132907: step 15029, loss = 0.42751 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:44:28.419273 ops/training.py:65 2019-01-17 05:44:28.419173: step 15030, loss = 0.47335 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:44:29.706430 ops/training.py:65 2019-01-17 05:44:29.706315: step 15031, loss = 0.44224 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:44:30.996171 ops/training.py:65 2019-01-17 05:44:30.996014: step 15032, loss = 0.32416 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:44:32.281171 ops/training.py:65 2019-01-17 05:44:32.281060: step 15033, loss = 0.49457 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:44:33.573176 ops/training.py:65 2019-01-17 05:44:33.573065: step 15034, loss = 0.42485 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:44:34.858304 ops/training.py:65 2019-01-17 05:44:34.858240: step 15035, loss = 0.43824 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:44:36.148714 ops/training.py:65 2019-01-17 05:44:36.148606: step 15036, loss = 0.42115 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:44:37.434907 ops/training.py:65 2019-01-17 05:44:37.434802: step 15037, loss = 0.39553 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:44:38.721052 ops/training.py:65 2019-01-17 05:44:38.720936: step 15038, loss = 0.48041 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:44:40.009117 ops/training.py:65 2019-01-17 05:44:40.009008: step 15039, loss = 0.46140 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:44:41.299797 ops/training.py:65 2019-01-17 05:44:41.299685: step 15040, loss = 0.41408 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:44:42.586351 ops/training.py:65 2019-01-17 05:44:42.586276: step 15041, loss = 0.47798 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:44:43.871077 ops/training.py:65 2019-01-17 05:44:43.870981: step 15042, loss = 0.48799 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:44:45.157444 ops/training.py:65 2019-01-17 05:44:45.157294: step 15043, loss = 0.51737 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:44:46.449269 ops/training.py:65 2019-01-17 05:44:46.449167: step 15044, loss = 0.36106 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:44:47.738245 ops/training.py:65 2019-01-17 05:44:47.738173: step 15045, loss = 0.45933 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:44:49.028289 ops/training.py:65 2019-01-17 05:44:49.028217: step 15046, loss = 0.65667 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:44:50.317111 ops/training.py:65 2019-01-17 05:44:50.316974: step 15047, loss = 0.37810 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:44:51.607180 ops/training.py:65 2019-01-17 05:44:51.607074: step 15048, loss = 0.52391 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:44:52.892170 ops/training.py:65 2019-01-17 05:44:52.892098: step 15049, loss = 0.43313 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:44:54.176835 ops/training.py:65 2019-01-17 05:44:54.176744: step 15050, loss = 0.39645 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:44:55.468687 ops/training.py:65 2019-01-17 05:44:55.468581: step 15051, loss = 0.42474 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:44:56.754010 ops/training.py:65 2019-01-17 05:44:56.753857: step 15052, loss = 0.51777 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:44:58.041544 ops/training.py:65 2019-01-17 05:44:58.041434: step 15053, loss = 0.44957 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:44:59.332864 ops/training.py:65 2019-01-17 05:44:59.332764: step 15054, loss = 0.40388 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:45:00.618744 ops/training.py:65 2019-01-17 05:45:00.618671: step 15055, loss = 0.51690 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:45:01.905044 ops/training.py:65 2019-01-17 05:45:01.904954: step 15056, loss = 0.41004 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:45:03.196523 ops/training.py:65 2019-01-17 05:45:03.196424: step 15057, loss = 0.51974 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:45:04.489048 ops/training.py:65 2019-01-17 05:45:04.488979: step 15058, loss = 0.45359 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:45:05.775887 ops/training.py:65 2019-01-17 05:45:05.775787: step 15059, loss = 0.43786 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:45:07.063482 ops/training.py:65 2019-01-17 05:45:07.063376: step 15060, loss = 0.39427 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:45:08.347310 ops/training.py:65 2019-01-17 05:45:08.347203: step 15061, loss = 0.40119 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:45:09.634038 ops/training.py:65 2019-01-17 05:45:09.633932: step 15062, loss = 0.38911 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:45:10.920120 ops/training.py:65 2019-01-17 05:45:10.920012: step 15063, loss = 0.44900 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:45:12.204961 ops/training.py:65 2019-01-17 05:45:12.204847: step 15064, loss = 0.36943 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:45:13.492688 ops/training.py:65 2019-01-17 05:45:13.492593: step 15065, loss = 0.48252 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:45:14.777450 ops/training.py:65 2019-01-17 05:45:14.777345: step 15066, loss = 0.51242 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:45:16.066414 ops/training.py:65 2019-01-17 05:45:16.066309: step 15067, loss = 0.40834 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:45:17.352665 ops/training.py:65 2019-01-17 05:45:17.352592: step 15068, loss = 0.40936 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:45:18.643744 ops/training.py:65 2019-01-17 05:45:18.643640: step 15069, loss = 0.37251 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:45:19.930132 ops/training.py:65 2019-01-17 05:45:19.930044: step 15070, loss = 0.52185 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:45:21.214238 ops/training.py:65 2019-01-17 05:45:21.214134: step 15071, loss = 0.49716 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:45:22.498133 ops/training.py:65 2019-01-17 05:45:22.498024: step 15072, loss = 0.44225 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:45:23.790165 ops/training.py:65 2019-01-17 05:45:23.790066: step 15073, loss = 0.46315 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:45:25.075899 ops/training.py:65 2019-01-17 05:45:25.075805: step 15074, loss = 0.35812 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:45:26.359541 ops/training.py:65 2019-01-17 05:45:26.359432: step 15075, loss = 0.47230 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:45:27.651278 ops/training.py:65 2019-01-17 05:45:27.651180: step 15076, loss = 0.37516 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:45:28.941173 ops/training.py:65 2019-01-17 05:45:28.941106: step 15077, loss = 0.51122 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:45:30.228609 ops/training.py:65 2019-01-17 05:45:30.228540: step 15078, loss = 0.50077 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:45:31.512325 ops/training.py:65 2019-01-17 05:45:31.512264: step 15079, loss = 0.39885 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:45:32.797124 ops/training.py:65 2019-01-17 05:45:32.797027: step 15080, loss = 0.43111 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:45:34.084108 ops/training.py:65 2019-01-17 05:45:34.084012: step 15081, loss = 0.38061 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:45:35.376833 ops/training.py:65 2019-01-17 05:45:35.376726: step 15082, loss = 0.37700 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:45:36.657381 ops/training.py:65 2019-01-17 05:45:36.657270: step 15083, loss = 0.46662 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:45:37.943804 ops/training.py:65 2019-01-17 05:45:37.943694: step 15084, loss = 0.47976 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:45:39.235030 ops/training.py:65 2019-01-17 05:45:39.234926: step 15085, loss = 0.41935 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:45:40.524962 ops/training.py:65 2019-01-17 05:45:40.524872: step 15086, loss = 0.43673 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:45:41.813164 ops/training.py:65 2019-01-17 05:45:41.813096: step 15087, loss = 0.36063 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:45:43.099282 ops/training.py:65 2019-01-17 05:45:43.099216: step 15088, loss = 0.43467 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:45:44.391568 ops/training.py:65 2019-01-17 05:45:44.391468: step 15089, loss = 0.44648 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:45:45.679196 ops/training.py:65 2019-01-17 05:45:45.679082: step 15090, loss = 0.46569 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:45:46.965502 ops/training.py:65 2019-01-17 05:45:46.965396: step 15091, loss = 0.52076 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:45:48.258741 ops/training.py:65 2019-01-17 05:45:48.258633: step 15092, loss = 0.49801 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:45:49.550514 ops/training.py:65 2019-01-17 05:45:49.550425: step 15093, loss = 0.40686 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:45:50.834951 ops/training.py:65 2019-01-17 05:45:50.834886: step 15094, loss = 0.40756 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:45:52.120049 ops/training.py:65 2019-01-17 05:45:52.119884: step 15095, loss = 0.43706 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:45:53.412734 ops/training.py:65 2019-01-17 05:45:53.412630: step 15096, loss = 0.36487 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:45:54.703754 ops/training.py:65 2019-01-17 05:45:54.703682: step 15097, loss = 0.48986 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:45:55.990022 ops/training.py:65 2019-01-17 05:45:55.989948: step 15098, loss = 0.52513 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:45:57.275162 ops/training.py:65 2019-01-17 05:45:57.275054: step 15099, loss = 0.45800 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:45:58.561841 ops/training.py:65 2019-01-17 05:45:58.561737: step 15100, loss = 0.40918 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:45:59.854452 ops/training.py:65 2019-01-17 05:45:59.854345: step 15101, loss = 0.51329 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:46:01.140242 ops/training.py:65 2019-01-17 05:46:01.140170: step 15102, loss = 0.44695 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:46:02.424843 ops/training.py:65 2019-01-17 05:46:02.424734: step 15103, loss = 0.52365 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:46:03.711252 ops/training.py:65 2019-01-17 05:46:03.711142: step 15104, loss = 0.40800 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:46:04.997012 ops/training.py:65 2019-01-17 05:46:04.996856: step 15105, loss = 0.43763 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:46:06.290504 ops/training.py:65 2019-01-17 05:46:06.290401: step 15106, loss = 0.46726 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:46:07.582859 ops/training.py:65 2019-01-17 05:46:07.582792: step 15107, loss = 0.43812 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:46:08.871672 ops/training.py:65 2019-01-17 05:46:08.871607: step 15108, loss = 0.44947 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:46:10.160741 ops/training.py:65 2019-01-17 05:46:10.160676: step 15109, loss = 0.39859 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:46:11.443053 ops/training.py:65 2019-01-17 05:46:11.442969: step 15110, loss = 0.50654 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:46:12.730859 ops/training.py:65 2019-01-17 05:46:12.730745: step 15111, loss = 0.38682 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:46:14.015616 ops/training.py:65 2019-01-17 05:46:14.015521: step 15112, loss = 0.41982 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:46:15.303061 ops/training.py:65 2019-01-17 05:46:15.302952: step 15113, loss = 0.47639 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:46:16.589186 ops/training.py:65 2019-01-17 05:46:16.589079: step 15114, loss = 0.46417 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:46:17.882748 ops/training.py:65 2019-01-17 05:46:17.882638: step 15115, loss = 0.44582 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:46:19.174244 ops/training.py:65 2019-01-17 05:46:19.174176: step 15116, loss = 0.41626 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:46:20.464420 ops/training.py:65 2019-01-17 05:46:20.464344: step 15117, loss = 0.44445 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:46:21.748533 ops/training.py:65 2019-01-17 05:46:21.748451: step 15118, loss = 0.35985 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:46:23.033761 ops/training.py:65 2019-01-17 05:46:23.033618: step 15119, loss = 0.41183 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:46:24.326192 ops/training.py:65 2019-01-17 05:46:24.326079: step 15120, loss = 0.52854 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:46:25.610353 ops/training.py:65 2019-01-17 05:46:25.610290: step 15121, loss = 0.43803 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:46:26.893525 ops/training.py:65 2019-01-17 05:46:26.893428: step 15122, loss = 0.40134 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:46:28.187145 ops/training.py:65 2019-01-17 05:46:28.186984: step 15123, loss = 0.41296 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:46:29.470753 ops/training.py:65 2019-01-17 05:46:29.470671: step 15124, loss = 0.51285 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:46:30.756227 ops/training.py:65 2019-01-17 05:46:30.756126: step 15125, loss = 0.58821 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:46:32.042007 ops/training.py:65 2019-01-17 05:46:32.041903: step 15126, loss = 0.40405 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:46:33.326145 ops/training.py:65 2019-01-17 05:46:33.326037: step 15127, loss = 0.66233 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.59375
I4672 2019-01-17 05:46:34.608612 ops/training.py:65 2019-01-17 05:46:34.608507: step 15128, loss = 0.42279 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:46:35.894516 ops/training.py:65 2019-01-17 05:46:35.894416: step 15129, loss = 0.49247 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:46:37.185216 ops/training.py:65 2019-01-17 05:46:37.185110: step 15130, loss = 0.50559 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:46:38.470671 ops/training.py:65 2019-01-17 05:46:38.470564: step 15131, loss = 0.42530 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:46:39.750765 ops/training.py:65 2019-01-17 05:46:39.750659: step 15132, loss = 0.47199 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:46:41.036689 ops/training.py:65 2019-01-17 05:46:41.036587: step 15133, loss = 0.49724 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:46:42.318488 ops/training.py:65 2019-01-17 05:46:42.318391: step 15134, loss = 0.47798 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:46:43.604065 ops/training.py:65 2019-01-17 05:46:43.603972: step 15135, loss = 0.40907 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:46:44.891877 ops/training.py:65 2019-01-17 05:46:44.891773: step 15136, loss = 0.39514 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:46:46.177937 ops/training.py:65 2019-01-17 05:46:46.177837: step 15137, loss = 0.44114 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:46:47.464189 ops/training.py:65 2019-01-17 05:46:47.464083: step 15138, loss = 0.41680 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:46:48.751970 ops/training.py:65 2019-01-17 05:46:48.751866: step 15139, loss = 0.46858 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:46:50.034184 ops/training.py:65 2019-01-17 05:46:50.034097: step 15140, loss = 0.49430 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:46:51.320671 ops/training.py:65 2019-01-17 05:46:51.320569: step 15141, loss = 0.48006 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:46:52.611365 ops/training.py:65 2019-01-17 05:46:52.611272: step 15142, loss = 0.52551 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:46:53.902647 ops/training.py:65 2019-01-17 05:46:53.902555: step 15143, loss = 0.48133 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:46:55.187028 ops/training.py:65 2019-01-17 05:46:55.186914: step 15144, loss = 0.42333 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:46:56.473131 ops/training.py:65 2019-01-17 05:46:56.473058: step 15145, loss = 0.49491 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:46:57.754235 ops/training.py:65 2019-01-17 05:46:57.754133: step 15146, loss = 0.54133 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:46:59.035078 ops/training.py:65 2019-01-17 05:46:59.034979: step 15147, loss = 0.48566 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:47:00.323190 ops/training.py:65 2019-01-17 05:47:00.323089: step 15148, loss = 0.32481 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:47:01.615331 ops/training.py:65 2019-01-17 05:47:01.615226: step 15149, loss = 0.57807 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:47:02.901361 ops/training.py:65 2019-01-17 05:47:02.901254: step 15150, loss = 0.44683 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:47:04.181943 ops/training.py:65 2019-01-17 05:47:04.181841: step 15151, loss = 0.49509 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:47:05.469433 ops/training.py:65 2019-01-17 05:47:05.469334: step 15152, loss = 0.41846 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:47:06.754109 ops/training.py:65 2019-01-17 05:47:06.754009: step 15153, loss = 0.54028 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:47:08.044888 ops/training.py:65 2019-01-17 05:47:08.044784: step 15154, loss = 0.54660 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:47:09.332229 ops/training.py:65 2019-01-17 05:47:09.332148: step 15155, loss = 0.49717 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:47:10.620468 ops/training.py:65 2019-01-17 05:47:10.620387: step 15156, loss = 0.51329 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:47:11.909843 ops/training.py:65 2019-01-17 05:47:11.909746: step 15157, loss = 0.40791 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:47:13.195495 ops/training.py:65 2019-01-17 05:47:13.195428: step 15158, loss = 0.37456 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:47:14.479884 ops/training.py:65 2019-01-17 05:47:14.479792: step 15159, loss = 0.47917 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:47:15.767097 ops/training.py:65 2019-01-17 05:47:15.766988: step 15160, loss = 0.33344 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:47:17.050791 ops/training.py:65 2019-01-17 05:47:17.050644: step 15161, loss = 0.46555 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:47:18.335160 ops/training.py:65 2019-01-17 05:47:18.335010: step 15162, loss = 0.50248 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:47:19.616625 ops/training.py:65 2019-01-17 05:47:19.616521: step 15163, loss = 0.55086 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:47:20.898670 ops/training.py:65 2019-01-17 05:47:20.898560: step 15164, loss = 0.41971 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:47:22.190009 ops/training.py:65 2019-01-17 05:47:22.189897: step 15165, loss = 0.39121 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:47:23.474815 ops/training.py:65 2019-01-17 05:47:23.474734: step 15166, loss = 0.48547 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:47:24.762046 ops/training.py:65 2019-01-17 05:47:24.761952: step 15167, loss = 0.36567 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:47:26.050947 ops/training.py:65 2019-01-17 05:47:26.050877: step 15168, loss = 0.36154 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:47:27.338442 ops/training.py:65 2019-01-17 05:47:27.338377: step 15169, loss = 0.35088 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:47:28.626846 ops/training.py:65 2019-01-17 05:47:28.626768: step 15170, loss = 0.51089 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:47:29.915637 ops/training.py:65 2019-01-17 05:47:29.915559: step 15171, loss = 0.48202 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:47:31.204698 ops/training.py:65 2019-01-17 05:47:31.204611: step 15172, loss = 0.38260 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:47:32.494491 ops/training.py:65 2019-01-17 05:47:32.494418: step 15173, loss = 0.39290 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:47:33.783092 ops/training.py:65 2019-01-17 05:47:33.783016: step 15174, loss = 0.62029 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:47:35.072732 ops/training.py:65 2019-01-17 05:47:35.072599: step 15175, loss = 0.48151 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:47:36.357379 ops/training.py:65 2019-01-17 05:47:36.357259: step 15176, loss = 0.47038 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:47:37.648937 ops/training.py:65 2019-01-17 05:47:37.648784: step 15177, loss = 0.38130 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:47:38.938744 ops/training.py:65 2019-01-17 05:47:38.938663: step 15178, loss = 0.61002 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:47:40.227542 ops/training.py:65 2019-01-17 05:47:40.227473: step 15179, loss = 0.55542 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:47:41.515844 ops/training.py:65 2019-01-17 05:47:41.515772: step 15180, loss = 0.46800 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:47:42.805703 ops/training.py:65 2019-01-17 05:47:42.805624: step 15181, loss = 0.47458 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:47:44.094224 ops/training.py:65 2019-01-17 05:47:44.094149: step 15182, loss = 0.44245 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:47:45.379701 ops/training.py:65 2019-01-17 05:47:45.379630: step 15183, loss = 0.34743 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:47:46.666456 ops/training.py:65 2019-01-17 05:47:46.666358: step 15184, loss = 0.41280 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:47:47.955894 ops/training.py:65 2019-01-17 05:47:47.955820: step 15185, loss = 0.41594 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:47:49.243249 ops/training.py:65 2019-01-17 05:47:49.243175: step 15186, loss = 0.52975 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:47:50.531992 ops/training.py:65 2019-01-17 05:47:50.531924: step 15187, loss = 0.46957 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:47:51.819823 ops/training.py:65 2019-01-17 05:47:51.819730: step 15188, loss = 0.43019 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:47:53.109275 ops/training.py:65 2019-01-17 05:47:53.109204: step 15189, loss = 0.44476 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:47:54.397607 ops/training.py:65 2019-01-17 05:47:54.397537: step 15190, loss = 0.48486 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:47:55.682232 ops/training.py:65 2019-01-17 05:47:55.682165: step 15191, loss = 0.52452 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:47:56.971951 ops/training.py:65 2019-01-17 05:47:56.971808: step 15192, loss = 0.33552 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:47:58.261398 ops/training.py:65 2019-01-17 05:47:58.261289: step 15193, loss = 0.40957 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:47:59.552639 ops/training.py:65 2019-01-17 05:47:59.552561: step 15194, loss = 0.48579 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:48:00.841282 ops/training.py:65 2019-01-17 05:48:00.841207: step 15195, loss = 0.38972 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:48:02.130288 ops/training.py:65 2019-01-17 05:48:02.130208: step 15196, loss = 0.40424 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:48:03.419216 ops/training.py:65 2019-01-17 05:48:03.419138: step 15197, loss = 0.52263 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:48:04.708355 ops/training.py:65 2019-01-17 05:48:04.708260: step 15198, loss = 0.34209 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:48:06.001057 ops/training.py:65 2019-01-17 05:48:06.000992: step 15199, loss = 0.50008 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:48:07.286472 ops/training.py:65 2019-01-17 05:48:07.286383: step 15200, loss = 0.43759 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:48:08.578791 ops/training.py:65 2019-01-17 05:48:08.578632: step 15201, loss = 0.44046 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:48:09.865637 ops/training.py:65 2019-01-17 05:48:09.865574: step 15202, loss = 0.41888 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:48:11.161143 ops/training.py:65 2019-01-17 05:48:11.161042: step 15203, loss = 0.36954 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:48:12.445902 ops/training.py:65 2019-01-17 05:48:12.445820: step 15204, loss = 0.42228 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:48:13.735154 ops/training.py:65 2019-01-17 05:48:13.735023: step 15205, loss = 0.43516 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:48:15.024764 ops/training.py:65 2019-01-17 05:48:15.024656: step 15206, loss = 0.47498 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:48:16.315561 ops/training.py:65 2019-01-17 05:48:16.315497: step 15207, loss = 0.37114 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:48:17.602879 ops/training.py:65 2019-01-17 05:48:17.602771: step 15208, loss = 0.36415 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:48:18.891429 ops/training.py:65 2019-01-17 05:48:18.891352: step 15209, loss = 0.43131 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:48:20.180387 ops/training.py:65 2019-01-17 05:48:20.180290: step 15210, loss = 0.49822 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:48:21.468885 ops/training.py:65 2019-01-17 05:48:21.468822: step 15211, loss = 0.43922 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:48:22.757132 ops/training.py:65 2019-01-17 05:48:22.757060: step 15212, loss = 0.39284 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:48:24.044334 ops/training.py:65 2019-01-17 05:48:24.044266: step 15213, loss = 0.47279 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:48:25.327998 ops/training.py:65 2019-01-17 05:48:25.327937: step 15214, loss = 0.38369 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:48:26.612753 ops/training.py:65 2019-01-17 05:48:26.612653: step 15215, loss = 0.36103 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:48:27.899952 ops/training.py:65 2019-01-17 05:48:27.899845: step 15216, loss = 0.43064 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:48:29.185804 ops/training.py:65 2019-01-17 05:48:29.185705: step 15217, loss = 0.36099 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:48:30.477586 ops/training.py:65 2019-01-17 05:48:30.477427: step 15218, loss = 0.42769 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:48:31.770602 ops/training.py:65 2019-01-17 05:48:31.770499: step 15219, loss = 0.41696 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:48:33.056537 ops/training.py:65 2019-01-17 05:48:33.056472: step 15220, loss = 0.50244 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:48:34.337929 ops/training.py:65 2019-01-17 05:48:34.337817: step 15221, loss = 0.43246 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:48:35.628260 ops/training.py:65 2019-01-17 05:48:35.628156: step 15222, loss = 0.42686 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:48:36.916774 ops/training.py:65 2019-01-17 05:48:36.916671: step 15223, loss = 0.54758 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:48:38.206485 ops/training.py:65 2019-01-17 05:48:38.206415: step 15224, loss = 0.42936 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:48:39.490927 ops/training.py:65 2019-01-17 05:48:39.490862: step 15225, loss = 0.41096 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:48:40.776662 ops/training.py:65 2019-01-17 05:48:40.776559: step 15226, loss = 0.33387 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:48:42.068894 ops/training.py:65 2019-01-17 05:48:42.068789: step 15227, loss = 0.42860 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:48:43.359595 ops/training.py:65 2019-01-17 05:48:43.359528: step 15228, loss = 0.37827 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:48:44.643398 ops/training.py:65 2019-01-17 05:48:44.643327: step 15229, loss = 0.50821 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:48:45.927861 ops/training.py:65 2019-01-17 05:48:45.927753: step 15230, loss = 0.59271 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:48:47.220910 ops/training.py:65 2019-01-17 05:48:47.220809: step 15231, loss = 0.43676 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:48:48.510838 ops/training.py:65 2019-01-17 05:48:48.510772: step 15232, loss = 0.46775 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:48:49.799762 ops/training.py:65 2019-01-17 05:48:49.799697: step 15233, loss = 0.50900 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:48:51.080451 ops/training.py:65 2019-01-17 05:48:51.080390: step 15234, loss = 0.45192 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:48:52.363812 ops/training.py:65 2019-01-17 05:48:52.363751: step 15235, loss = 0.39721 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:48:53.647278 ops/training.py:65 2019-01-17 05:48:53.647216: step 15236, loss = 0.42355 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:48:54.931539 ops/training.py:65 2019-01-17 05:48:54.931430: step 15237, loss = 0.37141 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:48:56.222995 ops/training.py:65 2019-01-17 05:48:56.222886: step 15238, loss = 0.40684 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:48:57.508865 ops/training.py:65 2019-01-17 05:48:57.508801: step 15239, loss = 0.38527 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:48:58.794830 ops/training.py:65 2019-01-17 05:48:58.794708: step 15240, loss = 0.49778 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:49:00.081507 ops/training.py:65 2019-01-17 05:49:00.081399: step 15241, loss = 0.47674 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:49:01.365777 ops/training.py:65 2019-01-17 05:49:01.365672: step 15242, loss = 0.38896 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:49:02.653418 ops/training.py:65 2019-01-17 05:49:02.653310: step 15243, loss = 0.40507 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:49:03.938817 ops/training.py:65 2019-01-17 05:49:03.938713: step 15244, loss = 0.48395 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:49:05.226379 ops/training.py:65 2019-01-17 05:49:05.226264: step 15245, loss = 0.50871 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:49:06.516611 ops/training.py:65 2019-01-17 05:49:06.516500: step 15246, loss = 0.41074 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:49:07.812995 ops/training.py:65 2019-01-17 05:49:07.812920: step 15247, loss = 0.44607 (24.7 examples/sec; 1.295 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:49:09.102251 ops/training.py:65 2019-01-17 05:49:09.102119: step 15248, loss = 0.33672 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:49:10.391622 ops/training.py:65 2019-01-17 05:49:10.391534: step 15249, loss = 0.64791 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:49:11.677125 ops/training.py:65 2019-01-17 05:49:11.677059: step 15250, loss = 0.46628 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:49:12.967536 ops/training.py:65 2019-01-17 05:49:12.967429: step 15251, loss = 0.49319 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:49:14.255890 ops/training.py:65 2019-01-17 05:49:14.255815: step 15252, loss = 0.40298 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:49:15.536225 ops/training.py:65 2019-01-17 05:49:15.536155: step 15253, loss = 0.49035 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:49:16.820021 ops/training.py:65 2019-01-17 05:49:16.819942: step 15254, loss = 0.46485 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:49:18.111049 ops/training.py:65 2019-01-17 05:49:18.110950: step 15255, loss = 0.43129 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:49:19.396217 ops/training.py:65 2019-01-17 05:49:19.396151: step 15256, loss = 0.42478 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:49:20.684347 ops/training.py:65 2019-01-17 05:49:20.684283: step 15257, loss = 0.44885 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:49:21.973736 ops/training.py:65 2019-01-17 05:49:21.973641: step 15258, loss = 0.37678 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 05:49:23.258377 ops/training.py:65 2019-01-17 05:49:23.258308: step 15259, loss = 0.44118 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:49:24.543633 ops/training.py:65 2019-01-17 05:49:24.543475: step 15260, loss = 0.43137 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:49:25.835263 ops/training.py:65 2019-01-17 05:49:25.835154: step 15261, loss = 0.35915 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:49:27.126272 ops/training.py:65 2019-01-17 05:49:27.126187: step 15262, loss = 0.36535 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:49:28.411526 ops/training.py:65 2019-01-17 05:49:28.411461: step 15263, loss = 0.50511 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:49:29.697911 ops/training.py:65 2019-01-17 05:49:29.697819: step 15264, loss = 0.43167 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:49:30.985472 ops/training.py:65 2019-01-17 05:49:30.985362: step 15265, loss = 0.37441 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:49:32.271129 ops/training.py:65 2019-01-17 05:49:32.271019: step 15266, loss = 0.43858 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:49:33.556287 ops/training.py:65 2019-01-17 05:49:33.556185: step 15267, loss = 0.37248 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:49:34.846983 ops/training.py:65 2019-01-17 05:49:34.846876: step 15268, loss = 0.42176 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:49:36.133147 ops/training.py:65 2019-01-17 05:49:36.133058: step 15269, loss = 0.40407 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:49:37.418108 ops/training.py:65 2019-01-17 05:49:37.418045: step 15270, loss = 0.50009 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:49:38.702548 ops/training.py:65 2019-01-17 05:49:38.702445: step 15271, loss = 0.44050 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:49:39.994008 ops/training.py:65 2019-01-17 05:49:39.993897: step 15272, loss = 0.36204 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:49:41.284845 ops/training.py:65 2019-01-17 05:49:41.284759: step 15273, loss = 0.38818 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:49:42.573569 ops/training.py:65 2019-01-17 05:49:42.573502: step 15274, loss = 0.45400 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:49:43.862540 ops/training.py:65 2019-01-17 05:49:43.862466: step 15275, loss = 0.47819 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:49:45.146739 ops/training.py:65 2019-01-17 05:49:45.146674: step 15276, loss = 0.52931 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:49:46.435641 ops/training.py:65 2019-01-17 05:49:46.435535: step 15277, loss = 0.47852 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:49:47.720491 ops/training.py:65 2019-01-17 05:49:47.720420: step 15278, loss = 0.40504 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:49:49.005029 ops/training.py:65 2019-01-17 05:49:49.004924: step 15279, loss = 0.48383 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:49:50.288161 ops/training.py:65 2019-01-17 05:49:50.288062: step 15280, loss = 0.42790 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:49:51.574853 ops/training.py:65 2019-01-17 05:49:51.574743: step 15281, loss = 0.44946 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:49:52.864836 ops/training.py:65 2019-01-17 05:49:52.864684: step 15282, loss = 0.52465 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:49:54.154512 ops/training.py:65 2019-01-17 05:49:54.154368: step 15283, loss = 0.44960 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:49:55.441050 ops/training.py:65 2019-01-17 05:49:55.440979: step 15284, loss = 0.44369 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:49:56.723554 ops/training.py:65 2019-01-17 05:49:56.723445: step 15285, loss = 0.43627 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:49:58.010832 ops/training.py:65 2019-01-17 05:49:58.010719: step 15286, loss = 0.50039 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:49:59.296845 ops/training.py:65 2019-01-17 05:49:59.296754: step 15287, loss = 0.43646 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:50:00.581769 ops/training.py:65 2019-01-17 05:50:00.581661: step 15288, loss = 0.43073 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:50:01.865714 ops/training.py:65 2019-01-17 05:50:01.865635: step 15289, loss = 0.47679 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:50:03.152008 ops/training.py:65 2019-01-17 05:50:03.151919: step 15290, loss = 0.42348 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:50:04.438373 ops/training.py:65 2019-01-17 05:50:04.438276: step 15291, loss = 0.42250 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:50:05.721548 ops/training.py:65 2019-01-17 05:50:05.721452: step 15292, loss = 0.46760 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:50:07.003152 ops/training.py:65 2019-01-17 05:50:07.003041: step 15293, loss = 0.40124 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:50:08.288632 ops/training.py:65 2019-01-17 05:50:08.288532: step 15294, loss = 0.34870 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:50:09.570455 ops/training.py:65 2019-01-17 05:50:09.570359: step 15295, loss = 0.38461 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:50:10.857238 ops/training.py:65 2019-01-17 05:50:10.857128: step 15296, loss = 0.42136 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:50:12.134928 ops/training.py:65 2019-01-17 05:50:12.134821: step 15297, loss = 0.41378 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:50:13.421205 ops/training.py:65 2019-01-17 05:50:13.421052: step 15298, loss = 0.44066 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:50:14.715252 ops/training.py:65 2019-01-17 05:50:14.715113: step 15299, loss = 0.43120 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:50:16.004491 ops/training.py:65 2019-01-17 05:50:16.004342: step 15300, loss = 0.44232 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:50:17.289680 ops/training.py:65 2019-01-17 05:50:17.289541: step 15301, loss = 0.46715 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:50:18.574846 ops/training.py:65 2019-01-17 05:50:18.574734: step 15302, loss = 0.41941 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:50:19.860795 ops/training.py:65 2019-01-17 05:50:19.860686: step 15303, loss = 0.52501 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:50:21.152661 ops/training.py:65 2019-01-17 05:50:21.152557: step 15304, loss = 0.42644 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:50:22.439062 ops/training.py:65 2019-01-17 05:50:22.438953: step 15305, loss = 0.36300 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:50:23.725621 ops/training.py:65 2019-01-17 05:50:23.725523: step 15306, loss = 0.41569 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:50:25.011308 ops/training.py:65 2019-01-17 05:50:25.011214: step 15307, loss = 0.35029 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:50:26.308504 ops/training.py:65 2019-01-17 05:50:26.308399: step 15308, loss = 0.50291 (24.7 examples/sec; 1.296 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:50:27.592023 ops/training.py:65 2019-01-17 05:50:27.591938: step 15309, loss = 0.48582 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:50:28.882936 ops/training.py:65 2019-01-17 05:50:28.882847: step 15310, loss = 0.31339 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:50:30.169689 ops/training.py:65 2019-01-17 05:50:30.169584: step 15311, loss = 0.47825 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:50:31.456487 ops/training.py:65 2019-01-17 05:50:31.456382: step 15312, loss = 0.33592 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:50:32.736631 ops/training.py:65 2019-01-17 05:50:32.736533: step 15313, loss = 0.32730 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:50:34.027193 ops/training.py:65 2019-01-17 05:50:34.027087: step 15314, loss = 0.39970 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:50:35.317633 ops/training.py:65 2019-01-17 05:50:35.317529: step 15315, loss = 0.44944 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:50:36.602373 ops/training.py:65 2019-01-17 05:50:36.602309: step 15316, loss = 0.43649 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:50:37.891661 ops/training.py:65 2019-01-17 05:50:37.891554: step 15317, loss = 0.41678 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:50:39.180359 ops/training.py:65 2019-01-17 05:50:39.180282: step 15318, loss = 0.39650 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:50:40.465413 ops/training.py:65 2019-01-17 05:50:40.465349: step 15319, loss = 0.40555 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:50:41.749651 ops/training.py:65 2019-01-17 05:50:41.749560: step 15320, loss = 0.36732 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:50:43.034330 ops/training.py:65 2019-01-17 05:50:43.034221: step 15321, loss = 0.42081 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:50:44.318158 ops/training.py:65 2019-01-17 05:50:44.318083: step 15322, loss = 0.38178 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:50:45.606516 ops/training.py:65 2019-01-17 05:50:45.606411: step 15323, loss = 0.40845 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:50:46.896043 ops/training.py:65 2019-01-17 05:50:46.895950: step 15324, loss = 0.43044 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:50:48.181266 ops/training.py:65 2019-01-17 05:50:48.181202: step 15325, loss = 0.61504 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:50:49.468423 ops/training.py:65 2019-01-17 05:50:49.468269: step 15326, loss = 0.53731 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:50:50.756350 ops/training.py:65 2019-01-17 05:50:50.756242: step 15327, loss = 0.40589 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:50:52.044662 ops/training.py:65 2019-01-17 05:50:52.044518: step 15328, loss = 0.48920 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:50:53.331916 ops/training.py:65 2019-01-17 05:50:53.331815: step 15329, loss = 0.36683 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:50:54.614836 ops/training.py:65 2019-01-17 05:50:54.614740: step 15330, loss = 0.39321 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:50:55.908696 ops/training.py:65 2019-01-17 05:50:55.908589: step 15331, loss = 0.55020 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:50:57.193865 ops/training.py:65 2019-01-17 05:50:57.193787: step 15332, loss = 0.45011 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:50:58.482575 ops/training.py:65 2019-01-17 05:50:58.482465: step 15333, loss = 0.44476 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:50:59.767460 ops/training.py:65 2019-01-17 05:50:59.767365: step 15334, loss = 0.38852 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:51:01.057982 ops/training.py:65 2019-01-17 05:51:01.057828: step 15335, loss = 0.36694 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:51:02.344107 ops/training.py:65 2019-01-17 05:51:02.343957: step 15336, loss = 0.45192 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:51:03.631291 ops/training.py:65 2019-01-17 05:51:03.631191: step 15337, loss = 0.35380 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:51:04.912360 ops/training.py:65 2019-01-17 05:51:04.912251: step 15338, loss = 0.38537 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:51:06.198547 ops/training.py:65 2019-01-17 05:51:06.198397: step 15339, loss = 0.50113 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:51:07.478009 ops/training.py:65 2019-01-17 05:51:07.477914: step 15340, loss = 0.38072 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:51:08.763532 ops/training.py:65 2019-01-17 05:51:08.763419: step 15341, loss = 0.37498 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:51:10.054433 ops/training.py:65 2019-01-17 05:51:10.054314: step 15342, loss = 0.49224 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:51:11.338708 ops/training.py:65 2019-01-17 05:51:11.338644: step 15343, loss = 0.46006 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:51:12.622589 ops/training.py:65 2019-01-17 05:51:12.622522: step 15344, loss = 0.36757 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:51:13.906547 ops/training.py:65 2019-01-17 05:51:13.906455: step 15345, loss = 0.43125 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:51:15.197108 ops/training.py:65 2019-01-17 05:51:15.197001: step 15346, loss = 0.44583 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:51:16.487254 ops/training.py:65 2019-01-17 05:51:16.487163: step 15347, loss = 0.44856 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:51:17.771666 ops/training.py:65 2019-01-17 05:51:17.771590: step 15348, loss = 0.42234 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:51:19.054558 ops/training.py:65 2019-01-17 05:51:19.054448: step 15349, loss = 0.48760 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:51:20.337461 ops/training.py:65 2019-01-17 05:51:20.337384: step 15350, loss = 0.51923 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:51:21.620348 ops/training.py:65 2019-01-17 05:51:21.620252: step 15351, loss = 0.36102 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:51:22.905475 ops/training.py:65 2019-01-17 05:51:22.905399: step 15352, loss = 0.39959 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:51:24.195295 ops/training.py:65 2019-01-17 05:51:24.195193: step 15353, loss = 0.34553 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:51:25.483512 ops/training.py:65 2019-01-17 05:51:25.483443: step 15354, loss = 0.37857 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:51:26.772623 ops/training.py:65 2019-01-17 05:51:26.772528: step 15355, loss = 0.46976 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:51:28.057273 ops/training.py:65 2019-01-17 05:51:28.057187: step 15356, loss = 0.41940 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:51:29.341841 ops/training.py:65 2019-01-17 05:51:29.341743: step 15357, loss = 0.37770 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:51:30.621062 ops/training.py:65 2019-01-17 05:51:30.620978: step 15358, loss = 0.38493 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:51:31.903389 ops/training.py:65 2019-01-17 05:51:31.903240: step 15359, loss = 0.44178 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:51:33.189770 ops/training.py:65 2019-01-17 05:51:33.189665: step 15360, loss = 0.46277 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:51:34.473918 ops/training.py:65 2019-01-17 05:51:34.473805: step 15361, loss = 0.42905 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:51:35.766668 ops/training.py:65 2019-01-17 05:51:35.766563: step 15362, loss = 0.46466 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:51:37.057204 ops/training.py:65 2019-01-17 05:51:37.057094: step 15363, loss = 0.40099 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:51:38.337636 ops/training.py:65 2019-01-17 05:51:38.337531: step 15364, loss = 0.48966 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:51:39.629631 ops/training.py:65 2019-01-17 05:51:39.629524: step 15365, loss = 0.45236 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:51:40.919308 ops/training.py:65 2019-01-17 05:51:40.919211: step 15366, loss = 0.44198 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:51:42.202860 ops/training.py:65 2019-01-17 05:51:42.202791: step 15367, loss = 0.40777 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:51:43.486259 ops/training.py:65 2019-01-17 05:51:43.486161: step 15368, loss = 0.43440 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:51:44.777206 ops/training.py:65 2019-01-17 05:51:44.777067: step 15369, loss = 0.33794 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:51:46.068862 ops/training.py:65 2019-01-17 05:51:46.068778: step 15370, loss = 0.48757 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:51:47.357807 ops/training.py:65 2019-01-17 05:51:47.357741: step 15371, loss = 0.37393 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:51:48.643143 ops/training.py:65 2019-01-17 05:51:48.643070: step 15372, loss = 0.39547 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:51:49.927661 ops/training.py:65 2019-01-17 05:51:49.927554: step 15373, loss = 0.43261 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:51:51.217827 ops/training.py:65 2019-01-17 05:51:51.217727: step 15374, loss = 0.45358 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:51:52.507732 ops/training.py:65 2019-01-17 05:51:52.507626: step 15375, loss = 0.49407 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:51:53.791885 ops/training.py:65 2019-01-17 05:51:53.791807: step 15376, loss = 0.32172 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:51:55.080304 ops/training.py:65 2019-01-17 05:51:55.080200: step 15377, loss = 0.48191 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:51:56.368139 ops/training.py:65 2019-01-17 05:51:56.368052: step 15378, loss = 0.46463 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:51:57.657036 ops/training.py:65 2019-01-17 05:51:57.656944: step 15379, loss = 0.50464 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:51:58.946261 ops/training.py:65 2019-01-17 05:51:58.946181: step 15380, loss = 0.43726 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:52:00.230624 ops/training.py:65 2019-01-17 05:52:00.230553: step 15381, loss = 0.49162 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:52:01.510956 ops/training.py:65 2019-01-17 05:52:01.510881: step 15382, loss = 0.40760 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:52:02.794272 ops/training.py:65 2019-01-17 05:52:02.794170: step 15383, loss = 0.48447 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:52:04.080594 ops/training.py:65 2019-01-17 05:52:04.080494: step 15384, loss = 0.41025 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:52:05.366519 ops/training.py:65 2019-01-17 05:52:05.366414: step 15385, loss = 0.45677 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:52:06.648417 ops/training.py:65 2019-01-17 05:52:06.648329: step 15386, loss = 0.37655 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:52:07.930882 ops/training.py:65 2019-01-17 05:52:07.930778: step 15387, loss = 0.65168 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:52:09.221425 ops/training.py:65 2019-01-17 05:52:09.221286: step 15388, loss = 0.45451 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:52:10.507633 ops/training.py:65 2019-01-17 05:52:10.507553: step 15389, loss = 0.54178 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:52:11.789943 ops/training.py:65 2019-01-17 05:52:11.789835: step 15390, loss = 0.61728 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:52:13.075871 ops/training.py:65 2019-01-17 05:52:13.075772: step 15391, loss = 0.48244 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:52:14.358963 ops/training.py:65 2019-01-17 05:52:14.358869: step 15392, loss = 0.48859 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:52:15.643131 ops/training.py:65 2019-01-17 05:52:15.643021: step 15393, loss = 0.43339 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:52:16.927166 ops/training.py:65 2019-01-17 05:52:16.927116: step 15394, loss = 0.41147 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:52:18.216189 ops/training.py:65 2019-01-17 05:52:18.216089: step 15395, loss = 0.39283 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:52:19.504453 ops/training.py:65 2019-01-17 05:52:19.504381: step 15396, loss = 0.45997 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:52:20.792370 ops/training.py:65 2019-01-17 05:52:20.792306: step 15397, loss = 0.42560 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:52:22.074644 ops/training.py:65 2019-01-17 05:52:22.074579: step 15398, loss = 0.32733 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:52:23.364319 ops/training.py:65 2019-01-17 05:52:23.364258: step 15399, loss = 0.44948 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:52:24.653629 ops/training.py:65 2019-01-17 05:52:24.653520: step 15400, loss = 0.38110 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:52:25.938399 ops/training.py:65 2019-01-17 05:52:25.938331: step 15401, loss = 0.44036 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:52:27.225089 ops/training.py:65 2019-01-17 05:52:27.224992: step 15402, loss = 0.45791 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:52:28.514890 ops/training.py:65 2019-01-17 05:52:28.514804: step 15403, loss = 0.52173 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:52:29.803832 ops/training.py:65 2019-01-17 05:52:29.803743: step 15404, loss = 0.48373 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:52:31.093075 ops/training.py:65 2019-01-17 05:52:31.093007: step 15405, loss = 0.34525 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:52:32.380971 ops/training.py:65 2019-01-17 05:52:32.380883: step 15406, loss = 0.46837 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:52:33.669632 ops/training.py:65 2019-01-17 05:52:33.669567: step 15407, loss = 0.42355 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:52:34.958858 ops/training.py:65 2019-01-17 05:52:34.958793: step 15408, loss = 0.38894 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:52:36.248202 ops/training.py:65 2019-01-17 05:52:36.248116: step 15409, loss = 0.38924 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:52:37.538085 ops/training.py:65 2019-01-17 05:52:37.537992: step 15410, loss = 0.39144 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:52:38.827141 ops/training.py:65 2019-01-17 05:52:38.827071: step 15411, loss = 0.48826 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:52:40.111915 ops/training.py:65 2019-01-17 05:52:40.111850: step 15412, loss = 0.47409 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:52:41.400617 ops/training.py:65 2019-01-17 05:52:41.400548: step 15413, loss = 0.51105 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:52:42.689326 ops/training.py:65 2019-01-17 05:52:42.689259: step 15414, loss = 0.46060 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:52:43.978438 ops/training.py:65 2019-01-17 05:52:43.978360: step 15415, loss = 0.39625 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:52:45.267528 ops/training.py:65 2019-01-17 05:52:45.267437: step 15416, loss = 0.45823 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:52:46.556279 ops/training.py:65 2019-01-17 05:52:46.556190: step 15417, loss = 0.36205 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:52:47.843701 ops/training.py:65 2019-01-17 05:52:47.843633: step 15418, loss = 0.43662 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:52:49.131947 ops/training.py:65 2019-01-17 05:52:49.131877: step 15419, loss = 0.49064 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:52:50.422342 ops/training.py:65 2019-01-17 05:52:50.422249: step 15420, loss = 0.37540 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:52:51.711203 ops/training.py:65 2019-01-17 05:52:51.711133: step 15421, loss = 0.44798 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:52:52.999983 ops/training.py:65 2019-01-17 05:52:52.999906: step 15422, loss = 0.36554 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:52:54.294762 ops/training.py:65 2019-01-17 05:52:54.294663: step 15423, loss = 0.39693 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:52:55.584449 ops/training.py:65 2019-01-17 05:52:55.584381: step 15424, loss = 0.47557 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:52:56.873571 ops/training.py:65 2019-01-17 05:52:56.873500: step 15425, loss = 0.33185 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:52:58.162571 ops/training.py:65 2019-01-17 05:52:58.162483: step 15426, loss = 0.36924 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:52:59.452106 ops/training.py:65 2019-01-17 05:52:59.452042: step 15427, loss = 0.43863 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:53:00.740892 ops/training.py:65 2019-01-17 05:53:00.740804: step 15428, loss = 0.44509 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:53:02.031376 ops/training.py:65 2019-01-17 05:53:02.031287: step 15429, loss = 0.38035 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:53:03.321249 ops/training.py:65 2019-01-17 05:53:03.321155: step 15430, loss = 0.45788 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:53:04.609189 ops/training.py:65 2019-01-17 05:53:04.609117: step 15431, loss = 0.53913 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:53:05.896151 ops/training.py:65 2019-01-17 05:53:05.896056: step 15432, loss = 0.41779 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:53:07.185112 ops/training.py:65 2019-01-17 05:53:07.185039: step 15433, loss = 0.40602 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:53:08.473943 ops/training.py:65 2019-01-17 05:53:08.473868: step 15434, loss = 0.51483 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:53:09.762773 ops/training.py:65 2019-01-17 05:53:09.762682: step 15435, loss = 0.42486 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:53:11.053985 ops/training.py:65 2019-01-17 05:53:11.053900: step 15436, loss = 0.55989 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:53:12.342488 ops/training.py:65 2019-01-17 05:53:12.342416: step 15437, loss = 0.49140 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:53:13.630910 ops/training.py:65 2019-01-17 05:53:13.630835: step 15438, loss = 0.36140 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:53:14.919383 ops/training.py:65 2019-01-17 05:53:14.919309: step 15439, loss = 0.40223 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:53:16.207704 ops/training.py:65 2019-01-17 05:53:16.207639: step 15440, loss = 0.46535 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:53:17.496030 ops/training.py:65 2019-01-17 05:53:17.495958: step 15441, loss = 0.45717 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:53:18.784781 ops/training.py:65 2019-01-17 05:53:18.784710: step 15442, loss = 0.41647 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:53:20.073826 ops/training.py:65 2019-01-17 05:53:20.073761: step 15443, loss = 0.39518 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:53:21.361463 ops/training.py:65 2019-01-17 05:53:21.361397: step 15444, loss = 0.44446 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:53:22.650341 ops/training.py:65 2019-01-17 05:53:22.650269: step 15445, loss = 0.41166 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:53:23.934404 ops/training.py:65 2019-01-17 05:53:23.934337: step 15446, loss = 0.43530 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:53:25.217472 ops/training.py:65 2019-01-17 05:53:25.217374: step 15447, loss = 0.45075 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:53:26.509159 ops/training.py:65 2019-01-17 05:53:26.509062: step 15448, loss = 0.42375 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:53:27.798654 ops/training.py:65 2019-01-17 05:53:27.798585: step 15449, loss = 0.39863 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:53:29.086553 ops/training.py:65 2019-01-17 05:53:29.086482: step 15450, loss = 0.44628 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:53:30.375420 ops/training.py:65 2019-01-17 05:53:30.375354: step 15451, loss = 0.46841 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:53:31.664144 ops/training.py:65 2019-01-17 05:53:31.664071: step 15452, loss = 0.39187 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:53:32.953061 ops/training.py:65 2019-01-17 05:53:32.952988: step 15453, loss = 0.44447 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:53:34.241917 ops/training.py:65 2019-01-17 05:53:34.241840: step 15454, loss = 0.48426 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:53:35.528531 ops/training.py:65 2019-01-17 05:53:35.528460: step 15455, loss = 0.39318 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:53:36.816714 ops/training.py:65 2019-01-17 05:53:36.816644: step 15456, loss = 0.36695 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:53:38.105712 ops/training.py:65 2019-01-17 05:53:38.105643: step 15457, loss = 0.43248 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:53:39.395913 ops/training.py:65 2019-01-17 05:53:39.395835: step 15458, loss = 0.44916 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:53:40.683685 ops/training.py:65 2019-01-17 05:53:40.683598: step 15459, loss = 0.50013 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:53:41.967246 ops/training.py:65 2019-01-17 05:53:41.967176: step 15460, loss = 0.38934 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:53:43.250075 ops/training.py:65 2019-01-17 05:53:43.249977: step 15461, loss = 0.40039 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:53:44.534246 ops/training.py:65 2019-01-17 05:53:44.534148: step 15462, loss = 0.48625 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:53:45.822004 ops/training.py:65 2019-01-17 05:53:45.821893: step 15463, loss = 0.43410 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:53:47.107008 ops/training.py:65 2019-01-17 05:53:47.106856: step 15464, loss = 0.49450 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:53:48.394386 ops/training.py:65 2019-01-17 05:53:48.394226: step 15465, loss = 0.37306 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:53:49.684883 ops/training.py:65 2019-01-17 05:53:49.684780: step 15466, loss = 0.49918 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:53:50.974426 ops/training.py:65 2019-01-17 05:53:50.974352: step 15467, loss = 0.47697 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:53:52.263216 ops/training.py:65 2019-01-17 05:53:52.263130: step 15468, loss = 0.39788 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:53:53.552246 ops/training.py:65 2019-01-17 05:53:53.552176: step 15469, loss = 0.43525 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:53:54.840360 ops/training.py:65 2019-01-17 05:53:54.840302: step 15470, loss = 0.52995 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:53:56.124335 ops/training.py:65 2019-01-17 05:53:56.124276: step 15471, loss = 0.49813 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:53:57.412773 ops/training.py:65 2019-01-17 05:53:57.412641: step 15472, loss = 0.53670 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 05:53:58.701026 ops/training.py:65 2019-01-17 05:53:58.700960: step 15473, loss = 0.42841 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:53:59.989173 ops/training.py:65 2019-01-17 05:53:59.989109: step 15474, loss = 0.38889 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:54:01.277268 ops/training.py:65 2019-01-17 05:54:01.277183: step 15475, loss = 0.45710 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:54:02.565287 ops/training.py:65 2019-01-17 05:54:02.565198: step 15476, loss = 0.39426 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:54:03.855001 ops/training.py:65 2019-01-17 05:54:03.854921: step 15477, loss = 0.41431 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:54:05.142943 ops/training.py:65 2019-01-17 05:54:05.142861: step 15478, loss = 0.38692 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:54:06.426345 ops/training.py:65 2019-01-17 05:54:06.426278: step 15479, loss = 0.46143 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:54:07.713794 ops/training.py:65 2019-01-17 05:54:07.713733: step 15480, loss = 0.37960 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:54:09.001737 ops/training.py:65 2019-01-17 05:54:09.001665: step 15481, loss = 0.41913 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:54:10.291589 ops/training.py:65 2019-01-17 05:54:10.291527: step 15482, loss = 0.45327 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:54:11.575704 ops/training.py:65 2019-01-17 05:54:11.575637: step 15483, loss = 0.38500 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:54:12.865288 ops/training.py:65 2019-01-17 05:54:12.865212: step 15484, loss = 0.42087 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:54:14.152822 ops/training.py:65 2019-01-17 05:54:14.152746: step 15485, loss = 0.39659 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:54:15.442003 ops/training.py:65 2019-01-17 05:54:15.441906: step 15486, loss = 0.55911 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:54:16.730801 ops/training.py:65 2019-01-17 05:54:16.730713: step 15487, loss = 0.47248 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:54:18.018028 ops/training.py:65 2019-01-17 05:54:18.017959: step 15488, loss = 0.42827 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:54:19.306254 ops/training.py:65 2019-01-17 05:54:19.306183: step 15489, loss = 0.52684 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:54:20.594682 ops/training.py:65 2019-01-17 05:54:20.594598: step 15490, loss = 0.55191 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:54:21.883420 ops/training.py:65 2019-01-17 05:54:21.883327: step 15491, loss = 0.46544 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:54:23.173118 ops/training.py:65 2019-01-17 05:54:23.173025: step 15492, loss = 0.36040 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:54:24.462627 ops/training.py:65 2019-01-17 05:54:24.462531: step 15493, loss = 0.37441 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:54:25.751951 ops/training.py:65 2019-01-17 05:54:25.751879: step 15494, loss = 0.33100 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:54:27.040803 ops/training.py:65 2019-01-17 05:54:27.040729: step 15495, loss = 0.35447 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:54:28.329619 ops/training.py:65 2019-01-17 05:54:28.329550: step 15496, loss = 0.40184 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:54:29.619178 ops/training.py:65 2019-01-17 05:54:29.619079: step 15497, loss = 0.38380 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:54:30.908488 ops/training.py:65 2019-01-17 05:54:30.908412: step 15498, loss = 0.43644 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:54:32.196240 ops/training.py:65 2019-01-17 05:54:32.196175: step 15499, loss = 0.44245 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:54:33.479215 ops/training.py:65 2019-01-17 05:54:33.479143: step 15500, loss = 0.50672 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:54:34.764388 ops/training.py:65 2019-01-17 05:54:34.764290: step 15501, loss = 0.37244 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:54:36.053829 ops/training.py:65 2019-01-17 05:54:36.053673: step 15502, loss = 0.42121 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:54:37.339273 ops/training.py:65 2019-01-17 05:54:37.339203: step 15503, loss = 0.37932 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:54:38.627764 ops/training.py:65 2019-01-17 05:54:38.627675: step 15504, loss = 0.40129 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:54:39.911789 ops/training.py:65 2019-01-17 05:54:39.911720: step 15505, loss = 0.39200 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:54:41.197915 ops/training.py:65 2019-01-17 05:54:41.197845: step 15506, loss = 0.32339 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:54:42.485132 ops/training.py:65 2019-01-17 05:54:42.485060: step 15507, loss = 0.41599 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:54:43.769416 ops/training.py:65 2019-01-17 05:54:43.769347: step 15508, loss = 0.46233 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:54:45.057696 ops/training.py:65 2019-01-17 05:54:45.057605: step 15509, loss = 0.44837 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:54:46.342507 ops/training.py:65 2019-01-17 05:54:46.342446: step 15510, loss = 0.51878 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:54:47.621637 ops/training.py:65 2019-01-17 05:54:47.621575: step 15511, loss = 0.55439 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:54:48.901112 ops/training.py:65 2019-01-17 05:54:48.901038: step 15512, loss = 0.50131 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:54:50.192365 ops/training.py:65 2019-01-17 05:54:50.192257: step 15513, loss = 0.32302 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:54:51.482373 ops/training.py:65 2019-01-17 05:54:51.482313: step 15514, loss = 0.45569 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:54:52.762994 ops/training.py:65 2019-01-17 05:54:52.762943: step 15515, loss = 0.45884 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:54:54.049984 ops/training.py:65 2019-01-17 05:54:54.049915: step 15516, loss = 0.49245 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:54:55.335664 ops/training.py:65 2019-01-17 05:54:55.335559: step 15517, loss = 0.45124 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:54:56.627046 ops/training.py:65 2019-01-17 05:54:56.626890: step 15518, loss = 0.39909 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:54:57.918635 ops/training.py:65 2019-01-17 05:54:57.918567: step 15519, loss = 0.44653 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:54:59.207379 ops/training.py:65 2019-01-17 05:54:59.207312: step 15520, loss = 0.39461 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:55:00.491316 ops/training.py:65 2019-01-17 05:55:00.491250: step 15521, loss = 0.37467 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:55:01.779727 ops/training.py:65 2019-01-17 05:55:01.779584: step 15522, loss = 0.41400 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:55:03.063789 ops/training.py:65 2019-01-17 05:55:03.063693: step 15523, loss = 0.38704 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:55:04.349650 ops/training.py:65 2019-01-17 05:55:04.349545: step 15524, loss = 0.46368 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:55:05.634465 ops/training.py:65 2019-01-17 05:55:05.634360: step 15525, loss = 0.40538 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:55:06.922340 ops/training.py:65 2019-01-17 05:55:06.922231: step 15526, loss = 0.40649 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:55:08.208287 ops/training.py:65 2019-01-17 05:55:08.208222: step 15527, loss = 0.44094 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:55:09.497439 ops/training.py:65 2019-01-17 05:55:09.497342: step 15528, loss = 0.46910 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:55:10.778327 ops/training.py:65 2019-01-17 05:55:10.778266: step 15529, loss = 0.47718 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:55:12.067333 ops/training.py:65 2019-01-17 05:55:12.067248: step 15530, loss = 0.50176 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:55:13.353801 ops/training.py:65 2019-01-17 05:55:13.353720: step 15531, loss = 0.40851 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:55:14.642516 ops/training.py:65 2019-01-17 05:55:14.642446: step 15532, loss = 0.38607 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:55:15.922316 ops/training.py:65 2019-01-17 05:55:15.922253: step 15533, loss = 0.32829 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:55:17.206939 ops/training.py:65 2019-01-17 05:55:17.206874: step 15534, loss = 0.37186 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:55:18.495496 ops/training.py:65 2019-01-17 05:55:18.495435: step 15535, loss = 0.29108 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:55:19.780138 ops/training.py:65 2019-01-17 05:55:19.780053: step 15536, loss = 0.32491 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:55:21.067453 ops/training.py:65 2019-01-17 05:55:21.067343: step 15537, loss = 0.44864 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:55:22.359539 ops/training.py:65 2019-01-17 05:55:22.359395: step 15538, loss = 0.45322 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:55:23.646210 ops/training.py:65 2019-01-17 05:55:23.646140: step 15539, loss = 0.34772 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:55:24.930460 ops/training.py:65 2019-01-17 05:55:24.930396: step 15540, loss = 0.59515 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:55:26.215324 ops/training.py:65 2019-01-17 05:55:26.215244: step 15541, loss = 0.43573 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:55:27.496278 ops/training.py:65 2019-01-17 05:55:27.496203: step 15542, loss = 0.43415 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:55:28.780898 ops/training.py:65 2019-01-17 05:55:28.780796: step 15543, loss = 0.38345 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:55:30.069151 ops/training.py:65 2019-01-17 05:55:30.069059: step 15544, loss = 0.41381 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:55:31.356831 ops/training.py:65 2019-01-17 05:55:31.356714: step 15545, loss = 0.42415 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:55:32.640431 ops/training.py:65 2019-01-17 05:55:32.640332: step 15546, loss = 0.40904 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:55:33.932570 ops/training.py:65 2019-01-17 05:55:33.932471: step 15547, loss = 0.45819 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:55:35.215526 ops/training.py:65 2019-01-17 05:55:35.215454: step 15548, loss = 0.58396 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:55:36.508822 ops/training.py:65 2019-01-17 05:55:36.508710: step 15549, loss = 0.49914 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:55:37.788665 ops/training.py:65 2019-01-17 05:55:37.788559: step 15550, loss = 0.50496 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 05:55:39.076732 ops/training.py:65 2019-01-17 05:55:39.076626: step 15551, loss = 0.44887 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:55:40.360363 ops/training.py:65 2019-01-17 05:55:40.360287: step 15552, loss = 0.43533 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:55:41.648299 ops/training.py:65 2019-01-17 05:55:41.648152: step 15553, loss = 0.34422 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:55:42.937975 ops/training.py:65 2019-01-17 05:55:42.937911: step 15554, loss = 0.47406 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:55:44.226087 ops/training.py:65 2019-01-17 05:55:44.225996: step 15555, loss = 0.39714 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:55:45.515738 ops/training.py:65 2019-01-17 05:55:45.515664: step 15556, loss = 0.38517 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:55:46.804102 ops/training.py:65 2019-01-17 05:55:46.804039: step 15557, loss = 0.45949 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:55:48.088953 ops/training.py:65 2019-01-17 05:55:48.088886: step 15558, loss = 0.37109 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:55:49.376711 ops/training.py:65 2019-01-17 05:55:49.376648: step 15559, loss = 0.38513 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:55:50.665228 ops/training.py:65 2019-01-17 05:55:50.665132: step 15560, loss = 0.42061 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:55:51.954976 ops/training.py:65 2019-01-17 05:55:51.954914: step 15561, loss = 0.39630 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:55:53.238745 ops/training.py:65 2019-01-17 05:55:53.238678: step 15562, loss = 0.48705 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:55:54.521485 ops/training.py:65 2019-01-17 05:55:54.521399: step 15563, loss = 0.44401 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:55:55.806102 ops/training.py:65 2019-01-17 05:55:55.805991: step 15564, loss = 0.48543 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:55:57.099264 ops/training.py:65 2019-01-17 05:55:57.099161: step 15565, loss = 0.47947 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:55:58.389768 ops/training.py:65 2019-01-17 05:55:58.389699: step 15566, loss = 0.37837 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:55:59.677297 ops/training.py:65 2019-01-17 05:55:59.677235: step 15567, loss = 0.41094 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:56:00.965637 ops/training.py:65 2019-01-17 05:56:00.965548: step 15568, loss = 0.35494 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:56:02.251006 ops/training.py:65 2019-01-17 05:56:02.250941: step 15569, loss = 0.46681 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:56:03.534305 ops/training.py:65 2019-01-17 05:56:03.534244: step 15570, loss = 0.29461 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:56:04.818438 ops/training.py:65 2019-01-17 05:56:04.818351: step 15571, loss = 0.49904 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:56:06.109618 ops/training.py:65 2019-01-17 05:56:06.109513: step 15572, loss = 0.48832 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:56:07.398951 ops/training.py:65 2019-01-17 05:56:07.398835: step 15573, loss = 0.43738 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:56:08.682503 ops/training.py:65 2019-01-17 05:56:08.682435: step 15574, loss = 0.38892 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:56:09.975256 ops/training.py:65 2019-01-17 05:56:09.975142: step 15575, loss = 0.41389 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:56:11.265292 ops/training.py:65 2019-01-17 05:56:11.265227: step 15576, loss = 0.34698 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:56:12.549316 ops/training.py:65 2019-01-17 05:56:12.549241: step 15577, loss = 0.37632 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:56:13.838894 ops/training.py:65 2019-01-17 05:56:13.838825: step 15578, loss = 0.41037 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:56:15.128259 ops/training.py:65 2019-01-17 05:56:15.128155: step 15579, loss = 0.42799 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:56:16.418273 ops/training.py:65 2019-01-17 05:56:16.418198: step 15580, loss = 0.42299 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:56:17.702544 ops/training.py:65 2019-01-17 05:56:17.702476: step 15581, loss = 0.39069 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:56:18.993039 ops/training.py:65 2019-01-17 05:56:18.992931: step 15582, loss = 0.50996 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:56:20.281828 ops/training.py:65 2019-01-17 05:56:20.281720: step 15583, loss = 0.43870 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:56:21.565837 ops/training.py:65 2019-01-17 05:56:21.565760: step 15584, loss = 0.33684 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:56:22.855733 ops/training.py:65 2019-01-17 05:56:22.855625: step 15585, loss = 0.35570 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:56:24.144133 ops/training.py:65 2019-01-17 05:56:24.144035: step 15586, loss = 0.40048 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:56:25.433411 ops/training.py:65 2019-01-17 05:56:25.433311: step 15587, loss = 0.40587 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:56:26.717783 ops/training.py:65 2019-01-17 05:56:26.717720: step 15588, loss = 0.45706 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:56:28.006619 ops/training.py:65 2019-01-17 05:56:28.006459: step 15589, loss = 0.39474 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:56:29.296549 ops/training.py:65 2019-01-17 05:56:29.296462: step 15590, loss = 0.49451 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:56:30.585620 ops/training.py:65 2019-01-17 05:56:30.585535: step 15591, loss = 0.45983 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:56:31.874479 ops/training.py:65 2019-01-17 05:56:31.874417: step 15592, loss = 0.36922 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:56:33.161567 ops/training.py:65 2019-01-17 05:56:33.161493: step 15593, loss = 0.45451 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:56:34.448673 ops/training.py:65 2019-01-17 05:56:34.448600: step 15594, loss = 0.47527 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:56:35.732982 ops/training.py:65 2019-01-17 05:56:35.732917: step 15595, loss = 0.35149 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:56:37.017075 ops/training.py:65 2019-01-17 05:56:37.016954: step 15596, loss = 0.49415 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:56:38.309553 ops/training.py:65 2019-01-17 05:56:38.309443: step 15597, loss = 0.32792 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:56:39.601708 ops/training.py:65 2019-01-17 05:56:39.601616: step 15598, loss = 0.40835 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:56:40.891517 ops/training.py:65 2019-01-17 05:56:40.891450: step 15599, loss = 0.40128 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:56:42.179861 ops/training.py:65 2019-01-17 05:56:42.179790: step 15600, loss = 0.46826 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:56:43.464606 ops/training.py:65 2019-01-17 05:56:43.464540: step 15601, loss = 0.46064 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:56:44.753115 ops/training.py:65 2019-01-17 05:56:44.753052: step 15602, loss = 0.46397 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:56:46.041859 ops/training.py:65 2019-01-17 05:56:46.041790: step 15603, loss = 0.43492 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:56:47.330630 ops/training.py:65 2019-01-17 05:56:47.330564: step 15604, loss = 0.43079 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:56:48.618724 ops/training.py:65 2019-01-17 05:56:48.618657: step 15605, loss = 0.44213 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:56:49.906538 ops/training.py:65 2019-01-17 05:56:49.906447: step 15606, loss = 0.48865 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:56:51.195289 ops/training.py:65 2019-01-17 05:56:51.195218: step 15607, loss = 0.40646 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:56:52.483967 ops/training.py:65 2019-01-17 05:56:52.483901: step 15608, loss = 0.48125 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:56:53.768971 ops/training.py:65 2019-01-17 05:56:53.768880: step 15609, loss = 0.47506 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:56:55.057778 ops/training.py:65 2019-01-17 05:56:55.057707: step 15610, loss = 0.42981 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:56:56.347186 ops/training.py:65 2019-01-17 05:56:56.347094: step 15611, loss = 0.43446 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:56:57.637637 ops/training.py:65 2019-01-17 05:56:57.637567: step 15612, loss = 0.32626 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:56:58.932233 ops/training.py:65 2019-01-17 05:56:58.932170: step 15613, loss = 0.42499 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:57:00.220668 ops/training.py:65 2019-01-17 05:57:00.220583: step 15614, loss = 0.43226 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:57:01.508474 ops/training.py:65 2019-01-17 05:57:01.508385: step 15615, loss = 0.41464 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:57:02.798195 ops/training.py:65 2019-01-17 05:57:02.798102: step 15616, loss = 0.48525 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:57:04.082044 ops/training.py:65 2019-01-17 05:57:04.081976: step 15617, loss = 0.45985 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:57:05.363322 ops/training.py:65 2019-01-17 05:57:05.363203: step 15618, loss = 0.39072 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:57:06.649741 ops/training.py:65 2019-01-17 05:57:06.649634: step 15619, loss = 0.54874 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:57:07.937704 ops/training.py:65 2019-01-17 05:57:07.937596: step 15620, loss = 0.49787 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:57:09.223659 ops/training.py:65 2019-01-17 05:57:09.223552: step 15621, loss = 0.39712 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:57:10.515749 ops/training.py:65 2019-01-17 05:57:10.515591: step 15622, loss = 0.42154 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:57:11.806924 ops/training.py:65 2019-01-17 05:57:11.806845: step 15623, loss = 0.45727 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:57:13.096778 ops/training.py:65 2019-01-17 05:57:13.096710: step 15624, loss = 0.35192 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:57:14.384227 ops/training.py:65 2019-01-17 05:57:14.384112: step 15625, loss = 0.46346 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:57:15.677525 ops/training.py:65 2019-01-17 05:57:15.677420: step 15626, loss = 0.41439 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:57:16.962471 ops/training.py:65 2019-01-17 05:57:16.962405: step 15627, loss = 0.39871 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:57:18.248046 ops/training.py:65 2019-01-17 05:57:18.247935: step 15628, loss = 0.58180 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:57:19.534437 ops/training.py:65 2019-01-17 05:57:19.534338: step 15629, loss = 0.42365 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:57:20.827512 ops/training.py:65 2019-01-17 05:57:20.827353: step 15630, loss = 0.47735 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:57:22.120000 ops/training.py:65 2019-01-17 05:57:22.119900: step 15631, loss = 0.43475 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:57:23.415006 ops/training.py:65 2019-01-17 05:57:23.414932: step 15632, loss = 0.46819 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:57:24.698577 ops/training.py:65 2019-01-17 05:57:24.698514: step 15633, loss = 0.56369 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.625
I4672 2019-01-17 05:57:25.982757 ops/training.py:65 2019-01-17 05:57:25.982683: step 15634, loss = 0.37322 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:57:27.274254 ops/training.py:65 2019-01-17 05:57:27.274149: step 15635, loss = 0.44178 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:57:28.558867 ops/training.py:65 2019-01-17 05:57:28.558782: step 15636, loss = 0.42326 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:57:29.852953 ops/training.py:65 2019-01-17 05:57:29.852855: step 15637, loss = 0.29063 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:57:31.143673 ops/training.py:65 2019-01-17 05:57:31.143593: step 15638, loss = 0.45262 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:57:32.434197 ops/training.py:65 2019-01-17 05:57:32.434101: step 15639, loss = 0.38113 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:57:33.723531 ops/training.py:65 2019-01-17 05:57:33.723466: step 15640, loss = 0.43263 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:57:35.013741 ops/training.py:65 2019-01-17 05:57:35.013672: step 15641, loss = 0.35482 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:57:36.302827 ops/training.py:65 2019-01-17 05:57:36.302745: step 15642, loss = 0.34113 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:57:37.591039 ops/training.py:65 2019-01-17 05:57:37.590946: step 15643, loss = 0.52329 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:57:38.879988 ops/training.py:65 2019-01-17 05:57:38.879909: step 15644, loss = 0.37029 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:57:40.168740 ops/training.py:65 2019-01-17 05:57:40.168641: step 15645, loss = 0.43847 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:57:41.459322 ops/training.py:65 2019-01-17 05:57:41.459250: step 15646, loss = 0.46101 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:57:42.748406 ops/training.py:65 2019-01-17 05:57:42.748340: step 15647, loss = 0.35926 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:57:44.036687 ops/training.py:65 2019-01-17 05:57:44.036616: step 15648, loss = 0.41749 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:57:45.326002 ops/training.py:65 2019-01-17 05:57:45.325931: step 15649, loss = 0.43318 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:57:46.614500 ops/training.py:65 2019-01-17 05:57:46.614430: step 15650, loss = 0.39869 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:57:47.898609 ops/training.py:65 2019-01-17 05:57:47.898541: step 15651, loss = 0.35394 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:57:49.182872 ops/training.py:65 2019-01-17 05:57:49.182793: step 15652, loss = 0.39431 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:57:50.470121 ops/training.py:65 2019-01-17 05:57:50.470008: step 15653, loss = 0.54049 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:57:51.754910 ops/training.py:65 2019-01-17 05:57:51.754802: step 15654, loss = 0.44204 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:57:53.047317 ops/training.py:65 2019-01-17 05:57:53.047175: step 15655, loss = 0.44794 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:57:54.334743 ops/training.py:65 2019-01-17 05:57:54.334666: step 15656, loss = 0.41752 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:57:55.620293 ops/training.py:65 2019-01-17 05:57:55.620182: step 15657, loss = 0.39068 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:57:56.906472 ops/training.py:65 2019-01-17 05:57:56.906364: step 15658, loss = 0.40569 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:57:58.197234 ops/training.py:65 2019-01-17 05:57:58.197129: step 15659, loss = 0.44738 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:57:59.488020 ops/training.py:65 2019-01-17 05:57:59.487946: step 15660, loss = 0.52421 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:58:00.772319 ops/training.py:65 2019-01-17 05:58:00.772240: step 15661, loss = 0.41380 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:58:02.057985 ops/training.py:65 2019-01-17 05:58:02.057911: step 15662, loss = 0.46701 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:58:03.343598 ops/training.py:65 2019-01-17 05:58:03.343532: step 15663, loss = 0.41088 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:58:04.633750 ops/training.py:65 2019-01-17 05:58:04.633638: step 15664, loss = 0.42236 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:58:05.915045 ops/training.py:65 2019-01-17 05:58:05.914983: step 15665, loss = 0.42622 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:58:07.203508 ops/training.py:65 2019-01-17 05:58:07.203437: step 15666, loss = 0.40616 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:58:08.492172 ops/training.py:65 2019-01-17 05:58:08.492105: step 15667, loss = 0.43833 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:58:09.781524 ops/training.py:65 2019-01-17 05:58:09.781453: step 15668, loss = 0.36125 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:58:11.065534 ops/training.py:65 2019-01-17 05:58:11.065469: step 15669, loss = 0.37969 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:58:12.349426 ops/training.py:65 2019-01-17 05:58:12.349335: step 15670, loss = 0.44114 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:58:13.640917 ops/training.py:65 2019-01-17 05:58:13.640810: step 15671, loss = 0.41509 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:58:14.933159 ops/training.py:65 2019-01-17 05:58:14.933091: step 15672, loss = 0.40760 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:58:16.217102 ops/training.py:65 2019-01-17 05:58:16.217039: step 15673, loss = 0.31594 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 05:58:17.507241 ops/training.py:65 2019-01-17 05:58:17.507125: step 15674, loss = 0.39486 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:58:18.796385 ops/training.py:65 2019-01-17 05:58:18.796287: step 15675, loss = 0.31705 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:58:20.084064 ops/training.py:65 2019-01-17 05:58:20.083966: step 15676, loss = 0.33094 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:58:21.368198 ops/training.py:65 2019-01-17 05:58:21.368137: step 15677, loss = 0.36501 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:58:22.652217 ops/training.py:65 2019-01-17 05:58:22.652154: step 15678, loss = 0.43220 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:58:23.940984 ops/training.py:65 2019-01-17 05:58:23.940904: step 15679, loss = 0.40675 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:58:25.224515 ops/training.py:65 2019-01-17 05:58:25.224439: step 15680, loss = 0.36992 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:58:26.510266 ops/training.py:65 2019-01-17 05:58:26.510194: step 15681, loss = 0.37092 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:58:27.794516 ops/training.py:65 2019-01-17 05:58:27.794403: step 15682, loss = 0.41104 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:58:29.085869 ops/training.py:65 2019-01-17 05:58:29.085720: step 15683, loss = 0.44489 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:58:30.372461 ops/training.py:65 2019-01-17 05:58:30.372396: step 15684, loss = 0.43219 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:58:31.660950 ops/training.py:65 2019-01-17 05:58:31.660793: step 15685, loss = 0.44555 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:58:32.946252 ops/training.py:65 2019-01-17 05:58:32.946188: step 15686, loss = 0.41261 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:58:34.230903 ops/training.py:65 2019-01-17 05:58:34.230833: step 15687, loss = 0.41326 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:58:35.517382 ops/training.py:65 2019-01-17 05:58:35.517272: step 15688, loss = 0.45213 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:58:36.805957 ops/training.py:65 2019-01-17 05:58:36.805852: step 15689, loss = 0.47251 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:58:38.098844 ops/training.py:65 2019-01-17 05:58:38.098741: step 15690, loss = 0.40534 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:58:39.390651 ops/training.py:65 2019-01-17 05:58:39.390582: step 15691, loss = 0.30647 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:58:40.674962 ops/training.py:65 2019-01-17 05:58:40.674885: step 15692, loss = 0.42144 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:58:41.963952 ops/training.py:65 2019-01-17 05:58:41.963884: step 15693, loss = 0.46060 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:58:43.249439 ops/training.py:65 2019-01-17 05:58:43.249368: step 15694, loss = 0.42461 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:58:44.532670 ops/training.py:65 2019-01-17 05:58:44.532597: step 15695, loss = 0.43215 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:58:45.824146 ops/training.py:65 2019-01-17 05:58:45.823989: step 15696, loss = 0.48235 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:58:47.115422 ops/training.py:65 2019-01-17 05:58:47.115353: step 15697, loss = 0.39248 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:58:48.404659 ops/training.py:65 2019-01-17 05:58:48.404577: step 15698, loss = 0.40224 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:58:49.694308 ops/training.py:65 2019-01-17 05:58:49.694238: step 15699, loss = 0.34419 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:58:50.977955 ops/training.py:65 2019-01-17 05:58:50.977870: step 15700, loss = 0.46306 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:58:52.266860 ops/training.py:65 2019-01-17 05:58:52.266773: step 15701, loss = 0.43780 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:58:53.552522 ops/training.py:65 2019-01-17 05:58:53.552440: step 15702, loss = 0.40902 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:58:54.840713 ops/training.py:65 2019-01-17 05:58:54.840620: step 15703, loss = 0.41553 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:58:56.125303 ops/training.py:65 2019-01-17 05:58:56.125216: step 15704, loss = 0.36894 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:58:57.413587 ops/training.py:65 2019-01-17 05:58:57.413499: step 15705, loss = 0.38001 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:58:58.700396 ops/training.py:65 2019-01-17 05:58:58.700302: step 15706, loss = 0.47184 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 05:58:59.984665 ops/training.py:65 2019-01-17 05:58:59.984604: step 15707, loss = 0.43452 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:59:01.273600 ops/training.py:65 2019-01-17 05:59:01.273443: step 15708, loss = 0.45677 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:59:02.562362 ops/training.py:65 2019-01-17 05:59:02.562289: step 15709, loss = 0.51958 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:59:03.850750 ops/training.py:65 2019-01-17 05:59:03.850652: step 15710, loss = 0.41478 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:59:05.140361 ops/training.py:65 2019-01-17 05:59:05.140267: step 15711, loss = 0.47687 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:59:06.428577 ops/training.py:65 2019-01-17 05:59:06.428480: step 15712, loss = 0.36118 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:59:07.718506 ops/training.py:65 2019-01-17 05:59:07.718436: step 15713, loss = 0.40551 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:59:09.006432 ops/training.py:65 2019-01-17 05:59:09.006367: step 15714, loss = 0.39741 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:59:10.294714 ops/training.py:65 2019-01-17 05:59:10.294631: step 15715, loss = 0.41426 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:59:11.582803 ops/training.py:65 2019-01-17 05:59:11.582729: step 15716, loss = 0.48481 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:59:12.872337 ops/training.py:65 2019-01-17 05:59:12.872269: step 15717, loss = 0.39073 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:59:14.160966 ops/training.py:65 2019-01-17 05:59:14.160896: step 15718, loss = 0.46921 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:59:15.444573 ops/training.py:65 2019-01-17 05:59:15.444502: step 15719, loss = 0.34101 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:59:16.728113 ops/training.py:65 2019-01-17 05:59:16.728002: step 15720, loss = 0.46735 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:59:18.012457 ops/training.py:65 2019-01-17 05:59:18.012346: step 15721, loss = 0.39735 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:59:19.303566 ops/training.py:65 2019-01-17 05:59:19.303464: step 15722, loss = 0.45773 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:59:20.583395 ops/training.py:65 2019-01-17 05:59:20.583316: step 15723, loss = 0.38396 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:59:21.865943 ops/training.py:65 2019-01-17 05:59:21.865831: step 15724, loss = 0.43203 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:59:23.157314 ops/training.py:65 2019-01-17 05:59:23.157210: step 15725, loss = 0.44559 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:59:24.449516 ops/training.py:65 2019-01-17 05:59:24.449446: step 15726, loss = 0.31867 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:59:25.738202 ops/training.py:65 2019-01-17 05:59:25.738131: step 15727, loss = 0.46782 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:59:27.025615 ops/training.py:65 2019-01-17 05:59:27.025546: step 15728, loss = 0.39510 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:59:28.314603 ops/training.py:65 2019-01-17 05:59:28.314513: step 15729, loss = 0.45453 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:59:29.604383 ops/training.py:65 2019-01-17 05:59:29.604317: step 15730, loss = 0.36432 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:59:30.888337 ops/training.py:65 2019-01-17 05:59:30.888268: step 15731, loss = 0.48713 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:59:32.177344 ops/training.py:65 2019-01-17 05:59:32.177232: step 15732, loss = 0.42605 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:59:33.464142 ops/training.py:65 2019-01-17 05:59:33.464041: step 15733, loss = 0.51738 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 05:59:34.748756 ops/training.py:65 2019-01-17 05:59:34.748691: step 15734, loss = 0.29900 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:59:36.031658 ops/training.py:65 2019-01-17 05:59:36.031560: step 15735, loss = 0.42125 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 05:59:37.323271 ops/training.py:65 2019-01-17 05:59:37.323160: step 15736, loss = 0.39854 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:59:38.615550 ops/training.py:65 2019-01-17 05:59:38.615483: step 15737, loss = 0.45370 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:59:39.904921 ops/training.py:65 2019-01-17 05:59:39.904858: step 15738, loss = 0.39690 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:59:41.194796 ops/training.py:65 2019-01-17 05:59:41.194731: step 15739, loss = 0.37093 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 05:59:42.478148 ops/training.py:65 2019-01-17 05:59:42.478073: step 15740, loss = 0.49735 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 05:59:43.762098 ops/training.py:65 2019-01-17 05:59:43.762023: step 15741, loss = 0.32601 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:59:45.046513 ops/training.py:65 2019-01-17 05:59:45.046449: step 15742, loss = 0.38771 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:59:46.333877 ops/training.py:65 2019-01-17 05:59:46.333812: step 15743, loss = 0.40715 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:59:47.618781 ops/training.py:65 2019-01-17 05:59:47.618717: step 15744, loss = 0.47332 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:59:48.903291 ops/training.py:65 2019-01-17 05:59:48.903223: step 15745, loss = 0.39728 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:59:50.190835 ops/training.py:65 2019-01-17 05:59:50.190728: step 15746, loss = 0.41252 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 05:59:51.473239 ops/training.py:65 2019-01-17 05:59:51.473134: step 15747, loss = 0.49535 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:59:52.760673 ops/training.py:65 2019-01-17 05:59:52.760568: step 15748, loss = 0.46150 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 05:59:54.042584 ops/training.py:65 2019-01-17 05:59:54.042480: step 15749, loss = 0.29579 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:59:55.329196 ops/training.py:65 2019-01-17 05:59:55.329086: step 15750, loss = 0.33481 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 05:59:56.620895 ops/training.py:65 2019-01-17 05:59:56.620829: step 15751, loss = 0.39358 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:59:57.910643 ops/training.py:65 2019-01-17 05:59:57.910567: step 15752, loss = 0.33687 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 05:59:59.199816 ops/training.py:65 2019-01-17 05:59:59.199743: step 15753, loss = 0.40173 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:00:00.488208 ops/training.py:65 2019-01-17 06:00:00.488135: step 15754, loss = 0.38695 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:00:01.771725 ops/training.py:65 2019-01-17 06:00:01.771671: step 15755, loss = 0.42545 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:00:03.054793 ops/training.py:65 2019-01-17 06:00:03.054720: step 15756, loss = 0.46703 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:00:04.346301 ops/training.py:65 2019-01-17 06:00:04.346199: step 15757, loss = 0.39601 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:00:05.636400 ops/training.py:65 2019-01-17 06:00:05.636326: step 15758, loss = 0.39079 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:00:06.925621 ops/training.py:65 2019-01-17 06:00:06.925527: step 15759, loss = 0.36334 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:00:08.209755 ops/training.py:65 2019-01-17 06:00:08.209687: step 15760, loss = 0.51304 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 06:00:09.497919 ops/training.py:65 2019-01-17 06:00:09.497832: step 15761, loss = 0.37963 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:00:10.782260 ops/training.py:65 2019-01-17 06:00:10.782198: step 15762, loss = 0.36333 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:00:12.070828 ops/training.py:65 2019-01-17 06:00:12.070762: step 15763, loss = 0.40113 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:00:13.354046 ops/training.py:65 2019-01-17 06:00:13.353973: step 15764, loss = 0.54257 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:00:14.644372 ops/training.py:65 2019-01-17 06:00:14.644272: step 15765, loss = 0.38335 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:00:15.934926 ops/training.py:65 2019-01-17 06:00:15.934834: step 15766, loss = 0.57282 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 06:00:17.224657 ops/training.py:65 2019-01-17 06:00:17.224589: step 15767, loss = 0.40557 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:00:18.512722 ops/training.py:65 2019-01-17 06:00:18.512652: step 15768, loss = 0.40659 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:00:19.801068 ops/training.py:65 2019-01-17 06:00:19.800996: step 15769, loss = 0.40430 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:00:21.085507 ops/training.py:65 2019-01-17 06:00:21.085416: step 15770, loss = 0.36283 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:00:22.368668 ops/training.py:65 2019-01-17 06:00:22.368561: step 15771, loss = 0.42259 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:00:23.660765 ops/training.py:65 2019-01-17 06:00:23.660663: step 15772, loss = 0.48251 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:00:24.952115 ops/training.py:65 2019-01-17 06:00:24.952050: step 15773, loss = 0.39963 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:00:26.238115 ops/training.py:65 2019-01-17 06:00:26.238024: step 15774, loss = 0.40602 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:00:27.521889 ops/training.py:65 2019-01-17 06:00:27.521809: step 15775, loss = 0.39231 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:00:28.810406 ops/training.py:65 2019-01-17 06:00:28.810251: step 15776, loss = 0.36750 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:00:30.103049 ops/training.py:65 2019-01-17 06:00:30.102982: step 15777, loss = 0.44405 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:00:31.387816 ops/training.py:65 2019-01-17 06:00:31.387736: step 15778, loss = 0.43463 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:00:32.676020 ops/training.py:65 2019-01-17 06:00:32.675945: step 15779, loss = 0.40041 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:00:33.963171 ops/training.py:65 2019-01-17 06:00:33.963110: step 15780, loss = 0.39282 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:00:35.252201 ops/training.py:65 2019-01-17 06:00:35.252099: step 15781, loss = 0.38045 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:00:36.541914 ops/training.py:65 2019-01-17 06:00:36.541845: step 15782, loss = 0.47935 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:00:37.825103 ops/training.py:65 2019-01-17 06:00:37.825035: step 15783, loss = 0.39034 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:00:39.111856 ops/training.py:65 2019-01-17 06:00:39.111783: step 15784, loss = 0.33318 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:00:40.401006 ops/training.py:65 2019-01-17 06:00:40.400920: step 15785, loss = 0.54375 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:00:41.696584 ops/training.py:65 2019-01-17 06:00:41.696490: step 15786, loss = 0.40069 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:00:42.986549 ops/training.py:65 2019-01-17 06:00:42.986460: step 15787, loss = 0.48247 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 06:00:44.273909 ops/training.py:65 2019-01-17 06:00:44.273831: step 15788, loss = 0.60710 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.5625
I4672 2019-01-17 06:00:45.562502 ops/training.py:65 2019-01-17 06:00:45.562436: step 15789, loss = 0.44577 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:00:46.842724 ops/training.py:65 2019-01-17 06:00:46.842661: step 15790, loss = 0.35328 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:00:48.135044 ops/training.py:65 2019-01-17 06:00:48.134905: step 15791, loss = 0.37225 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:00:49.422661 ops/training.py:65 2019-01-17 06:00:49.422589: step 15792, loss = 0.39622 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:00:50.710888 ops/training.py:65 2019-01-17 06:00:50.710822: step 15793, loss = 0.42531 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:00:51.999359 ops/training.py:65 2019-01-17 06:00:51.999292: step 15794, loss = 0.36448 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:00:53.283838 ops/training.py:65 2019-01-17 06:00:53.283775: step 15795, loss = 0.36726 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:00:54.572351 ops/training.py:65 2019-01-17 06:00:54.572289: step 15796, loss = 0.41198 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:00:55.854729 ops/training.py:65 2019-01-17 06:00:55.854621: step 15797, loss = 0.36319 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:00:57.146488 ops/training.py:65 2019-01-17 06:00:57.146383: step 15798, loss = 0.40354 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:00:58.436633 ops/training.py:65 2019-01-17 06:00:58.436543: step 15799, loss = 0.42447 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:00:59.725988 ops/training.py:65 2019-01-17 06:00:59.725915: step 15800, loss = 0.39346 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:01:01.016086 ops/training.py:65 2019-01-17 06:01:01.016026: step 15801, loss = 0.37640 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:01:02.305578 ops/training.py:65 2019-01-17 06:01:02.305507: step 15802, loss = 0.32579 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:01:03.594835 ops/training.py:65 2019-01-17 06:01:03.594769: step 15803, loss = 0.33910 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:01:04.885292 ops/training.py:65 2019-01-17 06:01:04.885218: step 15804, loss = 0.45316 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 06:01:06.174714 ops/training.py:65 2019-01-17 06:01:06.174641: step 15805, loss = 0.36945 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:01:07.456890 ops/training.py:65 2019-01-17 06:01:07.456822: step 15806, loss = 0.48113 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:01:08.747979 ops/training.py:65 2019-01-17 06:01:08.747876: step 15807, loss = 0.36872 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:01:10.038135 ops/training.py:65 2019-01-17 06:01:10.038065: step 15808, loss = 0.35811 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:01:11.325801 ops/training.py:65 2019-01-17 06:01:11.325717: step 15809, loss = 0.37624 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:01:12.616351 ops/training.py:65 2019-01-17 06:01:12.616265: step 15810, loss = 0.43862 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:01:13.904858 ops/training.py:65 2019-01-17 06:01:13.904792: step 15811, loss = 0.38291 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:01:15.194801 ops/training.py:65 2019-01-17 06:01:15.194733: step 15812, loss = 0.44474 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:01:16.483678 ops/training.py:65 2019-01-17 06:01:16.483607: step 15813, loss = 0.43253 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:01:17.767887 ops/training.py:65 2019-01-17 06:01:17.767820: step 15814, loss = 0.35323 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:01:19.047568 ops/training.py:65 2019-01-17 06:01:19.047493: step 15815, loss = 0.37706 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:01:20.335802 ops/training.py:65 2019-01-17 06:01:20.335705: step 15816, loss = 0.47647 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:01:21.627321 ops/training.py:65 2019-01-17 06:01:21.627254: step 15817, loss = 0.38501 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:01:22.911560 ops/training.py:65 2019-01-17 06:01:22.911494: step 15818, loss = 0.48354 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:01:24.199305 ops/training.py:65 2019-01-17 06:01:24.199213: step 15819, loss = 0.48273 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 06:01:25.487057 ops/training.py:65 2019-01-17 06:01:25.486985: step 15820, loss = 0.44465 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 06:01:26.775959 ops/training.py:65 2019-01-17 06:01:26.775883: step 15821, loss = 0.35777 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:01:28.065311 ops/training.py:65 2019-01-17 06:01:28.065251: step 15822, loss = 0.40831 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:01:29.354439 ops/training.py:65 2019-01-17 06:01:29.354349: step 15823, loss = 0.40404 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:01:30.642871 ops/training.py:65 2019-01-17 06:01:30.642790: step 15824, loss = 0.42385 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:01:31.932686 ops/training.py:65 2019-01-17 06:01:31.932611: step 15825, loss = 0.48706 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:01:33.221364 ops/training.py:65 2019-01-17 06:01:33.221291: step 15826, loss = 0.41696 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:01:34.509774 ops/training.py:65 2019-01-17 06:01:34.509705: step 15827, loss = 0.39265 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:01:35.798697 ops/training.py:65 2019-01-17 06:01:35.798628: step 15828, loss = 0.57065 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:01:37.088417 ops/training.py:65 2019-01-17 06:01:37.088344: step 15829, loss = 0.43419 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:01:38.378176 ops/training.py:65 2019-01-17 06:01:38.378108: step 15830, loss = 0.38900 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:01:39.667190 ops/training.py:65 2019-01-17 06:01:39.667114: step 15831, loss = 0.39750 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:01:40.955203 ops/training.py:65 2019-01-17 06:01:40.955135: step 15832, loss = 0.45184 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:01:42.243272 ops/training.py:65 2019-01-17 06:01:42.243204: step 15833, loss = 0.40557 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:01:43.532501 ops/training.py:65 2019-01-17 06:01:43.532430: step 15834, loss = 0.44761 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:01:44.821552 ops/training.py:65 2019-01-17 06:01:44.821467: step 15835, loss = 0.45098 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 06:01:46.106163 ops/training.py:65 2019-01-17 06:01:46.106097: step 15836, loss = 0.36581 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:01:47.390022 ops/training.py:65 2019-01-17 06:01:47.389946: step 15837, loss = 0.44411 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:01:48.677468 ops/training.py:65 2019-01-17 06:01:48.677353: step 15838, loss = 0.53173 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:01:49.961140 ops/training.py:65 2019-01-17 06:01:49.961034: step 15839, loss = 0.33698 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:01:51.253871 ops/training.py:65 2019-01-17 06:01:51.253714: step 15840, loss = 0.44663 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:01:52.540037 ops/training.py:65 2019-01-17 06:01:52.539976: step 15841, loss = 0.35067 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:01:53.824200 ops/training.py:65 2019-01-17 06:01:53.824110: step 15842, loss = 0.38718 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:01:55.109606 ops/training.py:65 2019-01-17 06:01:55.109493: step 15843, loss = 0.44561 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:01:56.394415 ops/training.py:65 2019-01-17 06:01:56.394308: step 15844, loss = 0.45510 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:01:57.686291 ops/training.py:65 2019-01-17 06:01:57.686138: step 15845, loss = 0.42844 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:01:58.978405 ops/training.py:65 2019-01-17 06:01:58.978311: step 15846, loss = 0.49655 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 06:02:00.268110 ops/training.py:65 2019-01-17 06:02:00.268041: step 15847, loss = 0.40269 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:02:01.556990 ops/training.py:65 2019-01-17 06:02:01.556895: step 15848, loss = 0.42365 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:02:02.846257 ops/training.py:65 2019-01-17 06:02:02.846185: step 15849, loss = 0.42083 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:02:04.135553 ops/training.py:65 2019-01-17 06:02:04.135489: step 15850, loss = 0.44408 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:02:05.423741 ops/training.py:65 2019-01-17 06:02:05.423643: step 15851, loss = 0.36158 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:02:06.713812 ops/training.py:65 2019-01-17 06:02:06.713743: step 15852, loss = 0.31747 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:02:07.998008 ops/training.py:65 2019-01-17 06:02:07.997944: step 15853, loss = 0.42018 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:02:09.285317 ops/training.py:65 2019-01-17 06:02:09.285256: step 15854, loss = 0.45412 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:02:10.575351 ops/training.py:65 2019-01-17 06:02:10.575190: step 15855, loss = 0.40609 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:02:11.860813 ops/training.py:65 2019-01-17 06:02:11.860747: step 15856, loss = 0.34328 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:02:13.147907 ops/training.py:65 2019-01-17 06:02:13.147834: step 15857, loss = 0.39405 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:02:14.437537 ops/training.py:65 2019-01-17 06:02:14.437469: step 15858, loss = 0.36922 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:02:15.726727 ops/training.py:65 2019-01-17 06:02:15.726638: step 15859, loss = 0.47967 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:02:17.016114 ops/training.py:65 2019-01-17 06:02:17.016040: step 15860, loss = 0.44406 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:02:18.304404 ops/training.py:65 2019-01-17 06:02:18.304313: step 15861, loss = 0.47623 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:02:19.593570 ops/training.py:65 2019-01-17 06:02:19.593472: step 15862, loss = 0.43311 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:02:20.882516 ops/training.py:65 2019-01-17 06:02:20.882429: step 15863, loss = 0.40392 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:02:22.172782 ops/training.py:65 2019-01-17 06:02:22.172699: step 15864, loss = 0.43580 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:02:23.457103 ops/training.py:65 2019-01-17 06:02:23.457028: step 15865, loss = 0.38644 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:02:24.749026 ops/training.py:65 2019-01-17 06:02:24.748871: step 15866, loss = 0.41454 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:02:26.040369 ops/training.py:65 2019-01-17 06:02:26.040303: step 15867, loss = 0.51865 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 06:02:27.330103 ops/training.py:65 2019-01-17 06:02:27.330031: step 15868, loss = 0.37171 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:02:28.624786 ops/training.py:65 2019-01-17 06:02:28.624719: step 15869, loss = 0.36205 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:02:29.909205 ops/training.py:65 2019-01-17 06:02:29.909134: step 15870, loss = 0.43521 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:02:31.192827 ops/training.py:65 2019-01-17 06:02:31.192760: step 15871, loss = 0.38570 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:02:32.484406 ops/training.py:65 2019-01-17 06:02:32.484307: step 15872, loss = 0.44389 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:02:33.775319 ops/training.py:65 2019-01-17 06:02:33.775256: step 15873, loss = 0.40487 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:02:35.065633 ops/training.py:65 2019-01-17 06:02:35.065565: step 15874, loss = 0.38629 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:02:36.354189 ops/training.py:65 2019-01-17 06:02:36.354118: step 15875, loss = 0.44323 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:02:37.643325 ops/training.py:65 2019-01-17 06:02:37.643249: step 15876, loss = 0.51770 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 06:02:38.927736 ops/training.py:65 2019-01-17 06:02:38.927675: step 15877, loss = 0.37888 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:02:40.215044 ops/training.py:65 2019-01-17 06:02:40.214975: step 15878, loss = 0.39615 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:02:41.504412 ops/training.py:65 2019-01-17 06:02:41.504326: step 15879, loss = 0.46902 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:02:42.793201 ops/training.py:65 2019-01-17 06:02:42.793125: step 15880, loss = 0.45159 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:02:44.081157 ops/training.py:65 2019-01-17 06:02:44.081066: step 15881, loss = 0.41718 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:02:45.369903 ops/training.py:65 2019-01-17 06:02:45.369818: step 15882, loss = 0.47245 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:02:46.659604 ops/training.py:65 2019-01-17 06:02:46.659527: step 15883, loss = 0.40294 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:02:47.947149 ops/training.py:65 2019-01-17 06:02:47.947076: step 15884, loss = 0.34733 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:02:49.235028 ops/training.py:65 2019-01-17 06:02:49.234933: step 15885, loss = 0.41122 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:02:50.524795 ops/training.py:65 2019-01-17 06:02:50.524704: step 15886, loss = 0.38972 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:02:51.813348 ops/training.py:65 2019-01-17 06:02:51.813279: step 15887, loss = 0.35335 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:02:53.100930 ops/training.py:65 2019-01-17 06:02:53.100866: step 15888, loss = 0.45679 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:02:54.389465 ops/training.py:65 2019-01-17 06:02:54.389405: step 15889, loss = 0.40554 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:02:55.673954 ops/training.py:65 2019-01-17 06:02:55.673894: step 15890, loss = 0.39892 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:02:56.957527 ops/training.py:65 2019-01-17 06:02:56.957457: step 15891, loss = 0.44811 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:02:58.240798 ops/training.py:65 2019-01-17 06:02:58.240683: step 15892, loss = 0.43332 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:02:59.532394 ops/training.py:65 2019-01-17 06:02:59.532299: step 15893, loss = 0.44667 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:03:00.818966 ops/training.py:65 2019-01-17 06:03:00.818898: step 15894, loss = 0.33240 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:03:02.103075 ops/training.py:65 2019-01-17 06:03:02.103002: step 15895, loss = 0.46238 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:03:03.385397 ops/training.py:65 2019-01-17 06:03:03.385299: step 15896, loss = 0.50031 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 06:03:04.677539 ops/training.py:65 2019-01-17 06:03:04.677435: step 15897, loss = 0.50438 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 06:03:05.967843 ops/training.py:65 2019-01-17 06:03:05.967768: step 15898, loss = 0.37401 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:03:07.256039 ops/training.py:65 2019-01-17 06:03:07.255963: step 15899, loss = 0.41023 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:03:08.545498 ops/training.py:65 2019-01-17 06:03:08.545426: step 15900, loss = 0.39789 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:03:09.834390 ops/training.py:65 2019-01-17 06:03:09.834303: step 15901, loss = 0.39162 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:03:11.123082 ops/training.py:65 2019-01-17 06:03:11.123016: step 15902, loss = 0.35280 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:03:12.410069 ops/training.py:65 2019-01-17 06:03:12.409996: step 15903, loss = 0.44701 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:03:13.699677 ops/training.py:65 2019-01-17 06:03:13.699601: step 15904, loss = 0.43565 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:03:14.983572 ops/training.py:65 2019-01-17 06:03:14.983487: step 15905, loss = 0.37292 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:03:16.271728 ops/training.py:65 2019-01-17 06:03:16.271657: step 15906, loss = 0.43108 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:03:17.557169 ops/training.py:65 2019-01-17 06:03:17.557107: step 15907, loss = 0.43615 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:03:18.845472 ops/training.py:65 2019-01-17 06:03:18.845409: step 15908, loss = 0.37360 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:03:20.133953 ops/training.py:65 2019-01-17 06:03:20.133876: step 15909, loss = 0.32787 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:03:21.419783 ops/training.py:65 2019-01-17 06:03:21.419720: step 15910, loss = 0.37711 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:03:22.703774 ops/training.py:65 2019-01-17 06:03:22.703699: step 15911, loss = 0.45131 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:03:23.986798 ops/training.py:65 2019-01-17 06:03:23.986721: step 15912, loss = 0.30261 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:03:25.279583 ops/training.py:65 2019-01-17 06:03:25.279443: step 15913, loss = 0.34482 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:03:26.570108 ops/training.py:65 2019-01-17 06:03:26.570044: step 15914, loss = 0.57252 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 06:03:27.854808 ops/training.py:65 2019-01-17 06:03:27.854746: step 15915, loss = 0.40351 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:03:29.142865 ops/training.py:65 2019-01-17 06:03:29.142791: step 15916, loss = 0.43559 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:03:30.431972 ops/training.py:65 2019-01-17 06:03:30.431895: step 15917, loss = 0.38320 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:03:31.721015 ops/training.py:65 2019-01-17 06:03:31.720944: step 15918, loss = 0.43624 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:03:33.009145 ops/training.py:65 2019-01-17 06:03:33.009050: step 15919, loss = 0.44189 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:03:34.297428 ops/training.py:65 2019-01-17 06:03:34.297356: step 15920, loss = 0.42647 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:03:35.584885 ops/training.py:65 2019-01-17 06:03:35.584811: step 15921, loss = 0.40061 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:03:36.873717 ops/training.py:65 2019-01-17 06:03:36.873656: step 15922, loss = 0.37962 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:03:38.162387 ops/training.py:65 2019-01-17 06:03:38.162323: step 15923, loss = 0.48767 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:03:39.449700 ops/training.py:65 2019-01-17 06:03:39.449631: step 15924, loss = 0.46387 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 06:03:40.736951 ops/training.py:65 2019-01-17 06:03:40.736875: step 15925, loss = 0.41160 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:03:42.017581 ops/training.py:65 2019-01-17 06:03:42.017516: step 15926, loss = 0.49857 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:03:43.304936 ops/training.py:65 2019-01-17 06:03:43.304835: step 15927, loss = 0.43734 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:03:44.592674 ops/training.py:65 2019-01-17 06:03:44.592605: step 15928, loss = 0.34141 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:03:45.880573 ops/training.py:65 2019-01-17 06:03:45.880500: step 15929, loss = 0.41417 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:03:47.170279 ops/training.py:65 2019-01-17 06:03:47.170209: step 15930, loss = 0.38116 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:03:48.459241 ops/training.py:65 2019-01-17 06:03:48.459169: step 15931, loss = 0.40466 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:03:49.748663 ops/training.py:65 2019-01-17 06:03:49.748590: step 15932, loss = 0.31810 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:03:51.037930 ops/training.py:65 2019-01-17 06:03:51.037850: step 15933, loss = 0.49348 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:03:52.327208 ops/training.py:65 2019-01-17 06:03:52.327144: step 15934, loss = 0.54478 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 06:03:53.616381 ops/training.py:65 2019-01-17 06:03:53.616309: step 15935, loss = 0.34323 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:03:54.905310 ops/training.py:65 2019-01-17 06:03:54.905232: step 15936, loss = 0.29123 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:03:56.193790 ops/training.py:65 2019-01-17 06:03:56.193704: step 15937, loss = 0.39289 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:03:57.480923 ops/training.py:65 2019-01-17 06:03:57.480864: step 15938, loss = 0.37094 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:03:58.769855 ops/training.py:65 2019-01-17 06:03:58.769765: step 15939, loss = 0.35132 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:04:00.059179 ops/training.py:65 2019-01-17 06:04:00.059086: step 15940, loss = 0.44948 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:04:01.348064 ops/training.py:65 2019-01-17 06:04:01.347988: step 15941, loss = 0.40444 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:04:02.637063 ops/training.py:65 2019-01-17 06:04:02.636997: step 15942, loss = 0.39730 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:04:03.927234 ops/training.py:65 2019-01-17 06:04:03.927166: step 15943, loss = 0.38409 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:04:05.215038 ops/training.py:65 2019-01-17 06:04:05.214954: step 15944, loss = 0.39958 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:04:06.505310 ops/training.py:65 2019-01-17 06:04:06.505247: step 15945, loss = 0.39466 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:04:07.793331 ops/training.py:65 2019-01-17 06:04:07.793256: step 15946, loss = 0.43648 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:04:09.077371 ops/training.py:65 2019-01-17 06:04:09.077302: step 15947, loss = 0.45412 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:04:10.365307 ops/training.py:65 2019-01-17 06:04:10.365167: step 15948, loss = 0.36007 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:04:11.649779 ops/training.py:65 2019-01-17 06:04:11.649712: step 15949, loss = 0.38863 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:04:12.935452 ops/training.py:65 2019-01-17 06:04:12.935364: step 15950, loss = 0.50636 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:04:14.218888 ops/training.py:65 2019-01-17 06:04:14.218815: step 15951, loss = 0.39647 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:04:15.510055 ops/training.py:65 2019-01-17 06:04:15.509958: step 15952, loss = 0.39473 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:04:16.793893 ops/training.py:65 2019-01-17 06:04:16.793822: step 15953, loss = 0.36074 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:04:18.081520 ops/training.py:65 2019-01-17 06:04:18.081441: step 15954, loss = 0.40382 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:04:19.370458 ops/training.py:65 2019-01-17 06:04:19.370393: step 15955, loss = 0.49685 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 06:04:20.658558 ops/training.py:65 2019-01-17 06:04:20.658493: step 15956, loss = 0.45129 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:04:21.949114 ops/training.py:65 2019-01-17 06:04:21.949023: step 15957, loss = 0.44551 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:04:23.239185 ops/training.py:65 2019-01-17 06:04:23.239115: step 15958, loss = 0.34529 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:04:24.526934 ops/training.py:65 2019-01-17 06:04:24.526852: step 15959, loss = 0.33491 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:04:25.811826 ops/training.py:65 2019-01-17 06:04:25.811756: step 15960, loss = 0.35451 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:04:27.101426 ops/training.py:65 2019-01-17 06:04:27.101337: step 15961, loss = 0.38599 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:04:28.390298 ops/training.py:65 2019-01-17 06:04:28.390226: step 15962, loss = 0.51947 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 06:04:29.674484 ops/training.py:65 2019-01-17 06:04:29.674425: step 15963, loss = 0.44428 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:04:30.960681 ops/training.py:65 2019-01-17 06:04:30.960573: step 15964, loss = 0.42194 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:04:32.248774 ops/training.py:65 2019-01-17 06:04:32.248658: step 15965, loss = 0.42724 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:04:33.537007 ops/training.py:65 2019-01-17 06:04:33.536910: step 15966, loss = 0.41543 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:04:34.826345 ops/training.py:65 2019-01-17 06:04:34.826233: step 15967, loss = 0.44837 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:04:36.115693 ops/training.py:65 2019-01-17 06:04:36.115629: step 15968, loss = 0.42414 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:04:37.404232 ops/training.py:65 2019-01-17 06:04:37.404159: step 15969, loss = 0.32489 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:04:38.693360 ops/training.py:65 2019-01-17 06:04:38.693300: step 15970, loss = 0.43967 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:04:39.981865 ops/training.py:65 2019-01-17 06:04:39.981792: step 15971, loss = 0.29858 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:04:41.270592 ops/training.py:65 2019-01-17 06:04:41.270517: step 15972, loss = 0.45747 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:04:42.552601 ops/training.py:65 2019-01-17 06:04:42.552525: step 15973, loss = 0.37520 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:04:43.836308 ops/training.py:65 2019-01-17 06:04:43.836215: step 15974, loss = 0.38505 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:04:45.119492 ops/training.py:65 2019-01-17 06:04:45.119386: step 15975, loss = 0.38506 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:04:46.411736 ops/training.py:65 2019-01-17 06:04:46.411581: step 15976, loss = 0.43039 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:04:47.702061 ops/training.py:65 2019-01-17 06:04:47.701976: step 15977, loss = 0.44652 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:04:48.989978 ops/training.py:65 2019-01-17 06:04:48.989846: step 15978, loss = 0.38853 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:04:50.275472 ops/training.py:65 2019-01-17 06:04:50.275368: step 15979, loss = 0.37495 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:04:51.563290 ops/training.py:65 2019-01-17 06:04:51.563250: step 15980, loss = 0.37333 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:04:52.850191 ops/training.py:65 2019-01-17 06:04:52.850102: step 15981, loss = 0.34540 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:04:54.140026 ops/training.py:65 2019-01-17 06:04:54.139948: step 15982, loss = 0.39875 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:04:55.429839 ops/training.py:65 2019-01-17 06:04:55.429766: step 15983, loss = 0.38348 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:04:56.718186 ops/training.py:65 2019-01-17 06:04:56.718118: step 15984, loss = 0.33851 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:04:58.005669 ops/training.py:65 2019-01-17 06:04:58.005597: step 15985, loss = 0.39895 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:04:59.293475 ops/training.py:65 2019-01-17 06:04:59.293405: step 15986, loss = 0.29764 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:05:00.582427 ops/training.py:65 2019-01-17 06:05:00.582352: step 15987, loss = 0.35820 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:05:01.865323 ops/training.py:65 2019-01-17 06:05:01.865256: step 15988, loss = 0.38783 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:05:03.148378 ops/training.py:65 2019-01-17 06:05:03.148313: step 15989, loss = 0.47238 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:05:04.438732 ops/training.py:65 2019-01-17 06:05:04.438636: step 15990, loss = 0.34495 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:05:05.729994 ops/training.py:65 2019-01-17 06:05:05.729919: step 15991, loss = 0.38132 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:05:07.019107 ops/training.py:65 2019-01-17 06:05:07.019020: step 15992, loss = 0.44318 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 06:05:08.307958 ops/training.py:65 2019-01-17 06:05:08.307894: step 15993, loss = 0.39434 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:05:09.596920 ops/training.py:65 2019-01-17 06:05:09.596847: step 15994, loss = 0.34457 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:05:10.885420 ops/training.py:65 2019-01-17 06:05:10.885355: step 15995, loss = 0.39137 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:05:12.173753 ops/training.py:65 2019-01-17 06:05:12.173673: step 15996, loss = 0.37066 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:05:13.462381 ops/training.py:65 2019-01-17 06:05:13.462300: step 15997, loss = 0.42151 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:05:14.751187 ops/training.py:65 2019-01-17 06:05:14.751082: step 15998, loss = 0.44090 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:05:16.038724 ops/training.py:65 2019-01-17 06:05:16.038629: step 15999, loss = 0.39349 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:11:21.564929 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I4672 2019-01-17 06:11:21.565845 ops/training.py:41 2019-01-17 06:11:21.565798: step 16000, loss = 0.36 (0.1 examples/sec; 364.236 sec/batch) | Training accuracy = 0.875 | Validation accuracy = 0.5176 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_23_33_01_706250
I4672 2019-01-17 06:11:22.851757 ops/training.py:65 2019-01-17 06:11:22.851663: step 16001, loss = 0.35198 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:11:24.142278 ops/training.py:65 2019-01-17 06:11:24.142186: step 16002, loss = 0.39005 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:11:25.431250 ops/training.py:65 2019-01-17 06:11:25.431169: step 16003, loss = 0.46704 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:11:26.720428 ops/training.py:65 2019-01-17 06:11:26.720355: step 16004, loss = 0.43344 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:11:28.009665 ops/training.py:65 2019-01-17 06:11:28.009590: step 16005, loss = 0.39854 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:11:29.298137 ops/training.py:65 2019-01-17 06:11:29.298060: step 16006, loss = 0.28941 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:11:30.587612 ops/training.py:65 2019-01-17 06:11:30.587543: step 16007, loss = 0.44223 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:11:31.876906 ops/training.py:65 2019-01-17 06:11:31.876834: step 16008, loss = 0.38662 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:11:33.162988 ops/training.py:65 2019-01-17 06:11:33.162892: step 16009, loss = 0.36882 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:11:34.453011 ops/training.py:65 2019-01-17 06:11:34.452938: step 16010, loss = 0.52480 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 06:11:35.741023 ops/training.py:65 2019-01-17 06:11:35.740955: step 16011, loss = 0.46195 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:11:37.031376 ops/training.py:65 2019-01-17 06:11:37.031316: step 16012, loss = 0.36347 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:11:38.319398 ops/training.py:65 2019-01-17 06:11:38.319320: step 16013, loss = 0.43304 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:11:39.603521 ops/training.py:65 2019-01-17 06:11:39.603455: step 16014, loss = 0.47377 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 06:11:40.887293 ops/training.py:65 2019-01-17 06:11:40.887187: step 16015, loss = 0.33726 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:11:42.173429 ops/training.py:65 2019-01-17 06:11:42.173273: step 16016, loss = 0.39818 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:11:43.468115 ops/training.py:65 2019-01-17 06:11:43.468014: step 16017, loss = 0.41881 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:11:44.758863 ops/training.py:65 2019-01-17 06:11:44.758788: step 16018, loss = 0.36128 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:11:46.047378 ops/training.py:65 2019-01-17 06:11:46.047298: step 16019, loss = 0.40656 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:11:47.335172 ops/training.py:65 2019-01-17 06:11:47.335097: step 16020, loss = 0.42098 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:11:48.624586 ops/training.py:65 2019-01-17 06:11:48.624513: step 16021, loss = 0.40915 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:11:49.912609 ops/training.py:65 2019-01-17 06:11:49.912539: step 16022, loss = 0.30558 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:11:51.202437 ops/training.py:65 2019-01-17 06:11:51.202366: step 16023, loss = 0.38294 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:11:52.490756 ops/training.py:65 2019-01-17 06:11:52.490677: step 16024, loss = 0.32714 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:11:53.779927 ops/training.py:65 2019-01-17 06:11:53.779852: step 16025, loss = 0.48001 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 06:11:55.068180 ops/training.py:65 2019-01-17 06:11:55.068104: step 16026, loss = 0.41125 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:11:56.356910 ops/training.py:65 2019-01-17 06:11:56.356826: step 16027, loss = 0.41018 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:11:57.645425 ops/training.py:65 2019-01-17 06:11:57.645355: step 16028, loss = 0.45529 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:11:58.933329 ops/training.py:65 2019-01-17 06:11:58.933236: step 16029, loss = 0.51658 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:12:00.229314 ops/training.py:65 2019-01-17 06:12:00.229245: step 16030, loss = 0.58469 (24.7 examples/sec; 1.295 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 06:12:01.517135 ops/training.py:65 2019-01-17 06:12:01.517064: step 16031, loss = 0.42547 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:12:02.804613 ops/training.py:65 2019-01-17 06:12:02.804544: step 16032, loss = 0.51998 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 06:12:04.092330 ops/training.py:65 2019-01-17 06:12:04.092255: step 16033, loss = 0.38647 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:12:05.375909 ops/training.py:65 2019-01-17 06:12:05.375853: step 16034, loss = 0.39664 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:12:06.660284 ops/training.py:65 2019-01-17 06:12:06.660213: step 16035, loss = 0.28232 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:12:07.952544 ops/training.py:65 2019-01-17 06:12:07.952437: step 16036, loss = 0.35768 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:12:09.239009 ops/training.py:65 2019-01-17 06:12:09.238948: step 16037, loss = 0.36213 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:12:10.530405 ops/training.py:65 2019-01-17 06:12:10.530305: step 16038, loss = 0.41565 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:12:11.820875 ops/training.py:65 2019-01-17 06:12:11.820805: step 16039, loss = 0.40950 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:12:13.106570 ops/training.py:65 2019-01-17 06:12:13.106482: step 16040, loss = 0.39460 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:12:14.391489 ops/training.py:65 2019-01-17 06:12:14.391429: step 16041, loss = 0.43575 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:12:15.681765 ops/training.py:65 2019-01-17 06:12:15.681668: step 16042, loss = 0.37543 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:12:16.971501 ops/training.py:65 2019-01-17 06:12:16.971433: step 16043, loss = 0.38748 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:12:18.259521 ops/training.py:65 2019-01-17 06:12:18.259422: step 16044, loss = 0.30476 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:12:19.547843 ops/training.py:65 2019-01-17 06:12:19.547761: step 16045, loss = 0.38548 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:12:20.833910 ops/training.py:65 2019-01-17 06:12:20.833837: step 16046, loss = 0.37274 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:12:22.123332 ops/training.py:65 2019-01-17 06:12:22.123229: step 16047, loss = 0.40157 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:12:23.411409 ops/training.py:65 2019-01-17 06:12:23.411330: step 16048, loss = 0.34760 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:12:24.701064 ops/training.py:65 2019-01-17 06:12:24.701004: step 16049, loss = 0.35953 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:12:25.990442 ops/training.py:65 2019-01-17 06:12:25.990378: step 16050, loss = 0.37088 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:12:27.274168 ops/training.py:65 2019-01-17 06:12:27.274104: step 16051, loss = 0.31661 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:12:28.559199 ops/training.py:65 2019-01-17 06:12:28.559096: step 16052, loss = 0.38937 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:12:29.850773 ops/training.py:65 2019-01-17 06:12:29.850630: step 16053, loss = 0.41713 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:12:31.137126 ops/training.py:65 2019-01-17 06:12:31.137061: step 16054, loss = 0.39833 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:12:32.425236 ops/training.py:65 2019-01-17 06:12:32.425176: step 16055, loss = 0.47120 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:12:33.714819 ops/training.py:65 2019-01-17 06:12:33.714733: step 16056, loss = 0.33842 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:12:34.999248 ops/training.py:65 2019-01-17 06:12:34.999187: step 16057, loss = 0.37887 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:12:36.288891 ops/training.py:65 2019-01-17 06:12:36.288792: step 16058, loss = 0.35921 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:12:37.577911 ops/training.py:65 2019-01-17 06:12:37.577848: step 16059, loss = 0.33365 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:12:38.866695 ops/training.py:65 2019-01-17 06:12:38.866627: step 16060, loss = 0.35787 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:12:40.155359 ops/training.py:65 2019-01-17 06:12:40.155287: step 16061, loss = 0.38553 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:12:41.444154 ops/training.py:65 2019-01-17 06:12:41.444083: step 16062, loss = 0.34354 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:12:42.733130 ops/training.py:65 2019-01-17 06:12:42.733066: step 16063, loss = 0.49483 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:12:44.020937 ops/training.py:65 2019-01-17 06:12:44.020864: step 16064, loss = 0.32552 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:12:45.308529 ops/training.py:65 2019-01-17 06:12:45.308455: step 16065, loss = 0.40011 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:12:46.599225 ops/training.py:65 2019-01-17 06:12:46.599158: step 16066, loss = 0.33727 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:12:47.888625 ops/training.py:65 2019-01-17 06:12:47.888561: step 16067, loss = 0.29285 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:12:49.174412 ops/training.py:65 2019-01-17 06:12:49.174347: step 16068, loss = 0.38753 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:12:50.459255 ops/training.py:65 2019-01-17 06:12:50.459191: step 16069, loss = 0.32081 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:12:51.742748 ops/training.py:65 2019-01-17 06:12:51.742642: step 16070, loss = 0.42484 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:12:53.032244 ops/training.py:65 2019-01-17 06:12:53.032131: step 16071, loss = 0.37657 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:12:54.323244 ops/training.py:65 2019-01-17 06:12:54.323143: step 16072, loss = 0.36190 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:12:55.613847 ops/training.py:65 2019-01-17 06:12:55.613773: step 16073, loss = 0.41663 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:12:56.903126 ops/training.py:65 2019-01-17 06:12:56.903068: step 16074, loss = 0.38467 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:12:58.192326 ops/training.py:65 2019-01-17 06:12:58.192253: step 16075, loss = 0.45134 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:12:59.480644 ops/training.py:65 2019-01-17 06:12:59.480578: step 16076, loss = 0.41365 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:13:00.764099 ops/training.py:65 2019-01-17 06:13:00.764035: step 16077, loss = 0.41404 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:13:02.051181 ops/training.py:65 2019-01-17 06:13:02.051076: step 16078, loss = 0.35344 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:13:03.340885 ops/training.py:65 2019-01-17 06:13:03.340813: step 16079, loss = 0.39721 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:13:04.628227 ops/training.py:65 2019-01-17 06:13:04.628160: step 16080, loss = 0.36993 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:13:05.918198 ops/training.py:65 2019-01-17 06:13:05.918129: step 16081, loss = 0.36515 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:13:07.207313 ops/training.py:65 2019-01-17 06:13:07.207245: step 16082, loss = 0.36703 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:13:08.495070 ops/training.py:65 2019-01-17 06:13:08.494971: step 16083, loss = 0.40680 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:13:09.780261 ops/training.py:65 2019-01-17 06:13:09.780197: step 16084, loss = 0.41164 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:13:11.063644 ops/training.py:65 2019-01-17 06:13:11.063585: step 16085, loss = 0.38363 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:13:12.355155 ops/training.py:65 2019-01-17 06:13:12.354999: step 16086, loss = 0.43464 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:13:13.646551 ops/training.py:65 2019-01-17 06:13:13.646481: step 16087, loss = 0.45303 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:13:14.931638 ops/training.py:65 2019-01-17 06:13:14.931567: step 16088, loss = 0.43999 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:13:16.220657 ops/training.py:65 2019-01-17 06:13:16.220576: step 16089, loss = 0.39471 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:13:17.509764 ops/training.py:65 2019-01-17 06:13:17.509690: step 16090, loss = 0.42607 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:13:18.793650 ops/training.py:65 2019-01-17 06:13:18.793581: step 16091, loss = 0.43519 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:13:20.082809 ops/training.py:65 2019-01-17 06:13:20.082720: step 16092, loss = 0.43513 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:13:21.368652 ops/training.py:65 2019-01-17 06:13:21.368542: step 16093, loss = 0.38805 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:13:22.652887 ops/training.py:65 2019-01-17 06:13:22.652782: step 16094, loss = 0.42284 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:13:23.945070 ops/training.py:65 2019-01-17 06:13:23.944973: step 16095, loss = 0.36845 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:13:25.236043 ops/training.py:65 2019-01-17 06:13:25.235970: step 16096, loss = 0.40951 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:13:26.525695 ops/training.py:65 2019-01-17 06:13:26.525608: step 16097, loss = 0.38877 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:13:27.815242 ops/training.py:65 2019-01-17 06:13:27.815168: step 16098, loss = 0.47443 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:13:29.103592 ops/training.py:65 2019-01-17 06:13:29.103528: step 16099, loss = 0.41750 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:13:30.387620 ops/training.py:65 2019-01-17 06:13:30.387553: step 16100, loss = 0.46445 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:13:31.676702 ops/training.py:65 2019-01-17 06:13:31.676642: step 16101, loss = 0.34470 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:13:32.965729 ops/training.py:65 2019-01-17 06:13:32.965631: step 16102, loss = 0.31473 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:13:34.255588 ops/training.py:65 2019-01-17 06:13:34.255500: step 16103, loss = 0.34234 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:13:35.545348 ops/training.py:65 2019-01-17 06:13:35.545278: step 16104, loss = 0.40098 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:13:36.834792 ops/training.py:65 2019-01-17 06:13:36.834719: step 16105, loss = 0.37291 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:13:38.123725 ops/training.py:65 2019-01-17 06:13:38.123646: step 16106, loss = 0.38588 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:13:39.410644 ops/training.py:65 2019-01-17 06:13:39.410561: step 16107, loss = 0.43338 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:13:40.700300 ops/training.py:65 2019-01-17 06:13:40.700222: step 16108, loss = 0.39401 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:13:41.989779 ops/training.py:65 2019-01-17 06:13:41.989703: step 16109, loss = 0.42485 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:13:43.277623 ops/training.py:65 2019-01-17 06:13:43.277550: step 16110, loss = 0.39331 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:13:44.566559 ops/training.py:65 2019-01-17 06:13:44.566470: step 16111, loss = 0.36972 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:13:45.856368 ops/training.py:65 2019-01-17 06:13:45.856295: step 16112, loss = 0.46885 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:13:47.146021 ops/training.py:65 2019-01-17 06:13:47.145950: step 16113, loss = 0.43225 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:13:48.435327 ops/training.py:65 2019-01-17 06:13:48.435247: step 16114, loss = 0.49782 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:13:49.723988 ops/training.py:65 2019-01-17 06:13:49.723921: step 16115, loss = 0.40523 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:13:51.013501 ops/training.py:65 2019-01-17 06:13:51.013429: step 16116, loss = 0.37081 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:13:52.303818 ops/training.py:65 2019-01-17 06:13:52.303751: step 16117, loss = 0.29535 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:13:53.592399 ops/training.py:65 2019-01-17 06:13:53.592313: step 16118, loss = 0.46133 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:13:54.880327 ops/training.py:65 2019-01-17 06:13:54.880238: step 16119, loss = 0.34838 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:13:56.169561 ops/training.py:65 2019-01-17 06:13:56.169485: step 16120, loss = 0.39801 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:13:57.459119 ops/training.py:65 2019-01-17 06:13:57.459045: step 16121, loss = 0.48957 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:13:58.748472 ops/training.py:65 2019-01-17 06:13:58.748403: step 16122, loss = 0.42965 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:14:00.036619 ops/training.py:65 2019-01-17 06:14:00.036525: step 16123, loss = 0.42882 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:14:01.324951 ops/training.py:65 2019-01-17 06:14:01.324880: step 16124, loss = 0.34519 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:14:02.614044 ops/training.py:65 2019-01-17 06:14:02.613972: step 16125, loss = 0.41284 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:14:03.902605 ops/training.py:65 2019-01-17 06:14:03.902530: step 16126, loss = 0.30842 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:14:05.192002 ops/training.py:65 2019-01-17 06:14:05.191915: step 16127, loss = 0.42683 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:14:06.479848 ops/training.py:65 2019-01-17 06:14:06.479769: step 16128, loss = 0.35282 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:14:07.769441 ops/training.py:65 2019-01-17 06:14:07.769361: step 16129, loss = 0.37651 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:14:09.054944 ops/training.py:65 2019-01-17 06:14:09.054849: step 16130, loss = 0.45505 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:14:10.345513 ops/training.py:65 2019-01-17 06:14:10.345412: step 16131, loss = 0.32577 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:14:11.634126 ops/training.py:65 2019-01-17 06:14:11.634029: step 16132, loss = 0.31409 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:14:12.922900 ops/training.py:65 2019-01-17 06:14:12.922825: step 16133, loss = 0.39023 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:14:14.210666 ops/training.py:65 2019-01-17 06:14:14.210572: step 16134, loss = 0.37883 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:14:15.500173 ops/training.py:65 2019-01-17 06:14:15.500099: step 16135, loss = 0.36193 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:14:16.789460 ops/training.py:65 2019-01-17 06:14:16.789364: step 16136, loss = 0.48805 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:14:18.077993 ops/training.py:65 2019-01-17 06:14:18.077902: step 16137, loss = 0.32957 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:14:19.366458 ops/training.py:65 2019-01-17 06:14:19.366386: step 16138, loss = 0.43256 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:14:20.655182 ops/training.py:65 2019-01-17 06:14:20.655112: step 16139, loss = 0.40213 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:14:21.943028 ops/training.py:65 2019-01-17 06:14:21.942954: step 16140, loss = 0.35964 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:14:23.236447 ops/training.py:65 2019-01-17 06:14:23.236375: step 16141, loss = 0.33494 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:14:24.525397 ops/training.py:65 2019-01-17 06:14:24.525301: step 16142, loss = 0.42436 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:14:25.814120 ops/training.py:65 2019-01-17 06:14:25.814053: step 16143, loss = 0.33581 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:14:27.103565 ops/training.py:65 2019-01-17 06:14:27.103466: step 16144, loss = 0.36568 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:14:28.391767 ops/training.py:65 2019-01-17 06:14:28.391682: step 16145, loss = 0.36454 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:14:29.681432 ops/training.py:65 2019-01-17 06:14:29.681354: step 16146, loss = 0.39068 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:14:30.969669 ops/training.py:65 2019-01-17 06:14:30.969604: step 16147, loss = 0.27858 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:14:32.256712 ops/training.py:65 2019-01-17 06:14:32.256615: step 16148, loss = 0.36450 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:14:33.546028 ops/training.py:65 2019-01-17 06:14:33.545929: step 16149, loss = 0.42172 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:14:34.836169 ops/training.py:65 2019-01-17 06:14:34.836095: step 16150, loss = 0.39174 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:14:36.123062 ops/training.py:65 2019-01-17 06:14:36.122986: step 16151, loss = 0.37381 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:14:37.410899 ops/training.py:65 2019-01-17 06:14:37.410827: step 16152, loss = 0.44489 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:14:38.699333 ops/training.py:65 2019-01-17 06:14:38.699260: step 16153, loss = 0.41677 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:14:39.987070 ops/training.py:65 2019-01-17 06:14:39.986979: step 16154, loss = 0.44748 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:14:41.276320 ops/training.py:65 2019-01-17 06:14:41.276245: step 16155, loss = 0.45886 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:14:42.564913 ops/training.py:65 2019-01-17 06:14:42.564837: step 16156, loss = 0.29245 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:14:43.852980 ops/training.py:65 2019-01-17 06:14:43.852900: step 16157, loss = 0.30332 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:14:45.140777 ops/training.py:65 2019-01-17 06:14:45.140699: step 16158, loss = 0.48895 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 06:14:46.428488 ops/training.py:65 2019-01-17 06:14:46.428396: step 16159, loss = 0.42821 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:14:47.718301 ops/training.py:65 2019-01-17 06:14:47.718228: step 16160, loss = 0.35804 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:14:49.006057 ops/training.py:65 2019-01-17 06:14:49.005984: step 16161, loss = 0.37669 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:14:50.294298 ops/training.py:65 2019-01-17 06:14:50.294217: step 16162, loss = 0.38995 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:14:51.582079 ops/training.py:65 2019-01-17 06:14:51.582009: step 16163, loss = 0.33157 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:14:52.870992 ops/training.py:65 2019-01-17 06:14:52.870906: step 16164, loss = 0.47283 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:14:54.158147 ops/training.py:65 2019-01-17 06:14:54.158069: step 16165, loss = 0.44643 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:14:55.446848 ops/training.py:65 2019-01-17 06:14:55.446782: step 16166, loss = 0.40908 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:14:56.733546 ops/training.py:65 2019-01-17 06:14:56.733467: step 16167, loss = 0.41276 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:14:58.016567 ops/training.py:65 2019-01-17 06:14:58.016486: step 16168, loss = 0.36006 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:14:59.305173 ops/training.py:65 2019-01-17 06:14:59.305099: step 16169, loss = 0.31150 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:15:00.592554 ops/training.py:65 2019-01-17 06:15:00.592482: step 16170, loss = 0.36156 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:15:01.881257 ops/training.py:65 2019-01-17 06:15:01.881166: step 16171, loss = 0.38912 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:15:03.169734 ops/training.py:65 2019-01-17 06:15:03.169640: step 16172, loss = 0.39978 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:15:04.458120 ops/training.py:65 2019-01-17 06:15:04.458041: step 16173, loss = 0.41731 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:15:05.747535 ops/training.py:65 2019-01-17 06:15:05.747469: step 16174, loss = 0.31200 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:15:07.036037 ops/training.py:65 2019-01-17 06:15:07.035941: step 16175, loss = 0.30146 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:15:08.324670 ops/training.py:65 2019-01-17 06:15:08.324566: step 16176, loss = 0.40561 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:15:09.614399 ops/training.py:65 2019-01-17 06:15:09.614328: step 16177, loss = 0.35485 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:15:10.902893 ops/training.py:65 2019-01-17 06:15:10.902818: step 16178, loss = 0.39142 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:15:12.187456 ops/training.py:65 2019-01-17 06:15:12.187392: step 16179, loss = 0.41191 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:15:13.471000 ops/training.py:65 2019-01-17 06:15:13.470927: step 16180, loss = 0.35255 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:15:14.762579 ops/training.py:65 2019-01-17 06:15:14.762468: step 16181, loss = 0.38699 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:15:16.052493 ops/training.py:65 2019-01-17 06:15:16.052405: step 16182, loss = 0.47639 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:15:17.341473 ops/training.py:65 2019-01-17 06:15:17.341402: step 16183, loss = 0.44924 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:15:18.623675 ops/training.py:65 2019-01-17 06:15:18.623587: step 16184, loss = 0.34148 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:15:19.907768 ops/training.py:65 2019-01-17 06:15:19.907697: step 16185, loss = 0.40972 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:15:21.191727 ops/training.py:65 2019-01-17 06:15:21.191617: step 16186, loss = 0.39919 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:15:22.483020 ops/training.py:65 2019-01-17 06:15:22.482912: step 16187, loss = 0.38380 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:15:23.766782 ops/training.py:65 2019-01-17 06:15:23.766713: step 16188, loss = 0.36018 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:15:25.059098 ops/training.py:65 2019-01-17 06:15:25.058940: step 16189, loss = 0.37534 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:15:26.350339 ops/training.py:65 2019-01-17 06:15:26.350261: step 16190, loss = 0.34269 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:15:27.639807 ops/training.py:65 2019-01-17 06:15:27.639729: step 16191, loss = 0.37024 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:15:28.928291 ops/training.py:65 2019-01-17 06:15:28.928206: step 16192, loss = 0.37313 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:15:30.217206 ops/training.py:65 2019-01-17 06:15:30.217109: step 16193, loss = 0.30006 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:15:31.501339 ops/training.py:65 2019-01-17 06:15:31.501266: step 16194, loss = 0.39583 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:15:32.792051 ops/training.py:65 2019-01-17 06:15:32.791943: step 16195, loss = 0.30277 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:15:34.078982 ops/training.py:65 2019-01-17 06:15:34.078913: step 16196, loss = 0.32974 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:15:35.362528 ops/training.py:65 2019-01-17 06:15:35.362447: step 16197, loss = 0.35561 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:15:36.646403 ops/training.py:65 2019-01-17 06:15:36.646299: step 16198, loss = 0.36451 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:15:37.936144 ops/training.py:65 2019-01-17 06:15:37.936035: step 16199, loss = 0.44905 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:15:39.226710 ops/training.py:65 2019-01-17 06:15:39.226638: step 16200, loss = 0.42282 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:15:40.514534 ops/training.py:65 2019-01-17 06:15:40.514461: step 16201, loss = 0.38629 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:15:41.803850 ops/training.py:65 2019-01-17 06:15:41.803779: step 16202, loss = 0.40648 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:15:43.092402 ops/training.py:65 2019-01-17 06:15:43.092329: step 16203, loss = 0.38676 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:15:44.380583 ops/training.py:65 2019-01-17 06:15:44.380519: step 16204, loss = 0.39777 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:15:45.669584 ops/training.py:65 2019-01-17 06:15:45.669516: step 16205, loss = 0.43686 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:15:46.958401 ops/training.py:65 2019-01-17 06:15:46.958329: step 16206, loss = 0.44036 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:15:48.246012 ops/training.py:65 2019-01-17 06:15:48.245934: step 16207, loss = 0.54549 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 06:15:49.534361 ops/training.py:65 2019-01-17 06:15:49.534291: step 16208, loss = 0.38316 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:15:50.822179 ops/training.py:65 2019-01-17 06:15:50.822108: step 16209, loss = 0.48179 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:15:52.110296 ops/training.py:65 2019-01-17 06:15:52.110230: step 16210, loss = 0.35359 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:15:53.398920 ops/training.py:65 2019-01-17 06:15:53.398842: step 16211, loss = 0.41870 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:15:54.688191 ops/training.py:65 2019-01-17 06:15:54.688123: step 16212, loss = 0.39607 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:15:55.971509 ops/training.py:65 2019-01-17 06:15:55.971438: step 16213, loss = 0.35585 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:15:57.262963 ops/training.py:65 2019-01-17 06:15:57.262852: step 16214, loss = 0.35527 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:15:58.546013 ops/training.py:65 2019-01-17 06:15:58.545944: step 16215, loss = 0.33276 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:15:59.837135 ops/training.py:65 2019-01-17 06:15:59.837025: step 16216, loss = 0.33388 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:16:01.127108 ops/training.py:65 2019-01-17 06:16:01.127035: step 16217, loss = 0.28472 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:16:02.415291 ops/training.py:65 2019-01-17 06:16:02.415222: step 16218, loss = 0.41290 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:16:03.704749 ops/training.py:65 2019-01-17 06:16:03.704677: step 16219, loss = 0.34260 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:16:04.993746 ops/training.py:65 2019-01-17 06:16:04.993647: step 16220, loss = 0.38872 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:16:06.282014 ops/training.py:65 2019-01-17 06:16:06.281918: step 16221, loss = 0.36104 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:16:07.571596 ops/training.py:65 2019-01-17 06:16:07.571507: step 16222, loss = 0.34505 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:16:08.856908 ops/training.py:65 2019-01-17 06:16:08.856834: step 16223, loss = 0.33061 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:16:10.135837 ops/training.py:65 2019-01-17 06:16:10.135757: step 16224, loss = 0.38896 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:16:11.428074 ops/training.py:65 2019-01-17 06:16:11.427964: step 16225, loss = 0.39240 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:16:12.719061 ops/training.py:65 2019-01-17 06:16:12.718992: step 16226, loss = 0.29806 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:16:14.007581 ops/training.py:65 2019-01-17 06:16:14.007517: step 16227, loss = 0.35095 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:16:15.296829 ops/training.py:65 2019-01-17 06:16:15.296759: step 16228, loss = 0.32929 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:16:16.585784 ops/training.py:65 2019-01-17 06:16:16.585718: step 16229, loss = 0.35741 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:16:17.874022 ops/training.py:65 2019-01-17 06:16:17.873950: step 16230, loss = 0.38098 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:16:19.156936 ops/training.py:65 2019-01-17 06:16:19.156871: step 16231, loss = 0.44234 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:16:20.441471 ops/training.py:65 2019-01-17 06:16:20.441405: step 16232, loss = 0.48220 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:16:21.734329 ops/training.py:65 2019-01-17 06:16:21.734229: step 16233, loss = 0.41724 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:16:23.024927 ops/training.py:65 2019-01-17 06:16:23.024855: step 16234, loss = 0.48316 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 06:16:24.309329 ops/training.py:65 2019-01-17 06:16:24.309260: step 16235, loss = 0.31663 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:16:25.600383 ops/training.py:65 2019-01-17 06:16:25.600273: step 16236, loss = 0.49004 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:16:26.886529 ops/training.py:65 2019-01-17 06:16:26.886444: step 16237, loss = 0.43069 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:16:28.170551 ops/training.py:65 2019-01-17 06:16:28.170440: step 16238, loss = 0.42618 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:16:29.457961 ops/training.py:65 2019-01-17 06:16:29.457848: step 16239, loss = 0.41539 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:16:30.748738 ops/training.py:65 2019-01-17 06:16:30.748638: step 16240, loss = 0.36559 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:16:32.037626 ops/training.py:65 2019-01-17 06:16:32.037557: step 16241, loss = 0.38305 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:16:33.325587 ops/training.py:65 2019-01-17 06:16:33.325517: step 16242, loss = 0.32545 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:16:34.613700 ops/training.py:65 2019-01-17 06:16:34.613606: step 16243, loss = 0.34777 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:16:35.902209 ops/training.py:65 2019-01-17 06:16:35.902142: step 16244, loss = 0.35569 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:16:37.191424 ops/training.py:65 2019-01-17 06:16:37.191355: step 16245, loss = 0.47368 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:16:38.475672 ops/training.py:65 2019-01-17 06:16:38.475604: step 16246, loss = 0.42522 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:16:39.759295 ops/training.py:65 2019-01-17 06:16:39.759211: step 16247, loss = 0.35249 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:16:41.049927 ops/training.py:65 2019-01-17 06:16:41.049815: step 16248, loss = 0.38591 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:16:42.339432 ops/training.py:65 2019-01-17 06:16:42.339371: step 16249, loss = 0.35089 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:16:43.628361 ops/training.py:65 2019-01-17 06:16:43.628292: step 16250, loss = 0.51051 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:16:44.917446 ops/training.py:65 2019-01-17 06:16:44.917370: step 16251, loss = 0.36282 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:16:46.207267 ops/training.py:65 2019-01-17 06:16:46.207173: step 16252, loss = 0.36125 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:16:47.496106 ops/training.py:65 2019-01-17 06:16:47.496030: step 16253, loss = 0.32190 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:16:48.780306 ops/training.py:65 2019-01-17 06:16:48.780238: step 16254, loss = 0.31301 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:16:50.063279 ops/training.py:65 2019-01-17 06:16:50.063209: step 16255, loss = 0.41119 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:16:51.354774 ops/training.py:65 2019-01-17 06:16:51.354617: step 16256, loss = 0.38869 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:16:52.645083 ops/training.py:65 2019-01-17 06:16:52.644991: step 16257, loss = 0.40611 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:16:53.932951 ops/training.py:65 2019-01-17 06:16:53.932872: step 16258, loss = 0.40630 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:16:55.217756 ops/training.py:65 2019-01-17 06:16:55.217687: step 16259, loss = 0.44340 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:16:56.501229 ops/training.py:65 2019-01-17 06:16:56.501124: step 16260, loss = 0.39789 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:16:57.793747 ops/training.py:65 2019-01-17 06:16:57.793650: step 16261, loss = 0.36332 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:16:59.085174 ops/training.py:65 2019-01-17 06:16:59.085091: step 16262, loss = 0.28244 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:17:00.374540 ops/training.py:65 2019-01-17 06:17:00.374450: step 16263, loss = 0.40940 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:17:01.663927 ops/training.py:65 2019-01-17 06:17:01.663853: step 16264, loss = 0.36841 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:17:02.948091 ops/training.py:65 2019-01-17 06:17:02.948014: step 16265, loss = 0.32850 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:17:04.243926 ops/training.py:65 2019-01-17 06:17:04.243823: step 16266, loss = 0.41413 (24.7 examples/sec; 1.295 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:17:05.535099 ops/training.py:65 2019-01-17 06:17:05.535000: step 16267, loss = 0.32301 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:17:06.823472 ops/training.py:65 2019-01-17 06:17:06.823405: step 16268, loss = 0.39226 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:17:08.111425 ops/training.py:65 2019-01-17 06:17:08.111349: step 16269, loss = 0.38402 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:17:09.399833 ops/training.py:65 2019-01-17 06:17:09.399764: step 16270, loss = 0.31876 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:17:10.687387 ops/training.py:65 2019-01-17 06:17:10.687311: step 16271, loss = 0.32575 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:17:11.971616 ops/training.py:65 2019-01-17 06:17:11.971546: step 16272, loss = 0.38959 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:17:13.255521 ops/training.py:65 2019-01-17 06:17:13.255418: step 16273, loss = 0.37655 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:17:14.538959 ops/training.py:65 2019-01-17 06:17:14.538795: step 16274, loss = 0.38662 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:17:15.824115 ops/training.py:65 2019-01-17 06:17:15.824015: step 16275, loss = 0.38263 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:17:17.111845 ops/training.py:65 2019-01-17 06:17:17.111732: step 16276, loss = 0.42074 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:17:18.395865 ops/training.py:65 2019-01-17 06:17:18.395757: step 16277, loss = 0.36041 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:17:19.686630 ops/training.py:65 2019-01-17 06:17:19.686522: step 16278, loss = 0.36081 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:17:20.977055 ops/training.py:65 2019-01-17 06:17:20.976975: step 16279, loss = 0.30820 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:17:22.265035 ops/training.py:65 2019-01-17 06:17:22.264955: step 16280, loss = 0.44503 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:17:23.553034 ops/training.py:65 2019-01-17 06:17:23.552960: step 16281, loss = 0.38768 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:17:24.837150 ops/training.py:65 2019-01-17 06:17:24.837079: step 16282, loss = 0.42561 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:17:26.120883 ops/training.py:65 2019-01-17 06:17:26.120727: step 16283, loss = 0.36122 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:17:27.409612 ops/training.py:65 2019-01-17 06:17:27.409503: step 16284, loss = 0.34884 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:17:28.700407 ops/training.py:65 2019-01-17 06:17:28.700307: step 16285, loss = 0.32999 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:17:29.985589 ops/training.py:65 2019-01-17 06:17:29.985518: step 16286, loss = 0.36998 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:17:31.278312 ops/training.py:65 2019-01-17 06:17:31.278210: step 16287, loss = 0.38791 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:17:32.568961 ops/training.py:65 2019-01-17 06:17:32.568895: step 16288, loss = 0.35170 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:17:33.852955 ops/training.py:65 2019-01-17 06:17:33.852884: step 16289, loss = 0.45575 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:17:35.144671 ops/training.py:65 2019-01-17 06:17:35.144567: step 16290, loss = 0.50901 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:17:36.437115 ops/training.py:65 2019-01-17 06:17:36.437045: step 16291, loss = 0.41217 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:17:37.725935 ops/training.py:65 2019-01-17 06:17:37.725872: step 16292, loss = 0.50880 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:17:39.013789 ops/training.py:65 2019-01-17 06:17:39.013713: step 16293, loss = 0.37129 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:17:40.301352 ops/training.py:65 2019-01-17 06:17:40.301261: step 16294, loss = 0.47229 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:17:41.585564 ops/training.py:65 2019-01-17 06:17:41.585484: step 16295, loss = 0.33333 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:17:42.873727 ops/training.py:65 2019-01-17 06:17:42.873634: step 16296, loss = 0.47421 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:17:44.160577 ops/training.py:65 2019-01-17 06:17:44.160534: step 16297, loss = 0.51945 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 06:17:45.448488 ops/training.py:65 2019-01-17 06:17:45.448451: step 16298, loss = 0.37361 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:17:46.733277 ops/training.py:65 2019-01-17 06:17:46.733214: step 16299, loss = 0.39064 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:17:48.021936 ops/training.py:65 2019-01-17 06:17:48.021857: step 16300, loss = 0.36989 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:17:49.309731 ops/training.py:65 2019-01-17 06:17:49.309682: step 16301, loss = 0.41837 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:17:50.596930 ops/training.py:65 2019-01-17 06:17:50.596881: step 16302, loss = 0.40509 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:17:51.884906 ops/training.py:65 2019-01-17 06:17:51.884871: step 16303, loss = 0.29264 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:17:53.165284 ops/training.py:65 2019-01-17 06:17:53.165245: step 16304, loss = 0.32889 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:17:54.448285 ops/training.py:65 2019-01-17 06:17:54.448251: step 16305, loss = 0.40064 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:17:55.739530 ops/training.py:65 2019-01-17 06:17:55.739495: step 16306, loss = 0.45754 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:17:57.030950 ops/training.py:65 2019-01-17 06:17:57.030921: step 16307, loss = 0.32882 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:17:58.321139 ops/training.py:65 2019-01-17 06:17:58.321101: step 16308, loss = 0.30400 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:17:59.607058 ops/training.py:65 2019-01-17 06:17:59.607004: step 16309, loss = 0.35034 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:18:00.896225 ops/training.py:65 2019-01-17 06:18:00.896147: step 16310, loss = 0.53700 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 06:18:02.188211 ops/training.py:65 2019-01-17 06:18:02.188105: step 16311, loss = 0.46739 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:18:03.478599 ops/training.py:65 2019-01-17 06:18:03.478516: step 16312, loss = 0.39092 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:18:04.766879 ops/training.py:65 2019-01-17 06:18:04.766809: step 16313, loss = 0.49081 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 06:18:06.050711 ops/training.py:65 2019-01-17 06:18:06.050649: step 16314, loss = 0.43166 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:18:07.333520 ops/training.py:65 2019-01-17 06:18:07.333437: step 16315, loss = 0.29945 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:18:08.625815 ops/training.py:65 2019-01-17 06:18:08.625707: step 16316, loss = 0.35654 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:18:09.916474 ops/training.py:65 2019-01-17 06:18:09.916400: step 16317, loss = 0.39247 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:18:11.199421 ops/training.py:65 2019-01-17 06:18:11.199324: step 16318, loss = 0.42490 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:18:12.489804 ops/training.py:65 2019-01-17 06:18:12.489693: step 16319, loss = 0.38520 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:18:13.780437 ops/training.py:65 2019-01-17 06:18:13.780341: step 16320, loss = 0.44136 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:18:15.065724 ops/training.py:65 2019-01-17 06:18:15.065651: step 16321, loss = 0.41632 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:18:16.349895 ops/training.py:65 2019-01-17 06:18:16.349800: step 16322, loss = 0.50273 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:18:17.639722 ops/training.py:65 2019-01-17 06:18:17.639618: step 16323, loss = 0.44742 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:18:18.930691 ops/training.py:65 2019-01-17 06:18:18.930583: step 16324, loss = 0.29504 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:18:20.218688 ops/training.py:65 2019-01-17 06:18:20.218627: step 16325, loss = 0.33977 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:18:21.507081 ops/training.py:65 2019-01-17 06:18:21.507008: step 16326, loss = 0.39431 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:18:22.795868 ops/training.py:65 2019-01-17 06:18:22.795786: step 16327, loss = 0.42112 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:18:24.079917 ops/training.py:65 2019-01-17 06:18:24.079844: step 16328, loss = 0.37808 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:18:25.363233 ops/training.py:65 2019-01-17 06:18:25.363124: step 16329, loss = 0.40576 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:18:26.655583 ops/training.py:65 2019-01-17 06:18:26.655423: step 16330, loss = 0.30734 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:18:27.949378 ops/training.py:65 2019-01-17 06:18:27.949305: step 16331, loss = 0.36962 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:18:29.240524 ops/training.py:65 2019-01-17 06:18:29.240450: step 16332, loss = 0.39421 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:18:30.525971 ops/training.py:65 2019-01-17 06:18:30.525904: step 16333, loss = 0.40481 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:18:31.810846 ops/training.py:65 2019-01-17 06:18:31.810743: step 16334, loss = 0.40222 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:18:33.094351 ops/training.py:65 2019-01-17 06:18:33.094255: step 16335, loss = 0.36027 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:18:34.387174 ops/training.py:65 2019-01-17 06:18:34.387077: step 16336, loss = 0.37757 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:18:35.676273 ops/training.py:65 2019-01-17 06:18:35.676206: step 16337, loss = 0.38954 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:18:36.965512 ops/training.py:65 2019-01-17 06:18:36.965427: step 16338, loss = 0.38029 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:18:38.253805 ops/training.py:65 2019-01-17 06:18:38.253735: step 16339, loss = 0.35535 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:18:39.543545 ops/training.py:65 2019-01-17 06:18:39.543478: step 16340, loss = 0.48107 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:18:40.831469 ops/training.py:65 2019-01-17 06:18:40.831399: step 16341, loss = 0.28217 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:18:42.115320 ops/training.py:65 2019-01-17 06:18:42.115246: step 16342, loss = 0.31696 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:18:43.398882 ops/training.py:65 2019-01-17 06:18:43.398811: step 16343, loss = 0.44006 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:18:44.691681 ops/training.py:65 2019-01-17 06:18:44.691525: step 16344, loss = 0.39155 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:18:45.978352 ops/training.py:65 2019-01-17 06:18:45.978285: step 16345, loss = 0.37698 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:18:47.264335 ops/training.py:65 2019-01-17 06:18:47.264235: step 16346, loss = 0.42424 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:18:48.547046 ops/training.py:65 2019-01-17 06:18:48.546939: step 16347, loss = 0.49119 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:18:49.833080 ops/training.py:65 2019-01-17 06:18:49.832971: step 16348, loss = 0.43917 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:18:51.118617 ops/training.py:65 2019-01-17 06:18:51.118511: step 16349, loss = 0.49591 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 06:18:52.408844 ops/training.py:65 2019-01-17 06:18:52.408767: step 16350, loss = 0.35600 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:18:53.698317 ops/training.py:65 2019-01-17 06:18:53.698235: step 16351, loss = 0.42833 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:18:54.982768 ops/training.py:65 2019-01-17 06:18:54.982681: step 16352, loss = 0.50390 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:18:56.270484 ops/training.py:65 2019-01-17 06:18:56.270327: step 16353, loss = 0.48458 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:18:57.557104 ops/training.py:65 2019-01-17 06:18:57.556995: step 16354, loss = 0.42747 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:18:58.847826 ops/training.py:65 2019-01-17 06:18:58.847721: step 16355, loss = 0.57432 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.65625
I4672 2019-01-17 06:19:00.137564 ops/training.py:65 2019-01-17 06:19:00.137495: step 16356, loss = 0.45568 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:19:01.419928 ops/training.py:65 2019-01-17 06:19:01.419853: step 16357, loss = 0.40805 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:19:02.704685 ops/training.py:65 2019-01-17 06:19:02.704528: step 16358, loss = 0.35528 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:19:03.990487 ops/training.py:65 2019-01-17 06:19:03.990388: step 16359, loss = 0.36171 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:19:05.276368 ops/training.py:65 2019-01-17 06:19:05.276260: step 16360, loss = 0.35651 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:19:06.559026 ops/training.py:65 2019-01-17 06:19:06.558873: step 16361, loss = 0.44696 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:19:07.845765 ops/training.py:65 2019-01-17 06:19:07.845657: step 16362, loss = 0.39877 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:19:09.132625 ops/training.py:65 2019-01-17 06:19:09.132511: step 16363, loss = 0.39581 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:19:10.418723 ops/training.py:65 2019-01-17 06:19:10.418612: step 16364, loss = 0.39863 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:19:11.710314 ops/training.py:65 2019-01-17 06:19:11.710212: step 16365, loss = 0.37040 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:19:12.995545 ops/training.py:65 2019-01-17 06:19:12.995479: step 16366, loss = 0.51246 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:19:14.284847 ops/training.py:65 2019-01-17 06:19:14.284742: step 16367, loss = 0.40800 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:19:15.568914 ops/training.py:65 2019-01-17 06:19:15.568842: step 16368, loss = 0.39679 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:19:16.861220 ops/training.py:65 2019-01-17 06:19:16.861123: step 16369, loss = 0.41372 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:19:18.146671 ops/training.py:65 2019-01-17 06:19:18.146607: step 16370, loss = 0.31500 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:19:19.436210 ops/training.py:65 2019-01-17 06:19:19.436098: step 16371, loss = 0.37250 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:19:20.720316 ops/training.py:65 2019-01-17 06:19:20.720239: step 16372, loss = 0.36925 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:19:22.011620 ops/training.py:65 2019-01-17 06:19:22.011510: step 16373, loss = 0.43042 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:19:23.301500 ops/training.py:65 2019-01-17 06:19:23.301425: step 16374, loss = 0.37817 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:19:24.586400 ops/training.py:65 2019-01-17 06:19:24.586331: step 16375, loss = 0.38190 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:19:25.870777 ops/training.py:65 2019-01-17 06:19:25.870698: step 16376, loss = 0.42435 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:19:27.164359 ops/training.py:65 2019-01-17 06:19:27.164259: step 16377, loss = 0.45833 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:19:28.450519 ops/training.py:65 2019-01-17 06:19:28.450459: step 16378, loss = 0.36422 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:19:29.739091 ops/training.py:65 2019-01-17 06:19:29.738992: step 16379, loss = 0.40016 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:19:31.024475 ops/training.py:65 2019-01-17 06:19:31.024380: step 16380, loss = 0.42798 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:19:32.317501 ops/training.py:65 2019-01-17 06:19:32.317392: step 16381, loss = 0.49121 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:19:33.608804 ops/training.py:65 2019-01-17 06:19:33.608699: step 16382, loss = 0.38251 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:19:34.900639 ops/training.py:65 2019-01-17 06:19:34.900545: step 16383, loss = 0.42427 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:19:36.189599 ops/training.py:65 2019-01-17 06:19:36.189501: step 16384, loss = 0.39340 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:19:37.478861 ops/training.py:65 2019-01-17 06:19:37.478795: step 16385, loss = 0.40049 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:19:38.768588 ops/training.py:65 2019-01-17 06:19:38.768518: step 16386, loss = 0.33472 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:19:40.058660 ops/training.py:65 2019-01-17 06:19:40.058594: step 16387, loss = 0.27516 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:19:41.346713 ops/training.py:65 2019-01-17 06:19:41.346649: step 16388, loss = 0.39208 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:19:42.631484 ops/training.py:65 2019-01-17 06:19:42.631420: step 16389, loss = 0.33490 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:19:43.915019 ops/training.py:65 2019-01-17 06:19:43.914953: step 16390, loss = 0.36669 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:19:45.201605 ops/training.py:65 2019-01-17 06:19:45.201497: step 16391, loss = 0.36841 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:19:46.493684 ops/training.py:65 2019-01-17 06:19:46.493583: step 16392, loss = 0.36578 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:19:47.784686 ops/training.py:65 2019-01-17 06:19:47.784619: step 16393, loss = 0.38071 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:19:49.073129 ops/training.py:65 2019-01-17 06:19:49.073064: step 16394, loss = 0.40930 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:19:50.362317 ops/training.py:65 2019-01-17 06:19:50.362223: step 16395, loss = 0.45717 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:19:51.647171 ops/training.py:65 2019-01-17 06:19:51.647108: step 16396, loss = 0.39734 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:19:52.927726 ops/training.py:65 2019-01-17 06:19:52.927618: step 16397, loss = 0.40920 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:19:54.212732 ops/training.py:65 2019-01-17 06:19:54.212630: step 16398, loss = 0.36912 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:19:55.505719 ops/training.py:65 2019-01-17 06:19:55.505614: step 16399, loss = 0.40573 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:19:56.796664 ops/training.py:65 2019-01-17 06:19:56.796601: step 16400, loss = 0.38430 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:19:58.085176 ops/training.py:65 2019-01-17 06:19:58.085109: step 16401, loss = 0.37238 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:19:59.370817 ops/training.py:65 2019-01-17 06:19:59.370748: step 16402, loss = 0.36179 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:20:00.657815 ops/training.py:65 2019-01-17 06:20:00.657710: step 16403, loss = 0.34595 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:20:01.947153 ops/training.py:65 2019-01-17 06:20:01.947074: step 16404, loss = 0.37872 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:20:03.236160 ops/training.py:65 2019-01-17 06:20:03.236091: step 16405, loss = 0.38934 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:20:04.518882 ops/training.py:65 2019-01-17 06:20:04.518814: step 16406, loss = 0.34299 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:20:05.804287 ops/training.py:65 2019-01-17 06:20:05.804180: step 16407, loss = 0.37142 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:20:07.096528 ops/training.py:65 2019-01-17 06:20:07.096371: step 16408, loss = 0.41665 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:20:08.384370 ops/training.py:65 2019-01-17 06:20:08.384291: step 16409, loss = 0.33220 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:20:09.668251 ops/training.py:65 2019-01-17 06:20:09.668174: step 16410, loss = 0.38461 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:20:10.961578 ops/training.py:65 2019-01-17 06:20:10.961480: step 16411, loss = 0.42476 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:20:12.249233 ops/training.py:65 2019-01-17 06:20:12.249166: step 16412, loss = 0.40080 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:20:13.534618 ops/training.py:65 2019-01-17 06:20:13.534537: step 16413, loss = 0.38316 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:20:14.826271 ops/training.py:65 2019-01-17 06:20:14.826117: step 16414, loss = 0.31310 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:20:16.116811 ops/training.py:65 2019-01-17 06:20:16.116738: step 16415, loss = 0.41026 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:20:17.403555 ops/training.py:65 2019-01-17 06:20:17.403466: step 16416, loss = 0.40811 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:20:18.694563 ops/training.py:65 2019-01-17 06:20:18.694457: step 16417, loss = 0.41284 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:20:19.979215 ops/training.py:65 2019-01-17 06:20:19.979151: step 16418, loss = 0.34907 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:20:21.264956 ops/training.py:65 2019-01-17 06:20:21.264851: step 16419, loss = 0.44229 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:20:22.555470 ops/training.py:65 2019-01-17 06:20:22.555375: step 16420, loss = 0.46076 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 06:20:23.844087 ops/training.py:65 2019-01-17 06:20:23.844017: step 16421, loss = 0.35542 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:20:25.139396 ops/training.py:65 2019-01-17 06:20:25.139330: step 16422, loss = 0.40803 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:20:26.428156 ops/training.py:65 2019-01-17 06:20:26.428092: step 16423, loss = 0.35337 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:20:27.712361 ops/training.py:65 2019-01-17 06:20:27.712304: step 16424, loss = 0.31665 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:20:28.995496 ops/training.py:65 2019-01-17 06:20:28.995422: step 16425, loss = 0.43248 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:20:30.283559 ops/training.py:65 2019-01-17 06:20:30.283449: step 16426, loss = 0.34752 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:20:31.570995 ops/training.py:65 2019-01-17 06:20:31.570894: step 16427, loss = 0.38674 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:20:32.863071 ops/training.py:65 2019-01-17 06:20:32.862962: step 16428, loss = 0.34252 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:20:34.148686 ops/training.py:65 2019-01-17 06:20:34.148610: step 16429, loss = 0.35381 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:20:35.429898 ops/training.py:65 2019-01-17 06:20:35.429795: step 16430, loss = 0.31220 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:20:36.715731 ops/training.py:65 2019-01-17 06:20:36.715572: step 16431, loss = 0.33892 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:20:38.006989 ops/training.py:65 2019-01-17 06:20:38.006884: step 16432, loss = 0.34653 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:20:39.297264 ops/training.py:65 2019-01-17 06:20:39.297199: step 16433, loss = 0.33470 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:20:40.585628 ops/training.py:65 2019-01-17 06:20:40.585557: step 16434, loss = 0.36497 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:20:41.873916 ops/training.py:65 2019-01-17 06:20:41.873838: step 16435, loss = 0.35922 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:20:43.155239 ops/training.py:65 2019-01-17 06:20:43.155166: step 16436, loss = 0.35172 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:20:44.442637 ops/training.py:65 2019-01-17 06:20:44.442521: step 16437, loss = 0.44162 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:20:45.728148 ops/training.py:65 2019-01-17 06:20:45.728038: step 16438, loss = 0.30791 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:20:47.014039 ops/training.py:65 2019-01-17 06:20:47.013938: step 16439, loss = 0.27868 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:20:48.299403 ops/training.py:65 2019-01-17 06:20:48.299295: step 16440, loss = 0.41142 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:20:49.580043 ops/training.py:65 2019-01-17 06:20:49.579926: step 16441, loss = 0.34338 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:20:50.871581 ops/training.py:65 2019-01-17 06:20:50.871475: step 16442, loss = 0.40743 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:20:52.162562 ops/training.py:65 2019-01-17 06:20:52.162493: step 16443, loss = 0.38558 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:20:53.446597 ops/training.py:65 2019-01-17 06:20:53.446511: step 16444, loss = 0.47599 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:20:54.730979 ops/training.py:65 2019-01-17 06:20:54.730870: step 16445, loss = 0.37177 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:20:56.023083 ops/training.py:65 2019-01-17 06:20:56.022978: step 16446, loss = 0.49014 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:20:57.303813 ops/training.py:65 2019-01-17 06:20:57.303740: step 16447, loss = 0.37800 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:20:58.588665 ops/training.py:65 2019-01-17 06:20:58.588557: step 16448, loss = 0.38994 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:20:59.873586 ops/training.py:65 2019-01-17 06:20:59.873482: step 16449, loss = 0.34294 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:21:01.160256 ops/training.py:65 2019-01-17 06:21:01.160155: step 16450, loss = 0.35102 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:21:02.452351 ops/training.py:65 2019-01-17 06:21:02.452237: step 16451, loss = 0.42774 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:21:03.742912 ops/training.py:65 2019-01-17 06:21:03.742838: step 16452, loss = 0.33179 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:21:05.026441 ops/training.py:65 2019-01-17 06:21:05.026373: step 16453, loss = 0.39925 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:21:06.313867 ops/training.py:65 2019-01-17 06:21:06.313776: step 16454, loss = 0.38165 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:21:07.598658 ops/training.py:65 2019-01-17 06:21:07.598588: step 16455, loss = 0.32724 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:21:08.886539 ops/training.py:65 2019-01-17 06:21:08.886424: step 16456, loss = 0.35032 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:21:10.167826 ops/training.py:65 2019-01-17 06:21:10.167716: step 16457, loss = 0.40527 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:21:11.452303 ops/training.py:65 2019-01-17 06:21:11.452196: step 16458, loss = 0.32314 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:21:12.742374 ops/training.py:65 2019-01-17 06:21:12.742269: step 16459, loss = 0.31039 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:21:14.033326 ops/training.py:65 2019-01-17 06:21:14.033256: step 16460, loss = 0.34560 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:21:15.321978 ops/training.py:65 2019-01-17 06:21:15.321908: step 16461, loss = 0.37634 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:21:16.606550 ops/training.py:65 2019-01-17 06:21:16.606490: step 16462, loss = 0.33917 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:21:17.891175 ops/training.py:65 2019-01-17 06:21:17.891113: step 16463, loss = 0.36987 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:21:19.174373 ops/training.py:65 2019-01-17 06:21:19.174274: step 16464, loss = 0.41867 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:21:20.460268 ops/training.py:65 2019-01-17 06:21:20.460167: step 16465, loss = 0.36711 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:21:21.751697 ops/training.py:65 2019-01-17 06:21:21.751597: step 16466, loss = 0.38511 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:21:23.039956 ops/training.py:65 2019-01-17 06:21:23.039889: step 16467, loss = 0.35311 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:21:24.330080 ops/training.py:65 2019-01-17 06:21:24.329926: step 16468, loss = 0.31911 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:21:25.621758 ops/training.py:65 2019-01-17 06:21:25.621600: step 16469, loss = 0.35788 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:21:26.908833 ops/training.py:65 2019-01-17 06:21:26.908744: step 16470, loss = 0.28033 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:21:28.194181 ops/training.py:65 2019-01-17 06:21:28.194064: step 16471, loss = 0.35715 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:21:29.479011 ops/training.py:65 2019-01-17 06:21:29.478851: step 16472, loss = 0.36768 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:21:30.767077 ops/training.py:65 2019-01-17 06:21:30.766961: step 16473, loss = 0.41522 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:21:32.054457 ops/training.py:65 2019-01-17 06:21:32.054359: step 16474, loss = 0.44142 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:21:33.346532 ops/training.py:65 2019-01-17 06:21:33.346429: step 16475, loss = 0.41373 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:21:34.631868 ops/training.py:65 2019-01-17 06:21:34.631759: step 16476, loss = 0.32598 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:21:35.925547 ops/training.py:65 2019-01-17 06:21:35.925447: step 16477, loss = 0.35162 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:21:37.210604 ops/training.py:65 2019-01-17 06:21:37.210544: step 16478, loss = 0.37067 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:21:38.493133 ops/training.py:65 2019-01-17 06:21:38.493025: step 16479, loss = 0.29834 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:21:39.781011 ops/training.py:65 2019-01-17 06:21:39.780906: step 16480, loss = 0.35781 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:21:41.067634 ops/training.py:65 2019-01-17 06:21:41.067539: step 16481, loss = 0.39850 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:21:42.352177 ops/training.py:65 2019-01-17 06:21:42.352072: step 16482, loss = 0.44475 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:21:43.637281 ops/training.py:65 2019-01-17 06:21:43.637133: step 16483, loss = 0.41194 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:21:44.922568 ops/training.py:65 2019-01-17 06:21:44.922452: step 16484, loss = 0.30726 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:21:46.207978 ops/training.py:65 2019-01-17 06:21:46.207890: step 16485, loss = 0.39844 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:21:47.491145 ops/training.py:65 2019-01-17 06:21:47.491041: step 16486, loss = 0.37140 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:21:48.778491 ops/training.py:65 2019-01-17 06:21:48.778380: step 16487, loss = 0.40805 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:21:50.064563 ops/training.py:65 2019-01-17 06:21:50.064460: step 16488, loss = 0.42634 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:21:51.357165 ops/training.py:65 2019-01-17 06:21:51.357011: step 16489, loss = 0.41359 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:21:52.648832 ops/training.py:65 2019-01-17 06:21:52.648743: step 16490, loss = 0.33470 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:21:53.936635 ops/training.py:65 2019-01-17 06:21:53.936566: step 16491, loss = 0.44426 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:21:55.226788 ops/training.py:65 2019-01-17 06:21:55.226713: step 16492, loss = 0.39525 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:21:56.516311 ops/training.py:65 2019-01-17 06:21:56.516248: step 16493, loss = 0.38519 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:21:57.802210 ops/training.py:65 2019-01-17 06:21:57.802128: step 16494, loss = 0.36629 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:21:59.095168 ops/training.py:65 2019-01-17 06:21:59.095065: step 16495, loss = 0.34965 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:22:00.381346 ops/training.py:65 2019-01-17 06:22:00.381279: step 16496, loss = 0.29785 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:22:01.670340 ops/training.py:65 2019-01-17 06:22:01.670235: step 16497, loss = 0.40841 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:22:02.960641 ops/training.py:65 2019-01-17 06:22:02.960568: step 16498, loss = 0.45164 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:22:04.246308 ops/training.py:65 2019-01-17 06:22:04.246239: step 16499, loss = 0.48007 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:22:05.534561 ops/training.py:65 2019-01-17 06:22:05.534460: step 16500, loss = 0.33330 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:22:06.819330 ops/training.py:65 2019-01-17 06:22:06.819261: step 16501, loss = 0.34447 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:22:08.105379 ops/training.py:65 2019-01-17 06:22:08.105301: step 16502, loss = 0.37488 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:22:09.393015 ops/training.py:65 2019-01-17 06:22:09.392901: step 16503, loss = 0.33183 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:22:10.677156 ops/training.py:65 2019-01-17 06:22:10.677042: step 16504, loss = 0.35352 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:22:11.962562 ops/training.py:65 2019-01-17 06:22:11.962462: step 16505, loss = 0.32454 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:22:13.254343 ops/training.py:65 2019-01-17 06:22:13.254237: step 16506, loss = 0.35620 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:22:14.545939 ops/training.py:65 2019-01-17 06:22:14.545869: step 16507, loss = 0.37146 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:22:15.835950 ops/training.py:65 2019-01-17 06:22:15.835877: step 16508, loss = 0.28256 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:22:17.120636 ops/training.py:65 2019-01-17 06:22:17.120573: step 16509, loss = 0.29135 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:22:18.407410 ops/training.py:65 2019-01-17 06:22:18.407305: step 16510, loss = 0.36461 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:22:19.694493 ops/training.py:65 2019-01-17 06:22:19.694380: step 16511, loss = 0.41917 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:22:20.985905 ops/training.py:65 2019-01-17 06:22:20.985799: step 16512, loss = 0.36374 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:22:22.272740 ops/training.py:65 2019-01-17 06:22:22.272673: step 16513, loss = 0.45815 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:22:23.554021 ops/training.py:65 2019-01-17 06:22:23.553913: step 16514, loss = 0.35745 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:22:24.840398 ops/training.py:65 2019-01-17 06:22:24.840291: step 16515, loss = 0.35547 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:22:26.132771 ops/training.py:65 2019-01-17 06:22:26.132674: step 16516, loss = 0.38312 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:22:27.418310 ops/training.py:65 2019-01-17 06:22:27.418230: step 16517, loss = 0.44089 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:22:28.702508 ops/training.py:65 2019-01-17 06:22:28.702449: step 16518, loss = 0.46935 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:22:29.990405 ops/training.py:65 2019-01-17 06:22:29.990298: step 16519, loss = 0.39817 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:22:31.277107 ops/training.py:65 2019-01-17 06:22:31.277048: step 16520, loss = 0.39719 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:22:32.564464 ops/training.py:65 2019-01-17 06:22:32.564358: step 16521, loss = 0.35126 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:22:33.849734 ops/training.py:65 2019-01-17 06:22:33.849637: step 16522, loss = 0.47201 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:22:35.142131 ops/training.py:65 2019-01-17 06:22:35.142028: step 16523, loss = 0.32830 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:22:36.433019 ops/training.py:65 2019-01-17 06:22:36.432952: step 16524, loss = 0.28637 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:22:37.721972 ops/training.py:65 2019-01-17 06:22:37.721902: step 16525, loss = 0.26677 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:22:39.010781 ops/training.py:65 2019-01-17 06:22:39.010717: step 16526, loss = 0.36835 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:22:40.300291 ops/training.py:65 2019-01-17 06:22:40.300213: step 16527, loss = 0.41039 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:22:41.586145 ops/training.py:65 2019-01-17 06:22:41.586080: step 16528, loss = 0.37418 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:22:42.872134 ops/training.py:65 2019-01-17 06:22:42.872027: step 16529, loss = 0.36860 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:22:44.165426 ops/training.py:65 2019-01-17 06:22:44.165325: step 16530, loss = 0.37976 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:22:45.456143 ops/training.py:65 2019-01-17 06:22:45.456069: step 16531, loss = 0.30218 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:22:46.745706 ops/training.py:65 2019-01-17 06:22:46.745634: step 16532, loss = 0.41236 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:22:48.034986 ops/training.py:65 2019-01-17 06:22:48.034910: step 16533, loss = 0.31915 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:22:49.319082 ops/training.py:65 2019-01-17 06:22:49.319017: step 16534, loss = 0.39892 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:22:50.604317 ops/training.py:65 2019-01-17 06:22:50.604210: step 16535, loss = 0.35721 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:22:51.893691 ops/training.py:65 2019-01-17 06:22:51.893550: step 16536, loss = 0.34673 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:22:53.178974 ops/training.py:65 2019-01-17 06:22:53.178881: step 16537, loss = 0.36892 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:22:54.465061 ops/training.py:65 2019-01-17 06:22:54.464962: step 16538, loss = 0.36927 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:22:55.751359 ops/training.py:65 2019-01-17 06:22:55.751250: step 16539, loss = 0.41014 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:22:57.043878 ops/training.py:65 2019-01-17 06:22:57.043779: step 16540, loss = 0.35079 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:22:58.329996 ops/training.py:65 2019-01-17 06:22:58.329922: step 16541, loss = 0.30448 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:22:59.617208 ops/training.py:65 2019-01-17 06:22:59.617116: step 16542, loss = 0.33169 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:23:00.904737 ops/training.py:65 2019-01-17 06:23:00.904631: step 16543, loss = 0.31732 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:23:02.191385 ops/training.py:65 2019-01-17 06:23:02.191288: step 16544, loss = 0.37075 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:23:03.483130 ops/training.py:65 2019-01-17 06:23:03.483029: step 16545, loss = 0.34971 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:23:04.774650 ops/training.py:65 2019-01-17 06:23:04.774578: step 16546, loss = 0.35817 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:23:06.064009 ops/training.py:65 2019-01-17 06:23:06.063941: step 16547, loss = 0.41264 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:23:07.350112 ops/training.py:65 2019-01-17 06:23:07.350034: step 16548, loss = 0.38670 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:23:08.634131 ops/training.py:65 2019-01-17 06:23:08.634033: step 16549, loss = 0.39080 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:23:09.927396 ops/training.py:65 2019-01-17 06:23:09.927239: step 16550, loss = 0.39225 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:23:11.215010 ops/training.py:65 2019-01-17 06:23:11.214945: step 16551, loss = 0.37422 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:23:12.496702 ops/training.py:65 2019-01-17 06:23:12.496560: step 16552, loss = 0.29541 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:23:13.788658 ops/training.py:65 2019-01-17 06:23:13.788557: step 16553, loss = 0.34736 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:23:15.079224 ops/training.py:65 2019-01-17 06:23:15.079154: step 16554, loss = 0.35921 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:23:16.363510 ops/training.py:65 2019-01-17 06:23:16.363449: step 16555, loss = 0.35883 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:23:17.650002 ops/training.py:65 2019-01-17 06:23:17.649839: step 16556, loss = 0.39161 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:23:18.936035 ops/training.py:65 2019-01-17 06:23:18.935878: step 16557, loss = 0.29790 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:23:20.221984 ops/training.py:65 2019-01-17 06:23:20.221882: step 16558, loss = 0.35120 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:23:21.509691 ops/training.py:65 2019-01-17 06:23:21.509581: step 16559, loss = 0.41624 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:23:22.801665 ops/training.py:65 2019-01-17 06:23:22.801552: step 16560, loss = 0.31948 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:23:24.086933 ops/training.py:65 2019-01-17 06:23:24.086830: step 16561, loss = 0.35923 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:23:25.374946 ops/training.py:65 2019-01-17 06:23:25.374842: step 16562, loss = 0.35305 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:23:26.656827 ops/training.py:65 2019-01-17 06:23:26.656689: step 16563, loss = 0.32412 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:23:27.942362 ops/training.py:65 2019-01-17 06:23:27.942254: step 16564, loss = 0.38269 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:23:29.232017 ops/training.py:65 2019-01-17 06:23:29.231912: step 16565, loss = 0.29657 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:23:30.516756 ops/training.py:65 2019-01-17 06:23:30.516686: step 16566, loss = 0.43690 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:23:31.801896 ops/training.py:65 2019-01-17 06:23:31.801797: step 16567, loss = 0.31418 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:23:33.093748 ops/training.py:65 2019-01-17 06:23:33.093648: step 16568, loss = 0.35835 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:23:34.380574 ops/training.py:65 2019-01-17 06:23:34.380498: step 16569, loss = 0.45538 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:23:35.665161 ops/training.py:65 2019-01-17 06:23:35.665086: step 16570, loss = 0.39762 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:23:36.951718 ops/training.py:65 2019-01-17 06:23:36.951607: step 16571, loss = 0.34688 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:23:38.236593 ops/training.py:65 2019-01-17 06:23:38.236493: step 16572, loss = 0.45416 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:23:39.528940 ops/training.py:65 2019-01-17 06:23:39.528830: step 16573, loss = 0.34844 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:23:40.815697 ops/training.py:65 2019-01-17 06:23:40.815627: step 16574, loss = 0.36464 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:23:42.102207 ops/training.py:65 2019-01-17 06:23:42.102124: step 16575, loss = 0.30214 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:23:43.395607 ops/training.py:65 2019-01-17 06:23:43.395505: step 16576, loss = 0.38678 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:23:44.682926 ops/training.py:65 2019-01-17 06:23:44.682831: step 16577, loss = 0.35045 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:23:45.969237 ops/training.py:65 2019-01-17 06:23:45.969138: step 16578, loss = 0.37500 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:23:47.263333 ops/training.py:65 2019-01-17 06:23:47.263232: step 16579, loss = 0.38749 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:23:48.554790 ops/training.py:65 2019-01-17 06:23:48.554691: step 16580, loss = 0.42641 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:23:49.844092 ops/training.py:65 2019-01-17 06:23:49.844022: step 16581, loss = 0.41976 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:23:51.127642 ops/training.py:65 2019-01-17 06:23:51.127584: step 16582, loss = 0.40125 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:23:52.416510 ops/training.py:65 2019-01-17 06:23:52.416439: step 16583, loss = 0.41825 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:23:53.704916 ops/training.py:65 2019-01-17 06:23:53.704851: step 16584, loss = 0.35628 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:23:54.993130 ops/training.py:65 2019-01-17 06:23:54.993064: step 16585, loss = 0.31804 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:23:56.278066 ops/training.py:65 2019-01-17 06:23:56.277997: step 16586, loss = 0.47779 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 06:23:57.567819 ops/training.py:65 2019-01-17 06:23:57.567746: step 16587, loss = 0.31863 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:23:58.856032 ops/training.py:65 2019-01-17 06:23:58.855969: step 16588, loss = 0.38925 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:24:00.144032 ops/training.py:65 2019-01-17 06:24:00.143969: step 16589, loss = 0.32884 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:24:01.431620 ops/training.py:65 2019-01-17 06:24:01.431551: step 16590, loss = 0.44948 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:24:02.719452 ops/training.py:65 2019-01-17 06:24:02.719384: step 16591, loss = 0.40776 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:24:04.008348 ops/training.py:65 2019-01-17 06:24:04.008276: step 16592, loss = 0.29670 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:24:05.298083 ops/training.py:65 2019-01-17 06:24:05.298002: step 16593, loss = 0.29403 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:24:06.586332 ops/training.py:65 2019-01-17 06:24:06.586265: step 16594, loss = 0.41197 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:24:07.869821 ops/training.py:65 2019-01-17 06:24:07.869751: step 16595, loss = 0.35644 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:24:09.152854 ops/training.py:65 2019-01-17 06:24:09.152762: step 16596, loss = 0.41159 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:24:10.445481 ops/training.py:65 2019-01-17 06:24:10.445378: step 16597, loss = 0.34205 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:24:11.735861 ops/training.py:65 2019-01-17 06:24:11.735790: step 16598, loss = 0.33435 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:24:13.024863 ops/training.py:65 2019-01-17 06:24:13.024796: step 16599, loss = 0.40940 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:24:14.314843 ops/training.py:65 2019-01-17 06:24:14.314772: step 16600, loss = 0.37310 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:24:15.604474 ops/training.py:65 2019-01-17 06:24:15.604397: step 16601, loss = 0.33104 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:24:16.893334 ops/training.py:65 2019-01-17 06:24:16.893262: step 16602, loss = 0.35028 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:24:18.182344 ops/training.py:65 2019-01-17 06:24:18.182268: step 16603, loss = 0.38301 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:24:19.463793 ops/training.py:65 2019-01-17 06:24:19.463702: step 16604, loss = 0.32961 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:24:20.755021 ops/training.py:65 2019-01-17 06:24:20.754908: step 16605, loss = 0.33042 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:24:22.039898 ops/training.py:65 2019-01-17 06:24:22.039828: step 16606, loss = 0.39926 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:24:23.323908 ops/training.py:65 2019-01-17 06:24:23.323817: step 16607, loss = 0.39700 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:24:24.615653 ops/training.py:65 2019-01-17 06:24:24.615496: step 16608, loss = 0.29543 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:24:25.907133 ops/training.py:65 2019-01-17 06:24:25.907067: step 16609, loss = 0.39360 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:24:27.196119 ops/training.py:65 2019-01-17 06:24:27.196044: step 16610, loss = 0.40985 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:24:28.484122 ops/training.py:65 2019-01-17 06:24:28.484054: step 16611, loss = 0.29717 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:24:29.769080 ops/training.py:65 2019-01-17 06:24:29.769014: step 16612, loss = 0.31460 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:24:31.052568 ops/training.py:65 2019-01-17 06:24:31.052470: step 16613, loss = 0.31593 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:24:32.345363 ops/training.py:65 2019-01-17 06:24:32.345254: step 16614, loss = 0.34458 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:24:33.636621 ops/training.py:65 2019-01-17 06:24:33.636542: step 16615, loss = 0.50331 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:24:34.926220 ops/training.py:65 2019-01-17 06:24:34.926147: step 16616, loss = 0.50906 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:24:36.219641 ops/training.py:65 2019-01-17 06:24:36.219574: step 16617, loss = 0.29912 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:24:37.508804 ops/training.py:65 2019-01-17 06:24:37.508728: step 16618, loss = 0.34985 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:24:38.792634 ops/training.py:65 2019-01-17 06:24:38.792567: step 16619, loss = 0.41890 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:24:40.081820 ops/training.py:65 2019-01-17 06:24:40.081710: step 16620, loss = 0.33579 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:24:41.367997 ops/training.py:65 2019-01-17 06:24:41.367898: step 16621, loss = 0.36172 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:24:42.653085 ops/training.py:65 2019-01-17 06:24:42.653018: step 16622, loss = 0.45296 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:24:43.941672 ops/training.py:65 2019-01-17 06:24:43.941579: step 16623, loss = 0.34882 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:24:45.226059 ops/training.py:65 2019-01-17 06:24:45.225986: step 16624, loss = 0.31817 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:24:46.512932 ops/training.py:65 2019-01-17 06:24:46.512862: step 16625, loss = 0.36658 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:24:47.801749 ops/training.py:65 2019-01-17 06:24:47.801680: step 16626, loss = 0.40235 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:24:49.085343 ops/training.py:65 2019-01-17 06:24:49.085271: step 16627, loss = 0.37649 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:24:50.373448 ops/training.py:65 2019-01-17 06:24:50.373383: step 16628, loss = 0.31419 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:24:51.661097 ops/training.py:65 2019-01-17 06:24:51.661026: step 16629, loss = 0.41121 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:24:52.949175 ops/training.py:65 2019-01-17 06:24:52.949098: step 16630, loss = 0.36477 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:24:54.238174 ops/training.py:65 2019-01-17 06:24:54.238104: step 16631, loss = 0.34177 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:24:55.521777 ops/training.py:65 2019-01-17 06:24:55.521679: step 16632, loss = 0.46833 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:24:56.806118 ops/training.py:65 2019-01-17 06:24:56.806043: step 16633, loss = 0.40416 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:24:58.092642 ops/training.py:65 2019-01-17 06:24:58.092536: step 16634, loss = 0.46553 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:24:59.377727 ops/training.py:65 2019-01-17 06:24:59.377618: step 16635, loss = 0.46134 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:25:00.670664 ops/training.py:65 2019-01-17 06:25:00.670553: step 16636, loss = 0.33648 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:25:01.960665 ops/training.py:65 2019-01-17 06:25:01.960578: step 16637, loss = 0.42053 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:25:03.250412 ops/training.py:65 2019-01-17 06:25:03.250325: step 16638, loss = 0.40936 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:25:04.537549 ops/training.py:65 2019-01-17 06:25:04.537471: step 16639, loss = 0.45806 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:25:05.824520 ops/training.py:65 2019-01-17 06:25:05.824416: step 16640, loss = 0.42689 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:25:07.112554 ops/training.py:65 2019-01-17 06:25:07.112450: step 16641, loss = 0.49686 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:25:08.399259 ops/training.py:65 2019-01-17 06:25:08.399153: step 16642, loss = 0.39635 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:25:09.682649 ops/training.py:65 2019-01-17 06:25:09.682544: step 16643, loss = 0.40024 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:25:10.973599 ops/training.py:65 2019-01-17 06:25:10.973498: step 16644, loss = 0.41969 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:25:12.264535 ops/training.py:65 2019-01-17 06:25:12.264465: step 16645, loss = 0.42052 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:25:13.548903 ops/training.py:65 2019-01-17 06:25:13.548832: step 16646, loss = 0.37314 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:25:14.832188 ops/training.py:65 2019-01-17 06:25:14.832119: step 16647, loss = 0.48559 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:25:16.123598 ops/training.py:65 2019-01-17 06:25:16.123459: step 16648, loss = 0.43144 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:25:17.410978 ops/training.py:65 2019-01-17 06:25:17.410913: step 16649, loss = 0.37234 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:25:18.692143 ops/training.py:65 2019-01-17 06:25:18.692037: step 16650, loss = 0.51574 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:25:19.986199 ops/training.py:65 2019-01-17 06:25:19.986061: step 16651, loss = 0.41491 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:25:21.275119 ops/training.py:65 2019-01-17 06:25:21.275051: step 16652, loss = 0.31413 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:25:22.565011 ops/training.py:65 2019-01-17 06:25:22.564934: step 16653, loss = 0.37868 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:25:23.855152 ops/training.py:65 2019-01-17 06:25:23.855058: step 16654, loss = 0.34759 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:25:25.144695 ops/training.py:65 2019-01-17 06:25:25.144619: step 16655, loss = 0.41298 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:25:26.429717 ops/training.py:65 2019-01-17 06:25:26.429647: step 16656, loss = 0.40112 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:25:27.717932 ops/training.py:65 2019-01-17 06:25:27.717820: step 16657, loss = 0.35904 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:25:29.005278 ops/training.py:65 2019-01-17 06:25:29.005201: step 16658, loss = 0.38331 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:25:30.293695 ops/training.py:65 2019-01-17 06:25:30.293622: step 16659, loss = 0.35146 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:25:31.583183 ops/training.py:65 2019-01-17 06:25:31.583110: step 16660, loss = 0.34303 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:25:32.872559 ops/training.py:65 2019-01-17 06:25:32.872479: step 16661, loss = 0.42561 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:25:34.160302 ops/training.py:65 2019-01-17 06:25:34.160223: step 16662, loss = 0.34167 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:25:35.447909 ops/training.py:65 2019-01-17 06:25:35.447816: step 16663, loss = 0.29140 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:25:36.736856 ops/training.py:65 2019-01-17 06:25:36.736782: step 16664, loss = 0.36766 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:25:38.020872 ops/training.py:65 2019-01-17 06:25:38.020792: step 16665, loss = 0.32453 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:25:39.304547 ops/training.py:65 2019-01-17 06:25:39.304440: step 16666, loss = 0.39434 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:25:40.596157 ops/training.py:65 2019-01-17 06:25:40.596047: step 16667, loss = 0.33406 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:25:41.883158 ops/training.py:65 2019-01-17 06:25:41.883086: step 16668, loss = 0.33983 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:25:43.168217 ops/training.py:65 2019-01-17 06:25:43.168131: step 16669, loss = 0.31862 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:25:44.458596 ops/training.py:65 2019-01-17 06:25:44.458486: step 16670, loss = 0.34920 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:25:45.750100 ops/training.py:65 2019-01-17 06:25:45.750017: step 16671, loss = 0.36347 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:25:47.038784 ops/training.py:65 2019-01-17 06:25:47.038692: step 16672, loss = 0.33422 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:25:48.325858 ops/training.py:65 2019-01-17 06:25:48.325767: step 16673, loss = 0.38280 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:25:49.614103 ops/training.py:65 2019-01-17 06:25:49.613999: step 16674, loss = 0.28690 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:25:50.900309 ops/training.py:65 2019-01-17 06:25:50.900237: step 16675, loss = 0.35088 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:25:52.183856 ops/training.py:65 2019-01-17 06:25:52.183790: step 16676, loss = 0.40648 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:25:53.463882 ops/training.py:65 2019-01-17 06:25:53.463778: step 16677, loss = 0.35151 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:25:54.755239 ops/training.py:65 2019-01-17 06:25:54.755135: step 16678, loss = 0.37477 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:25:56.045120 ops/training.py:65 2019-01-17 06:25:56.045035: step 16679, loss = 0.38515 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:25:57.333161 ops/training.py:65 2019-01-17 06:25:57.333090: step 16680, loss = 0.32636 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:25:58.617505 ops/training.py:65 2019-01-17 06:25:58.617429: step 16681, loss = 0.40599 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:25:59.903787 ops/training.py:65 2019-01-17 06:25:59.903701: step 16682, loss = 0.30835 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:26:01.188329 ops/training.py:65 2019-01-17 06:26:01.188241: step 16683, loss = 0.32859 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:26:02.477616 ops/training.py:65 2019-01-17 06:26:02.477546: step 16684, loss = 0.38855 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:26:03.765433 ops/training.py:65 2019-01-17 06:26:03.765359: step 16685, loss = 0.34297 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:26:05.049116 ops/training.py:65 2019-01-17 06:26:05.049046: step 16686, loss = 0.37728 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:26:06.329463 ops/training.py:65 2019-01-17 06:26:06.329359: step 16687, loss = 0.36854 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:26:07.616109 ops/training.py:65 2019-01-17 06:26:07.616000: step 16688, loss = 0.40630 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:26:08.902016 ops/training.py:65 2019-01-17 06:26:08.901903: step 16689, loss = 0.31712 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:26:10.189445 ops/training.py:65 2019-01-17 06:26:10.189333: step 16690, loss = 0.30250 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:26:11.480186 ops/training.py:65 2019-01-17 06:26:11.480082: step 16691, loss = 0.38920 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:26:12.771676 ops/training.py:65 2019-01-17 06:26:12.771582: step 16692, loss = 0.47319 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:26:14.061844 ops/training.py:65 2019-01-17 06:26:14.061751: step 16693, loss = 0.30870 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:26:15.352789 ops/training.py:65 2019-01-17 06:26:15.352714: step 16694, loss = 0.41536 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:26:16.642060 ops/training.py:65 2019-01-17 06:26:16.641990: step 16695, loss = 0.32036 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:26:17.931000 ops/training.py:65 2019-01-17 06:26:17.930909: step 16696, loss = 0.30747 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:26:19.221408 ops/training.py:65 2019-01-17 06:26:19.221338: step 16697, loss = 0.34902 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:26:20.510405 ops/training.py:65 2019-01-17 06:26:20.510326: step 16698, loss = 0.35240 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:26:21.799277 ops/training.py:65 2019-01-17 06:26:21.799203: step 16699, loss = 0.47380 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:26:23.088298 ops/training.py:65 2019-01-17 06:26:23.088224: step 16700, loss = 0.28384 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:26:24.376598 ops/training.py:65 2019-01-17 06:26:24.376499: step 16701, loss = 0.36273 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:26:25.666521 ops/training.py:65 2019-01-17 06:26:25.666453: step 16702, loss = 0.35729 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:26:26.954719 ops/training.py:65 2019-01-17 06:26:26.954622: step 16703, loss = 0.33577 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:26:28.245554 ops/training.py:65 2019-01-17 06:26:28.245457: step 16704, loss = 0.27575 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:26:29.534756 ops/training.py:65 2019-01-17 06:26:29.534671: step 16705, loss = 0.40006 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:26:30.823396 ops/training.py:65 2019-01-17 06:26:30.823325: step 16706, loss = 0.35816 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:26:32.112568 ops/training.py:65 2019-01-17 06:26:32.112501: step 16707, loss = 0.34159 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:26:33.400824 ops/training.py:65 2019-01-17 06:26:33.400735: step 16708, loss = 0.30992 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:26:34.684689 ops/training.py:65 2019-01-17 06:26:34.684619: step 16709, loss = 0.33044 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:26:35.974266 ops/training.py:65 2019-01-17 06:26:35.974117: step 16710, loss = 0.35549 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:26:37.263967 ops/training.py:65 2019-01-17 06:26:37.263893: step 16711, loss = 0.37606 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:26:38.552338 ops/training.py:65 2019-01-17 06:26:38.552262: step 16712, loss = 0.39423 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:26:39.839609 ops/training.py:65 2019-01-17 06:26:39.839526: step 16713, loss = 0.33812 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:26:41.127520 ops/training.py:65 2019-01-17 06:26:41.127453: step 16714, loss = 0.40218 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:26:42.411697 ops/training.py:65 2019-01-17 06:26:42.411632: step 16715, loss = 0.34997 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:26:43.701229 ops/training.py:65 2019-01-17 06:26:43.701130: step 16716, loss = 0.34161 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:26:44.997110 ops/training.py:65 2019-01-17 06:26:44.997007: step 16717, loss = 0.40445 (24.7 examples/sec; 1.295 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:26:46.285633 ops/training.py:65 2019-01-17 06:26:46.285567: step 16718, loss = 0.37608 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:26:47.573015 ops/training.py:65 2019-01-17 06:26:47.572927: step 16719, loss = 0.36017 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:26:48.862492 ops/training.py:65 2019-01-17 06:26:48.862420: step 16720, loss = 0.41450 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:26:50.150220 ops/training.py:65 2019-01-17 06:26:50.150146: step 16721, loss = 0.35046 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:26:51.438430 ops/training.py:65 2019-01-17 06:26:51.438348: step 16722, loss = 0.32412 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:26:52.727820 ops/training.py:65 2019-01-17 06:26:52.727719: step 16723, loss = 0.43822 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:26:54.016555 ops/training.py:65 2019-01-17 06:26:54.016444: step 16724, loss = 0.35164 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:26:55.301648 ops/training.py:65 2019-01-17 06:26:55.301576: step 16725, loss = 0.33464 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:26:56.590433 ops/training.py:65 2019-01-17 06:26:56.590346: step 16726, loss = 0.38983 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:26:57.874488 ops/training.py:65 2019-01-17 06:26:57.874389: step 16727, loss = 0.38872 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:26:59.162182 ops/training.py:65 2019-01-17 06:26:59.162107: step 16728, loss = 0.37455 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:27:00.449987 ops/training.py:65 2019-01-17 06:27:00.449907: step 16729, loss = 0.37885 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:27:01.738095 ops/training.py:65 2019-01-17 06:27:01.738028: step 16730, loss = 0.32763 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:27:03.028272 ops/training.py:65 2019-01-17 06:27:03.028200: step 16731, loss = 0.40438 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:27:04.316046 ops/training.py:65 2019-01-17 06:27:04.315969: step 16732, loss = 0.43773 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 06:27:05.600027 ops/training.py:65 2019-01-17 06:27:05.599943: step 16733, loss = 0.39483 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:27:06.893201 ops/training.py:65 2019-01-17 06:27:06.893098: step 16734, loss = 0.39318 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:27:08.176908 ops/training.py:65 2019-01-17 06:27:08.176803: step 16735, loss = 0.35033 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:27:09.470504 ops/training.py:65 2019-01-17 06:27:09.470400: step 16736, loss = 0.40349 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:27:10.761492 ops/training.py:65 2019-01-17 06:27:10.761404: step 16737, loss = 0.39636 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:27:12.050728 ops/training.py:65 2019-01-17 06:27:12.050656: step 16738, loss = 0.37169 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:27:13.339560 ops/training.py:65 2019-01-17 06:27:13.339483: step 16739, loss = 0.36722 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:27:14.628492 ops/training.py:65 2019-01-17 06:27:14.628416: step 16740, loss = 0.37316 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:27:15.917687 ops/training.py:65 2019-01-17 06:27:15.917618: step 16741, loss = 0.48053 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:27:17.199277 ops/training.py:65 2019-01-17 06:27:17.199209: step 16742, loss = 0.39655 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:27:18.486718 ops/training.py:65 2019-01-17 06:27:18.486633: step 16743, loss = 0.31736 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:27:19.771030 ops/training.py:65 2019-01-17 06:27:19.770970: step 16744, loss = 0.51766 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:27:21.053229 ops/training.py:65 2019-01-17 06:27:21.053123: step 16745, loss = 0.34618 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:27:22.338359 ops/training.py:65 2019-01-17 06:27:22.338280: step 16746, loss = 0.41713 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:27:23.628523 ops/training.py:65 2019-01-17 06:27:23.628445: step 16747, loss = 0.34392 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:27:24.918124 ops/training.py:65 2019-01-17 06:27:24.918038: step 16748, loss = 0.38250 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:27:26.214195 ops/training.py:65 2019-01-17 06:27:26.214119: step 16749, loss = 0.28387 (24.7 examples/sec; 1.295 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:27:27.503859 ops/training.py:65 2019-01-17 06:27:27.503791: step 16750, loss = 0.29612 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:27:28.793139 ops/training.py:65 2019-01-17 06:27:28.793063: step 16751, loss = 0.36044 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:27:30.081531 ops/training.py:65 2019-01-17 06:27:30.081459: step 16752, loss = 0.34766 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:27:31.370094 ops/training.py:65 2019-01-17 06:27:31.370016: step 16753, loss = 0.30180 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:27:32.659492 ops/training.py:65 2019-01-17 06:27:32.659401: step 16754, loss = 0.44668 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:27:33.948689 ops/training.py:65 2019-01-17 06:27:33.948613: step 16755, loss = 0.43779 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:27:35.237362 ops/training.py:65 2019-01-17 06:27:35.237270: step 16756, loss = 0.36607 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:27:36.525285 ops/training.py:65 2019-01-17 06:27:36.525213: step 16757, loss = 0.37562 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:27:37.813231 ops/training.py:65 2019-01-17 06:27:37.813142: step 16758, loss = 0.36730 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:27:39.103406 ops/training.py:65 2019-01-17 06:27:39.103337: step 16759, loss = 0.34627 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:27:40.388422 ops/training.py:65 2019-01-17 06:27:40.388337: step 16760, loss = 0.27957 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:27:41.679318 ops/training.py:65 2019-01-17 06:27:41.679160: step 16761, loss = 0.37279 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:27:42.966415 ops/training.py:65 2019-01-17 06:27:42.966323: step 16762, loss = 0.33151 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:27:44.250938 ops/training.py:65 2019-01-17 06:27:44.250866: step 16763, loss = 0.36446 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:27:45.540511 ops/training.py:65 2019-01-17 06:27:45.540400: step 16764, loss = 0.34223 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:27:46.832563 ops/training.py:65 2019-01-17 06:27:46.832464: step 16765, loss = 0.38408 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:27:48.119695 ops/training.py:65 2019-01-17 06:27:48.119629: step 16766, loss = 0.25671 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:27:49.407394 ops/training.py:65 2019-01-17 06:27:49.407328: step 16767, loss = 0.34858 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:27:50.696113 ops/training.py:65 2019-01-17 06:27:50.696041: step 16768, loss = 0.34670 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:27:51.985589 ops/training.py:65 2019-01-17 06:27:51.985492: step 16769, loss = 0.37741 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:27:53.273293 ops/training.py:65 2019-01-17 06:27:53.273219: step 16770, loss = 0.38595 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:27:54.562178 ops/training.py:65 2019-01-17 06:27:54.562099: step 16771, loss = 0.28794 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:27:55.847318 ops/training.py:65 2019-01-17 06:27:55.847243: step 16772, loss = 0.31928 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:27:57.136473 ops/training.py:65 2019-01-17 06:27:57.136402: step 16773, loss = 0.35670 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:27:58.425406 ops/training.py:65 2019-01-17 06:27:58.425346: step 16774, loss = 0.31143 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:27:59.709065 ops/training.py:65 2019-01-17 06:27:59.709000: step 16775, loss = 0.35092 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:28:00.996434 ops/training.py:65 2019-01-17 06:28:00.996367: step 16776, loss = 0.35078 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:28:02.284007 ops/training.py:65 2019-01-17 06:28:02.283940: step 16777, loss = 0.31639 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:28:03.573036 ops/training.py:65 2019-01-17 06:28:03.572966: step 16778, loss = 0.28542 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:28:04.860815 ops/training.py:65 2019-01-17 06:28:04.860737: step 16779, loss = 0.36800 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:28:06.146604 ops/training.py:65 2019-01-17 06:28:06.146534: step 16780, loss = 0.26345 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:28:07.435500 ops/training.py:65 2019-01-17 06:28:07.435429: step 16781, loss = 0.34561 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:28:08.724184 ops/training.py:65 2019-01-17 06:28:08.724117: step 16782, loss = 0.38930 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:28:10.012527 ops/training.py:65 2019-01-17 06:28:10.012458: step 16783, loss = 0.44657 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 06:28:11.300140 ops/training.py:65 2019-01-17 06:28:11.300062: step 16784, loss = 0.38783 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:28:12.588347 ops/training.py:65 2019-01-17 06:28:12.588275: step 16785, loss = 0.40337 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:28:13.874638 ops/training.py:65 2019-01-17 06:28:13.874562: step 16786, loss = 0.33799 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:28:15.159553 ops/training.py:65 2019-01-17 06:28:15.159483: step 16787, loss = 0.55551 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 06:28:16.447133 ops/training.py:65 2019-01-17 06:28:16.447057: step 16788, loss = 0.33784 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:28:17.735343 ops/training.py:65 2019-01-17 06:28:17.735238: step 16789, loss = 0.34212 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:28:19.023908 ops/training.py:65 2019-01-17 06:28:19.023835: step 16790, loss = 0.36288 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:28:20.310964 ops/training.py:65 2019-01-17 06:28:20.310888: step 16791, loss = 0.40339 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:28:21.599517 ops/training.py:65 2019-01-17 06:28:21.599439: step 16792, loss = 0.39196 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:28:22.888353 ops/training.py:65 2019-01-17 06:28:22.888259: step 16793, loss = 0.40001 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:28:24.173379 ops/training.py:65 2019-01-17 06:28:24.173307: step 16794, loss = 0.42898 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:28:25.462038 ops/training.py:65 2019-01-17 06:28:25.461957: step 16795, loss = 0.26905 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:28:26.749805 ops/training.py:65 2019-01-17 06:28:26.749736: step 16796, loss = 0.28833 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:28:28.038350 ops/training.py:65 2019-01-17 06:28:28.038270: step 16797, loss = 0.31642 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:28:29.323591 ops/training.py:65 2019-01-17 06:28:29.323508: step 16798, loss = 0.38818 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:28:30.613515 ops/training.py:65 2019-01-17 06:28:30.613404: step 16799, loss = 0.31652 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:28:31.902766 ops/training.py:65 2019-01-17 06:28:31.902694: step 16800, loss = 0.27755 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:28:33.185947 ops/training.py:65 2019-01-17 06:28:33.185875: step 16801, loss = 0.28246 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:28:34.470233 ops/training.py:65 2019-01-17 06:28:34.470151: step 16802, loss = 0.29626 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:28:35.762774 ops/training.py:65 2019-01-17 06:28:35.762616: step 16803, loss = 0.40087 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:28:37.054185 ops/training.py:65 2019-01-17 06:28:37.054096: step 16804, loss = 0.32911 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:28:38.344198 ops/training.py:65 2019-01-17 06:28:38.344129: step 16805, loss = 0.43021 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:28:39.634439 ops/training.py:65 2019-01-17 06:28:39.634365: step 16806, loss = 0.41061 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:28:40.923882 ops/training.py:65 2019-01-17 06:28:40.923804: step 16807, loss = 0.37015 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:28:42.213119 ops/training.py:65 2019-01-17 06:28:42.213037: step 16808, loss = 0.36224 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:28:43.498626 ops/training.py:65 2019-01-17 06:28:43.498551: step 16809, loss = 0.38386 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:28:44.787019 ops/training.py:65 2019-01-17 06:28:44.786938: step 16810, loss = 0.39546 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:28:46.071245 ops/training.py:65 2019-01-17 06:28:46.071164: step 16811, loss = 0.28907 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:28:47.358809 ops/training.py:65 2019-01-17 06:28:47.358721: step 16812, loss = 0.36339 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:28:48.643521 ops/training.py:65 2019-01-17 06:28:48.643454: step 16813, loss = 0.29696 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:28:49.931945 ops/training.py:65 2019-01-17 06:28:49.931835: step 16814, loss = 0.33699 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:28:51.220329 ops/training.py:65 2019-01-17 06:28:51.220255: step 16815, loss = 0.39788 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:28:52.514995 ops/training.py:65 2019-01-17 06:28:52.514923: step 16816, loss = 0.39711 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:28:53.804146 ops/training.py:65 2019-01-17 06:28:53.804078: step 16817, loss = 0.37598 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:28:55.093833 ops/training.py:65 2019-01-17 06:28:55.093767: step 16818, loss = 0.43001 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:28:56.382750 ops/training.py:65 2019-01-17 06:28:56.382676: step 16819, loss = 0.26115 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:28:57.671615 ops/training.py:65 2019-01-17 06:28:57.671536: step 16820, loss = 0.36024 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:28:58.960414 ops/training.py:65 2019-01-17 06:28:58.960343: step 16821, loss = 0.34845 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:29:00.248662 ops/training.py:65 2019-01-17 06:29:00.248568: step 16822, loss = 0.35518 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:29:01.538025 ops/training.py:65 2019-01-17 06:29:01.537936: step 16823, loss = 0.32674 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:29:02.828593 ops/training.py:65 2019-01-17 06:29:02.828514: step 16824, loss = 0.41945 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:29:04.116533 ops/training.py:65 2019-01-17 06:29:04.116459: step 16825, loss = 0.33332 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:29:05.411462 ops/training.py:65 2019-01-17 06:29:05.411371: step 16826, loss = 0.32961 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:29:06.700633 ops/training.py:65 2019-01-17 06:29:06.700569: step 16827, loss = 0.33772 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:29:07.989998 ops/training.py:65 2019-01-17 06:29:07.989892: step 16828, loss = 0.31157 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:29:09.280886 ops/training.py:65 2019-01-17 06:29:09.280808: step 16829, loss = 0.34589 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:29:10.565928 ops/training.py:65 2019-01-17 06:29:10.565854: step 16830, loss = 0.36275 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:29:11.850522 ops/training.py:65 2019-01-17 06:29:11.850415: step 16831, loss = 0.42450 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:29:13.142646 ops/training.py:65 2019-01-17 06:29:13.142551: step 16832, loss = 0.26931 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:29:14.433162 ops/training.py:65 2019-01-17 06:29:14.433091: step 16833, loss = 0.28588 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:29:15.722486 ops/training.py:65 2019-01-17 06:29:15.722419: step 16834, loss = 0.40508 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:29:17.012102 ops/training.py:65 2019-01-17 06:29:17.012005: step 16835, loss = 0.30822 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:29:18.299462 ops/training.py:65 2019-01-17 06:29:18.299386: step 16836, loss = 0.41073 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:29:19.588708 ops/training.py:65 2019-01-17 06:29:19.588621: step 16837, loss = 0.32929 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:29:20.877280 ops/training.py:65 2019-01-17 06:29:20.877200: step 16838, loss = 0.31882 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:29:22.167645 ops/training.py:65 2019-01-17 06:29:22.167572: step 16839, loss = 0.35546 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:29:23.455192 ops/training.py:65 2019-01-17 06:29:23.455106: step 16840, loss = 0.32711 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:29:24.744394 ops/training.py:65 2019-01-17 06:29:24.744321: step 16841, loss = 0.39731 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:29:26.034082 ops/training.py:65 2019-01-17 06:29:26.034011: step 16842, loss = 0.33865 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:29:27.322653 ops/training.py:65 2019-01-17 06:29:27.322585: step 16843, loss = 0.29815 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:29:28.610374 ops/training.py:65 2019-01-17 06:29:28.610296: step 16844, loss = 0.38476 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:29:29.894672 ops/training.py:65 2019-01-17 06:29:29.894603: step 16845, loss = 0.34995 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:29:31.180534 ops/training.py:65 2019-01-17 06:29:31.180432: step 16846, loss = 0.27179 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:29:32.464326 ops/training.py:65 2019-01-17 06:29:32.464229: step 16847, loss = 0.34388 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:29:33.755841 ops/training.py:65 2019-01-17 06:29:33.755742: step 16848, loss = 0.37825 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:29:35.046867 ops/training.py:65 2019-01-17 06:29:35.046789: step 16849, loss = 0.40309 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:29:36.335573 ops/training.py:65 2019-01-17 06:29:36.335478: step 16850, loss = 0.33547 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:29:37.624533 ops/training.py:65 2019-01-17 06:29:37.624459: step 16851, loss = 0.36013 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:29:38.911052 ops/training.py:65 2019-01-17 06:29:38.910967: step 16852, loss = 0.39913 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:29:40.201207 ops/training.py:65 2019-01-17 06:29:40.201130: step 16853, loss = 0.27518 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:29:41.489725 ops/training.py:65 2019-01-17 06:29:41.489660: step 16854, loss = 0.29702 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:29:42.778513 ops/training.py:65 2019-01-17 06:29:42.778443: step 16855, loss = 0.39721 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:29:44.065792 ops/training.py:65 2019-01-17 06:29:44.065721: step 16856, loss = 0.31867 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:29:45.355113 ops/training.py:65 2019-01-17 06:29:45.355026: step 16857, loss = 0.28801 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:29:46.644971 ops/training.py:65 2019-01-17 06:29:46.644905: step 16858, loss = 0.34716 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:29:47.934319 ops/training.py:65 2019-01-17 06:29:47.934246: step 16859, loss = 0.44726 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:29:49.219683 ops/training.py:65 2019-01-17 06:29:49.219607: step 16860, loss = 0.31593 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:29:50.508339 ops/training.py:65 2019-01-17 06:29:50.508266: step 16861, loss = 0.38039 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:29:51.796943 ops/training.py:65 2019-01-17 06:29:51.796845: step 16862, loss = 0.32004 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:29:53.085938 ops/training.py:65 2019-01-17 06:29:53.085861: step 16863, loss = 0.32357 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:29:54.374191 ops/training.py:65 2019-01-17 06:29:54.374101: step 16864, loss = 0.34628 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:29:55.663440 ops/training.py:65 2019-01-17 06:29:55.663369: step 16865, loss = 0.33705 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:29:56.951326 ops/training.py:65 2019-01-17 06:29:56.951254: step 16866, loss = 0.39424 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:29:58.239731 ops/training.py:65 2019-01-17 06:29:58.239635: step 16867, loss = 0.35276 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:29:59.528441 ops/training.py:65 2019-01-17 06:29:59.528370: step 16868, loss = 0.37612 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:30:00.817003 ops/training.py:65 2019-01-17 06:30:00.816936: step 16869, loss = 0.27076 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:30:02.104734 ops/training.py:65 2019-01-17 06:30:02.104656: step 16870, loss = 0.31715 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:30:03.393755 ops/training.py:65 2019-01-17 06:30:03.393679: step 16871, loss = 0.41712 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:30:04.683708 ops/training.py:65 2019-01-17 06:30:04.683624: step 16872, loss = 0.30530 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:30:05.972201 ops/training.py:65 2019-01-17 06:30:05.972132: step 16873, loss = 0.30476 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:30:07.261151 ops/training.py:65 2019-01-17 06:30:07.261067: step 16874, loss = 0.29618 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:30:08.549884 ops/training.py:65 2019-01-17 06:30:08.549787: step 16875, loss = 0.38133 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:30:09.835733 ops/training.py:65 2019-01-17 06:30:09.835661: step 16876, loss = 0.40530 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:30:11.125247 ops/training.py:65 2019-01-17 06:30:11.125174: step 16877, loss = 0.38607 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:30:12.413223 ops/training.py:65 2019-01-17 06:30:12.413124: step 16878, loss = 0.30315 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:30:13.701693 ops/training.py:65 2019-01-17 06:30:13.701615: step 16879, loss = 0.34408 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:30:14.990913 ops/training.py:65 2019-01-17 06:30:14.990842: step 16880, loss = 0.36422 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:30:16.279661 ops/training.py:65 2019-01-17 06:30:16.279565: step 16881, loss = 0.28648 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:30:17.568583 ops/training.py:65 2019-01-17 06:30:17.568509: step 16882, loss = 0.31869 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:30:18.856085 ops/training.py:65 2019-01-17 06:30:18.856005: step 16883, loss = 0.31279 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:30:20.144270 ops/training.py:65 2019-01-17 06:30:20.144200: step 16884, loss = 0.35314 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:30:21.434006 ops/training.py:65 2019-01-17 06:30:21.433879: step 16885, loss = 0.29291 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:30:22.723282 ops/training.py:65 2019-01-17 06:30:22.723214: step 16886, loss = 0.30229 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:30:24.013067 ops/training.py:65 2019-01-17 06:30:24.012992: step 16887, loss = 0.33772 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:30:25.298822 ops/training.py:65 2019-01-17 06:30:25.298750: step 16888, loss = 0.30160 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:30:26.587344 ops/training.py:65 2019-01-17 06:30:26.587264: step 16889, loss = 0.37869 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:30:27.876958 ops/training.py:65 2019-01-17 06:30:27.876889: step 16890, loss = 0.38799 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:30:29.167103 ops/training.py:65 2019-01-17 06:30:29.167031: step 16891, loss = 0.30385 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:30:30.452320 ops/training.py:65 2019-01-17 06:30:30.452257: step 16892, loss = 0.37759 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:30:31.741069 ops/training.py:65 2019-01-17 06:30:31.740997: step 16893, loss = 0.37637 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:30:33.025269 ops/training.py:65 2019-01-17 06:30:33.025205: step 16894, loss = 0.32187 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:30:34.308414 ops/training.py:65 2019-01-17 06:30:34.308309: step 16895, loss = 0.35253 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:30:35.591985 ops/training.py:65 2019-01-17 06:30:35.591875: step 16896, loss = 0.39518 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:30:36.875765 ops/training.py:65 2019-01-17 06:30:36.875669: step 16897, loss = 0.34475 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:30:38.161940 ops/training.py:65 2019-01-17 06:30:38.161826: step 16898, loss = 0.34854 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:30:39.454267 ops/training.py:65 2019-01-17 06:30:39.454165: step 16899, loss = 0.35243 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:30:40.740663 ops/training.py:65 2019-01-17 06:30:40.740582: step 16900, loss = 0.36826 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:30:42.027502 ops/training.py:65 2019-01-17 06:30:42.027441: step 16901, loss = 0.34329 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:30:43.311024 ops/training.py:65 2019-01-17 06:30:43.310883: step 16902, loss = 0.38370 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:30:44.598216 ops/training.py:65 2019-01-17 06:30:44.598109: step 16903, loss = 0.34603 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:30:45.888877 ops/training.py:65 2019-01-17 06:30:45.888771: step 16904, loss = 0.33783 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:30:47.171128 ops/training.py:65 2019-01-17 06:30:47.171042: step 16905, loss = 0.25694 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:30:48.461282 ops/training.py:65 2019-01-17 06:30:48.461177: step 16906, loss = 0.33582 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:30:49.748199 ops/training.py:65 2019-01-17 06:30:49.748134: step 16907, loss = 0.30753 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:30:51.033890 ops/training.py:65 2019-01-17 06:30:51.033802: step 16908, loss = 0.33833 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:30:52.324536 ops/training.py:65 2019-01-17 06:30:52.324379: step 16909, loss = 0.33762 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:30:53.617231 ops/training.py:65 2019-01-17 06:30:53.617083: step 16910, loss = 0.37040 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:30:54.907549 ops/training.py:65 2019-01-17 06:30:54.907477: step 16911, loss = 0.32528 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:30:56.196717 ops/training.py:65 2019-01-17 06:30:56.196643: step 16912, loss = 0.36969 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:30:57.485114 ops/training.py:65 2019-01-17 06:30:57.485036: step 16913, loss = 0.31708 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:30:58.769600 ops/training.py:65 2019-01-17 06:30:58.769527: step 16914, loss = 0.33609 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:31:00.053301 ops/training.py:65 2019-01-17 06:31:00.053232: step 16915, loss = 0.32877 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:31:01.343322 ops/training.py:65 2019-01-17 06:31:01.343259: step 16916, loss = 0.29609 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:31:02.632600 ops/training.py:65 2019-01-17 06:31:02.632514: step 16917, loss = 0.37166 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:31:03.922275 ops/training.py:65 2019-01-17 06:31:03.922209: step 16918, loss = 0.33037 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:31:05.212228 ops/training.py:65 2019-01-17 06:31:05.212117: step 16919, loss = 0.36019 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:31:06.502168 ops/training.py:65 2019-01-17 06:31:06.502094: step 16920, loss = 0.28867 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:31:07.791778 ops/training.py:65 2019-01-17 06:31:07.791702: step 16921, loss = 0.34679 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:31:09.080170 ops/training.py:65 2019-01-17 06:31:09.080096: step 16922, loss = 0.44675 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:31:10.360842 ops/training.py:65 2019-01-17 06:31:10.360775: step 16923, loss = 0.36953 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:31:11.645076 ops/training.py:65 2019-01-17 06:31:11.644966: step 16924, loss = 0.32386 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:31:12.929115 ops/training.py:65 2019-01-17 06:31:12.929007: step 16925, loss = 0.32734 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:31:14.220329 ops/training.py:65 2019-01-17 06:31:14.220233: step 16926, loss = 0.30614 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:31:15.509481 ops/training.py:65 2019-01-17 06:31:15.509414: step 16927, loss = 0.34037 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:31:16.794568 ops/training.py:65 2019-01-17 06:31:16.794479: step 16928, loss = 0.34341 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:31:18.085482 ops/training.py:65 2019-01-17 06:31:18.085370: step 16929, loss = 0.51533 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:31:19.377875 ops/training.py:65 2019-01-17 06:31:19.377810: step 16930, loss = 0.36734 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:31:20.664301 ops/training.py:65 2019-01-17 06:31:20.664200: step 16931, loss = 0.33101 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:31:21.953525 ops/training.py:65 2019-01-17 06:31:21.953452: step 16932, loss = 0.34035 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:31:23.240673 ops/training.py:65 2019-01-17 06:31:23.240597: step 16933, loss = 0.42075 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:31:24.524699 ops/training.py:65 2019-01-17 06:31:24.524634: step 16934, loss = 0.38670 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:31:25.816246 ops/training.py:65 2019-01-17 06:31:25.816143: step 16935, loss = 0.29088 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:31:27.109104 ops/training.py:65 2019-01-17 06:31:27.108995: step 16936, loss = 0.34158 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:31:28.399134 ops/training.py:65 2019-01-17 06:31:28.399065: step 16937, loss = 0.33113 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:31:29.687995 ops/training.py:65 2019-01-17 06:31:29.687923: step 16938, loss = 0.40676 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:31:30.972403 ops/training.py:65 2019-01-17 06:31:30.972338: step 16939, loss = 0.30650 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:31:32.256205 ops/training.py:65 2019-01-17 06:31:32.256144: step 16940, loss = 0.34450 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:31:33.546983 ops/training.py:65 2019-01-17 06:31:33.546878: step 16941, loss = 0.31077 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:31:34.837493 ops/training.py:65 2019-01-17 06:31:34.837429: step 16942, loss = 0.30316 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:31:36.126740 ops/training.py:65 2019-01-17 06:31:36.126665: step 16943, loss = 0.29405 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:31:37.413826 ops/training.py:65 2019-01-17 06:31:37.413739: step 16944, loss = 0.35628 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:31:38.702670 ops/training.py:65 2019-01-17 06:31:38.702604: step 16945, loss = 0.34524 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:31:39.991507 ops/training.py:65 2019-01-17 06:31:39.991438: step 16946, loss = 0.32346 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:31:41.281268 ops/training.py:65 2019-01-17 06:31:41.281184: step 16947, loss = 0.35984 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:31:42.570978 ops/training.py:65 2019-01-17 06:31:42.570911: step 16948, loss = 0.26944 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:31:43.858142 ops/training.py:65 2019-01-17 06:31:43.858067: step 16949, loss = 0.37382 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:31:45.142329 ops/training.py:65 2019-01-17 06:31:45.142249: step 16950, loss = 0.41496 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:31:46.427921 ops/training.py:65 2019-01-17 06:31:46.427820: step 16951, loss = 0.38741 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:31:47.721135 ops/training.py:65 2019-01-17 06:31:47.721037: step 16952, loss = 0.41712 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:31:49.010955 ops/training.py:65 2019-01-17 06:31:49.010885: step 16953, loss = 0.40687 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:31:50.295996 ops/training.py:65 2019-01-17 06:31:50.295901: step 16954, loss = 0.36200 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:31:51.584070 ops/training.py:65 2019-01-17 06:31:51.583961: step 16955, loss = 0.35262 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:31:52.864251 ops/training.py:65 2019-01-17 06:31:52.864144: step 16956, loss = 0.33154 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:31:54.149578 ops/training.py:65 2019-01-17 06:31:54.149484: step 16957, loss = 0.35825 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:31:55.435261 ops/training.py:65 2019-01-17 06:31:55.435155: step 16958, loss = 0.36229 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:31:56.719745 ops/training.py:65 2019-01-17 06:31:56.719639: step 16959, loss = 0.30759 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:31:58.014361 ops/training.py:65 2019-01-17 06:31:58.014255: step 16960, loss = 0.33605 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:31:59.306336 ops/training.py:65 2019-01-17 06:31:59.306262: step 16961, loss = 0.36446 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:32:00.595656 ops/training.py:65 2019-01-17 06:32:00.595588: step 16962, loss = 0.31108 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:32:01.880345 ops/training.py:65 2019-01-17 06:32:01.880280: step 16963, loss = 0.31670 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:32:03.160862 ops/training.py:65 2019-01-17 06:32:03.160778: step 16964, loss = 0.39212 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:32:04.450111 ops/training.py:65 2019-01-17 06:32:04.450011: step 16965, loss = 0.34419 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:32:05.737545 ops/training.py:65 2019-01-17 06:32:05.737442: step 16966, loss = 0.36738 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:32:07.029438 ops/training.py:65 2019-01-17 06:32:07.029330: step 16967, loss = 0.36367 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:32:08.319660 ops/training.py:65 2019-01-17 06:32:08.319594: step 16968, loss = 0.39178 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:32:09.602077 ops/training.py:65 2019-01-17 06:32:09.602006: step 16969, loss = 0.33644 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:32:10.897218 ops/training.py:65 2019-01-17 06:32:10.897104: step 16970, loss = 0.38140 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:32:12.182507 ops/training.py:65 2019-01-17 06:32:12.182439: step 16971, loss = 0.36285 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:32:13.465529 ops/training.py:65 2019-01-17 06:32:13.465429: step 16972, loss = 0.34145 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:32:14.749810 ops/training.py:65 2019-01-17 06:32:14.749707: step 16973, loss = 0.34701 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:32:16.043645 ops/training.py:65 2019-01-17 06:32:16.043540: step 16974, loss = 0.30734 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:32:17.333846 ops/training.py:65 2019-01-17 06:32:17.333777: step 16975, loss = 0.29442 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:32:18.623095 ops/training.py:65 2019-01-17 06:32:18.623025: step 16976, loss = 0.36048 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:32:19.909231 ops/training.py:65 2019-01-17 06:32:19.909165: step 16977, loss = 0.33824 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:32:21.198648 ops/training.py:65 2019-01-17 06:32:21.198539: step 16978, loss = 0.45646 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:32:22.483459 ops/training.py:65 2019-01-17 06:32:22.483395: step 16979, loss = 0.37308 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:32:23.772751 ops/training.py:65 2019-01-17 06:32:23.772643: step 16980, loss = 0.29931 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:32:25.057683 ops/training.py:65 2019-01-17 06:32:25.057570: step 16981, loss = 0.34238 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:32:26.343842 ops/training.py:65 2019-01-17 06:32:26.343730: step 16982, loss = 0.25394 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:32:27.636562 ops/training.py:65 2019-01-17 06:32:27.636453: step 16983, loss = 0.36832 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:32:28.922227 ops/training.py:65 2019-01-17 06:32:28.922118: step 16984, loss = 0.36767 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:32:30.207856 ops/training.py:65 2019-01-17 06:32:30.207757: step 16985, loss = 0.34879 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:32:31.492082 ops/training.py:65 2019-01-17 06:32:31.491976: step 16986, loss = 0.34616 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:32:32.778320 ops/training.py:65 2019-01-17 06:32:32.778221: step 16987, loss = 0.36746 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:32:34.068045 ops/training.py:65 2019-01-17 06:32:34.067930: step 16988, loss = 0.42254 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:32:35.349881 ops/training.py:65 2019-01-17 06:32:35.349773: step 16989, loss = 0.32448 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:32:36.638218 ops/training.py:65 2019-01-17 06:32:36.638105: step 16990, loss = 0.36296 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:32:37.920805 ops/training.py:65 2019-01-17 06:32:37.920698: step 16991, loss = 0.45155 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:32:39.207720 ops/training.py:65 2019-01-17 06:32:39.207613: step 16992, loss = 0.40444 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:32:40.500364 ops/training.py:65 2019-01-17 06:32:40.500261: step 16993, loss = 0.30511 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:32:41.790061 ops/training.py:65 2019-01-17 06:32:41.789985: step 16994, loss = 0.25411 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:32:43.081371 ops/training.py:65 2019-01-17 06:32:43.081285: step 16995, loss = 0.43361 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:32:44.370510 ops/training.py:65 2019-01-17 06:32:44.370439: step 16996, loss = 0.36316 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:32:45.657004 ops/training.py:65 2019-01-17 06:32:45.656923: step 16997, loss = 0.33679 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:32:46.948818 ops/training.py:65 2019-01-17 06:32:46.948675: step 16998, loss = 0.34450 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:32:48.235702 ops/training.py:65 2019-01-17 06:32:48.235634: step 16999, loss = 0.37954 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:32:49.524824 ops/training.py:65 2019-01-17 06:32:49.524764: step 17000, loss = 0.34552 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:32:50.813317 ops/training.py:65 2019-01-17 06:32:50.813239: step 17001, loss = 0.34243 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:32:52.101527 ops/training.py:65 2019-01-17 06:32:52.101458: step 17002, loss = 0.29932 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:32:53.385317 ops/training.py:65 2019-01-17 06:32:53.385247: step 17003, loss = 0.27691 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:32:54.675243 ops/training.py:65 2019-01-17 06:32:54.675086: step 17004, loss = 0.29245 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:32:55.965971 ops/training.py:65 2019-01-17 06:32:55.965887: step 17005, loss = 0.43602 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:32:57.249544 ops/training.py:65 2019-01-17 06:32:57.249463: step 17006, loss = 0.27061 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:32:58.542507 ops/training.py:65 2019-01-17 06:32:58.542396: step 17007, loss = 0.34294 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:32:59.828886 ops/training.py:65 2019-01-17 06:32:59.828821: step 17008, loss = 0.30709 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:33:01.117862 ops/training.py:65 2019-01-17 06:33:01.117795: step 17009, loss = 0.36556 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:33:02.402391 ops/training.py:65 2019-01-17 06:33:02.402326: step 17010, loss = 0.36624 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:33:03.686191 ops/training.py:65 2019-01-17 06:33:03.686108: step 17011, loss = 0.39805 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:33:04.971729 ops/training.py:65 2019-01-17 06:33:04.971629: step 17012, loss = 0.31654 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:33:06.260313 ops/training.py:65 2019-01-17 06:33:06.260214: step 17013, loss = 0.40884 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:33:07.552240 ops/training.py:65 2019-01-17 06:33:07.552099: step 17014, loss = 0.32480 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:33:08.838163 ops/training.py:65 2019-01-17 06:33:08.838066: step 17015, loss = 0.38297 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:33:10.123371 ops/training.py:65 2019-01-17 06:33:10.123267: step 17016, loss = 0.27707 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:33:11.414981 ops/training.py:65 2019-01-17 06:33:11.414844: step 17017, loss = 0.26189 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:33:12.706420 ops/training.py:65 2019-01-17 06:33:12.706333: step 17018, loss = 0.41996 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:33:13.996715 ops/training.py:65 2019-01-17 06:33:13.996598: step 17019, loss = 0.42208 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:33:15.286025 ops/training.py:65 2019-01-17 06:33:15.285954: step 17020, loss = 0.34393 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:33:16.574819 ops/training.py:65 2019-01-17 06:33:16.574745: step 17021, loss = 0.28471 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:33:17.863314 ops/training.py:65 2019-01-17 06:33:17.863240: step 17022, loss = 0.28267 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:33:19.153172 ops/training.py:65 2019-01-17 06:33:19.153103: step 17023, loss = 0.42589 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:33:20.437853 ops/training.py:65 2019-01-17 06:33:20.437784: step 17024, loss = 0.32917 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:33:21.722363 ops/training.py:65 2019-01-17 06:33:21.722260: step 17025, loss = 0.39560 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:33:23.014231 ops/training.py:65 2019-01-17 06:33:23.014082: step 17026, loss = 0.38980 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:33:24.302227 ops/training.py:65 2019-01-17 06:33:24.302146: step 17027, loss = 0.41681 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:33:25.586428 ops/training.py:65 2019-01-17 06:33:25.586324: step 17028, loss = 0.33889 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:33:26.874436 ops/training.py:65 2019-01-17 06:33:26.874329: step 17029, loss = 0.28976 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:33:28.158669 ops/training.py:65 2019-01-17 06:33:28.158565: step 17030, loss = 0.35291 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:33:29.450407 ops/training.py:65 2019-01-17 06:33:29.450322: step 17031, loss = 0.37417 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:33:30.738450 ops/training.py:65 2019-01-17 06:33:30.738376: step 17032, loss = 0.27863 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:33:32.027933 ops/training.py:65 2019-01-17 06:33:32.027848: step 17033, loss = 0.31815 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:33:33.318162 ops/training.py:65 2019-01-17 06:33:33.318093: step 17034, loss = 0.33317 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:33:34.606174 ops/training.py:65 2019-01-17 06:33:34.606106: step 17035, loss = 0.38922 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:33:35.894807 ops/training.py:65 2019-01-17 06:33:35.894740: step 17036, loss = 0.35082 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:33:37.178186 ops/training.py:65 2019-01-17 06:33:37.178127: step 17037, loss = 0.24418 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:33:38.462272 ops/training.py:65 2019-01-17 06:33:38.462165: step 17038, loss = 0.38789 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:33:39.753334 ops/training.py:65 2019-01-17 06:33:39.753235: step 17039, loss = 0.42735 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:33:41.044112 ops/training.py:65 2019-01-17 06:33:41.044037: step 17040, loss = 0.24345 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:33:42.329114 ops/training.py:65 2019-01-17 06:33:42.329051: step 17041, loss = 0.30361 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:33:43.619428 ops/training.py:65 2019-01-17 06:33:43.619329: step 17042, loss = 0.33666 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:33:44.906881 ops/training.py:65 2019-01-17 06:33:44.906823: step 17043, loss = 0.35681 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:33:46.190835 ops/training.py:65 2019-01-17 06:33:46.190734: step 17044, loss = 0.39775 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:33:47.473150 ops/training.py:65 2019-01-17 06:33:47.473049: step 17045, loss = 0.33559 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:33:48.765858 ops/training.py:65 2019-01-17 06:33:48.765707: step 17046, loss = 0.38196 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:33:50.057345 ops/training.py:65 2019-01-17 06:33:50.057265: step 17047, loss = 0.41373 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:33:51.346551 ops/training.py:65 2019-01-17 06:33:51.346474: step 17048, loss = 0.30472 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:33:52.636638 ops/training.py:65 2019-01-17 06:33:52.636561: step 17049, loss = 0.37208 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:33:53.926445 ops/training.py:65 2019-01-17 06:33:53.926378: step 17050, loss = 0.31348 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:33:55.214890 ops/training.py:65 2019-01-17 06:33:55.214796: step 17051, loss = 0.35813 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:33:56.504247 ops/training.py:65 2019-01-17 06:33:56.504175: step 17052, loss = 0.38484 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:33:57.793329 ops/training.py:65 2019-01-17 06:33:57.793261: step 17053, loss = 0.27783 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:33:59.082001 ops/training.py:65 2019-01-17 06:33:59.081928: step 17054, loss = 0.38916 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:34:00.371066 ops/training.py:65 2019-01-17 06:34:00.370994: step 17055, loss = 0.33179 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:34:01.659114 ops/training.py:65 2019-01-17 06:34:01.659049: step 17056, loss = 0.33161 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:34:02.947833 ops/training.py:65 2019-01-17 06:34:02.947763: step 17057, loss = 0.32693 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:34:04.232938 ops/training.py:65 2019-01-17 06:34:04.232856: step 17058, loss = 0.33402 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:34:05.522705 ops/training.py:65 2019-01-17 06:34:05.522601: step 17059, loss = 0.37016 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:34:06.813363 ops/training.py:65 2019-01-17 06:34:06.813258: step 17060, loss = 0.33724 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:34:08.103465 ops/training.py:65 2019-01-17 06:34:08.103401: step 17061, loss = 0.35873 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:34:09.391399 ops/training.py:65 2019-01-17 06:34:09.391329: step 17062, loss = 0.34617 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:34:10.679781 ops/training.py:65 2019-01-17 06:34:10.679718: step 17063, loss = 0.34823 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:34:11.967910 ops/training.py:65 2019-01-17 06:34:11.967840: step 17064, loss = 0.34813 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:34:13.257116 ops/training.py:65 2019-01-17 06:34:13.257046: step 17065, loss = 0.30991 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:34:14.546475 ops/training.py:65 2019-01-17 06:34:14.546407: step 17066, loss = 0.28747 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:34:15.835378 ops/training.py:65 2019-01-17 06:34:15.835306: step 17067, loss = 0.31555 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:34:17.124753 ops/training.py:65 2019-01-17 06:34:17.124686: step 17068, loss = 0.34386 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:34:18.412877 ops/training.py:65 2019-01-17 06:34:18.412799: step 17069, loss = 0.35016 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:34:19.701642 ops/training.py:65 2019-01-17 06:34:19.701566: step 17070, loss = 0.33420 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:34:20.990862 ops/training.py:65 2019-01-17 06:34:20.990771: step 17071, loss = 0.35354 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:34:22.280297 ops/training.py:65 2019-01-17 06:34:22.280197: step 17072, loss = 0.33712 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:34:23.565744 ops/training.py:65 2019-01-17 06:34:23.565675: step 17073, loss = 0.36507 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:34:24.852942 ops/training.py:65 2019-01-17 06:34:24.852835: step 17074, loss = 0.34928 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:34:26.141235 ops/training.py:65 2019-01-17 06:34:26.141128: step 17075, loss = 0.30874 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:34:27.423470 ops/training.py:65 2019-01-17 06:34:27.423357: step 17076, loss = 0.35333 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:34:28.714122 ops/training.py:65 2019-01-17 06:34:28.713967: step 17077, loss = 0.28557 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:34:30.002564 ops/training.py:65 2019-01-17 06:34:30.002491: step 17078, loss = 0.37785 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:34:31.291645 ops/training.py:65 2019-01-17 06:34:31.291570: step 17079, loss = 0.39742 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:34:32.579816 ops/training.py:65 2019-01-17 06:34:32.579746: step 17080, loss = 0.31025 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:34:33.869230 ops/training.py:65 2019-01-17 06:34:33.869152: step 17081, loss = 0.32392 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:34:35.164605 ops/training.py:65 2019-01-17 06:34:35.164533: step 17082, loss = 0.41416 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:34:36.455759 ops/training.py:65 2019-01-17 06:34:36.455686: step 17083, loss = 0.30999 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:34:37.745436 ops/training.py:65 2019-01-17 06:34:37.745344: step 17084, loss = 0.37714 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:34:39.034899 ops/training.py:65 2019-01-17 06:34:39.034798: step 17085, loss = 0.40135 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:34:40.320422 ops/training.py:65 2019-01-17 06:34:40.320356: step 17086, loss = 0.35135 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:34:41.610108 ops/training.py:65 2019-01-17 06:34:41.609993: step 17087, loss = 0.29711 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:34:42.891783 ops/training.py:65 2019-01-17 06:34:42.891705: step 17088, loss = 0.32602 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:34:44.180492 ops/training.py:65 2019-01-17 06:34:44.180420: step 17089, loss = 0.42483 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:34:45.470941 ops/training.py:65 2019-01-17 06:34:45.470864: step 17090, loss = 0.38054 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:34:46.759932 ops/training.py:65 2019-01-17 06:34:46.759866: step 17091, loss = 0.36115 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:34:48.048159 ops/training.py:65 2019-01-17 06:34:48.048090: step 17092, loss = 0.38146 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:34:49.336600 ops/training.py:65 2019-01-17 06:34:49.336522: step 17093, loss = 0.31032 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:34:50.624208 ops/training.py:65 2019-01-17 06:34:50.624125: step 17094, loss = 0.37551 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:34:51.909393 ops/training.py:65 2019-01-17 06:34:51.909324: step 17095, loss = 0.33794 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:34:53.198256 ops/training.py:65 2019-01-17 06:34:53.198168: step 17096, loss = 0.32438 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:34:54.487076 ops/training.py:65 2019-01-17 06:34:54.487015: step 17097, loss = 0.28122 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:34:55.771731 ops/training.py:65 2019-01-17 06:34:55.771657: step 17098, loss = 0.35617 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:34:57.056922 ops/training.py:65 2019-01-17 06:34:57.056852: step 17099, loss = 0.35023 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:34:58.346207 ops/training.py:65 2019-01-17 06:34:58.346130: step 17100, loss = 0.33757 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:34:59.635512 ops/training.py:65 2019-01-17 06:34:59.635439: step 17101, loss = 0.26759 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:35:00.923201 ops/training.py:65 2019-01-17 06:35:00.923127: step 17102, loss = 0.32320 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:35:02.212084 ops/training.py:65 2019-01-17 06:35:02.212001: step 17103, loss = 0.34086 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:35:03.501107 ops/training.py:65 2019-01-17 06:35:03.501018: step 17104, loss = 0.37033 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:35:04.788771 ops/training.py:65 2019-01-17 06:35:04.788696: step 17105, loss = 0.40927 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:35:06.076968 ops/training.py:65 2019-01-17 06:35:06.076892: step 17106, loss = 0.36870 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:35:07.365504 ops/training.py:65 2019-01-17 06:35:07.365434: step 17107, loss = 0.36281 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:35:08.649299 ops/training.py:65 2019-01-17 06:35:08.649210: step 17108, loss = 0.33105 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:35:09.938001 ops/training.py:65 2019-01-17 06:35:09.937931: step 17109, loss = 0.31945 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:35:11.226010 ops/training.py:65 2019-01-17 06:35:11.225935: step 17110, loss = 0.38063 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:35:12.507971 ops/training.py:65 2019-01-17 06:35:12.507892: step 17111, loss = 0.30982 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:35:13.788976 ops/training.py:65 2019-01-17 06:35:13.788876: step 17112, loss = 0.36457 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:35:15.083437 ops/training.py:65 2019-01-17 06:35:15.083326: step 17113, loss = 0.43933 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:35:16.370167 ops/training.py:65 2019-01-17 06:35:16.370092: step 17114, loss = 0.30644 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:35:17.660953 ops/training.py:65 2019-01-17 06:35:17.660880: step 17115, loss = 0.34179 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:35:18.945148 ops/training.py:65 2019-01-17 06:35:18.945075: step 17116, loss = 0.31993 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:35:20.234719 ops/training.py:65 2019-01-17 06:35:20.234649: step 17117, loss = 0.34119 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:35:21.523154 ops/training.py:65 2019-01-17 06:35:21.523066: step 17118, loss = 0.38406 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:35:22.807863 ops/training.py:65 2019-01-17 06:35:22.807792: step 17119, loss = 0.35250 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:35:24.091619 ops/training.py:65 2019-01-17 06:35:24.091550: step 17120, loss = 0.33581 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:35:25.373135 ops/training.py:65 2019-01-17 06:35:25.372990: step 17121, loss = 0.29248 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:35:26.658655 ops/training.py:65 2019-01-17 06:35:26.658500: step 17122, loss = 0.34949 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:35:27.952635 ops/training.py:65 2019-01-17 06:35:27.952480: step 17123, loss = 0.32273 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:35:29.245772 ops/training.py:65 2019-01-17 06:35:29.245698: step 17124, loss = 0.33545 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:35:30.529336 ops/training.py:65 2019-01-17 06:35:30.529258: step 17125, loss = 0.30508 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:35:31.820388 ops/training.py:65 2019-01-17 06:35:31.820283: step 17126, loss = 0.43148 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:35:33.113218 ops/training.py:65 2019-01-17 06:35:33.113120: step 17127, loss = 0.33067 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:35:34.399035 ops/training.py:65 2019-01-17 06:35:34.398867: step 17128, loss = 0.38695 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:35:35.686137 ops/training.py:65 2019-01-17 06:35:35.686030: step 17129, loss = 0.36676 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:35:36.977477 ops/training.py:65 2019-01-17 06:35:36.977332: step 17130, loss = 0.31908 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:35:38.268312 ops/training.py:65 2019-01-17 06:35:38.268217: step 17131, loss = 0.32389 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:35:39.557887 ops/training.py:65 2019-01-17 06:35:39.557799: step 17132, loss = 0.32505 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:35:40.847260 ops/training.py:65 2019-01-17 06:35:40.847156: step 17133, loss = 0.40062 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:35:42.136702 ops/training.py:65 2019-01-17 06:35:42.136635: step 17134, loss = 0.32889 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:35:43.425744 ops/training.py:65 2019-01-17 06:35:43.425676: step 17135, loss = 0.36758 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:35:44.713639 ops/training.py:65 2019-01-17 06:35:44.713551: step 17136, loss = 0.36380 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:35:46.003302 ops/training.py:65 2019-01-17 06:35:46.003203: step 17137, loss = 0.32545 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:35:47.292899 ops/training.py:65 2019-01-17 06:35:47.292825: step 17138, loss = 0.28335 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:35:48.581980 ops/training.py:65 2019-01-17 06:35:48.581913: step 17139, loss = 0.34221 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:35:49.869783 ops/training.py:65 2019-01-17 06:35:49.869709: step 17140, loss = 0.30452 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:35:51.158302 ops/training.py:65 2019-01-17 06:35:51.158230: step 17141, loss = 0.33367 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:35:52.448826 ops/training.py:65 2019-01-17 06:35:52.448753: step 17142, loss = 0.31801 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:35:53.736534 ops/training.py:65 2019-01-17 06:35:53.736460: step 17143, loss = 0.32800 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:35:55.024956 ops/training.py:65 2019-01-17 06:35:55.024864: step 17144, loss = 0.34630 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:35:56.313436 ops/training.py:65 2019-01-17 06:35:56.313370: step 17145, loss = 0.41946 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:35:57.601088 ops/training.py:65 2019-01-17 06:35:57.601022: step 17146, loss = 0.37827 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:35:58.889428 ops/training.py:65 2019-01-17 06:35:58.889363: step 17147, loss = 0.31349 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:36:00.177766 ops/training.py:65 2019-01-17 06:36:00.177694: step 17148, loss = 0.30469 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:36:01.466605 ops/training.py:65 2019-01-17 06:36:01.466539: step 17149, loss = 0.30019 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:36:02.755697 ops/training.py:65 2019-01-17 06:36:02.755615: step 17150, loss = 0.35921 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:36:04.039385 ops/training.py:65 2019-01-17 06:36:04.039315: step 17151, loss = 0.30269 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:36:05.327348 ops/training.py:65 2019-01-17 06:36:05.327236: step 17152, loss = 0.31384 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:36:06.616592 ops/training.py:65 2019-01-17 06:36:06.616517: step 17153, loss = 0.38793 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:36:07.905188 ops/training.py:65 2019-01-17 06:36:07.905120: step 17154, loss = 0.33461 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:36:09.188604 ops/training.py:65 2019-01-17 06:36:09.188536: step 17155, loss = 0.35110 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:36:10.475777 ops/training.py:65 2019-01-17 06:36:10.475667: step 17156, loss = 0.38376 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:36:11.760478 ops/training.py:65 2019-01-17 06:36:11.760369: step 17157, loss = 0.33967 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:36:13.050034 ops/training.py:65 2019-01-17 06:36:13.049927: step 17158, loss = 0.33264 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:36:14.343574 ops/training.py:65 2019-01-17 06:36:14.343461: step 17159, loss = 0.40181 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:36:15.632399 ops/training.py:65 2019-01-17 06:36:15.632336: step 17160, loss = 0.42461 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:36:16.921780 ops/training.py:65 2019-01-17 06:36:16.921713: step 17161, loss = 0.37892 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:36:18.207670 ops/training.py:65 2019-01-17 06:36:18.207595: step 17162, loss = 0.35785 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:36:19.497499 ops/training.py:65 2019-01-17 06:36:19.497434: step 17163, loss = 0.46881 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:36:20.780930 ops/training.py:65 2019-01-17 06:36:20.780850: step 17164, loss = 0.26178 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:36:22.066497 ops/training.py:65 2019-01-17 06:36:22.066395: step 17165, loss = 0.27610 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:36:23.351843 ops/training.py:65 2019-01-17 06:36:23.351737: step 17166, loss = 0.30082 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:36:24.639640 ops/training.py:65 2019-01-17 06:36:24.639526: step 17167, loss = 0.34871 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:36:25.925204 ops/training.py:65 2019-01-17 06:36:25.925094: step 17168, loss = 0.38988 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:36:27.218051 ops/training.py:65 2019-01-17 06:36:27.217943: step 17169, loss = 0.40530 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:36:28.506267 ops/training.py:65 2019-01-17 06:36:28.506195: step 17170, loss = 0.33146 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:36:29.792001 ops/training.py:65 2019-01-17 06:36:29.791893: step 17171, loss = 0.34181 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:36:31.079508 ops/training.py:65 2019-01-17 06:36:31.079403: step 17172, loss = 0.46570 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 06:36:32.370038 ops/training.py:65 2019-01-17 06:36:32.369888: step 17173, loss = 0.32863 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:36:33.663440 ops/training.py:65 2019-01-17 06:36:33.663354: step 17174, loss = 0.33535 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:36:34.952014 ops/training.py:65 2019-01-17 06:36:34.951952: step 17175, loss = 0.36110 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:36:36.241218 ops/training.py:65 2019-01-17 06:36:36.241154: step 17176, loss = 0.35941 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:36:37.525859 ops/training.py:65 2019-01-17 06:36:37.525792: step 17177, loss = 0.31302 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:36:38.814022 ops/training.py:65 2019-01-17 06:36:38.813914: step 17178, loss = 0.37711 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:36:40.103766 ops/training.py:65 2019-01-17 06:36:40.103659: step 17179, loss = 0.22051 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:36:41.392971 ops/training.py:65 2019-01-17 06:36:41.392903: step 17180, loss = 0.39591 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:36:42.680686 ops/training.py:65 2019-01-17 06:36:42.680619: step 17181, loss = 0.31143 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:36:43.970780 ops/training.py:65 2019-01-17 06:36:43.970697: step 17182, loss = 0.37550 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:36:45.259502 ops/training.py:65 2019-01-17 06:36:45.259429: step 17183, loss = 0.34293 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:36:46.547568 ops/training.py:65 2019-01-17 06:36:46.547502: step 17184, loss = 0.33878 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:36:47.833019 ops/training.py:65 2019-01-17 06:36:47.832954: step 17185, loss = 0.39367 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:36:49.121915 ops/training.py:65 2019-01-17 06:36:49.121805: step 17186, loss = 0.30033 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:36:50.410471 ops/training.py:65 2019-01-17 06:36:50.410402: step 17187, loss = 0.38610 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:36:51.698838 ops/training.py:65 2019-01-17 06:36:51.698757: step 17188, loss = 0.29602 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:36:52.988498 ops/training.py:65 2019-01-17 06:36:52.988402: step 17189, loss = 0.27605 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:36:54.278214 ops/training.py:65 2019-01-17 06:36:54.278104: step 17190, loss = 0.41775 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:36:55.568883 ops/training.py:65 2019-01-17 06:36:55.568785: step 17191, loss = 0.36264 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:36:56.857741 ops/training.py:65 2019-01-17 06:36:56.857653: step 17192, loss = 0.23081 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:36:58.143341 ops/training.py:65 2019-01-17 06:36:58.143264: step 17193, loss = 0.29273 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:36:59.432483 ops/training.py:65 2019-01-17 06:36:59.432387: step 17194, loss = 0.39769 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:37:00.719123 ops/training.py:65 2019-01-17 06:37:00.719049: step 17195, loss = 0.29410 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:37:02.008117 ops/training.py:65 2019-01-17 06:37:02.008046: step 17196, loss = 0.31780 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:37:03.295930 ops/training.py:65 2019-01-17 06:37:03.295858: step 17197, loss = 0.28965 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:37:04.579685 ops/training.py:65 2019-01-17 06:37:04.579608: step 17198, loss = 0.34323 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:37:05.869061 ops/training.py:65 2019-01-17 06:37:05.868994: step 17199, loss = 0.21515 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:37:07.154069 ops/training.py:65 2019-01-17 06:37:07.153992: step 17200, loss = 0.33931 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:37:08.435353 ops/training.py:65 2019-01-17 06:37:08.435266: step 17201, loss = 0.36308 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:37:09.720467 ops/training.py:65 2019-01-17 06:37:09.720431: step 17202, loss = 0.33489 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:37:11.010798 ops/training.py:65 2019-01-17 06:37:11.010764: step 17203, loss = 0.20627 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:37:12.301940 ops/training.py:65 2019-01-17 06:37:12.301899: step 17204, loss = 0.38011 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:37:13.591639 ops/training.py:65 2019-01-17 06:37:13.591586: step 17205, loss = 0.25648 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:37:14.879272 ops/training.py:65 2019-01-17 06:37:14.879187: step 17206, loss = 0.36490 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:37:16.163717 ops/training.py:65 2019-01-17 06:37:16.163659: step 17207, loss = 0.27071 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:37:17.447085 ops/training.py:65 2019-01-17 06:37:17.446999: step 17208, loss = 0.32290 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:37:18.740004 ops/training.py:65 2019-01-17 06:37:18.739891: step 17209, loss = 0.33554 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:37:20.031422 ops/training.py:65 2019-01-17 06:37:20.031340: step 17210, loss = 0.33286 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:37:21.319055 ops/training.py:65 2019-01-17 06:37:21.318977: step 17211, loss = 0.31270 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:37:22.607584 ops/training.py:65 2019-01-17 06:37:22.607513: step 17212, loss = 0.33325 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:37:23.892840 ops/training.py:65 2019-01-17 06:37:23.892761: step 17213, loss = 0.30667 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:37:25.176166 ops/training.py:65 2019-01-17 06:37:25.176053: step 17214, loss = 0.38663 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:37:26.469447 ops/training.py:65 2019-01-17 06:37:26.469297: step 17215, loss = 0.34232 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:37:27.755408 ops/training.py:65 2019-01-17 06:37:27.755335: step 17216, loss = 0.39747 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:37:29.039837 ops/training.py:65 2019-01-17 06:37:29.039740: step 17217, loss = 0.35972 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:37:30.327408 ops/training.py:65 2019-01-17 06:37:30.327306: step 17218, loss = 0.32057 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:37:31.611573 ops/training.py:65 2019-01-17 06:37:31.611469: step 17219, loss = 0.36071 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:37:32.899365 ops/training.py:65 2019-01-17 06:37:32.899265: step 17220, loss = 0.38148 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:37:34.191583 ops/training.py:65 2019-01-17 06:37:34.191476: step 17221, loss = 0.29929 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:37:35.482968 ops/training.py:65 2019-01-17 06:37:35.482899: step 17222, loss = 0.29881 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:37:36.771329 ops/training.py:65 2019-01-17 06:37:36.771256: step 17223, loss = 0.35197 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:37:38.060335 ops/training.py:65 2019-01-17 06:37:38.060261: step 17224, loss = 0.38104 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:37:39.350360 ops/training.py:65 2019-01-17 06:37:39.350264: step 17225, loss = 0.32499 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:37:40.639954 ops/training.py:65 2019-01-17 06:37:40.639882: step 17226, loss = 0.26585 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:37:41.929293 ops/training.py:65 2019-01-17 06:37:41.929194: step 17227, loss = 0.46807 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:37:43.218580 ops/training.py:65 2019-01-17 06:37:43.218491: step 17228, loss = 0.42531 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:37:44.506966 ops/training.py:65 2019-01-17 06:37:44.506886: step 17229, loss = 0.33598 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:37:45.789877 ops/training.py:65 2019-01-17 06:37:45.789807: step 17230, loss = 0.33852 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:37:47.073031 ops/training.py:65 2019-01-17 06:37:47.072945: step 17231, loss = 0.29948 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:37:48.365882 ops/training.py:65 2019-01-17 06:37:48.365733: step 17232, loss = 0.36130 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:37:49.656430 ops/training.py:65 2019-01-17 06:37:49.656327: step 17233, loss = 0.34774 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:37:50.945388 ops/training.py:65 2019-01-17 06:37:50.945293: step 17234, loss = 0.44465 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:37:52.232226 ops/training.py:65 2019-01-17 06:37:52.232158: step 17235, loss = 0.36788 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:37:53.521672 ops/training.py:65 2019-01-17 06:37:53.521569: step 17236, loss = 0.31884 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:37:54.810284 ops/training.py:65 2019-01-17 06:37:54.810215: step 17237, loss = 0.29269 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:37:56.095031 ops/training.py:65 2019-01-17 06:37:56.094969: step 17238, loss = 0.35673 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:37:57.383770 ops/training.py:65 2019-01-17 06:37:57.383671: step 17239, loss = 0.32163 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:37:58.677080 ops/training.py:65 2019-01-17 06:37:58.677011: step 17240, loss = 0.35698 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:37:59.963721 ops/training.py:65 2019-01-17 06:37:59.963643: step 17241, loss = 0.36453 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:38:01.249536 ops/training.py:65 2019-01-17 06:38:01.249471: step 17242, loss = 0.32777 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:38:02.527973 ops/training.py:65 2019-01-17 06:38:02.527888: step 17243, loss = 0.28176 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:38:03.811964 ops/training.py:65 2019-01-17 06:38:03.811857: step 17244, loss = 0.35937 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:38:05.103868 ops/training.py:65 2019-01-17 06:38:05.103763: step 17245, loss = 0.36648 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:38:06.392896 ops/training.py:65 2019-01-17 06:38:06.392774: step 17246, loss = 0.36126 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:38:07.683494 ops/training.py:65 2019-01-17 06:38:07.683417: step 17247, loss = 0.44441 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:38:08.967298 ops/training.py:65 2019-01-17 06:38:08.967228: step 17248, loss = 0.30619 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:38:10.255430 ops/training.py:65 2019-01-17 06:38:10.255362: step 17249, loss = 0.49658 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:38:11.545232 ops/training.py:65 2019-01-17 06:38:11.545159: step 17250, loss = 0.37310 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:38:12.829095 ops/training.py:65 2019-01-17 06:38:12.829022: step 17251, loss = 0.37491 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:38:14.112780 ops/training.py:65 2019-01-17 06:38:14.112635: step 17252, loss = 0.44063 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:38:15.405855 ops/training.py:65 2019-01-17 06:38:15.405750: step 17253, loss = 0.34296 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:38:16.698286 ops/training.py:65 2019-01-17 06:38:16.698211: step 17254, loss = 0.30581 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:38:17.983135 ops/training.py:65 2019-01-17 06:38:17.983069: step 17255, loss = 0.28044 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:38:19.272290 ops/training.py:65 2019-01-17 06:38:19.272185: step 17256, loss = 0.29625 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:38:20.560917 ops/training.py:65 2019-01-17 06:38:20.560768: step 17257, loss = 0.30041 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:38:21.853374 ops/training.py:65 2019-01-17 06:38:21.853300: step 17258, loss = 0.24785 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:38:23.143102 ops/training.py:65 2019-01-17 06:38:23.143009: step 17259, loss = 0.29163 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:38:24.427609 ops/training.py:65 2019-01-17 06:38:24.427539: step 17260, loss = 0.51388 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 06:38:25.712707 ops/training.py:65 2019-01-17 06:38:25.712601: step 17261, loss = 0.34294 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:38:26.998900 ops/training.py:65 2019-01-17 06:38:26.998790: step 17262, loss = 0.45259 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:38:28.289771 ops/training.py:65 2019-01-17 06:38:28.289632: step 17263, loss = 0.39233 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:38:29.574017 ops/training.py:65 2019-01-17 06:38:29.573948: step 17264, loss = 0.36904 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:38:30.859428 ops/training.py:65 2019-01-17 06:38:30.859325: step 17265, loss = 0.38244 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:38:32.148437 ops/training.py:65 2019-01-17 06:38:32.148366: step 17266, loss = 0.39842 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:38:33.438230 ops/training.py:65 2019-01-17 06:38:33.438161: step 17267, loss = 0.35529 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:38:34.726963 ops/training.py:65 2019-01-17 06:38:34.726898: step 17268, loss = 0.26960 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:38:36.014711 ops/training.py:65 2019-01-17 06:38:36.014638: step 17269, loss = 0.30673 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:38:37.298690 ops/training.py:65 2019-01-17 06:38:37.298622: step 17270, loss = 0.36138 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:38:38.582852 ops/training.py:65 2019-01-17 06:38:38.582790: step 17271, loss = 0.35232 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:38:39.866408 ops/training.py:65 2019-01-17 06:38:39.866299: step 17272, loss = 0.32372 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:38:41.158964 ops/training.py:65 2019-01-17 06:38:41.158864: step 17273, loss = 0.39541 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:38:42.449766 ops/training.py:65 2019-01-17 06:38:42.449694: step 17274, loss = 0.31871 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:38:43.734461 ops/training.py:65 2019-01-17 06:38:43.734390: step 17275, loss = 0.29788 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:38:45.024968 ops/training.py:65 2019-01-17 06:38:45.024863: step 17276, loss = 0.39563 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:38:46.316201 ops/training.py:65 2019-01-17 06:38:46.316139: step 17277, loss = 0.38047 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:38:47.605897 ops/training.py:65 2019-01-17 06:38:47.605828: step 17278, loss = 0.28583 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:38:48.890027 ops/training.py:65 2019-01-17 06:38:48.889957: step 17279, loss = 0.37733 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:38:50.173493 ops/training.py:65 2019-01-17 06:38:50.173393: step 17280, loss = 0.32050 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:38:51.466071 ops/training.py:65 2019-01-17 06:38:51.465965: step 17281, loss = 0.37458 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:38:52.758207 ops/training.py:65 2019-01-17 06:38:52.758133: step 17282, loss = 0.32877 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:38:54.047400 ops/training.py:65 2019-01-17 06:38:54.047306: step 17283, loss = 0.27776 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:38:55.336387 ops/training.py:65 2019-01-17 06:38:55.336310: step 17284, loss = 0.24551 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:38:56.621887 ops/training.py:65 2019-01-17 06:38:56.621816: step 17285, loss = 0.31252 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:38:57.911451 ops/training.py:65 2019-01-17 06:38:57.911370: step 17286, loss = 0.28231 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:38:59.201270 ops/training.py:65 2019-01-17 06:38:59.201204: step 17287, loss = 0.33346 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:39:00.485608 ops/training.py:65 2019-01-17 06:39:00.485545: step 17288, loss = 0.37923 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:39:01.770289 ops/training.py:65 2019-01-17 06:39:01.770188: step 17289, loss = 0.35036 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:39:03.062349 ops/training.py:65 2019-01-17 06:39:03.062252: step 17290, loss = 0.32681 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:39:04.350956 ops/training.py:65 2019-01-17 06:39:04.350863: step 17291, loss = 0.37570 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:39:05.639478 ops/training.py:65 2019-01-17 06:39:05.639381: step 17292, loss = 0.32472 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:39:06.928584 ops/training.py:65 2019-01-17 06:39:06.928512: step 17293, loss = 0.31507 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:39:08.217503 ops/training.py:65 2019-01-17 06:39:08.217426: step 17294, loss = 0.36071 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:39:09.511693 ops/training.py:65 2019-01-17 06:39:09.511626: step 17295, loss = 0.28735 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:39:10.802943 ops/training.py:65 2019-01-17 06:39:10.802874: step 17296, loss = 0.30715 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:39:12.091056 ops/training.py:65 2019-01-17 06:39:12.090965: step 17297, loss = 0.30386 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:39:13.381278 ops/training.py:65 2019-01-17 06:39:13.381188: step 17298, loss = 0.36384 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:39:14.664354 ops/training.py:65 2019-01-17 06:39:14.664287: step 17299, loss = 0.29572 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:39:15.947883 ops/training.py:65 2019-01-17 06:39:15.947783: step 17300, loss = 0.33832 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:39:17.239712 ops/training.py:65 2019-01-17 06:39:17.239619: step 17301, loss = 0.41794 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:39:18.530293 ops/training.py:65 2019-01-17 06:39:18.530219: step 17302, loss = 0.39871 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:39:19.819063 ops/training.py:65 2019-01-17 06:39:19.818988: step 17303, loss = 0.31507 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:39:21.108593 ops/training.py:65 2019-01-17 06:39:21.108510: step 17304, loss = 0.36837 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:39:22.392532 ops/training.py:65 2019-01-17 06:39:22.392454: step 17305, loss = 0.33379 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:39:23.682076 ops/training.py:65 2019-01-17 06:39:23.682011: step 17306, loss = 0.40229 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:39:24.971055 ops/training.py:65 2019-01-17 06:39:24.970962: step 17307, loss = 0.25338 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:39:26.257045 ops/training.py:65 2019-01-17 06:39:26.256979: step 17308, loss = 0.32305 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:39:27.544279 ops/training.py:65 2019-01-17 06:39:27.544200: step 17309, loss = 0.33915 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:39:28.828641 ops/training.py:65 2019-01-17 06:39:28.828581: step 17310, loss = 0.34186 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:39:30.113124 ops/training.py:65 2019-01-17 06:39:30.113031: step 17311, loss = 0.32070 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:39:31.399977 ops/training.py:65 2019-01-17 06:39:31.399866: step 17312, loss = 0.32790 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:39:32.684354 ops/training.py:65 2019-01-17 06:39:32.684263: step 17313, loss = 0.40081 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:39:33.977539 ops/training.py:65 2019-01-17 06:39:33.977443: step 17314, loss = 0.38089 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:39:35.264052 ops/training.py:65 2019-01-17 06:39:35.263977: step 17315, loss = 0.35628 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:39:36.550487 ops/training.py:65 2019-01-17 06:39:36.550379: step 17316, loss = 0.31512 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:39:37.844516 ops/training.py:65 2019-01-17 06:39:37.844415: step 17317, loss = 0.29812 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:39:39.133502 ops/training.py:65 2019-01-17 06:39:39.133438: step 17318, loss = 0.27576 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:39:40.422236 ops/training.py:65 2019-01-17 06:39:40.422170: step 17319, loss = 0.38958 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:39:41.705803 ops/training.py:65 2019-01-17 06:39:41.705738: step 17320, loss = 0.31160 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:39:42.995564 ops/training.py:65 2019-01-17 06:39:42.995461: step 17321, loss = 0.33545 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:39:44.284665 ops/training.py:65 2019-01-17 06:39:44.284569: step 17322, loss = 0.34512 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:39:45.575792 ops/training.py:65 2019-01-17 06:39:45.575721: step 17323, loss = 0.34516 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:39:46.869029 ops/training.py:65 2019-01-17 06:39:46.868928: step 17324, loss = 0.37629 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:39:48.160701 ops/training.py:65 2019-01-17 06:39:48.160623: step 17325, loss = 0.33710 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:39:49.448786 ops/training.py:65 2019-01-17 06:39:49.448718: step 17326, loss = 0.36629 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:39:50.733512 ops/training.py:65 2019-01-17 06:39:50.733446: step 17327, loss = 0.37896 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:39:52.018108 ops/training.py:65 2019-01-17 06:39:52.018033: step 17328, loss = 0.29284 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:39:53.297819 ops/training.py:65 2019-01-17 06:39:53.297729: step 17329, loss = 0.32455 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:39:54.588522 ops/training.py:65 2019-01-17 06:39:54.588420: step 17330, loss = 0.47983 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:39:55.876531 ops/training.py:65 2019-01-17 06:39:55.876471: step 17331, loss = 0.33329 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:39:57.160983 ops/training.py:65 2019-01-17 06:39:57.160908: step 17332, loss = 0.27727 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:39:58.448597 ops/training.py:65 2019-01-17 06:39:58.448488: step 17333, loss = 0.36434 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:39:59.732182 ops/training.py:65 2019-01-17 06:39:59.732080: step 17334, loss = 0.43650 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.75
I4672 2019-01-17 06:40:01.024899 ops/training.py:65 2019-01-17 06:40:01.024793: step 17335, loss = 0.45538 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 06:40:02.311671 ops/training.py:65 2019-01-17 06:40:02.311598: step 17336, loss = 0.39078 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:40:03.601323 ops/training.py:65 2019-01-17 06:40:03.601235: step 17337, loss = 0.38359 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:40:04.893708 ops/training.py:65 2019-01-17 06:40:04.893598: step 17338, loss = 0.36516 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:40:06.182593 ops/training.py:65 2019-01-17 06:40:06.182526: step 17339, loss = 0.36360 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:40:07.467679 ops/training.py:65 2019-01-17 06:40:07.467616: step 17340, loss = 0.28504 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:40:08.756086 ops/training.py:65 2019-01-17 06:40:08.755939: step 17341, loss = 0.29698 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:40:10.045026 ops/training.py:65 2019-01-17 06:40:10.044961: step 17342, loss = 0.27171 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:40:11.332913 ops/training.py:65 2019-01-17 06:40:11.332844: step 17343, loss = 0.34305 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:40:12.621519 ops/training.py:65 2019-01-17 06:40:12.621454: step 17344, loss = 0.29243 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:40:13.908818 ops/training.py:65 2019-01-17 06:40:13.908734: step 17345, loss = 0.33359 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:40:15.197004 ops/training.py:65 2019-01-17 06:40:15.196893: step 17346, loss = 0.30158 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:40:16.478480 ops/training.py:65 2019-01-17 06:40:16.478367: step 17347, loss = 0.36523 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:40:17.766652 ops/training.py:65 2019-01-17 06:40:17.766602: step 17348, loss = 0.35774 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:40:19.052500 ops/training.py:65 2019-01-17 06:40:19.052401: step 17349, loss = 0.32034 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:40:20.340432 ops/training.py:65 2019-01-17 06:40:20.340321: step 17350, loss = 0.30653 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:40:21.630662 ops/training.py:65 2019-01-17 06:40:21.630565: step 17351, loss = 0.36268 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:40:22.920447 ops/training.py:65 2019-01-17 06:40:22.920378: step 17352, loss = 0.30672 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:40:24.204861 ops/training.py:65 2019-01-17 06:40:24.204796: step 17353, loss = 0.33564 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:40:25.489268 ops/training.py:65 2019-01-17 06:40:25.489202: step 17354, loss = 0.37937 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:40:26.778010 ops/training.py:65 2019-01-17 06:40:26.777936: step 17355, loss = 0.39831 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:40:28.068718 ops/training.py:65 2019-01-17 06:40:28.068649: step 17356, loss = 0.33953 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:40:29.352085 ops/training.py:65 2019-01-17 06:40:29.352024: step 17357, loss = 0.25391 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:40:30.637235 ops/training.py:65 2019-01-17 06:40:30.637125: step 17358, loss = 0.29772 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:40:31.921665 ops/training.py:65 2019-01-17 06:40:31.921583: step 17359, loss = 0.34677 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:40:33.206278 ops/training.py:65 2019-01-17 06:40:33.206212: step 17360, loss = 0.35217 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:40:34.489755 ops/training.py:65 2019-01-17 06:40:34.489602: step 17361, loss = 0.33793 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:40:35.782189 ops/training.py:65 2019-01-17 06:40:35.782082: step 17362, loss = 0.36464 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:40:37.062357 ops/training.py:65 2019-01-17 06:40:37.062287: step 17363, loss = 0.36712 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:40:38.347018 ops/training.py:65 2019-01-17 06:40:38.346908: step 17364, loss = 0.36015 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:40:39.638245 ops/training.py:65 2019-01-17 06:40:39.638136: step 17365, loss = 0.31353 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:40:40.928011 ops/training.py:65 2019-01-17 06:40:40.927943: step 17366, loss = 0.39745 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:40:42.212163 ops/training.py:65 2019-01-17 06:40:42.212091: step 17367, loss = 0.38173 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:40:43.503335 ops/training.py:65 2019-01-17 06:40:43.503233: step 17368, loss = 0.26808 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:40:44.790827 ops/training.py:65 2019-01-17 06:40:44.790765: step 17369, loss = 0.43135 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:40:46.074888 ops/training.py:65 2019-01-17 06:40:46.074824: step 17370, loss = 0.41820 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:40:47.359169 ops/training.py:65 2019-01-17 06:40:47.359106: step 17371, loss = 0.27820 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:40:48.644730 ops/training.py:65 2019-01-17 06:40:48.644619: step 17372, loss = 0.29197 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:40:49.934311 ops/training.py:65 2019-01-17 06:40:49.934162: step 17373, loss = 0.30288 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:40:51.225403 ops/training.py:65 2019-01-17 06:40:51.225326: step 17374, loss = 0.34431 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:40:52.514283 ops/training.py:65 2019-01-17 06:40:52.514209: step 17375, loss = 0.33708 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:40:53.802723 ops/training.py:65 2019-01-17 06:40:53.802642: step 17376, loss = 0.31233 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:40:55.090889 ops/training.py:65 2019-01-17 06:40:55.090810: step 17377, loss = 0.30170 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:40:56.378873 ops/training.py:65 2019-01-17 06:40:56.378765: step 17378, loss = 0.35689 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:40:57.668357 ops/training.py:65 2019-01-17 06:40:57.668280: step 17379, loss = 0.26426 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:40:58.952924 ops/training.py:65 2019-01-17 06:40:58.952834: step 17380, loss = 0.33227 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:41:00.241687 ops/training.py:65 2019-01-17 06:41:00.241618: step 17381, loss = 0.32567 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:41:01.531389 ops/training.py:65 2019-01-17 06:41:01.531300: step 17382, loss = 0.33763 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:41:02.815946 ops/training.py:65 2019-01-17 06:41:02.815878: step 17383, loss = 0.32872 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:41:04.100046 ops/training.py:65 2019-01-17 06:41:04.099980: step 17384, loss = 0.24611 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:41:05.382509 ops/training.py:65 2019-01-17 06:41:05.382398: step 17385, loss = 0.37358 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:41:06.674759 ops/training.py:65 2019-01-17 06:41:06.674656: step 17386, loss = 0.30987 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:41:07.966498 ops/training.py:65 2019-01-17 06:41:07.966430: step 17387, loss = 0.37602 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:41:09.256009 ops/training.py:65 2019-01-17 06:41:09.255943: step 17388, loss = 0.34689 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:41:10.535806 ops/training.py:65 2019-01-17 06:41:10.535721: step 17389, loss = 0.34598 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:41:11.817941 ops/training.py:65 2019-01-17 06:41:11.817842: step 17390, loss = 0.33865 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:41:13.102239 ops/training.py:65 2019-01-17 06:41:13.102136: step 17391, loss = 0.28469 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:41:14.385781 ops/training.py:65 2019-01-17 06:41:14.385674: step 17392, loss = 0.29267 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:41:15.670800 ops/training.py:65 2019-01-17 06:41:15.670692: step 17393, loss = 0.31664 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:41:16.961196 ops/training.py:65 2019-01-17 06:41:16.961100: step 17394, loss = 0.36838 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:41:18.247171 ops/training.py:65 2019-01-17 06:41:18.247109: step 17395, loss = 0.33433 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:41:19.534088 ops/training.py:65 2019-01-17 06:41:19.534017: step 17396, loss = 0.33558 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:41:20.822016 ops/training.py:65 2019-01-17 06:41:20.821930: step 17397, loss = 0.29287 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:41:22.110281 ops/training.py:65 2019-01-17 06:41:22.110214: step 17398, loss = 0.31200 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:41:23.394499 ops/training.py:65 2019-01-17 06:41:23.394434: step 17399, loss = 0.31028 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:41:24.681127 ops/training.py:65 2019-01-17 06:41:24.681036: step 17400, loss = 0.30661 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:41:25.969532 ops/training.py:65 2019-01-17 06:41:25.969469: step 17401, loss = 0.27057 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:41:27.258599 ops/training.py:65 2019-01-17 06:41:27.258532: step 17402, loss = 0.37342 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:41:28.540267 ops/training.py:65 2019-01-17 06:41:28.540198: step 17403, loss = 0.28763 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:41:29.823732 ops/training.py:65 2019-01-17 06:41:29.823656: step 17404, loss = 0.37708 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:41:31.114870 ops/training.py:65 2019-01-17 06:41:31.114768: step 17405, loss = 0.32503 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:41:32.406350 ops/training.py:65 2019-01-17 06:41:32.406267: step 17406, loss = 0.37076 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:41:33.696672 ops/training.py:65 2019-01-17 06:41:33.696605: step 17407, loss = 0.32876 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:41:34.987009 ops/training.py:65 2019-01-17 06:41:34.986938: step 17408, loss = 0.25352 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:41:36.275998 ops/training.py:65 2019-01-17 06:41:36.275933: step 17409, loss = 0.26708 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:41:37.565225 ops/training.py:65 2019-01-17 06:41:37.565135: step 17410, loss = 0.34284 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:41:38.853196 ops/training.py:65 2019-01-17 06:41:38.853128: step 17411, loss = 0.41340 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:41:40.142102 ops/training.py:65 2019-01-17 06:41:40.142007: step 17412, loss = 0.30793 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:41:41.431941 ops/training.py:65 2019-01-17 06:41:41.431853: step 17413, loss = 0.37745 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:41:42.721556 ops/training.py:65 2019-01-17 06:41:42.721490: step 17414, loss = 0.35545 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:41:44.010330 ops/training.py:65 2019-01-17 06:41:44.010259: step 17415, loss = 0.29328 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:41:45.299318 ops/training.py:65 2019-01-17 06:41:45.299245: step 17416, loss = 0.29285 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:41:46.587935 ops/training.py:65 2019-01-17 06:41:46.587850: step 17417, loss = 0.30497 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:41:47.872771 ops/training.py:65 2019-01-17 06:41:47.872683: step 17418, loss = 0.36884 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:41:49.156515 ops/training.py:65 2019-01-17 06:41:49.156438: step 17419, loss = 0.31239 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:41:50.447920 ops/training.py:65 2019-01-17 06:41:50.447814: step 17420, loss = 0.28402 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:41:51.737969 ops/training.py:65 2019-01-17 06:41:51.737901: step 17421, loss = 0.32239 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:41:53.020731 ops/training.py:65 2019-01-17 06:41:53.020664: step 17422, loss = 0.26791 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:41:54.304688 ops/training.py:65 2019-01-17 06:41:54.304605: step 17423, loss = 0.30603 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:41:55.596557 ops/training.py:65 2019-01-17 06:41:55.596446: step 17424, loss = 0.30383 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:41:56.887899 ops/training.py:65 2019-01-17 06:41:56.887808: step 17425, loss = 0.28514 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:41:58.172230 ops/training.py:65 2019-01-17 06:41:58.172169: step 17426, loss = 0.32505 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:41:59.462514 ops/training.py:65 2019-01-17 06:41:59.462417: step 17427, loss = 0.25392 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:42:00.752335 ops/training.py:65 2019-01-17 06:42:00.752268: step 17428, loss = 0.34353 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:42:02.036494 ops/training.py:65 2019-01-17 06:42:02.036416: step 17429, loss = 0.30750 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:42:03.319778 ops/training.py:65 2019-01-17 06:42:03.319681: step 17430, loss = 0.28995 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:42:04.611757 ops/training.py:65 2019-01-17 06:42:04.611653: step 17431, loss = 0.39136 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:42:05.902910 ops/training.py:65 2019-01-17 06:42:05.902839: step 17432, loss = 0.27558 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:42:07.190861 ops/training.py:65 2019-01-17 06:42:07.190788: step 17433, loss = 0.29576 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:42:08.479440 ops/training.py:65 2019-01-17 06:42:08.479372: step 17434, loss = 0.32171 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:42:09.762490 ops/training.py:65 2019-01-17 06:42:09.762420: step 17435, loss = 0.31387 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:42:11.054283 ops/training.py:65 2019-01-17 06:42:11.054174: step 17436, loss = 0.32056 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:42:12.340187 ops/training.py:65 2019-01-17 06:42:12.340109: step 17437, loss = 0.32989 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:42:13.631670 ops/training.py:65 2019-01-17 06:42:13.631530: step 17438, loss = 0.23815 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:42:14.922250 ops/training.py:65 2019-01-17 06:42:14.922181: step 17439, loss = 0.31508 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:42:16.210624 ops/training.py:65 2019-01-17 06:42:16.210553: step 17440, loss = 0.35698 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:42:17.498940 ops/training.py:65 2019-01-17 06:42:17.498876: step 17441, loss = 0.32586 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:42:18.782853 ops/training.py:65 2019-01-17 06:42:18.782788: step 17442, loss = 0.34955 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:42:20.075292 ops/training.py:65 2019-01-17 06:42:20.075134: step 17443, loss = 0.34186 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:42:21.367374 ops/training.py:65 2019-01-17 06:42:21.367308: step 17444, loss = 0.39804 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:42:22.652714 ops/training.py:65 2019-01-17 06:42:22.652653: step 17445, loss = 0.28832 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:42:23.937632 ops/training.py:65 2019-01-17 06:42:23.937559: step 17446, loss = 0.31540 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:42:25.229110 ops/training.py:65 2019-01-17 06:42:25.229012: step 17447, loss = 0.29299 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:42:26.517348 ops/training.py:65 2019-01-17 06:42:26.517292: step 17448, loss = 0.32827 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:42:27.802137 ops/training.py:65 2019-01-17 06:42:27.802077: step 17449, loss = 0.31688 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:42:29.090857 ops/training.py:65 2019-01-17 06:42:29.090794: step 17450, loss = 0.33494 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:42:30.380227 ops/training.py:65 2019-01-17 06:42:30.380166: step 17451, loss = 0.33647 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:42:31.666826 ops/training.py:65 2019-01-17 06:42:31.666766: step 17452, loss = 0.34825 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:42:32.955036 ops/training.py:65 2019-01-17 06:42:32.954963: step 17453, loss = 0.37883 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:42:34.244001 ops/training.py:65 2019-01-17 06:42:34.243938: step 17454, loss = 0.37765 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:42:35.532019 ops/training.py:65 2019-01-17 06:42:35.531955: step 17455, loss = 0.32207 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:42:36.821145 ops/training.py:65 2019-01-17 06:42:36.821071: step 17456, loss = 0.35866 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:42:38.105083 ops/training.py:65 2019-01-17 06:42:38.105015: step 17457, loss = 0.24241 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:42:39.390111 ops/training.py:65 2019-01-17 06:42:39.390042: step 17458, loss = 0.23769 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:42:40.679386 ops/training.py:65 2019-01-17 06:42:40.679318: step 17459, loss = 0.31195 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:42:41.968698 ops/training.py:65 2019-01-17 06:42:41.968620: step 17460, loss = 0.26631 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:42:43.258212 ops/training.py:65 2019-01-17 06:42:43.258143: step 17461, loss = 0.29039 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:42:44.546499 ops/training.py:65 2019-01-17 06:42:44.546426: step 17462, loss = 0.34163 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:42:45.834015 ops/training.py:65 2019-01-17 06:42:45.833944: step 17463, loss = 0.38504 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:42:47.122249 ops/training.py:65 2019-01-17 06:42:47.122162: step 17464, loss = 0.34514 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:42:48.406506 ops/training.py:65 2019-01-17 06:42:48.406434: step 17465, loss = 0.30333 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:42:49.697755 ops/training.py:65 2019-01-17 06:42:49.697646: step 17466, loss = 0.33569 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:42:50.989012 ops/training.py:65 2019-01-17 06:42:50.988940: step 17467, loss = 0.28265 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:42:52.273589 ops/training.py:65 2019-01-17 06:42:52.273527: step 17468, loss = 0.27806 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:42:53.558427 ops/training.py:65 2019-01-17 06:42:53.558340: step 17469, loss = 0.29621 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:42:54.849033 ops/training.py:65 2019-01-17 06:42:54.848933: step 17470, loss = 0.30934 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:42:56.138672 ops/training.py:65 2019-01-17 06:42:56.138586: step 17471, loss = 0.34346 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:42:57.427497 ops/training.py:65 2019-01-17 06:42:57.427429: step 17472, loss = 0.37948 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:42:58.711432 ops/training.py:65 2019-01-17 06:42:58.711370: step 17473, loss = 0.27213 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:43:00.001902 ops/training.py:65 2019-01-17 06:43:00.001805: step 17474, loss = 0.30126 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:43:01.291570 ops/training.py:65 2019-01-17 06:43:01.291505: step 17475, loss = 0.36217 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:43:02.580198 ops/training.py:65 2019-01-17 06:43:02.580126: step 17476, loss = 0.24267 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:43:03.868502 ops/training.py:65 2019-01-17 06:43:03.868432: step 17477, loss = 0.27372 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:43:05.157186 ops/training.py:65 2019-01-17 06:43:05.157091: step 17478, loss = 0.31760 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:43:06.446758 ops/training.py:65 2019-01-17 06:43:06.446689: step 17479, loss = 0.34447 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:43:07.733808 ops/training.py:65 2019-01-17 06:43:07.733726: step 17480, loss = 0.34980 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:43:09.023081 ops/training.py:65 2019-01-17 06:43:09.023011: step 17481, loss = 0.37832 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:43:10.307395 ops/training.py:65 2019-01-17 06:43:10.307330: step 17482, loss = 0.29071 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:43:11.590346 ops/training.py:65 2019-01-17 06:43:11.590271: step 17483, loss = 0.33938 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:43:12.883090 ops/training.py:65 2019-01-17 06:43:12.882946: step 17484, loss = 0.39772 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:43:14.169943 ops/training.py:65 2019-01-17 06:43:14.169858: step 17485, loss = 0.26384 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:43:15.459934 ops/training.py:65 2019-01-17 06:43:15.459870: step 17486, loss = 0.34460 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:43:16.750395 ops/training.py:65 2019-01-17 06:43:16.750310: step 17487, loss = 0.32131 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:43:18.033599 ops/training.py:65 2019-01-17 06:43:18.033535: step 17488, loss = 0.35732 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:43:19.317499 ops/training.py:65 2019-01-17 06:43:19.317417: step 17489, loss = 0.33989 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:43:20.609450 ops/training.py:65 2019-01-17 06:43:20.609306: step 17490, loss = 0.33183 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:43:21.900964 ops/training.py:65 2019-01-17 06:43:21.900880: step 17491, loss = 0.33591 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:43:23.190733 ops/training.py:65 2019-01-17 06:43:23.190658: step 17492, loss = 0.33013 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:43:24.475343 ops/training.py:65 2019-01-17 06:43:24.475275: step 17493, loss = 0.38525 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:43:25.758603 ops/training.py:65 2019-01-17 06:43:25.758493: step 17494, loss = 0.33867 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:43:27.052673 ops/training.py:65 2019-01-17 06:43:27.052515: step 17495, loss = 0.38850 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:43:28.341677 ops/training.py:65 2019-01-17 06:43:28.341602: step 17496, loss = 0.31718 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:43:29.630265 ops/training.py:65 2019-01-17 06:43:29.630196: step 17497, loss = 0.39562 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:43:30.918940 ops/training.py:65 2019-01-17 06:43:30.918846: step 17498, loss = 0.46206 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.71875
I4672 2019-01-17 06:43:32.207995 ops/training.py:65 2019-01-17 06:43:32.207928: step 17499, loss = 0.31096 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:43:33.496509 ops/training.py:65 2019-01-17 06:43:33.496426: step 17500, loss = 0.39269 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:43:34.785806 ops/training.py:65 2019-01-17 06:43:34.785742: step 17501, loss = 0.36208 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:43:36.071317 ops/training.py:65 2019-01-17 06:43:36.071254: step 17502, loss = 0.40566 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:43:37.351915 ops/training.py:65 2019-01-17 06:43:37.351840: step 17503, loss = 0.39903 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:43:38.635348 ops/training.py:65 2019-01-17 06:43:38.635193: step 17504, loss = 0.30031 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:43:39.923215 ops/training.py:65 2019-01-17 06:43:39.923053: step 17505, loss = 0.33152 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:43:41.209066 ops/training.py:65 2019-01-17 06:43:41.208955: step 17506, loss = 0.35715 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:43:42.496493 ops/training.py:65 2019-01-17 06:43:42.496386: step 17507, loss = 0.26830 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:43:43.787414 ops/training.py:65 2019-01-17 06:43:43.787265: step 17508, loss = 0.29961 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:43:45.074395 ops/training.py:65 2019-01-17 06:43:45.074325: step 17509, loss = 0.31221 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:43:46.360950 ops/training.py:65 2019-01-17 06:43:46.360841: step 17510, loss = 0.39546 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:43:47.646378 ops/training.py:65 2019-01-17 06:43:47.646283: step 17511, loss = 0.35940 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:43:48.933682 ops/training.py:65 2019-01-17 06:43:48.933575: step 17512, loss = 0.36477 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:43:50.222945 ops/training.py:65 2019-01-17 06:43:50.222832: step 17513, loss = 0.29877 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:43:51.508404 ops/training.py:65 2019-01-17 06:43:51.508296: step 17514, loss = 0.30753 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:43:52.801318 ops/training.py:65 2019-01-17 06:43:52.801210: step 17515, loss = 0.33946 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:43:54.094805 ops/training.py:65 2019-01-17 06:43:54.094729: step 17516, loss = 0.34952 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:43:55.379290 ops/training.py:65 2019-01-17 06:43:55.379215: step 17517, loss = 0.33492 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:43:56.672085 ops/training.py:65 2019-01-17 06:43:56.671985: step 17518, loss = 0.39066 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:43:57.962524 ops/training.py:65 2019-01-17 06:43:57.962451: step 17519, loss = 0.38832 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:43:59.249132 ops/training.py:65 2019-01-17 06:43:59.249064: step 17520, loss = 0.32730 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:44:00.537319 ops/training.py:65 2019-01-17 06:44:00.537253: step 17521, loss = 0.39018 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:44:01.822030 ops/training.py:65 2019-01-17 06:44:01.821921: step 17522, loss = 0.35137 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:44:03.108095 ops/training.py:65 2019-01-17 06:44:03.107960: step 17523, loss = 0.25796 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:44:04.399888 ops/training.py:65 2019-01-17 06:44:04.399776: step 17524, loss = 0.29822 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:44:05.690171 ops/training.py:65 2019-01-17 06:44:05.690104: step 17525, loss = 0.38009 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:44:06.974002 ops/training.py:65 2019-01-17 06:44:06.973940: step 17526, loss = 0.45975 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.6875
I4672 2019-01-17 06:44:08.259451 ops/training.py:65 2019-01-17 06:44:08.259385: step 17527, loss = 0.31002 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:44:09.551420 ops/training.py:65 2019-01-17 06:44:09.551310: step 17528, loss = 0.37738 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:44:10.838473 ops/training.py:65 2019-01-17 06:44:10.838372: step 17529, loss = 0.38802 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:44:12.124521 ops/training.py:65 2019-01-17 06:44:12.124439: step 17530, loss = 0.33902 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:44:13.416001 ops/training.py:65 2019-01-17 06:44:13.415902: step 17531, loss = 0.27763 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:44:14.707918 ops/training.py:65 2019-01-17 06:44:14.707846: step 17532, loss = 0.30315 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:44:15.998528 ops/training.py:65 2019-01-17 06:44:15.998444: step 17533, loss = 0.35388 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:44:17.286820 ops/training.py:65 2019-01-17 06:44:17.286733: step 17534, loss = 0.30211 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:44:18.571223 ops/training.py:65 2019-01-17 06:44:18.571152: step 17535, loss = 0.28907 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:44:19.856748 ops/training.py:65 2019-01-17 06:44:19.856643: step 17536, loss = 0.25690 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:44:21.150297 ops/training.py:65 2019-01-17 06:44:21.150190: step 17537, loss = 0.26994 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:44:22.437352 ops/training.py:65 2019-01-17 06:44:22.437272: step 17538, loss = 0.38312 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:44:23.729482 ops/training.py:65 2019-01-17 06:44:23.729379: step 17539, loss = 0.34012 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:44:25.016574 ops/training.py:65 2019-01-17 06:44:25.016485: step 17540, loss = 0.31451 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:44:26.305830 ops/training.py:65 2019-01-17 06:44:26.305763: step 17541, loss = 0.43243 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 06:44:27.589124 ops/training.py:65 2019-01-17 06:44:27.589044: step 17542, loss = 0.38234 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:44:28.878175 ops/training.py:65 2019-01-17 06:44:28.878062: step 17543, loss = 0.35832 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:44:30.162839 ops/training.py:65 2019-01-17 06:44:30.162736: step 17544, loss = 0.31282 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:44:31.453987 ops/training.py:65 2019-01-17 06:44:31.453831: step 17545, loss = 0.33902 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:44:32.745090 ops/training.py:65 2019-01-17 06:44:32.745007: step 17546, loss = 0.39236 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:44:34.025447 ops/training.py:65 2019-01-17 06:44:34.025367: step 17547, loss = 0.35593 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:44:35.317174 ops/training.py:65 2019-01-17 06:44:35.317032: step 17548, loss = 0.39696 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:44:36.607736 ops/training.py:65 2019-01-17 06:44:36.607671: step 17549, loss = 0.32813 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:44:37.892839 ops/training.py:65 2019-01-17 06:44:37.892751: step 17550, loss = 0.31238 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:44:39.176814 ops/training.py:65 2019-01-17 06:44:39.176703: step 17551, loss = 0.29630 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:44:40.468308 ops/training.py:65 2019-01-17 06:44:40.468199: step 17552, loss = 0.31591 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:44:41.756541 ops/training.py:65 2019-01-17 06:44:41.756472: step 17553, loss = 0.29408 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:44:43.045694 ops/training.py:65 2019-01-17 06:44:43.045629: step 17554, loss = 0.40271 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:44:44.335062 ops/training.py:65 2019-01-17 06:44:44.334990: step 17555, loss = 0.29672 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:44:45.624192 ops/training.py:65 2019-01-17 06:44:45.624123: step 17556, loss = 0.33585 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:44:46.913327 ops/training.py:65 2019-01-17 06:44:46.913259: step 17557, loss = 0.30070 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:44:48.201583 ops/training.py:65 2019-01-17 06:44:48.201515: step 17558, loss = 0.28166 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:44:49.489487 ops/training.py:65 2019-01-17 06:44:49.489420: step 17559, loss = 0.34115 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:44:50.772785 ops/training.py:65 2019-01-17 06:44:50.772712: step 17560, loss = 0.31368 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:44:52.061569 ops/training.py:65 2019-01-17 06:44:52.061464: step 17561, loss = 0.33365 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:44:53.352438 ops/training.py:65 2019-01-17 06:44:53.352337: step 17562, loss = 0.33784 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:44:54.643632 ops/training.py:65 2019-01-17 06:44:54.643564: step 17563, loss = 0.29434 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:44:55.927170 ops/training.py:65 2019-01-17 06:44:55.927066: step 17564, loss = 0.31838 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:44:57.216137 ops/training.py:65 2019-01-17 06:44:57.215975: step 17565, loss = 0.31035 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:44:58.501344 ops/training.py:65 2019-01-17 06:44:58.501239: step 17566, loss = 0.31722 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:44:59.785671 ops/training.py:65 2019-01-17 06:44:59.785562: step 17567, loss = 0.33606 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:45:01.070444 ops/training.py:65 2019-01-17 06:45:01.070290: step 17568, loss = 0.32987 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:45:02.357905 ops/training.py:65 2019-01-17 06:45:02.357790: step 17569, loss = 0.32705 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:45:03.641756 ops/training.py:65 2019-01-17 06:45:03.641658: step 17570, loss = 0.36396 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:45:04.922628 ops/training.py:65 2019-01-17 06:45:04.922520: step 17571, loss = 0.36147 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:45:06.206973 ops/training.py:65 2019-01-17 06:45:06.206864: step 17572, loss = 0.33731 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:45:07.494064 ops/training.py:65 2019-01-17 06:45:07.493956: step 17573, loss = 0.27748 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:45:08.778244 ops/training.py:65 2019-01-17 06:45:08.778138: step 17574, loss = 0.27714 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:45:10.065966 ops/training.py:65 2019-01-17 06:45:10.065854: step 17575, loss = 0.34594 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:45:11.350118 ops/training.py:65 2019-01-17 06:45:11.350021: step 17576, loss = 0.26791 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:45:12.630804 ops/training.py:65 2019-01-17 06:45:12.630696: step 17577, loss = 0.28002 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:45:13.910912 ops/training.py:65 2019-01-17 06:45:13.910753: step 17578, loss = 0.31729 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:45:15.198027 ops/training.py:65 2019-01-17 06:45:15.197919: step 17579, loss = 0.37540 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:45:16.481620 ops/training.py:65 2019-01-17 06:45:16.481513: step 17580, loss = 0.31331 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:45:17.772853 ops/training.py:65 2019-01-17 06:45:17.772756: step 17581, loss = 0.29589 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:45:19.058235 ops/training.py:65 2019-01-17 06:45:19.058158: step 17582, loss = 0.34761 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:45:20.347073 ops/training.py:65 2019-01-17 06:45:20.347008: step 17583, loss = 0.25481 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:45:21.636913 ops/training.py:65 2019-01-17 06:45:21.636842: step 17584, loss = 0.31915 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:45:22.925161 ops/training.py:65 2019-01-17 06:45:22.925081: step 17585, loss = 0.30974 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:45:24.209696 ops/training.py:65 2019-01-17 06:45:24.209603: step 17586, loss = 0.29965 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:45:25.499445 ops/training.py:65 2019-01-17 06:45:25.499288: step 17587, loss = 0.33247 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:45:26.791651 ops/training.py:65 2019-01-17 06:45:26.791574: step 17588, loss = 0.28962 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:45:28.081178 ops/training.py:65 2019-01-17 06:45:28.081097: step 17589, loss = 0.26349 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:45:29.371114 ops/training.py:65 2019-01-17 06:45:29.371023: step 17590, loss = 0.29858 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:45:30.658793 ops/training.py:65 2019-01-17 06:45:30.658729: step 17591, loss = 0.33839 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:45:31.947318 ops/training.py:65 2019-01-17 06:45:31.947232: step 17592, loss = 0.35900 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:45:33.232351 ops/training.py:65 2019-01-17 06:45:33.232289: step 17593, loss = 0.34421 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:45:34.515932 ops/training.py:65 2019-01-17 06:45:34.515827: step 17594, loss = 0.29872 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:45:35.806665 ops/training.py:65 2019-01-17 06:45:35.806565: step 17595, loss = 0.32593 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:45:37.092154 ops/training.py:65 2019-01-17 06:45:37.092089: step 17596, loss = 0.32262 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:45:38.381522 ops/training.py:65 2019-01-17 06:45:38.381410: step 17597, loss = 0.29201 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:45:39.667956 ops/training.py:65 2019-01-17 06:45:39.667884: step 17598, loss = 0.27093 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:45:40.955527 ops/training.py:65 2019-01-17 06:45:40.955462: step 17599, loss = 0.31951 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:45:42.242572 ops/training.py:65 2019-01-17 06:45:42.242504: step 17600, loss = 0.36505 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:45:43.530796 ops/training.py:65 2019-01-17 06:45:43.530722: step 17601, loss = 0.29707 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:45:44.819557 ops/training.py:65 2019-01-17 06:45:44.819468: step 17602, loss = 0.26647 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:45:46.109135 ops/training.py:65 2019-01-17 06:45:46.109064: step 17603, loss = 0.34400 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:45:47.392699 ops/training.py:65 2019-01-17 06:45:47.392584: step 17604, loss = 0.36409 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:45:48.676439 ops/training.py:65 2019-01-17 06:45:48.676336: step 17605, loss = 0.30933 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:45:49.960643 ops/training.py:65 2019-01-17 06:45:49.960533: step 17606, loss = 0.30632 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:45:51.252521 ops/training.py:65 2019-01-17 06:45:51.252416: step 17607, loss = 0.25466 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:45:52.543884 ops/training.py:65 2019-01-17 06:45:52.543814: step 17608, loss = 0.32595 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:45:53.833068 ops/training.py:65 2019-01-17 06:45:53.832996: step 17609, loss = 0.27864 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:45:55.120792 ops/training.py:65 2019-01-17 06:45:55.120727: step 17610, loss = 0.33733 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:45:56.410244 ops/training.py:65 2019-01-17 06:45:56.410138: step 17611, loss = 0.35218 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:45:57.699833 ops/training.py:65 2019-01-17 06:45:57.699761: step 17612, loss = 0.30705 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:45:58.988046 ops/training.py:65 2019-01-17 06:45:58.987959: step 17613, loss = 0.31135 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:46:00.276905 ops/training.py:65 2019-01-17 06:46:00.276809: step 17614, loss = 0.31734 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:46:01.566739 ops/training.py:65 2019-01-17 06:46:01.566668: step 17615, loss = 0.27593 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:46:02.855217 ops/training.py:65 2019-01-17 06:46:02.855146: step 17616, loss = 0.26472 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:46:04.143109 ops/training.py:65 2019-01-17 06:46:04.143041: step 17617, loss = 0.24834 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:46:05.432291 ops/training.py:65 2019-01-17 06:46:05.432203: step 17618, loss = 0.36421 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:46:06.720401 ops/training.py:65 2019-01-17 06:46:06.720330: step 17619, loss = 0.34919 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:46:08.004144 ops/training.py:65 2019-01-17 06:46:08.004084: step 17620, loss = 0.24575 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:46:09.292291 ops/training.py:65 2019-01-17 06:46:09.292231: step 17621, loss = 0.33248 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:46:10.581600 ops/training.py:65 2019-01-17 06:46:10.581531: step 17622, loss = 0.27113 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:46:11.869560 ops/training.py:65 2019-01-17 06:46:11.869480: step 17623, loss = 0.31939 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:46:13.153205 ops/training.py:65 2019-01-17 06:46:13.153131: step 17624, loss = 0.38780 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:46:14.442581 ops/training.py:65 2019-01-17 06:46:14.442521: step 17625, loss = 0.33147 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:46:15.730995 ops/training.py:65 2019-01-17 06:46:15.730922: step 17626, loss = 0.27737 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:46:17.025223 ops/training.py:65 2019-01-17 06:46:17.025154: step 17627, loss = 0.32877 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:46:18.312721 ops/training.py:65 2019-01-17 06:46:18.312652: step 17628, loss = 0.32263 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:46:19.601197 ops/training.py:65 2019-01-17 06:46:19.601126: step 17629, loss = 0.35715 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:46:20.891038 ops/training.py:65 2019-01-17 06:46:20.890973: step 17630, loss = 0.29478 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:46:22.178980 ops/training.py:65 2019-01-17 06:46:22.178917: step 17631, loss = 0.33815 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:46:23.467277 ops/training.py:65 2019-01-17 06:46:23.467210: step 17632, loss = 0.32920 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:46:24.755531 ops/training.py:65 2019-01-17 06:46:24.755458: step 17633, loss = 0.32521 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:46:26.045373 ops/training.py:65 2019-01-17 06:46:26.045293: step 17634, loss = 0.27617 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:46:27.334368 ops/training.py:65 2019-01-17 06:46:27.334295: step 17635, loss = 0.32340 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:46:28.622597 ops/training.py:65 2019-01-17 06:46:28.622531: step 17636, loss = 0.32494 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:46:29.910972 ops/training.py:65 2019-01-17 06:46:29.910906: step 17637, loss = 0.30263 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:46:31.195642 ops/training.py:65 2019-01-17 06:46:31.195551: step 17638, loss = 0.30963 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:46:32.484328 ops/training.py:65 2019-01-17 06:46:32.484262: step 17639, loss = 0.32858 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:46:33.774186 ops/training.py:65 2019-01-17 06:46:33.774112: step 17640, loss = 0.21523 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:46:35.063076 ops/training.py:65 2019-01-17 06:46:35.062996: step 17641, loss = 0.33091 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:46:36.350918 ops/training.py:65 2019-01-17 06:46:36.350842: step 17642, loss = 0.38194 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:46:37.633729 ops/training.py:65 2019-01-17 06:46:37.633656: step 17643, loss = 0.28381 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:46:38.922417 ops/training.py:65 2019-01-17 06:46:38.922275: step 17644, loss = 0.31619 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:46:40.211203 ops/training.py:65 2019-01-17 06:46:40.211133: step 17645, loss = 0.32129 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:46:41.498436 ops/training.py:65 2019-01-17 06:46:41.498343: step 17646, loss = 0.34136 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:46:42.787171 ops/training.py:65 2019-01-17 06:46:42.787099: step 17647, loss = 0.31109 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:46:44.075889 ops/training.py:65 2019-01-17 06:46:44.075817: step 17648, loss = 0.28770 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:46:45.363664 ops/training.py:65 2019-01-17 06:46:45.363585: step 17649, loss = 0.30074 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:46:46.653465 ops/training.py:65 2019-01-17 06:46:46.653371: step 17650, loss = 0.30906 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:46:47.942966 ops/training.py:65 2019-01-17 06:46:47.942886: step 17651, loss = 0.33145 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:46:49.229864 ops/training.py:65 2019-01-17 06:46:49.229784: step 17652, loss = 0.30606 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:46:50.517281 ops/training.py:65 2019-01-17 06:46:50.517210: step 17653, loss = 0.30003 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:46:51.805991 ops/training.py:65 2019-01-17 06:46:51.805920: step 17654, loss = 0.33209 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:46:53.093675 ops/training.py:65 2019-01-17 06:46:53.093606: step 17655, loss = 0.32195 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:46:54.382689 ops/training.py:65 2019-01-17 06:46:54.382604: step 17656, loss = 0.30561 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:46:55.672608 ops/training.py:65 2019-01-17 06:46:55.672534: step 17657, loss = 0.31082 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:46:56.962290 ops/training.py:65 2019-01-17 06:46:56.962222: step 17658, loss = 0.39254 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:46:58.250319 ops/training.py:65 2019-01-17 06:46:58.250223: step 17659, loss = 0.31367 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:46:59.538359 ops/training.py:65 2019-01-17 06:46:59.538284: step 17660, loss = 0.27720 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:47:00.823689 ops/training.py:65 2019-01-17 06:47:00.823617: step 17661, loss = 0.31826 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:47:02.111147 ops/training.py:65 2019-01-17 06:47:02.111061: step 17662, loss = 0.28036 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:47:03.400032 ops/training.py:65 2019-01-17 06:47:03.399961: step 17663, loss = 0.25910 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:47:04.683993 ops/training.py:65 2019-01-17 06:47:04.683928: step 17664, loss = 0.33743 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:47:05.973770 ops/training.py:65 2019-01-17 06:47:05.973657: step 17665, loss = 0.22370 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:47:07.264112 ops/training.py:65 2019-01-17 06:47:07.264025: step 17666, loss = 0.27115 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:47:08.553157 ops/training.py:65 2019-01-17 06:47:08.553055: step 17667, loss = 0.30590 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:47:09.842291 ops/training.py:65 2019-01-17 06:47:09.842223: step 17668, loss = 0.29967 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:47:11.131016 ops/training.py:65 2019-01-17 06:47:11.130947: step 17669, loss = 0.38370 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:47:12.420413 ops/training.py:65 2019-01-17 06:47:12.420343: step 17670, loss = 0.27479 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:47:13.707976 ops/training.py:65 2019-01-17 06:47:13.707898: step 17671, loss = 0.33846 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:47:14.996944 ops/training.py:65 2019-01-17 06:47:14.996865: step 17672, loss = 0.28794 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:47:16.285693 ops/training.py:65 2019-01-17 06:47:16.285613: step 17673, loss = 0.28367 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:47:17.573535 ops/training.py:65 2019-01-17 06:47:17.573459: step 17674, loss = 0.36649 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:47:18.861428 ops/training.py:65 2019-01-17 06:47:18.861339: step 17675, loss = 0.29055 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:47:20.151480 ops/training.py:65 2019-01-17 06:47:20.151414: step 17676, loss = 0.33829 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:47:21.439384 ops/training.py:65 2019-01-17 06:47:21.439318: step 17677, loss = 0.33404 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:47:22.728260 ops/training.py:65 2019-01-17 06:47:22.728170: step 17678, loss = 0.33476 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:47:24.013418 ops/training.py:65 2019-01-17 06:47:24.013356: step 17679, loss = 0.30713 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:47:25.301776 ops/training.py:65 2019-01-17 06:47:25.301707: step 17680, loss = 0.35321 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:47:26.591215 ops/training.py:65 2019-01-17 06:47:26.591144: step 17681, loss = 0.40573 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:47:27.879894 ops/training.py:65 2019-01-17 06:47:27.879824: step 17682, loss = 0.24785 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:47:29.167669 ops/training.py:65 2019-01-17 06:47:29.167596: step 17683, loss = 0.44659 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:47:30.456481 ops/training.py:65 2019-01-17 06:47:30.456398: step 17684, loss = 0.32214 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:47:31.744440 ops/training.py:65 2019-01-17 06:47:31.744368: step 17685, loss = 0.33046 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:47:33.027933 ops/training.py:65 2019-01-17 06:47:33.027846: step 17686, loss = 0.35579 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:47:34.311191 ops/training.py:65 2019-01-17 06:47:34.311111: step 17687, loss = 0.32949 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:47:35.597952 ops/training.py:65 2019-01-17 06:47:35.597847: step 17688, loss = 0.23987 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:47:36.888467 ops/training.py:65 2019-01-17 06:47:36.888392: step 17689, loss = 0.26982 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:47:38.177843 ops/training.py:65 2019-01-17 06:47:38.177769: step 17690, loss = 0.31790 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:47:39.466886 ops/training.py:65 2019-01-17 06:47:39.466797: step 17691, loss = 0.30628 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:47:40.756245 ops/training.py:65 2019-01-17 06:47:40.756175: step 17692, loss = 0.30118 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:47:42.044214 ops/training.py:65 2019-01-17 06:47:42.044152: step 17693, loss = 0.29016 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:47:43.328764 ops/training.py:65 2019-01-17 06:47:43.328694: step 17694, loss = 0.32185 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:47:44.621980 ops/training.py:65 2019-01-17 06:47:44.621885: step 17695, loss = 0.35712 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:47:45.907294 ops/training.py:65 2019-01-17 06:47:45.907231: step 17696, loss = 0.30111 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:47:47.196169 ops/training.py:65 2019-01-17 06:47:47.196112: step 17697, loss = 0.33983 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:47:48.481139 ops/training.py:65 2019-01-17 06:47:48.481076: step 17698, loss = 0.38467 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:47:49.766892 ops/training.py:65 2019-01-17 06:47:49.766817: step 17699, loss = 0.37929 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:47:51.059146 ops/training.py:65 2019-01-17 06:47:51.059042: step 17700, loss = 0.28757 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:47:52.351683 ops/training.py:65 2019-01-17 06:47:52.351611: step 17701, loss = 0.33238 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:47:53.637044 ops/training.py:65 2019-01-17 06:47:53.636975: step 17702, loss = 0.33636 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:47:54.925893 ops/training.py:65 2019-01-17 06:47:54.925825: step 17703, loss = 0.35159 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:47:56.215944 ops/training.py:65 2019-01-17 06:47:56.215857: step 17704, loss = 0.30771 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:47:57.506980 ops/training.py:65 2019-01-17 06:47:57.506912: step 17705, loss = 0.33795 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:47:58.795062 ops/training.py:65 2019-01-17 06:47:58.794983: step 17706, loss = 0.38973 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:48:00.084552 ops/training.py:65 2019-01-17 06:48:00.084486: step 17707, loss = 0.24826 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:48:01.368455 ops/training.py:65 2019-01-17 06:48:01.368387: step 17708, loss = 0.32539 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:48:02.652047 ops/training.py:65 2019-01-17 06:48:02.651972: step 17709, loss = 0.23317 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:48:03.936946 ops/training.py:65 2019-01-17 06:48:03.936849: step 17710, loss = 0.36536 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:48:05.222999 ops/training.py:65 2019-01-17 06:48:05.222890: step 17711, loss = 0.32629 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:48:06.507398 ops/training.py:65 2019-01-17 06:48:06.507326: step 17712, loss = 0.32555 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:48:07.795001 ops/training.py:65 2019-01-17 06:48:07.794928: step 17713, loss = 0.27186 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:48:09.079102 ops/training.py:65 2019-01-17 06:48:09.079025: step 17714, loss = 0.38177 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:48:10.363392 ops/training.py:65 2019-01-17 06:48:10.363289: step 17715, loss = 0.28005 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:48:11.651831 ops/training.py:65 2019-01-17 06:48:11.651761: step 17716, loss = 0.31565 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:48:12.940822 ops/training.py:65 2019-01-17 06:48:12.940749: step 17717, loss = 0.32061 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:48:14.228674 ops/training.py:65 2019-01-17 06:48:14.228605: step 17718, loss = 0.25404 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:48:15.514489 ops/training.py:65 2019-01-17 06:48:15.514424: step 17719, loss = 0.35106 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:48:16.801751 ops/training.py:65 2019-01-17 06:48:16.801662: step 17720, loss = 0.27801 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:48:18.091191 ops/training.py:65 2019-01-17 06:48:18.091100: step 17721, loss = 0.27204 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:48:19.379850 ops/training.py:65 2019-01-17 06:48:19.379754: step 17722, loss = 0.34915 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:48:20.669138 ops/training.py:65 2019-01-17 06:48:20.669045: step 17723, loss = 0.32702 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:48:21.956521 ops/training.py:65 2019-01-17 06:48:21.956450: step 17724, loss = 0.29275 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:48:23.244488 ops/training.py:65 2019-01-17 06:48:23.244414: step 17725, loss = 0.24928 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:48:24.529077 ops/training.py:65 2019-01-17 06:48:24.529000: step 17726, loss = 0.27217 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:48:25.819506 ops/training.py:65 2019-01-17 06:48:25.819394: step 17727, loss = 0.34217 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:48:27.103386 ops/training.py:65 2019-01-17 06:48:27.103312: step 17728, loss = 0.26339 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:48:28.390780 ops/training.py:65 2019-01-17 06:48:28.390672: step 17729, loss = 0.27620 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:48:29.680019 ops/training.py:65 2019-01-17 06:48:29.679898: step 17730, loss = 0.31173 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:48:30.967799 ops/training.py:65 2019-01-17 06:48:30.967723: step 17731, loss = 0.31529 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:48:32.251338 ops/training.py:65 2019-01-17 06:48:32.251258: step 17732, loss = 0.36518 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:48:33.538423 ops/training.py:65 2019-01-17 06:48:33.538358: step 17733, loss = 0.37471 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:48:34.822413 ops/training.py:65 2019-01-17 06:48:34.822339: step 17734, loss = 0.30644 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:48:36.110448 ops/training.py:65 2019-01-17 06:48:36.110381: step 17735, loss = 0.30767 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:48:37.398352 ops/training.py:65 2019-01-17 06:48:37.398277: step 17736, loss = 0.37892 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:48:38.686790 ops/training.py:65 2019-01-17 06:48:38.686713: step 17737, loss = 0.23090 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:48:39.971509 ops/training.py:65 2019-01-17 06:48:39.971437: step 17738, loss = 0.32729 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:48:41.259757 ops/training.py:65 2019-01-17 06:48:41.259691: step 17739, loss = 0.30817 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:48:42.547441 ops/training.py:65 2019-01-17 06:48:42.547348: step 17740, loss = 0.35180 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:48:43.835360 ops/training.py:65 2019-01-17 06:48:43.835287: step 17741, loss = 0.37341 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:48:45.120916 ops/training.py:65 2019-01-17 06:48:45.120850: step 17742, loss = 0.23812 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:48:46.405723 ops/training.py:65 2019-01-17 06:48:46.405655: step 17743, loss = 0.32623 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:48:47.691842 ops/training.py:65 2019-01-17 06:48:47.691762: step 17744, loss = 0.34003 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:48:48.981312 ops/training.py:65 2019-01-17 06:48:48.981215: step 17745, loss = 0.39949 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:48:50.265419 ops/training.py:65 2019-01-17 06:48:50.265319: step 17746, loss = 0.31369 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:48:51.556947 ops/training.py:65 2019-01-17 06:48:51.556793: step 17747, loss = 0.31305 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:48:52.848664 ops/training.py:65 2019-01-17 06:48:52.848581: step 17748, loss = 0.39009 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:48:54.133956 ops/training.py:65 2019-01-17 06:48:54.133889: step 17749, loss = 0.33176 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:48:55.414898 ops/training.py:65 2019-01-17 06:48:55.414827: step 17750, loss = 0.25838 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:48:56.699676 ops/training.py:65 2019-01-17 06:48:56.699574: step 17751, loss = 0.35753 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:48:57.981736 ops/training.py:65 2019-01-17 06:48:57.981626: step 17752, loss = 0.38551 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:48:59.264463 ops/training.py:65 2019-01-17 06:48:59.264363: step 17753, loss = 0.37757 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:49:00.557017 ops/training.py:65 2019-01-17 06:49:00.556913: step 17754, loss = 0.29802 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:49:01.847493 ops/training.py:65 2019-01-17 06:49:01.847435: step 17755, loss = 0.28208 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:49:03.136752 ops/training.py:65 2019-01-17 06:49:03.136676: step 17756, loss = 0.34620 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:49:04.421684 ops/training.py:65 2019-01-17 06:49:04.421616: step 17757, loss = 0.30618 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:49:05.705386 ops/training.py:65 2019-01-17 06:49:05.705318: step 17758, loss = 0.23740 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:49:06.992639 ops/training.py:65 2019-01-17 06:49:06.992573: step 17759, loss = 0.24025 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:49:08.277826 ops/training.py:65 2019-01-17 06:49:08.277749: step 17760, loss = 0.29019 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:49:09.567291 ops/training.py:65 2019-01-17 06:49:09.567188: step 17761, loss = 0.35215 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:49:10.858195 ops/training.py:65 2019-01-17 06:49:10.858128: step 17762, loss = 0.32911 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:49:12.143057 ops/training.py:65 2019-01-17 06:49:12.142996: step 17763, loss = 0.30902 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:49:13.432169 ops/training.py:65 2019-01-17 06:49:13.432105: step 17764, loss = 0.32981 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:49:14.723282 ops/training.py:65 2019-01-17 06:49:14.723208: step 17765, loss = 0.30067 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:49:16.012038 ops/training.py:65 2019-01-17 06:49:16.011958: step 17766, loss = 0.26087 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:49:17.299008 ops/training.py:65 2019-01-17 06:49:17.298925: step 17767, loss = 0.28860 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:49:18.589286 ops/training.py:65 2019-01-17 06:49:18.589217: step 17768, loss = 0.45711 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:49:19.870370 ops/training.py:65 2019-01-17 06:49:19.870302: step 17769, loss = 0.33877 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:49:21.159712 ops/training.py:65 2019-01-17 06:49:21.159642: step 17770, loss = 0.31217 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:49:22.449337 ops/training.py:65 2019-01-17 06:49:22.449262: step 17771, loss = 0.30907 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:49:23.738298 ops/training.py:65 2019-01-17 06:49:23.738224: step 17772, loss = 0.25177 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:49:25.026488 ops/training.py:65 2019-01-17 06:49:25.026422: step 17773, loss = 0.32377 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:49:26.315577 ops/training.py:65 2019-01-17 06:49:26.315489: step 17774, loss = 0.28156 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:49:27.604994 ops/training.py:65 2019-01-17 06:49:27.604922: step 17775, loss = 0.33349 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:49:28.892899 ops/training.py:65 2019-01-17 06:49:28.892831: step 17776, loss = 0.30415 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:49:30.181746 ops/training.py:65 2019-01-17 06:49:30.181676: step 17777, loss = 0.37739 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:49:31.470746 ops/training.py:65 2019-01-17 06:49:31.470681: step 17778, loss = 0.26963 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:49:32.759615 ops/training.py:65 2019-01-17 06:49:32.759523: step 17779, loss = 0.29656 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:49:34.049208 ops/training.py:65 2019-01-17 06:49:34.049139: step 17780, loss = 0.32435 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:49:35.334157 ops/training.py:65 2019-01-17 06:49:35.334089: step 17781, loss = 0.19682 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:49:36.624101 ops/training.py:65 2019-01-17 06:49:36.623959: step 17782, loss = 0.27246 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:49:37.908553 ops/training.py:65 2019-01-17 06:49:37.908484: step 17783, loss = 0.29014 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:49:39.194244 ops/training.py:65 2019-01-17 06:49:39.194132: step 17784, loss = 0.28502 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:49:40.488042 ops/training.py:65 2019-01-17 06:49:40.487938: step 17785, loss = 0.33036 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:49:41.779058 ops/training.py:65 2019-01-17 06:49:41.778983: step 17786, loss = 0.28396 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:49:43.068876 ops/training.py:65 2019-01-17 06:49:43.068784: step 17787, loss = 0.26012 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:49:44.359526 ops/training.py:65 2019-01-17 06:49:44.359453: step 17788, loss = 0.24926 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:49:45.644560 ops/training.py:65 2019-01-17 06:49:45.644484: step 17789, loss = 0.31023 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:49:46.924859 ops/training.py:65 2019-01-17 06:49:46.924765: step 17790, loss = 0.35842 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:49:48.214853 ops/training.py:65 2019-01-17 06:49:48.214755: step 17791, loss = 0.25026 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:49:49.505297 ops/training.py:65 2019-01-17 06:49:49.505193: step 17792, loss = 0.34520 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:49:50.793875 ops/training.py:65 2019-01-17 06:49:50.793803: step 17793, loss = 0.25499 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:49:52.083208 ops/training.py:65 2019-01-17 06:49:52.083132: step 17794, loss = 0.28955 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:49:53.373799 ops/training.py:65 2019-01-17 06:49:53.373696: step 17795, loss = 0.34968 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:49:54.664850 ops/training.py:65 2019-01-17 06:49:54.664750: step 17796, loss = 0.32142 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:49:55.955042 ops/training.py:65 2019-01-17 06:49:55.954972: step 17797, loss = 0.29495 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:49:57.245188 ops/training.py:65 2019-01-17 06:49:57.245116: step 17798, loss = 0.26710 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:49:58.533466 ops/training.py:65 2019-01-17 06:49:58.533394: step 17799, loss = 0.30410 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:49:59.822417 ops/training.py:65 2019-01-17 06:49:59.822349: step 17800, loss = 0.23294 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:50:01.105697 ops/training.py:65 2019-01-17 06:50:01.105627: step 17801, loss = 0.31119 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:50:02.385577 ops/training.py:65 2019-01-17 06:50:02.385498: step 17802, loss = 0.37904 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:50:03.672170 ops/training.py:65 2019-01-17 06:50:03.672063: step 17803, loss = 0.27168 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:50:04.960422 ops/training.py:65 2019-01-17 06:50:04.960310: step 17804, loss = 0.34090 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:50:06.244874 ops/training.py:65 2019-01-17 06:50:06.244772: step 17805, loss = 0.36363 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:50:07.531603 ops/training.py:65 2019-01-17 06:50:07.531487: step 17806, loss = 0.24784 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:50:08.815684 ops/training.py:65 2019-01-17 06:50:08.815614: step 17807, loss = 0.27226 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:50:10.103019 ops/training.py:65 2019-01-17 06:50:10.102862: step 17808, loss = 0.28652 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:50:11.388046 ops/training.py:65 2019-01-17 06:50:11.387945: step 17809, loss = 0.29648 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:50:12.680929 ops/training.py:65 2019-01-17 06:50:12.680827: step 17810, loss = 0.30538 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:50:13.970510 ops/training.py:65 2019-01-17 06:50:13.970434: step 17811, loss = 0.33117 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:50:15.254284 ops/training.py:65 2019-01-17 06:50:15.254214: step 17812, loss = 0.26866 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:50:16.542801 ops/training.py:65 2019-01-17 06:50:16.542714: step 17813, loss = 0.34450 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:50:17.832656 ops/training.py:65 2019-01-17 06:50:17.832586: step 17814, loss = 0.28855 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:50:19.117127 ops/training.py:65 2019-01-17 06:50:19.117066: step 17815, loss = 0.25100 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:50:20.406395 ops/training.py:65 2019-01-17 06:50:20.406331: step 17816, loss = 0.29190 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:50:21.694607 ops/training.py:65 2019-01-17 06:50:21.694538: step 17817, loss = 0.31745 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:50:22.982586 ops/training.py:65 2019-01-17 06:50:22.982522: step 17818, loss = 0.24825 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:50:24.271662 ops/training.py:65 2019-01-17 06:50:24.271590: step 17819, loss = 0.33180 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:50:25.560367 ops/training.py:65 2019-01-17 06:50:25.560293: step 17820, loss = 0.30655 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:50:26.844757 ops/training.py:65 2019-01-17 06:50:26.844690: step 17821, loss = 0.26533 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:50:28.135000 ops/training.py:65 2019-01-17 06:50:28.134893: step 17822, loss = 0.26771 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:50:29.423765 ops/training.py:65 2019-01-17 06:50:29.423694: step 17823, loss = 0.33707 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:50:30.707854 ops/training.py:65 2019-01-17 06:50:30.707778: step 17824, loss = 0.27286 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:50:31.996299 ops/training.py:65 2019-01-17 06:50:31.996229: step 17825, loss = 0.36471 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:50:33.285850 ops/training.py:65 2019-01-17 06:50:33.285770: step 17826, loss = 0.33659 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:50:34.569090 ops/training.py:65 2019-01-17 06:50:34.569018: step 17827, loss = 0.31998 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:50:35.857626 ops/training.py:65 2019-01-17 06:50:35.857485: step 17828, loss = 0.19646 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:50:37.146643 ops/training.py:65 2019-01-17 06:50:37.146576: step 17829, loss = 0.24237 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:50:38.434429 ops/training.py:65 2019-01-17 06:50:38.434360: step 17830, loss = 0.30795 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:50:39.722768 ops/training.py:65 2019-01-17 06:50:39.722709: step 17831, loss = 0.24723 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:50:41.011227 ops/training.py:65 2019-01-17 06:50:41.011157: step 17832, loss = 0.29491 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:50:42.300240 ops/training.py:65 2019-01-17 06:50:42.300169: step 17833, loss = 0.36146 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:50:43.588887 ops/training.py:65 2019-01-17 06:50:43.588790: step 17834, loss = 0.26943 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:50:44.873514 ops/training.py:65 2019-01-17 06:50:44.873437: step 17835, loss = 0.27672 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:50:46.162805 ops/training.py:65 2019-01-17 06:50:46.162708: step 17836, loss = 0.26851 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:50:47.451464 ops/training.py:65 2019-01-17 06:50:47.451394: step 17837, loss = 0.26339 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:50:48.740038 ops/training.py:65 2019-01-17 06:50:48.739962: step 17838, loss = 0.32539 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:50:50.029188 ops/training.py:65 2019-01-17 06:50:50.029101: step 17839, loss = 0.27309 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:50:51.319093 ops/training.py:65 2019-01-17 06:50:51.319021: step 17840, loss = 0.26832 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:50:52.607305 ops/training.py:65 2019-01-17 06:50:52.607226: step 17841, loss = 0.24107 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:50:53.894933 ops/training.py:65 2019-01-17 06:50:53.894863: step 17842, loss = 0.31602 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:50:55.183775 ops/training.py:65 2019-01-17 06:50:55.183701: step 17843, loss = 0.25113 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:50:56.472671 ops/training.py:65 2019-01-17 06:50:56.472599: step 17844, loss = 0.29612 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:50:57.760062 ops/training.py:65 2019-01-17 06:50:57.759980: step 17845, loss = 0.31339 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:50:59.051811 ops/training.py:65 2019-01-17 06:50:59.051731: step 17846, loss = 0.26830 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:51:00.337529 ops/training.py:65 2019-01-17 06:51:00.337458: step 17847, loss = 0.28734 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:51:01.622232 ops/training.py:65 2019-01-17 06:51:01.622156: step 17848, loss = 0.38554 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:51:02.910666 ops/training.py:65 2019-01-17 06:51:02.910601: step 17849, loss = 0.32771 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:51:04.200193 ops/training.py:65 2019-01-17 06:51:04.200121: step 17850, loss = 0.35001 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:51:05.487782 ops/training.py:65 2019-01-17 06:51:05.487711: step 17851, loss = 0.28283 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:51:06.771850 ops/training.py:65 2019-01-17 06:51:06.771770: step 17852, loss = 0.33840 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:51:08.055638 ops/training.py:65 2019-01-17 06:51:08.055576: step 17853, loss = 0.31990 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:51:09.344272 ops/training.py:65 2019-01-17 06:51:09.344170: step 17854, loss = 0.32258 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:51:10.632679 ops/training.py:65 2019-01-17 06:51:10.632612: step 17855, loss = 0.29801 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:51:11.920349 ops/training.py:65 2019-01-17 06:51:11.920282: step 17856, loss = 0.26486 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:51:13.206031 ops/training.py:65 2019-01-17 06:51:13.205941: step 17857, loss = 0.32973 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:51:14.496261 ops/training.py:65 2019-01-17 06:51:14.496154: step 17858, loss = 0.30226 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:51:15.785405 ops/training.py:65 2019-01-17 06:51:15.785334: step 17859, loss = 0.27684 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:51:17.074182 ops/training.py:65 2019-01-17 06:51:17.074110: step 17860, loss = 0.31508 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:51:18.361193 ops/training.py:65 2019-01-17 06:51:18.361129: step 17861, loss = 0.38127 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:51:19.646102 ops/training.py:65 2019-01-17 06:51:19.646037: step 17862, loss = 0.33131 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:51:20.933744 ops/training.py:65 2019-01-17 06:51:20.933665: step 17863, loss = 0.26136 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:51:22.221639 ops/training.py:65 2019-01-17 06:51:22.221567: step 17864, loss = 0.32500 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:51:23.505138 ops/training.py:65 2019-01-17 06:51:23.505063: step 17865, loss = 0.24617 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:51:24.796194 ops/training.py:65 2019-01-17 06:51:24.796084: step 17866, loss = 0.31120 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:51:26.087853 ops/training.py:65 2019-01-17 06:51:26.087781: step 17867, loss = 0.34130 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:51:27.377067 ops/training.py:65 2019-01-17 06:51:27.376997: step 17868, loss = 0.28437 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:51:28.666482 ops/training.py:65 2019-01-17 06:51:28.666410: step 17869, loss = 0.33495 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:51:29.956074 ops/training.py:65 2019-01-17 06:51:29.955987: step 17870, loss = 0.30329 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:51:31.244781 ops/training.py:65 2019-01-17 06:51:31.244715: step 17871, loss = 0.37229 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:51:32.529021 ops/training.py:65 2019-01-17 06:51:32.528947: step 17872, loss = 0.26501 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:51:33.813619 ops/training.py:65 2019-01-17 06:51:33.813517: step 17873, loss = 0.33260 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:51:35.105530 ops/training.py:65 2019-01-17 06:51:35.105421: step 17874, loss = 0.33635 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:51:36.394900 ops/training.py:65 2019-01-17 06:51:36.394830: step 17875, loss = 0.31928 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:51:37.683744 ops/training.py:65 2019-01-17 06:51:37.683675: step 17876, loss = 0.32025 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:51:38.973008 ops/training.py:65 2019-01-17 06:51:38.972936: step 17877, loss = 0.31909 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:51:40.262890 ops/training.py:65 2019-01-17 06:51:40.262827: step 17878, loss = 0.29176 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:51:41.550813 ops/training.py:65 2019-01-17 06:51:41.550745: step 17879, loss = 0.35228 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:51:42.838558 ops/training.py:65 2019-01-17 06:51:42.838458: step 17880, loss = 0.34850 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:51:44.126681 ops/training.py:65 2019-01-17 06:51:44.126608: step 17881, loss = 0.35040 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:51:45.416584 ops/training.py:65 2019-01-17 06:51:45.416508: step 17882, loss = 0.25799 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:51:46.705321 ops/training.py:65 2019-01-17 06:51:46.705244: step 17883, loss = 0.27651 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:51:47.994216 ops/training.py:65 2019-01-17 06:51:47.994123: step 17884, loss = 0.24239 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:51:49.278714 ops/training.py:65 2019-01-17 06:51:49.278644: step 17885, loss = 0.25609 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:51:50.568279 ops/training.py:65 2019-01-17 06:51:50.568181: step 17886, loss = 0.25836 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:51:51.856070 ops/training.py:65 2019-01-17 06:51:51.856003: step 17887, loss = 0.36202 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:51:53.145420 ops/training.py:65 2019-01-17 06:51:53.145342: step 17888, loss = 0.29432 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:51:54.433382 ops/training.py:65 2019-01-17 06:51:54.433312: step 17889, loss = 0.29543 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:51:55.716822 ops/training.py:65 2019-01-17 06:51:55.716759: step 17890, loss = 0.29150 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:51:57.000817 ops/training.py:65 2019-01-17 06:51:57.000753: step 17891, loss = 0.30842 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:51:58.285569 ops/training.py:65 2019-01-17 06:51:58.285457: step 17892, loss = 0.29347 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:51:59.571166 ops/training.py:65 2019-01-17 06:51:59.571054: step 17893, loss = 0.28110 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:52:00.853032 ops/training.py:65 2019-01-17 06:52:00.852928: step 17894, loss = 0.34767 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:52:02.138848 ops/training.py:65 2019-01-17 06:52:02.138738: step 17895, loss = 0.28677 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:52:03.423655 ops/training.py:65 2019-01-17 06:52:03.423560: step 17896, loss = 0.28199 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:52:04.720642 ops/training.py:65 2019-01-17 06:52:04.720534: step 17897, loss = 0.27238 (24.7 examples/sec; 1.296 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:52:06.009793 ops/training.py:65 2019-01-17 06:52:06.009729: step 17898, loss = 0.28549 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:52:07.298188 ops/training.py:65 2019-01-17 06:52:07.298120: step 17899, loss = 0.37085 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:52:08.581505 ops/training.py:65 2019-01-17 06:52:08.581442: step 17900, loss = 0.30647 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:52:09.867925 ops/training.py:65 2019-01-17 06:52:09.867830: step 17901, loss = 0.28929 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:52:11.157639 ops/training.py:65 2019-01-17 06:52:11.157540: step 17902, loss = 0.23015 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:52:12.444700 ops/training.py:65 2019-01-17 06:52:12.444631: step 17903, loss = 0.28094 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:52:13.732579 ops/training.py:65 2019-01-17 06:52:13.732513: step 17904, loss = 0.31668 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:52:15.016454 ops/training.py:65 2019-01-17 06:52:15.016381: step 17905, loss = 0.32416 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:52:16.309232 ops/training.py:65 2019-01-17 06:52:16.309148: step 17906, loss = 0.37534 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:52:17.607244 ops/training.py:65 2019-01-17 06:52:17.607102: step 17907, loss = 0.29098 (24.7 examples/sec; 1.297 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:52:18.894659 ops/training.py:65 2019-01-17 06:52:18.894587: step 17908, loss = 0.40244 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:52:20.181475 ops/training.py:65 2019-01-17 06:52:20.181375: step 17909, loss = 0.30578 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:52:21.472169 ops/training.py:65 2019-01-17 06:52:21.472064: step 17910, loss = 0.24867 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:52:22.764208 ops/training.py:65 2019-01-17 06:52:22.764134: step 17911, loss = 0.26021 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:52:24.052580 ops/training.py:65 2019-01-17 06:52:24.052492: step 17912, loss = 0.26208 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:52:25.337410 ops/training.py:65 2019-01-17 06:52:25.337333: step 17913, loss = 0.29460 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:52:26.623228 ops/training.py:65 2019-01-17 06:52:26.623143: step 17914, loss = 0.36960 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:52:27.915744 ops/training.py:65 2019-01-17 06:52:27.915636: step 17915, loss = 0.33265 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:52:29.198600 ops/training.py:65 2019-01-17 06:52:29.198539: step 17916, loss = 0.34945 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:52:30.483615 ops/training.py:65 2019-01-17 06:52:30.483541: step 17917, loss = 0.28931 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:52:31.771055 ops/training.py:65 2019-01-17 06:52:31.770950: step 17918, loss = 0.27173 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:52:33.063164 ops/training.py:65 2019-01-17 06:52:33.063063: step 17919, loss = 0.26563 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:52:34.354466 ops/training.py:65 2019-01-17 06:52:34.354395: step 17920, loss = 0.29088 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:52:35.644260 ops/training.py:65 2019-01-17 06:52:35.644186: step 17921, loss = 0.26603 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:52:36.933910 ops/training.py:65 2019-01-17 06:52:36.933841: step 17922, loss = 0.22397 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:52:38.224406 ops/training.py:65 2019-01-17 06:52:38.224331: step 17923, loss = 0.26747 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:52:39.508592 ops/training.py:65 2019-01-17 06:52:39.508527: step 17924, loss = 0.28071 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:52:40.793927 ops/training.py:65 2019-01-17 06:52:40.793822: step 17925, loss = 0.32814 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:52:42.085281 ops/training.py:65 2019-01-17 06:52:42.085173: step 17926, loss = 0.31710 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:52:43.368509 ops/training.py:65 2019-01-17 06:52:43.368438: step 17927, loss = 0.31457 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:52:44.655736 ops/training.py:65 2019-01-17 06:52:44.655627: step 17928, loss = 0.33578 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:52:45.947573 ops/training.py:65 2019-01-17 06:52:45.947467: step 17929, loss = 0.26837 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:52:47.233557 ops/training.py:65 2019-01-17 06:52:47.233483: step 17930, loss = 0.27155 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:52:48.522389 ops/training.py:65 2019-01-17 06:52:48.522329: step 17931, loss = 0.37000 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:52:49.805852 ops/training.py:65 2019-01-17 06:52:49.805788: step 17932, loss = 0.30237 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:52:51.091733 ops/training.py:65 2019-01-17 06:52:51.091640: step 17933, loss = 0.29418 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:52:52.384652 ops/training.py:65 2019-01-17 06:52:52.384503: step 17934, loss = 0.30829 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:52:53.676423 ops/training.py:65 2019-01-17 06:52:53.676346: step 17935, loss = 0.31080 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:52:54.960545 ops/training.py:65 2019-01-17 06:52:54.960477: step 17936, loss = 0.31126 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:52:56.244166 ops/training.py:65 2019-01-17 06:52:56.244082: step 17937, loss = 0.24932 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:52:57.533543 ops/training.py:65 2019-01-17 06:52:57.533438: step 17938, loss = 0.22159 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:52:58.823384 ops/training.py:65 2019-01-17 06:52:58.823318: step 17939, loss = 0.26896 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:53:00.111324 ops/training.py:65 2019-01-17 06:53:00.111225: step 17940, loss = 0.29046 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:53:01.395970 ops/training.py:65 2019-01-17 06:53:01.395902: step 17941, loss = 0.27422 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:53:02.679856 ops/training.py:65 2019-01-17 06:53:02.679787: step 17942, loss = 0.31832 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:53:03.969661 ops/training.py:65 2019-01-17 06:53:03.969566: step 17943, loss = 0.27986 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:53:05.258840 ops/training.py:65 2019-01-17 06:53:05.258743: step 17944, loss = 0.26655 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:53:06.549109 ops/training.py:65 2019-01-17 06:53:06.549033: step 17945, loss = 0.26584 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:53:07.834196 ops/training.py:65 2019-01-17 06:53:07.834131: step 17946, loss = 0.35200 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:53:09.117352 ops/training.py:65 2019-01-17 06:53:09.117285: step 17947, loss = 0.37582 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 06:53:10.400819 ops/training.py:65 2019-01-17 06:53:10.400711: step 17948, loss = 0.23696 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:53:11.691097 ops/training.py:65 2019-01-17 06:53:11.690996: step 17949, loss = 0.22256 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:53:12.979562 ops/training.py:65 2019-01-17 06:53:12.979445: step 17950, loss = 0.33377 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:53:14.270459 ops/training.py:65 2019-01-17 06:53:14.270314: step 17951, loss = 0.30637 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:53:15.562656 ops/training.py:65 2019-01-17 06:53:15.562557: step 17952, loss = 0.21182 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:53:16.850831 ops/training.py:65 2019-01-17 06:53:16.850738: step 17953, loss = 0.25533 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:53:18.140749 ops/training.py:65 2019-01-17 06:53:18.140680: step 17954, loss = 0.28257 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:53:19.425335 ops/training.py:65 2019-01-17 06:53:19.425271: step 17955, loss = 0.24826 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:53:20.713600 ops/training.py:65 2019-01-17 06:53:20.713509: step 17956, loss = 0.27450 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:53:22.002790 ops/training.py:65 2019-01-17 06:53:22.002696: step 17957, loss = 0.31460 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:53:23.288194 ops/training.py:65 2019-01-17 06:53:23.288127: step 17958, loss = 0.30279 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:53:24.573211 ops/training.py:65 2019-01-17 06:53:24.573097: step 17959, loss = 0.32940 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:53:25.865306 ops/training.py:65 2019-01-17 06:53:25.865201: step 17960, loss = 0.28926 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:53:27.152019 ops/training.py:65 2019-01-17 06:53:27.151954: step 17961, loss = 0.29465 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:53:28.440035 ops/training.py:65 2019-01-17 06:53:28.439965: step 17962, loss = 0.30279 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:53:29.724592 ops/training.py:65 2019-01-17 06:53:29.724521: step 17963, loss = 0.30925 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:53:31.005346 ops/training.py:65 2019-01-17 06:53:31.005230: step 17964, loss = 0.26776 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:53:32.288353 ops/training.py:65 2019-01-17 06:53:32.288249: step 17965, loss = 0.30693 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:53:33.569779 ops/training.py:65 2019-01-17 06:53:33.569684: step 17966, loss = 0.30813 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:53:34.860885 ops/training.py:65 2019-01-17 06:53:34.860773: step 17967, loss = 0.34635 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:53:36.154655 ops/training.py:65 2019-01-17 06:53:36.154499: step 17968, loss = 0.29559 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:53:37.444661 ops/training.py:65 2019-01-17 06:53:37.444593: step 17969, loss = 0.28351 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:53:38.728147 ops/training.py:65 2019-01-17 06:53:38.728072: step 17970, loss = 0.28449 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:53:40.019776 ops/training.py:65 2019-01-17 06:53:40.019667: step 17971, loss = 0.28579 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:53:41.305748 ops/training.py:65 2019-01-17 06:53:41.305678: step 17972, loss = 0.25701 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:53:42.589165 ops/training.py:65 2019-01-17 06:53:42.589081: step 17973, loss = 0.27264 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:53:43.871994 ops/training.py:65 2019-01-17 06:53:43.871896: step 17974, loss = 0.24448 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:53:45.159987 ops/training.py:65 2019-01-17 06:53:45.159826: step 17975, loss = 0.31061 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:53:46.451572 ops/training.py:65 2019-01-17 06:53:46.451470: step 17976, loss = 0.34922 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:53:47.741287 ops/training.py:65 2019-01-17 06:53:47.741212: step 17977, loss = 0.33132 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 06:53:49.030140 ops/training.py:65 2019-01-17 06:53:49.030071: step 17978, loss = 0.40201 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:53:50.310152 ops/training.py:65 2019-01-17 06:53:50.310078: step 17979, loss = 0.30817 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:53:51.595984 ops/training.py:65 2019-01-17 06:53:51.595872: step 17980, loss = 0.27977 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:53:52.879344 ops/training.py:65 2019-01-17 06:53:52.879246: step 17981, loss = 0.22589 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:53:54.171195 ops/training.py:65 2019-01-17 06:53:54.171051: step 17982, loss = 0.27437 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:53:55.461654 ops/training.py:65 2019-01-17 06:53:55.461561: step 17983, loss = 0.28557 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:53:56.747636 ops/training.py:65 2019-01-17 06:53:56.747570: step 17984, loss = 0.32947 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:53:58.033083 ops/training.py:65 2019-01-17 06:53:58.033013: step 17985, loss = 0.31043 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:53:59.322495 ops/training.py:65 2019-01-17 06:53:59.322421: step 17986, loss = 0.24488 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:54:00.612410 ops/training.py:65 2019-01-17 06:54:00.612339: step 17987, loss = 0.31895 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:54:01.896191 ops/training.py:65 2019-01-17 06:54:01.896126: step 17988, loss = 0.23724 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:54:03.186340 ops/training.py:65 2019-01-17 06:54:03.186265: step 17989, loss = 0.31804 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:54:04.475566 ops/training.py:65 2019-01-17 06:54:04.475468: step 17990, loss = 0.31658 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:54:05.760828 ops/training.py:65 2019-01-17 06:54:05.760757: step 17991, loss = 0.25319 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:54:07.049657 ops/training.py:65 2019-01-17 06:54:07.049591: step 17992, loss = 0.25838 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:54:08.333361 ops/training.py:65 2019-01-17 06:54:08.333292: step 17993, loss = 0.32583 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:54:09.619208 ops/training.py:65 2019-01-17 06:54:09.619120: step 17994, loss = 0.30614 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 06:54:10.910836 ops/training.py:65 2019-01-17 06:54:10.910737: step 17995, loss = 0.35316 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 06:54:12.202002 ops/training.py:65 2019-01-17 06:54:12.201929: step 17996, loss = 0.27351 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 06:54:13.491174 ops/training.py:65 2019-01-17 06:54:13.491099: step 17997, loss = 0.31722 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 06:54:14.781783 ops/training.py:65 2019-01-17 06:54:14.781701: step 17998, loss = 0.31062 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 06:54:16.070678 ops/training.py:65 2019-01-17 06:54:16.070606: step 17999, loss = 0.39293 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:00:21.710910 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I4672 2019-01-17 07:00:21.711860 ops/training.py:41 2019-01-17 07:00:21.711809: step 18000, loss = 0.32 (0.1 examples/sec; 364.352 sec/batch) | Training accuracy = 0.96875 | Validation accuracy = 0.50605 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_23_33_01_706250
I4672 2019-01-17 07:00:22.997285 ops/training.py:65 2019-01-17 07:00:22.997230: step 18001, loss = 0.28897 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:00:24.284549 ops/training.py:65 2019-01-17 07:00:24.284499: step 18002, loss = 0.30455 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:00:25.572575 ops/training.py:65 2019-01-17 07:00:25.572512: step 18003, loss = 0.35061 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:00:26.861194 ops/training.py:65 2019-01-17 07:00:26.861135: step 18004, loss = 0.34947 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:00:28.150262 ops/training.py:65 2019-01-17 07:00:28.150189: step 18005, loss = 0.35033 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:00:29.439938 ops/training.py:65 2019-01-17 07:00:29.439865: step 18006, loss = 0.33739 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:00:30.728063 ops/training.py:65 2019-01-17 07:00:30.728015: step 18007, loss = 0.28866 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:00:32.011146 ops/training.py:65 2019-01-17 07:00:32.011093: step 18008, loss = 0.35542 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:00:33.299536 ops/training.py:65 2019-01-17 07:00:33.299478: step 18009, loss = 0.18973 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:00:34.587204 ops/training.py:65 2019-01-17 07:00:34.587138: step 18010, loss = 0.30828 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:00:35.875925 ops/training.py:65 2019-01-17 07:00:35.875845: step 18011, loss = 0.34377 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:00:37.160099 ops/training.py:65 2019-01-17 07:00:37.160034: step 18012, loss = 0.36145 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:00:38.446976 ops/training.py:65 2019-01-17 07:00:38.446939: step 18013, loss = 0.34339 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:00:39.736262 ops/training.py:65 2019-01-17 07:00:39.736214: step 18014, loss = 0.31790 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:00:41.024809 ops/training.py:65 2019-01-17 07:00:41.024744: step 18015, loss = 0.29331 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:00:42.308740 ops/training.py:65 2019-01-17 07:00:42.308700: step 18016, loss = 0.29372 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:00:43.597533 ops/training.py:65 2019-01-17 07:00:43.597497: step 18017, loss = 0.27125 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:00:44.886320 ops/training.py:65 2019-01-17 07:00:44.886253: step 18018, loss = 0.23852 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:00:46.171995 ops/training.py:65 2019-01-17 07:00:46.171937: step 18019, loss = 0.32520 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:00:47.455233 ops/training.py:65 2019-01-17 07:00:47.455202: step 18020, loss = 0.25871 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:00:48.746227 ops/training.py:65 2019-01-17 07:00:48.746196: step 18021, loss = 0.40561 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:00:50.035701 ops/training.py:65 2019-01-17 07:00:50.035656: step 18022, loss = 0.22992 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:00:51.320952 ops/training.py:65 2019-01-17 07:00:51.320895: step 18023, loss = 0.35965 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:00:52.603006 ops/training.py:65 2019-01-17 07:00:52.602972: step 18024, loss = 0.25309 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:00:53.891943 ops/training.py:65 2019-01-17 07:00:53.891913: step 18025, loss = 0.34638 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:00:55.181698 ops/training.py:65 2019-01-17 07:00:55.181643: step 18026, loss = 0.28171 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:00:56.471212 ops/training.py:65 2019-01-17 07:00:56.471121: step 18027, loss = 0.31734 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:00:57.757501 ops/training.py:65 2019-01-17 07:00:57.757419: step 18028, loss = 0.33315 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:00:59.045422 ops/training.py:65 2019-01-17 07:00:59.045325: step 18029, loss = 0.24428 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:01:00.329698 ops/training.py:65 2019-01-17 07:01:00.329629: step 18030, loss = 0.29074 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:01:01.614914 ops/training.py:65 2019-01-17 07:01:01.614765: step 18031, loss = 0.31043 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:01:02.903315 ops/training.py:65 2019-01-17 07:01:02.903220: step 18032, loss = 0.24991 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:01:04.192878 ops/training.py:65 2019-01-17 07:01:04.192790: step 18033, loss = 0.38742 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:01:05.481184 ops/training.py:65 2019-01-17 07:01:05.481112: step 18034, loss = 0.22790 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:01:06.771072 ops/training.py:65 2019-01-17 07:01:06.770995: step 18035, loss = 0.31719 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:01:08.055592 ops/training.py:65 2019-01-17 07:01:08.055516: step 18036, loss = 0.30752 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:01:09.339909 ops/training.py:65 2019-01-17 07:01:09.339811: step 18037, loss = 0.24681 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:01:10.626359 ops/training.py:65 2019-01-17 07:01:10.626255: step 18038, loss = 0.24114 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:01:11.917571 ops/training.py:65 2019-01-17 07:01:11.917415: step 18039, loss = 0.28609 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:01:13.210005 ops/training.py:65 2019-01-17 07:01:13.209910: step 18040, loss = 0.26939 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:01:14.498690 ops/training.py:65 2019-01-17 07:01:14.498591: step 18041, loss = 0.29708 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:01:15.783525 ops/training.py:65 2019-01-17 07:01:15.783453: step 18042, loss = 0.25820 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:01:17.067629 ops/training.py:65 2019-01-17 07:01:17.067531: step 18043, loss = 0.35110 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:01:18.357350 ops/training.py:65 2019-01-17 07:01:18.357192: step 18044, loss = 0.31118 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:01:19.644446 ops/training.py:65 2019-01-17 07:01:19.644378: step 18045, loss = 0.36280 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:01:20.934352 ops/training.py:65 2019-01-17 07:01:20.934196: step 18046, loss = 0.29340 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:01:22.220500 ops/training.py:65 2019-01-17 07:01:22.220435: step 18047, loss = 0.22996 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:01:23.504859 ops/training.py:65 2019-01-17 07:01:23.504768: step 18048, loss = 0.32944 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:01:24.794159 ops/training.py:65 2019-01-17 07:01:24.794000: step 18049, loss = 0.30761 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:01:26.083369 ops/training.py:65 2019-01-17 07:01:26.083277: step 18050, loss = 0.41542 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:01:27.372203 ops/training.py:65 2019-01-17 07:01:27.372114: step 18051, loss = 0.32705 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:01:28.660664 ops/training.py:65 2019-01-17 07:01:28.660590: step 18052, loss = 0.26004 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:01:29.948728 ops/training.py:65 2019-01-17 07:01:29.948650: step 18053, loss = 0.28913 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:01:31.231776 ops/training.py:65 2019-01-17 07:01:31.231709: step 18054, loss = 0.37774 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:01:32.520702 ops/training.py:65 2019-01-17 07:01:32.520546: step 18055, loss = 0.20669 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:01:33.804438 ops/training.py:65 2019-01-17 07:01:33.804364: step 18056, loss = 0.28826 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:01:35.090168 ops/training.py:65 2019-01-17 07:01:35.090059: step 18057, loss = 0.32393 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:01:36.377758 ops/training.py:65 2019-01-17 07:01:36.377647: step 18058, loss = 0.31559 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:01:37.664108 ops/training.py:65 2019-01-17 07:01:37.663965: step 18059, loss = 0.26860 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:01:38.955593 ops/training.py:65 2019-01-17 07:01:38.955483: step 18060, loss = 0.29032 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:01:40.245581 ops/training.py:65 2019-01-17 07:01:40.245511: step 18061, loss = 0.28260 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:01:41.529112 ops/training.py:65 2019-01-17 07:01:41.529046: step 18062, loss = 0.24767 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:01:42.816089 ops/training.py:65 2019-01-17 07:01:42.816019: step 18063, loss = 0.39715 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 07:01:44.103007 ops/training.py:65 2019-01-17 07:01:44.102942: step 18064, loss = 0.28003 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:01:45.384089 ops/training.py:65 2019-01-17 07:01:45.383975: step 18065, loss = 0.26418 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:01:46.672335 ops/training.py:65 2019-01-17 07:01:46.672175: step 18066, loss = 0.31801 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:01:47.958119 ops/training.py:65 2019-01-17 07:01:47.958010: step 18067, loss = 0.26143 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:01:49.247552 ops/training.py:65 2019-01-17 07:01:49.247457: step 18068, loss = 0.29574 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:01:50.536097 ops/training.py:65 2019-01-17 07:01:50.535988: step 18069, loss = 0.26353 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:01:51.826426 ops/training.py:65 2019-01-17 07:01:51.826328: step 18070, loss = 0.31056 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:01:53.113910 ops/training.py:65 2019-01-17 07:01:53.113839: step 18071, loss = 0.32269 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:01:54.399354 ops/training.py:65 2019-01-17 07:01:54.399258: step 18072, loss = 0.32878 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:01:55.686454 ops/training.py:65 2019-01-17 07:01:55.686342: step 18073, loss = 0.23254 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:01:56.971437 ops/training.py:65 2019-01-17 07:01:56.971329: step 18074, loss = 0.33187 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:01:58.262726 ops/training.py:65 2019-01-17 07:01:58.262625: step 18075, loss = 0.28723 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:01:59.552648 ops/training.py:65 2019-01-17 07:01:59.552569: step 18076, loss = 0.35258 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:02:00.835536 ops/training.py:65 2019-01-17 07:02:00.835465: step 18077, loss = 0.27657 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:02:02.123269 ops/training.py:65 2019-01-17 07:02:02.123162: step 18078, loss = 0.26797 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:02:03.414611 ops/training.py:65 2019-01-17 07:02:03.414544: step 18079, loss = 0.25040 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:02:04.702758 ops/training.py:65 2019-01-17 07:02:04.702686: step 18080, loss = 0.30565 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:02:05.990088 ops/training.py:65 2019-01-17 07:02:05.990019: step 18081, loss = 0.34833 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:02:07.278620 ops/training.py:65 2019-01-17 07:02:07.278556: step 18082, loss = 0.31889 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:02:08.561892 ops/training.py:65 2019-01-17 07:02:08.561826: step 18083, loss = 0.30387 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:02:09.850523 ops/training.py:65 2019-01-17 07:02:09.850382: step 18084, loss = 0.29541 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:02:11.135015 ops/training.py:65 2019-01-17 07:02:11.134904: step 18085, loss = 0.26405 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:02:12.426232 ops/training.py:65 2019-01-17 07:02:12.426120: step 18086, loss = 0.37888 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:02:13.713849 ops/training.py:65 2019-01-17 07:02:13.713748: step 18087, loss = 0.30728 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:02:15.001492 ops/training.py:65 2019-01-17 07:02:15.001419: step 18088, loss = 0.24104 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:02:16.290090 ops/training.py:65 2019-01-17 07:02:16.290011: step 18089, loss = 0.30210 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:02:17.570611 ops/training.py:65 2019-01-17 07:02:17.570536: step 18090, loss = 0.26170 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:02:18.854562 ops/training.py:65 2019-01-17 07:02:18.854464: step 18091, loss = 0.27124 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:02:20.142185 ops/training.py:65 2019-01-17 07:02:20.142081: step 18092, loss = 0.33340 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:02:21.428931 ops/training.py:65 2019-01-17 07:02:21.428825: step 18093, loss = 0.33450 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:02:22.713368 ops/training.py:65 2019-01-17 07:02:22.713262: step 18094, loss = 0.31230 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:02:24.005480 ops/training.py:65 2019-01-17 07:02:24.005337: step 18095, loss = 0.23835 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:02:25.296077 ops/training.py:65 2019-01-17 07:02:25.296005: step 18096, loss = 0.26628 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:02:26.584034 ops/training.py:65 2019-01-17 07:02:26.583877: step 18097, loss = 0.25923 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:02:27.870344 ops/training.py:65 2019-01-17 07:02:27.870269: step 18098, loss = 0.27887 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:02:29.160020 ops/training.py:65 2019-01-17 07:02:29.159912: step 18099, loss = 0.29988 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:02:30.444363 ops/training.py:65 2019-01-17 07:02:30.444257: step 18100, loss = 0.31519 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:02:31.728296 ops/training.py:65 2019-01-17 07:02:31.728186: step 18101, loss = 0.23142 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:02:33.015226 ops/training.py:65 2019-01-17 07:02:33.015120: step 18102, loss = 0.39922 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:02:34.300090 ops/training.py:65 2019-01-17 07:02:34.299995: step 18103, loss = 0.33430 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:02:35.591556 ops/training.py:65 2019-01-17 07:02:35.591445: step 18104, loss = 0.22768 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:02:36.879746 ops/training.py:65 2019-01-17 07:02:36.879649: step 18105, loss = 0.32338 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 07:02:38.168959 ops/training.py:65 2019-01-17 07:02:38.168887: step 18106, loss = 0.32684 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:02:39.460313 ops/training.py:65 2019-01-17 07:02:39.460234: step 18107, loss = 0.31875 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:02:40.742741 ops/training.py:65 2019-01-17 07:02:40.742641: step 18108, loss = 0.27760 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:02:42.033812 ops/training.py:65 2019-01-17 07:02:42.033707: step 18109, loss = 0.19732 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:02:43.324944 ops/training.py:65 2019-01-17 07:02:43.324874: step 18110, loss = 0.27496 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:02:44.612852 ops/training.py:65 2019-01-17 07:02:44.612783: step 18111, loss = 0.22960 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:02:45.902256 ops/training.py:65 2019-01-17 07:02:45.902165: step 18112, loss = 0.34705 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:02:47.191724 ops/training.py:65 2019-01-17 07:02:47.191655: step 18113, loss = 0.25939 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:02:48.480557 ops/training.py:65 2019-01-17 07:02:48.480483: step 18114, loss = 0.29062 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:02:49.767469 ops/training.py:65 2019-01-17 07:02:49.767400: step 18115, loss = 0.27667 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:02:51.055278 ops/training.py:65 2019-01-17 07:02:51.055193: step 18116, loss = 0.27161 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:02:52.342081 ops/training.py:65 2019-01-17 07:02:52.342011: step 18117, loss = 0.36963 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:02:53.626016 ops/training.py:65 2019-01-17 07:02:53.625953: step 18118, loss = 0.29775 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:02:54.914308 ops/training.py:65 2019-01-17 07:02:54.914200: step 18119, loss = 0.25793 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:02:56.203535 ops/training.py:65 2019-01-17 07:02:56.203435: step 18120, loss = 0.33192 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 07:02:57.498696 ops/training.py:65 2019-01-17 07:02:57.498629: step 18121, loss = 0.27196 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:02:58.786113 ops/training.py:65 2019-01-17 07:02:58.786041: step 18122, loss = 0.26948 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:03:00.075001 ops/training.py:65 2019-01-17 07:03:00.074929: step 18123, loss = 0.32961 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:03:01.362844 ops/training.py:65 2019-01-17 07:03:01.362772: step 18124, loss = 0.28567 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:03:02.647318 ops/training.py:65 2019-01-17 07:03:02.647247: step 18125, loss = 0.27895 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:03:03.941274 ops/training.py:65 2019-01-17 07:03:03.941177: step 18126, loss = 0.24320 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:03:05.229108 ops/training.py:65 2019-01-17 07:03:05.229044: step 18127, loss = 0.24891 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:03:06.517320 ops/training.py:65 2019-01-17 07:03:06.517223: step 18128, loss = 0.22513 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:03:07.805842 ops/training.py:65 2019-01-17 07:03:07.805768: step 18129, loss = 0.29522 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:03:09.089709 ops/training.py:65 2019-01-17 07:03:09.089614: step 18130, loss = 0.25580 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:03:10.381166 ops/training.py:65 2019-01-17 07:03:10.381056: step 18131, loss = 0.31052 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:03:11.671298 ops/training.py:65 2019-01-17 07:03:11.671234: step 18132, loss = 0.29562 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:03:12.960334 ops/training.py:65 2019-01-17 07:03:12.960248: step 18133, loss = 0.35290 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:03:14.248966 ops/training.py:65 2019-01-17 07:03:14.248892: step 18134, loss = 0.29150 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:03:15.532945 ops/training.py:65 2019-01-17 07:03:15.532880: step 18135, loss = 0.31779 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:03:16.821259 ops/training.py:65 2019-01-17 07:03:16.821153: step 18136, loss = 0.26892 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:03:18.105689 ops/training.py:65 2019-01-17 07:03:18.105625: step 18137, loss = 0.23819 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:03:19.389916 ops/training.py:65 2019-01-17 07:03:19.389816: step 18138, loss = 0.36756 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:03:20.681927 ops/training.py:65 2019-01-17 07:03:20.681815: step 18139, loss = 0.25650 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:03:21.972104 ops/training.py:65 2019-01-17 07:03:21.972026: step 18140, loss = 0.34695 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:03:23.259546 ops/training.py:65 2019-01-17 07:03:23.259473: step 18141, loss = 0.31918 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:03:24.548626 ops/training.py:65 2019-01-17 07:03:24.548548: step 18142, loss = 0.33662 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:03:25.835219 ops/training.py:65 2019-01-17 07:03:25.835130: step 18143, loss = 0.28721 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:03:27.130166 ops/training.py:65 2019-01-17 07:03:27.130075: step 18144, loss = 0.25227 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:03:28.417824 ops/training.py:65 2019-01-17 07:03:28.417757: step 18145, loss = 0.30811 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:03:29.700527 ops/training.py:65 2019-01-17 07:03:29.700464: step 18146, loss = 0.24605 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:03:30.989172 ops/training.py:65 2019-01-17 07:03:30.989063: step 18147, loss = 0.31634 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:03:32.277761 ops/training.py:65 2019-01-17 07:03:32.277690: step 18148, loss = 0.27782 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:03:33.566133 ops/training.py:65 2019-01-17 07:03:33.566059: step 18149, loss = 0.24736 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:03:34.854207 ops/training.py:65 2019-01-17 07:03:34.854138: step 18150, loss = 0.29000 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:03:36.142861 ops/training.py:65 2019-01-17 07:03:36.142795: step 18151, loss = 0.37667 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:03:37.423090 ops/training.py:65 2019-01-17 07:03:37.423010: step 18152, loss = 0.24517 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:03:38.707846 ops/training.py:65 2019-01-17 07:03:38.707743: step 18153, loss = 0.29164 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:03:39.998721 ops/training.py:65 2019-01-17 07:03:39.998571: step 18154, loss = 0.28642 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:03:41.289591 ops/training.py:65 2019-01-17 07:03:41.289531: step 18155, loss = 0.26207 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:03:42.575700 ops/training.py:65 2019-01-17 07:03:42.575597: step 18156, loss = 0.28159 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:03:43.862446 ops/training.py:65 2019-01-17 07:03:43.862348: step 18157, loss = 0.32942 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:03:45.153753 ops/training.py:65 2019-01-17 07:03:45.153655: step 18158, loss = 0.27839 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:03:46.444693 ops/training.py:65 2019-01-17 07:03:46.444593: step 18159, loss = 0.31845 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:03:47.734461 ops/training.py:65 2019-01-17 07:03:47.734397: step 18160, loss = 0.26677 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:03:49.022502 ops/training.py:65 2019-01-17 07:03:49.022432: step 18161, loss = 0.37105 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:03:50.306404 ops/training.py:65 2019-01-17 07:03:50.306340: step 18162, loss = 0.33522 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:03:51.590402 ops/training.py:65 2019-01-17 07:03:51.590299: step 18163, loss = 0.37730 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:03:52.880867 ops/training.py:65 2019-01-17 07:03:52.880755: step 18164, loss = 0.34788 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:03:54.170585 ops/training.py:65 2019-01-17 07:03:54.170514: step 18165, loss = 0.30087 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:03:55.454879 ops/training.py:65 2019-01-17 07:03:55.454814: step 18166, loss = 0.35396 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:03:56.740223 ops/training.py:65 2019-01-17 07:03:56.740116: step 18167, loss = 0.28405 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:03:58.024982 ops/training.py:65 2019-01-17 07:03:58.024880: step 18168, loss = 0.30325 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:03:59.315025 ops/training.py:65 2019-01-17 07:03:59.314922: step 18169, loss = 0.22655 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:04:00.605253 ops/training.py:65 2019-01-17 07:04:00.605181: step 18170, loss = 0.29602 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:04:01.893122 ops/training.py:65 2019-01-17 07:04:01.893028: step 18171, loss = 0.28156 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:04:03.180510 ops/training.py:65 2019-01-17 07:04:03.180442: step 18172, loss = 0.36640 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:04:04.463828 ops/training.py:65 2019-01-17 07:04:04.463770: step 18173, loss = 0.25980 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:04:05.757108 ops/training.py:65 2019-01-17 07:04:05.756996: step 18174, loss = 0.26665 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:04:07.044856 ops/training.py:65 2019-01-17 07:04:07.044792: step 18175, loss = 0.24298 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:04:08.333222 ops/training.py:65 2019-01-17 07:04:08.333119: step 18176, loss = 0.33694 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:04:09.621770 ops/training.py:65 2019-01-17 07:04:09.621699: step 18177, loss = 0.34155 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:04:10.905691 ops/training.py:65 2019-01-17 07:04:10.905628: step 18178, loss = 0.35820 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 07:04:12.195034 ops/training.py:65 2019-01-17 07:04:12.194891: step 18179, loss = 0.23805 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:04:13.484345 ops/training.py:65 2019-01-17 07:04:13.484274: step 18180, loss = 0.28790 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:04:14.772591 ops/training.py:65 2019-01-17 07:04:14.772520: step 18181, loss = 0.25147 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:04:16.059714 ops/training.py:65 2019-01-17 07:04:16.059641: step 18182, loss = 0.30014 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:04:17.347432 ops/training.py:65 2019-01-17 07:04:17.347363: step 18183, loss = 0.39794 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 07:04:18.631937 ops/training.py:65 2019-01-17 07:04:18.631867: step 18184, loss = 0.29044 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:04:19.920345 ops/training.py:65 2019-01-17 07:04:19.920267: step 18185, loss = 0.42271 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:04:21.208590 ops/training.py:65 2019-01-17 07:04:21.208516: step 18186, loss = 0.29661 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:04:22.503712 ops/training.py:65 2019-01-17 07:04:22.503625: step 18187, loss = 0.30262 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:04:23.792731 ops/training.py:65 2019-01-17 07:04:23.792655: step 18188, loss = 0.29928 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:04:25.081010 ops/training.py:65 2019-01-17 07:04:25.080921: step 18189, loss = 0.32715 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:04:26.363008 ops/training.py:65 2019-01-17 07:04:26.362931: step 18190, loss = 0.37591 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 07:04:27.653281 ops/training.py:65 2019-01-17 07:04:27.653181: step 18191, loss = 0.39607 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 07:04:28.943622 ops/training.py:65 2019-01-17 07:04:28.943520: step 18192, loss = 0.34875 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:04:30.227853 ops/training.py:65 2019-01-17 07:04:30.227786: step 18193, loss = 0.30511 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:04:31.517416 ops/training.py:65 2019-01-17 07:04:31.517307: step 18194, loss = 0.28695 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:04:32.805108 ops/training.py:65 2019-01-17 07:04:32.805038: step 18195, loss = 0.25977 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:04:34.092315 ops/training.py:65 2019-01-17 07:04:34.092239: step 18196, loss = 0.30718 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:04:35.377343 ops/training.py:65 2019-01-17 07:04:35.377272: step 18197, loss = 0.28629 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:04:36.660358 ops/training.py:65 2019-01-17 07:04:36.660246: step 18198, loss = 0.25599 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:04:37.946606 ops/training.py:65 2019-01-17 07:04:37.946496: step 18199, loss = 0.26084 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:04:39.234637 ops/training.py:65 2019-01-17 07:04:39.234523: step 18200, loss = 0.26102 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:04:40.527109 ops/training.py:65 2019-01-17 07:04:40.526998: step 18201, loss = 0.32330 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:04:41.818363 ops/training.py:65 2019-01-17 07:04:41.818257: step 18202, loss = 0.27953 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:04:43.107789 ops/training.py:65 2019-01-17 07:04:43.107693: step 18203, loss = 0.38677 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:04:44.392690 ops/training.py:65 2019-01-17 07:04:44.392620: step 18204, loss = 0.31885 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:04:45.676605 ops/training.py:65 2019-01-17 07:04:45.676497: step 18205, loss = 0.30828 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:04:46.969108 ops/training.py:65 2019-01-17 07:04:46.969004: step 18206, loss = 0.33014 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:04:48.255382 ops/training.py:65 2019-01-17 07:04:48.255315: step 18207, loss = 0.30249 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:04:49.544131 ops/training.py:65 2019-01-17 07:04:49.543991: step 18208, loss = 0.35680 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:04:50.833628 ops/training.py:65 2019-01-17 07:04:50.833553: step 18209, loss = 0.29289 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:04:52.121250 ops/training.py:65 2019-01-17 07:04:52.121180: step 18210, loss = 0.27895 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:04:53.404008 ops/training.py:65 2019-01-17 07:04:53.403941: step 18211, loss = 0.35020 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:04:54.692484 ops/training.py:65 2019-01-17 07:04:54.692375: step 18212, loss = 0.27553 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:04:55.982875 ops/training.py:65 2019-01-17 07:04:55.982800: step 18213, loss = 0.21985 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:04:57.271678 ops/training.py:65 2019-01-17 07:04:57.271610: step 18214, loss = 0.28142 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:04:58.559611 ops/training.py:65 2019-01-17 07:04:58.559533: step 18215, loss = 0.36135 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:04:59.847442 ops/training.py:65 2019-01-17 07:04:59.847370: step 18216, loss = 0.26795 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:05:01.134667 ops/training.py:65 2019-01-17 07:05:01.134606: step 18217, loss = 0.23216 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:05:02.422318 ops/training.py:65 2019-01-17 07:05:02.422257: step 18218, loss = 0.29248 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:05:03.704030 ops/training.py:65 2019-01-17 07:05:03.703956: step 18219, loss = 0.33666 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:05:04.987170 ops/training.py:65 2019-01-17 07:05:04.987070: step 18220, loss = 0.23878 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:05:06.280175 ops/training.py:65 2019-01-17 07:05:06.280068: step 18221, loss = 0.27473 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:05:07.569746 ops/training.py:65 2019-01-17 07:05:07.569675: step 18222, loss = 0.21177 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:05:08.853286 ops/training.py:65 2019-01-17 07:05:08.853218: step 18223, loss = 0.28325 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:05:10.143511 ops/training.py:65 2019-01-17 07:05:10.143411: step 18224, loss = 0.27039 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:05:11.432228 ops/training.py:65 2019-01-17 07:05:11.432136: step 18225, loss = 0.29474 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:05:12.720259 ops/training.py:65 2019-01-17 07:05:12.720195: step 18226, loss = 0.27825 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:05:14.003296 ops/training.py:65 2019-01-17 07:05:14.003220: step 18227, loss = 0.24658 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:05:15.284676 ops/training.py:65 2019-01-17 07:05:15.284568: step 18228, loss = 0.26320 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:05:16.576259 ops/training.py:65 2019-01-17 07:05:16.576102: step 18229, loss = 0.31829 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:05:17.867851 ops/training.py:65 2019-01-17 07:05:17.867789: step 18230, loss = 0.25533 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:05:19.156699 ops/training.py:65 2019-01-17 07:05:19.156635: step 18231, loss = 0.25816 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:05:20.445755 ops/training.py:65 2019-01-17 07:05:20.445690: step 18232, loss = 0.28847 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:05:21.730378 ops/training.py:65 2019-01-17 07:05:21.730312: step 18233, loss = 0.27301 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:05:23.013584 ops/training.py:65 2019-01-17 07:05:23.013480: step 18234, loss = 0.26224 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:05:24.299682 ops/training.py:65 2019-01-17 07:05:24.299579: step 18235, loss = 0.22730 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:05:25.584727 ops/training.py:65 2019-01-17 07:05:25.584625: step 18236, loss = 0.28696 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:05:26.870681 ops/training.py:65 2019-01-17 07:05:26.870576: step 18237, loss = 0.29884 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:05:28.161233 ops/training.py:65 2019-01-17 07:05:28.161140: step 18238, loss = 0.29277 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:05:29.446501 ops/training.py:65 2019-01-17 07:05:29.446427: step 18239, loss = 0.30232 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:05:30.730406 ops/training.py:65 2019-01-17 07:05:30.730328: step 18240, loss = 0.28723 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:05:32.017442 ops/training.py:65 2019-01-17 07:05:32.017341: step 18241, loss = 0.27948 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:05:33.298318 ops/training.py:65 2019-01-17 07:05:33.298237: step 18242, loss = 0.35265 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:05:34.586278 ops/training.py:65 2019-01-17 07:05:34.586136: step 18243, loss = 0.26751 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:05:35.877014 ops/training.py:65 2019-01-17 07:05:35.876903: step 18244, loss = 0.29964 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:05:37.165916 ops/training.py:65 2019-01-17 07:05:37.165847: step 18245, loss = 0.27425 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:05:38.453862 ops/training.py:65 2019-01-17 07:05:38.453791: step 18246, loss = 0.27524 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:05:39.742486 ops/training.py:65 2019-01-17 07:05:39.742415: step 18247, loss = 0.29377 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:05:41.026350 ops/training.py:65 2019-01-17 07:05:41.026281: step 18248, loss = 0.30280 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:05:42.314662 ops/training.py:65 2019-01-17 07:05:42.314593: step 18249, loss = 0.25411 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:05:43.603427 ops/training.py:65 2019-01-17 07:05:43.603352: step 18250, loss = 0.24245 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:05:44.891770 ops/training.py:65 2019-01-17 07:05:44.891698: step 18251, loss = 0.29434 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:05:46.176074 ops/training.py:65 2019-01-17 07:05:46.176009: step 18252, loss = 0.30027 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:05:47.460656 ops/training.py:65 2019-01-17 07:05:47.460552: step 18253, loss = 0.25863 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:05:48.744146 ops/training.py:65 2019-01-17 07:05:48.744046: step 18254, loss = 0.26353 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:05:50.036231 ops/training.py:65 2019-01-17 07:05:50.036136: step 18255, loss = 0.28224 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:05:51.328103 ops/training.py:65 2019-01-17 07:05:51.328036: step 18256, loss = 0.32071 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:05:52.616595 ops/training.py:65 2019-01-17 07:05:52.616530: step 18257, loss = 0.34145 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:05:53.904731 ops/training.py:65 2019-01-17 07:05:53.904658: step 18258, loss = 0.32484 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:05:55.191966 ops/training.py:65 2019-01-17 07:05:55.191893: step 18259, loss = 0.35572 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:05:56.479850 ops/training.py:65 2019-01-17 07:05:56.479760: step 18260, loss = 0.22080 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:05:57.768535 ops/training.py:65 2019-01-17 07:05:57.768461: step 18261, loss = 0.32345 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:05:59.056599 ops/training.py:65 2019-01-17 07:05:59.056533: step 18262, loss = 0.28472 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:06:00.346675 ops/training.py:65 2019-01-17 07:06:00.346580: step 18263, loss = 0.24615 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:06:01.634874 ops/training.py:65 2019-01-17 07:06:01.634783: step 18264, loss = 0.28874 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:06:02.924180 ops/training.py:65 2019-01-17 07:06:02.924107: step 18265, loss = 0.27736 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:06:04.212301 ops/training.py:65 2019-01-17 07:06:04.212227: step 18266, loss = 0.26588 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:06:05.501470 ops/training.py:65 2019-01-17 07:06:05.501390: step 18267, loss = 0.26968 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:06:06.789749 ops/training.py:65 2019-01-17 07:06:06.789684: step 18268, loss = 0.31019 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:06:08.078053 ops/training.py:65 2019-01-17 07:06:08.077982: step 18269, loss = 0.22516 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:06:09.365957 ops/training.py:65 2019-01-17 07:06:09.365877: step 18270, loss = 0.29668 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:06:10.651146 ops/training.py:65 2019-01-17 07:06:10.651053: step 18271, loss = 0.27415 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:06:11.941568 ops/training.py:65 2019-01-17 07:06:11.941503: step 18272, loss = 0.31343 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:06:13.225587 ops/training.py:65 2019-01-17 07:06:13.225496: step 18273, loss = 0.28030 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:06:14.506352 ops/training.py:65 2019-01-17 07:06:14.506254: step 18274, loss = 0.27330 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:06:15.797200 ops/training.py:65 2019-01-17 07:06:15.797090: step 18275, loss = 0.27909 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:06:17.086030 ops/training.py:65 2019-01-17 07:06:17.085961: step 18276, loss = 0.30825 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:06:18.375533 ops/training.py:65 2019-01-17 07:06:18.375440: step 18277, loss = 0.21590 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:06:19.661216 ops/training.py:65 2019-01-17 07:06:19.661154: step 18278, loss = 0.26816 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:06:20.945714 ops/training.py:65 2019-01-17 07:06:20.945604: step 18279, loss = 0.32835 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:06:22.231757 ops/training.py:65 2019-01-17 07:06:22.231653: step 18280, loss = 0.26489 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:06:23.523929 ops/training.py:65 2019-01-17 07:06:23.523831: step 18281, loss = 0.23655 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:06:24.813152 ops/training.py:65 2019-01-17 07:06:24.813081: step 18282, loss = 0.27482 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:06:26.102793 ops/training.py:65 2019-01-17 07:06:26.102696: step 18283, loss = 0.25524 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:06:27.388217 ops/training.py:65 2019-01-17 07:06:27.388150: step 18284, loss = 0.27103 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:06:28.672342 ops/training.py:65 2019-01-17 07:06:28.672241: step 18285, loss = 0.24517 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:06:29.963123 ops/training.py:65 2019-01-17 07:06:29.963010: step 18286, loss = 0.36150 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:06:31.253891 ops/training.py:65 2019-01-17 07:06:31.253777: step 18287, loss = 0.31441 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:06:32.543961 ops/training.py:65 2019-01-17 07:06:32.543879: step 18288, loss = 0.27005 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:06:33.831704 ops/training.py:65 2019-01-17 07:06:33.831623: step 18289, loss = 0.30362 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:06:35.121121 ops/training.py:65 2019-01-17 07:06:35.121035: step 18290, loss = 0.33723 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:06:36.410359 ops/training.py:65 2019-01-17 07:06:36.410269: step 18291, loss = 0.36187 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:06:37.695716 ops/training.py:65 2019-01-17 07:06:37.695638: step 18292, loss = 0.28496 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:06:38.979530 ops/training.py:65 2019-01-17 07:06:38.979427: step 18293, loss = 0.31172 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:06:40.260599 ops/training.py:65 2019-01-17 07:06:40.260496: step 18294, loss = 0.32617 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:06:41.547391 ops/training.py:65 2019-01-17 07:06:41.547280: step 18295, loss = 0.37735 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 07:06:42.835895 ops/training.py:65 2019-01-17 07:06:42.835806: step 18296, loss = 0.36857 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:06:44.121042 ops/training.py:65 2019-01-17 07:06:44.120970: step 18297, loss = 0.34021 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:06:45.396829 ops/training.py:65 2019-01-17 07:06:45.396730: step 18298, loss = 0.29585 (25.1 examples/sec; 1.275 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:06:46.688990 ops/training.py:65 2019-01-17 07:06:46.688883: step 18299, loss = 0.42097 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:06:47.975148 ops/training.py:65 2019-01-17 07:06:47.975049: step 18300, loss = 0.30170 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:06:49.259741 ops/training.py:65 2019-01-17 07:06:49.259610: step 18301, loss = 0.29770 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:06:50.552477 ops/training.py:65 2019-01-17 07:06:50.552378: step 18302, loss = 0.29349 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:06:51.839183 ops/training.py:65 2019-01-17 07:06:51.839106: step 18303, loss = 0.32041 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:06:53.124946 ops/training.py:65 2019-01-17 07:06:53.124846: step 18304, loss = 0.30407 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:06:54.416301 ops/training.py:65 2019-01-17 07:06:54.416200: step 18305, loss = 0.40339 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 07:06:55.703083 ops/training.py:65 2019-01-17 07:06:55.702974: step 18306, loss = 0.27494 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:06:56.983582 ops/training.py:65 2019-01-17 07:06:56.983481: step 18307, loss = 0.26043 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:06:58.264082 ops/training.py:65 2019-01-17 07:06:58.263967: step 18308, loss = 0.27197 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:06:59.546295 ops/training.py:65 2019-01-17 07:06:59.546195: step 18309, loss = 0.26263 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:07:00.828963 ops/training.py:65 2019-01-17 07:07:00.828861: step 18310, loss = 0.26883 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:07:02.115621 ops/training.py:65 2019-01-17 07:07:02.115513: step 18311, loss = 0.27962 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:07:03.395702 ops/training.py:65 2019-01-17 07:07:03.395588: step 18312, loss = 0.29468 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:07:04.686387 ops/training.py:65 2019-01-17 07:07:04.686296: step 18313, loss = 0.28093 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:07:05.971518 ops/training.py:65 2019-01-17 07:07:05.971420: step 18314, loss = 0.25334 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:07:07.257326 ops/training.py:65 2019-01-17 07:07:07.257177: step 18315, loss = 0.21445 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:07:08.539089 ops/training.py:65 2019-01-17 07:07:08.538983: step 18316, loss = 0.26690 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:07:09.823241 ops/training.py:65 2019-01-17 07:07:09.823136: step 18317, loss = 0.28607 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:07:11.111955 ops/training.py:65 2019-01-17 07:07:11.111853: step 18318, loss = 0.27317 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:07:12.405689 ops/training.py:65 2019-01-17 07:07:12.405624: step 18319, loss = 0.31504 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:07:13.695067 ops/training.py:65 2019-01-17 07:07:13.694924: step 18320, loss = 0.25741 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:07:14.985747 ops/training.py:65 2019-01-17 07:07:14.985668: step 18321, loss = 0.26074 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:07:16.269589 ops/training.py:65 2019-01-17 07:07:16.269510: step 18322, loss = 0.35237 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:07:17.557039 ops/training.py:65 2019-01-17 07:07:17.556890: step 18323, loss = 0.32599 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:07:18.849910 ops/training.py:65 2019-01-17 07:07:18.849836: step 18324, loss = 0.23370 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:07:20.132789 ops/training.py:65 2019-01-17 07:07:20.132717: step 18325, loss = 0.28846 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:07:21.416553 ops/training.py:65 2019-01-17 07:07:21.416447: step 18326, loss = 0.33493 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:07:22.703978 ops/training.py:65 2019-01-17 07:07:22.703868: step 18327, loss = 0.25744 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:07:23.988193 ops/training.py:65 2019-01-17 07:07:23.988099: step 18328, loss = 0.25742 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:07:25.276883 ops/training.py:65 2019-01-17 07:07:25.276783: step 18329, loss = 0.23753 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:07:26.567697 ops/training.py:65 2019-01-17 07:07:26.567616: step 18330, loss = 0.34013 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:07:27.856504 ops/training.py:65 2019-01-17 07:07:27.856400: step 18331, loss = 0.29318 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:07:29.147050 ops/training.py:65 2019-01-17 07:07:29.146971: step 18332, loss = 0.32437 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:07:30.430906 ops/training.py:65 2019-01-17 07:07:30.430838: step 18333, loss = 0.29927 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:07:31.715477 ops/training.py:65 2019-01-17 07:07:31.715373: step 18334, loss = 0.27516 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:07:33.000429 ops/training.py:65 2019-01-17 07:07:33.000330: step 18335, loss = 0.32000 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:07:34.290141 ops/training.py:65 2019-01-17 07:07:34.290052: step 18336, loss = 0.36486 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 07:07:35.575169 ops/training.py:65 2019-01-17 07:07:35.575093: step 18337, loss = 0.26292 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:07:36.859278 ops/training.py:65 2019-01-17 07:07:36.859174: step 18338, loss = 0.21723 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:07:38.147424 ops/training.py:65 2019-01-17 07:07:38.147322: step 18339, loss = 0.20591 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:07:39.433708 ops/training.py:65 2019-01-17 07:07:39.433608: step 18340, loss = 0.26334 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:07:40.721274 ops/training.py:65 2019-01-17 07:07:40.721173: step 18341, loss = 0.35705 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:07:42.008414 ops/training.py:65 2019-01-17 07:07:42.008302: step 18342, loss = 0.27960 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:07:43.292761 ops/training.py:65 2019-01-17 07:07:43.292668: step 18343, loss = 0.28238 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:07:44.579546 ops/training.py:65 2019-01-17 07:07:44.579446: step 18344, loss = 0.27844 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:07:45.865700 ops/training.py:65 2019-01-17 07:07:45.865596: step 18345, loss = 0.27371 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:07:47.157132 ops/training.py:65 2019-01-17 07:07:47.157024: step 18346, loss = 0.25192 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:07:48.443276 ops/training.py:65 2019-01-17 07:07:48.443195: step 18347, loss = 0.30616 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:07:49.723624 ops/training.py:65 2019-01-17 07:07:49.723527: step 18348, loss = 0.34853 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:07:51.008090 ops/training.py:65 2019-01-17 07:07:51.007990: step 18349, loss = 0.30981 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:07:52.300629 ops/training.py:65 2019-01-17 07:07:52.300526: step 18350, loss = 0.32237 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:07:53.592697 ops/training.py:65 2019-01-17 07:07:53.592618: step 18351, loss = 0.25410 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:07:54.876461 ops/training.py:65 2019-01-17 07:07:54.876360: step 18352, loss = 0.26807 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:07:56.165727 ops/training.py:65 2019-01-17 07:07:56.165569: step 18353, loss = 0.34986 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:07:57.451129 ops/training.py:65 2019-01-17 07:07:57.451019: step 18354, loss = 0.35756 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:07:58.743241 ops/training.py:65 2019-01-17 07:07:58.743100: step 18355, loss = 0.25396 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:08:00.028973 ops/training.py:65 2019-01-17 07:08:00.028912: step 18356, loss = 0.31588 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:08:01.314485 ops/training.py:65 2019-01-17 07:08:01.314378: step 18357, loss = 0.34442 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:08:02.599432 ops/training.py:65 2019-01-17 07:08:02.599325: step 18358, loss = 0.25511 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:08:03.888586 ops/training.py:65 2019-01-17 07:08:03.888481: step 18359, loss = 0.25220 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:08:05.175576 ops/training.py:65 2019-01-17 07:08:05.175479: step 18360, loss = 0.21861 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:08:06.458671 ops/training.py:65 2019-01-17 07:08:06.458566: step 18361, loss = 0.32847 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:08:07.744739 ops/training.py:65 2019-01-17 07:08:07.744628: step 18362, loss = 0.30551 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:08:09.026069 ops/training.py:65 2019-01-17 07:08:09.025965: step 18363, loss = 0.29277 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:08:10.308167 ops/training.py:65 2019-01-17 07:08:10.308067: step 18364, loss = 0.30759 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:08:11.599018 ops/training.py:65 2019-01-17 07:08:11.598914: step 18365, loss = 0.37899 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:08:12.880941 ops/training.py:65 2019-01-17 07:08:12.880836: step 18366, loss = 0.27594 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:08:14.164547 ops/training.py:65 2019-01-17 07:08:14.164432: step 18367, loss = 0.28457 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:08:15.452287 ops/training.py:65 2019-01-17 07:08:15.452176: step 18368, loss = 0.31124 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:08:16.736937 ops/training.py:65 2019-01-17 07:08:16.736830: step 18369, loss = 0.30685 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:08:18.021878 ops/training.py:65 2019-01-17 07:08:18.021773: step 18370, loss = 0.32338 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:08:19.309075 ops/training.py:65 2019-01-17 07:08:19.308979: step 18371, loss = 0.28047 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:08:20.593041 ops/training.py:65 2019-01-17 07:08:20.592934: step 18372, loss = 0.28527 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:08:21.879879 ops/training.py:65 2019-01-17 07:08:21.879772: step 18373, loss = 0.26242 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:08:23.166008 ops/training.py:65 2019-01-17 07:08:23.165907: step 18374, loss = 0.25627 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:08:24.445191 ops/training.py:65 2019-01-17 07:08:24.445088: step 18375, loss = 0.22692 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:08:25.728577 ops/training.py:65 2019-01-17 07:08:25.728473: step 18376, loss = 0.31433 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:08:27.015298 ops/training.py:65 2019-01-17 07:08:27.015199: step 18377, loss = 0.28534 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:08:28.300745 ops/training.py:65 2019-01-17 07:08:28.300649: step 18378, loss = 0.29028 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:08:29.588429 ops/training.py:65 2019-01-17 07:08:29.588329: step 18379, loss = 0.31542 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:08:30.868523 ops/training.py:65 2019-01-17 07:08:30.868418: step 18380, loss = 0.31538 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:08:32.148390 ops/training.py:65 2019-01-17 07:08:32.148281: step 18381, loss = 0.23775 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:08:33.429938 ops/training.py:65 2019-01-17 07:08:33.429838: step 18382, loss = 0.24130 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:08:34.716922 ops/training.py:65 2019-01-17 07:08:34.716817: step 18383, loss = 0.35980 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:08:36.006833 ops/training.py:65 2019-01-17 07:08:36.006735: step 18384, loss = 0.24454 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:08:37.288334 ops/training.py:65 2019-01-17 07:08:37.288172: step 18385, loss = 0.28854 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:08:38.581739 ops/training.py:65 2019-01-17 07:08:38.581583: step 18386, loss = 0.32348 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:08:39.868970 ops/training.py:65 2019-01-17 07:08:39.868860: step 18387, loss = 0.30843 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:08:41.149618 ops/training.py:65 2019-01-17 07:08:41.149511: step 18388, loss = 0.22774 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:08:42.434724 ops/training.py:65 2019-01-17 07:08:42.434618: step 18389, loss = 0.30845 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:08:43.721711 ops/training.py:65 2019-01-17 07:08:43.721562: step 18390, loss = 0.35625 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:08:45.006841 ops/training.py:65 2019-01-17 07:08:45.006681: step 18391, loss = 0.28159 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:08:46.288680 ops/training.py:65 2019-01-17 07:08:46.288578: step 18392, loss = 0.30911 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:08:47.568222 ops/training.py:65 2019-01-17 07:08:47.568111: step 18393, loss = 0.26677 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:08:48.858582 ops/training.py:65 2019-01-17 07:08:48.858480: step 18394, loss = 0.25071 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:08:50.140355 ops/training.py:65 2019-01-17 07:08:50.140263: step 18395, loss = 0.24004 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:08:51.423787 ops/training.py:65 2019-01-17 07:08:51.423679: step 18396, loss = 0.22952 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:08:52.709990 ops/training.py:65 2019-01-17 07:08:52.709876: step 18397, loss = 0.24760 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:08:54.000199 ops/training.py:65 2019-01-17 07:08:54.000048: step 18398, loss = 0.28686 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:08:55.291890 ops/training.py:65 2019-01-17 07:08:55.291786: step 18399, loss = 0.29590 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:08:56.580502 ops/training.py:65 2019-01-17 07:08:56.580396: step 18400, loss = 0.23258 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:08:57.867695 ops/training.py:65 2019-01-17 07:08:57.867630: step 18401, loss = 0.32716 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:08:59.151182 ops/training.py:65 2019-01-17 07:08:59.151118: step 18402, loss = 0.27453 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:09:00.438336 ops/training.py:65 2019-01-17 07:09:00.438185: step 18403, loss = 0.35758 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:09:01.715947 ops/training.py:65 2019-01-17 07:09:01.715842: step 18404, loss = 0.27155 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:09:03.006235 ops/training.py:65 2019-01-17 07:09:03.006138: step 18405, loss = 0.28814 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:09:04.295695 ops/training.py:65 2019-01-17 07:09:04.295614: step 18406, loss = 0.31202 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:09:05.581187 ops/training.py:65 2019-01-17 07:09:05.581104: step 18407, loss = 0.25174 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:09:06.865261 ops/training.py:65 2019-01-17 07:09:06.865165: step 18408, loss = 0.24827 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:09:08.151494 ops/training.py:65 2019-01-17 07:09:08.151387: step 18409, loss = 0.30725 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:09:09.435042 ops/training.py:65 2019-01-17 07:09:09.434943: step 18410, loss = 0.29119 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:09:10.718990 ops/training.py:65 2019-01-17 07:09:10.718910: step 18411, loss = 0.32609 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:09:12.004778 ops/training.py:65 2019-01-17 07:09:12.004690: step 18412, loss = 0.29377 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:09:13.291295 ops/training.py:65 2019-01-17 07:09:13.291244: step 18413, loss = 0.30249 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:09:14.575681 ops/training.py:65 2019-01-17 07:09:14.575616: step 18414, loss = 0.29954 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:09:15.861609 ops/training.py:65 2019-01-17 07:09:15.861517: step 18415, loss = 0.23657 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:09:17.147330 ops/training.py:65 2019-01-17 07:09:17.147231: step 18416, loss = 0.28187 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:09:18.432529 ops/training.py:65 2019-01-17 07:09:18.432420: step 18417, loss = 0.25423 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:09:19.718606 ops/training.py:65 2019-01-17 07:09:19.718525: step 18418, loss = 0.24171 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:09:21.004572 ops/training.py:65 2019-01-17 07:09:21.004468: step 18419, loss = 0.31037 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:09:22.292819 ops/training.py:65 2019-01-17 07:09:22.292709: step 18420, loss = 0.29472 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:09:23.582746 ops/training.py:65 2019-01-17 07:09:23.582665: step 18421, loss = 0.23260 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:09:24.871691 ops/training.py:65 2019-01-17 07:09:24.871581: step 18422, loss = 0.29375 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:09:26.161657 ops/training.py:65 2019-01-17 07:09:26.161580: step 18423, loss = 0.24530 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:09:27.447328 ops/training.py:65 2019-01-17 07:09:27.447257: step 18424, loss = 0.28132 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:09:28.730809 ops/training.py:65 2019-01-17 07:09:28.730698: step 18425, loss = 0.24312 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:09:30.019150 ops/training.py:65 2019-01-17 07:09:30.019051: step 18426, loss = 0.24594 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:09:31.303790 ops/training.py:65 2019-01-17 07:09:31.303686: step 18427, loss = 0.28409 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:09:32.591076 ops/training.py:65 2019-01-17 07:09:32.590980: step 18428, loss = 0.32021 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:09:33.874777 ops/training.py:65 2019-01-17 07:09:33.874672: step 18429, loss = 0.26242 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:09:35.166569 ops/training.py:65 2019-01-17 07:09:35.166475: step 18430, loss = 0.32487 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:09:36.450967 ops/training.py:65 2019-01-17 07:09:36.450859: step 18431, loss = 0.27154 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:09:37.738724 ops/training.py:65 2019-01-17 07:09:37.738619: step 18432, loss = 0.27446 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:09:39.030047 ops/training.py:65 2019-01-17 07:09:39.029925: step 18433, loss = 0.30861 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:09:40.316791 ops/training.py:65 2019-01-17 07:09:40.316721: step 18434, loss = 0.29502 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:09:41.599857 ops/training.py:65 2019-01-17 07:09:41.599758: step 18435, loss = 0.27656 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:09:42.886057 ops/training.py:65 2019-01-17 07:09:42.885949: step 18436, loss = 0.23061 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:09:44.178998 ops/training.py:65 2019-01-17 07:09:44.178850: step 18437, loss = 0.29758 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:09:45.470521 ops/training.py:65 2019-01-17 07:09:45.470417: step 18438, loss = 0.29541 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:09:46.759653 ops/training.py:65 2019-01-17 07:09:46.759560: step 18439, loss = 0.27921 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:09:48.044073 ops/training.py:65 2019-01-17 07:09:48.044010: step 18440, loss = 0.26532 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:09:49.335628 ops/training.py:65 2019-01-17 07:09:49.335539: step 18441, loss = 0.35084 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:09:50.623553 ops/training.py:65 2019-01-17 07:09:50.623481: step 18442, loss = 0.22967 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:09:51.907439 ops/training.py:65 2019-01-17 07:09:51.907334: step 18443, loss = 0.29734 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:09:53.193654 ops/training.py:65 2019-01-17 07:09:53.193553: step 18444, loss = 0.29148 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:09:54.480103 ops/training.py:65 2019-01-17 07:09:54.480006: step 18445, loss = 0.27155 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:09:55.767706 ops/training.py:65 2019-01-17 07:09:55.767600: step 18446, loss = 0.22509 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:09:57.054017 ops/training.py:65 2019-01-17 07:09:57.053942: step 18447, loss = 0.27271 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:09:58.337917 ops/training.py:65 2019-01-17 07:09:58.337814: step 18448, loss = 0.27921 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:09:59.630253 ops/training.py:65 2019-01-17 07:09:59.630146: step 18449, loss = 0.30895 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:10:00.921721 ops/training.py:65 2019-01-17 07:10:00.921622: step 18450, loss = 0.23309 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:10:02.208485 ops/training.py:65 2019-01-17 07:10:02.208421: step 18451, loss = 0.29346 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:10:03.496713 ops/training.py:65 2019-01-17 07:10:03.496619: step 18452, loss = 0.28629 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:10:04.787696 ops/training.py:65 2019-01-17 07:10:04.787622: step 18453, loss = 0.30471 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:10:06.073350 ops/training.py:65 2019-01-17 07:10:06.073276: step 18454, loss = 0.21324 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:10:07.357281 ops/training.py:65 2019-01-17 07:10:07.357171: step 18455, loss = 0.25948 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:10:08.640732 ops/training.py:65 2019-01-17 07:10:08.640623: step 18456, loss = 0.27492 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:10:09.931615 ops/training.py:65 2019-01-17 07:10:09.931509: step 18457, loss = 0.24842 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:10:11.219219 ops/training.py:65 2019-01-17 07:10:11.219118: step 18458, loss = 0.30659 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:10:12.507297 ops/training.py:65 2019-01-17 07:10:12.507189: step 18459, loss = 0.39041 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:10:13.794497 ops/training.py:65 2019-01-17 07:10:13.794400: step 18460, loss = 0.23544 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:10:15.084886 ops/training.py:65 2019-01-17 07:10:15.084743: step 18461, loss = 0.26401 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:10:16.370631 ops/training.py:65 2019-01-17 07:10:16.370530: step 18462, loss = 0.29226 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:10:17.657526 ops/training.py:65 2019-01-17 07:10:17.657361: step 18463, loss = 0.29719 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:10:18.941658 ops/training.py:65 2019-01-17 07:10:18.941562: step 18464, loss = 0.29518 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:10:20.224627 ops/training.py:65 2019-01-17 07:10:20.224537: step 18465, loss = 0.30091 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:10:21.510935 ops/training.py:65 2019-01-17 07:10:21.510832: step 18466, loss = 0.26593 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:10:22.795929 ops/training.py:65 2019-01-17 07:10:22.795789: step 18467, loss = 0.38392 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:10:24.087832 ops/training.py:65 2019-01-17 07:10:24.087749: step 18468, loss = 0.27707 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:10:25.376394 ops/training.py:65 2019-01-17 07:10:25.376283: step 18469, loss = 0.32263 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:10:26.660675 ops/training.py:65 2019-01-17 07:10:26.660573: step 18470, loss = 0.26995 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:10:27.946774 ops/training.py:65 2019-01-17 07:10:27.946664: step 18471, loss = 0.23256 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:10:29.236807 ops/training.py:65 2019-01-17 07:10:29.236707: step 18472, loss = 0.26683 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:10:30.517322 ops/training.py:65 2019-01-17 07:10:30.517212: step 18473, loss = 0.26070 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:10:31.798443 ops/training.py:65 2019-01-17 07:10:31.798335: step 18474, loss = 0.23265 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:10:33.082542 ops/training.py:65 2019-01-17 07:10:33.082443: step 18475, loss = 0.35587 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:10:34.369740 ops/training.py:65 2019-01-17 07:10:34.369631: step 18476, loss = 0.26433 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:10:35.650627 ops/training.py:65 2019-01-17 07:10:35.650523: step 18477, loss = 0.29576 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:10:36.935720 ops/training.py:65 2019-01-17 07:10:36.935574: step 18478, loss = 0.28479 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:10:38.216506 ops/training.py:65 2019-01-17 07:10:38.216399: step 18479, loss = 0.32720 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:10:39.498790 ops/training.py:65 2019-01-17 07:10:39.498697: step 18480, loss = 0.30741 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:10:40.783147 ops/training.py:65 2019-01-17 07:10:40.783051: step 18481, loss = 0.25962 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:10:42.065216 ops/training.py:65 2019-01-17 07:10:42.065060: step 18482, loss = 0.27390 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:10:43.352458 ops/training.py:65 2019-01-17 07:10:43.352348: step 18483, loss = 0.26971 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:10:44.634212 ops/training.py:65 2019-01-17 07:10:44.634106: step 18484, loss = 0.24638 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:10:45.915830 ops/training.py:65 2019-01-17 07:10:45.915683: step 18485, loss = 0.30650 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:10:47.208262 ops/training.py:65 2019-01-17 07:10:47.208158: step 18486, loss = 0.24797 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:10:48.496612 ops/training.py:65 2019-01-17 07:10:48.496510: step 18487, loss = 0.30807 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:10:49.779833 ops/training.py:65 2019-01-17 07:10:49.779757: step 18488, loss = 0.28896 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:10:51.068093 ops/training.py:65 2019-01-17 07:10:51.068019: step 18489, loss = 0.30747 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:10:52.349595 ops/training.py:65 2019-01-17 07:10:52.349560: step 18490, loss = 0.27135 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:10:53.637556 ops/training.py:65 2019-01-17 07:10:53.637480: step 18491, loss = 0.23938 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:10:54.922297 ops/training.py:65 2019-01-17 07:10:54.922240: step 18492, loss = 0.25496 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:10:56.203118 ops/training.py:65 2019-01-17 07:10:56.203080: step 18493, loss = 0.32146 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:10:57.490202 ops/training.py:65 2019-01-17 07:10:57.490170: step 18494, loss = 0.17838 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:10:58.776441 ops/training.py:65 2019-01-17 07:10:58.776409: step 18495, loss = 0.28668 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:11:00.058607 ops/training.py:65 2019-01-17 07:11:00.058555: step 18496, loss = 0.28921 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:11:01.343377 ops/training.py:65 2019-01-17 07:11:01.343343: step 18497, loss = 0.31426 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:11:02.627514 ops/training.py:65 2019-01-17 07:11:02.627481: step 18498, loss = 0.32898 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:11:03.912719 ops/training.py:65 2019-01-17 07:11:03.912672: step 18499, loss = 0.32642 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:11:05.202984 ops/training.py:65 2019-01-17 07:11:05.202952: step 18500, loss = 0.36412 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:11:06.487831 ops/training.py:65 2019-01-17 07:11:06.487799: step 18501, loss = 0.26678 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:11:07.769523 ops/training.py:65 2019-01-17 07:11:07.769488: step 18502, loss = 0.27015 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:11:09.050540 ops/training.py:65 2019-01-17 07:11:09.050510: step 18503, loss = 0.24445 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:11:10.333555 ops/training.py:65 2019-01-17 07:11:10.333526: step 18504, loss = 0.24843 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:11:11.618843 ops/training.py:65 2019-01-17 07:11:11.618812: step 18505, loss = 0.24127 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:11:12.909482 ops/training.py:65 2019-01-17 07:11:12.909389: step 18506, loss = 0.27287 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:11:14.194187 ops/training.py:65 2019-01-17 07:11:14.194137: step 18507, loss = 0.26539 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:11:15.475470 ops/training.py:65 2019-01-17 07:11:15.475423: step 18508, loss = 0.25283 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:11:16.757990 ops/training.py:65 2019-01-17 07:11:16.757959: step 18509, loss = 0.32376 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:11:18.039381 ops/training.py:65 2019-01-17 07:11:18.039351: step 18510, loss = 0.24516 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:11:19.329432 ops/training.py:65 2019-01-17 07:11:19.329375: step 18511, loss = 0.29307 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:11:20.612988 ops/training.py:65 2019-01-17 07:11:20.612919: step 18512, loss = 0.29937 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:11:21.895505 ops/training.py:65 2019-01-17 07:11:21.895460: step 18513, loss = 0.24710 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:11:23.178409 ops/training.py:65 2019-01-17 07:11:23.178344: step 18514, loss = 0.27692 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:11:24.461767 ops/training.py:65 2019-01-17 07:11:24.461728: step 18515, loss = 0.29139 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:11:25.744699 ops/training.py:65 2019-01-17 07:11:25.744668: step 18516, loss = 0.26122 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:11:27.032171 ops/training.py:65 2019-01-17 07:11:27.032138: step 18517, loss = 0.30640 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:11:28.313315 ops/training.py:65 2019-01-17 07:11:28.313234: step 18518, loss = 0.21159 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:11:29.599477 ops/training.py:65 2019-01-17 07:11:29.599415: step 18519, loss = 0.24259 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:11:30.891362 ops/training.py:65 2019-01-17 07:11:30.891264: step 18520, loss = 0.24911 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:11:32.176241 ops/training.py:65 2019-01-17 07:11:32.176177: step 18521, loss = 0.30060 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:11:33.467092 ops/training.py:65 2019-01-17 07:11:33.466995: step 18522, loss = 0.18875 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:11:34.751243 ops/training.py:65 2019-01-17 07:11:34.751182: step 18523, loss = 0.27862 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:11:36.036335 ops/training.py:65 2019-01-17 07:11:36.036226: step 18524, loss = 0.22967 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:11:37.321026 ops/training.py:65 2019-01-17 07:11:37.320924: step 18525, loss = 0.31243 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:11:38.609231 ops/training.py:65 2019-01-17 07:11:38.609125: step 18526, loss = 0.31798 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:11:39.897800 ops/training.py:65 2019-01-17 07:11:39.897732: step 18527, loss = 0.33974 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:11:41.188006 ops/training.py:65 2019-01-17 07:11:41.187932: step 18528, loss = 0.27351 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:11:42.479155 ops/training.py:65 2019-01-17 07:11:42.479054: step 18529, loss = 0.38249 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:11:43.760057 ops/training.py:65 2019-01-17 07:11:43.759989: step 18530, loss = 0.24346 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:11:45.044453 ops/training.py:65 2019-01-17 07:11:45.044362: step 18531, loss = 0.31653 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:11:46.328196 ops/training.py:65 2019-01-17 07:11:46.328160: step 18532, loss = 0.27455 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:11:47.619185 ops/training.py:65 2019-01-17 07:11:47.619147: step 18533, loss = 0.33009 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:11:48.903043 ops/training.py:65 2019-01-17 07:11:48.903009: step 18534, loss = 0.19447 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:11:50.194571 ops/training.py:65 2019-01-17 07:11:50.194539: step 18535, loss = 0.28607 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:11:51.478484 ops/training.py:65 2019-01-17 07:11:51.478448: step 18536, loss = 0.25314 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:11:52.765698 ops/training.py:65 2019-01-17 07:11:52.765665: step 18537, loss = 0.24507 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:11:54.054426 ops/training.py:65 2019-01-17 07:11:54.054356: step 18538, loss = 0.36576 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:11:55.346504 ops/training.py:65 2019-01-17 07:11:55.346463: step 18539, loss = 0.24627 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:11:56.629855 ops/training.py:65 2019-01-17 07:11:56.629824: step 18540, loss = 0.30793 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:11:57.921055 ops/training.py:65 2019-01-17 07:11:57.921023: step 18541, loss = 0.29386 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:11:59.207423 ops/training.py:65 2019-01-17 07:11:59.207339: step 18542, loss = 0.25505 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:12:00.492254 ops/training.py:65 2019-01-17 07:12:00.492190: step 18543, loss = 0.27949 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:12:01.775406 ops/training.py:65 2019-01-17 07:12:01.775298: step 18544, loss = 0.29389 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:12:03.064201 ops/training.py:65 2019-01-17 07:12:03.064054: step 18545, loss = 0.30200 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:12:04.346006 ops/training.py:65 2019-01-17 07:12:04.345895: step 18546, loss = 0.32196 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:12:05.630142 ops/training.py:65 2019-01-17 07:12:05.630004: step 18547, loss = 0.26835 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:12:06.922603 ops/training.py:65 2019-01-17 07:12:06.922445: step 18548, loss = 0.25994 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:12:08.210623 ops/training.py:65 2019-01-17 07:12:08.210559: step 18549, loss = 0.35111 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:12:09.496696 ops/training.py:65 2019-01-17 07:12:09.496594: step 18550, loss = 0.22206 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:12:10.784391 ops/training.py:65 2019-01-17 07:12:10.784286: step 18551, loss = 0.22929 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:12:12.065304 ops/training.py:65 2019-01-17 07:12:12.065196: step 18552, loss = 0.25485 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:12:13.347342 ops/training.py:65 2019-01-17 07:12:13.347247: step 18553, loss = 0.23151 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:12:14.627352 ops/training.py:65 2019-01-17 07:12:14.627195: step 18554, loss = 0.24584 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:12:15.916059 ops/training.py:65 2019-01-17 07:12:15.915958: step 18555, loss = 0.28936 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:12:17.203191 ops/training.py:65 2019-01-17 07:12:17.203092: step 18556, loss = 0.27348 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:12:18.492597 ops/training.py:65 2019-01-17 07:12:18.492501: step 18557, loss = 0.27694 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:12:19.782763 ops/training.py:65 2019-01-17 07:12:19.782669: step 18558, loss = 0.20590 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:12:21.075173 ops/training.py:65 2019-01-17 07:12:21.075069: step 18559, loss = 0.19359 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:12:22.362782 ops/training.py:65 2019-01-17 07:12:22.362715: step 18560, loss = 0.27442 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:12:23.648361 ops/training.py:65 2019-01-17 07:12:23.648304: step 18561, loss = 0.18520 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:12:24.933239 ops/training.py:65 2019-01-17 07:12:24.933131: step 18562, loss = 0.28292 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:12:26.224076 ops/training.py:65 2019-01-17 07:12:26.223973: step 18563, loss = 0.28558 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:12:27.504937 ops/training.py:65 2019-01-17 07:12:27.504878: step 18564, loss = 0.23178 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:12:28.788972 ops/training.py:65 2019-01-17 07:12:28.788864: step 18565, loss = 0.27960 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:12:30.072853 ops/training.py:65 2019-01-17 07:12:30.072750: step 18566, loss = 0.27135 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:12:31.369620 ops/training.py:65 2019-01-17 07:12:31.369512: step 18567, loss = 0.28575 (24.7 examples/sec; 1.296 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:12:32.656505 ops/training.py:65 2019-01-17 07:12:32.656426: step 18568, loss = 0.32976 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:12:33.946315 ops/training.py:65 2019-01-17 07:12:33.946186: step 18569, loss = 0.22337 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:12:35.232147 ops/training.py:65 2019-01-17 07:12:35.232079: step 18570, loss = 0.37113 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:12:36.516519 ops/training.py:65 2019-01-17 07:12:36.516411: step 18571, loss = 0.27692 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:12:37.807749 ops/training.py:65 2019-01-17 07:12:37.807641: step 18572, loss = 0.29293 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:12:39.100269 ops/training.py:65 2019-01-17 07:12:39.100198: step 18573, loss = 0.26227 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:12:40.385695 ops/training.py:65 2019-01-17 07:12:40.385618: step 18574, loss = 0.26053 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:12:41.666223 ops/training.py:65 2019-01-17 07:12:41.666118: step 18575, loss = 0.27674 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:12:42.959017 ops/training.py:65 2019-01-17 07:12:42.958919: step 18576, loss = 0.21253 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:12:44.239152 ops/training.py:65 2019-01-17 07:12:44.239050: step 18577, loss = 0.25460 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:12:45.523047 ops/training.py:65 2019-01-17 07:12:45.522945: step 18578, loss = 0.25515 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:12:46.814892 ops/training.py:65 2019-01-17 07:12:46.814748: step 18579, loss = 0.40165 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:12:48.103976 ops/training.py:65 2019-01-17 07:12:48.103897: step 18580, loss = 0.27230 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:12:49.385379 ops/training.py:65 2019-01-17 07:12:49.385230: step 18581, loss = 0.25932 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:12:50.674740 ops/training.py:65 2019-01-17 07:12:50.674645: step 18582, loss = 0.27761 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:12:51.964649 ops/training.py:65 2019-01-17 07:12:51.964504: step 18583, loss = 0.24927 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:12:53.251549 ops/training.py:65 2019-01-17 07:12:53.251478: step 18584, loss = 0.28950 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:12:54.536153 ops/training.py:65 2019-01-17 07:12:54.536002: step 18585, loss = 0.29647 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:12:55.823920 ops/training.py:65 2019-01-17 07:12:55.823822: step 18586, loss = 0.22669 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:12:57.112747 ops/training.py:65 2019-01-17 07:12:57.112650: step 18587, loss = 0.32539 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:12:58.398218 ops/training.py:65 2019-01-17 07:12:58.398113: step 18588, loss = 0.21435 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:12:59.685103 ops/training.py:65 2019-01-17 07:12:59.684953: step 18589, loss = 0.30442 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:13:00.978601 ops/training.py:65 2019-01-17 07:13:00.978443: step 18590, loss = 0.25832 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:13:02.268135 ops/training.py:65 2019-01-17 07:13:02.268038: step 18591, loss = 0.25206 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:13:03.548602 ops/training.py:65 2019-01-17 07:13:03.548509: step 18592, loss = 0.20688 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:13:04.840233 ops/training.py:65 2019-01-17 07:13:04.840164: step 18593, loss = 0.29333 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:13:06.125701 ops/training.py:65 2019-01-17 07:13:06.125629: step 18594, loss = 0.26111 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:13:07.408941 ops/training.py:65 2019-01-17 07:13:07.408829: step 18595, loss = 0.28194 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:13:08.697108 ops/training.py:65 2019-01-17 07:13:08.697000: step 18596, loss = 0.25425 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:13:09.985081 ops/training.py:65 2019-01-17 07:13:09.984980: step 18597, loss = 0.23476 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:13:11.265431 ops/training.py:65 2019-01-17 07:13:11.265324: step 18598, loss = 0.32175 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:13:12.554173 ops/training.py:65 2019-01-17 07:13:12.554065: step 18599, loss = 0.30524 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:13:13.838858 ops/training.py:65 2019-01-17 07:13:13.838754: step 18600, loss = 0.21734 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:13:15.126396 ops/training.py:65 2019-01-17 07:13:15.126295: step 18601, loss = 0.28483 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:13:16.410252 ops/training.py:65 2019-01-17 07:13:16.410150: step 18602, loss = 0.26416 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:13:17.696820 ops/training.py:65 2019-01-17 07:13:17.696723: step 18603, loss = 0.28383 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:13:18.980888 ops/training.py:65 2019-01-17 07:13:18.980781: step 18604, loss = 0.20288 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:13:20.267207 ops/training.py:65 2019-01-17 07:13:20.267111: step 18605, loss = 0.29693 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:13:21.555595 ops/training.py:65 2019-01-17 07:13:21.555461: step 18606, loss = 0.27775 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:13:22.846341 ops/training.py:65 2019-01-17 07:13:22.846239: step 18607, loss = 0.32038 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:13:24.132074 ops/training.py:65 2019-01-17 07:13:24.132003: step 18608, loss = 0.28786 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:13:25.415654 ops/training.py:65 2019-01-17 07:13:25.415546: step 18609, loss = 0.25804 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:13:26.702702 ops/training.py:65 2019-01-17 07:13:26.702607: step 18610, loss = 0.26625 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:13:27.987448 ops/training.py:65 2019-01-17 07:13:27.987346: step 18611, loss = 0.28547 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:13:29.274214 ops/training.py:65 2019-01-17 07:13:29.274107: step 18612, loss = 0.25080 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:13:30.554633 ops/training.py:65 2019-01-17 07:13:30.554525: step 18613, loss = 0.36010 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:13:31.835586 ops/training.py:65 2019-01-17 07:13:31.835476: step 18614, loss = 0.22190 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:13:33.117548 ops/training.py:65 2019-01-17 07:13:33.117427: step 18615, loss = 0.30257 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:13:34.403761 ops/training.py:65 2019-01-17 07:13:34.403603: step 18616, loss = 0.31231 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:13:35.697378 ops/training.py:65 2019-01-17 07:13:35.697287: step 18617, loss = 0.24032 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:13:36.987703 ops/training.py:65 2019-01-17 07:13:36.987636: step 18618, loss = 0.22939 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:13:38.268143 ops/training.py:65 2019-01-17 07:13:38.268049: step 18619, loss = 0.26152 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:13:39.553674 ops/training.py:65 2019-01-17 07:13:39.553571: step 18620, loss = 0.31478 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:13:40.839696 ops/training.py:65 2019-01-17 07:13:40.839591: step 18621, loss = 0.32886 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:13:42.127637 ops/training.py:65 2019-01-17 07:13:42.127528: step 18622, loss = 0.36277 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:13:43.416308 ops/training.py:65 2019-01-17 07:13:43.416213: step 18623, loss = 0.24805 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:13:44.707294 ops/training.py:65 2019-01-17 07:13:44.707185: step 18624, loss = 0.29392 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:13:45.993874 ops/training.py:65 2019-01-17 07:13:45.993809: step 18625, loss = 0.24816 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:13:47.274701 ops/training.py:65 2019-01-17 07:13:47.274589: step 18626, loss = 0.25184 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:13:48.566238 ops/training.py:65 2019-01-17 07:13:48.566084: step 18627, loss = 0.30572 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:13:49.859166 ops/training.py:65 2019-01-17 07:13:49.859022: step 18628, loss = 0.26015 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:13:51.146657 ops/training.py:65 2019-01-17 07:13:51.146585: step 18629, loss = 0.25553 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:13:52.429944 ops/training.py:65 2019-01-17 07:13:52.429876: step 18630, loss = 0.31019 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:13:53.718509 ops/training.py:65 2019-01-17 07:13:53.718417: step 18631, loss = 0.37650 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:13:55.011915 ops/training.py:65 2019-01-17 07:13:55.011809: step 18632, loss = 0.24521 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:13:56.300221 ops/training.py:65 2019-01-17 07:13:56.300069: step 18633, loss = 0.29652 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:13:57.587573 ops/training.py:65 2019-01-17 07:13:57.587475: step 18634, loss = 0.24453 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:13:58.867250 ops/training.py:65 2019-01-17 07:13:58.867149: step 18635, loss = 0.19839 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:14:00.151919 ops/training.py:65 2019-01-17 07:14:00.151788: step 18636, loss = 0.23908 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:14:01.436812 ops/training.py:65 2019-01-17 07:14:01.436711: step 18637, loss = 0.26321 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:14:02.729511 ops/training.py:65 2019-01-17 07:14:02.729416: step 18638, loss = 0.26067 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:14:04.022099 ops/training.py:65 2019-01-17 07:14:04.022020: step 18639, loss = 0.20251 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:14:05.307253 ops/training.py:65 2019-01-17 07:14:05.307188: step 18640, loss = 0.23550 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:14:06.591806 ops/training.py:65 2019-01-17 07:14:06.591702: step 18641, loss = 0.23183 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:14:07.872171 ops/training.py:65 2019-01-17 07:14:07.872075: step 18642, loss = 0.28968 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:14:09.153502 ops/training.py:65 2019-01-17 07:14:09.153398: step 18643, loss = 0.27345 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:14:10.431718 ops/training.py:65 2019-01-17 07:14:10.431610: step 18644, loss = 0.28591 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:14:11.715293 ops/training.py:65 2019-01-17 07:14:11.715199: step 18645, loss = 0.26579 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:14:13.002081 ops/training.py:65 2019-01-17 07:14:13.001972: step 18646, loss = 0.28476 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:14:14.293933 ops/training.py:65 2019-01-17 07:14:14.293845: step 18647, loss = 0.30667 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:14:15.579758 ops/training.py:65 2019-01-17 07:14:15.579691: step 18648, loss = 0.26366 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:14:16.857365 ops/training.py:65 2019-01-17 07:14:16.857265: step 18649, loss = 0.30304 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:14:18.137453 ops/training.py:65 2019-01-17 07:14:18.137349: step 18650, loss = 0.29030 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:14:19.423240 ops/training.py:65 2019-01-17 07:14:19.423135: step 18651, loss = 0.29730 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:14:20.704284 ops/training.py:65 2019-01-17 07:14:20.704193: step 18652, loss = 0.29251 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:14:21.989455 ops/training.py:65 2019-01-17 07:14:21.989346: step 18653, loss = 0.32336 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:14:23.276427 ops/training.py:65 2019-01-17 07:14:23.276327: step 18654, loss = 0.27383 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:14:24.559617 ops/training.py:65 2019-01-17 07:14:24.559499: step 18655, loss = 0.24848 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:14:25.848767 ops/training.py:65 2019-01-17 07:14:25.848665: step 18656, loss = 0.31468 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:14:27.135341 ops/training.py:65 2019-01-17 07:14:27.135236: step 18657, loss = 0.22529 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:14:28.421693 ops/training.py:65 2019-01-17 07:14:28.421589: step 18658, loss = 0.27695 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:14:29.707033 ops/training.py:65 2019-01-17 07:14:29.706925: step 18659, loss = 0.25369 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:14:30.996009 ops/training.py:65 2019-01-17 07:14:30.995908: step 18660, loss = 0.26363 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:14:32.287304 ops/training.py:65 2019-01-17 07:14:32.287204: step 18661, loss = 0.19872 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:14:33.574852 ops/training.py:65 2019-01-17 07:14:33.574769: step 18662, loss = 0.22418 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:14:34.855210 ops/training.py:65 2019-01-17 07:14:34.855097: step 18663, loss = 0.30463 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:14:36.136589 ops/training.py:65 2019-01-17 07:14:36.136490: step 18664, loss = 0.29241 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:14:37.416689 ops/training.py:65 2019-01-17 07:14:37.416576: step 18665, loss = 0.21570 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:14:38.704117 ops/training.py:65 2019-01-17 07:14:38.704010: step 18666, loss = 0.27538 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:14:39.988856 ops/training.py:65 2019-01-17 07:14:39.988749: step 18667, loss = 0.26378 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:14:41.274302 ops/training.py:65 2019-01-17 07:14:41.274196: step 18668, loss = 0.23444 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:14:42.562444 ops/training.py:65 2019-01-17 07:14:42.562341: step 18669, loss = 0.26453 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:14:43.847657 ops/training.py:65 2019-01-17 07:14:43.847563: step 18670, loss = 0.31514 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:14:45.138182 ops/training.py:65 2019-01-17 07:14:45.138031: step 18671, loss = 0.29942 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:14:46.428297 ops/training.py:65 2019-01-17 07:14:46.428186: step 18672, loss = 0.24745 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:14:47.709798 ops/training.py:65 2019-01-17 07:14:47.709696: step 18673, loss = 0.29917 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:14:48.993663 ops/training.py:65 2019-01-17 07:14:48.993577: step 18674, loss = 0.19748 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:14:50.284459 ops/training.py:65 2019-01-17 07:14:50.284367: step 18675, loss = 0.26409 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:14:51.571783 ops/training.py:65 2019-01-17 07:14:51.571685: step 18676, loss = 0.26585 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:14:52.856720 ops/training.py:65 2019-01-17 07:14:52.856626: step 18677, loss = 0.22738 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:14:54.139342 ops/training.py:65 2019-01-17 07:14:54.139245: step 18678, loss = 0.31554 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:14:55.427296 ops/training.py:65 2019-01-17 07:14:55.427193: step 18679, loss = 0.29949 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:14:56.711661 ops/training.py:65 2019-01-17 07:14:56.711519: step 18680, loss = 0.32306 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:14:57.996633 ops/training.py:65 2019-01-17 07:14:57.996532: step 18681, loss = 0.27216 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:14:59.276200 ops/training.py:65 2019-01-17 07:14:59.276066: step 18682, loss = 0.29128 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:15:00.554175 ops/training.py:65 2019-01-17 07:15:00.554073: step 18683, loss = 0.29749 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:15:01.836321 ops/training.py:65 2019-01-17 07:15:01.836207: step 18684, loss = 0.22095 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:15:03.126413 ops/training.py:65 2019-01-17 07:15:03.126313: step 18685, loss = 0.27527 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:15:04.409746 ops/training.py:65 2019-01-17 07:15:04.409601: step 18686, loss = 0.26864 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:15:05.690130 ops/training.py:65 2019-01-17 07:15:05.690033: step 18687, loss = 0.29955 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:15:06.981980 ops/training.py:65 2019-01-17 07:15:06.981881: step 18688, loss = 0.30749 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:15:08.273008 ops/training.py:65 2019-01-17 07:15:08.272919: step 18689, loss = 0.36698 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:15:09.558338 ops/training.py:65 2019-01-17 07:15:09.558255: step 18690, loss = 0.29370 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:15:10.847187 ops/training.py:65 2019-01-17 07:15:10.847084: step 18691, loss = 0.26511 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:15:12.131841 ops/training.py:65 2019-01-17 07:15:12.131741: step 18692, loss = 0.27434 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:15:13.414208 ops/training.py:65 2019-01-17 07:15:13.414118: step 18693, loss = 0.29907 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:15:14.696290 ops/training.py:65 2019-01-17 07:15:14.696175: step 18694, loss = 0.37834 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:15:15.977110 ops/training.py:65 2019-01-17 07:15:15.977018: step 18695, loss = 0.24416 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:15:17.257160 ops/training.py:65 2019-01-17 07:15:17.257064: step 18696, loss = 0.21573 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:15:18.543502 ops/training.py:65 2019-01-17 07:15:18.543409: step 18697, loss = 0.24408 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:15:19.831981 ops/training.py:65 2019-01-17 07:15:19.831872: step 18698, loss = 0.29148 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:15:21.114510 ops/training.py:65 2019-01-17 07:15:21.114412: step 18699, loss = 0.22993 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:15:22.405378 ops/training.py:65 2019-01-17 07:15:22.405257: step 18700, loss = 0.27288 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:15:23.687632 ops/training.py:65 2019-01-17 07:15:23.687524: step 18701, loss = 0.23318 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:15:24.976763 ops/training.py:65 2019-01-17 07:15:24.976664: step 18702, loss = 0.26094 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:15:26.261378 ops/training.py:65 2019-01-17 07:15:26.261273: step 18703, loss = 0.25342 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:15:27.550283 ops/training.py:65 2019-01-17 07:15:27.550183: step 18704, loss = 0.23845 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:15:28.840638 ops/training.py:65 2019-01-17 07:15:28.840546: step 18705, loss = 0.20458 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:15:30.126868 ops/training.py:65 2019-01-17 07:15:30.126770: step 18706, loss = 0.25396 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:15:31.406586 ops/training.py:65 2019-01-17 07:15:31.406485: step 18707, loss = 0.31609 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:15:32.691877 ops/training.py:65 2019-01-17 07:15:32.691783: step 18708, loss = 0.23316 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:15:33.977457 ops/training.py:65 2019-01-17 07:15:33.977350: step 18709, loss = 0.27467 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:15:35.271336 ops/training.py:65 2019-01-17 07:15:35.271229: step 18710, loss = 0.22383 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:15:36.562539 ops/training.py:65 2019-01-17 07:15:36.562431: step 18711, loss = 0.23821 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:15:37.843907 ops/training.py:65 2019-01-17 07:15:37.843799: step 18712, loss = 0.20457 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:15:39.128897 ops/training.py:65 2019-01-17 07:15:39.128799: step 18713, loss = 0.29007 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:15:40.414480 ops/training.py:65 2019-01-17 07:15:40.414365: step 18714, loss = 0.23249 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:15:41.701341 ops/training.py:65 2019-01-17 07:15:41.701234: step 18715, loss = 0.23422 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:15:42.987815 ops/training.py:65 2019-01-17 07:15:42.987709: step 18716, loss = 0.30249 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:15:44.277215 ops/training.py:65 2019-01-17 07:15:44.277120: step 18717, loss = 0.26512 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:15:45.562451 ops/training.py:65 2019-01-17 07:15:45.562334: step 18718, loss = 0.22482 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:15:46.845387 ops/training.py:65 2019-01-17 07:15:46.845286: step 18719, loss = 0.23978 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:15:48.130000 ops/training.py:65 2019-01-17 07:15:48.129868: step 18720, loss = 0.27948 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:15:49.418158 ops/training.py:65 2019-01-17 07:15:49.418050: step 18721, loss = 0.25596 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:15:50.697878 ops/training.py:65 2019-01-17 07:15:50.697783: step 18722, loss = 0.22381 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:15:51.982868 ops/training.py:65 2019-01-17 07:15:51.982762: step 18723, loss = 0.31643 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:15:53.264687 ops/training.py:65 2019-01-17 07:15:53.264594: step 18724, loss = 0.25802 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:15:54.550257 ops/training.py:65 2019-01-17 07:15:54.550151: step 18725, loss = 0.21656 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:15:55.840800 ops/training.py:65 2019-01-17 07:15:55.840693: step 18726, loss = 0.27184 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:15:57.125112 ops/training.py:65 2019-01-17 07:15:57.125015: step 18727, loss = 0.26777 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:15:58.413874 ops/training.py:65 2019-01-17 07:15:58.413774: step 18728, loss = 0.29699 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:15:59.691482 ops/training.py:65 2019-01-17 07:15:59.691379: step 18729, loss = 0.31287 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:16:00.975893 ops/training.py:65 2019-01-17 07:16:00.975781: step 18730, loss = 0.26600 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:16:02.272882 ops/training.py:65 2019-01-17 07:16:02.272763: step 18731, loss = 0.34162 (24.7 examples/sec; 1.295 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:16:03.557435 ops/training.py:65 2019-01-17 07:16:03.557335: step 18732, loss = 0.22099 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:16:04.846436 ops/training.py:65 2019-01-17 07:16:04.846348: step 18733, loss = 0.30808 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:16:06.136951 ops/training.py:65 2019-01-17 07:16:06.136855: step 18734, loss = 0.30781 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:16:07.423536 ops/training.py:65 2019-01-17 07:16:07.423440: step 18735, loss = 0.29165 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:16:08.706882 ops/training.py:65 2019-01-17 07:16:08.706665: step 18736, loss = 0.30799 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:16:10.002142 ops/training.py:65 2019-01-17 07:16:10.002045: step 18737, loss = 0.23983 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:16:11.291962 ops/training.py:65 2019-01-17 07:16:11.291824: step 18738, loss = 0.25908 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:16:12.581553 ops/training.py:65 2019-01-17 07:16:12.581457: step 18739, loss = 0.26519 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:16:13.871758 ops/training.py:65 2019-01-17 07:16:13.871668: step 18740, loss = 0.23213 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:16:15.153936 ops/training.py:65 2019-01-17 07:16:15.153869: step 18741, loss = 0.23798 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:16:16.437276 ops/training.py:65 2019-01-17 07:16:16.437176: step 18742, loss = 0.29732 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:16:17.729818 ops/training.py:65 2019-01-17 07:16:17.729717: step 18743, loss = 0.26516 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:16:19.014326 ops/training.py:65 2019-01-17 07:16:19.014222: step 18744, loss = 0.23806 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:16:20.304727 ops/training.py:65 2019-01-17 07:16:20.304638: step 18745, loss = 0.21995 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:16:21.581680 ops/training.py:65 2019-01-17 07:16:21.581575: step 18746, loss = 0.29293 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:16:22.864760 ops/training.py:65 2019-01-17 07:16:22.864641: step 18747, loss = 0.27316 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:16:24.152462 ops/training.py:65 2019-01-17 07:16:24.152367: step 18748, loss = 0.26230 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:16:25.438755 ops/training.py:65 2019-01-17 07:16:25.438647: step 18749, loss = 0.31145 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:16:26.728107 ops/training.py:65 2019-01-17 07:16:26.728006: step 18750, loss = 0.33384 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:16:28.015308 ops/training.py:65 2019-01-17 07:16:28.015163: step 18751, loss = 0.24093 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:16:29.305436 ops/training.py:65 2019-01-17 07:16:29.305328: step 18752, loss = 0.25833 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:16:30.594594 ops/training.py:65 2019-01-17 07:16:30.594491: step 18753, loss = 0.25153 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:16:31.878135 ops/training.py:65 2019-01-17 07:16:31.878033: step 18754, loss = 0.34487 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:16:33.166390 ops/training.py:65 2019-01-17 07:16:33.166302: step 18755, loss = 0.26833 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:16:34.448668 ops/training.py:65 2019-01-17 07:16:34.448570: step 18756, loss = 0.28623 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:16:35.731470 ops/training.py:65 2019-01-17 07:16:35.731373: step 18757, loss = 0.27959 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:16:37.026011 ops/training.py:65 2019-01-17 07:16:37.025907: step 18758, loss = 0.33568 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:16:38.309663 ops/training.py:65 2019-01-17 07:16:38.309562: step 18759, loss = 0.34496 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:16:39.599796 ops/training.py:65 2019-01-17 07:16:39.599695: step 18760, loss = 0.32384 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:16:40.883576 ops/training.py:65 2019-01-17 07:16:40.883469: step 18761, loss = 0.27279 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:16:42.171778 ops/training.py:65 2019-01-17 07:16:42.171681: step 18762, loss = 0.27154 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:16:43.457110 ops/training.py:65 2019-01-17 07:16:43.457016: step 18763, loss = 0.28221 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:16:44.749257 ops/training.py:65 2019-01-17 07:16:44.749112: step 18764, loss = 0.26778 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:16:46.040208 ops/training.py:65 2019-01-17 07:16:46.040115: step 18765, loss = 0.23883 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:16:47.325121 ops/training.py:65 2019-01-17 07:16:47.325016: step 18766, loss = 0.21201 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:16:48.605024 ops/training.py:65 2019-01-17 07:16:48.604928: step 18767, loss = 0.27592 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:16:49.889183 ops/training.py:65 2019-01-17 07:16:49.889089: step 18768, loss = 0.26492 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:16:51.178064 ops/training.py:65 2019-01-17 07:16:51.177968: step 18769, loss = 0.27278 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:16:52.470942 ops/training.py:65 2019-01-17 07:16:52.470838: step 18770, loss = 0.28276 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:16:53.755470 ops/training.py:65 2019-01-17 07:16:53.755363: step 18771, loss = 0.24071 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:16:55.039837 ops/training.py:65 2019-01-17 07:16:55.039734: step 18772, loss = 0.25779 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:16:56.332441 ops/training.py:65 2019-01-17 07:16:56.332351: step 18773, loss = 0.23841 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:16:57.616016 ops/training.py:65 2019-01-17 07:16:57.615937: step 18774, loss = 0.22494 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:16:58.900223 ops/training.py:65 2019-01-17 07:16:58.900072: step 18775, loss = 0.24610 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:17:00.180188 ops/training.py:65 2019-01-17 07:17:00.180082: step 18776, loss = 0.26428 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:17:01.471573 ops/training.py:65 2019-01-17 07:17:01.471466: step 18777, loss = 0.23316 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:17:02.757172 ops/training.py:65 2019-01-17 07:17:02.757077: step 18778, loss = 0.23695 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:17:04.039729 ops/training.py:65 2019-01-17 07:17:04.039636: step 18779, loss = 0.22978 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:17:05.325780 ops/training.py:65 2019-01-17 07:17:05.325679: step 18780, loss = 0.34001 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:17:06.611618 ops/training.py:65 2019-01-17 07:17:06.611462: step 18781, loss = 0.21008 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:17:07.897305 ops/training.py:65 2019-01-17 07:17:07.897195: step 18782, loss = 0.24701 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:17:09.188976 ops/training.py:65 2019-01-17 07:17:09.188875: step 18783, loss = 0.33954 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:17:10.479996 ops/training.py:65 2019-01-17 07:17:10.479916: step 18784, loss = 0.28516 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:17:11.770538 ops/training.py:65 2019-01-17 07:17:11.770459: step 18785, loss = 0.26604 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:17:13.058319 ops/training.py:65 2019-01-17 07:17:13.058245: step 18786, loss = 0.20329 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:17:14.342196 ops/training.py:65 2019-01-17 07:17:14.342130: step 18787, loss = 0.22711 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:17:15.628186 ops/training.py:65 2019-01-17 07:17:15.628084: step 18788, loss = 0.26962 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:17:16.911907 ops/training.py:65 2019-01-17 07:17:16.911811: step 18789, loss = 0.19046 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:17:18.193057 ops/training.py:65 2019-01-17 07:17:18.192950: step 18790, loss = 0.25329 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:17:19.479687 ops/training.py:65 2019-01-17 07:17:19.479585: step 18791, loss = 0.28771 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:17:20.770041 ops/training.py:65 2019-01-17 07:17:20.769940: step 18792, loss = 0.23349 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:17:22.061472 ops/training.py:65 2019-01-17 07:17:22.061394: step 18793, loss = 0.24338 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:17:23.343729 ops/training.py:65 2019-01-17 07:17:23.343659: step 18794, loss = 0.23583 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:17:24.632819 ops/training.py:65 2019-01-17 07:17:24.632715: step 18795, loss = 0.31551 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:17:25.920685 ops/training.py:65 2019-01-17 07:17:25.920591: step 18796, loss = 0.38901 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:17:27.206529 ops/training.py:65 2019-01-17 07:17:27.206457: step 18797, loss = 0.33404 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:17:28.492170 ops/training.py:65 2019-01-17 07:17:28.492065: step 18798, loss = 0.25784 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:17:29.779726 ops/training.py:65 2019-01-17 07:17:29.779579: step 18799, loss = 0.25546 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:17:31.060649 ops/training.py:65 2019-01-17 07:17:31.060489: step 18800, loss = 0.27871 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:17:32.347472 ops/training.py:65 2019-01-17 07:17:32.347366: step 18801, loss = 0.24364 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:17:33.628748 ops/training.py:65 2019-01-17 07:17:33.628651: step 18802, loss = 0.24708 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:17:34.914119 ops/training.py:65 2019-01-17 07:17:34.913990: step 18803, loss = 0.22169 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:17:36.207501 ops/training.py:65 2019-01-17 07:17:36.207407: step 18804, loss = 0.35557 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:17:37.492983 ops/training.py:65 2019-01-17 07:17:37.492914: step 18805, loss = 0.27526 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:17:38.773724 ops/training.py:65 2019-01-17 07:17:38.773661: step 18806, loss = 0.24641 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:17:40.060792 ops/training.py:65 2019-01-17 07:17:40.060683: step 18807, loss = 0.24693 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:17:41.344755 ops/training.py:65 2019-01-17 07:17:41.344649: step 18808, loss = 0.28035 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:17:42.634043 ops/training.py:65 2019-01-17 07:17:42.633944: step 18809, loss = 0.25675 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:17:43.913644 ops/training.py:65 2019-01-17 07:17:43.913497: step 18810, loss = 0.28358 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:17:45.206655 ops/training.py:65 2019-01-17 07:17:45.206513: step 18811, loss = 0.27297 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:17:46.498714 ops/training.py:65 2019-01-17 07:17:46.498613: step 18812, loss = 0.24602 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:17:47.788882 ops/training.py:65 2019-01-17 07:17:47.788811: step 18813, loss = 0.25444 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:17:49.077577 ops/training.py:65 2019-01-17 07:17:49.077500: step 18814, loss = 0.26883 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:17:50.366738 ops/training.py:65 2019-01-17 07:17:50.366657: step 18815, loss = 0.29595 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:17:51.655726 ops/training.py:65 2019-01-17 07:17:51.655623: step 18816, loss = 0.27531 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:17:52.943786 ops/training.py:65 2019-01-17 07:17:52.943702: step 18817, loss = 0.23352 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:17:54.233156 ops/training.py:65 2019-01-17 07:17:54.233074: step 18818, loss = 0.26185 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:17:55.517978 ops/training.py:65 2019-01-17 07:17:55.517905: step 18819, loss = 0.24076 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:17:56.808078 ops/training.py:65 2019-01-17 07:17:56.807971: step 18820, loss = 0.21302 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:17:58.096522 ops/training.py:65 2019-01-17 07:17:58.096445: step 18821, loss = 0.30678 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:17:59.382058 ops/training.py:65 2019-01-17 07:17:59.381985: step 18822, loss = 0.29608 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:18:00.662873 ops/training.py:65 2019-01-17 07:18:00.662713: step 18823, loss = 0.29338 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:18:01.948278 ops/training.py:65 2019-01-17 07:18:01.948173: step 18824, loss = 0.34925 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:18:03.239780 ops/training.py:65 2019-01-17 07:18:03.239641: step 18825, loss = 0.30138 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:18:04.526120 ops/training.py:65 2019-01-17 07:18:04.526052: step 18826, loss = 0.37348 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 07:18:05.808905 ops/training.py:65 2019-01-17 07:18:05.808803: step 18827, loss = 0.38769 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.78125
I4672 2019-01-17 07:18:07.099319 ops/training.py:65 2019-01-17 07:18:07.099209: step 18828, loss = 0.29328 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:18:08.385613 ops/training.py:65 2019-01-17 07:18:08.385536: step 18829, loss = 0.35686 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 07:18:09.669914 ops/training.py:65 2019-01-17 07:18:09.669851: step 18830, loss = 0.24653 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:18:10.954229 ops/training.py:65 2019-01-17 07:18:10.954122: step 18831, loss = 0.22909 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:18:12.246136 ops/training.py:65 2019-01-17 07:18:12.246029: step 18832, loss = 0.26692 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:18:13.534382 ops/training.py:65 2019-01-17 07:18:13.534308: step 18833, loss = 0.27718 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:18:14.817277 ops/training.py:65 2019-01-17 07:18:14.817214: step 18834, loss = 0.22453 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:18:16.103696 ops/training.py:65 2019-01-17 07:18:16.103586: step 18835, loss = 0.32379 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:18:17.390489 ops/training.py:65 2019-01-17 07:18:17.390408: step 18836, loss = 0.31504 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:18:18.675567 ops/training.py:65 2019-01-17 07:18:18.675423: step 18837, loss = 0.28186 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:18:19.962186 ops/training.py:65 2019-01-17 07:18:19.962088: step 18838, loss = 0.24877 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:18:21.253099 ops/training.py:65 2019-01-17 07:18:21.252996: step 18839, loss = 0.33629 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:18:22.538936 ops/training.py:65 2019-01-17 07:18:22.538863: step 18840, loss = 0.29006 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:18:23.825113 ops/training.py:65 2019-01-17 07:18:23.825035: step 18841, loss = 0.26661 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:18:25.106478 ops/training.py:65 2019-01-17 07:18:25.106374: step 18842, loss = 0.30436 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:18:26.391975 ops/training.py:65 2019-01-17 07:18:26.391880: step 18843, loss = 0.26431 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:18:27.676791 ops/training.py:65 2019-01-17 07:18:27.676684: step 18844, loss = 0.38240 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:18:28.962664 ops/training.py:65 2019-01-17 07:18:28.962564: step 18845, loss = 0.27989 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:18:30.249761 ops/training.py:65 2019-01-17 07:18:30.249655: step 18846, loss = 0.23443 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:18:31.531944 ops/training.py:65 2019-01-17 07:18:31.531837: step 18847, loss = 0.23767 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:18:32.816515 ops/training.py:65 2019-01-17 07:18:32.816402: step 18848, loss = 0.25243 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:18:34.102788 ops/training.py:65 2019-01-17 07:18:34.102694: step 18849, loss = 0.25427 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:18:35.389802 ops/training.py:65 2019-01-17 07:18:35.389713: step 18850, loss = 0.31846 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:18:36.678015 ops/training.py:65 2019-01-17 07:18:36.677919: step 18851, loss = 0.36743 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:18:37.958702 ops/training.py:65 2019-01-17 07:18:37.958602: step 18852, loss = 0.26850 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:18:39.242813 ops/training.py:65 2019-01-17 07:18:39.242707: step 18853, loss = 0.28682 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:18:40.530710 ops/training.py:65 2019-01-17 07:18:40.530611: step 18854, loss = 0.30415 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:18:41.813665 ops/training.py:65 2019-01-17 07:18:41.813562: step 18855, loss = 0.27541 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:18:43.103838 ops/training.py:65 2019-01-17 07:18:43.103735: step 18856, loss = 0.20051 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:18:44.394948 ops/training.py:65 2019-01-17 07:18:44.394872: step 18857, loss = 0.29977 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:18:45.683339 ops/training.py:65 2019-01-17 07:18:45.683266: step 18858, loss = 0.24448 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:18:46.968652 ops/training.py:65 2019-01-17 07:18:46.968589: step 18859, loss = 0.24778 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:18:48.256294 ops/training.py:65 2019-01-17 07:18:48.256186: step 18860, loss = 0.24010 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:18:49.547684 ops/training.py:65 2019-01-17 07:18:49.547582: step 18861, loss = 0.26435 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:18:50.831962 ops/training.py:65 2019-01-17 07:18:50.831867: step 18862, loss = 0.32152 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:18:52.119432 ops/training.py:65 2019-01-17 07:18:52.119328: step 18863, loss = 0.22823 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:18:53.404991 ops/training.py:65 2019-01-17 07:18:53.404892: step 18864, loss = 0.28626 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:18:54.692217 ops/training.py:65 2019-01-17 07:18:54.692067: step 18865, loss = 0.26093 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:18:55.977418 ops/training.py:65 2019-01-17 07:18:55.977313: step 18866, loss = 0.26090 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:18:57.269879 ops/training.py:65 2019-01-17 07:18:57.269773: step 18867, loss = 0.22542 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:18:58.555369 ops/training.py:65 2019-01-17 07:18:58.555286: step 18868, loss = 0.24360 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:18:59.836376 ops/training.py:65 2019-01-17 07:18:59.836310: step 18869, loss = 0.21809 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:19:01.121317 ops/training.py:65 2019-01-17 07:19:01.121208: step 18870, loss = 0.27060 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:19:02.413282 ops/training.py:65 2019-01-17 07:19:02.413174: step 18871, loss = 0.26779 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:19:03.693554 ops/training.py:65 2019-01-17 07:19:03.693479: step 18872, loss = 0.23880 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:19:04.973787 ops/training.py:65 2019-01-17 07:19:04.973690: step 18873, loss = 0.23391 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:19:06.258160 ops/training.py:65 2019-01-17 07:19:06.258065: step 18874, loss = 0.30031 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:19:07.548301 ops/training.py:65 2019-01-17 07:19:07.548199: step 18875, loss = 0.30984 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:19:08.834739 ops/training.py:65 2019-01-17 07:19:08.834673: step 18876, loss = 0.27861 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:19:10.119507 ops/training.py:65 2019-01-17 07:19:10.119405: step 18877, loss = 0.30180 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:19:11.410648 ops/training.py:65 2019-01-17 07:19:11.410548: step 18878, loss = 0.26112 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:19:12.696217 ops/training.py:65 2019-01-17 07:19:12.696139: step 18879, loss = 0.23056 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:19:13.985553 ops/training.py:65 2019-01-17 07:19:13.985453: step 18880, loss = 0.20102 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:19:15.267785 ops/training.py:65 2019-01-17 07:19:15.267703: step 18881, loss = 0.26716 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:19:16.559178 ops/training.py:65 2019-01-17 07:19:16.559028: step 18882, loss = 0.27540 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:19:17.844959 ops/training.py:65 2019-01-17 07:19:17.844884: step 18883, loss = 0.25246 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:19:19.133435 ops/training.py:65 2019-01-17 07:19:19.133330: step 18884, loss = 0.27654 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:19:20.423327 ops/training.py:65 2019-01-17 07:19:20.423253: step 18885, loss = 0.25324 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:19:21.711261 ops/training.py:65 2019-01-17 07:19:21.711187: step 18886, loss = 0.26430 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:19:22.991229 ops/training.py:65 2019-01-17 07:19:22.991152: step 18887, loss = 0.24847 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:19:24.281830 ops/training.py:65 2019-01-17 07:19:24.281727: step 18888, loss = 0.27457 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:19:25.563872 ops/training.py:65 2019-01-17 07:19:25.563765: step 18889, loss = 0.30792 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:19:26.852767 ops/training.py:65 2019-01-17 07:19:26.852668: step 18890, loss = 0.21893 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:19:28.141771 ops/training.py:65 2019-01-17 07:19:28.141690: step 18891, loss = 0.31038 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:19:29.429833 ops/training.py:65 2019-01-17 07:19:29.429754: step 18892, loss = 0.22539 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:19:30.714861 ops/training.py:65 2019-01-17 07:19:30.714796: step 18893, loss = 0.25855 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:19:32.003005 ops/training.py:65 2019-01-17 07:19:32.002896: step 18894, loss = 0.25661 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:19:33.288305 ops/training.py:65 2019-01-17 07:19:33.288208: step 18895, loss = 0.20738 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:19:34.580674 ops/training.py:65 2019-01-17 07:19:34.580574: step 18896, loss = 0.30714 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:19:35.871707 ops/training.py:65 2019-01-17 07:19:35.871616: step 18897, loss = 0.29569 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:19:37.151253 ops/training.py:65 2019-01-17 07:19:37.151149: step 18898, loss = 0.31226 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:19:38.432864 ops/training.py:65 2019-01-17 07:19:38.432757: step 18899, loss = 0.22753 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:19:39.719489 ops/training.py:65 2019-01-17 07:19:39.719379: step 18900, loss = 0.23664 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:19:41.007111 ops/training.py:65 2019-01-17 07:19:41.007009: step 18901, loss = 0.20387 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:19:42.290899 ops/training.py:65 2019-01-17 07:19:42.290801: step 18902, loss = 0.22160 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:19:43.575605 ops/training.py:65 2019-01-17 07:19:43.575515: step 18903, loss = 0.16947 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:19:44.867145 ops/training.py:65 2019-01-17 07:19:44.867038: step 18904, loss = 0.22304 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:19:46.153101 ops/training.py:65 2019-01-17 07:19:46.153035: step 18905, loss = 0.29545 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:19:47.433121 ops/training.py:65 2019-01-17 07:19:47.433028: step 18906, loss = 0.22382 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:19:48.719907 ops/training.py:65 2019-01-17 07:19:48.719808: step 18907, loss = 0.21761 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:19:50.005398 ops/training.py:65 2019-01-17 07:19:50.005288: step 18908, loss = 0.31019 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:19:51.296045 ops/training.py:65 2019-01-17 07:19:51.295961: step 18909, loss = 0.36533 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:19:52.579741 ops/training.py:65 2019-01-17 07:19:52.579656: step 18910, loss = 0.24881 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:19:53.861938 ops/training.py:65 2019-01-17 07:19:53.861849: step 18911, loss = 0.24417 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:19:55.154332 ops/training.py:65 2019-01-17 07:19:55.154178: step 18912, loss = 0.21476 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:19:56.439928 ops/training.py:65 2019-01-17 07:19:56.439828: step 18913, loss = 0.23863 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:19:57.724612 ops/training.py:65 2019-01-17 07:19:57.724512: step 18914, loss = 0.22771 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:19:59.009494 ops/training.py:65 2019-01-17 07:19:59.009393: step 18915, loss = 0.23738 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:20:00.295368 ops/training.py:65 2019-01-17 07:20:00.295212: step 18916, loss = 0.25540 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:20:01.586864 ops/training.py:65 2019-01-17 07:20:01.586706: step 18917, loss = 0.24980 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:20:02.873579 ops/training.py:65 2019-01-17 07:20:02.873515: step 18918, loss = 0.19706 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:20:04.157192 ops/training.py:65 2019-01-17 07:20:04.157096: step 18919, loss = 0.24945 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:20:05.442006 ops/training.py:65 2019-01-17 07:20:05.441875: step 18920, loss = 0.33681 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:20:06.726888 ops/training.py:65 2019-01-17 07:20:06.726776: step 18921, loss = 0.28583 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:20:08.020432 ops/training.py:65 2019-01-17 07:20:08.020300: step 18922, loss = 0.27332 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:20:09.307850 ops/training.py:65 2019-01-17 07:20:09.307749: step 18923, loss = 0.24461 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:20:10.592425 ops/training.py:65 2019-01-17 07:20:10.592359: step 18924, loss = 0.29450 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:20:11.873362 ops/training.py:65 2019-01-17 07:20:11.873254: step 18925, loss = 0.29940 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:20:13.157626 ops/training.py:65 2019-01-17 07:20:13.157530: step 18926, loss = 0.27094 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:20:14.443274 ops/training.py:65 2019-01-17 07:20:14.443167: step 18927, loss = 0.24808 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:20:15.731957 ops/training.py:65 2019-01-17 07:20:15.731857: step 18928, loss = 0.26019 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:20:17.014981 ops/training.py:65 2019-01-17 07:20:17.014884: step 18929, loss = 0.26825 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:20:18.303149 ops/training.py:65 2019-01-17 07:20:18.303052: step 18930, loss = 0.23360 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:20:19.590807 ops/training.py:65 2019-01-17 07:20:19.590707: step 18931, loss = 0.18905 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:20:20.878072 ops/training.py:65 2019-01-17 07:20:20.877986: step 18932, loss = 0.27284 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:20:22.158850 ops/training.py:65 2019-01-17 07:20:22.158749: step 18933, loss = 0.23934 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:20:23.441963 ops/training.py:65 2019-01-17 07:20:23.441868: step 18934, loss = 0.24776 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:20:24.720697 ops/training.py:65 2019-01-17 07:20:24.720589: step 18935, loss = 0.26813 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:20:26.005897 ops/training.py:65 2019-01-17 07:20:26.005812: step 18936, loss = 0.19795 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:20:27.296899 ops/training.py:65 2019-01-17 07:20:27.296804: step 18937, loss = 0.29201 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:20:28.581416 ops/training.py:65 2019-01-17 07:20:28.581356: step 18938, loss = 0.24790 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:20:29.865728 ops/training.py:65 2019-01-17 07:20:29.865587: step 18939, loss = 0.25622 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:20:31.146035 ops/training.py:65 2019-01-17 07:20:31.145897: step 18940, loss = 0.23580 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:20:32.433930 ops/training.py:65 2019-01-17 07:20:32.433771: step 18941, loss = 0.30047 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:20:33.724605 ops/training.py:65 2019-01-17 07:20:33.724512: step 18942, loss = 0.28826 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:20:35.008810 ops/training.py:65 2019-01-17 07:20:35.008719: step 18943, loss = 0.24203 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:20:36.289955 ops/training.py:65 2019-01-17 07:20:36.289856: step 18944, loss = 0.25541 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:20:37.574337 ops/training.py:65 2019-01-17 07:20:37.574275: step 18945, loss = 0.24076 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:20:38.859320 ops/training.py:65 2019-01-17 07:20:38.859211: step 18946, loss = 0.22649 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:20:40.139062 ops/training.py:65 2019-01-17 07:20:40.138950: step 18947, loss = 0.29118 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:20:41.420531 ops/training.py:65 2019-01-17 07:20:41.420427: step 18948, loss = 0.27576 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:20:42.702940 ops/training.py:65 2019-01-17 07:20:42.702837: step 18949, loss = 0.27854 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:20:43.983026 ops/training.py:65 2019-01-17 07:20:43.982927: step 18950, loss = 0.29704 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:20:45.268614 ops/training.py:65 2019-01-17 07:20:45.268509: step 18951, loss = 0.33192 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:20:46.556955 ops/training.py:65 2019-01-17 07:20:46.556852: step 18952, loss = 0.25247 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:20:47.847566 ops/training.py:65 2019-01-17 07:20:47.847466: step 18953, loss = 0.19032 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:20:49.137132 ops/training.py:65 2019-01-17 07:20:49.137030: step 18954, loss = 0.29186 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:20:50.429537 ops/training.py:65 2019-01-17 07:20:50.429464: step 18955, loss = 0.25902 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:20:51.710276 ops/training.py:65 2019-01-17 07:20:51.710211: step 18956, loss = 0.21897 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:20:52.995341 ops/training.py:65 2019-01-17 07:20:52.995239: step 18957, loss = 0.25110 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:20:54.283343 ops/training.py:65 2019-01-17 07:20:54.283242: step 18958, loss = 0.28336 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:20:55.569717 ops/training.py:65 2019-01-17 07:20:55.569610: step 18959, loss = 0.24165 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:20:56.851715 ops/training.py:65 2019-01-17 07:20:56.851606: step 18960, loss = 0.25345 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:20:58.136740 ops/training.py:65 2019-01-17 07:20:58.136634: step 18961, loss = 0.24345 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:20:59.425459 ops/training.py:65 2019-01-17 07:20:59.425355: step 18962, loss = 0.24950 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:21:00.712123 ops/training.py:65 2019-01-17 07:21:00.712026: step 18963, loss = 0.25033 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:21:01.992892 ops/training.py:65 2019-01-17 07:21:01.992787: step 18964, loss = 0.22962 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:21:03.279455 ops/training.py:65 2019-01-17 07:21:03.279348: step 18965, loss = 0.25007 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:21:04.567307 ops/training.py:65 2019-01-17 07:21:04.567203: step 18966, loss = 0.26923 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:21:05.851305 ops/training.py:65 2019-01-17 07:21:05.851211: step 18967, loss = 0.30212 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:21:07.139462 ops/training.py:65 2019-01-17 07:21:07.139365: step 18968, loss = 0.26741 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:21:08.427057 ops/training.py:65 2019-01-17 07:21:08.426946: step 18969, loss = 0.22529 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:21:09.708989 ops/training.py:65 2019-01-17 07:21:09.708879: step 18970, loss = 0.26461 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:21:10.989837 ops/training.py:65 2019-01-17 07:21:10.989736: step 18971, loss = 0.22340 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:21:12.274985 ops/training.py:65 2019-01-17 07:21:12.274879: step 18972, loss = 0.25096 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:21:13.562124 ops/training.py:65 2019-01-17 07:21:13.562017: step 18973, loss = 0.25659 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:21:14.843384 ops/training.py:65 2019-01-17 07:21:14.843234: step 18974, loss = 0.25911 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:21:16.137151 ops/training.py:65 2019-01-17 07:21:16.137048: step 18975, loss = 0.27686 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:21:17.427936 ops/training.py:65 2019-01-17 07:21:17.427826: step 18976, loss = 0.18493 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:21:18.717299 ops/training.py:65 2019-01-17 07:21:18.717223: step 18977, loss = 0.24568 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:21:19.997978 ops/training.py:65 2019-01-17 07:21:19.997897: step 18978, loss = 0.23044 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:21:21.278917 ops/training.py:65 2019-01-17 07:21:21.278826: step 18979, loss = 0.23418 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:21:22.563250 ops/training.py:65 2019-01-17 07:21:22.563153: step 18980, loss = 0.25458 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:21:23.848177 ops/training.py:65 2019-01-17 07:21:23.848076: step 18981, loss = 0.25889 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:21:25.136093 ops/training.py:65 2019-01-17 07:21:25.135988: step 18982, loss = 0.26454 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:21:26.429693 ops/training.py:65 2019-01-17 07:21:26.429546: step 18983, loss = 0.19812 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:21:27.715856 ops/training.py:65 2019-01-17 07:21:27.715749: step 18984, loss = 0.23759 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:21:29.000224 ops/training.py:65 2019-01-17 07:21:29.000072: step 18985, loss = 0.23270 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:21:30.286364 ops/training.py:65 2019-01-17 07:21:30.286256: step 18986, loss = 0.20993 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:21:31.573501 ops/training.py:65 2019-01-17 07:21:31.573393: step 18987, loss = 0.20037 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:21:32.864611 ops/training.py:65 2019-01-17 07:21:32.864504: step 18988, loss = 0.25917 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:21:34.149792 ops/training.py:65 2019-01-17 07:21:34.149686: step 18989, loss = 0.23962 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:21:35.431937 ops/training.py:65 2019-01-17 07:21:35.431849: step 18990, loss = 0.24428 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:21:36.719207 ops/training.py:65 2019-01-17 07:21:36.719107: step 18991, loss = 0.30956 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:21:38.006000 ops/training.py:65 2019-01-17 07:21:38.005897: step 18992, loss = 0.24248 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:21:39.288003 ops/training.py:65 2019-01-17 07:21:39.287899: step 18993, loss = 0.26621 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:21:40.573992 ops/training.py:65 2019-01-17 07:21:40.573884: step 18994, loss = 0.23416 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:21:41.859889 ops/training.py:65 2019-01-17 07:21:41.859775: step 18995, loss = 0.28445 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:21:43.148281 ops/training.py:65 2019-01-17 07:21:43.148176: step 18996, loss = 0.25728 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:21:44.438185 ops/training.py:65 2019-01-17 07:21:44.438089: step 18997, loss = 0.21681 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:21:45.721854 ops/training.py:65 2019-01-17 07:21:45.721787: step 18998, loss = 0.31211 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:21:47.013552 ops/training.py:65 2019-01-17 07:21:47.013447: step 18999, loss = 0.31756 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:21:48.297436 ops/training.py:65 2019-01-17 07:21:48.297363: step 19000, loss = 0.33327 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:21:49.583467 ops/training.py:65 2019-01-17 07:21:49.583369: step 19001, loss = 0.25732 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:21:50.871085 ops/training.py:65 2019-01-17 07:21:50.870987: step 19002, loss = 0.28495 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:21:52.155005 ops/training.py:65 2019-01-17 07:21:52.154908: step 19003, loss = 0.21815 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:21:53.443522 ops/training.py:65 2019-01-17 07:21:53.443374: step 19004, loss = 0.35168 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:21:54.732229 ops/training.py:65 2019-01-17 07:21:54.732126: step 19005, loss = 0.29149 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:21:56.020177 ops/training.py:65 2019-01-17 07:21:56.020077: step 19006, loss = 0.33195 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:21:57.310101 ops/training.py:65 2019-01-17 07:21:57.310002: step 19007, loss = 0.22278 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:21:58.594469 ops/training.py:65 2019-01-17 07:21:58.594364: step 19008, loss = 0.37203 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:21:59.883015 ops/training.py:65 2019-01-17 07:21:59.882904: step 19009, loss = 0.26175 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:22:01.173327 ops/training.py:65 2019-01-17 07:22:01.173219: step 19010, loss = 0.27571 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:22:02.461547 ops/training.py:65 2019-01-17 07:22:02.461442: step 19011, loss = 0.25774 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:22:03.746902 ops/training.py:65 2019-01-17 07:22:03.746796: step 19012, loss = 0.22605 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:22:05.038827 ops/training.py:65 2019-01-17 07:22:05.038722: step 19013, loss = 0.21544 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:22:06.326508 ops/training.py:65 2019-01-17 07:22:06.326435: step 19014, loss = 0.33557 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:22:07.613290 ops/training.py:65 2019-01-17 07:22:07.613181: step 19015, loss = 0.27431 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:22:08.897789 ops/training.py:65 2019-01-17 07:22:08.897688: step 19016, loss = 0.21542 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:22:10.179511 ops/training.py:65 2019-01-17 07:22:10.179414: step 19017, loss = 0.21748 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:22:11.470300 ops/training.py:65 2019-01-17 07:22:11.470194: step 19018, loss = 0.22037 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:22:12.760013 ops/training.py:65 2019-01-17 07:22:12.759901: step 19019, loss = 0.32163 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:22:14.041294 ops/training.py:65 2019-01-17 07:22:14.041227: step 19020, loss = 0.27595 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:22:15.325900 ops/training.py:65 2019-01-17 07:22:15.325797: step 19021, loss = 0.23773 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:22:16.612514 ops/training.py:65 2019-01-17 07:22:16.612416: step 19022, loss = 0.20746 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:22:17.899363 ops/training.py:65 2019-01-17 07:22:17.899266: step 19023, loss = 0.26806 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:22:19.189280 ops/training.py:65 2019-01-17 07:22:19.189177: step 19024, loss = 0.26576 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:22:20.475109 ops/training.py:65 2019-01-17 07:22:20.475046: step 19025, loss = 0.20747 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:22:21.758551 ops/training.py:65 2019-01-17 07:22:21.758404: step 19026, loss = 0.29397 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:22:23.048771 ops/training.py:65 2019-01-17 07:22:23.048670: step 19027, loss = 0.20393 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:22:24.332080 ops/training.py:65 2019-01-17 07:22:24.331974: step 19028, loss = 0.23838 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:22:25.618530 ops/training.py:65 2019-01-17 07:22:25.618421: step 19029, loss = 0.27992 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:22:26.910413 ops/training.py:65 2019-01-17 07:22:26.910311: step 19030, loss = 0.25153 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:22:28.196195 ops/training.py:65 2019-01-17 07:22:28.196128: step 19031, loss = 0.21057 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:22:29.480433 ops/training.py:65 2019-01-17 07:22:29.480334: step 19032, loss = 0.26117 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:22:30.771603 ops/training.py:65 2019-01-17 07:22:30.771510: step 19033, loss = 0.24841 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:22:32.060275 ops/training.py:65 2019-01-17 07:22:32.060211: step 19034, loss = 0.26544 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:22:33.342753 ops/training.py:65 2019-01-17 07:22:33.342686: step 19035, loss = 0.27770 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:22:34.627257 ops/training.py:65 2019-01-17 07:22:34.627154: step 19036, loss = 0.22325 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:22:35.907282 ops/training.py:65 2019-01-17 07:22:35.907188: step 19037, loss = 0.25922 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:22:37.193085 ops/training.py:65 2019-01-17 07:22:37.192950: step 19038, loss = 0.23101 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:22:38.478759 ops/training.py:65 2019-01-17 07:22:38.478652: step 19039, loss = 0.21520 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:22:39.766389 ops/training.py:65 2019-01-17 07:22:39.766287: step 19040, loss = 0.18974 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:22:41.043176 ops/training.py:65 2019-01-17 07:22:41.043072: step 19041, loss = 0.27525 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:22:42.323582 ops/training.py:65 2019-01-17 07:22:42.323475: step 19042, loss = 0.30932 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:22:43.611748 ops/training.py:65 2019-01-17 07:22:43.611646: step 19043, loss = 0.36777 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:22:44.894745 ops/training.py:65 2019-01-17 07:22:44.894640: step 19044, loss = 0.21730 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:22:46.185625 ops/training.py:65 2019-01-17 07:22:46.185573: step 19045, loss = 0.19432 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:22:47.473901 ops/training.py:65 2019-01-17 07:22:47.473829: step 19046, loss = 0.22218 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:22:48.762283 ops/training.py:65 2019-01-17 07:22:48.762204: step 19047, loss = 0.28896 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:22:50.050123 ops/training.py:65 2019-01-17 07:22:50.050033: step 19048, loss = 0.26962 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:22:51.334110 ops/training.py:65 2019-01-17 07:22:51.334043: step 19049, loss = 0.29955 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:22:52.618582 ops/training.py:65 2019-01-17 07:22:52.618546: step 19050, loss = 0.24107 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:22:53.906609 ops/training.py:65 2019-01-17 07:22:53.906557: step 19051, loss = 0.24103 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:22:55.193325 ops/training.py:65 2019-01-17 07:22:55.193257: step 19052, loss = 0.32089 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:22:56.477600 ops/training.py:65 2019-01-17 07:22:56.477529: step 19053, loss = 0.27060 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:22:57.758997 ops/training.py:65 2019-01-17 07:22:57.758949: step 19054, loss = 0.21050 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:22:59.046511 ops/training.py:65 2019-01-17 07:22:59.046472: step 19055, loss = 0.25695 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:23:00.327745 ops/training.py:65 2019-01-17 07:23:00.327651: step 19056, loss = 0.24260 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:23:01.614996 ops/training.py:65 2019-01-17 07:23:01.614889: step 19057, loss = 0.24681 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:23:02.895174 ops/training.py:65 2019-01-17 07:23:02.895064: step 19058, loss = 0.27212 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:23:04.179184 ops/training.py:65 2019-01-17 07:23:04.179082: step 19059, loss = 0.25685 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:23:05.465034 ops/training.py:65 2019-01-17 07:23:05.464942: step 19060, loss = 0.24732 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:23:06.749686 ops/training.py:65 2019-01-17 07:23:06.749586: step 19061, loss = 0.22612 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:23:08.036754 ops/training.py:65 2019-01-17 07:23:08.036646: step 19062, loss = 0.20853 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:23:09.326497 ops/training.py:65 2019-01-17 07:23:09.326421: step 19063, loss = 0.27695 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:23:10.610524 ops/training.py:65 2019-01-17 07:23:10.610449: step 19064, loss = 0.25528 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:23:11.892041 ops/training.py:65 2019-01-17 07:23:11.891932: step 19065, loss = 0.27283 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:23:13.172639 ops/training.py:65 2019-01-17 07:23:13.172543: step 19066, loss = 0.20482 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:23:14.457048 ops/training.py:65 2019-01-17 07:23:14.456949: step 19067, loss = 0.18459 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:23:15.748062 ops/training.py:65 2019-01-17 07:23:15.747960: step 19068, loss = 0.25267 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:23:17.034573 ops/training.py:65 2019-01-17 07:23:17.034501: step 19069, loss = 0.23992 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:23:18.315789 ops/training.py:65 2019-01-17 07:23:18.315684: step 19070, loss = 0.27626 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:23:19.607722 ops/training.py:65 2019-01-17 07:23:19.607625: step 19071, loss = 0.29255 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:23:20.892827 ops/training.py:65 2019-01-17 07:23:20.892755: step 19072, loss = 0.24215 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:23:22.177556 ops/training.py:65 2019-01-17 07:23:22.177479: step 19073, loss = 0.22000 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:23:23.464149 ops/training.py:65 2019-01-17 07:23:23.464061: step 19074, loss = 0.21595 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:23:24.749431 ops/training.py:65 2019-01-17 07:23:24.749330: step 19075, loss = 0.29777 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:23:26.035409 ops/training.py:65 2019-01-17 07:23:26.035311: step 19076, loss = 0.25734 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:23:27.324986 ops/training.py:65 2019-01-17 07:23:27.324877: step 19077, loss = 0.20470 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:23:28.611889 ops/training.py:65 2019-01-17 07:23:28.611784: step 19078, loss = 0.22195 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:23:29.898590 ops/training.py:65 2019-01-17 07:23:29.898491: step 19079, loss = 0.22969 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:23:31.182124 ops/training.py:65 2019-01-17 07:23:31.182019: step 19080, loss = 0.24420 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:23:32.466597 ops/training.py:65 2019-01-17 07:23:32.466486: step 19081, loss = 0.26142 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:23:33.747641 ops/training.py:65 2019-01-17 07:23:33.747533: step 19082, loss = 0.26111 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:23:35.030283 ops/training.py:65 2019-01-17 07:23:35.030176: step 19083, loss = 0.33368 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:23:36.312069 ops/training.py:65 2019-01-17 07:23:36.311979: step 19084, loss = 0.24252 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:23:37.601748 ops/training.py:65 2019-01-17 07:23:37.601645: step 19085, loss = 0.28312 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:23:38.887500 ops/training.py:65 2019-01-17 07:23:38.887426: step 19086, loss = 0.24178 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:23:40.171405 ops/training.py:65 2019-01-17 07:23:40.171302: step 19087, loss = 0.20366 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:23:41.458245 ops/training.py:65 2019-01-17 07:23:41.458139: step 19088, loss = 0.28155 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:23:42.742393 ops/training.py:65 2019-01-17 07:23:42.742297: step 19089, loss = 0.22902 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:23:44.034548 ops/training.py:65 2019-01-17 07:23:44.034446: step 19090, loss = 0.20510 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:23:45.324799 ops/training.py:65 2019-01-17 07:23:45.324722: step 19091, loss = 0.25340 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:23:46.611207 ops/training.py:65 2019-01-17 07:23:46.611127: step 19092, loss = 0.18531 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:23:47.906658 ops/training.py:65 2019-01-17 07:23:47.906568: step 19093, loss = 0.19928 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:23:49.194731 ops/training.py:65 2019-01-17 07:23:49.194625: step 19094, loss = 0.23025 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:23:50.478470 ops/training.py:65 2019-01-17 07:23:50.478400: step 19095, loss = 0.22718 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:23:51.759358 ops/training.py:65 2019-01-17 07:23:51.759254: step 19096, loss = 0.22801 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:23:53.043491 ops/training.py:65 2019-01-17 07:23:53.043397: step 19097, loss = 0.21090 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:23:54.329995 ops/training.py:65 2019-01-17 07:23:54.329883: step 19098, loss = 0.31274 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:23:55.613985 ops/training.py:65 2019-01-17 07:23:55.613882: step 19099, loss = 0.19523 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:23:56.901327 ops/training.py:65 2019-01-17 07:23:56.901225: step 19100, loss = 0.23279 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:23:58.181332 ops/training.py:65 2019-01-17 07:23:58.181231: step 19101, loss = 0.28636 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:23:59.464455 ops/training.py:65 2019-01-17 07:23:59.464346: step 19102, loss = 0.28472 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:24:00.749412 ops/training.py:65 2019-01-17 07:24:00.749318: step 19103, loss = 0.31687 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:24:02.034429 ops/training.py:65 2019-01-17 07:24:02.034328: step 19104, loss = 0.22847 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:24:03.322642 ops/training.py:65 2019-01-17 07:24:03.322542: step 19105, loss = 0.27221 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:24:04.609112 ops/training.py:65 2019-01-17 07:24:04.609006: step 19106, loss = 0.29827 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:24:05.896381 ops/training.py:65 2019-01-17 07:24:05.896281: step 19107, loss = 0.24638 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:24:07.185952 ops/training.py:65 2019-01-17 07:24:07.185853: step 19108, loss = 0.36663 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:24:08.471443 ops/training.py:65 2019-01-17 07:24:08.471367: step 19109, loss = 0.24364 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:24:09.753225 ops/training.py:65 2019-01-17 07:24:09.753116: step 19110, loss = 0.20902 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:24:11.038628 ops/training.py:65 2019-01-17 07:24:11.038525: step 19111, loss = 0.23485 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:24:12.324590 ops/training.py:65 2019-01-17 07:24:12.324487: step 19112, loss = 0.21474 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:24:13.609684 ops/training.py:65 2019-01-17 07:24:13.609584: step 19113, loss = 0.27801 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:24:14.895867 ops/training.py:65 2019-01-17 07:24:14.895767: step 19114, loss = 0.27339 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:24:16.185483 ops/training.py:65 2019-01-17 07:24:16.185386: step 19115, loss = 0.24640 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:24:17.471085 ops/training.py:65 2019-01-17 07:24:17.471008: step 19116, loss = 0.28626 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:24:18.752784 ops/training.py:65 2019-01-17 07:24:18.752679: step 19117, loss = 0.24193 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:24:20.032669 ops/training.py:65 2019-01-17 07:24:20.032570: step 19118, loss = 0.25932 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:24:21.313168 ops/training.py:65 2019-01-17 07:24:21.313075: step 19119, loss = 0.23312 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:24:22.592050 ops/training.py:65 2019-01-17 07:24:22.591947: step 19120, loss = 0.30058 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:24:23.881836 ops/training.py:65 2019-01-17 07:24:23.881736: step 19121, loss = 0.20392 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:24:25.167117 ops/training.py:65 2019-01-17 07:24:25.167014: step 19122, loss = 0.19656 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:24:26.447690 ops/training.py:65 2019-01-17 07:24:26.447595: step 19123, loss = 0.24419 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:24:27.738582 ops/training.py:65 2019-01-17 07:24:27.738483: step 19124, loss = 0.25700 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:24:29.029656 ops/training.py:65 2019-01-17 07:24:29.029577: step 19125, loss = 0.30129 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:24:30.319216 ops/training.py:65 2019-01-17 07:24:30.319121: step 19126, loss = 0.22852 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:24:31.607387 ops/training.py:65 2019-01-17 07:24:31.607302: step 19127, loss = 0.22668 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:24:32.895273 ops/training.py:65 2019-01-17 07:24:32.895191: step 19128, loss = 0.20164 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:24:34.179041 ops/training.py:65 2019-01-17 07:24:34.178973: step 19129, loss = 0.27249 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:24:35.467880 ops/training.py:65 2019-01-17 07:24:35.467782: step 19130, loss = 0.24354 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:24:36.758017 ops/training.py:65 2019-01-17 07:24:36.757918: step 19131, loss = 0.20045 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:24:38.042456 ops/training.py:65 2019-01-17 07:24:38.042374: step 19132, loss = 0.28256 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:24:39.327659 ops/training.py:65 2019-01-17 07:24:39.327595: step 19133, loss = 0.24403 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:24:40.614039 ops/training.py:65 2019-01-17 07:24:40.613940: step 19134, loss = 0.27774 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:24:41.898589 ops/training.py:65 2019-01-17 07:24:41.898481: step 19135, loss = 0.24367 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:24:43.185828 ops/training.py:65 2019-01-17 07:24:43.185727: step 19136, loss = 0.25354 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:24:44.476810 ops/training.py:65 2019-01-17 07:24:44.476709: step 19137, loss = 0.23437 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:24:45.762501 ops/training.py:65 2019-01-17 07:24:45.762397: step 19138, loss = 0.36219 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 07:24:47.047364 ops/training.py:65 2019-01-17 07:24:47.047254: step 19139, loss = 0.22922 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:24:48.333193 ops/training.py:65 2019-01-17 07:24:48.333097: step 19140, loss = 0.23381 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:24:49.611811 ops/training.py:65 2019-01-17 07:24:49.611704: step 19141, loss = 0.25331 (25.0 examples/sec; 1.277 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:24:50.898440 ops/training.py:65 2019-01-17 07:24:50.898341: step 19142, loss = 0.25943 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:24:52.180335 ops/training.py:65 2019-01-17 07:24:52.180227: step 19143, loss = 0.29632 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:24:53.459319 ops/training.py:65 2019-01-17 07:24:53.459211: step 19144, loss = 0.26866 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:24:54.750651 ops/training.py:65 2019-01-17 07:24:54.750510: step 19145, loss = 0.25528 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:24:56.038256 ops/training.py:65 2019-01-17 07:24:56.038155: step 19146, loss = 0.25088 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:24:57.320125 ops/training.py:65 2019-01-17 07:24:57.320020: step 19147, loss = 0.25520 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:24:58.601571 ops/training.py:65 2019-01-17 07:24:58.601472: step 19148, loss = 0.24932 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:24:59.882247 ops/training.py:65 2019-01-17 07:24:59.882139: step 19149, loss = 0.19024 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:25:01.171937 ops/training.py:65 2019-01-17 07:25:01.171835: step 19150, loss = 0.21747 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:25:02.456238 ops/training.py:65 2019-01-17 07:25:02.456169: step 19151, loss = 0.20932 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:25:03.742988 ops/training.py:65 2019-01-17 07:25:03.742886: step 19152, loss = 0.27421 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:25:05.028285 ops/training.py:65 2019-01-17 07:25:05.028180: step 19153, loss = 0.22501 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:25:06.312639 ops/training.py:65 2019-01-17 07:25:06.312548: step 19154, loss = 0.21331 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:25:07.593384 ops/training.py:65 2019-01-17 07:25:07.593280: step 19155, loss = 0.24698 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:25:08.876360 ops/training.py:65 2019-01-17 07:25:08.876259: step 19156, loss = 0.23355 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:25:10.163330 ops/training.py:65 2019-01-17 07:25:10.163225: step 19157, loss = 0.22340 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:25:11.448822 ops/training.py:65 2019-01-17 07:25:11.448718: step 19158, loss = 0.22171 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:25:12.737308 ops/training.py:65 2019-01-17 07:25:12.737203: step 19159, loss = 0.23227 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:25:14.021358 ops/training.py:65 2019-01-17 07:25:14.021256: step 19160, loss = 0.22179 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:25:15.309166 ops/training.py:65 2019-01-17 07:25:15.309065: step 19161, loss = 0.17190 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:25:16.592640 ops/training.py:65 2019-01-17 07:25:16.592542: step 19162, loss = 0.24531 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:25:17.877154 ops/training.py:65 2019-01-17 07:25:17.877053: step 19163, loss = 0.27384 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:25:19.164675 ops/training.py:65 2019-01-17 07:25:19.164572: step 19164, loss = 0.28116 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:25:20.448754 ops/training.py:65 2019-01-17 07:25:20.448650: step 19165, loss = 0.20641 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:25:21.734726 ops/training.py:65 2019-01-17 07:25:21.734601: step 19166, loss = 0.26845 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:25:23.020872 ops/training.py:65 2019-01-17 07:25:23.020773: step 19167, loss = 0.24791 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:25:24.303807 ops/training.py:65 2019-01-17 07:25:24.303708: step 19168, loss = 0.23191 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:25:25.587667 ops/training.py:65 2019-01-17 07:25:25.587564: step 19169, loss = 0.28472 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:25:26.869056 ops/training.py:65 2019-01-17 07:25:26.868952: step 19170, loss = 0.21583 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:25:28.155657 ops/training.py:65 2019-01-17 07:25:28.155550: step 19171, loss = 0.28114 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:25:29.435901 ops/training.py:65 2019-01-17 07:25:29.435792: step 19172, loss = 0.25217 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:25:30.722198 ops/training.py:65 2019-01-17 07:25:30.722096: step 19173, loss = 0.22700 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:25:32.007647 ops/training.py:65 2019-01-17 07:25:32.007549: step 19174, loss = 0.22661 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:25:33.291819 ops/training.py:65 2019-01-17 07:25:33.291715: step 19175, loss = 0.26951 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:25:34.577652 ops/training.py:65 2019-01-17 07:25:34.577548: step 19176, loss = 0.31318 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:25:35.859574 ops/training.py:65 2019-01-17 07:25:35.859472: step 19177, loss = 0.30008 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:25:37.141144 ops/training.py:65 2019-01-17 07:25:37.141042: step 19178, loss = 0.22332 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:25:38.424669 ops/training.py:65 2019-01-17 07:25:38.424532: step 19179, loss = 0.20972 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:25:39.715194 ops/training.py:65 2019-01-17 07:25:39.715102: step 19180, loss = 0.25897 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:25:41.004821 ops/training.py:65 2019-01-17 07:25:41.004715: step 19181, loss = 0.26166 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:25:42.288850 ops/training.py:65 2019-01-17 07:25:42.288769: step 19182, loss = 0.27805 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:25:43.574599 ops/training.py:65 2019-01-17 07:25:43.574515: step 19183, loss = 0.25079 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:25:44.860919 ops/training.py:65 2019-01-17 07:25:44.860815: step 19184, loss = 0.29199 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:25:46.143759 ops/training.py:65 2019-01-17 07:25:46.143687: step 19185, loss = 0.27835 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:25:47.426175 ops/training.py:65 2019-01-17 07:25:47.426096: step 19186, loss = 0.27634 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:25:48.716346 ops/training.py:65 2019-01-17 07:25:48.716248: step 19187, loss = 0.26930 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:25:50.006026 ops/training.py:65 2019-01-17 07:25:50.005944: step 19188, loss = 0.20155 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:25:51.293338 ops/training.py:65 2019-01-17 07:25:51.293259: step 19189, loss = 0.25061 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:25:52.582440 ops/training.py:65 2019-01-17 07:25:52.582351: step 19190, loss = 0.24569 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:25:53.870254 ops/training.py:65 2019-01-17 07:25:53.870175: step 19191, loss = 0.26767 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:25:55.158646 ops/training.py:65 2019-01-17 07:25:55.158557: step 19192, loss = 0.23131 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:25:56.446520 ops/training.py:65 2019-01-17 07:25:56.446429: step 19193, loss = 0.27888 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:25:57.736223 ops/training.py:65 2019-01-17 07:25:57.736145: step 19194, loss = 0.24120 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:25:59.024635 ops/training.py:65 2019-01-17 07:25:59.024552: step 19195, loss = 0.20901 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:26:00.312751 ops/training.py:65 2019-01-17 07:26:00.312675: step 19196, loss = 0.22894 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:26:01.600988 ops/training.py:65 2019-01-17 07:26:01.600911: step 19197, loss = 0.24413 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:26:02.889908 ops/training.py:65 2019-01-17 07:26:02.889826: step 19198, loss = 0.25412 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:26:04.174235 ops/training.py:65 2019-01-17 07:26:04.174149: step 19199, loss = 0.27466 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:26:05.464207 ops/training.py:65 2019-01-17 07:26:05.464111: step 19200, loss = 0.24384 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:26:06.748164 ops/training.py:65 2019-01-17 07:26:06.748089: step 19201, loss = 0.22454 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:26:08.031553 ops/training.py:65 2019-01-17 07:26:08.031453: step 19202, loss = 0.20820 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:26:09.322267 ops/training.py:65 2019-01-17 07:26:09.322157: step 19203, loss = 0.25364 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:26:10.612333 ops/training.py:65 2019-01-17 07:26:10.612256: step 19204, loss = 0.18341 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:26:11.900054 ops/training.py:65 2019-01-17 07:26:11.899969: step 19205, loss = 0.22340 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:26:13.188761 ops/training.py:65 2019-01-17 07:26:13.188686: step 19206, loss = 0.19684 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:26:14.476496 ops/training.py:65 2019-01-17 07:26:14.476413: step 19207, loss = 0.34399 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:26:15.764334 ops/training.py:65 2019-01-17 07:26:15.764226: step 19208, loss = 0.17237 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:26:17.051717 ops/training.py:65 2019-01-17 07:26:17.051632: step 19209, loss = 0.21349 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:26:18.339452 ops/training.py:65 2019-01-17 07:26:18.339357: step 19210, loss = 0.18377 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:26:19.624184 ops/training.py:65 2019-01-17 07:26:19.624103: step 19211, loss = 0.29921 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:26:20.911754 ops/training.py:65 2019-01-17 07:26:20.911678: step 19212, loss = 0.27563 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:26:22.199189 ops/training.py:65 2019-01-17 07:26:22.199104: step 19213, loss = 0.24575 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:26:23.484397 ops/training.py:65 2019-01-17 07:26:23.484320: step 19214, loss = 0.26267 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:26:24.766966 ops/training.py:65 2019-01-17 07:26:24.766866: step 19215, loss = 0.24313 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:26:26.063729 ops/training.py:65 2019-01-17 07:26:26.063589: step 19216, loss = 0.25400 (24.7 examples/sec; 1.296 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:26:27.354396 ops/training.py:65 2019-01-17 07:26:27.354307: step 19217, loss = 0.26780 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:26:28.643644 ops/training.py:65 2019-01-17 07:26:28.643561: step 19218, loss = 0.23828 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:26:29.932192 ops/training.py:65 2019-01-17 07:26:29.932116: step 19219, loss = 0.20212 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:26:31.221009 ops/training.py:65 2019-01-17 07:26:31.220919: step 19220, loss = 0.22597 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:26:32.511336 ops/training.py:65 2019-01-17 07:26:32.511252: step 19221, loss = 0.25949 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:26:33.798535 ops/training.py:65 2019-01-17 07:26:33.798450: step 19222, loss = 0.29038 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:26:35.083205 ops/training.py:65 2019-01-17 07:26:35.083124: step 19223, loss = 0.28760 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:26:36.373078 ops/training.py:65 2019-01-17 07:26:36.372992: step 19224, loss = 0.21568 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:26:37.661630 ops/training.py:65 2019-01-17 07:26:37.661547: step 19225, loss = 0.30120 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:26:38.949410 ops/training.py:65 2019-01-17 07:26:38.949321: step 19226, loss = 0.27291 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:26:40.236850 ops/training.py:65 2019-01-17 07:26:40.236749: step 19227, loss = 0.33991 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:26:41.525746 ops/training.py:65 2019-01-17 07:26:41.525672: step 19228, loss = 0.35484 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:26:42.809112 ops/training.py:65 2019-01-17 07:26:42.809035: step 19229, loss = 0.23669 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:26:44.097819 ops/training.py:65 2019-01-17 07:26:44.097737: step 19230, loss = 0.29226 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:26:45.385182 ops/training.py:65 2019-01-17 07:26:45.385101: step 19231, loss = 0.26125 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:26:46.673990 ops/training.py:65 2019-01-17 07:26:46.673875: step 19232, loss = 0.21867 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:26:47.963193 ops/training.py:65 2019-01-17 07:26:47.963113: step 19233, loss = 0.26246 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:26:49.252232 ops/training.py:65 2019-01-17 07:26:49.252149: step 19234, loss = 0.20018 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:26:50.541534 ops/training.py:65 2019-01-17 07:26:50.541454: step 19235, loss = 0.21011 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:26:51.830191 ops/training.py:65 2019-01-17 07:26:51.830104: step 19236, loss = 0.32656 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:26:53.117678 ops/training.py:65 2019-01-17 07:26:53.117591: step 19237, loss = 0.21863 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:26:54.406575 ops/training.py:65 2019-01-17 07:26:54.406492: step 19238, loss = 0.26511 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:26:55.696255 ops/training.py:65 2019-01-17 07:26:55.696174: step 19239, loss = 0.17101 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:26:56.984900 ops/training.py:65 2019-01-17 07:26:56.984819: step 19240, loss = 0.24203 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:26:58.268742 ops/training.py:65 2019-01-17 07:26:58.268668: step 19241, loss = 0.24797 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:26:59.552954 ops/training.py:65 2019-01-17 07:26:59.552816: step 19242, loss = 0.27300 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:27:00.840835 ops/training.py:65 2019-01-17 07:27:00.840725: step 19243, loss = 0.34425 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:27:02.125516 ops/training.py:65 2019-01-17 07:27:02.125380: step 19244, loss = 0.20847 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:27:03.416950 ops/training.py:65 2019-01-17 07:27:03.416854: step 19245, loss = 0.24961 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:27:04.700869 ops/training.py:65 2019-01-17 07:27:04.700716: step 19246, loss = 0.23462 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:27:05.985963 ops/training.py:65 2019-01-17 07:27:05.985873: step 19247, loss = 0.23796 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:27:07.273050 ops/training.py:65 2019-01-17 07:27:07.272942: step 19248, loss = 0.25565 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:27:08.559555 ops/training.py:65 2019-01-17 07:27:08.559452: step 19249, loss = 0.29195 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:27:09.851225 ops/training.py:65 2019-01-17 07:27:09.851124: step 19250, loss = 0.21379 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:27:11.140770 ops/training.py:65 2019-01-17 07:27:11.140693: step 19251, loss = 0.22306 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:27:12.428540 ops/training.py:65 2019-01-17 07:27:12.428459: step 19252, loss = 0.28154 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:27:13.711914 ops/training.py:65 2019-01-17 07:27:13.711847: step 19253, loss = 0.29052 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:27:14.993459 ops/training.py:65 2019-01-17 07:27:14.993354: step 19254, loss = 0.24911 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:27:16.276990 ops/training.py:65 2019-01-17 07:27:16.276883: step 19255, loss = 0.21063 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:27:17.568611 ops/training.py:65 2019-01-17 07:27:17.568509: step 19256, loss = 0.27207 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:27:18.851817 ops/training.py:65 2019-01-17 07:27:18.851714: step 19257, loss = 0.25768 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:27:20.137287 ops/training.py:65 2019-01-17 07:27:20.137185: step 19258, loss = 0.18541 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:27:21.423683 ops/training.py:65 2019-01-17 07:27:21.423583: step 19259, loss = 0.21132 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:27:22.715547 ops/training.py:65 2019-01-17 07:27:22.715448: step 19260, loss = 0.22267 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:27:24.006250 ops/training.py:65 2019-01-17 07:27:24.006146: step 19261, loss = 0.24378 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:27:25.293040 ops/training.py:65 2019-01-17 07:27:25.292940: step 19262, loss = 0.22127 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:27:26.583854 ops/training.py:65 2019-01-17 07:27:26.583753: step 19263, loss = 0.25144 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:27:27.872169 ops/training.py:65 2019-01-17 07:27:27.872076: step 19264, loss = 0.24880 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:27:29.160683 ops/training.py:65 2019-01-17 07:27:29.160609: step 19265, loss = 0.23674 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:27:30.442625 ops/training.py:65 2019-01-17 07:27:30.442538: step 19266, loss = 0.21776 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:27:31.724482 ops/training.py:65 2019-01-17 07:27:31.724344: step 19267, loss = 0.26992 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:27:33.013102 ops/training.py:65 2019-01-17 07:27:33.012994: step 19268, loss = 0.24880 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:27:34.293554 ops/training.py:65 2019-01-17 07:27:34.293485: step 19269, loss = 0.19772 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:27:35.573076 ops/training.py:65 2019-01-17 07:27:35.573006: step 19270, loss = 0.22371 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:27:36.857072 ops/training.py:65 2019-01-17 07:27:36.857009: step 19271, loss = 0.21878 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:27:38.146077 ops/training.py:65 2019-01-17 07:27:38.145974: step 19272, loss = 0.22172 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:27:39.430985 ops/training.py:65 2019-01-17 07:27:39.430892: step 19273, loss = 0.22381 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:27:40.713978 ops/training.py:65 2019-01-17 07:27:40.713883: step 19274, loss = 0.26159 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:27:42.000372 ops/training.py:65 2019-01-17 07:27:42.000265: step 19275, loss = 0.25698 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:27:43.291928 ops/training.py:65 2019-01-17 07:27:43.291832: step 19276, loss = 0.19913 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:27:44.572756 ops/training.py:65 2019-01-17 07:27:44.572662: step 19277, loss = 0.23676 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:27:45.859554 ops/training.py:65 2019-01-17 07:27:45.859453: step 19278, loss = 0.21971 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:27:47.142039 ops/training.py:65 2019-01-17 07:27:47.141944: step 19279, loss = 0.24060 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:27:48.424775 ops/training.py:65 2019-01-17 07:27:48.424674: step 19280, loss = 0.23750 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:27:49.708233 ops/training.py:65 2019-01-17 07:27:49.708198: step 19281, loss = 0.23108 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:27:50.995231 ops/training.py:65 2019-01-17 07:27:50.995199: step 19282, loss = 0.22394 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:27:52.284001 ops/training.py:65 2019-01-17 07:27:52.283928: step 19283, loss = 0.21176 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:27:53.566767 ops/training.py:65 2019-01-17 07:27:53.566693: step 19284, loss = 0.25329 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:27:54.849295 ops/training.py:65 2019-01-17 07:27:54.849218: step 19285, loss = 0.21145 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:27:56.129523 ops/training.py:65 2019-01-17 07:27:56.129455: step 19286, loss = 0.25103 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:27:57.409805 ops/training.py:65 2019-01-17 07:27:57.409760: step 19287, loss = 0.24743 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:27:58.692895 ops/training.py:65 2019-01-17 07:27:58.692863: step 19288, loss = 0.23558 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:27:59.984084 ops/training.py:65 2019-01-17 07:27:59.984048: step 19289, loss = 0.29743 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:28:01.270337 ops/training.py:65 2019-01-17 07:28:01.270286: step 19290, loss = 0.27769 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:28:02.558828 ops/training.py:65 2019-01-17 07:28:02.558748: step 19291, loss = 0.20454 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:28:03.847518 ops/training.py:65 2019-01-17 07:28:03.847434: step 19292, loss = 0.35365 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:28:05.129791 ops/training.py:65 2019-01-17 07:28:05.129717: step 19293, loss = 0.21678 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:28:06.417826 ops/training.py:65 2019-01-17 07:28:06.417751: step 19294, loss = 0.31170 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:28:07.705762 ops/training.py:65 2019-01-17 07:28:07.705672: step 19295, loss = 0.17865 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:28:08.989548 ops/training.py:65 2019-01-17 07:28:08.989481: step 19296, loss = 0.24933 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:28:10.272978 ops/training.py:65 2019-01-17 07:28:10.272876: step 19297, loss = 0.24203 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:28:11.554598 ops/training.py:65 2019-01-17 07:28:11.554488: step 19298, loss = 0.28442 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:28:12.841418 ops/training.py:65 2019-01-17 07:28:12.841312: step 19299, loss = 0.23970 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:28:14.125035 ops/training.py:65 2019-01-17 07:28:14.124881: step 19300, loss = 0.23369 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:28:15.413203 ops/training.py:65 2019-01-17 07:28:15.413095: step 19301, loss = 0.25104 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:28:16.696858 ops/training.py:65 2019-01-17 07:28:16.696722: step 19302, loss = 0.21657 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:28:17.984281 ops/training.py:65 2019-01-17 07:28:17.984177: step 19303, loss = 0.29477 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:28:19.269919 ops/training.py:65 2019-01-17 07:28:19.269816: step 19304, loss = 0.25826 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:28:20.554571 ops/training.py:65 2019-01-17 07:28:20.554445: step 19305, loss = 0.31741 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:28:21.841110 ops/training.py:65 2019-01-17 07:28:21.841022: step 19306, loss = 0.27843 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:28:23.125001 ops/training.py:65 2019-01-17 07:28:23.124893: step 19307, loss = 0.20228 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:28:24.414272 ops/training.py:65 2019-01-17 07:28:24.414132: step 19308, loss = 0.28562 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:28:25.698333 ops/training.py:65 2019-01-17 07:28:25.698256: step 19309, loss = 0.21239 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:28:26.979582 ops/training.py:65 2019-01-17 07:28:26.979480: step 19310, loss = 0.21237 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:28:28.264524 ops/training.py:65 2019-01-17 07:28:28.264425: step 19311, loss = 0.31196 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:28:29.554062 ops/training.py:65 2019-01-17 07:28:29.553926: step 19312, loss = 0.17716 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:28:30.838924 ops/training.py:65 2019-01-17 07:28:30.838853: step 19313, loss = 0.24731 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:28:32.119097 ops/training.py:65 2019-01-17 07:28:32.119005: step 19314, loss = 0.25901 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:28:33.400335 ops/training.py:65 2019-01-17 07:28:33.400238: step 19315, loss = 0.25695 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:28:34.687839 ops/training.py:65 2019-01-17 07:28:34.687741: step 19316, loss = 0.23543 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:28:35.978565 ops/training.py:65 2019-01-17 07:28:35.978479: step 19317, loss = 0.25765 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:28:37.268569 ops/training.py:65 2019-01-17 07:28:37.268467: step 19318, loss = 0.28186 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:28:38.556947 ops/training.py:65 2019-01-17 07:28:38.556875: step 19319, loss = 0.30850 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:28:39.839801 ops/training.py:65 2019-01-17 07:28:39.839732: step 19320, loss = 0.22583 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:28:41.123614 ops/training.py:65 2019-01-17 07:28:41.123512: step 19321, loss = 0.25448 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:28:42.404318 ops/training.py:65 2019-01-17 07:28:42.404246: step 19322, loss = 0.22999 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:28:43.693997 ops/training.py:65 2019-01-17 07:28:43.693895: step 19323, loss = 0.21946 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:28:44.984813 ops/training.py:65 2019-01-17 07:28:44.984713: step 19324, loss = 0.21497 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:28:46.276414 ops/training.py:65 2019-01-17 07:28:46.276326: step 19325, loss = 0.22856 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:28:47.565907 ops/training.py:65 2019-01-17 07:28:47.565806: step 19326, loss = 0.25270 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:28:48.853632 ops/training.py:65 2019-01-17 07:28:48.853559: step 19327, loss = 0.22022 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:28:50.141687 ops/training.py:65 2019-01-17 07:28:50.141611: step 19328, loss = 0.25028 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:28:51.430387 ops/training.py:65 2019-01-17 07:28:51.430311: step 19329, loss = 0.28562 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:28:52.714777 ops/training.py:65 2019-01-17 07:28:52.714705: step 19330, loss = 0.29142 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:28:53.998829 ops/training.py:65 2019-01-17 07:28:53.998726: step 19331, loss = 0.27608 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:28:55.285363 ops/training.py:65 2019-01-17 07:28:55.285256: step 19332, loss = 0.25281 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:28:56.569402 ops/training.py:65 2019-01-17 07:28:56.569298: step 19333, loss = 0.25360 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:28:57.861271 ops/training.py:65 2019-01-17 07:28:57.861124: step 19334, loss = 0.18189 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:28:59.147907 ops/training.py:65 2019-01-17 07:28:59.147833: step 19335, loss = 0.30115 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:29:00.432692 ops/training.py:65 2019-01-17 07:29:00.432627: step 19336, loss = 0.26734 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:29:01.721776 ops/training.py:65 2019-01-17 07:29:01.721670: step 19337, loss = 0.28339 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:29:03.007268 ops/training.py:65 2019-01-17 07:29:03.007163: step 19338, loss = 0.32063 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:29:04.294943 ops/training.py:65 2019-01-17 07:29:04.294842: step 19339, loss = 0.26199 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:29:05.584801 ops/training.py:65 2019-01-17 07:29:05.584691: step 19340, loss = 0.26656 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:29:06.874012 ops/training.py:65 2019-01-17 07:29:06.873932: step 19341, loss = 0.26988 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:29:08.164204 ops/training.py:65 2019-01-17 07:29:08.164130: step 19342, loss = 0.22394 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:29:09.447108 ops/training.py:65 2019-01-17 07:29:09.447037: step 19343, loss = 0.28723 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:29:10.730954 ops/training.py:65 2019-01-17 07:29:10.730853: step 19344, loss = 0.24300 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:29:12.022022 ops/training.py:65 2019-01-17 07:29:12.021921: step 19345, loss = 0.19166 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:29:13.305964 ops/training.py:65 2019-01-17 07:29:13.305891: step 19346, loss = 0.20227 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:29:14.592456 ops/training.py:65 2019-01-17 07:29:14.592356: step 19347, loss = 0.21350 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:29:15.883840 ops/training.py:65 2019-01-17 07:29:15.883738: step 19348, loss = 0.22960 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:29:17.174384 ops/training.py:65 2019-01-17 07:29:17.174286: step 19349, loss = 0.22343 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:29:18.462782 ops/training.py:65 2019-01-17 07:29:18.462711: step 19350, loss = 0.26614 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:29:19.746550 ops/training.py:65 2019-01-17 07:29:19.746477: step 19351, loss = 0.25385 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:29:21.035866 ops/training.py:65 2019-01-17 07:29:21.035778: step 19352, loss = 0.19771 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:29:22.325103 ops/training.py:65 2019-01-17 07:29:22.325007: step 19353, loss = 0.21934 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:29:23.612530 ops/training.py:65 2019-01-17 07:29:23.612428: step 19354, loss = 0.24553 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:29:24.893020 ops/training.py:65 2019-01-17 07:29:24.892950: step 19355, loss = 0.19117 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:29:26.173437 ops/training.py:65 2019-01-17 07:29:26.173376: step 19356, loss = 0.17683 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:29:27.454823 ops/training.py:65 2019-01-17 07:29:27.454754: step 19357, loss = 0.22496 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:29:28.739594 ops/training.py:65 2019-01-17 07:29:28.739489: step 19358, loss = 0.22902 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:29:30.028923 ops/training.py:65 2019-01-17 07:29:30.028827: step 19359, loss = 0.20670 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:29:31.314461 ops/training.py:65 2019-01-17 07:29:31.314397: step 19360, loss = 0.27469 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:29:32.600340 ops/training.py:65 2019-01-17 07:29:32.600239: step 19361, loss = 0.24636 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:29:33.888071 ops/training.py:65 2019-01-17 07:29:33.887973: step 19362, loss = 0.24054 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:29:35.180000 ops/training.py:65 2019-01-17 07:29:35.179853: step 19363, loss = 0.21211 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:29:36.471234 ops/training.py:65 2019-01-17 07:29:36.471156: step 19364, loss = 0.22236 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:29:37.755314 ops/training.py:65 2019-01-17 07:29:37.755245: step 19365, loss = 0.23698 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:29:39.038390 ops/training.py:65 2019-01-17 07:29:39.038289: step 19366, loss = 0.28567 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:29:40.329478 ops/training.py:65 2019-01-17 07:29:40.329378: step 19367, loss = 0.22265 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:29:41.616724 ops/training.py:65 2019-01-17 07:29:41.616625: step 19368, loss = 0.24745 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:29:42.905469 ops/training.py:65 2019-01-17 07:29:42.905370: step 19369, loss = 0.30380 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:29:44.195503 ops/training.py:65 2019-01-17 07:29:44.195365: step 19370, loss = 0.29581 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:29:45.485079 ops/training.py:65 2019-01-17 07:29:45.484998: step 19371, loss = 0.22519 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:29:46.772455 ops/training.py:65 2019-01-17 07:29:46.772352: step 19372, loss = 0.25149 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:29:48.059175 ops/training.py:65 2019-01-17 07:29:48.059092: step 19373, loss = 0.18133 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:29:49.343360 ops/training.py:65 2019-01-17 07:29:49.343291: step 19374, loss = 0.21555 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:29:50.627571 ops/training.py:65 2019-01-17 07:29:50.627465: step 19375, loss = 0.32682 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:29:51.919486 ops/training.py:65 2019-01-17 07:29:51.919397: step 19376, loss = 0.21465 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:29:53.210176 ops/training.py:65 2019-01-17 07:29:53.210095: step 19377, loss = 0.29638 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:29:54.494226 ops/training.py:65 2019-01-17 07:29:54.494157: step 19378, loss = 0.23550 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:29:55.774291 ops/training.py:65 2019-01-17 07:29:55.774186: step 19379, loss = 0.27301 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:29:57.065554 ops/training.py:65 2019-01-17 07:29:57.065454: step 19380, loss = 0.21693 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:29:58.351471 ops/training.py:65 2019-01-17 07:29:58.351402: step 19381, loss = 0.24466 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:29:59.635646 ops/training.py:65 2019-01-17 07:29:59.635539: step 19382, loss = 0.17936 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:30:00.919095 ops/training.py:65 2019-01-17 07:30:00.918994: step 19383, loss = 0.24568 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:30:02.201844 ops/training.py:65 2019-01-17 07:30:02.201748: step 19384, loss = 0.25028 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:30:03.492593 ops/training.py:65 2019-01-17 07:30:03.492487: step 19385, loss = 0.25307 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:30:04.778356 ops/training.py:65 2019-01-17 07:30:04.778260: step 19386, loss = 0.29206 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:30:06.058157 ops/training.py:65 2019-01-17 07:30:06.058057: step 19387, loss = 0.24589 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:30:07.349067 ops/training.py:65 2019-01-17 07:30:07.348970: step 19388, loss = 0.27852 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:30:08.638741 ops/training.py:65 2019-01-17 07:30:08.638666: step 19389, loss = 0.33623 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:30:09.919436 ops/training.py:65 2019-01-17 07:30:09.919369: step 19390, loss = 0.20114 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:30:11.199642 ops/training.py:65 2019-01-17 07:30:11.199541: step 19391, loss = 0.23161 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:30:12.483949 ops/training.py:65 2019-01-17 07:30:12.483847: step 19392, loss = 0.22723 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:30:13.773074 ops/training.py:65 2019-01-17 07:30:13.772978: step 19393, loss = 0.23764 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:30:15.059254 ops/training.py:65 2019-01-17 07:30:15.059152: step 19394, loss = 0.25537 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:30:16.336708 ops/training.py:65 2019-01-17 07:30:16.336607: step 19395, loss = 0.24209 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:30:17.623272 ops/training.py:65 2019-01-17 07:30:17.623172: step 19396, loss = 0.22625 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:30:18.909297 ops/training.py:65 2019-01-17 07:30:18.909206: step 19397, loss = 0.24522 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:30:20.199419 ops/training.py:65 2019-01-17 07:30:20.199324: step 19398, loss = 0.28744 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:30:21.488840 ops/training.py:65 2019-01-17 07:30:21.488766: step 19399, loss = 0.26917 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:30:22.777299 ops/training.py:65 2019-01-17 07:30:22.777197: step 19400, loss = 0.21982 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:30:24.063370 ops/training.py:65 2019-01-17 07:30:24.063296: step 19401, loss = 0.24398 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:30:25.351327 ops/training.py:65 2019-01-17 07:30:25.351221: step 19402, loss = 0.20425 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:30:26.641450 ops/training.py:65 2019-01-17 07:30:26.641368: step 19403, loss = 0.23540 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:30:27.930042 ops/training.py:65 2019-01-17 07:30:27.929952: step 19404, loss = 0.21161 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:30:29.213322 ops/training.py:65 2019-01-17 07:30:29.213254: step 19405, loss = 0.27611 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:30:30.500878 ops/training.py:65 2019-01-17 07:30:30.500741: step 19406, loss = 0.20154 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:30:31.789094 ops/training.py:65 2019-01-17 07:30:31.788990: step 19407, loss = 0.18833 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:30:33.073836 ops/training.py:65 2019-01-17 07:30:33.073764: step 19408, loss = 0.32914 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:30:34.354840 ops/training.py:65 2019-01-17 07:30:34.354738: step 19409, loss = 0.26095 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:30:35.640056 ops/training.py:65 2019-01-17 07:30:35.639934: step 19410, loss = 0.23146 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:30:36.929738 ops/training.py:65 2019-01-17 07:30:36.929637: step 19411, loss = 0.23657 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:30:38.216329 ops/training.py:65 2019-01-17 07:30:38.216245: step 19412, loss = 0.23759 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:30:39.498285 ops/training.py:65 2019-01-17 07:30:39.498187: step 19413, loss = 0.29933 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:30:40.785627 ops/training.py:65 2019-01-17 07:30:40.785573: step 19414, loss = 0.22161 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:30:42.067810 ops/training.py:65 2019-01-17 07:30:42.067771: step 19415, loss = 0.28469 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:30:43.355091 ops/training.py:65 2019-01-17 07:30:43.355040: step 19416, loss = 0.26110 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:30:44.638529 ops/training.py:65 2019-01-17 07:30:44.638496: step 19417, loss = 0.25281 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:30:45.923400 ops/training.py:65 2019-01-17 07:30:45.923317: step 19418, loss = 0.19197 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:30:47.208775 ops/training.py:65 2019-01-17 07:30:47.208668: step 19419, loss = 0.25024 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:30:48.493285 ops/training.py:65 2019-01-17 07:30:48.493148: step 19420, loss = 0.28912 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:30:49.781198 ops/training.py:65 2019-01-17 07:30:49.781101: step 19421, loss = 0.26026 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:30:51.066085 ops/training.py:65 2019-01-17 07:30:51.065990: step 19422, loss = 0.22938 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:30:52.350512 ops/training.py:65 2019-01-17 07:30:52.350413: step 19423, loss = 0.24247 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:30:53.640128 ops/training.py:65 2019-01-17 07:30:53.640033: step 19424, loss = 0.18325 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:30:54.924090 ops/training.py:65 2019-01-17 07:30:54.923980: step 19425, loss = 0.24209 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:30:56.207931 ops/training.py:65 2019-01-17 07:30:56.207831: step 19426, loss = 0.24448 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:30:57.498017 ops/training.py:65 2019-01-17 07:30:57.497909: step 19427, loss = 0.28606 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:30:58.785604 ops/training.py:65 2019-01-17 07:30:58.785530: step 19428, loss = 0.23930 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:31:00.075073 ops/training.py:65 2019-01-17 07:31:00.075002: step 19429, loss = 0.23964 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:31:01.358539 ops/training.py:65 2019-01-17 07:31:01.358461: step 19430, loss = 0.20060 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:31:02.638947 ops/training.py:65 2019-01-17 07:31:02.638848: step 19431, loss = 0.21543 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:31:03.929495 ops/training.py:65 2019-01-17 07:31:03.929402: step 19432, loss = 0.20707 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:31:05.214141 ops/training.py:65 2019-01-17 07:31:05.214075: step 19433, loss = 0.23317 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:31:06.501623 ops/training.py:65 2019-01-17 07:31:06.501542: step 19434, loss = 0.22589 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:31:07.785399 ops/training.py:65 2019-01-17 07:31:07.785328: step 19435, loss = 0.30719 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:31:09.068123 ops/training.py:65 2019-01-17 07:31:09.068023: step 19436, loss = 0.25869 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:31:10.358532 ops/training.py:65 2019-01-17 07:31:10.358431: step 19437, loss = 0.24211 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:31:11.642857 ops/training.py:65 2019-01-17 07:31:11.642794: step 19438, loss = 0.24060 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:31:12.933784 ops/training.py:65 2019-01-17 07:31:12.933712: step 19439, loss = 0.35443 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 07:31:14.222365 ops/training.py:65 2019-01-17 07:31:14.222291: step 19440, loss = 0.27197 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:31:15.511485 ops/training.py:65 2019-01-17 07:31:15.511405: step 19441, loss = 0.25531 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:31:16.793739 ops/training.py:65 2019-01-17 07:31:16.793666: step 19442, loss = 0.19965 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:31:18.077188 ops/training.py:65 2019-01-17 07:31:18.077124: step 19443, loss = 0.17868 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:31:19.367807 ops/training.py:65 2019-01-17 07:31:19.367702: step 19444, loss = 0.24247 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:31:20.652754 ops/training.py:65 2019-01-17 07:31:20.652680: step 19445, loss = 0.15853 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:31:21.936522 ops/training.py:65 2019-01-17 07:31:21.936424: step 19446, loss = 0.23789 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:31:23.223096 ops/training.py:65 2019-01-17 07:31:23.222994: step 19447, loss = 0.20497 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:31:24.503871 ops/training.py:65 2019-01-17 07:31:24.503763: step 19448, loss = 0.21330 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:31:25.792857 ops/training.py:65 2019-01-17 07:31:25.792760: step 19449, loss = 0.20728 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:31:27.079680 ops/training.py:65 2019-01-17 07:31:27.079585: step 19450, loss = 0.23876 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:31:28.364466 ops/training.py:65 2019-01-17 07:31:28.364359: step 19451, loss = 0.26869 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:31:29.648122 ops/training.py:65 2019-01-17 07:31:29.648017: step 19452, loss = 0.21466 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:31:30.938374 ops/training.py:65 2019-01-17 07:31:30.938279: step 19453, loss = 0.25551 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:31:32.223627 ops/training.py:65 2019-01-17 07:31:32.223525: step 19454, loss = 0.28815 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:31:33.504831 ops/training.py:65 2019-01-17 07:31:33.504723: step 19455, loss = 0.21987 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:31:34.793246 ops/training.py:65 2019-01-17 07:31:34.793144: step 19456, loss = 0.28804 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:31:36.073384 ops/training.py:65 2019-01-17 07:31:36.073314: step 19457, loss = 0.25100 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:31:37.354458 ops/training.py:65 2019-01-17 07:31:37.354383: step 19458, loss = 0.26389 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:31:38.644548 ops/training.py:65 2019-01-17 07:31:38.644464: step 19459, loss = 0.22612 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:31:39.930841 ops/training.py:65 2019-01-17 07:31:39.930752: step 19460, loss = 0.21801 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:31:41.216106 ops/training.py:65 2019-01-17 07:31:41.216029: step 19461, loss = 0.18881 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:31:42.499710 ops/training.py:65 2019-01-17 07:31:42.499606: step 19462, loss = 0.22473 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:31:43.792586 ops/training.py:65 2019-01-17 07:31:43.792451: step 19463, loss = 0.21602 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:31:45.079221 ops/training.py:65 2019-01-17 07:31:45.079146: step 19464, loss = 0.20850 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:31:46.364562 ops/training.py:65 2019-01-17 07:31:46.364478: step 19465, loss = 0.19716 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:31:47.656441 ops/training.py:65 2019-01-17 07:31:47.656339: step 19466, loss = 0.24179 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:31:48.946207 ops/training.py:65 2019-01-17 07:31:48.946107: step 19467, loss = 0.25936 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:31:50.236516 ops/training.py:65 2019-01-17 07:31:50.236434: step 19468, loss = 0.23392 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:31:51.520813 ops/training.py:65 2019-01-17 07:31:51.520742: step 19469, loss = 0.24952 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:31:52.801910 ops/training.py:65 2019-01-17 07:31:52.801838: step 19470, loss = 0.25344 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:31:54.088821 ops/training.py:65 2019-01-17 07:31:54.088722: step 19471, loss = 0.24595 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:31:55.373453 ops/training.py:65 2019-01-17 07:31:55.373353: step 19472, loss = 0.18646 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:31:56.660149 ops/training.py:65 2019-01-17 07:31:56.660047: step 19473, loss = 0.25646 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:31:57.945074 ops/training.py:65 2019-01-17 07:31:57.944974: step 19474, loss = 0.26992 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:31:59.230508 ops/training.py:65 2019-01-17 07:31:59.230408: step 19475, loss = 0.28573 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:32:00.513871 ops/training.py:65 2019-01-17 07:32:00.513768: step 19476, loss = 0.30320 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:32:01.803709 ops/training.py:65 2019-01-17 07:32:01.803606: step 19477, loss = 0.22476 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:32:03.093501 ops/training.py:65 2019-01-17 07:32:03.093418: step 19478, loss = 0.20087 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:32:04.377722 ops/training.py:65 2019-01-17 07:32:04.377652: step 19479, loss = 0.28460 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:32:05.662533 ops/training.py:65 2019-01-17 07:32:05.662465: step 19480, loss = 0.20668 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:32:06.952898 ops/training.py:65 2019-01-17 07:32:06.952827: step 19481, loss = 0.21624 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:32:08.241477 ops/training.py:65 2019-01-17 07:32:08.241398: step 19482, loss = 0.21011 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:32:09.529332 ops/training.py:65 2019-01-17 07:32:09.529264: step 19483, loss = 0.25868 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:32:10.816956 ops/training.py:65 2019-01-17 07:32:10.816882: step 19484, loss = 0.26657 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:32:12.100523 ops/training.py:65 2019-01-17 07:32:12.100446: step 19485, loss = 0.21210 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:32:13.384324 ops/training.py:65 2019-01-17 07:32:13.384259: step 19486, loss = 0.22891 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:32:14.670222 ops/training.py:65 2019-01-17 07:32:14.670123: step 19487, loss = 0.22537 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:32:15.954262 ops/training.py:65 2019-01-17 07:32:15.954163: step 19488, loss = 0.24028 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:32:17.241321 ops/training.py:65 2019-01-17 07:32:17.241221: step 19489, loss = 0.25261 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:32:18.527339 ops/training.py:65 2019-01-17 07:32:18.527241: step 19490, loss = 0.22839 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:32:19.810960 ops/training.py:65 2019-01-17 07:32:19.810860: step 19491, loss = 0.25712 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:32:21.103109 ops/training.py:65 2019-01-17 07:32:21.103021: step 19492, loss = 0.21802 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:32:22.385291 ops/training.py:65 2019-01-17 07:32:22.385226: step 19493, loss = 0.25263 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:32:23.673186 ops/training.py:65 2019-01-17 07:32:23.673081: step 19494, loss = 0.21454 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:32:24.964422 ops/training.py:65 2019-01-17 07:32:24.964314: step 19495, loss = 0.25779 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:32:26.248382 ops/training.py:65 2019-01-17 07:32:26.248285: step 19496, loss = 0.26890 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:32:27.532467 ops/training.py:65 2019-01-17 07:32:27.532366: step 19497, loss = 0.24781 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:32:28.822080 ops/training.py:65 2019-01-17 07:32:28.821944: step 19498, loss = 0.28318 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:32:30.106495 ops/training.py:65 2019-01-17 07:32:30.106415: step 19499, loss = 0.26377 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:32:31.394696 ops/training.py:65 2019-01-17 07:32:31.394583: step 19500, loss = 0.27017 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:32:32.684406 ops/training.py:65 2019-01-17 07:32:32.684327: step 19501, loss = 0.20763 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:32:33.972915 ops/training.py:65 2019-01-17 07:32:33.972838: step 19502, loss = 0.22041 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:32:35.260377 ops/training.py:65 2019-01-17 07:32:35.260300: step 19503, loss = 0.25634 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:32:36.549143 ops/training.py:65 2019-01-17 07:32:36.549035: step 19504, loss = 0.29077 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:32:37.835139 ops/training.py:65 2019-01-17 07:32:37.835060: step 19505, loss = 0.31204 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:32:39.124183 ops/training.py:65 2019-01-17 07:32:39.124102: step 19506, loss = 0.19159 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:32:40.407978 ops/training.py:65 2019-01-17 07:32:40.407912: step 19507, loss = 0.21678 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:32:41.688128 ops/training.py:65 2019-01-17 07:32:41.688029: step 19508, loss = 0.24924 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:32:42.967208 ops/training.py:65 2019-01-17 07:32:42.967100: step 19509, loss = 0.25679 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:32:44.256389 ops/training.py:65 2019-01-17 07:32:44.256299: step 19510, loss = 0.24743 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:32:45.545667 ops/training.py:65 2019-01-17 07:32:45.545564: step 19511, loss = 0.27522 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:32:46.836184 ops/training.py:65 2019-01-17 07:32:46.836110: step 19512, loss = 0.21182 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:32:48.123582 ops/training.py:65 2019-01-17 07:32:48.123511: step 19513, loss = 0.28850 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:32:49.410021 ops/training.py:65 2019-01-17 07:32:49.409939: step 19514, loss = 0.21473 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:32:50.694896 ops/training.py:65 2019-01-17 07:32:50.694832: step 19515, loss = 0.22588 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:32:51.978747 ops/training.py:65 2019-01-17 07:32:51.978654: step 19516, loss = 0.26381 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:32:53.270253 ops/training.py:65 2019-01-17 07:32:53.270157: step 19517, loss = 0.22846 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:32:54.557162 ops/training.py:65 2019-01-17 07:32:54.557087: step 19518, loss = 0.20474 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:32:55.841365 ops/training.py:65 2019-01-17 07:32:55.841266: step 19519, loss = 0.23010 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:32:57.132319 ops/training.py:65 2019-01-17 07:32:57.132164: step 19520, loss = 0.19429 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:32:58.424055 ops/training.py:65 2019-01-17 07:32:58.423978: step 19521, loss = 0.27077 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:32:59.713194 ops/training.py:65 2019-01-17 07:32:59.713119: step 19522, loss = 0.22235 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:33:01.002366 ops/training.py:65 2019-01-17 07:33:01.002292: step 19523, loss = 0.22038 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:33:02.286322 ops/training.py:65 2019-01-17 07:33:02.286251: step 19524, loss = 0.23639 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:33:03.569176 ops/training.py:65 2019-01-17 07:33:03.569081: step 19525, loss = 0.18504 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:33:04.859957 ops/training.py:65 2019-01-17 07:33:04.859861: step 19526, loss = 0.25204 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:33:06.146051 ops/training.py:65 2019-01-17 07:33:06.145986: step 19527, loss = 0.22111 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:33:07.430694 ops/training.py:65 2019-01-17 07:33:07.430591: step 19528, loss = 0.24390 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:33:08.715274 ops/training.py:65 2019-01-17 07:33:08.715179: step 19529, loss = 0.22713 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:33:10.006615 ops/training.py:65 2019-01-17 07:33:10.006468: step 19530, loss = 0.27774 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:33:11.297751 ops/training.py:65 2019-01-17 07:33:11.297669: step 19531, loss = 0.23437 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:33:12.586135 ops/training.py:65 2019-01-17 07:33:12.586057: step 19532, loss = 0.22717 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:33:13.870672 ops/training.py:65 2019-01-17 07:33:13.870605: step 19533, loss = 0.22668 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:33:15.154699 ops/training.py:65 2019-01-17 07:33:15.154635: step 19534, loss = 0.24634 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:33:16.437033 ops/training.py:65 2019-01-17 07:33:16.436963: step 19535, loss = 0.23913 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:33:17.721606 ops/training.py:65 2019-01-17 07:33:17.721544: step 19536, loss = 0.21195 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:33:19.007736 ops/training.py:65 2019-01-17 07:33:19.007644: step 19537, loss = 0.22508 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:33:20.297537 ops/training.py:65 2019-01-17 07:33:20.297437: step 19538, loss = 0.22551 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:33:21.582007 ops/training.py:65 2019-01-17 07:33:21.581937: step 19539, loss = 0.22608 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:33:22.869891 ops/training.py:65 2019-01-17 07:33:22.869795: step 19540, loss = 0.19549 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:33:24.154109 ops/training.py:65 2019-01-17 07:33:24.154039: step 19541, loss = 0.23160 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:33:25.442023 ops/training.py:65 2019-01-17 07:33:25.441923: step 19542, loss = 0.24046 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:33:26.727444 ops/training.py:65 2019-01-17 07:33:26.727372: step 19543, loss = 0.26905 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:33:28.012489 ops/training.py:65 2019-01-17 07:33:28.012383: step 19544, loss = 0.23857 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:33:29.290797 ops/training.py:65 2019-01-17 07:33:29.290699: step 19545, loss = 0.17388 (25.1 examples/sec; 1.277 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:33:30.575138 ops/training.py:65 2019-01-17 07:33:30.575038: step 19546, loss = 0.19520 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:33:31.864364 ops/training.py:65 2019-01-17 07:33:31.864264: step 19547, loss = 0.23282 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:33:33.150528 ops/training.py:65 2019-01-17 07:33:33.150459: step 19548, loss = 0.19062 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:33:34.433100 ops/training.py:65 2019-01-17 07:33:34.433000: step 19549, loss = 0.22134 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:33:35.716731 ops/training.py:65 2019-01-17 07:33:35.716630: step 19550, loss = 0.21709 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:33:37.003836 ops/training.py:65 2019-01-17 07:33:37.003747: step 19551, loss = 0.24119 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:33:38.288307 ops/training.py:65 2019-01-17 07:33:38.288206: step 19552, loss = 0.24676 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:33:39.578332 ops/training.py:65 2019-01-17 07:33:39.578227: step 19553, loss = 0.22215 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:33:40.869207 ops/training.py:65 2019-01-17 07:33:40.869128: step 19554, loss = 0.19883 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:33:42.158179 ops/training.py:65 2019-01-17 07:33:42.158102: step 19555, loss = 0.31522 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:33:43.442037 ops/training.py:65 2019-01-17 07:33:43.441963: step 19556, loss = 0.26048 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:33:44.726332 ops/training.py:65 2019-01-17 07:33:44.726238: step 19557, loss = 0.21232 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:33:46.010373 ops/training.py:65 2019-01-17 07:33:46.010276: step 19558, loss = 0.23792 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:33:47.300654 ops/training.py:65 2019-01-17 07:33:47.300558: step 19559, loss = 0.23308 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:33:48.589488 ops/training.py:65 2019-01-17 07:33:48.589392: step 19560, loss = 0.21006 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:33:49.873674 ops/training.py:65 2019-01-17 07:33:49.873602: step 19561, loss = 0.18612 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:33:51.154105 ops/training.py:65 2019-01-17 07:33:51.154017: step 19562, loss = 0.24911 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:33:52.438368 ops/training.py:65 2019-01-17 07:33:52.438269: step 19563, loss = 0.25897 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:33:53.725130 ops/training.py:65 2019-01-17 07:33:53.725036: step 19564, loss = 0.21443 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:33:55.014444 ops/training.py:65 2019-01-17 07:33:55.014344: step 19565, loss = 0.21786 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:33:56.299230 ops/training.py:65 2019-01-17 07:33:56.299152: step 19566, loss = 0.21472 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:33:57.580065 ops/training.py:65 2019-01-17 07:33:57.579960: step 19567, loss = 0.23103 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:33:58.864804 ops/training.py:65 2019-01-17 07:33:58.864703: step 19568, loss = 0.22327 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:34:00.149579 ops/training.py:65 2019-01-17 07:34:00.149481: step 19569, loss = 0.22335 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:34:01.437753 ops/training.py:65 2019-01-17 07:34:01.437653: step 19570, loss = 0.27211 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:34:02.721947 ops/training.py:65 2019-01-17 07:34:02.721849: step 19571, loss = 0.20349 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:34:04.008581 ops/training.py:65 2019-01-17 07:34:04.008487: step 19572, loss = 0.23249 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:34:05.292938 ops/training.py:65 2019-01-17 07:34:05.292837: step 19573, loss = 0.18891 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:34:06.582385 ops/training.py:65 2019-01-17 07:34:06.582298: step 19574, loss = 0.24375 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:34:07.871379 ops/training.py:65 2019-01-17 07:34:07.871271: step 19575, loss = 0.24900 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:34:09.156911 ops/training.py:65 2019-01-17 07:34:09.156817: step 19576, loss = 0.22480 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:34:10.445459 ops/training.py:65 2019-01-17 07:34:10.445317: step 19577, loss = 0.20073 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:34:11.730272 ops/training.py:65 2019-01-17 07:34:11.730212: step 19578, loss = 0.27899 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:34:13.015362 ops/training.py:65 2019-01-17 07:34:13.015267: step 19579, loss = 0.26231 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:34:14.304456 ops/training.py:65 2019-01-17 07:34:14.304348: step 19580, loss = 0.24855 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:34:15.593515 ops/training.py:65 2019-01-17 07:34:15.593433: step 19581, loss = 0.24826 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:34:16.876711 ops/training.py:65 2019-01-17 07:34:16.876641: step 19582, loss = 0.20252 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:34:18.165723 ops/training.py:65 2019-01-17 07:34:18.165629: step 19583, loss = 0.25909 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:34:19.454634 ops/training.py:65 2019-01-17 07:34:19.454534: step 19584, loss = 0.27484 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:34:20.743467 ops/training.py:65 2019-01-17 07:34:20.743388: step 19585, loss = 0.22178 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:34:22.031573 ops/training.py:65 2019-01-17 07:34:22.031496: step 19586, loss = 0.27044 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:34:23.319504 ops/training.py:65 2019-01-17 07:34:23.319408: step 19587, loss = 0.22270 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:34:24.608125 ops/training.py:65 2019-01-17 07:34:24.608047: step 19588, loss = 0.20086 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:34:25.891241 ops/training.py:65 2019-01-17 07:34:25.891168: step 19589, loss = 0.26652 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:34:27.174507 ops/training.py:65 2019-01-17 07:34:27.174406: step 19590, loss = 0.26052 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:34:28.464084 ops/training.py:65 2019-01-17 07:34:28.463982: step 19591, loss = 0.21070 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:34:29.749883 ops/training.py:65 2019-01-17 07:34:29.749782: step 19592, loss = 0.24052 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:34:31.033839 ops/training.py:65 2019-01-17 07:34:31.033739: step 19593, loss = 0.23199 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:34:32.319872 ops/training.py:65 2019-01-17 07:34:32.319770: step 19594, loss = 0.20270 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:34:33.611821 ops/training.py:65 2019-01-17 07:34:33.611721: step 19595, loss = 0.16684 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:34:34.896083 ops/training.py:65 2019-01-17 07:34:34.896013: step 19596, loss = 0.22076 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:34:36.179414 ops/training.py:65 2019-01-17 07:34:36.179324: step 19597, loss = 0.24726 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:34:37.469480 ops/training.py:65 2019-01-17 07:34:37.469344: step 19598, loss = 0.19024 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:34:38.759124 ops/training.py:65 2019-01-17 07:34:38.759044: step 19599, loss = 0.22977 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:34:40.048039 ops/training.py:65 2019-01-17 07:34:40.047957: step 19600, loss = 0.26490 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:34:41.337019 ops/training.py:65 2019-01-17 07:34:41.336922: step 19601, loss = 0.19744 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:34:42.622913 ops/training.py:65 2019-01-17 07:34:42.622841: step 19602, loss = 0.22414 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:34:43.906671 ops/training.py:65 2019-01-17 07:34:43.906576: step 19603, loss = 0.21004 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:34:45.195422 ops/training.py:65 2019-01-17 07:34:45.195328: step 19604, loss = 0.27869 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:34:46.485751 ops/training.py:65 2019-01-17 07:34:46.485672: step 19605, loss = 0.21294 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:34:47.769955 ops/training.py:65 2019-01-17 07:34:47.769882: step 19606, loss = 0.20907 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:34:49.053265 ops/training.py:65 2019-01-17 07:34:49.053171: step 19607, loss = 0.22480 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:34:50.344259 ops/training.py:65 2019-01-17 07:34:50.344152: step 19608, loss = 0.19402 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:34:51.634514 ops/training.py:65 2019-01-17 07:34:51.634435: step 19609, loss = 0.24305 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:34:52.918566 ops/training.py:65 2019-01-17 07:34:52.918483: step 19610, loss = 0.21592 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:34:54.200286 ops/training.py:65 2019-01-17 07:34:54.200195: step 19611, loss = 0.18442 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:34:55.487435 ops/training.py:65 2019-01-17 07:34:55.487333: step 19612, loss = 0.27613 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:34:56.773574 ops/training.py:65 2019-01-17 07:34:56.773474: step 19613, loss = 0.25471 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:34:58.064471 ops/training.py:65 2019-01-17 07:34:58.064362: step 19614, loss = 0.19459 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:34:59.353092 ops/training.py:65 2019-01-17 07:34:59.353008: step 19615, loss = 0.19167 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:35:00.648936 ops/training.py:65 2019-01-17 07:35:00.648850: step 19616, loss = 0.23695 (24.7 examples/sec; 1.295 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:35:01.937467 ops/training.py:65 2019-01-17 07:35:01.937355: step 19617, loss = 0.20109 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:35:03.226136 ops/training.py:65 2019-01-17 07:35:03.226051: step 19618, loss = 0.26427 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:35:04.515081 ops/training.py:65 2019-01-17 07:35:04.515001: step 19619, loss = 0.21969 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:35:05.803482 ops/training.py:65 2019-01-17 07:35:05.803379: step 19620, loss = 0.24093 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:35:07.092404 ops/training.py:65 2019-01-17 07:35:07.092302: step 19621, loss = 0.24311 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:35:08.377023 ops/training.py:65 2019-01-17 07:35:08.376961: step 19622, loss = 0.19424 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:35:09.663536 ops/training.py:65 2019-01-17 07:35:09.663439: step 19623, loss = 0.21522 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:35:10.947510 ops/training.py:65 2019-01-17 07:35:10.947411: step 19624, loss = 0.25722 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:35:12.234034 ops/training.py:65 2019-01-17 07:35:12.233936: step 19625, loss = 0.24122 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:35:13.518446 ops/training.py:65 2019-01-17 07:35:13.518348: step 19626, loss = 0.31110 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:35:14.809310 ops/training.py:65 2019-01-17 07:35:14.809206: step 19627, loss = 0.21442 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:35:16.098867 ops/training.py:65 2019-01-17 07:35:16.098765: step 19628, loss = 0.23244 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:35:17.382728 ops/training.py:65 2019-01-17 07:35:17.382655: step 19629, loss = 0.22016 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:35:18.666353 ops/training.py:65 2019-01-17 07:35:18.666257: step 19630, loss = 0.23125 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:35:19.956160 ops/training.py:65 2019-01-17 07:35:19.956024: step 19631, loss = 0.20497 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:35:21.245427 ops/training.py:65 2019-01-17 07:35:21.245352: step 19632, loss = 0.24066 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:35:22.534327 ops/training.py:65 2019-01-17 07:35:22.534217: step 19633, loss = 0.24081 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:35:23.818195 ops/training.py:65 2019-01-17 07:35:23.818118: step 19634, loss = 0.30149 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.8125
I4672 2019-01-17 07:35:25.107224 ops/training.py:65 2019-01-17 07:35:25.107143: step 19635, loss = 0.21350 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:35:26.397008 ops/training.py:65 2019-01-17 07:35:26.396926: step 19636, loss = 0.22744 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:35:27.686047 ops/training.py:65 2019-01-17 07:35:27.685962: step 19637, loss = 0.18836 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:35:28.974040 ops/training.py:65 2019-01-17 07:35:28.973955: step 19638, loss = 0.21902 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:35:30.261339 ops/training.py:65 2019-01-17 07:35:30.261251: step 19639, loss = 0.22150 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:35:31.550762 ops/training.py:65 2019-01-17 07:35:31.550665: step 19640, loss = 0.21160 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:35:32.839114 ops/training.py:65 2019-01-17 07:35:32.839022: step 19641, loss = 0.25233 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:35:34.127612 ops/training.py:65 2019-01-17 07:35:34.127524: step 19642, loss = 0.22843 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:35:35.407569 ops/training.py:65 2019-01-17 07:35:35.407485: step 19643, loss = 0.20429 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:35:36.690025 ops/training.py:65 2019-01-17 07:35:36.689924: step 19644, loss = 0.26403 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:35:37.976174 ops/training.py:65 2019-01-17 07:35:37.976068: step 19645, loss = 0.21281 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:35:39.260378 ops/training.py:65 2019-01-17 07:35:39.260270: step 19646, loss = 0.19873 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:35:40.552026 ops/training.py:65 2019-01-17 07:35:40.551924: step 19647, loss = 0.21490 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:35:41.837864 ops/training.py:65 2019-01-17 07:35:41.837760: step 19648, loss = 0.17933 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:35:43.123334 ops/training.py:65 2019-01-17 07:35:43.123235: step 19649, loss = 0.23158 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:35:44.412722 ops/training.py:65 2019-01-17 07:35:44.412619: step 19650, loss = 0.20246 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:35:45.697931 ops/training.py:65 2019-01-17 07:35:45.697823: step 19651, loss = 0.23214 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:35:46.986583 ops/training.py:65 2019-01-17 07:35:46.986489: step 19652, loss = 0.23867 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:35:48.275125 ops/training.py:65 2019-01-17 07:35:48.275019: step 19653, loss = 0.18967 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:35:49.563765 ops/training.py:65 2019-01-17 07:35:49.563676: step 19654, loss = 0.24641 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:35:50.852896 ops/training.py:65 2019-01-17 07:35:50.852810: step 19655, loss = 0.21203 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:35:52.137202 ops/training.py:65 2019-01-17 07:35:52.137128: step 19656, loss = 0.20781 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:35:53.421378 ops/training.py:65 2019-01-17 07:35:53.421285: step 19657, loss = 0.24378 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:35:54.704377 ops/training.py:65 2019-01-17 07:35:54.704275: step 19658, loss = 0.23983 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:35:55.994906 ops/training.py:65 2019-01-17 07:35:55.994805: step 19659, loss = 0.22807 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:35:57.278790 ops/training.py:65 2019-01-17 07:35:57.278689: step 19660, loss = 0.25149 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:35:58.568577 ops/training.py:65 2019-01-17 07:35:58.568477: step 19661, loss = 0.24548 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:35:59.853140 ops/training.py:65 2019-01-17 07:35:59.853043: step 19662, loss = 0.23846 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:36:01.134997 ops/training.py:65 2019-01-17 07:36:01.134855: step 19663, loss = 0.20220 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:36:02.421609 ops/training.py:65 2019-01-17 07:36:02.421513: step 19664, loss = 0.27768 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:36:03.707082 ops/training.py:65 2019-01-17 07:36:03.706984: step 19665, loss = 0.30645 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:36:04.992044 ops/training.py:65 2019-01-17 07:36:04.991940: step 19666, loss = 0.30535 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:36:06.283106 ops/training.py:65 2019-01-17 07:36:06.283012: step 19667, loss = 0.22549 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:36:07.568105 ops/training.py:65 2019-01-17 07:36:07.568002: step 19668, loss = 0.29629 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:36:08.856504 ops/training.py:65 2019-01-17 07:36:08.856411: step 19669, loss = 0.38661 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.84375
I4672 2019-01-17 07:36:10.152930 ops/training.py:65 2019-01-17 07:36:10.152832: step 19670, loss = 0.30299 (24.7 examples/sec; 1.295 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:36:11.437555 ops/training.py:65 2019-01-17 07:36:11.437471: step 19671, loss = 0.33185 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:36:12.727470 ops/training.py:65 2019-01-17 07:36:12.727363: step 19672, loss = 0.25258 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:36:14.020262 ops/training.py:65 2019-01-17 07:36:14.020163: step 19673, loss = 0.23354 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:36:15.308695 ops/training.py:65 2019-01-17 07:36:15.308602: step 19674, loss = 0.19761 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:36:16.592532 ops/training.py:65 2019-01-17 07:36:16.592449: step 19675, loss = 0.19051 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:36:17.877185 ops/training.py:65 2019-01-17 07:36:17.877090: step 19676, loss = 0.22466 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:36:19.162358 ops/training.py:65 2019-01-17 07:36:19.162274: step 19677, loss = 0.24791 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:36:20.449787 ops/training.py:65 2019-01-17 07:36:20.449700: step 19678, loss = 0.23672 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:36:21.737022 ops/training.py:65 2019-01-17 07:36:21.736985: step 19679, loss = 0.26431 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:36:23.025072 ops/training.py:65 2019-01-17 07:36:23.024976: step 19680, loss = 0.24029 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:36:24.314230 ops/training.py:65 2019-01-17 07:36:24.314148: step 19681, loss = 0.24061 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:36:25.599038 ops/training.py:65 2019-01-17 07:36:25.598953: step 19682, loss = 0.18828 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:36:26.882122 ops/training.py:65 2019-01-17 07:36:26.882028: step 19683, loss = 0.26051 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:36:28.173200 ops/training.py:65 2019-01-17 07:36:28.173094: step 19684, loss = 0.28221 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:36:29.459647 ops/training.py:65 2019-01-17 07:36:29.459559: step 19685, loss = 0.26663 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:36:30.746734 ops/training.py:65 2019-01-17 07:36:30.746650: step 19686, loss = 0.23518 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:36:32.031046 ops/training.py:65 2019-01-17 07:36:32.030960: step 19687, loss = 0.26926 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:36:33.314654 ops/training.py:65 2019-01-17 07:36:33.314557: step 19688, loss = 0.22561 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:36:34.600681 ops/training.py:65 2019-01-17 07:36:34.600573: step 19689, loss = 0.20105 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:36:35.880897 ops/training.py:65 2019-01-17 07:36:35.880808: step 19690, loss = 0.20510 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:36:37.171747 ops/training.py:65 2019-01-17 07:36:37.171664: step 19691, loss = 0.19464 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:36:38.459676 ops/training.py:65 2019-01-17 07:36:38.459575: step 19692, loss = 0.24730 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:36:39.748939 ops/training.py:65 2019-01-17 07:36:39.748879: step 19693, loss = 0.19760 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:36:41.036006 ops/training.py:65 2019-01-17 07:36:41.035921: step 19694, loss = 0.22260 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:36:42.323742 ops/training.py:65 2019-01-17 07:36:42.323648: step 19695, loss = 0.24818 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:36:43.609947 ops/training.py:65 2019-01-17 07:36:43.609863: step 19696, loss = 0.24430 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:36:44.897338 ops/training.py:65 2019-01-17 07:36:44.897256: step 19697, loss = 0.25256 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:36:46.185284 ops/training.py:65 2019-01-17 07:36:46.185202: step 19698, loss = 0.21126 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:36:47.472801 ops/training.py:65 2019-01-17 07:36:47.472721: step 19699, loss = 0.24827 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:36:48.755611 ops/training.py:65 2019-01-17 07:36:48.755539: step 19700, loss = 0.24732 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:36:50.039659 ops/training.py:65 2019-01-17 07:36:50.039560: step 19701, loss = 0.26621 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:36:51.330963 ops/training.py:65 2019-01-17 07:36:51.330874: step 19702, loss = 0.21877 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:36:52.616200 ops/training.py:65 2019-01-17 07:36:52.616131: step 19703, loss = 0.23758 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:36:53.906378 ops/training.py:65 2019-01-17 07:36:53.906277: step 19704, loss = 0.26565 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:36:55.192153 ops/training.py:65 2019-01-17 07:36:55.192049: step 19705, loss = 0.25378 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:36:56.475538 ops/training.py:65 2019-01-17 07:36:56.475436: step 19706, loss = 0.18892 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:36:57.762347 ops/training.py:65 2019-01-17 07:36:57.762242: step 19707, loss = 0.21479 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:36:59.047897 ops/training.py:65 2019-01-17 07:36:59.047791: step 19708, loss = 0.26710 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:37:00.333295 ops/training.py:65 2019-01-17 07:37:00.333193: step 19709, loss = 0.23561 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:37:01.623322 ops/training.py:65 2019-01-17 07:37:01.623217: step 19710, loss = 0.18120 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:37:02.903366 ops/training.py:65 2019-01-17 07:37:02.903305: step 19711, loss = 0.21068 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:37:04.190375 ops/training.py:65 2019-01-17 07:37:04.190263: step 19712, loss = 0.21718 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:37:05.473828 ops/training.py:65 2019-01-17 07:37:05.473716: step 19713, loss = 0.20951 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:37:06.764472 ops/training.py:65 2019-01-17 07:37:06.764373: step 19714, loss = 0.25154 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:37:08.050308 ops/training.py:65 2019-01-17 07:37:08.050223: step 19715, loss = 0.32975 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:37:09.338623 ops/training.py:65 2019-01-17 07:37:09.338519: step 19716, loss = 0.23482 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:37:10.623198 ops/training.py:65 2019-01-17 07:37:10.623094: step 19717, loss = 0.23031 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:37:11.912670 ops/training.py:65 2019-01-17 07:37:11.912560: step 19718, loss = 0.21058 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:37:13.201661 ops/training.py:65 2019-01-17 07:37:13.201578: step 19719, loss = 0.25465 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:37:14.490230 ops/training.py:65 2019-01-17 07:37:14.490130: step 19720, loss = 0.26621 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:37:15.779089 ops/training.py:65 2019-01-17 07:37:15.779006: step 19721, loss = 0.25005 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:37:17.063387 ops/training.py:65 2019-01-17 07:37:17.063310: step 19722, loss = 0.20714 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:37:18.348084 ops/training.py:65 2019-01-17 07:37:18.347980: step 19723, loss = 0.18466 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:37:19.638870 ops/training.py:65 2019-01-17 07:37:19.638738: step 19724, loss = 0.24279 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:37:20.930819 ops/training.py:65 2019-01-17 07:37:20.930733: step 19725, loss = 0.19895 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:37:22.215025 ops/training.py:65 2019-01-17 07:37:22.214951: step 19726, loss = 0.18705 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:37:23.499123 ops/training.py:65 2019-01-17 07:37:23.499027: step 19727, loss = 0.21446 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:37:24.790127 ops/training.py:65 2019-01-17 07:37:24.790017: step 19728, loss = 0.21250 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:37:26.076915 ops/training.py:65 2019-01-17 07:37:26.076777: step 19729, loss = 0.23618 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:37:27.360658 ops/training.py:65 2019-01-17 07:37:27.360550: step 19730, loss = 0.22652 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:37:28.651979 ops/training.py:65 2019-01-17 07:37:28.651872: step 19731, loss = 0.23261 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:37:29.942011 ops/training.py:65 2019-01-17 07:37:29.941915: step 19732, loss = 0.22127 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:37:31.226145 ops/training.py:65 2019-01-17 07:37:31.226065: step 19733, loss = 0.17881 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:37:32.514767 ops/training.py:65 2019-01-17 07:37:32.514664: step 19734, loss = 0.22501 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:37:33.804103 ops/training.py:65 2019-01-17 07:37:33.804016: step 19735, loss = 0.17955 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:37:35.092498 ops/training.py:65 2019-01-17 07:37:35.092384: step 19736, loss = 0.25571 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:37:36.376815 ops/training.py:65 2019-01-17 07:37:36.376721: step 19737, loss = 0.23522 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:37:37.661215 ops/training.py:65 2019-01-17 07:37:37.661104: step 19738, loss = 0.30288 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:37:38.949088 ops/training.py:65 2019-01-17 07:37:38.949003: step 19739, loss = 0.26013 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:37:40.236687 ops/training.py:65 2019-01-17 07:37:40.236602: step 19740, loss = 0.22516 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:37:41.526178 ops/training.py:65 2019-01-17 07:37:41.526088: step 19741, loss = 0.22048 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:37:42.813567 ops/training.py:65 2019-01-17 07:37:42.813457: step 19742, loss = 0.18625 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:37:44.102497 ops/training.py:65 2019-01-17 07:37:44.102378: step 19743, loss = 0.19005 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:37:45.391499 ops/training.py:65 2019-01-17 07:37:45.391413: step 19744, loss = 0.26275 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:37:46.679982 ops/training.py:65 2019-01-17 07:37:46.679883: step 19745, loss = 0.25933 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:37:47.967778 ops/training.py:65 2019-01-17 07:37:47.967693: step 19746, loss = 0.28371 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:37:49.256256 ops/training.py:65 2019-01-17 07:37:49.256177: step 19747, loss = 0.20336 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:37:50.545244 ops/training.py:65 2019-01-17 07:37:50.545157: step 19748, loss = 0.24745 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:37:51.833161 ops/training.py:65 2019-01-17 07:37:51.833072: step 19749, loss = 0.21892 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:37:53.118032 ops/training.py:65 2019-01-17 07:37:53.117938: step 19750, loss = 0.20636 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:37:54.406123 ops/training.py:65 2019-01-17 07:37:54.406026: step 19751, loss = 0.19552 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:37:55.694422 ops/training.py:65 2019-01-17 07:37:55.694321: step 19752, loss = 0.25481 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:37:56.983172 ops/training.py:65 2019-01-17 07:37:56.983077: step 19753, loss = 0.23064 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:37:58.268930 ops/training.py:65 2019-01-17 07:37:58.268856: step 19754, loss = 0.25067 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:37:59.557717 ops/training.py:65 2019-01-17 07:37:59.557609: step 19755, loss = 0.19462 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:38:00.843083 ops/training.py:65 2019-01-17 07:38:00.842975: step 19756, loss = 0.24415 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:38:02.131577 ops/training.py:65 2019-01-17 07:38:02.131476: step 19757, loss = 0.22677 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:38:03.419470 ops/training.py:65 2019-01-17 07:38:03.419369: step 19758, loss = 0.20870 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:38:04.704440 ops/training.py:65 2019-01-17 07:38:04.704340: step 19759, loss = 0.21871 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:38:05.988188 ops/training.py:65 2019-01-17 07:38:05.988082: step 19760, loss = 0.21535 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:38:07.277023 ops/training.py:65 2019-01-17 07:38:07.276925: step 19761, loss = 0.19444 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:38:08.567068 ops/training.py:65 2019-01-17 07:38:08.566960: step 19762, loss = 0.29324 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:38:09.855768 ops/training.py:65 2019-01-17 07:38:09.855672: step 19763, loss = 0.22623 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:38:11.144191 ops/training.py:65 2019-01-17 07:38:11.144088: step 19764, loss = 0.25648 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:38:12.431323 ops/training.py:65 2019-01-17 07:38:12.431238: step 19765, loss = 0.17256 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:38:13.719111 ops/training.py:65 2019-01-17 07:38:13.719031: step 19766, loss = 0.19763 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:38:15.007307 ops/training.py:65 2019-01-17 07:38:15.007227: step 19767, loss = 0.24667 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:38:16.295635 ops/training.py:65 2019-01-17 07:38:16.295553: step 19768, loss = 0.19802 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:38:17.580248 ops/training.py:65 2019-01-17 07:38:17.580166: step 19769, loss = 0.20362 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:38:18.859496 ops/training.py:65 2019-01-17 07:38:18.859428: step 19770, loss = 0.22759 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:38:20.146558 ops/training.py:65 2019-01-17 07:38:20.146456: step 19771, loss = 0.20989 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:38:21.434664 ops/training.py:65 2019-01-17 07:38:21.434580: step 19772, loss = 0.25493 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:38:22.723393 ops/training.py:65 2019-01-17 07:38:22.723312: step 19773, loss = 0.19015 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:38:24.013452 ops/training.py:65 2019-01-17 07:38:24.013367: step 19774, loss = 0.28693 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:38:25.296872 ops/training.py:65 2019-01-17 07:38:25.296784: step 19775, loss = 0.19398 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:38:26.580155 ops/training.py:65 2019-01-17 07:38:26.580091: step 19776, loss = 0.21698 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:38:27.866923 ops/training.py:65 2019-01-17 07:38:27.866813: step 19777, loss = 0.25586 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:38:29.146886 ops/training.py:65 2019-01-17 07:38:29.146781: step 19778, loss = 0.19365 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:38:30.436892 ops/training.py:65 2019-01-17 07:38:30.436782: step 19779, loss = 0.19170 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:38:31.726709 ops/training.py:65 2019-01-17 07:38:31.726629: step 19780, loss = 0.23379 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:38:33.015584 ops/training.py:65 2019-01-17 07:38:33.015503: step 19781, loss = 0.26983 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:38:34.304257 ops/training.py:65 2019-01-17 07:38:34.304174: step 19782, loss = 0.23497 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:38:35.593948 ops/training.py:65 2019-01-17 07:38:35.593863: step 19783, loss = 0.24445 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:38:36.878908 ops/training.py:65 2019-01-17 07:38:36.878837: step 19784, loss = 0.21245 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:38:38.162084 ops/training.py:65 2019-01-17 07:38:38.161983: step 19785, loss = 0.25689 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:38:39.448025 ops/training.py:65 2019-01-17 07:38:39.447917: step 19786, loss = 0.23027 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:38:40.737834 ops/training.py:65 2019-01-17 07:38:40.737729: step 19787, loss = 0.24932 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:38:42.027212 ops/training.py:65 2019-01-17 07:38:42.027140: step 19788, loss = 0.23761 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:38:43.308295 ops/training.py:65 2019-01-17 07:38:43.308236: step 19789, loss = 0.20623 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:38:44.591300 ops/training.py:65 2019-01-17 07:38:44.591200: step 19790, loss = 0.26764 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:38:45.881822 ops/training.py:65 2019-01-17 07:38:45.881726: step 19791, loss = 0.20482 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:38:47.170345 ops/training.py:65 2019-01-17 07:38:47.170268: step 19792, loss = 0.20301 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:38:48.453622 ops/training.py:65 2019-01-17 07:38:48.453523: step 19793, loss = 0.27737 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:38:49.739412 ops/training.py:65 2019-01-17 07:38:49.739308: step 19794, loss = 0.31010 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:38:51.025576 ops/training.py:65 2019-01-17 07:38:51.025467: step 19795, loss = 0.24353 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:38:52.314937 ops/training.py:65 2019-01-17 07:38:52.314859: step 19796, loss = 0.21568 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:38:53.604111 ops/training.py:65 2019-01-17 07:38:53.604031: step 19797, loss = 0.19178 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:38:54.888754 ops/training.py:65 2019-01-17 07:38:54.888685: step 19798, loss = 0.20641 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:38:56.172896 ops/training.py:65 2019-01-17 07:38:56.172793: step 19799, loss = 0.15669 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:38:57.463600 ops/training.py:65 2019-01-17 07:38:57.463500: step 19800, loss = 0.20941 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:38:58.749764 ops/training.py:65 2019-01-17 07:38:58.749699: step 19801, loss = 0.24417 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:39:00.033264 ops/training.py:65 2019-01-17 07:39:00.033162: step 19802, loss = 0.23370 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:39:01.320042 ops/training.py:65 2019-01-17 07:39:01.319929: step 19803, loss = 0.19438 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:39:02.604048 ops/training.py:65 2019-01-17 07:39:02.603947: step 19804, loss = 0.23827 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:39:03.891165 ops/training.py:65 2019-01-17 07:39:03.891065: step 19805, loss = 0.23383 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:39:05.183192 ops/training.py:65 2019-01-17 07:39:05.183089: step 19806, loss = 0.24716 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:39:06.471706 ops/training.py:65 2019-01-17 07:39:06.471649: step 19807, loss = 0.25983 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:39:07.756505 ops/training.py:65 2019-01-17 07:39:07.756412: step 19808, loss = 0.25728 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:39:09.040715 ops/training.py:65 2019-01-17 07:39:09.040605: step 19809, loss = 0.24601 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:39:10.325632 ops/training.py:65 2019-01-17 07:39:10.325527: step 19810, loss = 0.21440 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:39:11.612103 ops/training.py:65 2019-01-17 07:39:11.611993: step 19811, loss = 0.29877 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:39:12.892959 ops/training.py:65 2019-01-17 07:39:12.892857: step 19812, loss = 0.22675 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:39:14.176164 ops/training.py:65 2019-01-17 07:39:14.176057: step 19813, loss = 0.23931 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:39:15.460477 ops/training.py:65 2019-01-17 07:39:15.460374: step 19814, loss = 0.20911 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:39:16.745555 ops/training.py:65 2019-01-17 07:39:16.745450: step 19815, loss = 0.25822 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:39:18.030175 ops/training.py:65 2019-01-17 07:39:18.030075: step 19816, loss = 0.23215 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:39:19.318160 ops/training.py:65 2019-01-17 07:39:19.318046: step 19817, loss = 0.18029 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:39:20.602470 ops/training.py:65 2019-01-17 07:39:20.602372: step 19818, loss = 0.17959 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:39:21.893319 ops/training.py:65 2019-01-17 07:39:21.893232: step 19819, loss = 0.23188 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:39:23.183016 ops/training.py:65 2019-01-17 07:39:23.182928: step 19820, loss = 0.20339 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:39:24.473139 ops/training.py:65 2019-01-17 07:39:24.473061: step 19821, loss = 0.19992 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:39:25.758214 ops/training.py:65 2019-01-17 07:39:25.758142: step 19822, loss = 0.18920 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:39:27.042699 ops/training.py:65 2019-01-17 07:39:27.042591: step 19823, loss = 0.22966 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:39:28.328801 ops/training.py:65 2019-01-17 07:39:28.328695: step 19824, loss = 0.20741 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:39:29.619801 ops/training.py:65 2019-01-17 07:39:29.619694: step 19825, loss = 0.23194 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:39:30.905851 ops/training.py:65 2019-01-17 07:39:30.905779: step 19826, loss = 0.21001 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:39:32.189521 ops/training.py:65 2019-01-17 07:39:32.189454: step 19827, loss = 0.20993 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:39:33.480308 ops/training.py:65 2019-01-17 07:39:33.480203: step 19828, loss = 0.23940 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:39:34.769642 ops/training.py:65 2019-01-17 07:39:34.769563: step 19829, loss = 0.23939 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:39:36.058123 ops/training.py:65 2019-01-17 07:39:36.058042: step 19830, loss = 0.17081 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:39:37.345615 ops/training.py:65 2019-01-17 07:39:37.345544: step 19831, loss = 0.21475 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:39:38.635561 ops/training.py:65 2019-01-17 07:39:38.635473: step 19832, loss = 0.19257 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:39:39.923541 ops/training.py:65 2019-01-17 07:39:39.923471: step 19833, loss = 0.19462 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:39:41.211980 ops/training.py:65 2019-01-17 07:39:41.211877: step 19834, loss = 0.22147 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:39:42.495335 ops/training.py:65 2019-01-17 07:39:42.495250: step 19835, loss = 0.25728 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:39:43.779272 ops/training.py:65 2019-01-17 07:39:43.779193: step 19836, loss = 0.20221 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:39:45.069435 ops/training.py:65 2019-01-17 07:39:45.069347: step 19837, loss = 0.19676 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:39:46.353117 ops/training.py:65 2019-01-17 07:39:46.353042: step 19838, loss = 0.19730 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:39:47.636964 ops/training.py:65 2019-01-17 07:39:47.636852: step 19839, loss = 0.28340 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:39:48.927214 ops/training.py:65 2019-01-17 07:39:48.927115: step 19840, loss = 0.17403 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:39:50.222132 ops/training.py:65 2019-01-17 07:39:50.222031: step 19841, loss = 0.32721 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:39:51.511313 ops/training.py:65 2019-01-17 07:39:51.511232: step 19842, loss = 0.20623 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:39:52.800748 ops/training.py:65 2019-01-17 07:39:52.800673: step 19843, loss = 0.22996 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:39:54.084590 ops/training.py:65 2019-01-17 07:39:54.084518: step 19844, loss = 0.25840 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:39:55.368035 ops/training.py:65 2019-01-17 07:39:55.367966: step 19845, loss = 0.23577 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:39:56.654486 ops/training.py:65 2019-01-17 07:39:56.654414: step 19846, loss = 0.21560 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:39:57.937979 ops/training.py:65 2019-01-17 07:39:57.937892: step 19847, loss = 0.28828 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:39:59.223175 ops/training.py:65 2019-01-17 07:39:59.223098: step 19848, loss = 0.25039 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:40:00.506629 ops/training.py:65 2019-01-17 07:40:00.506529: step 19849, loss = 0.22695 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:40:01.793015 ops/training.py:65 2019-01-17 07:40:01.792926: step 19850, loss = 0.21685 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:40:03.072819 ops/training.py:65 2019-01-17 07:40:03.072730: step 19851, loss = 0.22056 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:40:04.350200 ops/training.py:65 2019-01-17 07:40:04.350090: step 19852, loss = 0.17349 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:40:05.634011 ops/training.py:65 2019-01-17 07:40:05.633910: step 19853, loss = 0.20075 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:40:06.917820 ops/training.py:65 2019-01-17 07:40:06.917726: step 19854, loss = 0.22441 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:40:08.203347 ops/training.py:65 2019-01-17 07:40:08.203245: step 19855, loss = 0.22183 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:40:09.492056 ops/training.py:65 2019-01-17 07:40:09.491954: step 19856, loss = 0.19154 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:40:10.780916 ops/training.py:65 2019-01-17 07:40:10.780818: step 19857, loss = 0.24584 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:40:12.070450 ops/training.py:65 2019-01-17 07:40:12.070353: step 19858, loss = 0.18896 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:40:13.358499 ops/training.py:65 2019-01-17 07:40:13.358411: step 19859, loss = 0.28221 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:40:14.643404 ops/training.py:65 2019-01-17 07:40:14.643326: step 19860, loss = 0.19469 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:40:15.926998 ops/training.py:65 2019-01-17 07:40:15.926896: step 19861, loss = 0.20575 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:40:17.212262 ops/training.py:65 2019-01-17 07:40:17.212155: step 19862, loss = 0.19570 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:40:18.501795 ops/training.py:65 2019-01-17 07:40:18.501689: step 19863, loss = 0.24716 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:40:19.786815 ops/training.py:65 2019-01-17 07:40:19.786732: step 19864, loss = 0.22732 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:40:21.071157 ops/training.py:65 2019-01-17 07:40:21.071055: step 19865, loss = 0.22170 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:40:22.361586 ops/training.py:65 2019-01-17 07:40:22.361496: step 19866, loss = 0.24548 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:40:23.650432 ops/training.py:65 2019-01-17 07:40:23.650324: step 19867, loss = 0.23365 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:40:24.935555 ops/training.py:65 2019-01-17 07:40:24.935481: step 19868, loss = 0.23975 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:40:26.223119 ops/training.py:65 2019-01-17 07:40:26.223014: step 19869, loss = 0.20995 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:40:27.508339 ops/training.py:65 2019-01-17 07:40:27.508247: step 19870, loss = 0.25037 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:40:28.797271 ops/training.py:65 2019-01-17 07:40:28.797192: step 19871, loss = 0.20281 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:40:30.086608 ops/training.py:65 2019-01-17 07:40:30.086527: step 19872, loss = 0.15452 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:40:31.369987 ops/training.py:65 2019-01-17 07:40:31.369916: step 19873, loss = 0.23239 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:40:32.654031 ops/training.py:65 2019-01-17 07:40:32.653926: step 19874, loss = 0.22657 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:40:33.945375 ops/training.py:65 2019-01-17 07:40:33.945273: step 19875, loss = 0.20763 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:40:35.235085 ops/training.py:65 2019-01-17 07:40:35.235003: step 19876, loss = 0.21616 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:40:36.523183 ops/training.py:65 2019-01-17 07:40:36.523108: step 19877, loss = 0.24231 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:40:37.811104 ops/training.py:65 2019-01-17 07:40:37.811039: step 19878, loss = 0.21296 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:40:39.094884 ops/training.py:65 2019-01-17 07:40:39.094808: step 19879, loss = 0.29190 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:40:40.383382 ops/training.py:65 2019-01-17 07:40:40.383303: step 19880, loss = 0.24957 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:40:41.667267 ops/training.py:65 2019-01-17 07:40:41.667194: step 19881, loss = 0.24897 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:40:42.955528 ops/training.py:65 2019-01-17 07:40:42.955446: step 19882, loss = 0.24426 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:40:44.238649 ops/training.py:65 2019-01-17 07:40:44.238579: step 19883, loss = 0.24350 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:40:45.526074 ops/training.py:65 2019-01-17 07:40:45.525968: step 19884, loss = 0.21434 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:40:46.814924 ops/training.py:65 2019-01-17 07:40:46.814820: step 19885, loss = 0.22400 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:40:48.103811 ops/training.py:65 2019-01-17 07:40:48.103729: step 19886, loss = 0.20800 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:40:49.393352 ops/training.py:65 2019-01-17 07:40:49.393270: step 19887, loss = 0.21538 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:40:50.682313 ops/training.py:65 2019-01-17 07:40:50.682232: step 19888, loss = 0.23151 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:40:51.970310 ops/training.py:65 2019-01-17 07:40:51.970233: step 19889, loss = 0.23930 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:40:53.254063 ops/training.py:65 2019-01-17 07:40:53.253997: step 19890, loss = 0.22874 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:40:54.542158 ops/training.py:65 2019-01-17 07:40:54.542060: step 19891, loss = 0.24010 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:40:55.826383 ops/training.py:65 2019-01-17 07:40:55.826312: step 19892, loss = 0.22561 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:40:57.103846 ops/training.py:65 2019-01-17 07:40:57.103738: step 19893, loss = 0.23511 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:40:58.387567 ops/training.py:65 2019-01-17 07:40:58.387460: step 19894, loss = 0.21013 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:40:59.674056 ops/training.py:65 2019-01-17 07:40:59.673954: step 19895, loss = 0.23309 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:41:00.953977 ops/training.py:65 2019-01-17 07:41:00.953865: step 19896, loss = 0.23920 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:41:02.242123 ops/training.py:65 2019-01-17 07:41:02.242021: step 19897, loss = 0.19547 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:41:03.530510 ops/training.py:65 2019-01-17 07:41:03.530408: step 19898, loss = 0.23755 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:41:04.820264 ops/training.py:65 2019-01-17 07:41:04.820157: step 19899, loss = 0.19608 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:41:06.110493 ops/training.py:65 2019-01-17 07:41:06.110406: step 19900, loss = 0.18657 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:41:07.395498 ops/training.py:65 2019-01-17 07:41:07.395428: step 19901, loss = 0.31295 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:41:08.686145 ops/training.py:65 2019-01-17 07:41:08.686035: step 19902, loss = 0.18391 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:41:09.971006 ops/training.py:65 2019-01-17 07:41:09.970910: step 19903, loss = 0.19122 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:41:11.268023 ops/training.py:65 2019-01-17 07:41:11.267927: step 19904, loss = 0.22921 (24.7 examples/sec; 1.296 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:41:12.557406 ops/training.py:65 2019-01-17 07:41:12.557328: step 19905, loss = 0.26865 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:41:13.840827 ops/training.py:65 2019-01-17 07:41:13.840751: step 19906, loss = 0.19457 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:41:15.120609 ops/training.py:65 2019-01-17 07:41:15.120503: step 19907, loss = 0.26964 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:41:16.406499 ops/training.py:65 2019-01-17 07:41:16.406401: step 19908, loss = 0.18637 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:41:17.691454 ops/training.py:65 2019-01-17 07:41:17.691312: step 19909, loss = 0.25917 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:41:18.980826 ops/training.py:65 2019-01-17 07:41:18.980732: step 19910, loss = 0.18392 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:41:20.267507 ops/training.py:65 2019-01-17 07:41:20.267432: step 19911, loss = 0.22649 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:41:21.555615 ops/training.py:65 2019-01-17 07:41:21.555507: step 19912, loss = 0.26173 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:41:22.844774 ops/training.py:65 2019-01-17 07:41:22.844696: step 19913, loss = 0.25144 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:41:24.131054 ops/training.py:65 2019-01-17 07:41:24.130978: step 19914, loss = 0.28936 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:41:25.415697 ops/training.py:65 2019-01-17 07:41:25.415622: step 19915, loss = 0.24616 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:41:26.705431 ops/training.py:65 2019-01-17 07:41:26.705323: step 19916, loss = 0.21005 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:41:27.993720 ops/training.py:65 2019-01-17 07:41:27.993641: step 19917, loss = 0.18295 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:41:29.281233 ops/training.py:65 2019-01-17 07:41:29.281164: step 19918, loss = 0.23816 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:41:30.568912 ops/training.py:65 2019-01-17 07:41:30.568843: step 19919, loss = 0.22230 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:41:31.853168 ops/training.py:65 2019-01-17 07:41:31.853097: step 19920, loss = 0.24309 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:41:33.132595 ops/training.py:65 2019-01-17 07:41:33.132501: step 19921, loss = 0.20699 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:41:34.416535 ops/training.py:65 2019-01-17 07:41:34.416433: step 19922, loss = 0.20661 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:41:35.705339 ops/training.py:65 2019-01-17 07:41:35.705235: step 19923, loss = 0.24085 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:41:36.988979 ops/training.py:65 2019-01-17 07:41:36.988881: step 19924, loss = 0.27932 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:41:38.279715 ops/training.py:65 2019-01-17 07:41:38.279614: step 19925, loss = 0.22326 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:41:39.566999 ops/training.py:65 2019-01-17 07:41:39.566935: step 19926, loss = 0.25826 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:41:40.856485 ops/training.py:65 2019-01-17 07:41:40.856377: step 19927, loss = 0.19011 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:41:42.145963 ops/training.py:65 2019-01-17 07:41:42.145893: step 19928, loss = 0.17121 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:41:43.436734 ops/training.py:65 2019-01-17 07:41:43.436657: step 19929, loss = 0.23439 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:41:44.724519 ops/training.py:65 2019-01-17 07:41:44.724439: step 19930, loss = 0.21408 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:41:46.012589 ops/training.py:65 2019-01-17 07:41:46.012519: step 19931, loss = 0.22994 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:41:47.299605 ops/training.py:65 2019-01-17 07:41:47.299540: step 19932, loss = 0.22825 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:41:48.586990 ops/training.py:65 2019-01-17 07:41:48.586925: step 19933, loss = 0.23073 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:41:49.870968 ops/training.py:65 2019-01-17 07:41:49.870907: step 19934, loss = 0.19730 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:41:51.159328 ops/training.py:65 2019-01-17 07:41:51.159226: step 19935, loss = 0.27081 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:41:52.447541 ops/training.py:65 2019-01-17 07:41:52.447466: step 19936, loss = 0.25881 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:41:53.736249 ops/training.py:65 2019-01-17 07:41:53.736176: step 19937, loss = 0.28336 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:41:55.023339 ops/training.py:65 2019-01-17 07:41:55.023265: step 19938, loss = 0.29094 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:41:56.311588 ops/training.py:65 2019-01-17 07:41:56.311515: step 19939, loss = 0.21941 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:41:57.592788 ops/training.py:65 2019-01-17 07:41:57.592725: step 19940, loss = 0.20540 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:41:58.881183 ops/training.py:65 2019-01-17 07:41:58.881084: step 19941, loss = 0.23898 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:42:00.169514 ops/training.py:65 2019-01-17 07:42:00.169449: step 19942, loss = 0.24660 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:42:01.457402 ops/training.py:65 2019-01-17 07:42:01.457335: step 19943, loss = 0.18928 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:42:02.740927 ops/training.py:65 2019-01-17 07:42:02.740862: step 19944, loss = 0.25046 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:42:04.029704 ops/training.py:65 2019-01-17 07:42:04.029609: step 19945, loss = 0.24509 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:42:05.314251 ops/training.py:65 2019-01-17 07:42:05.314180: step 19946, loss = 0.26830 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:42:06.597884 ops/training.py:65 2019-01-17 07:42:06.597786: step 19947, loss = 0.29013 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:42:07.885045 ops/training.py:65 2019-01-17 07:42:07.884950: step 19948, loss = 0.19306 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:42:09.164846 ops/training.py:65 2019-01-17 07:42:09.164747: step 19949, loss = 0.23343 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:42:10.448738 ops/training.py:65 2019-01-17 07:42:10.448638: step 19950, loss = 0.22005 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:42:11.739773 ops/training.py:65 2019-01-17 07:42:11.739676: step 19951, loss = 0.21339 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:42:13.030299 ops/training.py:65 2019-01-17 07:42:13.030225: step 19952, loss = 0.21248 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:42:14.318593 ops/training.py:65 2019-01-17 07:42:14.318517: step 19953, loss = 0.21236 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:42:15.601810 ops/training.py:65 2019-01-17 07:42:15.601745: step 19954, loss = 0.28541 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:42:16.885691 ops/training.py:65 2019-01-17 07:42:16.885587: step 19955, loss = 0.17558 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:42:18.176714 ops/training.py:65 2019-01-17 07:42:18.176617: step 19956, loss = 0.23002 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:42:19.466685 ops/training.py:65 2019-01-17 07:42:19.466611: step 19957, loss = 0.23881 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:42:20.751411 ops/training.py:65 2019-01-17 07:42:20.751348: step 19958, loss = 0.19944 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:42:22.035729 ops/training.py:65 2019-01-17 07:42:22.035633: step 19959, loss = 0.21606 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:42:23.327902 ops/training.py:65 2019-01-17 07:42:23.327806: step 19960, loss = 0.20344 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:42:24.614640 ops/training.py:65 2019-01-17 07:42:24.614533: step 19961, loss = 0.18747 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:42:25.899651 ops/training.py:65 2019-01-17 07:42:25.899549: step 19962, loss = 0.20641 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:42:27.186650 ops/training.py:65 2019-01-17 07:42:27.186547: step 19963, loss = 0.24208 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:42:28.463438 ops/training.py:65 2019-01-17 07:42:28.463333: step 19964, loss = 0.26731 (25.1 examples/sec; 1.276 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:42:29.755604 ops/training.py:65 2019-01-17 07:42:29.755498: step 19965, loss = 0.22630 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:42:31.045242 ops/training.py:65 2019-01-17 07:42:31.045151: step 19966, loss = 0.20673 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:42:32.329540 ops/training.py:65 2019-01-17 07:42:32.329479: step 19967, loss = 0.24310 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:42:33.614275 ops/training.py:65 2019-01-17 07:42:33.614145: step 19968, loss = 0.22119 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:42:34.902954 ops/training.py:65 2019-01-17 07:42:34.902858: step 19969, loss = 0.22843 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:42:36.188750 ops/training.py:65 2019-01-17 07:42:36.188691: step 19970, loss = 0.23251 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:42:37.473945 ops/training.py:65 2019-01-17 07:42:37.473859: step 19971, loss = 0.24578 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:42:38.762061 ops/training.py:65 2019-01-17 07:42:38.761955: step 19972, loss = 0.24822 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:42:40.046949 ops/training.py:65 2019-01-17 07:42:40.046852: step 19973, loss = 0.22071 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:42:41.337467 ops/training.py:65 2019-01-17 07:42:41.337365: step 19974, loss = 0.30882 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:42:42.623767 ops/training.py:65 2019-01-17 07:42:42.623664: step 19975, loss = 0.24437 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:42:43.914592 ops/training.py:65 2019-01-17 07:42:43.914490: step 19976, loss = 0.21114 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:42:45.200214 ops/training.py:65 2019-01-17 07:42:45.200114: step 19977, loss = 0.23593 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:42:46.483446 ops/training.py:65 2019-01-17 07:42:46.483348: step 19978, loss = 0.26510 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:42:47.771940 ops/training.py:65 2019-01-17 07:42:47.771832: step 19979, loss = 0.24046 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:42:49.056269 ops/training.py:65 2019-01-17 07:42:49.056172: step 19980, loss = 0.29324 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:42:50.346861 ops/training.py:65 2019-01-17 07:42:50.346762: step 19981, loss = 0.19898 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:42:51.633184 ops/training.py:65 2019-01-17 07:42:51.633123: step 19982, loss = 0.26354 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:42:52.923593 ops/training.py:65 2019-01-17 07:42:52.923517: step 19983, loss = 0.21889 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:42:54.212006 ops/training.py:65 2019-01-17 07:42:54.211929: step 19984, loss = 0.19910 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:42:55.500158 ops/training.py:65 2019-01-17 07:42:55.500088: step 19985, loss = 0.17478 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:42:56.784041 ops/training.py:65 2019-01-17 07:42:56.783969: step 19986, loss = 0.19640 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:42:58.068661 ops/training.py:65 2019-01-17 07:42:58.068605: step 19987, loss = 0.22581 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:42:59.359597 ops/training.py:65 2019-01-17 07:42:59.359492: step 19988, loss = 0.15996 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:43:00.647132 ops/training.py:65 2019-01-17 07:43:00.647063: step 19989, loss = 0.26544 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:43:01.931156 ops/training.py:65 2019-01-17 07:43:01.931053: step 19990, loss = 0.27573 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:43:03.221970 ops/training.py:65 2019-01-17 07:43:03.221872: step 19991, loss = 0.25839 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:43:04.506230 ops/training.py:65 2019-01-17 07:43:04.506126: step 19992, loss = 0.24722 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:43:05.797375 ops/training.py:65 2019-01-17 07:43:05.797270: step 19993, loss = 0.18586 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:43:07.083155 ops/training.py:65 2019-01-17 07:43:07.083089: step 19994, loss = 0.26072 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:43:08.366945 ops/training.py:65 2019-01-17 07:43:08.366848: step 19995, loss = 0.22013 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:43:09.657822 ops/training.py:65 2019-01-17 07:43:09.657725: step 19996, loss = 0.22059 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:43:10.947898 ops/training.py:65 2019-01-17 07:43:10.947823: step 19997, loss = 0.21737 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:43:12.241916 ops/training.py:65 2019-01-17 07:43:12.241849: step 19998, loss = 0.20911 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:43:13.532740 ops/training.py:65 2019-01-17 07:43:13.532667: step 19999, loss = 0.16108 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:49:19.028932 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I4672 2019-01-17 07:49:19.029873 ops/training.py:41 2019-01-17 07:49:19.029818: step 20000, loss = 0.23 (0.1 examples/sec; 364.215 sec/batch) | Training accuracy = 1.0 | Validation accuracy = 0.5125 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_23_33_01_706250
I4672 2019-01-17 07:49:20.313011 ops/training.py:65 2019-01-17 07:49:20.312913: step 20001, loss = 0.21402 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:49:21.604521 ops/training.py:65 2019-01-17 07:49:21.604427: step 20002, loss = 0.18458 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:49:22.890977 ops/training.py:65 2019-01-17 07:49:22.890913: step 20003, loss = 0.19613 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:49:24.174889 ops/training.py:65 2019-01-17 07:49:24.174820: step 20004, loss = 0.17842 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:49:25.458137 ops/training.py:65 2019-01-17 07:49:25.457984: step 20005, loss = 0.16362 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:49:26.738419 ops/training.py:65 2019-01-17 07:49:26.738310: step 20006, loss = 0.18763 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:49:28.023609 ops/training.py:65 2019-01-17 07:49:28.023493: step 20007, loss = 0.26255 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:49:29.307992 ops/training.py:65 2019-01-17 07:49:29.307886: step 20008, loss = 0.19898 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:49:30.595958 ops/training.py:65 2019-01-17 07:49:30.595849: step 20009, loss = 0.19564 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:49:31.879920 ops/training.py:65 2019-01-17 07:49:31.879814: step 20010, loss = 0.22064 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:49:33.169663 ops/training.py:65 2019-01-17 07:49:33.169571: step 20011, loss = 0.22173 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:49:34.456379 ops/training.py:65 2019-01-17 07:49:34.456306: step 20012, loss = 0.21298 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:49:35.744711 ops/training.py:65 2019-01-17 07:49:35.744634: step 20013, loss = 0.20025 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:49:37.033341 ops/training.py:65 2019-01-17 07:49:37.033267: step 20014, loss = 0.21917 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:49:38.321774 ops/training.py:65 2019-01-17 07:49:38.321715: step 20015, loss = 0.26036 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:49:39.610069 ops/training.py:65 2019-01-17 07:49:39.609989: step 20016, loss = 0.27040 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:49:40.896577 ops/training.py:65 2019-01-17 07:49:40.896481: step 20017, loss = 0.20668 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:49:42.185827 ops/training.py:65 2019-01-17 07:49:42.185737: step 20018, loss = 0.18766 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:49:43.474018 ops/training.py:65 2019-01-17 07:49:43.473920: step 20019, loss = 0.25152 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:49:44.760599 ops/training.py:65 2019-01-17 07:49:44.760533: step 20020, loss = 0.17018 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:49:46.041249 ops/training.py:65 2019-01-17 07:49:46.041184: step 20021, loss = 0.19940 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:49:47.325480 ops/training.py:65 2019-01-17 07:49:47.325377: step 20022, loss = 0.22058 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:49:48.610712 ops/training.py:65 2019-01-17 07:49:48.610615: step 20023, loss = 0.20164 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:49:49.903360 ops/training.py:65 2019-01-17 07:49:49.903211: step 20024, loss = 0.25187 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:49:51.192957 ops/training.py:65 2019-01-17 07:49:51.192859: step 20025, loss = 0.23540 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:49:52.474585 ops/training.py:65 2019-01-17 07:49:52.474523: step 20026, loss = 0.23242 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:49:53.760410 ops/training.py:65 2019-01-17 07:49:53.760307: step 20027, loss = 0.22985 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:49:55.048497 ops/training.py:65 2019-01-17 07:49:55.048389: step 20028, loss = 0.20548 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:49:56.340590 ops/training.py:65 2019-01-17 07:49:56.340490: step 20029, loss = 0.18321 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:49:57.626783 ops/training.py:65 2019-01-17 07:49:57.626707: step 20030, loss = 0.25659 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:49:58.918159 ops/training.py:65 2019-01-17 07:49:58.918004: step 20031, loss = 0.23875 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:50:00.208990 ops/training.py:65 2019-01-17 07:50:00.208921: step 20032, loss = 0.31542 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:50:01.494721 ops/training.py:65 2019-01-17 07:50:01.494658: step 20033, loss = 0.17729 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:50:02.781093 ops/training.py:65 2019-01-17 07:50:02.780985: step 20034, loss = 0.23714 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:50:04.068973 ops/training.py:65 2019-01-17 07:50:04.068867: step 20035, loss = 0.19763 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:50:05.360101 ops/training.py:65 2019-01-17 07:50:05.360001: step 20036, loss = 0.25584 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:50:06.650380 ops/training.py:65 2019-01-17 07:50:06.650305: step 20037, loss = 0.18675 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:50:07.935097 ops/training.py:65 2019-01-17 07:50:07.935034: step 20038, loss = 0.22304 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:50:09.222655 ops/training.py:65 2019-01-17 07:50:09.222575: step 20039, loss = 0.18600 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:50:10.511722 ops/training.py:65 2019-01-17 07:50:10.511647: step 20040, loss = 0.24694 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:50:11.793768 ops/training.py:65 2019-01-17 07:50:11.793694: step 20041, loss = 0.21800 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:50:13.078293 ops/training.py:65 2019-01-17 07:50:13.078227: step 20042, loss = 0.17643 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:50:14.358471 ops/training.py:65 2019-01-17 07:50:14.358371: step 20043, loss = 0.20596 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:50:15.645349 ops/training.py:65 2019-01-17 07:50:15.645241: step 20044, loss = 0.19889 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:50:16.928575 ops/training.py:65 2019-01-17 07:50:16.928466: step 20045, loss = 0.21495 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:50:18.220815 ops/training.py:65 2019-01-17 07:50:18.220711: step 20046, loss = 0.20411 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:50:19.510897 ops/training.py:65 2019-01-17 07:50:19.510819: step 20047, loss = 0.17809 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:50:20.801644 ops/training.py:65 2019-01-17 07:50:20.801546: step 20048, loss = 0.26798 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:50:22.091312 ops/training.py:65 2019-01-17 07:50:22.091232: step 20049, loss = 0.21585 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:50:23.380979 ops/training.py:65 2019-01-17 07:50:23.380904: step 20050, loss = 0.18780 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:50:24.668322 ops/training.py:65 2019-01-17 07:50:24.668256: step 20051, loss = 0.23724 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:50:25.957184 ops/training.py:65 2019-01-17 07:50:25.957116: step 20052, loss = 0.20537 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:50:27.245532 ops/training.py:65 2019-01-17 07:50:27.245459: step 20053, loss = 0.24485 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:50:28.533820 ops/training.py:65 2019-01-17 07:50:28.533748: step 20054, loss = 0.25216 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:50:29.822129 ops/training.py:65 2019-01-17 07:50:29.822058: step 20055, loss = 0.17640 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:50:31.111546 ops/training.py:65 2019-01-17 07:50:31.111475: step 20056, loss = 0.18101 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:50:32.401494 ops/training.py:65 2019-01-17 07:50:32.401419: step 20057, loss = 0.17677 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:50:33.690735 ops/training.py:65 2019-01-17 07:50:33.690653: step 20058, loss = 0.20485 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:50:34.975870 ops/training.py:65 2019-01-17 07:50:34.975805: step 20059, loss = 0.22323 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:50:36.264737 ops/training.py:65 2019-01-17 07:50:36.264644: step 20060, loss = 0.17609 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:50:37.553147 ops/training.py:65 2019-01-17 07:50:37.553056: step 20061, loss = 0.20100 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:50:38.842287 ops/training.py:65 2019-01-17 07:50:38.842185: step 20062, loss = 0.28199 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:50:40.126031 ops/training.py:65 2019-01-17 07:50:40.125965: step 20063, loss = 0.19834 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:50:41.413473 ops/training.py:65 2019-01-17 07:50:41.413396: step 20064, loss = 0.20957 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:50:42.706602 ops/training.py:65 2019-01-17 07:50:42.706532: step 20065, loss = 0.22244 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:50:43.994349 ops/training.py:65 2019-01-17 07:50:43.994248: step 20066, loss = 0.23478 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:50:45.282089 ops/training.py:65 2019-01-17 07:50:45.282017: step 20067, loss = 0.17191 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:50:46.570836 ops/training.py:65 2019-01-17 07:50:46.570759: step 20068, loss = 0.23467 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:50:47.861585 ops/training.py:65 2019-01-17 07:50:47.861515: step 20069, loss = 0.16321 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:50:49.152369 ops/training.py:65 2019-01-17 07:50:49.152273: step 20070, loss = 0.21189 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:50:50.440877 ops/training.py:65 2019-01-17 07:50:50.440811: step 20071, loss = 0.23533 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:50:51.729156 ops/training.py:65 2019-01-17 07:50:51.729082: step 20072, loss = 0.26379 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:50:53.014431 ops/training.py:65 2019-01-17 07:50:53.014356: step 20073, loss = 0.18755 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:50:54.299820 ops/training.py:65 2019-01-17 07:50:54.299713: step 20074, loss = 0.15441 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:50:55.589790 ops/training.py:65 2019-01-17 07:50:55.589643: step 20075, loss = 0.23954 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:50:56.880619 ops/training.py:65 2019-01-17 07:50:56.880534: step 20076, loss = 0.21742 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:50:58.170185 ops/training.py:65 2019-01-17 07:50:58.170098: step 20077, loss = 0.19086 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:50:59.459216 ops/training.py:65 2019-01-17 07:50:59.459143: step 20078, loss = 0.20971 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:51:00.746673 ops/training.py:65 2019-01-17 07:51:00.746607: step 20079, loss = 0.25350 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:51:02.034450 ops/training.py:65 2019-01-17 07:51:02.034383: step 20080, loss = 0.21695 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:51:03.322748 ops/training.py:65 2019-01-17 07:51:03.322655: step 20081, loss = 0.24082 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:51:04.612549 ops/training.py:65 2019-01-17 07:51:04.612471: step 20082, loss = 0.21929 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:51:05.901904 ops/training.py:65 2019-01-17 07:51:05.901835: step 20083, loss = 0.24029 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:51:07.190230 ops/training.py:65 2019-01-17 07:51:07.190162: step 20084, loss = 0.16570 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:51:08.477526 ops/training.py:65 2019-01-17 07:51:08.477462: step 20085, loss = 0.29725 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:51:09.766183 ops/training.py:65 2019-01-17 07:51:09.766097: step 20086, loss = 0.20720 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:51:11.051522 ops/training.py:65 2019-01-17 07:51:11.051460: step 20087, loss = 0.21443 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:51:12.334124 ops/training.py:65 2019-01-17 07:51:12.334056: step 20088, loss = 0.22725 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:51:13.620514 ops/training.py:65 2019-01-17 07:51:13.620430: step 20089, loss = 0.19743 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:51:14.918117 ops/training.py:65 2019-01-17 07:51:14.918007: step 20090, loss = 0.19620 (24.7 examples/sec; 1.296 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:51:16.204057 ops/training.py:65 2019-01-17 07:51:16.203995: step 20091, loss = 0.24028 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:51:17.494415 ops/training.py:65 2019-01-17 07:51:17.494312: step 20092, loss = 0.21923 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:51:18.778448 ops/training.py:65 2019-01-17 07:51:18.778373: step 20093, loss = 0.17711 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:51:20.062786 ops/training.py:65 2019-01-17 07:51:20.062720: step 20094, loss = 0.24316 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:51:21.348318 ops/training.py:65 2019-01-17 07:51:21.348222: step 20095, loss = 0.16272 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:51:22.640524 ops/training.py:65 2019-01-17 07:51:22.640427: step 20096, loss = 0.21608 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:51:23.931911 ops/training.py:65 2019-01-17 07:51:23.931842: step 20097, loss = 0.21614 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:51:25.220776 ops/training.py:65 2019-01-17 07:51:25.220707: step 20098, loss = 0.23376 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:51:26.504279 ops/training.py:65 2019-01-17 07:51:26.504209: step 20099, loss = 0.19177 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:51:27.789352 ops/training.py:65 2019-01-17 07:51:27.789273: step 20100, loss = 0.22643 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:51:29.080214 ops/training.py:65 2019-01-17 07:51:29.080103: step 20101, loss = 0.20726 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:51:30.363224 ops/training.py:65 2019-01-17 07:51:30.363148: step 20102, loss = 0.29066 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:51:31.645632 ops/training.py:65 2019-01-17 07:51:31.645528: step 20103, loss = 0.21130 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:51:32.936769 ops/training.py:65 2019-01-17 07:51:32.936668: step 20104, loss = 0.22292 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:51:34.227531 ops/training.py:65 2019-01-17 07:51:34.227454: step 20105, loss = 0.17216 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:51:35.516257 ops/training.py:65 2019-01-17 07:51:35.516187: step 20106, loss = 0.16020 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:51:36.804695 ops/training.py:65 2019-01-17 07:51:36.804605: step 20107, loss = 0.20031 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:51:38.100609 ops/training.py:65 2019-01-17 07:51:38.100508: step 20108, loss = 0.26776 (24.7 examples/sec; 1.295 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:51:39.389459 ops/training.py:65 2019-01-17 07:51:39.389378: step 20109, loss = 0.18532 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:51:40.678543 ops/training.py:65 2019-01-17 07:51:40.678451: step 20110, loss = 0.20973 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:51:41.967753 ops/training.py:65 2019-01-17 07:51:41.967675: step 20111, loss = 0.22315 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:51:43.257295 ops/training.py:65 2019-01-17 07:51:43.257224: step 20112, loss = 0.20129 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:51:44.545260 ops/training.py:65 2019-01-17 07:51:44.545194: step 20113, loss = 0.20309 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:51:45.830169 ops/training.py:65 2019-01-17 07:51:45.830071: step 20114, loss = 0.25693 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:51:47.118536 ops/training.py:65 2019-01-17 07:51:47.118458: step 20115, loss = 0.26267 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:51:48.402023 ops/training.py:65 2019-01-17 07:51:48.401954: step 20116, loss = 0.18826 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:51:49.692489 ops/training.py:65 2019-01-17 07:51:49.692336: step 20117, loss = 0.22487 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:51:50.981553 ops/training.py:65 2019-01-17 07:51:50.981461: step 20118, loss = 0.22932 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:51:52.271288 ops/training.py:65 2019-01-17 07:51:52.271207: step 20119, loss = 0.23785 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:51:53.559522 ops/training.py:65 2019-01-17 07:51:53.559443: step 20120, loss = 0.22495 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:51:54.844638 ops/training.py:65 2019-01-17 07:51:54.844570: step 20121, loss = 0.32536 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:51:56.130069 ops/training.py:65 2019-01-17 07:51:56.129989: step 20122, loss = 0.20699 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:51:57.421918 ops/training.py:65 2019-01-17 07:51:57.421809: step 20123, loss = 0.23284 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:51:58.713223 ops/training.py:65 2019-01-17 07:51:58.713128: step 20124, loss = 0.22967 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:51:59.998767 ops/training.py:65 2019-01-17 07:51:59.998697: step 20125, loss = 0.20867 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:52:01.288372 ops/training.py:65 2019-01-17 07:52:01.288265: step 20126, loss = 0.22046 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:52:02.578557 ops/training.py:65 2019-01-17 07:52:02.578470: step 20127, loss = 0.20651 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:52:03.868452 ops/training.py:65 2019-01-17 07:52:03.868353: step 20128, loss = 0.20384 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:52:05.156450 ops/training.py:65 2019-01-17 07:52:05.156376: step 20129, loss = 0.19965 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:52:06.445686 ops/training.py:65 2019-01-17 07:52:06.445626: step 20130, loss = 0.19369 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:52:07.734694 ops/training.py:65 2019-01-17 07:52:07.734610: step 20131, loss = 0.18906 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:52:09.022664 ops/training.py:65 2019-01-17 07:52:09.022599: step 20132, loss = 0.21964 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:52:10.306617 ops/training.py:65 2019-01-17 07:52:10.306549: step 20133, loss = 0.22564 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:52:11.590427 ops/training.py:65 2019-01-17 07:52:11.590323: step 20134, loss = 0.25247 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:52:12.883652 ops/training.py:65 2019-01-17 07:52:12.883545: step 20135, loss = 0.22883 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:52:14.175568 ops/training.py:65 2019-01-17 07:52:14.175498: step 20136, loss = 0.22350 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:52:15.464884 ops/training.py:65 2019-01-17 07:52:15.464811: step 20137, loss = 0.18202 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:52:16.753404 ops/training.py:65 2019-01-17 07:52:16.753329: step 20138, loss = 0.20984 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:52:18.037416 ops/training.py:65 2019-01-17 07:52:18.037346: step 20139, loss = 0.20865 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:52:19.326335 ops/training.py:65 2019-01-17 07:52:19.326267: step 20140, loss = 0.21522 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:52:20.616322 ops/training.py:65 2019-01-17 07:52:20.616168: step 20141, loss = 0.21615 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:52:21.906777 ops/training.py:65 2019-01-17 07:52:21.906707: step 20142, loss = 0.21180 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:52:23.196037 ops/training.py:65 2019-01-17 07:52:23.195964: step 20143, loss = 0.22021 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:52:24.480087 ops/training.py:65 2019-01-17 07:52:24.480015: step 20144, loss = 0.21604 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:52:25.769182 ops/training.py:65 2019-01-17 07:52:25.769073: step 20145, loss = 0.24001 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:52:27.059712 ops/training.py:65 2019-01-17 07:52:27.059642: step 20146, loss = 0.24432 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:52:28.348832 ops/training.py:65 2019-01-17 07:52:28.348758: step 20147, loss = 0.23338 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:52:29.637036 ops/training.py:65 2019-01-17 07:52:29.636966: step 20148, loss = 0.25759 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:52:30.924998 ops/training.py:65 2019-01-17 07:52:30.924914: step 20149, loss = 0.18742 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:52:32.213339 ops/training.py:65 2019-01-17 07:52:32.213256: step 20150, loss = 0.22888 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:52:33.501366 ops/training.py:65 2019-01-17 07:52:33.501293: step 20151, loss = 0.23659 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:52:34.784952 ops/training.py:65 2019-01-17 07:52:34.784890: step 20152, loss = 0.22304 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:52:36.075214 ops/training.py:65 2019-01-17 07:52:36.075145: step 20153, loss = 0.22532 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:52:37.363073 ops/training.py:65 2019-01-17 07:52:37.363007: step 20154, loss = 0.20897 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:52:38.647580 ops/training.py:65 2019-01-17 07:52:38.647508: step 20155, loss = 0.24350 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:52:39.939495 ops/training.py:65 2019-01-17 07:52:39.939382: step 20156, loss = 0.26463 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:52:41.225586 ops/training.py:65 2019-01-17 07:52:41.225517: step 20157, loss = 0.25944 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:52:42.513927 ops/training.py:65 2019-01-17 07:52:42.513836: step 20158, loss = 0.20895 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:52:43.804067 ops/training.py:65 2019-01-17 07:52:43.803969: step 20159, loss = 0.21751 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:52:45.093848 ops/training.py:65 2019-01-17 07:52:45.093776: step 20160, loss = 0.17572 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:52:46.382714 ops/training.py:65 2019-01-17 07:52:46.382615: step 20161, loss = 0.20886 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:52:47.666589 ops/training.py:65 2019-01-17 07:52:47.666520: step 20162, loss = 0.22077 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:52:48.950168 ops/training.py:65 2019-01-17 07:52:48.950070: step 20163, loss = 0.19906 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:52:50.240493 ops/training.py:65 2019-01-17 07:52:50.240351: step 20164, loss = 0.18994 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:52:51.531771 ops/training.py:65 2019-01-17 07:52:51.531703: step 20165, loss = 0.23483 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:52:52.816524 ops/training.py:65 2019-01-17 07:52:52.816454: step 20166, loss = 0.24273 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:52:54.106366 ops/training.py:65 2019-01-17 07:52:54.106264: step 20167, loss = 0.22630 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:52:55.395791 ops/training.py:65 2019-01-17 07:52:55.395707: step 20168, loss = 0.22580 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:52:56.683765 ops/training.py:65 2019-01-17 07:52:56.683692: step 20169, loss = 0.20764 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:52:57.968431 ops/training.py:65 2019-01-17 07:52:57.968367: step 20170, loss = 0.21318 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:52:59.259849 ops/training.py:65 2019-01-17 07:52:59.259691: step 20171, loss = 0.23614 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:00.550584 ops/training.py:65 2019-01-17 07:53:00.550510: step 20172, loss = 0.20281 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:01.830220 ops/training.py:65 2019-01-17 07:53:01.830149: step 20173, loss = 0.21160 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:53:03.118532 ops/training.py:65 2019-01-17 07:53:03.118443: step 20174, loss = 0.21122 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:04.407245 ops/training.py:65 2019-01-17 07:53:04.407147: step 20175, loss = 0.17624 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:05.696362 ops/training.py:65 2019-01-17 07:53:05.696290: step 20176, loss = 0.19084 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:06.984179 ops/training.py:65 2019-01-17 07:53:06.984108: step 20177, loss = 0.23875 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:53:08.273148 ops/training.py:65 2019-01-17 07:53:08.273081: step 20178, loss = 0.18123 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:09.557207 ops/training.py:65 2019-01-17 07:53:09.557135: step 20179, loss = 0.19284 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:53:10.842824 ops/training.py:65 2019-01-17 07:53:10.842725: step 20180, loss = 0.17467 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:12.131540 ops/training.py:65 2019-01-17 07:53:12.131437: step 20181, loss = 0.22240 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:13.420662 ops/training.py:65 2019-01-17 07:53:13.420593: step 20182, loss = 0.24289 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:14.710282 ops/training.py:65 2019-01-17 07:53:14.710189: step 20183, loss = 0.17192 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:15.994186 ops/training.py:65 2019-01-17 07:53:15.994122: step 20184, loss = 0.22497 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:17.277887 ops/training.py:65 2019-01-17 07:53:17.277780: step 20185, loss = 0.24268 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:18.569873 ops/training.py:65 2019-01-17 07:53:18.569767: step 20186, loss = 0.20907 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:53:19.860807 ops/training.py:65 2019-01-17 07:53:19.860743: step 20187, loss = 0.23299 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:21.148619 ops/training.py:65 2019-01-17 07:53:21.148549: step 20188, loss = 0.19988 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:22.438093 ops/training.py:65 2019-01-17 07:53:22.438018: step 20189, loss = 0.27389 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:53:23.727167 ops/training.py:65 2019-01-17 07:53:23.727094: step 20190, loss = 0.22266 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:53:25.016337 ops/training.py:65 2019-01-17 07:53:25.016264: step 20191, loss = 0.24757 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:53:26.305584 ops/training.py:65 2019-01-17 07:53:26.305515: step 20192, loss = 0.19892 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:27.589704 ops/training.py:65 2019-01-17 07:53:27.589624: step 20193, loss = 0.27395 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:53:28.881577 ops/training.py:65 2019-01-17 07:53:28.881470: step 20194, loss = 0.20529 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:30.172615 ops/training.py:65 2019-01-17 07:53:30.172544: step 20195, loss = 0.22430 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:53:31.457614 ops/training.py:65 2019-01-17 07:53:31.457545: step 20196, loss = 0.20481 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:53:32.746330 ops/training.py:65 2019-01-17 07:53:32.746261: step 20197, loss = 0.20954 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:34.031238 ops/training.py:65 2019-01-17 07:53:34.031167: step 20198, loss = 0.22723 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:53:35.315242 ops/training.py:65 2019-01-17 07:53:35.315097: step 20199, loss = 0.21409 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:36.607116 ops/training.py:65 2019-01-17 07:53:36.607015: step 20200, loss = 0.25586 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:53:37.898231 ops/training.py:65 2019-01-17 07:53:37.898159: step 20201, loss = 0.21746 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:39.193522 ops/training.py:65 2019-01-17 07:53:39.193450: step 20202, loss = 0.28180 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:53:40.483543 ops/training.py:65 2019-01-17 07:53:40.483467: step 20203, loss = 0.20479 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:41.771582 ops/training.py:65 2019-01-17 07:53:41.771494: step 20204, loss = 0.23417 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:43.063977 ops/training.py:65 2019-01-17 07:53:43.063902: step 20205, loss = 0.25827 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:53:44.353426 ops/training.py:65 2019-01-17 07:53:44.353333: step 20206, loss = 0.19682 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:45.642715 ops/training.py:65 2019-01-17 07:53:45.642645: step 20207, loss = 0.20969 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:46.930989 ops/training.py:65 2019-01-17 07:53:46.930899: step 20208, loss = 0.19336 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:48.219968 ops/training.py:65 2019-01-17 07:53:48.219865: step 20209, loss = 0.24761 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:53:49.508134 ops/training.py:65 2019-01-17 07:53:49.508066: step 20210, loss = 0.22546 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:50.793969 ops/training.py:65 2019-01-17 07:53:50.793901: step 20211, loss = 0.17446 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:52.082789 ops/training.py:65 2019-01-17 07:53:52.082713: step 20212, loss = 0.19045 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:53.370894 ops/training.py:65 2019-01-17 07:53:53.370821: step 20213, loss = 0.20635 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:54.659101 ops/training.py:65 2019-01-17 07:53:54.659005: step 20214, loss = 0.20899 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:55.948369 ops/training.py:65 2019-01-17 07:53:55.948274: step 20215, loss = 0.21239 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:53:57.236615 ops/training.py:65 2019-01-17 07:53:57.236521: step 20216, loss = 0.24691 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:53:58.525166 ops/training.py:65 2019-01-17 07:53:58.525088: step 20217, loss = 0.18510 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:53:59.813522 ops/training.py:65 2019-01-17 07:53:59.813442: step 20218, loss = 0.24561 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:54:01.101973 ops/training.py:65 2019-01-17 07:54:01.101902: step 20219, loss = 0.24483 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:54:02.390488 ops/training.py:65 2019-01-17 07:54:02.390380: step 20220, loss = 0.31103 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:54:03.675246 ops/training.py:65 2019-01-17 07:54:03.675177: step 20221, loss = 0.26384 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:54:04.964102 ops/training.py:65 2019-01-17 07:54:04.963992: step 20222, loss = 0.21397 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:54:06.253863 ops/training.py:65 2019-01-17 07:54:06.253787: step 20223, loss = 0.13921 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:54:07.543202 ops/training.py:65 2019-01-17 07:54:07.543121: step 20224, loss = 0.21862 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:54:08.824538 ops/training.py:65 2019-01-17 07:54:08.824471: step 20225, loss = 0.27539 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:54:10.113427 ops/training.py:65 2019-01-17 07:54:10.113270: step 20226, loss = 0.21880 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:54:11.398861 ops/training.py:65 2019-01-17 07:54:11.398796: step 20227, loss = 0.22660 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:54:12.686444 ops/training.py:65 2019-01-17 07:54:12.686378: step 20228, loss = 0.28676 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:54:13.974706 ops/training.py:65 2019-01-17 07:54:13.974637: step 20229, loss = 0.23583 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:54:15.268617 ops/training.py:65 2019-01-17 07:54:15.268552: step 20230, loss = 0.20108 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:54:16.551404 ops/training.py:65 2019-01-17 07:54:16.551335: step 20231, loss = 0.23528 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:54:17.834373 ops/training.py:65 2019-01-17 07:54:17.834293: step 20232, loss = 0.18587 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:54:19.126033 ops/training.py:65 2019-01-17 07:54:19.125926: step 20233, loss = 0.21107 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:54:20.417050 ops/training.py:65 2019-01-17 07:54:20.416957: step 20234, loss = 0.24026 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:54:21.706480 ops/training.py:65 2019-01-17 07:54:21.706384: step 20235, loss = 0.22367 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:54:22.996539 ops/training.py:65 2019-01-17 07:54:22.996470: step 20236, loss = 0.20608 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:54:24.285536 ops/training.py:65 2019-01-17 07:54:24.285456: step 20237, loss = 0.20792 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:54:25.574858 ops/training.py:65 2019-01-17 07:54:25.574787: step 20238, loss = 0.23746 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:54:26.860902 ops/training.py:65 2019-01-17 07:54:26.860804: step 20239, loss = 0.19777 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:54:28.152007 ops/training.py:65 2019-01-17 07:54:28.151897: step 20240, loss = 0.21520 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:54:29.442148 ops/training.py:65 2019-01-17 07:54:29.442072: step 20241, loss = 0.24453 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:54:30.729996 ops/training.py:65 2019-01-17 07:54:30.729915: step 20242, loss = 0.22674 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:54:32.018284 ops/training.py:65 2019-01-17 07:54:32.018209: step 20243, loss = 0.21404 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:54:33.306236 ops/training.py:65 2019-01-17 07:54:33.306162: step 20244, loss = 0.22522 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:54:34.590644 ops/training.py:65 2019-01-17 07:54:34.590575: step 20245, loss = 0.16490 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:54:35.879861 ops/training.py:65 2019-01-17 07:54:35.879761: step 20246, loss = 0.18381 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:54:37.168659 ops/training.py:65 2019-01-17 07:54:37.168585: step 20247, loss = 0.20358 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:54:38.457137 ops/training.py:65 2019-01-17 07:54:38.457066: step 20248, loss = 0.22108 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:54:39.745707 ops/training.py:65 2019-01-17 07:54:39.745637: step 20249, loss = 0.16057 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:54:41.033514 ops/training.py:65 2019-01-17 07:54:41.033441: step 20250, loss = 0.26166 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:54:42.319440 ops/training.py:65 2019-01-17 07:54:42.319368: step 20251, loss = 0.19791 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:54:43.609214 ops/training.py:65 2019-01-17 07:54:43.609082: step 20252, loss = 0.21448 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:54:44.897423 ops/training.py:65 2019-01-17 07:54:44.897351: step 20253, loss = 0.18623 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:54:46.186725 ops/training.py:65 2019-01-17 07:54:46.186655: step 20254, loss = 0.22923 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:54:47.475467 ops/training.py:65 2019-01-17 07:54:47.475403: step 20255, loss = 0.21896 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:54:48.763826 ops/training.py:65 2019-01-17 07:54:48.763750: step 20256, loss = 0.18485 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:54:50.048230 ops/training.py:65 2019-01-17 07:54:50.048158: step 20257, loss = 0.21981 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:54:51.337445 ops/training.py:65 2019-01-17 07:54:51.337291: step 20258, loss = 0.17560 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:54:52.622447 ops/training.py:65 2019-01-17 07:54:52.622383: step 20259, loss = 0.20167 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:54:53.906052 ops/training.py:65 2019-01-17 07:54:53.905973: step 20260, loss = 0.24480 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:54:55.196864 ops/training.py:65 2019-01-17 07:54:55.196725: step 20261, loss = 0.21429 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:54:56.487635 ops/training.py:65 2019-01-17 07:54:56.487566: step 20262, loss = 0.20127 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:54:57.775653 ops/training.py:65 2019-01-17 07:54:57.775581: step 20263, loss = 0.19519 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:54:59.063766 ops/training.py:65 2019-01-17 07:54:59.063692: step 20264, loss = 0.21045 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:55:00.353161 ops/training.py:65 2019-01-17 07:55:00.353081: step 20265, loss = 0.19497 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:55:01.642774 ops/training.py:65 2019-01-17 07:55:01.642698: step 20266, loss = 0.19697 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:55:02.932717 ops/training.py:65 2019-01-17 07:55:02.932632: step 20267, loss = 0.24996 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:55:04.220576 ops/training.py:65 2019-01-17 07:55:04.220504: step 20268, loss = 0.22538 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:55:05.506844 ops/training.py:65 2019-01-17 07:55:05.506774: step 20269, loss = 0.19030 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:55:06.791979 ops/training.py:65 2019-01-17 07:55:06.791866: step 20270, loss = 0.19937 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:55:08.080749 ops/training.py:65 2019-01-17 07:55:08.080659: step 20271, loss = 0.19458 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:55:09.369116 ops/training.py:65 2019-01-17 07:55:09.369048: step 20272, loss = 0.21383 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:55:10.657092 ops/training.py:65 2019-01-17 07:55:10.657025: step 20273, loss = 0.20920 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:55:11.946701 ops/training.py:65 2019-01-17 07:55:11.946627: step 20274, loss = 0.25538 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:55:13.234568 ops/training.py:65 2019-01-17 07:55:13.234469: step 20275, loss = 0.17466 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:55:14.523377 ops/training.py:65 2019-01-17 07:55:14.523305: step 20276, loss = 0.22467 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:55:15.807109 ops/training.py:65 2019-01-17 07:55:15.807038: step 20277, loss = 0.14376 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:55:17.094664 ops/training.py:65 2019-01-17 07:55:17.094595: step 20278, loss = 0.25711 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:55:18.377777 ops/training.py:65 2019-01-17 07:55:18.377712: step 20279, loss = 0.19268 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:55:19.661376 ops/training.py:65 2019-01-17 07:55:19.661275: step 20280, loss = 0.22087 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:55:20.953319 ops/training.py:65 2019-01-17 07:55:20.953210: step 20281, loss = 0.20147 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:55:22.244719 ops/training.py:65 2019-01-17 07:55:22.244627: step 20282, loss = 0.19191 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:55:23.533631 ops/training.py:65 2019-01-17 07:55:23.533553: step 20283, loss = 0.19018 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:55:24.818474 ops/training.py:65 2019-01-17 07:55:24.818394: step 20284, loss = 0.24983 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:55:26.107343 ops/training.py:65 2019-01-17 07:55:26.107266: step 20285, loss = 0.22417 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:55:27.396124 ops/training.py:65 2019-01-17 07:55:27.396048: step 20286, loss = 0.16661 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:55:28.680840 ops/training.py:65 2019-01-17 07:55:28.680769: step 20287, loss = 0.20646 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:55:29.969588 ops/training.py:65 2019-01-17 07:55:29.969523: step 20288, loss = 0.17452 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:55:31.258447 ops/training.py:65 2019-01-17 07:55:31.258356: step 20289, loss = 0.26203 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:55:32.547160 ops/training.py:65 2019-01-17 07:55:32.547091: step 20290, loss = 0.15410 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:55:33.835532 ops/training.py:65 2019-01-17 07:55:33.835461: step 20291, loss = 0.19629 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:55:35.118674 ops/training.py:65 2019-01-17 07:55:35.118605: step 20292, loss = 0.20057 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:55:36.403513 ops/training.py:65 2019-01-17 07:55:36.403417: step 20293, loss = 0.22457 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:55:37.691186 ops/training.py:65 2019-01-17 07:55:37.691089: step 20294, loss = 0.18546 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:55:38.982485 ops/training.py:65 2019-01-17 07:55:38.982387: step 20295, loss = 0.24391 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:55:40.267834 ops/training.py:65 2019-01-17 07:55:40.267746: step 20296, loss = 0.21559 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:55:41.555959 ops/training.py:65 2019-01-17 07:55:41.555859: step 20297, loss = 0.16942 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:55:42.842086 ops/training.py:65 2019-01-17 07:55:42.841973: step 20298, loss = 0.19130 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:55:44.133773 ops/training.py:65 2019-01-17 07:55:44.133669: step 20299, loss = 0.26204 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:55:45.423948 ops/training.py:65 2019-01-17 07:55:45.423873: step 20300, loss = 0.19047 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:55:46.713927 ops/training.py:65 2019-01-17 07:55:46.713835: step 20301, loss = 0.15709 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:55:47.999168 ops/training.py:65 2019-01-17 07:55:47.999103: step 20302, loss = 0.22811 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:55:49.288629 ops/training.py:65 2019-01-17 07:55:49.288517: step 20303, loss = 0.21663 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:55:50.572616 ops/training.py:65 2019-01-17 07:55:50.572550: step 20304, loss = 0.26499 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:55:51.862169 ops/training.py:65 2019-01-17 07:55:51.862062: step 20305, loss = 0.23464 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:55:53.150905 ops/training.py:65 2019-01-17 07:55:53.150831: step 20306, loss = 0.21526 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:55:54.440583 ops/training.py:65 2019-01-17 07:55:54.440440: step 20307, loss = 0.19397 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:55:55.725326 ops/training.py:65 2019-01-17 07:55:55.725256: step 20308, loss = 0.21443 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:55:57.014968 ops/training.py:65 2019-01-17 07:55:57.014819: step 20309, loss = 0.19313 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:55:58.304352 ops/training.py:65 2019-01-17 07:55:58.304279: step 20310, loss = 0.24027 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:55:59.588901 ops/training.py:65 2019-01-17 07:55:59.588834: step 20311, loss = 0.22796 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:56:00.876820 ops/training.py:65 2019-01-17 07:56:00.876751: step 20312, loss = 0.23633 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:56:02.160899 ops/training.py:65 2019-01-17 07:56:02.160833: step 20313, loss = 0.16934 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:56:03.448727 ops/training.py:65 2019-01-17 07:56:03.448659: step 20314, loss = 0.20253 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:56:04.733411 ops/training.py:65 2019-01-17 07:56:04.733350: step 20315, loss = 0.20064 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:56:06.021493 ops/training.py:65 2019-01-17 07:56:06.021385: step 20316, loss = 0.23907 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:56:07.308678 ops/training.py:65 2019-01-17 07:56:07.308589: step 20317, loss = 0.20571 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:56:08.597708 ops/training.py:65 2019-01-17 07:56:08.597627: step 20318, loss = 0.22748 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:56:09.886085 ops/training.py:65 2019-01-17 07:56:09.886011: step 20319, loss = 0.22095 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:56:11.176313 ops/training.py:65 2019-01-17 07:56:11.176221: step 20320, loss = 0.19020 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:56:12.461209 ops/training.py:65 2019-01-17 07:56:12.461140: step 20321, loss = 0.21323 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:56:13.754996 ops/training.py:65 2019-01-17 07:56:13.754918: step 20322, loss = 0.26002 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:56:15.044078 ops/training.py:65 2019-01-17 07:56:15.044005: step 20323, loss = 0.21037 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:56:16.332010 ops/training.py:65 2019-01-17 07:56:16.331935: step 20324, loss = 0.21755 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:56:17.619748 ops/training.py:65 2019-01-17 07:56:17.619680: step 20325, loss = 0.15400 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:56:18.903254 ops/training.py:65 2019-01-17 07:56:18.903191: step 20326, loss = 0.17790 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:56:20.187815 ops/training.py:65 2019-01-17 07:56:20.187715: step 20327, loss = 0.22244 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:56:21.472538 ops/training.py:65 2019-01-17 07:56:21.472469: step 20328, loss = 0.21196 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:56:22.758909 ops/training.py:65 2019-01-17 07:56:22.758780: step 20329, loss = 0.20921 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:56:24.044624 ops/training.py:65 2019-01-17 07:56:24.044547: step 20330, loss = 0.16341 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:56:25.333330 ops/training.py:65 2019-01-17 07:56:25.333263: step 20331, loss = 0.19564 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:56:26.621305 ops/training.py:65 2019-01-17 07:56:26.621216: step 20332, loss = 0.22311 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:56:27.906096 ops/training.py:65 2019-01-17 07:56:27.906023: step 20333, loss = 0.21854 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:56:29.191257 ops/training.py:65 2019-01-17 07:56:29.191186: step 20334, loss = 0.26546 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:56:30.478646 ops/training.py:65 2019-01-17 07:56:30.478541: step 20335, loss = 0.16101 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:56:31.764757 ops/training.py:65 2019-01-17 07:56:31.764657: step 20336, loss = 0.24612 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:56:33.057112 ops/training.py:65 2019-01-17 07:56:33.056973: step 20337, loss = 0.17546 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:56:34.348522 ops/training.py:65 2019-01-17 07:56:34.348440: step 20338, loss = 0.18957 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:56:35.634541 ops/training.py:65 2019-01-17 07:56:35.634466: step 20339, loss = 0.20082 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:56:36.926827 ops/training.py:65 2019-01-17 07:56:36.926725: step 20340, loss = 0.23043 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:56:38.218142 ops/training.py:65 2019-01-17 07:56:38.218075: step 20341, loss = 0.16876 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:56:39.501556 ops/training.py:65 2019-01-17 07:56:39.501493: step 20342, loss = 0.20611 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:56:40.786397 ops/training.py:65 2019-01-17 07:56:40.786324: step 20343, loss = 0.18148 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:56:42.072781 ops/training.py:65 2019-01-17 07:56:42.072678: step 20344, loss = 0.19006 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:56:43.354200 ops/training.py:65 2019-01-17 07:56:43.354097: step 20345, loss = 0.21078 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:56:44.648175 ops/training.py:65 2019-01-17 07:56:44.648050: step 20346, loss = 0.17821 (24.8 examples/sec; 1.293 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:56:45.934916 ops/training.py:65 2019-01-17 07:56:45.934842: step 20347, loss = 0.18387 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:56:47.223584 ops/training.py:65 2019-01-17 07:56:47.223516: step 20348, loss = 0.22127 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:56:48.511155 ops/training.py:65 2019-01-17 07:56:48.511083: step 20349, loss = 0.17469 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:56:49.799669 ops/training.py:65 2019-01-17 07:56:49.799600: step 20350, loss = 0.16381 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:56:51.089476 ops/training.py:65 2019-01-17 07:56:51.089406: step 20351, loss = 0.21035 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:56:52.377930 ops/training.py:65 2019-01-17 07:56:52.377856: step 20352, loss = 0.21463 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:56:53.667667 ops/training.py:65 2019-01-17 07:56:53.667594: step 20353, loss = 0.22102 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:56:54.957361 ops/training.py:65 2019-01-17 07:56:54.957287: step 20354, loss = 0.20190 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:56:56.244977 ops/training.py:65 2019-01-17 07:56:56.244881: step 20355, loss = 0.20271 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:56:57.532605 ops/training.py:65 2019-01-17 07:56:57.532543: step 20356, loss = 0.21409 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:56:58.820527 ops/training.py:65 2019-01-17 07:56:58.820450: step 20357, loss = 0.21486 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:57:00.107087 ops/training.py:65 2019-01-17 07:57:00.107015: step 20358, loss = 0.15985 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:57:01.391739 ops/training.py:65 2019-01-17 07:57:01.391673: step 20359, loss = 0.24150 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:57:02.680204 ops/training.py:65 2019-01-17 07:57:02.680130: step 20360, loss = 0.27649 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:57:03.968841 ops/training.py:65 2019-01-17 07:57:03.968748: step 20361, loss = 0.15387 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:57:05.258430 ops/training.py:65 2019-01-17 07:57:05.258338: step 20362, loss = 0.18841 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:57:06.543238 ops/training.py:65 2019-01-17 07:57:06.543163: step 20363, loss = 0.17962 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:57:07.831836 ops/training.py:65 2019-01-17 07:57:07.831739: step 20364, loss = 0.25483 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:57:09.120634 ops/training.py:65 2019-01-17 07:57:09.120567: step 20365, loss = 0.19820 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:57:10.408799 ops/training.py:65 2019-01-17 07:57:10.408732: step 20366, loss = 0.24897 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:57:11.697471 ops/training.py:65 2019-01-17 07:57:11.697382: step 20367, loss = 0.22467 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:57:12.985526 ops/training.py:65 2019-01-17 07:57:12.985455: step 20368, loss = 0.24742 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:57:14.271464 ops/training.py:65 2019-01-17 07:57:14.271365: step 20369, loss = 0.21554 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:57:15.556215 ops/training.py:65 2019-01-17 07:57:15.556152: step 20370, loss = 0.27930 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:57:16.840205 ops/training.py:65 2019-01-17 07:57:16.840140: step 20371, loss = 0.20177 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:57:18.128300 ops/training.py:65 2019-01-17 07:57:18.128234: step 20372, loss = 0.19340 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:57:19.412191 ops/training.py:65 2019-01-17 07:57:19.412104: step 20373, loss = 0.18269 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:57:20.703828 ops/training.py:65 2019-01-17 07:57:20.703720: step 20374, loss = 0.23127 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:57:21.989659 ops/training.py:65 2019-01-17 07:57:21.989590: step 20375, loss = 0.21109 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:57:23.273152 ops/training.py:65 2019-01-17 07:57:23.273047: step 20376, loss = 0.17453 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:57:24.566662 ops/training.py:65 2019-01-17 07:57:24.566552: step 20377, loss = 0.22602 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:57:25.856780 ops/training.py:65 2019-01-17 07:57:25.856679: step 20378, loss = 0.17271 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:57:27.145845 ops/training.py:65 2019-01-17 07:57:27.145769: step 20379, loss = 0.17246 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:57:28.434810 ops/training.py:65 2019-01-17 07:57:28.434743: step 20380, loss = 0.20116 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:57:29.722152 ops/training.py:65 2019-01-17 07:57:29.722079: step 20381, loss = 0.23150 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:57:31.010457 ops/training.py:65 2019-01-17 07:57:31.010384: step 20382, loss = 0.19483 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:57:32.293930 ops/training.py:65 2019-01-17 07:57:32.293867: step 20383, loss = 0.24862 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:57:33.582201 ops/training.py:65 2019-01-17 07:57:33.582058: step 20384, loss = 0.20660 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:57:34.870243 ops/training.py:65 2019-01-17 07:57:34.870147: step 20385, loss = 0.17599 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:57:36.159437 ops/training.py:65 2019-01-17 07:57:36.159347: step 20386, loss = 0.25026 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:57:37.448179 ops/training.py:65 2019-01-17 07:57:37.448078: step 20387, loss = 0.22788 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:57:38.733438 ops/training.py:65 2019-01-17 07:57:38.733368: step 20388, loss = 0.15336 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:57:40.023931 ops/training.py:65 2019-01-17 07:57:40.023830: step 20389, loss = 0.18349 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:57:41.312105 ops/training.py:65 2019-01-17 07:57:41.312037: step 20390, loss = 0.19026 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:57:42.599838 ops/training.py:65 2019-01-17 07:57:42.599766: step 20391, loss = 0.22211 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:57:43.887566 ops/training.py:65 2019-01-17 07:57:43.887492: step 20392, loss = 0.24303 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:57:45.171058 ops/training.py:65 2019-01-17 07:57:45.170994: step 20393, loss = 0.21777 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:57:46.454980 ops/training.py:65 2019-01-17 07:57:46.454880: step 20394, loss = 0.30036 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:57:47.739427 ops/training.py:65 2019-01-17 07:57:47.739325: step 20395, loss = 0.26169 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:57:49.028821 ops/training.py:65 2019-01-17 07:57:49.028717: step 20396, loss = 0.27763 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:57:50.312735 ops/training.py:65 2019-01-17 07:57:50.312671: step 20397, loss = 0.18898 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:57:51.599676 ops/training.py:65 2019-01-17 07:57:51.599606: step 20398, loss = 0.24342 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:57:52.884419 ops/training.py:65 2019-01-17 07:57:52.884357: step 20399, loss = 0.21779 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:57:54.169071 ops/training.py:65 2019-01-17 07:57:54.168972: step 20400, loss = 0.22494 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:57:55.459244 ops/training.py:65 2019-01-17 07:57:55.459142: step 20401, loss = 0.22497 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:57:56.750729 ops/training.py:65 2019-01-17 07:57:56.750637: step 20402, loss = 0.18327 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:57:58.039985 ops/training.py:65 2019-01-17 07:57:58.039909: step 20403, loss = 0.20694 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:57:59.328524 ops/training.py:65 2019-01-17 07:57:59.328438: step 20404, loss = 0.19489 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:00.616786 ops/training.py:65 2019-01-17 07:58:00.616693: step 20405, loss = 0.18984 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:01.901758 ops/training.py:65 2019-01-17 07:58:01.901677: step 20406, loss = 0.25309 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:58:03.192988 ops/training.py:65 2019-01-17 07:58:03.192890: step 20407, loss = 0.15823 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:04.475114 ops/training.py:65 2019-01-17 07:58:04.475044: step 20408, loss = 0.18828 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:05.759899 ops/training.py:65 2019-01-17 07:58:05.759797: step 20409, loss = 0.22601 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:58:07.051922 ops/training.py:65 2019-01-17 07:58:07.051822: step 20410, loss = 0.19247 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:08.343398 ops/training.py:65 2019-01-17 07:58:08.343327: step 20411, loss = 0.27689 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:58:09.627677 ops/training.py:65 2019-01-17 07:58:09.627604: step 20412, loss = 0.16390 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:10.918901 ops/training.py:65 2019-01-17 07:58:10.918804: step 20413, loss = 0.16843 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:12.210662 ops/training.py:65 2019-01-17 07:58:12.210588: step 20414, loss = 0.20114 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:13.499742 ops/training.py:65 2019-01-17 07:58:13.499669: step 20415, loss = 0.17158 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:14.789109 ops/training.py:65 2019-01-17 07:58:14.789036: step 20416, loss = 0.22993 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:16.078593 ops/training.py:65 2019-01-17 07:58:16.078521: step 20417, loss = 0.18017 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:17.361492 ops/training.py:65 2019-01-17 07:58:17.361425: step 20418, loss = 0.19084 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:18.646875 ops/training.py:65 2019-01-17 07:58:18.646777: step 20419, loss = 0.21396 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:19.939060 ops/training.py:65 2019-01-17 07:58:19.938960: step 20420, loss = 0.26097 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:58:21.229464 ops/training.py:65 2019-01-17 07:58:21.229395: step 20421, loss = 0.16616 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:22.515066 ops/training.py:65 2019-01-17 07:58:22.514991: step 20422, loss = 0.24881 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:58:23.806127 ops/training.py:65 2019-01-17 07:58:23.806037: step 20423, loss = 0.19902 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:58:25.103772 ops/training.py:65 2019-01-17 07:58:25.103706: step 20424, loss = 0.25950 (24.7 examples/sec; 1.297 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:26.392444 ops/training.py:65 2019-01-17 07:58:26.392377: step 20425, loss = 0.24230 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:58:27.680341 ops/training.py:65 2019-01-17 07:58:27.680265: step 20426, loss = 0.19245 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:28.970486 ops/training.py:65 2019-01-17 07:58:28.970422: step 20427, loss = 0.21613 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:30.256459 ops/training.py:65 2019-01-17 07:58:30.256375: step 20428, loss = 0.20265 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:31.554006 ops/training.py:65 2019-01-17 07:58:31.553902: step 20429, loss = 0.20859 (24.7 examples/sec; 1.296 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:32.845137 ops/training.py:65 2019-01-17 07:58:32.845068: step 20430, loss = 0.19290 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:34.129844 ops/training.py:65 2019-01-17 07:58:34.129769: step 20431, loss = 0.20527 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:58:35.414857 ops/training.py:65 2019-01-17 07:58:35.414788: step 20432, loss = 0.22191 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:36.700219 ops/training.py:65 2019-01-17 07:58:36.700116: step 20433, loss = 0.19611 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:37.988044 ops/training.py:65 2019-01-17 07:58:37.987951: step 20434, loss = 0.19222 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:39.278924 ops/training.py:65 2019-01-17 07:58:39.278822: step 20435, loss = 0.18999 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:40.566885 ops/training.py:65 2019-01-17 07:58:40.566826: step 20436, loss = 0.24077 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:41.850284 ops/training.py:65 2019-01-17 07:58:41.850129: step 20437, loss = 0.22884 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:58:43.143207 ops/training.py:65 2019-01-17 07:58:43.143111: step 20438, loss = 0.23202 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:44.430133 ops/training.py:65 2019-01-17 07:58:44.430044: step 20439, loss = 0.18853 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:45.712556 ops/training.py:65 2019-01-17 07:58:45.712455: step 20440, loss = 0.19573 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:47.004009 ops/training.py:65 2019-01-17 07:58:47.003900: step 20441, loss = 0.17609 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:48.290626 ops/training.py:65 2019-01-17 07:58:48.290548: step 20442, loss = 0.19907 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:49.577236 ops/training.py:65 2019-01-17 07:58:49.577166: step 20443, loss = 0.22248 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:58:50.860933 ops/training.py:65 2019-01-17 07:58:50.860851: step 20444, loss = 0.22643 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:58:52.152472 ops/training.py:65 2019-01-17 07:58:52.152367: step 20445, loss = 0.29606 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 07:58:53.444219 ops/training.py:65 2019-01-17 07:58:53.444148: step 20446, loss = 0.19353 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:54.733635 ops/training.py:65 2019-01-17 07:58:54.733559: step 20447, loss = 0.21354 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:58:56.021612 ops/training.py:65 2019-01-17 07:58:56.021519: step 20448, loss = 0.23025 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:58:57.310642 ops/training.py:65 2019-01-17 07:58:57.310575: step 20449, loss = 0.29115 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:58:58.595412 ops/training.py:65 2019-01-17 07:58:58.595336: step 20450, loss = 0.17499 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:58:59.880066 ops/training.py:65 2019-01-17 07:58:59.879959: step 20451, loss = 0.23583 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:59:01.163933 ops/training.py:65 2019-01-17 07:59:01.163830: step 20452, loss = 0.18920 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:59:02.454052 ops/training.py:65 2019-01-17 07:59:02.453944: step 20453, loss = 0.18376 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:59:03.744361 ops/training.py:65 2019-01-17 07:59:03.744290: step 20454, loss = 0.22661 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:59:05.032917 ops/training.py:65 2019-01-17 07:59:05.032851: step 20455, loss = 0.21223 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:59:06.323030 ops/training.py:65 2019-01-17 07:59:06.322928: step 20456, loss = 0.20822 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:59:07.612116 ops/training.py:65 2019-01-17 07:59:07.612023: step 20457, loss = 0.18965 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:59:08.901375 ops/training.py:65 2019-01-17 07:59:08.901306: step 20458, loss = 0.28258 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:59:10.185951 ops/training.py:65 2019-01-17 07:59:10.185881: step 20459, loss = 0.27780 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:59:11.473967 ops/training.py:65 2019-01-17 07:59:11.473877: step 20460, loss = 0.18784 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:59:12.762300 ops/training.py:65 2019-01-17 07:59:12.762233: step 20461, loss = 0.31623 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 07:59:14.051292 ops/training.py:65 2019-01-17 07:59:14.051221: step 20462, loss = 0.20890 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:59:15.339473 ops/training.py:65 2019-01-17 07:59:15.339400: step 20463, loss = 0.17592 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:59:16.633807 ops/training.py:65 2019-01-17 07:59:16.633733: step 20464, loss = 0.23137 (24.7 examples/sec; 1.293 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:59:17.922911 ops/training.py:65 2019-01-17 07:59:17.922844: step 20465, loss = 0.24176 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:59:19.211745 ops/training.py:65 2019-01-17 07:59:19.211645: step 20466, loss = 0.18526 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:59:20.500750 ops/training.py:65 2019-01-17 07:59:20.500664: step 20467, loss = 0.19434 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:59:21.788802 ops/training.py:65 2019-01-17 07:59:21.788727: step 20468, loss = 0.23837 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:59:23.078487 ops/training.py:65 2019-01-17 07:59:23.078411: step 20469, loss = 0.20476 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:59:24.367141 ops/training.py:65 2019-01-17 07:59:24.367053: step 20470, loss = 0.19450 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:59:25.655185 ops/training.py:65 2019-01-17 07:59:25.655111: step 20471, loss = 0.19620 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:59:26.949945 ops/training.py:65 2019-01-17 07:59:26.949843: step 20472, loss = 0.24172 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:59:28.245447 ops/training.py:65 2019-01-17 07:59:28.245368: step 20473, loss = 0.22774 (24.7 examples/sec; 1.294 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:59:29.534751 ops/training.py:65 2019-01-17 07:59:29.534652: step 20474, loss = 0.19678 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:59:30.823776 ops/training.py:65 2019-01-17 07:59:30.823675: step 20475, loss = 0.19257 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:59:32.112008 ops/training.py:65 2019-01-17 07:59:32.111931: step 20476, loss = 0.15101 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:59:33.397302 ops/training.py:65 2019-01-17 07:59:33.397228: step 20477, loss = 0.17887 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:59:34.685648 ops/training.py:65 2019-01-17 07:59:34.685558: step 20478, loss = 0.20263 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:59:35.974445 ops/training.py:65 2019-01-17 07:59:35.974345: step 20479, loss = 0.18175 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:59:37.264288 ops/training.py:65 2019-01-17 07:59:37.264194: step 20480, loss = 0.23848 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:59:38.553829 ops/training.py:65 2019-01-17 07:59:38.553752: step 20481, loss = 0.17317 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:59:39.842882 ops/training.py:65 2019-01-17 07:59:39.842773: step 20482, loss = 0.19246 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:59:41.132390 ops/training.py:65 2019-01-17 07:59:41.132288: step 20483, loss = 0.16895 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:59:42.421003 ops/training.py:65 2019-01-17 07:59:42.420908: step 20484, loss = 0.16952 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:59:43.710170 ops/training.py:65 2019-01-17 07:59:43.710098: step 20485, loss = 0.22436 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:59:44.998936 ops/training.py:65 2019-01-17 07:59:44.998867: step 20486, loss = 0.18728 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:59:46.286828 ops/training.py:65 2019-01-17 07:59:46.286757: step 20487, loss = 0.19705 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:59:47.575717 ops/training.py:65 2019-01-17 07:59:47.575616: step 20488, loss = 0.17940 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:59:48.865005 ops/training.py:65 2019-01-17 07:59:48.864901: step 20489, loss = 0.17778 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:59:50.153664 ops/training.py:65 2019-01-17 07:59:50.153592: step 20490, loss = 0.19289 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:59:51.443776 ops/training.py:65 2019-01-17 07:59:51.443701: step 20491, loss = 0.25196 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:59:52.732645 ops/training.py:65 2019-01-17 07:59:52.732557: step 20492, loss = 0.22252 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:59:54.020403 ops/training.py:65 2019-01-17 07:59:54.020331: step 20493, loss = 0.18700 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:59:55.308508 ops/training.py:65 2019-01-17 07:59:55.308404: step 20494, loss = 0.22168 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 07:59:56.597223 ops/training.py:65 2019-01-17 07:59:56.597152: step 20495, loss = 0.18616 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 07:59:57.885102 ops/training.py:65 2019-01-17 07:59:57.885030: step 20496, loss = 0.17801 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 07:59:59.168349 ops/training.py:65 2019-01-17 07:59:59.168290: step 20497, loss = 0.20212 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:00:00.448266 ops/training.py:65 2019-01-17 08:00:00.448155: step 20498, loss = 0.21098 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:00:01.732258 ops/training.py:65 2019-01-17 08:00:01.732120: step 20499, loss = 0.20185 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:00:03.025892 ops/training.py:65 2019-01-17 08:00:03.025793: step 20500, loss = 0.18064 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:00:04.312783 ops/training.py:65 2019-01-17 08:00:04.312716: step 20501, loss = 0.25072 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:00:05.602938 ops/training.py:65 2019-01-17 08:00:05.602829: step 20502, loss = 0.25116 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 08:00:06.893705 ops/training.py:65 2019-01-17 08:00:06.893638: step 20503, loss = 0.20339 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:00:08.177446 ops/training.py:65 2019-01-17 08:00:08.177379: step 20504, loss = 0.18600 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:00:09.461334 ops/training.py:65 2019-01-17 08:00:09.461231: step 20505, loss = 0.23112 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 08:00:10.749748 ops/training.py:65 2019-01-17 08:00:10.749640: step 20506, loss = 0.30461 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.875
I4672 2019-01-17 08:00:12.037265 ops/training.py:65 2019-01-17 08:00:12.037117: step 20507, loss = 0.24310 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:00:13.328510 ops/training.py:65 2019-01-17 08:00:13.328442: step 20508, loss = 0.28706 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 08:00:14.618105 ops/training.py:65 2019-01-17 08:00:14.618022: step 20509, loss = 0.22909 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 08:00:15.906901 ops/training.py:65 2019-01-17 08:00:15.906817: step 20510, loss = 0.19761 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:00:17.196371 ops/training.py:65 2019-01-17 08:00:17.196307: step 20511, loss = 0.21208 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 08:00:18.481241 ops/training.py:65 2019-01-17 08:00:18.481174: step 20512, loss = 0.18149 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:00:19.765793 ops/training.py:65 2019-01-17 08:00:19.765729: step 20513, loss = 0.23512 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:00:21.051427 ops/training.py:65 2019-01-17 08:00:21.051342: step 20514, loss = 0.20662 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:00:22.339574 ops/training.py:65 2019-01-17 08:00:22.339483: step 20515, loss = 0.20424 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:00:23.623954 ops/training.py:65 2019-01-17 08:00:23.623883: step 20516, loss = 0.16823 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:00:24.906670 ops/training.py:65 2019-01-17 08:00:24.906604: step 20517, loss = 0.20071 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:00:26.197011 ops/training.py:65 2019-01-17 08:00:26.196904: step 20518, loss = 0.15800 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:00:27.486503 ops/training.py:65 2019-01-17 08:00:27.486416: step 20519, loss = 0.19293 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:00:28.770435 ops/training.py:65 2019-01-17 08:00:28.770371: step 20520, loss = 0.19895 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:00:30.055896 ops/training.py:65 2019-01-17 08:00:30.055794: step 20521, loss = 0.20069 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:00:31.346431 ops/training.py:65 2019-01-17 08:00:31.346326: step 20522, loss = 0.23204 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 08:00:32.630965 ops/training.py:65 2019-01-17 08:00:32.630899: step 20523, loss = 0.19336 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:00:33.913800 ops/training.py:65 2019-01-17 08:00:33.913726: step 20524, loss = 0.22591 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:00:35.204769 ops/training.py:65 2019-01-17 08:00:35.204666: step 20525, loss = 0.20114 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:00:36.495147 ops/training.py:65 2019-01-17 08:00:36.495075: step 20526, loss = 0.23958 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:00:37.779595 ops/training.py:65 2019-01-17 08:00:37.779531: step 20527, loss = 0.18981 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:00:39.067207 ops/training.py:65 2019-01-17 08:00:39.067137: step 20528, loss = 0.15973 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:00:40.356816 ops/training.py:65 2019-01-17 08:00:40.356714: step 20529, loss = 0.18659 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:00:41.646545 ops/training.py:65 2019-01-17 08:00:41.646467: step 20530, loss = 0.24328 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:00:42.929652 ops/training.py:65 2019-01-17 08:00:42.929562: step 20531, loss = 0.19013 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:00:44.217222 ops/training.py:65 2019-01-17 08:00:44.217117: step 20532, loss = 0.18276 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:00:45.508004 ops/training.py:65 2019-01-17 08:00:45.507929: step 20533, loss = 0.18926 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:00:46.797669 ops/training.py:65 2019-01-17 08:00:46.797594: step 20534, loss = 0.22914 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:00:48.087336 ops/training.py:65 2019-01-17 08:00:48.087264: step 20535, loss = 0.21390 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:00:49.376472 ops/training.py:65 2019-01-17 08:00:49.376373: step 20536, loss = 0.24756 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 08:00:50.665330 ops/training.py:65 2019-01-17 08:00:50.665252: step 20537, loss = 0.23570 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:00:51.953477 ops/training.py:65 2019-01-17 08:00:51.953375: step 20538, loss = 0.25809 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 08:00:53.237118 ops/training.py:65 2019-01-17 08:00:53.237041: step 20539, loss = 0.24565 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 08:00:54.530010 ops/training.py:65 2019-01-17 08:00:54.529899: step 20540, loss = 0.20854 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:00:55.815311 ops/training.py:65 2019-01-17 08:00:55.815243: step 20541, loss = 0.17565 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:00:57.104263 ops/training.py:65 2019-01-17 08:00:57.104119: step 20542, loss = 0.21394 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:00:58.389726 ops/training.py:65 2019-01-17 08:00:58.389651: step 20543, loss = 0.18214 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:00:59.670454 ops/training.py:65 2019-01-17 08:00:59.670297: step 20544, loss = 0.21589 (25.0 examples/sec; 1.280 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:01:00.958708 ops/training.py:65 2019-01-17 08:01:00.958601: step 20545, loss = 0.23535 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:01:02.238116 ops/training.py:65 2019-01-17 08:01:02.238023: step 20546, loss = 0.19314 (25.0 examples/sec; 1.278 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:01:03.530302 ops/training.py:65 2019-01-17 08:01:03.530192: step 20547, loss = 0.21208 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:01:04.820804 ops/training.py:65 2019-01-17 08:01:04.820703: step 20548, loss = 0.18259 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:01:06.111647 ops/training.py:65 2019-01-17 08:01:06.111555: step 20549, loss = 0.18747 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:01:07.401056 ops/training.py:65 2019-01-17 08:01:07.400992: step 20550, loss = 0.22183 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:01:08.687639 ops/training.py:65 2019-01-17 08:01:08.687555: step 20551, loss = 0.19704 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:01:09.972558 ops/training.py:65 2019-01-17 08:01:09.972479: step 20552, loss = 0.23036 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:01:11.256282 ops/training.py:65 2019-01-17 08:01:11.256205: step 20553, loss = 0.17384 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:01:12.548594 ops/training.py:65 2019-01-17 08:01:12.548494: step 20554, loss = 0.21688 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:01:13.840438 ops/training.py:65 2019-01-17 08:01:13.840360: step 20555, loss = 0.24090 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:01:15.129351 ops/training.py:65 2019-01-17 08:01:15.129275: step 20556, loss = 0.21244 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:01:16.417504 ops/training.py:65 2019-01-17 08:01:16.417434: step 20557, loss = 0.19577 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:01:17.706777 ops/training.py:65 2019-01-17 08:01:17.706706: step 20558, loss = 0.24997 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:01:18.995745 ops/training.py:65 2019-01-17 08:01:18.995649: step 20559, loss = 0.17837 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:01:20.283663 ops/training.py:65 2019-01-17 08:01:20.283588: step 20560, loss = 0.20692 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:01:21.572451 ops/training.py:65 2019-01-17 08:01:21.572365: step 20561, loss = 0.21822 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 08:01:22.860491 ops/training.py:65 2019-01-17 08:01:22.860394: step 20562, loss = 0.18776 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:01:24.149335 ops/training.py:65 2019-01-17 08:01:24.149265: step 20563, loss = 0.17206 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:01:25.437729 ops/training.py:65 2019-01-17 08:01:25.437651: step 20564, loss = 0.21332 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:01:26.726408 ops/training.py:65 2019-01-17 08:01:26.726341: step 20565, loss = 0.20015 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:01:28.014580 ops/training.py:65 2019-01-17 08:01:28.014505: step 20566, loss = 0.19203 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:01:29.303735 ops/training.py:65 2019-01-17 08:01:29.303642: step 20567, loss = 0.20249 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:01:30.593674 ops/training.py:65 2019-01-17 08:01:30.593598: step 20568, loss = 0.19823 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:01:31.882558 ops/training.py:65 2019-01-17 08:01:31.882480: step 20569, loss = 0.17306 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:01:33.171446 ops/training.py:65 2019-01-17 08:01:33.171372: step 20570, loss = 0.19650 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 08:01:34.459844 ops/training.py:65 2019-01-17 08:01:34.459746: step 20571, loss = 0.22683 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:01:35.742993 ops/training.py:65 2019-01-17 08:01:35.742926: step 20572, loss = 0.20393 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 08:01:37.036394 ops/training.py:65 2019-01-17 08:01:37.036329: step 20573, loss = 0.21160 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:01:38.325219 ops/training.py:65 2019-01-17 08:01:38.325160: step 20574, loss = 0.15690 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:01:39.607643 ops/training.py:65 2019-01-17 08:01:39.607578: step 20575, loss = 0.20688 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:01:40.893554 ops/training.py:65 2019-01-17 08:01:40.893445: step 20576, loss = 0.16486 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:01:42.176995 ops/training.py:65 2019-01-17 08:01:42.176889: step 20577, loss = 0.19186 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:01:43.468017 ops/training.py:65 2019-01-17 08:01:43.467917: step 20578, loss = 0.18263 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:01:44.754434 ops/training.py:65 2019-01-17 08:01:44.754367: step 20579, loss = 0.21052 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:01:46.039743 ops/training.py:65 2019-01-17 08:01:46.039635: step 20580, loss = 0.21007 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:01:47.330850 ops/training.py:65 2019-01-17 08:01:47.330783: step 20581, loss = 0.17362 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:01:48.618600 ops/training.py:65 2019-01-17 08:01:48.618531: step 20582, loss = 0.20941 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 08:01:49.904434 ops/training.py:65 2019-01-17 08:01:49.904363: step 20583, loss = 0.18740 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:01:51.197192 ops/training.py:65 2019-01-17 08:01:51.197081: step 20584, loss = 0.19182 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:01:52.483780 ops/training.py:65 2019-01-17 08:01:52.483672: step 20585, loss = 0.20273 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:01:53.776678 ops/training.py:65 2019-01-17 08:01:53.776582: step 20586, loss = 0.20708 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:01:55.067809 ops/training.py:65 2019-01-17 08:01:55.067741: step 20587, loss = 0.18392 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:01:56.352874 ops/training.py:65 2019-01-17 08:01:56.352802: step 20588, loss = 0.21678 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:01:57.640426 ops/training.py:65 2019-01-17 08:01:57.640356: step 20589, loss = 0.17315 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:01:58.929372 ops/training.py:65 2019-01-17 08:01:58.929304: step 20590, loss = 0.26679 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:00.213255 ops/training.py:65 2019-01-17 08:02:00.213191: step 20591, loss = 0.19664 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:02:01.498693 ops/training.py:65 2019-01-17 08:02:01.498584: step 20592, loss = 0.23622 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 08:02:02.790924 ops/training.py:65 2019-01-17 08:02:02.790812: step 20593, loss = 0.19235 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:04.078135 ops/training.py:65 2019-01-17 08:02:04.078066: step 20594, loss = 0.21030 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:02:05.366849 ops/training.py:65 2019-01-17 08:02:05.366783: step 20595, loss = 0.20188 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:06.655720 ops/training.py:65 2019-01-17 08:02:06.655629: step 20596, loss = 0.23065 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 08:02:07.945039 ops/training.py:65 2019-01-17 08:02:07.944970: step 20597, loss = 0.19038 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:09.233325 ops/training.py:65 2019-01-17 08:02:09.233243: step 20598, loss = 0.19218 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:10.522009 ops/training.py:65 2019-01-17 08:02:10.521938: step 20599, loss = 0.19785 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:11.810666 ops/training.py:65 2019-01-17 08:02:11.810597: step 20600, loss = 0.21408 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:13.099095 ops/training.py:65 2019-01-17 08:02:13.099017: step 20601, loss = 0.20999 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:02:14.388063 ops/training.py:65 2019-01-17 08:02:14.387963: step 20602, loss = 0.17973 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:15.673545 ops/training.py:65 2019-01-17 08:02:15.673466: step 20603, loss = 0.22632 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:16.967093 ops/training.py:65 2019-01-17 08:02:16.966992: step 20604, loss = 0.21537 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:18.253655 ops/training.py:65 2019-01-17 08:02:18.253592: step 20605, loss = 0.19976 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:19.542781 ops/training.py:65 2019-01-17 08:02:19.542672: step 20606, loss = 0.21315 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:02:20.824972 ops/training.py:65 2019-01-17 08:02:20.824908: step 20607, loss = 0.21965 (25.0 examples/sec; 1.281 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:22.114083 ops/training.py:65 2019-01-17 08:02:22.113978: step 20608, loss = 0.16810 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:23.400091 ops/training.py:65 2019-01-17 08:02:23.400026: step 20609, loss = 0.20872 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:02:24.690214 ops/training.py:65 2019-01-17 08:02:24.690115: step 20610, loss = 0.17860 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:25.978770 ops/training.py:65 2019-01-17 08:02:25.978701: step 20611, loss = 0.20897 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:27.267708 ops/training.py:65 2019-01-17 08:02:27.267607: step 20612, loss = 0.21248 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:02:28.558256 ops/training.py:65 2019-01-17 08:02:28.558166: step 20613, loss = 0.17997 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:02:29.846853 ops/training.py:65 2019-01-17 08:02:29.846753: step 20614, loss = 0.20997 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:31.135844 ops/training.py:65 2019-01-17 08:02:31.135777: step 20615, loss = 0.18273 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:32.424406 ops/training.py:65 2019-01-17 08:02:32.424312: step 20616, loss = 0.22554 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:33.713403 ops/training.py:65 2019-01-17 08:02:33.713333: step 20617, loss = 0.24251 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:02:34.997264 ops/training.py:65 2019-01-17 08:02:34.997192: step 20618, loss = 0.18257 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:36.283731 ops/training.py:65 2019-01-17 08:02:36.283620: step 20619, loss = 0.20060 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:37.575082 ops/training.py:65 2019-01-17 08:02:37.574980: step 20620, loss = 0.23832 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:02:38.867041 ops/training.py:65 2019-01-17 08:02:38.866941: step 20621, loss = 0.25440 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 08:02:40.156918 ops/training.py:65 2019-01-17 08:02:40.156849: step 20622, loss = 0.18495 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:41.445501 ops/training.py:65 2019-01-17 08:02:41.445415: step 20623, loss = 0.18340 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:42.731970 ops/training.py:65 2019-01-17 08:02:42.731901: step 20624, loss = 0.15857 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:44.015601 ops/training.py:65 2019-01-17 08:02:44.015502: step 20625, loss = 0.19394 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:45.303035 ops/training.py:65 2019-01-17 08:02:45.302925: step 20626, loss = 0.19157 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:46.594554 ops/training.py:65 2019-01-17 08:02:46.594444: step 20627, loss = 0.21531 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:02:47.879417 ops/training.py:65 2019-01-17 08:02:47.879337: step 20628, loss = 0.23885 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:49.171205 ops/training.py:65 2019-01-17 08:02:49.171100: step 20629, loss = 0.20554 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:50.456912 ops/training.py:65 2019-01-17 08:02:50.456851: step 20630, loss = 0.18233 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:51.745039 ops/training.py:65 2019-01-17 08:02:51.744929: step 20631, loss = 0.21320 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:53.030258 ops/training.py:65 2019-01-17 08:02:53.030187: step 20632, loss = 0.19564 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:54.315932 ops/training.py:65 2019-01-17 08:02:54.315842: step 20633, loss = 0.16448 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:55.600604 ops/training.py:65 2019-01-17 08:02:55.600499: step 20634, loss = 0.16915 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:02:56.887887 ops/training.py:65 2019-01-17 08:02:56.887777: step 20635, loss = 0.17371 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:58.167723 ops/training.py:65 2019-01-17 08:02:58.167621: step 20636, loss = 0.16866 (25.0 examples/sec; 1.279 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:02:59.458965 ops/training.py:65 2019-01-17 08:02:59.458853: step 20637, loss = 0.20813 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:03:00.749617 ops/training.py:65 2019-01-17 08:03:00.749466: step 20638, loss = 0.19096 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:03:02.036113 ops/training.py:65 2019-01-17 08:03:02.036011: step 20639, loss = 0.21785 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:03:03.320116 ops/training.py:65 2019-01-17 08:03:03.320006: step 20640, loss = 0.18616 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:03:04.605449 ops/training.py:65 2019-01-17 08:03:04.605308: step 20641, loss = 0.17735 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:03:05.892005 ops/training.py:65 2019-01-17 08:03:05.891895: step 20642, loss = 0.20795 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:03:07.178426 ops/training.py:65 2019-01-17 08:03:07.178275: step 20643, loss = 0.17828 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:03:08.465406 ops/training.py:65 2019-01-17 08:03:08.465318: step 20644, loss = 0.19280 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:03:09.757982 ops/training.py:65 2019-01-17 08:03:09.757883: step 20645, loss = 0.20960 (24.8 examples/sec; 1.291 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:03:11.053715 ops/training.py:65 2019-01-17 08:03:11.053652: step 20646, loss = 0.18551 (24.7 examples/sec; 1.295 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:03:12.342699 ops/training.py:65 2019-01-17 08:03:12.342617: step 20647, loss = 0.21540 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:03:13.626292 ops/training.py:65 2019-01-17 08:03:13.626222: step 20648, loss = 0.21688 (25.0 examples/sec; 1.283 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:03:14.915473 ops/training.py:65 2019-01-17 08:03:14.915375: step 20649, loss = 0.22675 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:03:16.206198 ops/training.py:65 2019-01-17 08:03:16.206106: step 20650, loss = 0.26317 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:03:17.494967 ops/training.py:65 2019-01-17 08:03:17.494899: step 20651, loss = 0.21751 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:03:18.783852 ops/training.py:65 2019-01-17 08:03:18.783766: step 20652, loss = 0.20408 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:03:20.071621 ops/training.py:65 2019-01-17 08:03:20.071556: step 20653, loss = 0.21848 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:03:21.360785 ops/training.py:65 2019-01-17 08:03:21.360719: step 20654, loss = 0.21153 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 08:03:22.645952 ops/training.py:65 2019-01-17 08:03:22.645884: step 20655, loss = 0.22314 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:03:23.934893 ops/training.py:65 2019-01-17 08:03:23.934767: step 20656, loss = 0.21097 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:03:25.224664 ops/training.py:65 2019-01-17 08:03:25.224589: step 20657, loss = 0.19665 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:03:26.513726 ops/training.py:65 2019-01-17 08:03:26.513646: step 20658, loss = 0.19834 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:03:27.803427 ops/training.py:65 2019-01-17 08:03:27.803316: step 20659, loss = 0.19947 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:03:29.093202 ops/training.py:65 2019-01-17 08:03:29.093123: step 20660, loss = 0.14407 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:03:30.382231 ops/training.py:65 2019-01-17 08:03:30.382157: step 20661, loss = 0.19570 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:03:31.671349 ops/training.py:65 2019-01-17 08:03:31.671256: step 20662, loss = 0.22483 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:03:32.959516 ops/training.py:65 2019-01-17 08:03:32.959433: step 20663, loss = 0.21799 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:03:34.247430 ops/training.py:65 2019-01-17 08:03:34.247353: step 20664, loss = 0.17461 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:03:35.535985 ops/training.py:65 2019-01-17 08:03:35.535915: step 20665, loss = 0.19360 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:03:36.824872 ops/training.py:65 2019-01-17 08:03:36.824793: step 20666, loss = 0.19912 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:03:38.114245 ops/training.py:65 2019-01-17 08:03:38.114149: step 20667, loss = 0.28969 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 08:03:39.398391 ops/training.py:65 2019-01-17 08:03:39.398325: step 20668, loss = 0.19559 (24.9 examples/sec; 1.283 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:03:40.686942 ops/training.py:65 2019-01-17 08:03:40.686844: step 20669, loss = 0.25820 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 08:03:41.976247 ops/training.py:65 2019-01-17 08:03:41.976176: step 20670, loss = 0.23526 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:03:43.261582 ops/training.py:65 2019-01-17 08:03:43.261486: step 20671, loss = 0.28161 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 08:03:44.551431 ops/training.py:65 2019-01-17 08:03:44.551360: step 20672, loss = 0.25361 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.90625
I4672 2019-01-17 08:03:45.839452 ops/training.py:65 2019-01-17 08:03:45.839380: step 20673, loss = 0.26363 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 08:03:47.126985 ops/training.py:65 2019-01-17 08:03:47.126917: step 20674, loss = 0.19457 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:03:48.416001 ops/training.py:65 2019-01-17 08:03:48.415903: step 20675, loss = 0.18329 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:03:49.703878 ops/training.py:65 2019-01-17 08:03:49.703810: step 20676, loss = 0.16863 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:03:50.993160 ops/training.py:65 2019-01-17 08:03:50.993075: step 20677, loss = 0.17189 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:03:52.282655 ops/training.py:65 2019-01-17 08:03:52.282587: step 20678, loss = 0.20493 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:03:53.571574 ops/training.py:65 2019-01-17 08:03:53.571499: step 20679, loss = 0.21653 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:03:54.859900 ops/training.py:65 2019-01-17 08:03:54.859806: step 20680, loss = 0.16478 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:03:56.150357 ops/training.py:65 2019-01-17 08:03:56.150277: step 20681, loss = 0.24802 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:03:57.438699 ops/training.py:65 2019-01-17 08:03:57.438628: step 20682, loss = 0.17244 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:03:58.727603 ops/training.py:65 2019-01-17 08:03:58.727526: step 20683, loss = 0.13244 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:04:00.015454 ops/training.py:65 2019-01-17 08:04:00.015376: step 20684, loss = 0.16785 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:04:01.303352 ops/training.py:65 2019-01-17 08:04:01.303246: step 20685, loss = 0.19962 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:04:02.593194 ops/training.py:65 2019-01-17 08:04:02.593120: step 20686, loss = 0.19838 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:04:03.882960 ops/training.py:65 2019-01-17 08:04:03.882881: step 20687, loss = 0.19291 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:04:05.172391 ops/training.py:65 2019-01-17 08:04:05.172307: step 20688, loss = 0.23868 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 08:04:06.459189 ops/training.py:65 2019-01-17 08:04:06.459105: step 20689, loss = 0.19841 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:04:07.752946 ops/training.py:65 2019-01-17 08:04:07.752800: step 20690, loss = 0.18311 (24.8 examples/sec; 1.292 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:04:09.039118 ops/training.py:65 2019-01-17 08:04:09.039053: step 20691, loss = 0.18572 (24.9 examples/sec; 1.285 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:04:10.322092 ops/training.py:65 2019-01-17 08:04:10.321987: step 20692, loss = 0.19234 (25.0 examples/sec; 1.282 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:04:11.613721 ops/training.py:65 2019-01-17 08:04:11.613565: step 20693, loss = 0.18019 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:04:12.905086 ops/training.py:65 2019-01-17 08:04:12.905012: step 20694, loss = 0.17720 (24.8 examples/sec; 1.290 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:04:14.194295 ops/training.py:65 2019-01-17 08:04:14.194208: step 20695, loss = 0.21113 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:04:15.483044 ops/training.py:65 2019-01-17 08:04:15.482954: step 20696, loss = 0.26728 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:04:16.774828 ops/training.py:65 2019-01-17 08:04:16.774765: step 20697, loss = 0.25197 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 08:04:18.064099 ops/training.py:65 2019-01-17 08:04:18.064028: step 20698, loss = 0.14874 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:04:19.351688 ops/training.py:65 2019-01-17 08:04:19.351627: step 20699, loss = 0.23150 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:04:20.639704 ops/training.py:65 2019-01-17 08:04:20.639611: step 20700, loss = 0.19633 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:04:21.924628 ops/training.py:65 2019-01-17 08:04:21.924556: step 20701, loss = 0.25432 (24.9 examples/sec; 1.284 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:04:23.213537 ops/training.py:65 2019-01-17 08:04:23.213403: step 20702, loss = 0.18418 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:04:24.502394 ops/training.py:65 2019-01-17 08:04:24.502327: step 20703, loss = 0.22664 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:04:25.790664 ops/training.py:65 2019-01-17 08:04:25.790568: step 20704, loss = 0.18274 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:04:27.079071 ops/training.py:65 2019-01-17 08:04:27.078995: step 20705, loss = 0.18865 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:04:28.366815 ops/training.py:65 2019-01-17 08:04:28.366736: step 20706, loss = 0.14556 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:04:29.655610 ops/training.py:65 2019-01-17 08:04:29.655526: step 20707, loss = 0.24245 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:04:30.943334 ops/training.py:65 2019-01-17 08:04:30.943247: step 20708, loss = 0.17979 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:04:32.231498 ops/training.py:65 2019-01-17 08:04:32.231418: step 20709, loss = 0.21431 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:04:33.519329 ops/training.py:65 2019-01-17 08:04:33.519255: step 20710, loss = 0.18402 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:04:34.807888 ops/training.py:65 2019-01-17 08:04:34.807814: step 20711, loss = 0.21096 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:04:36.096990 ops/training.py:65 2019-01-17 08:04:36.096898: step 20712, loss = 0.15709 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:04:37.385245 ops/training.py:65 2019-01-17 08:04:37.385176: step 20713, loss = 0.18550 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:04:38.673840 ops/training.py:65 2019-01-17 08:04:38.673750: step 20714, loss = 0.22407 (24.9 examples/sec; 1.288 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:04:39.961733 ops/training.py:65 2019-01-17 08:04:39.961634: step 20715, loss = 0.19352 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:04:41.250236 ops/training.py:65 2019-01-17 08:04:41.250164: step 20716, loss = 0.18390 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:04:42.537633 ops/training.py:65 2019-01-17 08:04:42.537555: step 20717, loss = 0.22276 (24.9 examples/sec; 1.286 sec/batch) | Training accuracy = 0.96875
I4672 2019-01-17 08:04:43.827625 ops/training.py:65 2019-01-17 08:04:43.827521: step 20718, loss = 0.19944 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:04:45.117451 ops/training.py:65 2019-01-17 08:04:45.117358: step 20719, loss = 0.22687 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 0.9375
I4672 2019-01-17 08:04:46.407185 ops/training.py:65 2019-01-17 08:04:46.407091: step 20720, loss = 0.20140 (24.8 examples/sec; 1.288 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:04:47.697081 ops/training.py:65 2019-01-17 08:04:47.697012: step 20721, loss = 0.18065 (24.8 examples/sec; 1.289 sec/batch) | Training accuracy = 1.0
I4672 2019-01-17 08:04:48.985440 ops/training.py:65 2019-01-17 08:04:48.985358: step 20722, loss = 0.20772 (24.9 examples/sec; 1.287 sec/batch) | Training accuracy = 1.0
