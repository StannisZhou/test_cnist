I1280 2019-01-16 19:27:05.812209 ops/training.py:229 Log written to /gpfs_home/dlinsley/cluttered_nist_experiments/logs/nist_3_ix2v2_50k_2019_01_16_19_26_22_049623
I1280 2019-01-16 19:31:44.064720 ops/training.py:396 Failed to save checkpoint: global name 'db' is not defined
I1280 2019-01-16 19:31:44.065551 ops/training.py:41 2019-01-16 19:31:44.065500: step 0, loss = 0.76 (0.1 examples/sec; 260.693 sec/batch) | Training accuracy = 0.46875 | Validation accuracy = 0.50225 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_19_26_22_049623
I1280 2019-01-16 19:31:44.983936 ops/training.py:65 2019-01-16 19:31:44.983905: step 1, loss = 0.76238 (34.9 examples/sec; 0.918 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:31:45.879209 ops/training.py:65 2019-01-16 19:31:45.879145: step 2, loss = 0.77289 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:31:46.772916 ops/training.py:65 2019-01-16 19:31:46.772865: step 3, loss = 0.70446 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:31:47.667117 ops/training.py:65 2019-01-16 19:31:47.667068: step 4, loss = 0.72167 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:31:48.560563 ops/training.py:65 2019-01-16 19:31:48.560515: step 5, loss = 0.77633 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:31:49.455185 ops/training.py:65 2019-01-16 19:31:49.455128: step 6, loss = 0.69724 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:31:50.349889 ops/training.py:65 2019-01-16 19:31:50.349817: step 7, loss = 0.82669 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:31:51.246027 ops/training.py:65 2019-01-16 19:31:51.245948: step 8, loss = 0.74252 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:31:52.142014 ops/training.py:65 2019-01-16 19:31:52.141950: step 9, loss = 0.70367 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:31:53.037760 ops/training.py:65 2019-01-16 19:31:53.037691: step 10, loss = 0.76897 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:31:53.933817 ops/training.py:65 2019-01-16 19:31:53.933752: step 11, loss = 0.63040 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.75
I1280 2019-01-16 19:31:54.829446 ops/training.py:65 2019-01-16 19:31:54.829396: step 12, loss = 0.71930 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:31:55.723510 ops/training.py:65 2019-01-16 19:31:55.723464: step 13, loss = 0.70418 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:31:56.618062 ops/training.py:65 2019-01-16 19:31:56.618015: step 14, loss = 0.83294 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:31:57.511931 ops/training.py:65 2019-01-16 19:31:57.511888: step 15, loss = 0.76926 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:31:58.407235 ops/training.py:65 2019-01-16 19:31:58.407189: step 16, loss = 0.68898 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:31:59.300994 ops/training.py:65 2019-01-16 19:31:59.300953: step 17, loss = 0.71205 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:32:00.194047 ops/training.py:65 2019-01-16 19:32:00.193997: step 18, loss = 0.73646 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:32:01.087928 ops/training.py:65 2019-01-16 19:32:01.087883: step 19, loss = 0.71706 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:32:01.981647 ops/training.py:65 2019-01-16 19:32:01.981604: step 20, loss = 0.66522 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:32:02.875966 ops/training.py:65 2019-01-16 19:32:02.875919: step 21, loss = 0.72335 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:32:03.770445 ops/training.py:65 2019-01-16 19:32:03.770398: step 22, loss = 0.69813 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:32:04.664320 ops/training.py:65 2019-01-16 19:32:04.664267: step 23, loss = 0.64113 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.75
I1280 2019-01-16 19:32:05.561237 ops/training.py:65 2019-01-16 19:32:05.561178: step 24, loss = 0.66834 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:32:06.456360 ops/training.py:65 2019-01-16 19:32:06.456306: step 25, loss = 0.76838 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:32:07.351155 ops/training.py:65 2019-01-16 19:32:07.351078: step 26, loss = 0.72228 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:32:08.245558 ops/training.py:65 2019-01-16 19:32:08.245485: step 27, loss = 0.69255 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:32:09.140956 ops/training.py:65 2019-01-16 19:32:09.140892: step 28, loss = 0.68224 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:32:10.035239 ops/training.py:65 2019-01-16 19:32:10.035189: step 29, loss = 0.72122 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:32:10.929105 ops/training.py:65 2019-01-16 19:32:10.929054: step 30, loss = 0.68117 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:32:11.823305 ops/training.py:65 2019-01-16 19:32:11.823258: step 31, loss = 0.73370 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:32:12.716369 ops/training.py:65 2019-01-16 19:32:12.716330: step 32, loss = 0.63770 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.75
I1280 2019-01-16 19:32:13.609695 ops/training.py:65 2019-01-16 19:32:13.609642: step 33, loss = 0.73454 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:32:14.504068 ops/training.py:65 2019-01-16 19:32:14.504020: step 34, loss = 0.71323 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:32:15.397173 ops/training.py:65 2019-01-16 19:32:15.397124: step 35, loss = 0.68241 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:32:16.290661 ops/training.py:65 2019-01-16 19:32:16.290592: step 36, loss = 0.71037 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:32:17.185708 ops/training.py:65 2019-01-16 19:32:17.185663: step 37, loss = 0.71121 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:32:18.081569 ops/training.py:65 2019-01-16 19:32:18.081518: step 38, loss = 0.71558 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:32:18.976053 ops/training.py:65 2019-01-16 19:32:18.976011: step 39, loss = 0.70213 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:32:19.873305 ops/training.py:65 2019-01-16 19:32:19.873263: step 40, loss = 0.75008 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:32:20.769795 ops/training.py:65 2019-01-16 19:32:20.769758: step 41, loss = 0.67396 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:32:21.664656 ops/training.py:65 2019-01-16 19:32:21.664611: step 42, loss = 0.70873 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:32:22.559082 ops/training.py:65 2019-01-16 19:32:22.559033: step 43, loss = 0.77230 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:32:23.452417 ops/training.py:65 2019-01-16 19:32:23.452369: step 44, loss = 0.75283 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:32:24.345215 ops/training.py:65 2019-01-16 19:32:24.345168: step 45, loss = 0.66168 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:32:25.242696 ops/training.py:65 2019-01-16 19:32:25.242650: step 46, loss = 0.77666 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:32:26.137119 ops/training.py:65 2019-01-16 19:32:26.137074: step 47, loss = 0.67633 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:32:27.032589 ops/training.py:65 2019-01-16 19:32:27.032508: step 48, loss = 0.70787 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:32:27.930109 ops/training.py:65 2019-01-16 19:32:27.930035: step 49, loss = 0.65295 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:32:28.826474 ops/training.py:65 2019-01-16 19:32:28.826413: step 50, loss = 0.70515 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:32:29.719903 ops/training.py:65 2019-01-16 19:32:29.719851: step 51, loss = 0.70239 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:32:30.612369 ops/training.py:65 2019-01-16 19:32:30.612324: step 52, loss = 0.74117 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:32:31.505568 ops/training.py:65 2019-01-16 19:32:31.505517: step 53, loss = 0.70519 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:32:32.400450 ops/training.py:65 2019-01-16 19:32:32.400405: step 54, loss = 0.70007 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:32:33.295903 ops/training.py:65 2019-01-16 19:32:33.295824: step 55, loss = 0.68780 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:32:34.189773 ops/training.py:65 2019-01-16 19:32:34.189705: step 56, loss = 0.72680 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:32:35.082570 ops/training.py:65 2019-01-16 19:32:35.082511: step 57, loss = 0.70647 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:32:35.976539 ops/training.py:65 2019-01-16 19:32:35.976459: step 58, loss = 0.67569 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:32:36.870548 ops/training.py:65 2019-01-16 19:32:36.870442: step 59, loss = 0.74005 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:32:37.764723 ops/training.py:65 2019-01-16 19:32:37.764644: step 60, loss = 0.72062 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:32:38.660997 ops/training.py:65 2019-01-16 19:32:38.660938: step 61, loss = 0.73559 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:32:39.555748 ops/training.py:65 2019-01-16 19:32:39.555674: step 62, loss = 0.73423 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:32:40.451068 ops/training.py:65 2019-01-16 19:32:40.451002: step 63, loss = 0.70700 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:32:41.344813 ops/training.py:65 2019-01-16 19:32:41.344762: step 64, loss = 0.69660 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:32:42.239055 ops/training.py:65 2019-01-16 19:32:42.239011: step 65, loss = 0.67170 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:32:43.132460 ops/training.py:65 2019-01-16 19:32:43.132413: step 66, loss = 0.67812 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:32:44.025010 ops/training.py:65 2019-01-16 19:32:44.024960: step 67, loss = 0.73308 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:32:44.916854 ops/training.py:65 2019-01-16 19:32:44.916806: step 68, loss = 0.69654 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:32:45.809805 ops/training.py:65 2019-01-16 19:32:45.809757: step 69, loss = 0.69600 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:32:46.702475 ops/training.py:65 2019-01-16 19:32:46.702424: step 70, loss = 0.76174 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:32:47.594808 ops/training.py:65 2019-01-16 19:32:47.594761: step 71, loss = 0.66987 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:32:48.486582 ops/training.py:65 2019-01-16 19:32:48.486533: step 72, loss = 0.73422 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 19:32:49.378749 ops/training.py:65 2019-01-16 19:32:49.378704: step 73, loss = 0.69696 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:32:50.271482 ops/training.py:65 2019-01-16 19:32:50.271431: step 74, loss = 0.72458 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:32:51.165159 ops/training.py:65 2019-01-16 19:32:51.165109: step 75, loss = 0.73381 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:32:52.057954 ops/training.py:65 2019-01-16 19:32:52.057908: step 76, loss = 0.68279 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:32:52.950943 ops/training.py:65 2019-01-16 19:32:52.950895: step 77, loss = 0.73065 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:32:53.843580 ops/training.py:65 2019-01-16 19:32:53.843532: step 78, loss = 0.74989 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:32:54.737300 ops/training.py:65 2019-01-16 19:32:54.737259: step 79, loss = 0.65411 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 19:32:55.632873 ops/training.py:65 2019-01-16 19:32:55.632826: step 80, loss = 0.69322 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:32:56.527544 ops/training.py:65 2019-01-16 19:32:56.527497: step 81, loss = 0.81590 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 19:32:57.423260 ops/training.py:65 2019-01-16 19:32:57.423197: step 82, loss = 0.71939 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:32:58.318287 ops/training.py:65 2019-01-16 19:32:58.318212: step 83, loss = 0.68311 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:32:59.214121 ops/training.py:65 2019-01-16 19:32:59.214057: step 84, loss = 0.75788 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:33:00.107238 ops/training.py:65 2019-01-16 19:33:00.107187: step 85, loss = 0.70321 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:33:01.000092 ops/training.py:65 2019-01-16 19:33:01.000045: step 86, loss = 0.71034 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:33:01.893726 ops/training.py:65 2019-01-16 19:33:01.893682: step 87, loss = 0.68766 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:33:02.786391 ops/training.py:65 2019-01-16 19:33:02.786345: step 88, loss = 0.73164 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:33:03.680711 ops/training.py:65 2019-01-16 19:33:03.680662: step 89, loss = 0.64746 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:33:04.575837 ops/training.py:65 2019-01-16 19:33:04.575782: step 90, loss = 0.67812 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:33:05.469877 ops/training.py:65 2019-01-16 19:33:05.469784: step 91, loss = 0.70707 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:33:06.363721 ops/training.py:65 2019-01-16 19:33:06.363648: step 92, loss = 0.74041 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:33:07.258289 ops/training.py:65 2019-01-16 19:33:07.258218: step 93, loss = 0.70290 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:33:08.153425 ops/training.py:65 2019-01-16 19:33:08.153344: step 94, loss = 0.75379 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:33:09.048462 ops/training.py:65 2019-01-16 19:33:09.048411: step 95, loss = 0.66615 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:33:09.941455 ops/training.py:65 2019-01-16 19:33:09.941406: step 96, loss = 0.70020 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:33:10.834631 ops/training.py:65 2019-01-16 19:33:10.834585: step 97, loss = 0.67053 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:33:11.727695 ops/training.py:65 2019-01-16 19:33:11.727649: step 98, loss = 0.75462 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:33:12.620454 ops/training.py:65 2019-01-16 19:33:12.620406: step 99, loss = 0.69882 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:33:13.512808 ops/training.py:65 2019-01-16 19:33:13.512758: step 100, loss = 0.77192 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:33:14.407767 ops/training.py:65 2019-01-16 19:33:14.407715: step 101, loss = 0.66955 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:33:15.300994 ops/training.py:65 2019-01-16 19:33:15.300946: step 102, loss = 0.70139 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:33:16.194645 ops/training.py:65 2019-01-16 19:33:16.194589: step 103, loss = 0.72351 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:33:17.090129 ops/training.py:65 2019-01-16 19:33:17.090085: step 104, loss = 0.68349 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:33:17.987069 ops/training.py:65 2019-01-16 19:33:17.987018: step 105, loss = 0.71532 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:33:18.882679 ops/training.py:65 2019-01-16 19:33:18.882626: step 106, loss = 0.69283 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:33:19.776954 ops/training.py:65 2019-01-16 19:33:19.776898: step 107, loss = 0.66139 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:33:20.671478 ops/training.py:65 2019-01-16 19:33:20.671426: step 108, loss = 0.70223 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:33:21.565558 ops/training.py:65 2019-01-16 19:33:21.565502: step 109, loss = 0.64647 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:33:22.459556 ops/training.py:65 2019-01-16 19:33:22.459490: step 110, loss = 0.72793 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:33:23.353405 ops/training.py:65 2019-01-16 19:33:23.353342: step 111, loss = 0.74476 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:33:24.247662 ops/training.py:65 2019-01-16 19:33:24.247599: step 112, loss = 0.67262 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:33:25.141766 ops/training.py:65 2019-01-16 19:33:25.141693: step 113, loss = 0.68333 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:33:26.035840 ops/training.py:65 2019-01-16 19:33:26.035788: step 114, loss = 0.66160 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:33:26.928875 ops/training.py:65 2019-01-16 19:33:26.928820: step 115, loss = 0.68489 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:33:27.822086 ops/training.py:65 2019-01-16 19:33:27.822042: step 116, loss = 0.64874 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:33:28.718745 ops/training.py:65 2019-01-16 19:33:28.718717: step 117, loss = 0.68484 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:33:29.614277 ops/training.py:65 2019-01-16 19:33:29.614248: step 118, loss = 0.72568 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:33:30.507894 ops/training.py:65 2019-01-16 19:33:30.507864: step 119, loss = 0.74273 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:33:31.401426 ops/training.py:65 2019-01-16 19:33:31.401395: step 120, loss = 0.71475 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:33:32.294238 ops/training.py:65 2019-01-16 19:33:32.294196: step 121, loss = 0.69775 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:33:33.187559 ops/training.py:65 2019-01-16 19:33:33.187513: step 122, loss = 0.68958 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:33:34.081147 ops/training.py:65 2019-01-16 19:33:34.081104: step 123, loss = 0.72827 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:33:34.976102 ops/training.py:65 2019-01-16 19:33:34.976041: step 124, loss = 0.68588 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:33:35.871795 ops/training.py:65 2019-01-16 19:33:35.871714: step 125, loss = 0.67807 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:33:36.767020 ops/training.py:65 2019-01-16 19:33:36.766927: step 126, loss = 0.71940 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:33:37.660900 ops/training.py:65 2019-01-16 19:33:37.660826: step 127, loss = 0.69927 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:33:38.554386 ops/training.py:65 2019-01-16 19:33:38.554338: step 128, loss = 0.73496 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:33:39.447726 ops/training.py:65 2019-01-16 19:33:39.447678: step 129, loss = 0.73493 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:33:40.341247 ops/training.py:65 2019-01-16 19:33:40.341196: step 130, loss = 0.72772 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:33:41.234601 ops/training.py:65 2019-01-16 19:33:41.234554: step 131, loss = 0.68262 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:33:42.127540 ops/training.py:65 2019-01-16 19:33:42.127485: step 132, loss = 0.70809 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:33:43.020429 ops/training.py:65 2019-01-16 19:33:43.020375: step 133, loss = 0.70641 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:33:43.914042 ops/training.py:65 2019-01-16 19:33:43.913989: step 134, loss = 0.69019 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:33:44.808063 ops/training.py:65 2019-01-16 19:33:44.808012: step 135, loss = 0.73180 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:33:45.702229 ops/training.py:65 2019-01-16 19:33:45.702174: step 136, loss = 0.74550 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:33:46.595035 ops/training.py:65 2019-01-16 19:33:46.594981: step 137, loss = 0.70849 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:33:47.488363 ops/training.py:65 2019-01-16 19:33:47.488310: step 138, loss = 0.73046 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:33:48.382294 ops/training.py:65 2019-01-16 19:33:48.382249: step 139, loss = 0.68129 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:33:49.275989 ops/training.py:65 2019-01-16 19:33:49.275936: step 140, loss = 0.71976 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:33:50.169505 ops/training.py:65 2019-01-16 19:33:50.169452: step 141, loss = 0.65241 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:33:51.068409 ops/training.py:65 2019-01-16 19:33:51.068358: step 142, loss = 0.65906 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:33:51.963924 ops/training.py:65 2019-01-16 19:33:51.963844: step 143, loss = 0.68796 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:33:52.859337 ops/training.py:65 2019-01-16 19:33:52.859257: step 144, loss = 0.72263 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:33:53.753516 ops/training.py:65 2019-01-16 19:33:53.753452: step 145, loss = 0.73643 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:33:54.649559 ops/training.py:65 2019-01-16 19:33:54.649487: step 146, loss = 0.69838 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:33:55.545149 ops/training.py:65 2019-01-16 19:33:55.545069: step 147, loss = 0.75031 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 19:33:56.440633 ops/training.py:65 2019-01-16 19:33:56.440575: step 148, loss = 0.73752 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:33:57.336566 ops/training.py:65 2019-01-16 19:33:57.336490: step 149, loss = 0.69606 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:33:58.233041 ops/training.py:65 2019-01-16 19:33:58.232956: step 150, loss = 0.67521 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:33:59.130294 ops/training.py:65 2019-01-16 19:33:59.130211: step 151, loss = 0.69683 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:34:00.025310 ops/training.py:65 2019-01-16 19:34:00.025251: step 152, loss = 0.65999 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 19:34:00.918450 ops/training.py:65 2019-01-16 19:34:00.918389: step 153, loss = 0.71053 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:34:01.811498 ops/training.py:65 2019-01-16 19:34:01.811441: step 154, loss = 0.77847 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:34:02.704850 ops/training.py:65 2019-01-16 19:34:02.704791: step 155, loss = 0.72664 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:34:03.598252 ops/training.py:65 2019-01-16 19:34:03.598199: step 156, loss = 0.66265 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:34:04.491996 ops/training.py:65 2019-01-16 19:34:04.491926: step 157, loss = 0.64025 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:34:05.386351 ops/training.py:65 2019-01-16 19:34:05.386279: step 158, loss = 0.63474 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:34:06.279880 ops/training.py:65 2019-01-16 19:34:06.279813: step 159, loss = 0.69732 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:34:07.173026 ops/training.py:65 2019-01-16 19:34:07.172976: step 160, loss = 0.68234 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:34:08.066020 ops/training.py:65 2019-01-16 19:34:08.065968: step 161, loss = 0.69425 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:34:08.959410 ops/training.py:65 2019-01-16 19:34:08.959362: step 162, loss = 0.79930 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:34:09.853148 ops/training.py:65 2019-01-16 19:34:09.853095: step 163, loss = 0.71498 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:34:10.747400 ops/training.py:65 2019-01-16 19:34:10.747354: step 164, loss = 0.70488 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:34:11.640813 ops/training.py:65 2019-01-16 19:34:11.640767: step 165, loss = 0.66224 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:34:12.534446 ops/training.py:65 2019-01-16 19:34:12.534396: step 166, loss = 0.67302 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:34:13.428980 ops/training.py:65 2019-01-16 19:34:13.428930: step 167, loss = 0.75327 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:34:14.323035 ops/training.py:65 2019-01-16 19:34:14.322984: step 168, loss = 0.69875 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:34:15.217201 ops/training.py:65 2019-01-16 19:34:15.217149: step 169, loss = 0.69048 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:34:16.110754 ops/training.py:65 2019-01-16 19:34:16.110705: step 170, loss = 0.70045 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:34:17.004850 ops/training.py:65 2019-01-16 19:34:17.004804: step 171, loss = 0.68528 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:34:17.899569 ops/training.py:65 2019-01-16 19:34:17.899525: step 172, loss = 0.66032 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:34:18.795139 ops/training.py:65 2019-01-16 19:34:18.795065: step 173, loss = 0.72341 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:34:19.693057 ops/training.py:65 2019-01-16 19:34:19.692984: step 174, loss = 0.69790 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:34:20.588408 ops/training.py:65 2019-01-16 19:34:20.588323: step 175, loss = 0.70636 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:34:21.482463 ops/training.py:65 2019-01-16 19:34:21.482408: step 176, loss = 0.73320 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:34:22.376150 ops/training.py:65 2019-01-16 19:34:22.376100: step 177, loss = 0.70547 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:34:23.269250 ops/training.py:65 2019-01-16 19:34:23.269197: step 178, loss = 0.72051 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:34:24.162398 ops/training.py:65 2019-01-16 19:34:24.162346: step 179, loss = 0.69664 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:34:25.054971 ops/training.py:65 2019-01-16 19:34:25.054925: step 180, loss = 0.72582 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:34:25.948820 ops/training.py:65 2019-01-16 19:34:25.948772: step 181, loss = 0.69755 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:34:26.841537 ops/training.py:65 2019-01-16 19:34:26.841492: step 182, loss = 0.69328 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:34:27.734751 ops/training.py:65 2019-01-16 19:34:27.734702: step 183, loss = 0.71121 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:34:28.627017 ops/training.py:65 2019-01-16 19:34:28.626960: step 184, loss = 0.76602 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:34:29.519982 ops/training.py:65 2019-01-16 19:34:29.519917: step 185, loss = 0.73847 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:34:30.412324 ops/training.py:65 2019-01-16 19:34:30.412270: step 186, loss = 0.73947 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:34:31.306110 ops/training.py:65 2019-01-16 19:34:31.306058: step 187, loss = 0.75236 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:34:32.199327 ops/training.py:65 2019-01-16 19:34:32.199279: step 188, loss = 0.70403 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:34:33.092880 ops/training.py:65 2019-01-16 19:34:33.092828: step 189, loss = 0.71421 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:34:33.988133 ops/training.py:65 2019-01-16 19:34:33.988079: step 190, loss = 0.67600 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:34:34.881810 ops/training.py:65 2019-01-16 19:34:34.881749: step 191, loss = 0.67458 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:34:35.795178 ops/training.py:65 2019-01-16 19:34:35.795103: step 192, loss = 0.72144 (35.1 examples/sec; 0.912 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:34:36.690210 ops/training.py:65 2019-01-16 19:34:36.690136: step 193, loss = 0.75532 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:34:37.584210 ops/training.py:65 2019-01-16 19:34:37.584151: step 194, loss = 0.74133 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:34:38.478041 ops/training.py:65 2019-01-16 19:34:38.477986: step 195, loss = 0.71854 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:34:39.371324 ops/training.py:65 2019-01-16 19:34:39.371275: step 196, loss = 0.72730 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:34:40.264364 ops/training.py:65 2019-01-16 19:34:40.264317: step 197, loss = 0.69930 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:34:41.159622 ops/training.py:65 2019-01-16 19:34:41.159577: step 198, loss = 0.68845 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:34:42.055129 ops/training.py:65 2019-01-16 19:34:42.055078: step 199, loss = 0.69504 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:34:42.949435 ops/training.py:65 2019-01-16 19:34:42.949383: step 200, loss = 0.68997 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:34:43.844434 ops/training.py:65 2019-01-16 19:34:43.844385: step 201, loss = 0.64642 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:34:44.739845 ops/training.py:65 2019-01-16 19:34:44.739793: step 202, loss = 0.74495 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:34:45.633332 ops/training.py:65 2019-01-16 19:34:45.633252: step 203, loss = 0.71675 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:34:46.530230 ops/training.py:65 2019-01-16 19:34:46.530159: step 204, loss = 0.67272 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:34:47.423592 ops/training.py:65 2019-01-16 19:34:47.423529: step 205, loss = 0.70032 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:34:48.318663 ops/training.py:65 2019-01-16 19:34:48.318600: step 206, loss = 0.70884 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:34:49.213710 ops/training.py:65 2019-01-16 19:34:49.213647: step 207, loss = 0.71574 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:34:50.109287 ops/training.py:65 2019-01-16 19:34:50.109226: step 208, loss = 0.72021 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:34:51.004951 ops/training.py:65 2019-01-16 19:34:51.004882: step 209, loss = 0.71256 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:34:51.901127 ops/training.py:65 2019-01-16 19:34:51.901059: step 210, loss = 0.71175 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:34:52.795196 ops/training.py:65 2019-01-16 19:34:52.795134: step 211, loss = 0.71489 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:34:53.688228 ops/training.py:65 2019-01-16 19:34:53.688163: step 212, loss = 0.66674 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:34:54.581021 ops/training.py:65 2019-01-16 19:34:54.580947: step 213, loss = 0.69896 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:34:55.475458 ops/training.py:65 2019-01-16 19:34:55.475390: step 214, loss = 0.70348 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:34:56.368597 ops/training.py:65 2019-01-16 19:34:56.368531: step 215, loss = 0.70636 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:34:57.262064 ops/training.py:65 2019-01-16 19:34:57.261985: step 216, loss = 0.66995 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:34:58.156007 ops/training.py:65 2019-01-16 19:34:58.155942: step 217, loss = 0.74848 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:34:59.048888 ops/training.py:65 2019-01-16 19:34:59.048825: step 218, loss = 0.66679 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:34:59.945750 ops/training.py:65 2019-01-16 19:34:59.945678: step 219, loss = 0.73740 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:35:00.842308 ops/training.py:65 2019-01-16 19:35:00.842240: step 220, loss = 0.71989 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:35:01.738522 ops/training.py:65 2019-01-16 19:35:01.738459: step 221, loss = 0.69962 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:35:02.631852 ops/training.py:65 2019-01-16 19:35:02.631789: step 222, loss = 0.68564 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:35:03.527429 ops/training.py:65 2019-01-16 19:35:03.527355: step 223, loss = 0.64785 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:35:04.422851 ops/training.py:65 2019-01-16 19:35:04.422788: step 224, loss = 0.64087 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:35:05.317151 ops/training.py:65 2019-01-16 19:35:05.317088: step 225, loss = 0.66784 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:35:06.210535 ops/training.py:65 2019-01-16 19:35:06.210463: step 226, loss = 0.75689 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:35:07.103231 ops/training.py:65 2019-01-16 19:35:07.103169: step 227, loss = 0.70550 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:35:07.996993 ops/training.py:65 2019-01-16 19:35:07.996935: step 228, loss = 0.68137 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:35:08.890753 ops/training.py:65 2019-01-16 19:35:08.890690: step 229, loss = 0.71268 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:35:09.784564 ops/training.py:65 2019-01-16 19:35:09.784493: step 230, loss = 0.70213 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:35:10.677154 ops/training.py:65 2019-01-16 19:35:10.677087: step 231, loss = 0.69138 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:35:11.569959 ops/training.py:65 2019-01-16 19:35:11.569889: step 232, loss = 0.67485 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:35:12.462481 ops/training.py:65 2019-01-16 19:35:12.462407: step 233, loss = 0.78404 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:35:13.355744 ops/training.py:65 2019-01-16 19:35:13.355677: step 234, loss = 0.73438 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:35:14.248647 ops/training.py:65 2019-01-16 19:35:14.248586: step 235, loss = 0.70467 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:35:15.141969 ops/training.py:65 2019-01-16 19:35:15.141895: step 236, loss = 0.69142 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:35:16.035202 ops/training.py:65 2019-01-16 19:35:16.035138: step 237, loss = 0.69825 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:35:16.930689 ops/training.py:65 2019-01-16 19:35:16.930627: step 238, loss = 0.71153 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:35:17.825124 ops/training.py:65 2019-01-16 19:35:17.825084: step 239, loss = 0.66092 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:35:18.719554 ops/training.py:65 2019-01-16 19:35:18.719509: step 240, loss = 0.68508 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:35:19.612285 ops/training.py:65 2019-01-16 19:35:19.612242: step 241, loss = 0.72196 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:35:20.505875 ops/training.py:65 2019-01-16 19:35:20.505832: step 242, loss = 0.73463 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:35:21.401473 ops/training.py:65 2019-01-16 19:35:21.401444: step 243, loss = 0.74468 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:35:22.295405 ops/training.py:65 2019-01-16 19:35:22.295357: step 244, loss = 0.70443 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:35:23.190769 ops/training.py:65 2019-01-16 19:35:23.190712: step 245, loss = 0.70351 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:35:24.085135 ops/training.py:65 2019-01-16 19:35:24.085093: step 246, loss = 0.72600 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:35:24.979790 ops/training.py:65 2019-01-16 19:35:24.979743: step 247, loss = 0.67213 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:35:25.873314 ops/training.py:65 2019-01-16 19:35:25.873262: step 248, loss = 0.72173 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:35:26.768049 ops/training.py:65 2019-01-16 19:35:26.768014: step 249, loss = 0.73163 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:35:27.661426 ops/training.py:65 2019-01-16 19:35:27.661377: step 250, loss = 0.75027 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.15625
I1280 2019-01-16 19:35:28.557135 ops/training.py:65 2019-01-16 19:35:28.557081: step 251, loss = 0.75112 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.21875
I1280 2019-01-16 19:35:29.451217 ops/training.py:65 2019-01-16 19:35:29.451154: step 252, loss = 0.69487 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:35:30.345052 ops/training.py:65 2019-01-16 19:35:30.345002: step 253, loss = 0.68861 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:35:31.239886 ops/training.py:65 2019-01-16 19:35:31.239831: step 254, loss = 0.70076 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:35:32.133284 ops/training.py:65 2019-01-16 19:35:32.133234: step 255, loss = 0.71678 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:35:33.027402 ops/training.py:65 2019-01-16 19:35:33.027355: step 256, loss = 0.68559 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:35:33.920968 ops/training.py:65 2019-01-16 19:35:33.920909: step 257, loss = 0.68677 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:35:34.818209 ops/training.py:65 2019-01-16 19:35:34.818150: step 258, loss = 0.67123 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:35:35.715360 ops/training.py:65 2019-01-16 19:35:35.715289: step 259, loss = 0.70881 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:35:36.614112 ops/training.py:65 2019-01-16 19:35:36.614068: step 260, loss = 0.67402 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:35:37.512349 ops/training.py:65 2019-01-16 19:35:37.512273: step 261, loss = 0.66272 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:35:38.407834 ops/training.py:65 2019-01-16 19:35:38.407784: step 262, loss = 0.72497 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:35:39.301982 ops/training.py:65 2019-01-16 19:35:39.301932: step 263, loss = 0.67077 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:35:40.196284 ops/training.py:65 2019-01-16 19:35:40.196235: step 264, loss = 0.71749 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:35:41.090323 ops/training.py:65 2019-01-16 19:35:41.090278: step 265, loss = 0.68834 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:35:41.985227 ops/training.py:65 2019-01-16 19:35:41.985182: step 266, loss = 0.70997 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:35:42.881525 ops/training.py:65 2019-01-16 19:35:42.881441: step 267, loss = 0.68748 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:35:43.777524 ops/training.py:65 2019-01-16 19:35:43.777444: step 268, loss = 0.70801 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:35:44.674788 ops/training.py:65 2019-01-16 19:35:44.674710: step 269, loss = 0.70403 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:35:45.570664 ops/training.py:65 2019-01-16 19:35:45.570595: step 270, loss = 0.69450 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:35:46.464927 ops/training.py:65 2019-01-16 19:35:46.464876: step 271, loss = 0.67269 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:35:47.358435 ops/training.py:65 2019-01-16 19:35:47.358383: step 272, loss = 0.69201 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:35:48.253355 ops/training.py:65 2019-01-16 19:35:48.253304: step 273, loss = 0.70203 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:35:49.147115 ops/training.py:65 2019-01-16 19:35:49.147065: step 274, loss = 0.70409 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:35:50.040818 ops/training.py:65 2019-01-16 19:35:50.040773: step 275, loss = 0.68869 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:35:50.934484 ops/training.py:65 2019-01-16 19:35:50.934439: step 276, loss = 0.69467 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:35:51.828801 ops/training.py:65 2019-01-16 19:35:51.828748: step 277, loss = 0.69615 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:35:52.723132 ops/training.py:65 2019-01-16 19:35:52.723079: step 278, loss = 0.69014 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:35:53.616783 ops/training.py:65 2019-01-16 19:35:53.616738: step 279, loss = 0.68845 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:35:54.509669 ops/training.py:65 2019-01-16 19:35:54.509624: step 280, loss = 0.69842 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:35:55.402886 ops/training.py:65 2019-01-16 19:35:55.402831: step 281, loss = 0.67612 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:35:56.297198 ops/training.py:65 2019-01-16 19:35:56.297147: step 282, loss = 0.69622 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:35:57.190249 ops/training.py:65 2019-01-16 19:35:57.190193: step 283, loss = 0.70773 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:35:58.083224 ops/training.py:65 2019-01-16 19:35:58.083172: step 284, loss = 0.68565 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:35:58.976765 ops/training.py:65 2019-01-16 19:35:58.976719: step 285, loss = 0.71567 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:35:59.871172 ops/training.py:65 2019-01-16 19:35:59.871107: step 286, loss = 0.70415 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:36:00.764247 ops/training.py:65 2019-01-16 19:36:00.764191: step 287, loss = 0.70789 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:36:01.658433 ops/training.py:65 2019-01-16 19:36:01.658385: step 288, loss = 0.68890 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:36:02.552304 ops/training.py:65 2019-01-16 19:36:02.552256: step 289, loss = 0.69247 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:36:03.445850 ops/training.py:65 2019-01-16 19:36:03.445799: step 290, loss = 0.69071 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:36:04.338861 ops/training.py:65 2019-01-16 19:36:04.338807: step 291, loss = 0.68092 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:36:05.232491 ops/training.py:65 2019-01-16 19:36:05.232429: step 292, loss = 0.71092 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:36:06.125545 ops/training.py:65 2019-01-16 19:36:06.125487: step 293, loss = 0.71441 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:36:07.018426 ops/training.py:65 2019-01-16 19:36:07.018373: step 294, loss = 0.72880 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:36:07.911415 ops/training.py:65 2019-01-16 19:36:07.911369: step 295, loss = 0.69643 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:36:08.804604 ops/training.py:65 2019-01-16 19:36:08.804532: step 296, loss = 0.70252 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:36:09.698434 ops/training.py:65 2019-01-16 19:36:09.698372: step 297, loss = 0.72157 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:36:10.592044 ops/training.py:65 2019-01-16 19:36:10.591995: step 298, loss = 0.68406 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:36:11.485284 ops/training.py:65 2019-01-16 19:36:11.485239: step 299, loss = 0.67271 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:36:12.378030 ops/training.py:65 2019-01-16 19:36:12.377978: step 300, loss = 0.65386 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:36:13.271256 ops/training.py:65 2019-01-16 19:36:13.271204: step 301, loss = 0.65844 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:36:14.164890 ops/training.py:65 2019-01-16 19:36:14.164845: step 302, loss = 0.69189 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:36:15.057455 ops/training.py:65 2019-01-16 19:36:15.057403: step 303, loss = 0.68221 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:36:15.950139 ops/training.py:65 2019-01-16 19:36:15.950091: step 304, loss = 0.68924 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:36:16.843281 ops/training.py:65 2019-01-16 19:36:16.843231: step 305, loss = 0.69451 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:36:17.736503 ops/training.py:65 2019-01-16 19:36:17.736418: step 306, loss = 0.69238 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:36:18.630249 ops/training.py:65 2019-01-16 19:36:18.630197: step 307, loss = 0.72494 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:36:19.523440 ops/training.py:65 2019-01-16 19:36:19.523395: step 308, loss = 0.71033 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:36:20.417016 ops/training.py:65 2019-01-16 19:36:20.416971: step 309, loss = 0.69719 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:36:21.310229 ops/training.py:65 2019-01-16 19:36:21.310180: step 310, loss = 0.69588 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:36:22.202766 ops/training.py:65 2019-01-16 19:36:22.202717: step 311, loss = 0.71707 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:36:23.095788 ops/training.py:65 2019-01-16 19:36:23.095740: step 312, loss = 0.69927 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:36:23.988715 ops/training.py:65 2019-01-16 19:36:23.988661: step 313, loss = 0.69979 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:36:24.882662 ops/training.py:65 2019-01-16 19:36:24.882602: step 314, loss = 0.72093 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:36:25.776210 ops/training.py:65 2019-01-16 19:36:25.776155: step 315, loss = 0.69881 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:36:26.669350 ops/training.py:65 2019-01-16 19:36:26.669291: step 316, loss = 0.69844 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:36:27.562670 ops/training.py:65 2019-01-16 19:36:27.562616: step 317, loss = 0.69733 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:36:28.457084 ops/training.py:65 2019-01-16 19:36:28.457036: step 318, loss = 0.69569 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:36:29.350677 ops/training.py:65 2019-01-16 19:36:29.350620: step 319, loss = 0.70279 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:36:30.244169 ops/training.py:65 2019-01-16 19:36:30.244116: step 320, loss = 0.69561 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 19:36:31.138105 ops/training.py:65 2019-01-16 19:36:31.138053: step 321, loss = 0.68795 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:36:32.031486 ops/training.py:65 2019-01-16 19:36:32.031440: step 322, loss = 0.73020 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 19:36:32.924840 ops/training.py:65 2019-01-16 19:36:32.924796: step 323, loss = 0.70150 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:36:33.818097 ops/training.py:65 2019-01-16 19:36:33.818044: step 324, loss = 0.69269 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:36:34.711452 ops/training.py:65 2019-01-16 19:36:34.711392: step 325, loss = 0.68413 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:36:35.605856 ops/training.py:65 2019-01-16 19:36:35.605793: step 326, loss = 0.70610 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:36:36.500720 ops/training.py:65 2019-01-16 19:36:36.500671: step 327, loss = 0.69724 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:36:37.396178 ops/training.py:65 2019-01-16 19:36:37.396098: step 328, loss = 0.66991 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:36:38.292854 ops/training.py:65 2019-01-16 19:36:38.292773: step 329, loss = 0.69888 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:36:39.189059 ops/training.py:65 2019-01-16 19:36:39.188973: step 330, loss = 0.67127 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:36:40.084713 ops/training.py:65 2019-01-16 19:36:40.084631: step 331, loss = 0.71230 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:36:40.981643 ops/training.py:65 2019-01-16 19:36:40.981482: step 332, loss = 0.71551 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:36:41.876705 ops/training.py:65 2019-01-16 19:36:41.876644: step 333, loss = 0.67767 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:36:42.771442 ops/training.py:65 2019-01-16 19:36:42.771374: step 334, loss = 0.68855 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:36:43.665956 ops/training.py:65 2019-01-16 19:36:43.665884: step 335, loss = 0.69857 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:36:44.559300 ops/training.py:65 2019-01-16 19:36:44.559244: step 336, loss = 0.69486 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:36:45.452977 ops/training.py:65 2019-01-16 19:36:45.452920: step 337, loss = 0.68749 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:36:46.346321 ops/training.py:65 2019-01-16 19:36:46.346268: step 338, loss = 0.69920 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:36:47.241110 ops/training.py:65 2019-01-16 19:36:47.241072: step 339, loss = 0.69988 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:36:48.137477 ops/training.py:65 2019-01-16 19:36:48.137399: step 340, loss = 0.70604 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:36:49.033407 ops/training.py:65 2019-01-16 19:36:49.033338: step 341, loss = 0.67196 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:36:49.927559 ops/training.py:65 2019-01-16 19:36:49.927511: step 342, loss = 0.68742 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:36:50.820781 ops/training.py:65 2019-01-16 19:36:50.820735: step 343, loss = 0.67119 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:36:51.713962 ops/training.py:65 2019-01-16 19:36:51.713916: step 344, loss = 0.69691 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:36:52.606706 ops/training.py:65 2019-01-16 19:36:52.606656: step 345, loss = 0.70888 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:36:53.501726 ops/training.py:65 2019-01-16 19:36:53.501680: step 346, loss = 0.68832 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:36:54.398683 ops/training.py:65 2019-01-16 19:36:54.398607: step 347, loss = 0.67700 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:36:55.294482 ops/training.py:65 2019-01-16 19:36:55.294411: step 348, loss = 0.68965 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:36:56.188550 ops/training.py:65 2019-01-16 19:36:56.188504: step 349, loss = 0.70658 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:36:57.082063 ops/training.py:65 2019-01-16 19:36:57.082011: step 350, loss = 0.69663 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:36:57.975978 ops/training.py:65 2019-01-16 19:36:57.975926: step 351, loss = 0.67500 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:36:58.870492 ops/training.py:65 2019-01-16 19:36:58.870429: step 352, loss = 0.70351 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:36:59.765071 ops/training.py:65 2019-01-16 19:36:59.765013: step 353, loss = 0.70672 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:37:00.658368 ops/training.py:65 2019-01-16 19:37:00.658319: step 354, loss = 0.67221 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:37:01.551495 ops/training.py:65 2019-01-16 19:37:01.551446: step 355, loss = 0.67483 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:37:02.445262 ops/training.py:65 2019-01-16 19:37:02.445211: step 356, loss = 0.70654 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:37:03.338570 ops/training.py:65 2019-01-16 19:37:03.338516: step 357, loss = 0.69569 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:37:04.232757 ops/training.py:65 2019-01-16 19:37:04.232707: step 358, loss = 0.70998 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:37:05.126674 ops/training.py:65 2019-01-16 19:37:05.126613: step 359, loss = 0.71881 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:37:06.022566 ops/training.py:65 2019-01-16 19:37:06.022514: step 360, loss = 0.70244 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:37:06.919440 ops/training.py:65 2019-01-16 19:37:06.919360: step 361, loss = 0.71036 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:37:07.813757 ops/training.py:65 2019-01-16 19:37:07.813686: step 362, loss = 0.73767 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 19:37:08.706585 ops/training.py:65 2019-01-16 19:37:08.706535: step 363, loss = 0.67239 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:37:09.600977 ops/training.py:65 2019-01-16 19:37:09.600935: step 364, loss = 0.71505 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:37:10.497086 ops/training.py:65 2019-01-16 19:37:10.497006: step 365, loss = 0.70870 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:37:11.392131 ops/training.py:65 2019-01-16 19:37:11.392063: step 366, loss = 0.71084 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:37:12.286375 ops/training.py:65 2019-01-16 19:37:12.286324: step 367, loss = 0.68162 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:37:13.180941 ops/training.py:65 2019-01-16 19:37:13.180897: step 368, loss = 0.70793 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:37:14.077870 ops/training.py:65 2019-01-16 19:37:14.077789: step 369, loss = 0.68338 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:37:14.973476 ops/training.py:65 2019-01-16 19:37:14.973402: step 370, loss = 0.68167 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:37:15.868036 ops/training.py:65 2019-01-16 19:37:15.867983: step 371, loss = 0.68586 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:37:16.762664 ops/training.py:65 2019-01-16 19:37:16.762621: step 372, loss = 0.67730 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:37:17.658083 ops/training.py:65 2019-01-16 19:37:17.658007: step 373, loss = 0.68074 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:37:18.553769 ops/training.py:65 2019-01-16 19:37:18.553704: step 374, loss = 0.70966 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:37:19.447002 ops/training.py:65 2019-01-16 19:37:19.446955: step 375, loss = 0.70934 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:37:20.340942 ops/training.py:65 2019-01-16 19:37:20.340892: step 376, loss = 0.68835 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:37:21.234716 ops/training.py:65 2019-01-16 19:37:21.234667: step 377, loss = 0.72010 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:37:22.129504 ops/training.py:65 2019-01-16 19:37:22.129455: step 378, loss = 0.68525 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:37:23.024031 ops/training.py:65 2019-01-16 19:37:23.023968: step 379, loss = 0.71083 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:37:23.920811 ops/training.py:65 2019-01-16 19:37:23.920759: step 380, loss = 0.68979 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:37:24.817098 ops/training.py:65 2019-01-16 19:37:24.817027: step 381, loss = 0.71560 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:37:25.712748 ops/training.py:65 2019-01-16 19:37:25.712683: step 382, loss = 0.68623 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:37:26.606718 ops/training.py:65 2019-01-16 19:37:26.606661: step 383, loss = 0.69287 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:37:27.500157 ops/training.py:65 2019-01-16 19:37:27.500110: step 384, loss = 0.68264 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:37:28.393567 ops/training.py:65 2019-01-16 19:37:28.393517: step 385, loss = 0.69477 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:37:29.287159 ops/training.py:65 2019-01-16 19:37:29.287111: step 386, loss = 0.69215 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:37:30.180730 ops/training.py:65 2019-01-16 19:37:30.180678: step 387, loss = 0.69825 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:37:31.074191 ops/training.py:65 2019-01-16 19:37:31.074141: step 388, loss = 0.70034 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:37:31.967114 ops/training.py:65 2019-01-16 19:37:31.967067: step 389, loss = 0.69125 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:37:32.859788 ops/training.py:65 2019-01-16 19:37:32.859744: step 390, loss = 0.69461 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:37:33.753655 ops/training.py:65 2019-01-16 19:37:33.753608: step 391, loss = 0.69631 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:37:34.647363 ops/training.py:65 2019-01-16 19:37:34.647304: step 392, loss = 0.70016 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:37:35.541967 ops/training.py:65 2019-01-16 19:37:35.541900: step 393, loss = 0.68142 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:37:36.437565 ops/training.py:65 2019-01-16 19:37:36.437484: step 394, loss = 0.67917 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:37:37.333943 ops/training.py:65 2019-01-16 19:37:37.333868: step 395, loss = 0.67545 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:37:38.228170 ops/training.py:65 2019-01-16 19:37:38.228113: step 396, loss = 0.71536 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:37:39.121207 ops/training.py:65 2019-01-16 19:37:39.121162: step 397, loss = 0.68578 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:37:40.014977 ops/training.py:65 2019-01-16 19:37:40.014929: step 398, loss = 0.67644 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:37:40.908115 ops/training.py:65 2019-01-16 19:37:40.908069: step 399, loss = 0.74952 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:37:41.801939 ops/training.py:65 2019-01-16 19:37:41.801895: step 400, loss = 0.75041 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:37:42.695584 ops/training.py:65 2019-01-16 19:37:42.695531: step 401, loss = 0.74972 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:37:43.588966 ops/training.py:65 2019-01-16 19:37:43.588916: step 402, loss = 0.69710 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:37:44.482243 ops/training.py:65 2019-01-16 19:37:44.482196: step 403, loss = 0.70145 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:37:45.375604 ops/training.py:65 2019-01-16 19:37:45.375559: step 404, loss = 0.71790 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:37:46.269079 ops/training.py:65 2019-01-16 19:37:46.269029: step 405, loss = 0.70241 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:37:47.162607 ops/training.py:65 2019-01-16 19:37:47.162555: step 406, loss = 0.73978 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:37:48.056770 ops/training.py:65 2019-01-16 19:37:48.056723: step 407, loss = 0.73082 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:37:48.951682 ops/training.py:65 2019-01-16 19:37:48.951634: step 408, loss = 0.72927 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:37:49.845580 ops/training.py:65 2019-01-16 19:37:49.845536: step 409, loss = 0.75764 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 19:37:50.740372 ops/training.py:65 2019-01-16 19:37:50.740322: step 410, loss = 0.65460 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:37:51.634536 ops/training.py:65 2019-01-16 19:37:51.634486: step 411, loss = 0.70537 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:37:52.527629 ops/training.py:65 2019-01-16 19:37:52.527579: step 412, loss = 0.67372 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:37:53.420873 ops/training.py:65 2019-01-16 19:37:53.420824: step 413, loss = 0.70422 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:37:54.314581 ops/training.py:65 2019-01-16 19:37:54.314532: step 414, loss = 0.67103 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:37:55.208355 ops/training.py:65 2019-01-16 19:37:55.208312: step 415, loss = 0.69678 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:37:56.101601 ops/training.py:65 2019-01-16 19:37:56.101553: step 416, loss = 0.67193 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:37:56.995280 ops/training.py:65 2019-01-16 19:37:56.995231: step 417, loss = 0.68854 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:37:57.891275 ops/training.py:65 2019-01-16 19:37:57.891232: step 418, loss = 0.74170 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:37:58.789157 ops/training.py:65 2019-01-16 19:37:58.789071: step 419, loss = 0.72932 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:37:59.686435 ops/training.py:65 2019-01-16 19:37:59.686385: step 420, loss = 0.71607 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:38:00.581376 ops/training.py:65 2019-01-16 19:38:00.581329: step 421, loss = 0.71546 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:38:01.475840 ops/training.py:65 2019-01-16 19:38:01.475794: step 422, loss = 0.71950 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:38:02.369205 ops/training.py:65 2019-01-16 19:38:02.369165: step 423, loss = 0.70644 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:38:03.262835 ops/training.py:65 2019-01-16 19:38:03.262785: step 424, loss = 0.70094 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:38:04.157128 ops/training.py:65 2019-01-16 19:38:04.157078: step 425, loss = 0.71347 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:38:05.051310 ops/training.py:65 2019-01-16 19:38:05.051250: step 426, loss = 0.73963 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:38:05.944813 ops/training.py:65 2019-01-16 19:38:05.944763: step 427, loss = 0.69551 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:38:06.838579 ops/training.py:65 2019-01-16 19:38:06.838528: step 428, loss = 0.70507 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:38:07.732420 ops/training.py:65 2019-01-16 19:38:07.732371: step 429, loss = 0.68761 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:38:08.626436 ops/training.py:65 2019-01-16 19:38:08.626386: step 430, loss = 0.69140 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:38:09.522026 ops/training.py:65 2019-01-16 19:38:09.521975: step 431, loss = 0.70763 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:38:10.414968 ops/training.py:65 2019-01-16 19:38:10.414913: step 432, loss = 0.70121 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:38:11.309245 ops/training.py:65 2019-01-16 19:38:11.309189: step 433, loss = 0.68487 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:38:12.202339 ops/training.py:65 2019-01-16 19:38:12.202291: step 434, loss = 0.67468 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:38:13.096685 ops/training.py:65 2019-01-16 19:38:13.096630: step 435, loss = 0.72612 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:38:13.991167 ops/training.py:65 2019-01-16 19:38:13.991113: step 436, loss = 0.70867 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:38:14.884819 ops/training.py:65 2019-01-16 19:38:14.884769: step 437, loss = 0.67815 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:38:15.779649 ops/training.py:65 2019-01-16 19:38:15.779597: step 438, loss = 0.70846 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:38:16.673521 ops/training.py:65 2019-01-16 19:38:16.673475: step 439, loss = 0.69505 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:38:17.567792 ops/training.py:65 2019-01-16 19:38:17.567751: step 440, loss = 0.73041 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:38:18.461745 ops/training.py:65 2019-01-16 19:38:18.461700: step 441, loss = 0.70198 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:38:19.356274 ops/training.py:65 2019-01-16 19:38:19.356235: step 442, loss = 0.68907 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:38:20.250801 ops/training.py:65 2019-01-16 19:38:20.250756: step 443, loss = 0.68710 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:38:21.145774 ops/training.py:65 2019-01-16 19:38:21.145727: step 444, loss = 0.68827 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:38:22.039321 ops/training.py:65 2019-01-16 19:38:22.039273: step 445, loss = 0.71363 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:38:22.933124 ops/training.py:65 2019-01-16 19:38:22.933075: step 446, loss = 0.67468 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:38:23.828095 ops/training.py:65 2019-01-16 19:38:23.828037: step 447, loss = 0.69249 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:38:24.721520 ops/training.py:65 2019-01-16 19:38:24.721471: step 448, loss = 0.67035 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:38:25.616573 ops/training.py:65 2019-01-16 19:38:25.616522: step 449, loss = 0.69927 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:38:26.511180 ops/training.py:65 2019-01-16 19:38:26.511127: step 450, loss = 0.72959 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 19:38:27.405252 ops/training.py:65 2019-01-16 19:38:27.405199: step 451, loss = 0.67725 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:38:28.300805 ops/training.py:65 2019-01-16 19:38:28.300749: step 452, loss = 0.69184 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:38:29.196251 ops/training.py:65 2019-01-16 19:38:29.196201: step 453, loss = 0.69456 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:38:30.091255 ops/training.py:65 2019-01-16 19:38:30.091202: step 454, loss = 0.70735 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:38:30.985981 ops/training.py:65 2019-01-16 19:38:30.985929: step 455, loss = 0.69786 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:38:31.881274 ops/training.py:65 2019-01-16 19:38:31.881222: step 456, loss = 0.67943 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:38:32.775402 ops/training.py:65 2019-01-16 19:38:32.775355: step 457, loss = 0.68131 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:38:33.671033 ops/training.py:65 2019-01-16 19:38:33.670981: step 458, loss = 0.68533 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:38:34.566000 ops/training.py:65 2019-01-16 19:38:34.565955: step 459, loss = 0.70297 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:38:35.460874 ops/training.py:65 2019-01-16 19:38:35.460813: step 460, loss = 0.71648 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:38:36.355596 ops/training.py:65 2019-01-16 19:38:36.355535: step 461, loss = 0.67940 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:38:37.249822 ops/training.py:65 2019-01-16 19:38:37.249767: step 462, loss = 0.68885 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:38:38.144605 ops/training.py:65 2019-01-16 19:38:38.144549: step 463, loss = 0.69706 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:38:39.039037 ops/training.py:65 2019-01-16 19:38:39.038986: step 464, loss = 0.68469 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:38:39.934272 ops/training.py:65 2019-01-16 19:38:39.934223: step 465, loss = 0.68733 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:38:40.828771 ops/training.py:65 2019-01-16 19:38:40.828723: step 466, loss = 0.69731 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:38:41.723682 ops/training.py:65 2019-01-16 19:38:41.723624: step 467, loss = 0.68207 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:38:42.619015 ops/training.py:65 2019-01-16 19:38:42.618944: step 468, loss = 0.69214 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:38:43.514667 ops/training.py:65 2019-01-16 19:38:43.514574: step 469, loss = 0.70569 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:38:44.413833 ops/training.py:65 2019-01-16 19:38:44.413740: step 470, loss = 0.69342 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:38:45.310963 ops/training.py:65 2019-01-16 19:38:45.310884: step 471, loss = 0.72872 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:38:46.207268 ops/training.py:65 2019-01-16 19:38:46.207207: step 472, loss = 0.71754 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:38:47.103382 ops/training.py:65 2019-01-16 19:38:47.103320: step 473, loss = 0.70485 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:38:47.998571 ops/training.py:65 2019-01-16 19:38:47.998509: step 474, loss = 0.69160 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:38:48.892607 ops/training.py:65 2019-01-16 19:38:48.892542: step 475, loss = 0.70143 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:38:49.788233 ops/training.py:65 2019-01-16 19:38:49.788174: step 476, loss = 0.68298 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:38:50.684409 ops/training.py:65 2019-01-16 19:38:50.684347: step 477, loss = 0.68958 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:38:51.579505 ops/training.py:65 2019-01-16 19:38:51.579441: step 478, loss = 0.68829 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:38:52.475601 ops/training.py:65 2019-01-16 19:38:52.475533: step 479, loss = 0.71444 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:38:53.370011 ops/training.py:65 2019-01-16 19:38:53.369946: step 480, loss = 0.69633 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:38:54.264725 ops/training.py:65 2019-01-16 19:38:54.264626: step 481, loss = 0.69735 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:38:55.162457 ops/training.py:65 2019-01-16 19:38:55.162361: step 482, loss = 0.69931 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:38:56.060453 ops/training.py:65 2019-01-16 19:38:56.060370: step 483, loss = 0.70108 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:38:56.956080 ops/training.py:65 2019-01-16 19:38:56.956019: step 484, loss = 0.69909 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:38:57.850322 ops/training.py:65 2019-01-16 19:38:57.850264: step 485, loss = 0.70370 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:38:58.743832 ops/training.py:65 2019-01-16 19:38:58.743763: step 486, loss = 0.71603 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:38:59.638011 ops/training.py:65 2019-01-16 19:38:59.637951: step 487, loss = 0.70119 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:39:00.531367 ops/training.py:65 2019-01-16 19:39:00.531309: step 488, loss = 0.69343 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:39:01.426062 ops/training.py:65 2019-01-16 19:39:01.426000: step 489, loss = 0.67561 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:39:02.320846 ops/training.py:65 2019-01-16 19:39:02.320793: step 490, loss = 0.68172 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:39:03.215855 ops/training.py:65 2019-01-16 19:39:03.215804: step 491, loss = 0.68654 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:39:04.113910 ops/training.py:65 2019-01-16 19:39:04.113842: step 492, loss = 0.69292 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:39:05.009903 ops/training.py:65 2019-01-16 19:39:05.009832: step 493, loss = 0.74900 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:39:05.905341 ops/training.py:65 2019-01-16 19:39:05.905283: step 494, loss = 0.67736 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:39:06.801415 ops/training.py:65 2019-01-16 19:39:06.801315: step 495, loss = 0.69071 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:39:07.698919 ops/training.py:65 2019-01-16 19:39:07.698851: step 496, loss = 0.69121 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:39:08.591928 ops/training.py:65 2019-01-16 19:39:08.591872: step 497, loss = 0.67440 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:39:09.486136 ops/training.py:65 2019-01-16 19:39:09.486088: step 498, loss = 0.66822 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:39:10.383515 ops/training.py:65 2019-01-16 19:39:10.383415: step 499, loss = 0.65536 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:39:11.278948 ops/training.py:65 2019-01-16 19:39:11.278853: step 500, loss = 0.68640 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:39:12.175276 ops/training.py:65 2019-01-16 19:39:12.175178: step 501, loss = 0.67494 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:39:13.070359 ops/training.py:65 2019-01-16 19:39:13.070257: step 502, loss = 0.68135 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:39:13.968299 ops/training.py:65 2019-01-16 19:39:13.968205: step 503, loss = 0.72371 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:39:14.865491 ops/training.py:65 2019-01-16 19:39:14.865406: step 504, loss = 0.69350 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:39:15.761005 ops/training.py:65 2019-01-16 19:39:15.760946: step 505, loss = 0.67338 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:39:16.656581 ops/training.py:65 2019-01-16 19:39:16.656532: step 506, loss = 0.66665 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:39:17.552259 ops/training.py:65 2019-01-16 19:39:17.552181: step 507, loss = 0.68138 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:39:18.450229 ops/training.py:65 2019-01-16 19:39:18.450126: step 508, loss = 0.71221 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:39:19.346198 ops/training.py:65 2019-01-16 19:39:19.346117: step 509, loss = 0.67293 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:39:20.241129 ops/training.py:65 2019-01-16 19:39:20.241073: step 510, loss = 0.66075 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:39:21.136411 ops/training.py:65 2019-01-16 19:39:21.136352: step 511, loss = 0.69394 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:39:22.031730 ops/training.py:65 2019-01-16 19:39:22.031673: step 512, loss = 0.70058 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:39:22.926704 ops/training.py:65 2019-01-16 19:39:22.926637: step 513, loss = 0.73196 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:39:23.821949 ops/training.py:65 2019-01-16 19:39:23.821888: step 514, loss = 0.72010 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:39:24.716049 ops/training.py:65 2019-01-16 19:39:24.716001: step 515, loss = 0.64664 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:39:25.612405 ops/training.py:65 2019-01-16 19:39:25.612305: step 516, loss = 0.72138 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:39:26.510704 ops/training.py:65 2019-01-16 19:39:26.510605: step 517, loss = 0.69177 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:39:27.408659 ops/training.py:65 2019-01-16 19:39:27.408564: step 518, loss = 0.70981 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:39:28.305524 ops/training.py:65 2019-01-16 19:39:28.305464: step 519, loss = 0.67686 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:39:29.200200 ops/training.py:65 2019-01-16 19:39:29.200134: step 520, loss = 0.69980 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:39:30.094372 ops/training.py:65 2019-01-16 19:39:30.094310: step 521, loss = 0.70888 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:39:30.989251 ops/training.py:65 2019-01-16 19:39:30.989186: step 522, loss = 0.66836 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:39:31.883031 ops/training.py:65 2019-01-16 19:39:31.882972: step 523, loss = 0.69198 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:39:32.777584 ops/training.py:65 2019-01-16 19:39:32.777533: step 524, loss = 0.69795 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:39:33.670740 ops/training.py:65 2019-01-16 19:39:33.670681: step 525, loss = 0.72082 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:39:34.565109 ops/training.py:65 2019-01-16 19:39:34.565066: step 526, loss = 0.67468 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:39:35.462574 ops/training.py:65 2019-01-16 19:39:35.462487: step 527, loss = 0.66537 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:39:36.357406 ops/training.py:65 2019-01-16 19:39:36.357314: step 528, loss = 0.68652 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:39:37.251322 ops/training.py:65 2019-01-16 19:39:37.251231: step 529, loss = 0.70590 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:39:38.144941 ops/training.py:65 2019-01-16 19:39:38.144877: step 530, loss = 0.68488 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:39:39.040419 ops/training.py:65 2019-01-16 19:39:39.040335: step 531, loss = 0.70365 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:39:39.935947 ops/training.py:65 2019-01-16 19:39:39.935847: step 532, loss = 0.75238 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 19:39:40.831254 ops/training.py:65 2019-01-16 19:39:40.831157: step 533, loss = 0.72668 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:39:41.727419 ops/training.py:65 2019-01-16 19:39:41.727325: step 534, loss = 0.73372 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:39:42.622131 ops/training.py:65 2019-01-16 19:39:42.622035: step 535, loss = 0.70664 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:39:43.520374 ops/training.py:65 2019-01-16 19:39:43.520273: step 536, loss = 0.67349 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:39:44.417858 ops/training.py:65 2019-01-16 19:39:44.417743: step 537, loss = 0.65362 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:39:45.312825 ops/training.py:65 2019-01-16 19:39:45.312766: step 538, loss = 0.70066 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:39:46.206839 ops/training.py:65 2019-01-16 19:39:46.206786: step 539, loss = 0.66691 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:39:47.102022 ops/training.py:65 2019-01-16 19:39:47.101963: step 540, loss = 0.60264 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.75
I1280 2019-01-16 19:39:47.998821 ops/training.py:65 2019-01-16 19:39:47.998715: step 541, loss = 0.67058 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:39:48.896545 ops/training.py:65 2019-01-16 19:39:48.896441: step 542, loss = 0.69556 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:39:49.795761 ops/training.py:65 2019-01-16 19:39:49.795670: step 543, loss = 0.72387 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:39:50.694232 ops/training.py:65 2019-01-16 19:39:50.694131: step 544, loss = 0.68179 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:39:51.592055 ops/training.py:65 2019-01-16 19:39:51.591957: step 545, loss = 0.70042 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:39:52.487860 ops/training.py:65 2019-01-16 19:39:52.487808: step 546, loss = 0.72315 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:39:53.383135 ops/training.py:65 2019-01-16 19:39:53.383036: step 547, loss = 0.67744 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:39:54.278399 ops/training.py:65 2019-01-16 19:39:54.278299: step 548, loss = 0.76096 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 19:39:55.173030 ops/training.py:65 2019-01-16 19:39:55.172933: step 549, loss = 0.71848 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:39:56.068991 ops/training.py:65 2019-01-16 19:39:56.068885: step 550, loss = 0.74215 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:39:56.964640 ops/training.py:65 2019-01-16 19:39:56.964534: step 551, loss = 0.74570 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:39:57.860035 ops/training.py:65 2019-01-16 19:39:57.859922: step 552, loss = 0.65889 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:39:58.755496 ops/training.py:65 2019-01-16 19:39:58.755394: step 553, loss = 0.68794 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:39:59.653497 ops/training.py:65 2019-01-16 19:39:59.653396: step 554, loss = 0.67936 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:40:00.549584 ops/training.py:65 2019-01-16 19:40:00.549485: step 555, loss = 0.70849 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:40:01.445323 ops/training.py:65 2019-01-16 19:40:01.445270: step 556, loss = 0.70498 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:40:02.341969 ops/training.py:65 2019-01-16 19:40:02.341892: step 557, loss = 0.68054 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:40:03.239684 ops/training.py:65 2019-01-16 19:40:03.239591: step 558, loss = 0.69712 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:40:04.136345 ops/training.py:65 2019-01-16 19:40:04.136247: step 559, loss = 0.69037 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:40:05.033451 ops/training.py:65 2019-01-16 19:40:05.033359: step 560, loss = 0.67821 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:40:05.929242 ops/training.py:65 2019-01-16 19:40:05.929160: step 561, loss = 0.67282 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:40:06.824525 ops/training.py:65 2019-01-16 19:40:06.824457: step 562, loss = 0.70759 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:40:07.720107 ops/training.py:65 2019-01-16 19:40:07.720042: step 563, loss = 0.67448 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:40:08.614826 ops/training.py:65 2019-01-16 19:40:08.614765: step 564, loss = 0.68148 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:40:09.510438 ops/training.py:65 2019-01-16 19:40:09.510379: step 565, loss = 0.69339 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:40:10.405058 ops/training.py:65 2019-01-16 19:40:10.404989: step 566, loss = 0.67857 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:40:11.300863 ops/training.py:65 2019-01-16 19:40:11.300799: step 567, loss = 0.69964 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:40:12.195530 ops/training.py:65 2019-01-16 19:40:12.195471: step 568, loss = 0.70672 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:40:13.089996 ops/training.py:65 2019-01-16 19:40:13.089925: step 569, loss = 0.66928 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:40:13.984261 ops/training.py:65 2019-01-16 19:40:13.984207: step 570, loss = 0.69775 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:40:14.878680 ops/training.py:65 2019-01-16 19:40:14.878621: step 571, loss = 0.71841 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:40:15.772882 ops/training.py:65 2019-01-16 19:40:15.772816: step 572, loss = 0.68323 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:40:16.667500 ops/training.py:65 2019-01-16 19:40:16.667443: step 573, loss = 0.69949 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:40:17.563407 ops/training.py:65 2019-01-16 19:40:17.563359: step 574, loss = 0.70127 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:40:18.458098 ops/training.py:65 2019-01-16 19:40:18.458041: step 575, loss = 0.66614 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:40:19.354755 ops/training.py:65 2019-01-16 19:40:19.354660: step 576, loss = 0.64816 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 19:40:20.251101 ops/training.py:65 2019-01-16 19:40:20.251019: step 577, loss = 0.74290 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:40:21.148145 ops/training.py:65 2019-01-16 19:40:21.148056: step 578, loss = 0.68845 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:40:22.045752 ops/training.py:65 2019-01-16 19:40:22.045667: step 579, loss = 0.73393 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:40:22.940821 ops/training.py:65 2019-01-16 19:40:22.940757: step 580, loss = 0.70308 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:40:23.834971 ops/training.py:65 2019-01-16 19:40:23.834914: step 581, loss = 0.66494 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:40:24.729929 ops/training.py:65 2019-01-16 19:40:24.729874: step 582, loss = 0.66825 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:40:25.628552 ops/training.py:65 2019-01-16 19:40:25.628464: step 583, loss = 0.70418 (35.7 examples/sec; 0.898 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:40:26.523999 ops/training.py:65 2019-01-16 19:40:26.523906: step 584, loss = 0.71500 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:40:27.419605 ops/training.py:65 2019-01-16 19:40:27.419507: step 585, loss = 0.67596 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:40:28.315114 ops/training.py:65 2019-01-16 19:40:28.315019: step 586, loss = 0.69532 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:40:29.212788 ops/training.py:65 2019-01-16 19:40:29.212697: step 587, loss = 0.72641 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:40:30.110171 ops/training.py:65 2019-01-16 19:40:30.110077: step 588, loss = 0.69305 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:40:31.005633 ops/training.py:65 2019-01-16 19:40:31.005552: step 589, loss = 0.75706 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:40:31.901460 ops/training.py:65 2019-01-16 19:40:31.901399: step 590, loss = 0.74313 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:40:32.827675 ops/training.py:65 2019-01-16 19:40:32.827629: step 591, loss = 0.72995 (34.6 examples/sec; 0.925 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:40:33.725510 ops/training.py:65 2019-01-16 19:40:33.725415: step 592, loss = 0.78051 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:40:34.622204 ops/training.py:65 2019-01-16 19:40:34.622129: step 593, loss = 0.74587 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:40:35.517173 ops/training.py:65 2019-01-16 19:40:35.517094: step 594, loss = 0.73406 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:40:36.413762 ops/training.py:65 2019-01-16 19:40:36.413670: step 595, loss = 0.72157 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:40:37.310566 ops/training.py:65 2019-01-16 19:40:37.310473: step 596, loss = 0.72700 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:40:38.206329 ops/training.py:65 2019-01-16 19:40:38.206258: step 597, loss = 0.75031 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:40:39.103779 ops/training.py:65 2019-01-16 19:40:39.103693: step 598, loss = 0.80829 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:40:40.000381 ops/training.py:65 2019-01-16 19:40:40.000300: step 599, loss = 0.66561 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:40:40.896604 ops/training.py:65 2019-01-16 19:40:40.896544: step 600, loss = 0.73393 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:40:41.792788 ops/training.py:65 2019-01-16 19:40:41.792734: step 601, loss = 0.68382 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:40:42.688301 ops/training.py:65 2019-01-16 19:40:42.688231: step 602, loss = 0.74280 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:40:43.584131 ops/training.py:65 2019-01-16 19:40:43.584078: step 603, loss = 0.74896 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:40:44.478664 ops/training.py:65 2019-01-16 19:40:44.478607: step 604, loss = 0.69321 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:40:45.373223 ops/training.py:65 2019-01-16 19:40:45.373164: step 605, loss = 0.71237 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:40:46.269130 ops/training.py:65 2019-01-16 19:40:46.269072: step 606, loss = 0.71831 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:40:47.165324 ops/training.py:65 2019-01-16 19:40:47.165216: step 607, loss = 0.69238 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:40:48.059675 ops/training.py:65 2019-01-16 19:40:48.059595: step 608, loss = 0.73570 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:40:48.954582 ops/training.py:65 2019-01-16 19:40:48.954480: step 609, loss = 0.76058 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:40:49.849711 ops/training.py:65 2019-01-16 19:40:49.849634: step 610, loss = 0.78921 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:40:50.747414 ops/training.py:65 2019-01-16 19:40:50.747321: step 611, loss = 0.70557 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:40:51.643848 ops/training.py:65 2019-01-16 19:40:51.643756: step 612, loss = 0.69904 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:40:52.539725 ops/training.py:65 2019-01-16 19:40:52.539674: step 613, loss = 0.73449 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:40:53.438219 ops/training.py:65 2019-01-16 19:40:53.438119: step 614, loss = 0.73656 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:40:54.335625 ops/training.py:65 2019-01-16 19:40:54.335527: step 615, loss = 0.69739 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:40:55.232644 ops/training.py:65 2019-01-16 19:40:55.232584: step 616, loss = 0.71777 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:40:56.128388 ops/training.py:65 2019-01-16 19:40:56.128328: step 617, loss = 0.68407 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:40:57.022187 ops/training.py:65 2019-01-16 19:40:57.022135: step 618, loss = 0.71563 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:40:57.920468 ops/training.py:65 2019-01-16 19:40:57.920366: step 619, loss = 0.77050 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:40:58.819020 ops/training.py:65 2019-01-16 19:40:58.818921: step 620, loss = 0.70848 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:40:59.716369 ops/training.py:65 2019-01-16 19:40:59.716306: step 621, loss = 0.69041 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:41:00.613937 ops/training.py:65 2019-01-16 19:41:00.613874: step 622, loss = 0.69916 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:41:01.509679 ops/training.py:65 2019-01-16 19:41:01.509622: step 623, loss = 0.71996 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:41:02.403760 ops/training.py:65 2019-01-16 19:41:02.403705: step 624, loss = 0.74495 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:41:03.299133 ops/training.py:65 2019-01-16 19:41:03.299068: step 625, loss = 0.75269 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:41:04.194117 ops/training.py:65 2019-01-16 19:41:04.194059: step 626, loss = 0.70976 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:41:05.090266 ops/training.py:65 2019-01-16 19:41:05.090195: step 627, loss = 0.72673 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:41:05.986206 ops/training.py:65 2019-01-16 19:41:05.986125: step 628, loss = 0.69403 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:41:06.881484 ops/training.py:65 2019-01-16 19:41:06.881385: step 629, loss = 0.70157 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:41:07.775855 ops/training.py:65 2019-01-16 19:41:07.775795: step 630, loss = 0.73456 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:41:08.668982 ops/training.py:65 2019-01-16 19:41:08.668930: step 631, loss = 0.71028 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:41:09.561873 ops/training.py:65 2019-01-16 19:41:09.561817: step 632, loss = 0.75742 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:41:10.456713 ops/training.py:65 2019-01-16 19:41:10.456664: step 633, loss = 0.64101 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:41:11.352590 ops/training.py:65 2019-01-16 19:41:11.352488: step 634, loss = 0.71096 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:41:12.247125 ops/training.py:65 2019-01-16 19:41:12.247035: step 635, loss = 0.70240 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:41:13.143047 ops/training.py:65 2019-01-16 19:41:13.142946: step 636, loss = 0.62161 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:41:14.037766 ops/training.py:65 2019-01-16 19:41:14.037669: step 637, loss = 0.72943 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:41:14.932573 ops/training.py:65 2019-01-16 19:41:14.932481: step 638, loss = 0.68050 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:41:15.828397 ops/training.py:65 2019-01-16 19:41:15.828297: step 639, loss = 0.69797 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:41:16.724879 ops/training.py:65 2019-01-16 19:41:16.724781: step 640, loss = 0.79217 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 19:41:17.619238 ops/training.py:65 2019-01-16 19:41:17.619193: step 641, loss = 0.75233 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:41:18.512768 ops/training.py:65 2019-01-16 19:41:18.512719: step 642, loss = 0.68799 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:41:19.408046 ops/training.py:65 2019-01-16 19:41:19.407987: step 643, loss = 0.73671 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:41:20.303441 ops/training.py:65 2019-01-16 19:41:20.303365: step 644, loss = 0.74739 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:41:21.198160 ops/training.py:65 2019-01-16 19:41:21.198063: step 645, loss = 0.69408 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:41:22.094071 ops/training.py:65 2019-01-16 19:41:22.093975: step 646, loss = 0.71403 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:41:22.989942 ops/training.py:65 2019-01-16 19:41:22.989835: step 647, loss = 0.74306 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:41:23.887381 ops/training.py:65 2019-01-16 19:41:23.887279: step 648, loss = 0.70155 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:41:24.783664 ops/training.py:65 2019-01-16 19:41:24.783567: step 649, loss = 0.68651 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:41:25.678974 ops/training.py:65 2019-01-16 19:41:25.678924: step 650, loss = 0.70793 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:41:26.572370 ops/training.py:65 2019-01-16 19:41:26.572316: step 651, loss = 0.69793 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:41:27.466955 ops/training.py:65 2019-01-16 19:41:27.466894: step 652, loss = 0.71154 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:41:28.361872 ops/training.py:65 2019-01-16 19:41:28.361816: step 653, loss = 0.68483 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:41:29.256603 ops/training.py:65 2019-01-16 19:41:29.256548: step 654, loss = 0.69077 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:41:30.149701 ops/training.py:65 2019-01-16 19:41:30.149646: step 655, loss = 0.71040 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:41:31.045490 ops/training.py:65 2019-01-16 19:41:31.045425: step 656, loss = 0.70702 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:41:31.942249 ops/training.py:65 2019-01-16 19:41:31.942151: step 657, loss = 0.69748 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:41:32.838169 ops/training.py:65 2019-01-16 19:41:32.838092: step 658, loss = 0.68572 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:41:33.734502 ops/training.py:65 2019-01-16 19:41:33.734411: step 659, loss = 0.68874 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:41:34.630291 ops/training.py:65 2019-01-16 19:41:34.630220: step 660, loss = 0.68395 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:41:35.527509 ops/training.py:65 2019-01-16 19:41:35.527440: step 661, loss = 0.70005 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:41:36.422970 ops/training.py:65 2019-01-16 19:41:36.422885: step 662, loss = 0.70862 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:41:37.318284 ops/training.py:65 2019-01-16 19:41:37.318185: step 663, loss = 0.70884 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:41:38.213234 ops/training.py:65 2019-01-16 19:41:38.213138: step 664, loss = 0.69671 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:41:39.108183 ops/training.py:65 2019-01-16 19:41:39.108094: step 665, loss = 0.70080 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:41:40.002906 ops/training.py:65 2019-01-16 19:41:40.002811: step 666, loss = 0.67731 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:41:40.897721 ops/training.py:65 2019-01-16 19:41:40.897629: step 667, loss = 0.69321 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:41:41.794533 ops/training.py:65 2019-01-16 19:41:41.794437: step 668, loss = 0.69702 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:41:42.690746 ops/training.py:65 2019-01-16 19:41:42.690647: step 669, loss = 0.70619 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:41:43.587936 ops/training.py:65 2019-01-16 19:41:43.587863: step 670, loss = 0.68754 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:41:44.482600 ops/training.py:65 2019-01-16 19:41:44.482544: step 671, loss = 0.71245 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:41:45.377161 ops/training.py:65 2019-01-16 19:41:45.377097: step 672, loss = 0.67718 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:41:46.275014 ops/training.py:65 2019-01-16 19:41:46.274913: step 673, loss = 0.68634 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:41:47.172472 ops/training.py:65 2019-01-16 19:41:47.172379: step 674, loss = 0.69889 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:41:48.068155 ops/training.py:65 2019-01-16 19:41:48.068088: step 675, loss = 0.68437 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:41:48.961914 ops/training.py:65 2019-01-16 19:41:48.961862: step 676, loss = 0.69310 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:41:49.855787 ops/training.py:65 2019-01-16 19:41:49.855740: step 677, loss = 0.70906 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:41:50.748881 ops/training.py:65 2019-01-16 19:41:50.748824: step 678, loss = 0.67972 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:41:51.643808 ops/training.py:65 2019-01-16 19:41:51.643752: step 679, loss = 0.70713 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:41:52.541850 ops/training.py:65 2019-01-16 19:41:52.541748: step 680, loss = 0.70052 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:41:53.439499 ops/training.py:65 2019-01-16 19:41:53.439401: step 681, loss = 0.70078 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:41:54.334867 ops/training.py:65 2019-01-16 19:41:54.334819: step 682, loss = 0.69301 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:41:55.229875 ops/training.py:65 2019-01-16 19:41:55.229776: step 683, loss = 0.70693 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:41:56.127919 ops/training.py:65 2019-01-16 19:41:56.127816: step 684, loss = 0.68939 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:41:57.024950 ops/training.py:65 2019-01-16 19:41:57.024853: step 685, loss = 0.71065 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:41:57.920824 ops/training.py:65 2019-01-16 19:41:57.920751: step 686, loss = 0.70095 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:41:58.815122 ops/training.py:65 2019-01-16 19:41:58.815030: step 687, loss = 0.68691 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:41:59.709223 ops/training.py:65 2019-01-16 19:41:59.709132: step 688, loss = 0.68354 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:42:00.604565 ops/training.py:65 2019-01-16 19:42:00.604469: step 689, loss = 0.69946 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:42:01.499424 ops/training.py:65 2019-01-16 19:42:01.499340: step 690, loss = 0.71209 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:42:02.394253 ops/training.py:65 2019-01-16 19:42:02.394174: step 691, loss = 0.68403 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:42:03.288300 ops/training.py:65 2019-01-16 19:42:03.288230: step 692, loss = 0.69954 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:42:04.182571 ops/training.py:65 2019-01-16 19:42:04.182477: step 693, loss = 0.69520 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:42:05.076438 ops/training.py:65 2019-01-16 19:42:05.076369: step 694, loss = 0.69217 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:42:05.969913 ops/training.py:65 2019-01-16 19:42:05.969837: step 695, loss = 0.69136 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:42:06.863991 ops/training.py:65 2019-01-16 19:42:06.863898: step 696, loss = 0.69932 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:42:07.758341 ops/training.py:65 2019-01-16 19:42:07.758246: step 697, loss = 0.68970 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:42:08.652448 ops/training.py:65 2019-01-16 19:42:08.652352: step 698, loss = 0.68963 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:42:09.546868 ops/training.py:65 2019-01-16 19:42:09.546792: step 699, loss = 0.70806 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 19:42:10.443060 ops/training.py:65 2019-01-16 19:42:10.442969: step 700, loss = 0.68355 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:42:11.338473 ops/training.py:65 2019-01-16 19:42:11.338390: step 701, loss = 0.70507 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:42:12.234475 ops/training.py:65 2019-01-16 19:42:12.234419: step 702, loss = 0.71213 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 19:42:13.128540 ops/training.py:65 2019-01-16 19:42:13.128487: step 703, loss = 0.70514 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:42:14.025300 ops/training.py:65 2019-01-16 19:42:14.025197: step 704, loss = 0.70031 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:42:14.921884 ops/training.py:65 2019-01-16 19:42:14.921780: step 705, loss = 0.69418 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:42:15.817563 ops/training.py:65 2019-01-16 19:42:15.817507: step 706, loss = 0.68335 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:42:16.712465 ops/training.py:65 2019-01-16 19:42:16.712410: step 707, loss = 0.69868 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:42:17.607051 ops/training.py:65 2019-01-16 19:42:17.607002: step 708, loss = 0.69072 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:42:18.502308 ops/training.py:65 2019-01-16 19:42:18.502244: step 709, loss = 0.70338 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:42:19.396636 ops/training.py:65 2019-01-16 19:42:19.396584: step 710, loss = 0.69075 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:42:20.290582 ops/training.py:65 2019-01-16 19:42:20.290509: step 711, loss = 0.70971 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:42:21.188029 ops/training.py:65 2019-01-16 19:42:21.187927: step 712, loss = 0.69426 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:42:22.084630 ops/training.py:65 2019-01-16 19:42:22.084540: step 713, loss = 0.70196 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:42:22.980727 ops/training.py:65 2019-01-16 19:42:22.980669: step 714, loss = 0.66887 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:42:23.878844 ops/training.py:65 2019-01-16 19:42:23.878744: step 715, loss = 0.71010 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:42:24.773966 ops/training.py:65 2019-01-16 19:42:24.773859: step 716, loss = 0.70266 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:42:25.671736 ops/training.py:65 2019-01-16 19:42:25.671629: step 717, loss = 0.69792 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:42:26.569780 ops/training.py:65 2019-01-16 19:42:26.569677: step 718, loss = 0.70448 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:42:27.465199 ops/training.py:65 2019-01-16 19:42:27.465100: step 719, loss = 0.69095 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:42:28.364111 ops/training.py:65 2019-01-16 19:42:28.364018: step 720, loss = 0.68863 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:42:29.259672 ops/training.py:65 2019-01-16 19:42:29.259561: step 721, loss = 0.68451 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:42:30.154109 ops/training.py:65 2019-01-16 19:42:30.154014: step 722, loss = 0.69174 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:42:31.051915 ops/training.py:65 2019-01-16 19:42:31.051817: step 723, loss = 0.68417 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:42:31.951034 ops/training.py:65 2019-01-16 19:42:31.950937: step 724, loss = 0.66792 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:42:32.846937 ops/training.py:65 2019-01-16 19:42:32.846885: step 725, loss = 0.68824 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:42:33.742512 ops/training.py:65 2019-01-16 19:42:33.742458: step 726, loss = 0.69582 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:42:34.637734 ops/training.py:65 2019-01-16 19:42:34.637680: step 727, loss = 0.69332 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:42:35.533523 ops/training.py:65 2019-01-16 19:42:35.533447: step 728, loss = 0.71244 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:42:36.431788 ops/training.py:65 2019-01-16 19:42:36.431700: step 729, loss = 0.69880 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:42:37.328389 ops/training.py:65 2019-01-16 19:42:37.328304: step 730, loss = 0.69413 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:42:38.223505 ops/training.py:65 2019-01-16 19:42:38.223451: step 731, loss = 0.67825 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:42:39.117909 ops/training.py:65 2019-01-16 19:42:39.117809: step 732, loss = 0.69040 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:42:40.015229 ops/training.py:65 2019-01-16 19:42:40.015129: step 733, loss = 0.72493 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:42:40.913358 ops/training.py:65 2019-01-16 19:42:40.913268: step 734, loss = 0.70000 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:42:41.808497 ops/training.py:65 2019-01-16 19:42:41.808443: step 735, loss = 0.70350 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:42:42.703586 ops/training.py:65 2019-01-16 19:42:42.703526: step 736, loss = 0.71179 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:42:43.601583 ops/training.py:65 2019-01-16 19:42:43.601485: step 737, loss = 0.70190 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:42:44.498520 ops/training.py:65 2019-01-16 19:42:44.498422: step 738, loss = 0.68058 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:42:45.394032 ops/training.py:65 2019-01-16 19:42:45.393984: step 739, loss = 0.66989 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 19:42:46.288344 ops/training.py:65 2019-01-16 19:42:46.288250: step 740, loss = 0.69538 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:42:47.184589 ops/training.py:65 2019-01-16 19:42:47.184500: step 741, loss = 0.69742 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:42:48.081769 ops/training.py:65 2019-01-16 19:42:48.081674: step 742, loss = 0.71061 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:42:48.978283 ops/training.py:65 2019-01-16 19:42:48.978187: step 743, loss = 0.68964 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:42:49.873518 ops/training.py:65 2019-01-16 19:42:49.873439: step 744, loss = 0.71458 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:42:50.768414 ops/training.py:65 2019-01-16 19:42:50.768314: step 745, loss = 0.68077 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:42:51.667513 ops/training.py:65 2019-01-16 19:42:51.667415: step 746, loss = 0.67900 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:42:52.564742 ops/training.py:65 2019-01-16 19:42:52.564640: step 747, loss = 0.69806 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:42:53.460696 ops/training.py:65 2019-01-16 19:42:53.460635: step 748, loss = 0.67386 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.78125
I1280 2019-01-16 19:42:54.355968 ops/training.py:65 2019-01-16 19:42:54.355907: step 749, loss = 0.69467 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:42:55.251389 ops/training.py:65 2019-01-16 19:42:55.251331: step 750, loss = 0.69767 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:42:56.146710 ops/training.py:65 2019-01-16 19:42:56.146653: step 751, loss = 0.71022 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:42:57.043106 ops/training.py:65 2019-01-16 19:42:57.043046: step 752, loss = 0.69658 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:42:57.939723 ops/training.py:65 2019-01-16 19:42:57.939661: step 753, loss = 0.71421 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:42:58.834688 ops/training.py:65 2019-01-16 19:42:58.834632: step 754, loss = 0.68786 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:42:59.733958 ops/training.py:65 2019-01-16 19:42:59.733861: step 755, loss = 0.67899 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:43:00.631611 ops/training.py:65 2019-01-16 19:43:00.631514: step 756, loss = 0.68555 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:43:01.527653 ops/training.py:65 2019-01-16 19:43:01.527597: step 757, loss = 0.71320 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:43:02.422746 ops/training.py:65 2019-01-16 19:43:02.422696: step 758, loss = 0.70070 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:43:03.321812 ops/training.py:65 2019-01-16 19:43:03.321724: step 759, loss = 0.70806 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:43:04.219639 ops/training.py:65 2019-01-16 19:43:04.219545: step 760, loss = 0.67141 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:43:05.115729 ops/training.py:65 2019-01-16 19:43:05.115658: step 761, loss = 0.68903 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:43:06.012260 ops/training.py:65 2019-01-16 19:43:06.012173: step 762, loss = 0.69651 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:43:06.908790 ops/training.py:65 2019-01-16 19:43:06.908696: step 763, loss = 0.69497 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:43:07.803159 ops/training.py:65 2019-01-16 19:43:07.803066: step 764, loss = 0.67331 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:43:08.699777 ops/training.py:65 2019-01-16 19:43:08.699688: step 765, loss = 0.76086 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:43:09.596583 ops/training.py:65 2019-01-16 19:43:09.596492: step 766, loss = 0.67959 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:43:10.490434 ops/training.py:65 2019-01-16 19:43:10.490344: step 767, loss = 0.73849 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:43:11.385105 ops/training.py:65 2019-01-16 19:43:11.385009: step 768, loss = 0.70197 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:43:12.283896 ops/training.py:65 2019-01-16 19:43:12.283804: step 769, loss = 0.67512 (35.7 examples/sec; 0.898 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:43:13.181664 ops/training.py:65 2019-01-16 19:43:13.181571: step 770, loss = 0.67964 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:43:14.078153 ops/training.py:65 2019-01-16 19:43:14.078089: step 771, loss = 0.64701 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.75
I1280 2019-01-16 19:43:14.972190 ops/training.py:65 2019-01-16 19:43:14.972137: step 772, loss = 0.71019 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:43:15.867328 ops/training.py:65 2019-01-16 19:43:15.867226: step 773, loss = 0.65578 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 19:43:16.761663 ops/training.py:65 2019-01-16 19:43:16.761560: step 774, loss = 0.71156 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:43:17.659079 ops/training.py:65 2019-01-16 19:43:17.659005: step 775, loss = 0.66260 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:43:18.556392 ops/training.py:65 2019-01-16 19:43:18.556260: step 776, loss = 0.68246 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:43:19.453403 ops/training.py:65 2019-01-16 19:43:19.453344: step 777, loss = 0.73147 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:43:20.348030 ops/training.py:65 2019-01-16 19:43:20.347979: step 778, loss = 0.67512 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:43:21.242393 ops/training.py:65 2019-01-16 19:43:21.242335: step 779, loss = 0.72517 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:43:22.136701 ops/training.py:65 2019-01-16 19:43:22.136645: step 780, loss = 0.69524 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:43:23.030981 ops/training.py:65 2019-01-16 19:43:23.030924: step 781, loss = 0.69619 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:43:23.925956 ops/training.py:65 2019-01-16 19:43:23.925891: step 782, loss = 0.71044 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:43:24.823963 ops/training.py:65 2019-01-16 19:43:24.823862: step 783, loss = 0.67504 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:43:25.720173 ops/training.py:65 2019-01-16 19:43:25.720076: step 784, loss = 0.71827 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:43:26.614721 ops/training.py:65 2019-01-16 19:43:26.614622: step 785, loss = 0.68848 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:43:27.512068 ops/training.py:65 2019-01-16 19:43:27.511966: step 786, loss = 0.69216 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:43:28.409926 ops/training.py:65 2019-01-16 19:43:28.409831: step 787, loss = 0.69097 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:43:29.306123 ops/training.py:65 2019-01-16 19:43:29.306065: step 788, loss = 0.72963 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.25
I1280 2019-01-16 19:43:30.199764 ops/training.py:65 2019-01-16 19:43:30.199714: step 789, loss = 0.71238 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:43:31.094825 ops/training.py:65 2019-01-16 19:43:31.094722: step 790, loss = 0.71131 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:43:31.993835 ops/training.py:65 2019-01-16 19:43:31.993740: step 791, loss = 0.69680 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:43:32.893069 ops/training.py:65 2019-01-16 19:43:32.892984: step 792, loss = 0.70611 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:43:33.791354 ops/training.py:65 2019-01-16 19:43:33.791256: step 793, loss = 0.69814 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:43:34.690444 ops/training.py:65 2019-01-16 19:43:34.690349: step 794, loss = 0.69422 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:43:35.588582 ops/training.py:65 2019-01-16 19:43:35.588499: step 795, loss = 0.69143 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:43:36.485213 ops/training.py:65 2019-01-16 19:43:36.485121: step 796, loss = 0.69409 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:43:37.381787 ops/training.py:65 2019-01-16 19:43:37.381692: step 797, loss = 0.71226 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:43:38.277961 ops/training.py:65 2019-01-16 19:43:38.277891: step 798, loss = 0.69436 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:43:39.172581 ops/training.py:65 2019-01-16 19:43:39.172530: step 799, loss = 0.69953 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:43:40.070809 ops/training.py:65 2019-01-16 19:43:40.070708: step 800, loss = 0.69814 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:43:40.967526 ops/training.py:65 2019-01-16 19:43:40.967449: step 801, loss = 0.68720 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:43:41.864499 ops/training.py:65 2019-01-16 19:43:41.864437: step 802, loss = 0.69436 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:43:42.759784 ops/training.py:65 2019-01-16 19:43:42.759716: step 803, loss = 0.70225 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:43:43.655476 ops/training.py:65 2019-01-16 19:43:43.655416: step 804, loss = 0.68737 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:43:44.550843 ops/training.py:65 2019-01-16 19:43:44.550779: step 805, loss = 0.69637 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:43:45.447223 ops/training.py:65 2019-01-16 19:43:45.447160: step 806, loss = 0.70118 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:43:46.341766 ops/training.py:65 2019-01-16 19:43:46.341717: step 807, loss = 0.70952 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:43:47.240321 ops/training.py:65 2019-01-16 19:43:47.240218: step 808, loss = 0.70232 (35.7 examples/sec; 0.898 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:43:48.139082 ops/training.py:65 2019-01-16 19:43:48.138984: step 809, loss = 0.69250 (35.7 examples/sec; 0.898 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:43:49.035054 ops/training.py:65 2019-01-16 19:43:49.034954: step 810, loss = 0.68939 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:43:49.932657 ops/training.py:65 2019-01-16 19:43:49.932573: step 811, loss = 0.70420 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:43:50.829817 ops/training.py:65 2019-01-16 19:43:50.829718: step 812, loss = 0.69278 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:43:51.729287 ops/training.py:65 2019-01-16 19:43:51.729194: step 813, loss = 0.69330 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:43:52.625786 ops/training.py:65 2019-01-16 19:43:52.625724: step 814, loss = 0.69433 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:43:53.521217 ops/training.py:65 2019-01-16 19:43:53.521150: step 815, loss = 0.69968 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:43:54.417505 ops/training.py:65 2019-01-16 19:43:54.417442: step 816, loss = 0.69906 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:43:55.312244 ops/training.py:65 2019-01-16 19:43:55.312184: step 817, loss = 0.70043 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:43:56.206887 ops/training.py:65 2019-01-16 19:43:56.206829: step 818, loss = 0.69533 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:43:57.100921 ops/training.py:65 2019-01-16 19:43:57.100869: step 819, loss = 0.70430 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:43:57.998072 ops/training.py:65 2019-01-16 19:43:57.998013: step 820, loss = 0.69072 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:43:58.894591 ops/training.py:65 2019-01-16 19:43:58.894498: step 821, loss = 0.70080 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:43:59.791021 ops/training.py:65 2019-01-16 19:43:59.790948: step 822, loss = 0.69275 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:44:00.687098 ops/training.py:65 2019-01-16 19:44:00.687033: step 823, loss = 0.69278 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:44:01.583193 ops/training.py:65 2019-01-16 19:44:01.583134: step 824, loss = 0.68450 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:44:02.478538 ops/training.py:65 2019-01-16 19:44:02.478474: step 825, loss = 0.67798 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:44:03.374375 ops/training.py:65 2019-01-16 19:44:03.374317: step 826, loss = 0.69709 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:44:04.269390 ops/training.py:65 2019-01-16 19:44:04.269326: step 827, loss = 0.68748 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:44:05.164124 ops/training.py:65 2019-01-16 19:44:05.164053: step 828, loss = 0.67892 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:44:06.059545 ops/training.py:65 2019-01-16 19:44:06.059464: step 829, loss = 0.69817 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:44:06.955775 ops/training.py:65 2019-01-16 19:44:06.955678: step 830, loss = 0.70425 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:44:07.853292 ops/training.py:65 2019-01-16 19:44:07.853224: step 831, loss = 0.68897 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:44:08.748272 ops/training.py:65 2019-01-16 19:44:08.748205: step 832, loss = 0.68503 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:44:09.644736 ops/training.py:65 2019-01-16 19:44:09.644677: step 833, loss = 0.69334 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:44:10.540853 ops/training.py:65 2019-01-16 19:44:10.540783: step 834, loss = 0.68930 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:44:11.435823 ops/training.py:65 2019-01-16 19:44:11.435759: step 835, loss = 0.69094 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:44:12.330387 ops/training.py:65 2019-01-16 19:44:12.330332: step 836, loss = 0.69268 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:44:13.227343 ops/training.py:65 2019-01-16 19:44:13.227281: step 837, loss = 0.71116 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:44:14.126087 ops/training.py:65 2019-01-16 19:44:14.125985: step 838, loss = 0.67985 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:44:15.023821 ops/training.py:65 2019-01-16 19:44:15.023726: step 839, loss = 0.69676 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:44:15.920769 ops/training.py:65 2019-01-16 19:44:15.920718: step 840, loss = 0.70433 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:44:16.818682 ops/training.py:65 2019-01-16 19:44:16.818584: step 841, loss = 0.68148 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:44:17.714425 ops/training.py:65 2019-01-16 19:44:17.714347: step 842, loss = 0.68258 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:44:18.611125 ops/training.py:65 2019-01-16 19:44:18.611024: step 843, loss = 0.68340 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:44:19.506243 ops/training.py:65 2019-01-16 19:44:19.506146: step 844, loss = 0.69864 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:44:20.399848 ops/training.py:65 2019-01-16 19:44:20.399771: step 845, loss = 0.67964 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:44:21.295545 ops/training.py:65 2019-01-16 19:44:21.295443: step 846, loss = 0.68570 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:44:22.189906 ops/training.py:65 2019-01-16 19:44:22.189808: step 847, loss = 0.70235 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:44:23.084688 ops/training.py:65 2019-01-16 19:44:23.084587: step 848, loss = 0.70590 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:44:23.983060 ops/training.py:65 2019-01-16 19:44:23.982953: step 849, loss = 0.68326 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:44:24.881065 ops/training.py:65 2019-01-16 19:44:24.880957: step 850, loss = 0.69603 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:44:25.776911 ops/training.py:65 2019-01-16 19:44:25.776839: step 851, loss = 0.71141 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:44:26.671245 ops/training.py:65 2019-01-16 19:44:26.671184: step 852, loss = 0.69605 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:44:27.566453 ops/training.py:65 2019-01-16 19:44:27.566396: step 853, loss = 0.67543 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 19:44:28.461941 ops/training.py:65 2019-01-16 19:44:28.461875: step 854, loss = 0.69892 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:44:29.357529 ops/training.py:65 2019-01-16 19:44:29.357460: step 855, loss = 0.71616 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:44:30.252711 ops/training.py:65 2019-01-16 19:44:30.252653: step 856, loss = 0.71460 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:44:31.146634 ops/training.py:65 2019-01-16 19:44:31.146581: step 857, loss = 0.68679 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:44:32.041735 ops/training.py:65 2019-01-16 19:44:32.041635: step 858, loss = 0.67870 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:44:32.936359 ops/training.py:65 2019-01-16 19:44:32.936279: step 859, loss = 0.68891 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:44:33.830537 ops/training.py:65 2019-01-16 19:44:33.830441: step 860, loss = 0.68809 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:44:34.725662 ops/training.py:65 2019-01-16 19:44:34.725584: step 861, loss = 0.70316 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:44:35.623135 ops/training.py:65 2019-01-16 19:44:35.623051: step 862, loss = 0.69005 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:44:36.520648 ops/training.py:65 2019-01-16 19:44:36.520549: step 863, loss = 0.69503 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:44:37.415746 ops/training.py:65 2019-01-16 19:44:37.415648: step 864, loss = 0.69922 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:44:38.311420 ops/training.py:65 2019-01-16 19:44:38.311317: step 865, loss = 0.68643 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:44:39.206277 ops/training.py:65 2019-01-16 19:44:39.206146: step 866, loss = 0.70090 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:44:40.101693 ops/training.py:65 2019-01-16 19:44:40.101593: step 867, loss = 0.69109 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:44:40.999298 ops/training.py:65 2019-01-16 19:44:40.999201: step 868, loss = 0.68799 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:44:41.896409 ops/training.py:65 2019-01-16 19:44:41.896311: step 869, loss = 0.68106 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:44:42.792188 ops/training.py:65 2019-01-16 19:44:42.792122: step 870, loss = 0.69979 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:44:43.687445 ops/training.py:65 2019-01-16 19:44:43.687345: step 871, loss = 0.70367 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:44:44.585537 ops/training.py:65 2019-01-16 19:44:44.585444: step 872, loss = 0.68851 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:44:45.480640 ops/training.py:65 2019-01-16 19:44:45.480549: step 873, loss = 0.69143 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:44:46.375495 ops/training.py:65 2019-01-16 19:44:46.375416: step 874, loss = 0.68872 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:44:47.270895 ops/training.py:65 2019-01-16 19:44:47.270812: step 875, loss = 0.70339 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:44:48.165423 ops/training.py:65 2019-01-16 19:44:48.165378: step 876, loss = 0.67286 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:44:49.059404 ops/training.py:65 2019-01-16 19:44:49.059310: step 877, loss = 0.70865 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:44:49.956346 ops/training.py:65 2019-01-16 19:44:49.956258: step 878, loss = 0.70188 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:44:50.853257 ops/training.py:65 2019-01-16 19:44:50.853160: step 879, loss = 0.70798 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:44:51.749729 ops/training.py:65 2019-01-16 19:44:51.749669: step 880, loss = 0.70349 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:44:52.644641 ops/training.py:65 2019-01-16 19:44:52.644578: step 881, loss = 0.70175 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:44:53.539320 ops/training.py:65 2019-01-16 19:44:53.539257: step 882, loss = 0.68489 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:44:54.434799 ops/training.py:65 2019-01-16 19:44:54.434740: step 883, loss = 0.69832 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:44:55.329884 ops/training.py:65 2019-01-16 19:44:55.329818: step 884, loss = 0.70029 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:44:56.225208 ops/training.py:65 2019-01-16 19:44:56.225149: step 885, loss = 0.68770 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:44:57.121570 ops/training.py:65 2019-01-16 19:44:57.121509: step 886, loss = 0.69607 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:44:58.017922 ops/training.py:65 2019-01-16 19:44:58.017854: step 887, loss = 0.70512 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 19:44:58.913849 ops/training.py:65 2019-01-16 19:44:58.913786: step 888, loss = 0.68922 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:44:59.808551 ops/training.py:65 2019-01-16 19:44:59.808489: step 889, loss = 0.70377 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:45:00.703288 ops/training.py:65 2019-01-16 19:45:00.703225: step 890, loss = 0.70123 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:45:01.598569 ops/training.py:65 2019-01-16 19:45:01.598513: step 891, loss = 0.68982 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:45:02.494481 ops/training.py:65 2019-01-16 19:45:02.494423: step 892, loss = 0.69646 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:45:03.389916 ops/training.py:65 2019-01-16 19:45:03.389860: step 893, loss = 0.71367 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:45:04.285219 ops/training.py:65 2019-01-16 19:45:04.285162: step 894, loss = 0.69157 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:45:05.181409 ops/training.py:65 2019-01-16 19:45:05.181303: step 895, loss = 0.68448 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:45:06.079982 ops/training.py:65 2019-01-16 19:45:06.079887: step 896, loss = 0.68526 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:45:06.975149 ops/training.py:65 2019-01-16 19:45:06.975063: step 897, loss = 0.69720 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:45:07.869412 ops/training.py:65 2019-01-16 19:45:07.869360: step 898, loss = 0.68466 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:45:08.764696 ops/training.py:65 2019-01-16 19:45:08.764591: step 899, loss = 0.70348 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:45:09.663181 ops/training.py:65 2019-01-16 19:45:09.663082: step 900, loss = 0.69241 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:45:10.559115 ops/training.py:65 2019-01-16 19:45:10.559036: step 901, loss = 0.69118 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:45:11.454777 ops/training.py:65 2019-01-16 19:45:11.454727: step 902, loss = 0.68736 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:45:12.353938 ops/training.py:65 2019-01-16 19:45:12.353844: step 903, loss = 0.69051 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:45:13.251857 ops/training.py:65 2019-01-16 19:45:13.251752: step 904, loss = 0.69867 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:45:14.148872 ops/training.py:65 2019-01-16 19:45:14.148812: step 905, loss = 0.68272 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:45:15.042956 ops/training.py:65 2019-01-16 19:45:15.042895: step 906, loss = 0.69367 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:45:15.939538 ops/training.py:65 2019-01-16 19:45:15.939474: step 907, loss = 0.68904 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:45:16.834389 ops/training.py:65 2019-01-16 19:45:16.834330: step 908, loss = 0.70103 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:45:17.731076 ops/training.py:65 2019-01-16 19:45:17.731024: step 909, loss = 0.70848 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:45:18.626314 ops/training.py:65 2019-01-16 19:45:18.626261: step 910, loss = 0.72248 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 19:45:19.521891 ops/training.py:65 2019-01-16 19:45:19.521828: step 911, loss = 0.70527 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:45:20.416827 ops/training.py:65 2019-01-16 19:45:20.416771: step 912, loss = 0.69585 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:45:21.313066 ops/training.py:65 2019-01-16 19:45:21.312999: step 913, loss = 0.71025 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:45:22.210042 ops/training.py:65 2019-01-16 19:45:22.209961: step 914, loss = 0.68156 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:45:23.106466 ops/training.py:65 2019-01-16 19:45:23.106368: step 915, loss = 0.69643 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:45:24.002562 ops/training.py:65 2019-01-16 19:45:24.002454: step 916, loss = 0.70381 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:45:24.900829 ops/training.py:65 2019-01-16 19:45:24.900725: step 917, loss = 0.68351 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:45:25.796139 ops/training.py:65 2019-01-16 19:45:25.796040: step 918, loss = 0.71646 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.25
I1280 2019-01-16 19:45:26.693157 ops/training.py:65 2019-01-16 19:45:26.693054: step 919, loss = 0.66671 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.78125
I1280 2019-01-16 19:45:27.589769 ops/training.py:65 2019-01-16 19:45:27.589667: step 920, loss = 0.68752 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:45:28.486311 ops/training.py:65 2019-01-16 19:45:28.486212: step 921, loss = 0.69728 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:45:29.384374 ops/training.py:65 2019-01-16 19:45:29.384272: step 922, loss = 0.67558 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 19:45:30.281783 ops/training.py:65 2019-01-16 19:45:30.281687: step 923, loss = 0.68816 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:45:31.180418 ops/training.py:65 2019-01-16 19:45:31.180323: step 924, loss = 0.69116 (35.7 examples/sec; 0.898 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:45:32.077660 ops/training.py:65 2019-01-16 19:45:32.077570: step 925, loss = 0.69501 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:45:32.972485 ops/training.py:65 2019-01-16 19:45:32.972438: step 926, loss = 0.70203 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:45:33.866541 ops/training.py:65 2019-01-16 19:45:33.866485: step 927, loss = 0.68876 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:45:34.761406 ops/training.py:65 2019-01-16 19:45:34.761356: step 928, loss = 0.68431 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:45:35.655274 ops/training.py:65 2019-01-16 19:45:35.655206: step 929, loss = 0.70000 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:45:36.550769 ops/training.py:65 2019-01-16 19:45:36.550680: step 930, loss = 0.72103 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 19:45:37.447734 ops/training.py:65 2019-01-16 19:45:37.447639: step 931, loss = 0.68685 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:45:38.344389 ops/training.py:65 2019-01-16 19:45:38.344291: step 932, loss = 0.70870 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:45:39.241912 ops/training.py:65 2019-01-16 19:45:39.241815: step 933, loss = 0.67867 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:45:40.138516 ops/training.py:65 2019-01-16 19:45:40.138423: step 934, loss = 0.72046 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:45:41.033721 ops/training.py:65 2019-01-16 19:45:41.033665: step 935, loss = 0.70394 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:45:41.928202 ops/training.py:65 2019-01-16 19:45:41.928141: step 936, loss = 0.68962 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:45:42.822671 ops/training.py:65 2019-01-16 19:45:42.822611: step 937, loss = 0.71335 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:45:43.717719 ops/training.py:65 2019-01-16 19:45:43.717618: step 938, loss = 0.67645 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:45:44.616627 ops/training.py:65 2019-01-16 19:45:44.616525: step 939, loss = 0.68533 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:45:45.511988 ops/training.py:65 2019-01-16 19:45:45.511891: step 940, loss = 0.71423 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 19:45:46.406272 ops/training.py:65 2019-01-16 19:45:46.406173: step 941, loss = 0.69080 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:45:47.304248 ops/training.py:65 2019-01-16 19:45:47.304150: step 942, loss = 0.72079 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:45:48.201266 ops/training.py:65 2019-01-16 19:45:48.201173: step 943, loss = 0.69507 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:45:49.100138 ops/training.py:65 2019-01-16 19:45:49.100038: step 944, loss = 0.69192 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:45:49.995747 ops/training.py:65 2019-01-16 19:45:49.995695: step 945, loss = 0.70530 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:45:50.890289 ops/training.py:65 2019-01-16 19:45:50.890227: step 946, loss = 0.69690 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:45:51.785310 ops/training.py:65 2019-01-16 19:45:51.785252: step 947, loss = 0.69988 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:45:52.680894 ops/training.py:65 2019-01-16 19:45:52.680841: step 948, loss = 0.72028 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:45:53.579401 ops/training.py:65 2019-01-16 19:45:53.579297: step 949, loss = 0.68520 (35.7 examples/sec; 0.898 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:45:54.478274 ops/training.py:65 2019-01-16 19:45:54.478171: step 950, loss = 0.70021 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:45:55.374650 ops/training.py:65 2019-01-16 19:45:55.374575: step 951, loss = 0.71584 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:45:56.269628 ops/training.py:65 2019-01-16 19:45:56.269569: step 952, loss = 0.67727 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:45:57.164199 ops/training.py:65 2019-01-16 19:45:57.164137: step 953, loss = 0.68877 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:45:58.060321 ops/training.py:65 2019-01-16 19:45:58.060256: step 954, loss = 0.67642 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:45:58.956665 ops/training.py:65 2019-01-16 19:45:58.956594: step 955, loss = 0.69097 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:45:59.855853 ops/training.py:65 2019-01-16 19:45:59.855785: step 956, loss = 0.70466 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:46:00.753024 ops/training.py:65 2019-01-16 19:46:00.752958: step 957, loss = 0.70167 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:46:01.648454 ops/training.py:65 2019-01-16 19:46:01.648392: step 958, loss = 0.69698 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:46:02.543116 ops/training.py:65 2019-01-16 19:46:02.543054: step 959, loss = 0.68906 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:46:03.438693 ops/training.py:65 2019-01-16 19:46:03.438636: step 960, loss = 0.73264 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 19:46:04.332876 ops/training.py:65 2019-01-16 19:46:04.332814: step 961, loss = 0.69853 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:46:05.228617 ops/training.py:65 2019-01-16 19:46:05.228546: step 962, loss = 0.71800 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:46:06.124437 ops/training.py:65 2019-01-16 19:46:06.124350: step 963, loss = 0.70757 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:46:07.020476 ops/training.py:65 2019-01-16 19:46:07.020374: step 964, loss = 0.68017 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:46:07.918210 ops/training.py:65 2019-01-16 19:46:07.918112: step 965, loss = 0.67986 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:46:08.814339 ops/training.py:65 2019-01-16 19:46:08.814242: step 966, loss = 0.70192 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:46:09.711442 ops/training.py:65 2019-01-16 19:46:09.711342: step 967, loss = 0.68084 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:46:10.606260 ops/training.py:65 2019-01-16 19:46:10.606183: step 968, loss = 0.69209 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:46:11.500574 ops/training.py:65 2019-01-16 19:46:11.500483: step 969, loss = 0.68768 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:46:12.396678 ops/training.py:65 2019-01-16 19:46:12.396579: step 970, loss = 0.68867 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:46:13.290722 ops/training.py:65 2019-01-16 19:46:13.290595: step 971, loss = 0.69217 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:46:14.184644 ops/training.py:65 2019-01-16 19:46:14.184548: step 972, loss = 0.70420 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:46:15.081244 ops/training.py:65 2019-01-16 19:46:15.081156: step 973, loss = 0.70774 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:46:15.977255 ops/training.py:65 2019-01-16 19:46:15.977184: step 974, loss = 0.68748 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:46:16.872468 ops/training.py:65 2019-01-16 19:46:16.872402: step 975, loss = 0.68483 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:46:17.767946 ops/training.py:65 2019-01-16 19:46:17.767892: step 976, loss = 0.70996 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:46:18.662827 ops/training.py:65 2019-01-16 19:46:18.662764: step 977, loss = 0.70600 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:46:19.558918 ops/training.py:65 2019-01-16 19:46:19.558854: step 978, loss = 0.69336 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:46:20.454596 ops/training.py:65 2019-01-16 19:46:20.454533: step 979, loss = 0.71800 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 19:46:21.349966 ops/training.py:65 2019-01-16 19:46:21.349900: step 980, loss = 0.69653 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:46:22.244806 ops/training.py:65 2019-01-16 19:46:22.244744: step 981, loss = 0.68629 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:46:23.140454 ops/training.py:65 2019-01-16 19:46:23.140388: step 982, loss = 0.69495 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:46:24.035760 ops/training.py:65 2019-01-16 19:46:24.035695: step 983, loss = 0.69993 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:46:24.931918 ops/training.py:65 2019-01-16 19:46:24.931856: step 984, loss = 0.68901 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:46:25.827542 ops/training.py:65 2019-01-16 19:46:25.827479: step 985, loss = 0.70014 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:46:26.722748 ops/training.py:65 2019-01-16 19:46:26.722680: step 986, loss = 0.69225 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:46:27.618577 ops/training.py:65 2019-01-16 19:46:27.618511: step 987, loss = 0.69935 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:46:28.513489 ops/training.py:65 2019-01-16 19:46:28.513427: step 988, loss = 0.69334 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:46:29.407119 ops/training.py:65 2019-01-16 19:46:29.407071: step 989, loss = 0.70782 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:46:30.304256 ops/training.py:65 2019-01-16 19:46:30.304159: step 990, loss = 0.71088 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:46:31.201410 ops/training.py:65 2019-01-16 19:46:31.201303: step 991, loss = 0.70541 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:46:32.096661 ops/training.py:65 2019-01-16 19:46:32.096563: step 992, loss = 0.68856 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:46:32.994786 ops/training.py:65 2019-01-16 19:46:32.994696: step 993, loss = 0.70411 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:46:33.893556 ops/training.py:65 2019-01-16 19:46:33.893454: step 994, loss = 0.68626 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:46:34.791218 ops/training.py:65 2019-01-16 19:46:34.791145: step 995, loss = 0.69620 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:46:35.687946 ops/training.py:65 2019-01-16 19:46:35.687860: step 996, loss = 0.69097 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:46:36.585918 ops/training.py:65 2019-01-16 19:46:36.585825: step 997, loss = 0.69221 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:46:37.483372 ops/training.py:65 2019-01-16 19:46:37.483276: step 998, loss = 0.71533 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 19:46:38.379798 ops/training.py:65 2019-01-16 19:46:38.379741: step 999, loss = 0.69646 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:46:39.275137 ops/training.py:65 2019-01-16 19:46:39.275041: step 1000, loss = 0.71029 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:46:40.173558 ops/training.py:65 2019-01-16 19:46:40.173462: step 1001, loss = 0.69478 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:46:41.072393 ops/training.py:65 2019-01-16 19:46:41.072307: step 1002, loss = 0.70008 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:46:41.968738 ops/training.py:65 2019-01-16 19:46:41.968669: step 1003, loss = 0.69181 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:46:42.865480 ops/training.py:65 2019-01-16 19:46:42.865381: step 1004, loss = 0.67874 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:46:43.763110 ops/training.py:65 2019-01-16 19:46:43.763053: step 1005, loss = 0.70438 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:46:44.657188 ops/training.py:65 2019-01-16 19:46:44.657127: step 1006, loss = 0.68285 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:46:45.551947 ops/training.py:65 2019-01-16 19:46:45.551887: step 1007, loss = 0.71563 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 19:46:46.447601 ops/training.py:65 2019-01-16 19:46:46.447502: step 1008, loss = 0.71054 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:46:47.341650 ops/training.py:65 2019-01-16 19:46:47.341548: step 1009, loss = 0.69426 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:46:48.239160 ops/training.py:65 2019-01-16 19:46:48.239063: step 1010, loss = 0.71904 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.25
I1280 2019-01-16 19:46:49.135507 ops/training.py:65 2019-01-16 19:46:49.135405: step 1011, loss = 0.71555 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:46:50.031645 ops/training.py:65 2019-01-16 19:46:50.031594: step 1012, loss = 0.69211 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:46:50.925663 ops/training.py:65 2019-01-16 19:46:50.925605: step 1013, loss = 0.70663 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:46:51.821009 ops/training.py:65 2019-01-16 19:46:51.820949: step 1014, loss = 0.67744 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:46:52.716292 ops/training.py:65 2019-01-16 19:46:52.716236: step 1015, loss = 0.70135 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:46:53.611803 ops/training.py:65 2019-01-16 19:46:53.611737: step 1016, loss = 0.68028 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:46:54.506438 ops/training.py:65 2019-01-16 19:46:54.506376: step 1017, loss = 0.71399 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:46:55.401484 ops/training.py:65 2019-01-16 19:46:55.401423: step 1018, loss = 0.70079 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:46:56.296517 ops/training.py:65 2019-01-16 19:46:56.296454: step 1019, loss = 0.69765 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:46:57.190855 ops/training.py:65 2019-01-16 19:46:57.190801: step 1020, loss = 0.68980 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:46:58.085923 ops/training.py:65 2019-01-16 19:46:58.085862: step 1021, loss = 0.67195 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:46:58.981188 ops/training.py:65 2019-01-16 19:46:58.981121: step 1022, loss = 0.69918 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:46:59.874913 ops/training.py:65 2019-01-16 19:46:59.874852: step 1023, loss = 0.69039 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:47:00.771201 ops/training.py:65 2019-01-16 19:47:00.771142: step 1024, loss = 0.69458 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:47:01.666571 ops/training.py:65 2019-01-16 19:47:01.666484: step 1025, loss = 0.69855 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:47:02.564917 ops/training.py:65 2019-01-16 19:47:02.564813: step 1026, loss = 0.70640 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:47:03.462946 ops/training.py:65 2019-01-16 19:47:03.462852: step 1027, loss = 0.69642 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:47:04.362100 ops/training.py:65 2019-01-16 19:47:04.362000: step 1028, loss = 0.69433 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:47:05.259611 ops/training.py:65 2019-01-16 19:47:05.259525: step 1029, loss = 0.70908 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:47:06.155731 ops/training.py:65 2019-01-16 19:47:06.155650: step 1030, loss = 0.68306 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:47:07.050597 ops/training.py:65 2019-01-16 19:47:07.050492: step 1031, loss = 0.69586 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:47:07.945765 ops/training.py:65 2019-01-16 19:47:07.945661: step 1032, loss = 0.68966 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:47:08.843470 ops/training.py:65 2019-01-16 19:47:08.843375: step 1033, loss = 0.70552 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:47:09.739146 ops/training.py:65 2019-01-16 19:47:09.739055: step 1034, loss = 0.70530 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:47:10.635518 ops/training.py:65 2019-01-16 19:47:10.635453: step 1035, loss = 0.70818 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:47:11.567596 ops/training.py:65 2019-01-16 19:47:11.567521: step 1036, loss = 0.69349 (34.4 examples/sec; 0.931 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:47:12.464550 ops/training.py:65 2019-01-16 19:47:12.464453: step 1037, loss = 0.69640 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:47:13.361562 ops/training.py:65 2019-01-16 19:47:13.361471: step 1038, loss = 0.68453 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:47:14.258001 ops/training.py:65 2019-01-16 19:47:14.257938: step 1039, loss = 0.69302 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:47:15.152587 ops/training.py:65 2019-01-16 19:47:15.152522: step 1040, loss = 0.69779 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:47:16.046921 ops/training.py:65 2019-01-16 19:47:16.046867: step 1041, loss = 0.71225 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:47:16.943165 ops/training.py:65 2019-01-16 19:47:16.943068: step 1042, loss = 0.69385 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:47:17.839770 ops/training.py:65 2019-01-16 19:47:17.839689: step 1043, loss = 0.69022 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:47:18.737656 ops/training.py:65 2019-01-16 19:47:18.737556: step 1044, loss = 0.70015 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:47:19.635650 ops/training.py:65 2019-01-16 19:47:19.635557: step 1045, loss = 0.70258 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:47:20.531916 ops/training.py:65 2019-01-16 19:47:20.531856: step 1046, loss = 0.69091 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:47:21.427150 ops/training.py:65 2019-01-16 19:47:21.427087: step 1047, loss = 0.70446 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:47:22.321680 ops/training.py:65 2019-01-16 19:47:22.321619: step 1048, loss = 0.69442 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:47:23.217329 ops/training.py:65 2019-01-16 19:47:23.217260: step 1049, loss = 0.68207 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:47:24.113069 ops/training.py:65 2019-01-16 19:47:24.113001: step 1050, loss = 0.68940 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:47:25.007861 ops/training.py:65 2019-01-16 19:47:25.007798: step 1051, loss = 0.69376 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:47:25.901912 ops/training.py:65 2019-01-16 19:47:25.901850: step 1052, loss = 0.69889 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:47:26.797205 ops/training.py:65 2019-01-16 19:47:26.797146: step 1053, loss = 0.70744 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:47:27.691623 ops/training.py:65 2019-01-16 19:47:27.691567: step 1054, loss = 0.68592 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:47:28.585997 ops/training.py:65 2019-01-16 19:47:28.585934: step 1055, loss = 0.69861 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:47:29.479902 ops/training.py:65 2019-01-16 19:47:29.479848: step 1056, loss = 0.68981 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:47:30.376534 ops/training.py:65 2019-01-16 19:47:30.376470: step 1057, loss = 0.70121 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:47:31.274387 ops/training.py:65 2019-01-16 19:47:31.274287: step 1058, loss = 0.69027 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:47:32.173417 ops/training.py:65 2019-01-16 19:47:32.173322: step 1059, loss = 0.69057 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:47:33.071071 ops/training.py:65 2019-01-16 19:47:33.070989: step 1060, loss = 0.71071 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:47:33.968819 ops/training.py:65 2019-01-16 19:47:33.968760: step 1061, loss = 0.70861 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:47:34.863157 ops/training.py:65 2019-01-16 19:47:34.863108: step 1062, loss = 0.71023 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:47:35.756765 ops/training.py:65 2019-01-16 19:47:35.756692: step 1063, loss = 0.68704 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:47:36.651856 ops/training.py:65 2019-01-16 19:47:36.651766: step 1064, loss = 0.69739 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:47:37.547060 ops/training.py:65 2019-01-16 19:47:37.546965: step 1065, loss = 0.70505 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 19:47:38.441702 ops/training.py:65 2019-01-16 19:47:38.441634: step 1066, loss = 0.69590 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:47:39.336723 ops/training.py:65 2019-01-16 19:47:39.336661: step 1067, loss = 0.69024 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:47:40.231057 ops/training.py:65 2019-01-16 19:47:40.230995: step 1068, loss = 0.68243 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 19:47:41.125317 ops/training.py:65 2019-01-16 19:47:41.125256: step 1069, loss = 0.68924 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:47:42.019580 ops/training.py:65 2019-01-16 19:47:42.019524: step 1070, loss = 0.69380 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:47:42.914281 ops/training.py:65 2019-01-16 19:47:42.914213: step 1071, loss = 0.69462 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:47:43.810282 ops/training.py:65 2019-01-16 19:47:43.810216: step 1072, loss = 0.68700 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:47:44.704111 ops/training.py:65 2019-01-16 19:47:44.704054: step 1073, loss = 0.69141 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:47:45.598744 ops/training.py:65 2019-01-16 19:47:45.598685: step 1074, loss = 0.69488 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:47:46.492501 ops/training.py:65 2019-01-16 19:47:46.492449: step 1075, loss = 0.70645 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:47:47.386410 ops/training.py:65 2019-01-16 19:47:47.386357: step 1076, loss = 0.69271 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:47:48.281638 ops/training.py:65 2019-01-16 19:47:48.281551: step 1077, loss = 0.68818 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:47:49.176518 ops/training.py:65 2019-01-16 19:47:49.176420: step 1078, loss = 0.69546 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:47:50.069209 ops/training.py:65 2019-01-16 19:47:50.069133: step 1079, loss = 0.68651 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.78125
I1280 2019-01-16 19:47:50.965996 ops/training.py:65 2019-01-16 19:47:50.965887: step 1080, loss = 0.69808 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:47:51.864250 ops/training.py:65 2019-01-16 19:47:51.864153: step 1081, loss = 0.68529 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:47:52.760669 ops/training.py:65 2019-01-16 19:47:52.760609: step 1082, loss = 0.69343 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:47:53.655106 ops/training.py:65 2019-01-16 19:47:53.655041: step 1083, loss = 0.69723 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:47:54.549727 ops/training.py:65 2019-01-16 19:47:54.549666: step 1084, loss = 0.69217 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:47:55.444692 ops/training.py:65 2019-01-16 19:47:55.444630: step 1085, loss = 0.70183 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 19:47:56.339412 ops/training.py:65 2019-01-16 19:47:56.339353: step 1086, loss = 0.68855 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:47:57.234277 ops/training.py:65 2019-01-16 19:47:57.234213: step 1087, loss = 0.69572 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:47:58.129059 ops/training.py:65 2019-01-16 19:47:58.128995: step 1088, loss = 0.69257 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:47:59.024155 ops/training.py:65 2019-01-16 19:47:59.024095: step 1089, loss = 0.69301 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:47:59.918907 ops/training.py:65 2019-01-16 19:47:59.918837: step 1090, loss = 0.69546 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:48:00.813556 ops/training.py:65 2019-01-16 19:48:00.813496: step 1091, loss = 0.69727 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:48:01.708839 ops/training.py:65 2019-01-16 19:48:01.708786: step 1092, loss = 0.68472 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:48:02.603708 ops/training.py:65 2019-01-16 19:48:02.603644: step 1093, loss = 0.68220 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:48:03.498845 ops/training.py:65 2019-01-16 19:48:03.498785: step 1094, loss = 0.69707 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:48:04.393931 ops/training.py:65 2019-01-16 19:48:04.393869: step 1095, loss = 0.70407 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:48:05.288515 ops/training.py:65 2019-01-16 19:48:05.288451: step 1096, loss = 0.70239 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:48:06.186608 ops/training.py:65 2019-01-16 19:48:06.186519: step 1097, loss = 0.68563 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:48:07.082290 ops/training.py:65 2019-01-16 19:48:07.082203: step 1098, loss = 0.69228 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:48:07.976493 ops/training.py:65 2019-01-16 19:48:07.976429: step 1099, loss = 0.69672 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:48:08.873961 ops/training.py:65 2019-01-16 19:48:08.873895: step 1100, loss = 0.68943 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:48:09.768881 ops/training.py:65 2019-01-16 19:48:09.768822: step 1101, loss = 0.68228 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:48:10.663561 ops/training.py:65 2019-01-16 19:48:10.663492: step 1102, loss = 0.70658 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 19:48:11.557970 ops/training.py:65 2019-01-16 19:48:11.557902: step 1103, loss = 0.69364 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:48:12.452950 ops/training.py:65 2019-01-16 19:48:12.452892: step 1104, loss = 0.70312 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:48:13.351681 ops/training.py:65 2019-01-16 19:48:13.351581: step 1105, loss = 0.68814 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:48:14.248221 ops/training.py:65 2019-01-16 19:48:14.248121: step 1106, loss = 0.68420 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:48:15.143353 ops/training.py:65 2019-01-16 19:48:15.143297: step 1107, loss = 0.69940 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:48:16.041280 ops/training.py:65 2019-01-16 19:48:16.041181: step 1108, loss = 0.69603 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:48:16.937964 ops/training.py:65 2019-01-16 19:48:16.937872: step 1109, loss = 0.68989 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:48:17.834532 ops/training.py:65 2019-01-16 19:48:17.834467: step 1110, loss = 0.69363 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:48:18.729094 ops/training.py:65 2019-01-16 19:48:18.729033: step 1111, loss = 0.68134 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:48:19.623769 ops/training.py:65 2019-01-16 19:48:19.623706: step 1112, loss = 0.70581 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:48:20.518620 ops/training.py:65 2019-01-16 19:48:20.518564: step 1113, loss = 0.68822 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:48:21.412139 ops/training.py:65 2019-01-16 19:48:21.412081: step 1114, loss = 0.68990 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:48:22.306506 ops/training.py:65 2019-01-16 19:48:22.306450: step 1115, loss = 0.71077 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:48:23.199951 ops/training.py:65 2019-01-16 19:48:23.199888: step 1116, loss = 0.69529 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:48:24.094814 ops/training.py:65 2019-01-16 19:48:24.094756: step 1117, loss = 0.69450 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:48:24.988970 ops/training.py:65 2019-01-16 19:48:24.988916: step 1118, loss = 0.68271 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:48:25.884624 ops/training.py:65 2019-01-16 19:48:25.884522: step 1119, loss = 0.69637 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:48:26.779898 ops/training.py:65 2019-01-16 19:48:26.779799: step 1120, loss = 0.69041 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:48:27.677779 ops/training.py:65 2019-01-16 19:48:27.677678: step 1121, loss = 0.69153 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:48:28.575725 ops/training.py:65 2019-01-16 19:48:28.575620: step 1122, loss = 0.68155 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:48:29.472056 ops/training.py:65 2019-01-16 19:48:29.471960: step 1123, loss = 0.68323 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:48:30.369384 ops/training.py:65 2019-01-16 19:48:30.369290: step 1124, loss = 0.68262 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:48:31.266772 ops/training.py:65 2019-01-16 19:48:31.266669: step 1125, loss = 0.70434 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:48:32.161635 ops/training.py:65 2019-01-16 19:48:32.161587: step 1126, loss = 0.69457 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:48:33.057900 ops/training.py:65 2019-01-16 19:48:33.057819: step 1127, loss = 0.68290 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:48:33.956165 ops/training.py:65 2019-01-16 19:48:33.956069: step 1128, loss = 0.70382 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:48:34.852323 ops/training.py:65 2019-01-16 19:48:34.852220: step 1129, loss = 0.69361 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:48:35.749433 ops/training.py:65 2019-01-16 19:48:35.749354: step 1130, loss = 0.68542 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:48:36.645042 ops/training.py:65 2019-01-16 19:48:36.644948: step 1131, loss = 0.68547 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:48:37.542756 ops/training.py:65 2019-01-16 19:48:37.542660: step 1132, loss = 0.68162 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:48:38.438913 ops/training.py:65 2019-01-16 19:48:38.438817: step 1133, loss = 0.69731 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:48:39.334768 ops/training.py:65 2019-01-16 19:48:39.334709: step 1134, loss = 0.69242 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:48:40.231576 ops/training.py:65 2019-01-16 19:48:40.231481: step 1135, loss = 0.70132 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:48:41.129297 ops/training.py:65 2019-01-16 19:48:41.129199: step 1136, loss = 0.69110 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:48:42.025261 ops/training.py:65 2019-01-16 19:48:42.025167: step 1137, loss = 0.69924 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:48:42.921920 ops/training.py:65 2019-01-16 19:48:42.921819: step 1138, loss = 0.68925 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:48:43.818212 ops/training.py:65 2019-01-16 19:48:43.818111: step 1139, loss = 0.68464 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:48:44.713709 ops/training.py:65 2019-01-16 19:48:44.713615: step 1140, loss = 0.68134 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:48:45.611143 ops/training.py:65 2019-01-16 19:48:45.611043: step 1141, loss = 0.68902 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:48:46.504310 ops/training.py:65 2019-01-16 19:48:46.504247: step 1142, loss = 0.68661 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:48:47.398230 ops/training.py:65 2019-01-16 19:48:47.398174: step 1143, loss = 0.70408 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:48:48.292369 ops/training.py:65 2019-01-16 19:48:48.292314: step 1144, loss = 0.70495 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:48:49.185203 ops/training.py:65 2019-01-16 19:48:49.185143: step 1145, loss = 0.69959 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:48:50.078025 ops/training.py:65 2019-01-16 19:48:50.077977: step 1146, loss = 0.70576 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:48:50.971794 ops/training.py:65 2019-01-16 19:48:50.971735: step 1147, loss = 0.69001 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:48:51.866626 ops/training.py:65 2019-01-16 19:48:51.866568: step 1148, loss = 0.69569 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:48:52.761443 ops/training.py:65 2019-01-16 19:48:52.761389: step 1149, loss = 0.69744 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:48:53.657183 ops/training.py:65 2019-01-16 19:48:53.657123: step 1150, loss = 0.69646 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:48:54.551820 ops/training.py:65 2019-01-16 19:48:54.551760: step 1151, loss = 0.69761 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:48:55.446320 ops/training.py:65 2019-01-16 19:48:55.446268: step 1152, loss = 0.68708 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:48:56.341072 ops/training.py:65 2019-01-16 19:48:56.341021: step 1153, loss = 0.68873 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:48:57.235924 ops/training.py:65 2019-01-16 19:48:57.235867: step 1154, loss = 0.68851 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:48:58.134641 ops/training.py:65 2019-01-16 19:48:58.134536: step 1155, loss = 0.68659 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:48:59.031508 ops/training.py:65 2019-01-16 19:48:59.031402: step 1156, loss = 0.70247 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:48:59.927304 ops/training.py:65 2019-01-16 19:48:59.927251: step 1157, loss = 0.68928 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:49:00.825710 ops/training.py:65 2019-01-16 19:49:00.825603: step 1158, loss = 0.70172 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:49:01.721601 ops/training.py:65 2019-01-16 19:49:01.721518: step 1159, loss = 0.70720 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:49:02.616563 ops/training.py:65 2019-01-16 19:49:02.616499: step 1160, loss = 0.69019 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:49:03.512227 ops/training.py:65 2019-01-16 19:49:03.512170: step 1161, loss = 0.69642 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:49:04.406163 ops/training.py:65 2019-01-16 19:49:04.406107: step 1162, loss = 0.71357 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 19:49:05.300597 ops/training.py:65 2019-01-16 19:49:05.300521: step 1163, loss = 0.68407 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:49:06.196242 ops/training.py:65 2019-01-16 19:49:06.196150: step 1164, loss = 0.68465 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:49:07.093102 ops/training.py:65 2019-01-16 19:49:07.093001: step 1165, loss = 0.69204 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:49:07.988605 ops/training.py:65 2019-01-16 19:49:07.988541: step 1166, loss = 0.68556 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:49:08.882783 ops/training.py:65 2019-01-16 19:49:08.882715: step 1167, loss = 0.69713 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:49:09.777325 ops/training.py:65 2019-01-16 19:49:09.777264: step 1168, loss = 0.68798 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:49:10.671712 ops/training.py:65 2019-01-16 19:49:10.671647: step 1169, loss = 0.69943 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:49:11.564993 ops/training.py:65 2019-01-16 19:49:11.564933: step 1170, loss = 0.67467 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:49:12.459641 ops/training.py:65 2019-01-16 19:49:12.459589: step 1171, loss = 0.70678 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:49:13.357229 ops/training.py:65 2019-01-16 19:49:13.357126: step 1172, loss = 0.69979 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:49:14.253847 ops/training.py:65 2019-01-16 19:49:14.253743: step 1173, loss = 0.70416 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:49:15.150541 ops/training.py:65 2019-01-16 19:49:15.150478: step 1174, loss = 0.70176 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:49:16.044997 ops/training.py:65 2019-01-16 19:49:16.044940: step 1175, loss = 0.69203 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:49:16.940858 ops/training.py:65 2019-01-16 19:49:16.940791: step 1176, loss = 0.68463 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:49:17.836172 ops/training.py:65 2019-01-16 19:49:17.836108: step 1177, loss = 0.70480 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:49:18.731456 ops/training.py:65 2019-01-16 19:49:18.731400: step 1178, loss = 0.68549 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:49:19.626078 ops/training.py:65 2019-01-16 19:49:19.626013: step 1179, loss = 0.70501 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:49:20.520762 ops/training.py:65 2019-01-16 19:49:20.520708: step 1180, loss = 0.70180 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:49:21.416183 ops/training.py:65 2019-01-16 19:49:21.416117: step 1181, loss = 0.67738 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:49:22.310806 ops/training.py:65 2019-01-16 19:49:22.310741: step 1182, loss = 0.69085 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:49:23.204411 ops/training.py:65 2019-01-16 19:49:23.204349: step 1183, loss = 0.69062 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:49:24.098794 ops/training.py:65 2019-01-16 19:49:24.098731: step 1184, loss = 0.68850 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:49:24.993654 ops/training.py:65 2019-01-16 19:49:24.993591: step 1185, loss = 0.67950 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:49:25.888258 ops/training.py:65 2019-01-16 19:49:25.888195: step 1186, loss = 0.68823 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:49:26.783206 ops/training.py:65 2019-01-16 19:49:26.783153: step 1187, loss = 0.69679 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:49:27.678979 ops/training.py:65 2019-01-16 19:49:27.678876: step 1188, loss = 0.70126 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:49:28.575849 ops/training.py:65 2019-01-16 19:49:28.575748: step 1189, loss = 0.69751 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:49:29.472873 ops/training.py:65 2019-01-16 19:49:29.472776: step 1190, loss = 0.69572 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:49:30.369535 ops/training.py:65 2019-01-16 19:49:30.369435: step 1191, loss = 0.68939 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:49:31.265604 ops/training.py:65 2019-01-16 19:49:31.265509: step 1192, loss = 0.70197 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:49:32.160514 ops/training.py:65 2019-01-16 19:49:32.160415: step 1193, loss = 0.68309 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:49:33.058570 ops/training.py:65 2019-01-16 19:49:33.058487: step 1194, loss = 0.70062 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:49:33.956568 ops/training.py:65 2019-01-16 19:49:33.956490: step 1195, loss = 0.68787 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:49:34.852518 ops/training.py:65 2019-01-16 19:49:34.852459: step 1196, loss = 0.68446 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:49:35.747214 ops/training.py:65 2019-01-16 19:49:35.747142: step 1197, loss = 0.68373 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:49:36.642314 ops/training.py:65 2019-01-16 19:49:36.642231: step 1198, loss = 0.69046 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:49:37.537109 ops/training.py:65 2019-01-16 19:49:37.537015: step 1199, loss = 0.69025 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:49:38.431707 ops/training.py:65 2019-01-16 19:49:38.431647: step 1200, loss = 0.69195 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:49:39.326420 ops/training.py:65 2019-01-16 19:49:39.326361: step 1201, loss = 0.70058 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:49:40.221515 ops/training.py:65 2019-01-16 19:49:40.221417: step 1202, loss = 0.69491 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:49:41.121293 ops/training.py:65 2019-01-16 19:49:41.121190: step 1203, loss = 0.70101 (35.6 examples/sec; 0.899 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:49:42.018808 ops/training.py:65 2019-01-16 19:49:42.018711: step 1204, loss = 0.68347 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:49:42.915092 ops/training.py:65 2019-01-16 19:49:42.915032: step 1205, loss = 0.69697 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:49:43.811285 ops/training.py:65 2019-01-16 19:49:43.811188: step 1206, loss = 0.69054 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:49:44.706286 ops/training.py:65 2019-01-16 19:49:44.706228: step 1207, loss = 0.70225 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:49:45.601439 ops/training.py:65 2019-01-16 19:49:45.601388: step 1208, loss = 0.70039 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:49:46.495708 ops/training.py:65 2019-01-16 19:49:46.495655: step 1209, loss = 0.68793 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:49:47.389367 ops/training.py:65 2019-01-16 19:49:47.389316: step 1210, loss = 0.68981 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:49:48.283309 ops/training.py:65 2019-01-16 19:49:48.283246: step 1211, loss = 0.69164 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:49:49.178679 ops/training.py:65 2019-01-16 19:49:49.178622: step 1212, loss = 0.70286 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:49:50.071499 ops/training.py:65 2019-01-16 19:49:50.071453: step 1213, loss = 0.69844 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:49:50.965959 ops/training.py:65 2019-01-16 19:49:50.965909: step 1214, loss = 0.67460 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.78125
I1280 2019-01-16 19:49:51.859229 ops/training.py:65 2019-01-16 19:49:51.859181: step 1215, loss = 0.69724 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:49:52.753523 ops/training.py:65 2019-01-16 19:49:52.753462: step 1216, loss = 0.69771 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:49:53.647926 ops/training.py:65 2019-01-16 19:49:53.647874: step 1217, loss = 0.69120 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:49:54.540228 ops/training.py:65 2019-01-16 19:49:54.540173: step 1218, loss = 0.67919 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:49:55.434936 ops/training.py:65 2019-01-16 19:49:55.434886: step 1219, loss = 0.68761 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:49:56.328398 ops/training.py:65 2019-01-16 19:49:56.328349: step 1220, loss = 0.69811 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:49:57.224647 ops/training.py:65 2019-01-16 19:49:57.224594: step 1221, loss = 0.70384 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:49:58.122504 ops/training.py:65 2019-01-16 19:49:58.122406: step 1222, loss = 0.71599 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 19:49:59.020444 ops/training.py:65 2019-01-16 19:49:59.020346: step 1223, loss = 0.68336 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:49:59.917121 ops/training.py:65 2019-01-16 19:49:59.917062: step 1224, loss = 0.69818 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:50:00.814288 ops/training.py:65 2019-01-16 19:50:00.814194: step 1225, loss = 0.70350 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:50:01.710526 ops/training.py:65 2019-01-16 19:50:01.710446: step 1226, loss = 0.68653 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:50:02.609272 ops/training.py:65 2019-01-16 19:50:02.609172: step 1227, loss = 0.67709 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:50:03.505832 ops/training.py:65 2019-01-16 19:50:03.505760: step 1228, loss = 0.68607 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:50:04.403837 ops/training.py:65 2019-01-16 19:50:04.403770: step 1229, loss = 0.69673 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:50:05.301345 ops/training.py:65 2019-01-16 19:50:05.301263: step 1230, loss = 0.69549 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:50:06.196722 ops/training.py:65 2019-01-16 19:50:06.196641: step 1231, loss = 0.71560 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.25
I1280 2019-01-16 19:50:07.092763 ops/training.py:65 2019-01-16 19:50:07.092664: step 1232, loss = 0.68226 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:50:07.990142 ops/training.py:65 2019-01-16 19:50:07.990045: step 1233, loss = 0.68799 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:50:08.889125 ops/training.py:65 2019-01-16 19:50:08.889019: step 1234, loss = 0.70504 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 19:50:09.783516 ops/training.py:65 2019-01-16 19:50:09.783449: step 1235, loss = 0.69708 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:50:10.678078 ops/training.py:65 2019-01-16 19:50:10.678019: step 1236, loss = 0.68795 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:50:11.573444 ops/training.py:65 2019-01-16 19:50:11.573352: step 1237, loss = 0.69851 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:50:12.469311 ops/training.py:65 2019-01-16 19:50:12.469249: step 1238, loss = 0.69888 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:50:13.363872 ops/training.py:65 2019-01-16 19:50:13.363812: step 1239, loss = 0.68070 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:50:14.258742 ops/training.py:65 2019-01-16 19:50:14.258690: step 1240, loss = 0.70138 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:50:15.157197 ops/training.py:65 2019-01-16 19:50:15.157096: step 1241, loss = 0.68213 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:50:16.054881 ops/training.py:65 2019-01-16 19:50:16.054798: step 1242, loss = 0.70333 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:50:16.953232 ops/training.py:65 2019-01-16 19:50:16.953170: step 1243, loss = 0.69256 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:50:17.850398 ops/training.py:65 2019-01-16 19:50:17.850294: step 1244, loss = 0.71008 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:50:18.747952 ops/training.py:65 2019-01-16 19:50:18.747895: step 1245, loss = 0.70262 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:50:19.644294 ops/training.py:65 2019-01-16 19:50:19.644229: step 1246, loss = 0.68977 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:50:20.542261 ops/training.py:65 2019-01-16 19:50:20.542165: step 1247, loss = 0.68693 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:50:21.441103 ops/training.py:65 2019-01-16 19:50:21.441003: step 1248, loss = 0.69691 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:50:22.338079 ops/training.py:65 2019-01-16 19:50:22.338016: step 1249, loss = 0.68656 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:50:23.234724 ops/training.py:65 2019-01-16 19:50:23.234660: step 1250, loss = 0.69282 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:50:24.128798 ops/training.py:65 2019-01-16 19:50:24.128735: step 1251, loss = 0.69453 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:50:25.024127 ops/training.py:65 2019-01-16 19:50:25.024057: step 1252, loss = 0.69774 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:50:25.918888 ops/training.py:65 2019-01-16 19:50:25.918830: step 1253, loss = 0.68173 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 19:50:26.813105 ops/training.py:65 2019-01-16 19:50:26.813050: step 1254, loss = 0.69883 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:50:27.708499 ops/training.py:65 2019-01-16 19:50:27.708448: step 1255, loss = 0.69185 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:50:28.604225 ops/training.py:65 2019-01-16 19:50:28.604122: step 1256, loss = 0.69243 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:50:29.503763 ops/training.py:65 2019-01-16 19:50:29.503661: step 1257, loss = 0.69220 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:50:30.400977 ops/training.py:65 2019-01-16 19:50:30.400873: step 1258, loss = 0.69707 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:50:31.299036 ops/training.py:65 2019-01-16 19:50:31.298976: step 1259, loss = 0.69369 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:50:32.194011 ops/training.py:65 2019-01-16 19:50:32.193959: step 1260, loss = 0.69970 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:50:33.089124 ops/training.py:65 2019-01-16 19:50:33.089069: step 1261, loss = 0.69086 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:50:33.983086 ops/training.py:65 2019-01-16 19:50:33.983024: step 1262, loss = 0.70233 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 19:50:34.878509 ops/training.py:65 2019-01-16 19:50:34.878452: step 1263, loss = 0.69983 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:50:35.771884 ops/training.py:65 2019-01-16 19:50:35.771818: step 1264, loss = 0.71775 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 19:50:36.667478 ops/training.py:65 2019-01-16 19:50:36.667379: step 1265, loss = 0.69089 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:50:37.563623 ops/training.py:65 2019-01-16 19:50:37.563523: step 1266, loss = 0.69611 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:50:38.458358 ops/training.py:65 2019-01-16 19:50:38.458288: step 1267, loss = 0.70119 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:50:39.353785 ops/training.py:65 2019-01-16 19:50:39.353724: step 1268, loss = 0.69726 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:50:40.248859 ops/training.py:65 2019-01-16 19:50:40.248798: step 1269, loss = 0.68898 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:50:41.144797 ops/training.py:65 2019-01-16 19:50:41.144736: step 1270, loss = 0.69811 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:50:42.040799 ops/training.py:65 2019-01-16 19:50:42.040710: step 1271, loss = 0.67638 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:50:42.937833 ops/training.py:65 2019-01-16 19:50:42.937723: step 1272, loss = 0.69812 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:50:43.835572 ops/training.py:65 2019-01-16 19:50:43.835467: step 1273, loss = 0.69473 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:50:44.731969 ops/training.py:65 2019-01-16 19:50:44.731865: step 1274, loss = 0.69046 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:50:45.627351 ops/training.py:65 2019-01-16 19:50:45.627249: step 1275, loss = 0.68965 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:50:46.524643 ops/training.py:65 2019-01-16 19:50:46.524540: step 1276, loss = 0.69768 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:50:47.421370 ops/training.py:65 2019-01-16 19:50:47.421292: step 1277, loss = 0.69341 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:50:48.317609 ops/training.py:65 2019-01-16 19:50:48.317510: step 1278, loss = 0.69129 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:50:49.212896 ops/training.py:65 2019-01-16 19:50:49.212821: step 1279, loss = 0.68562 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:50:50.110923 ops/training.py:65 2019-01-16 19:50:50.110821: step 1280, loss = 0.69782 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:50:51.007905 ops/training.py:65 2019-01-16 19:50:51.007815: step 1281, loss = 0.69107 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:50:51.904997 ops/training.py:65 2019-01-16 19:50:51.904931: step 1282, loss = 0.71088 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.25
I1280 2019-01-16 19:50:52.800675 ops/training.py:65 2019-01-16 19:50:52.800614: step 1283, loss = 0.68811 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:50:53.697021 ops/training.py:65 2019-01-16 19:50:53.696915: step 1284, loss = 0.67978 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:50:54.593232 ops/training.py:65 2019-01-16 19:50:54.593130: step 1285, loss = 0.69804 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:50:55.488951 ops/training.py:65 2019-01-16 19:50:55.488847: step 1286, loss = 0.69250 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:50:56.385294 ops/training.py:65 2019-01-16 19:50:56.385190: step 1287, loss = 0.68995 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:50:57.282766 ops/training.py:65 2019-01-16 19:50:57.282666: step 1288, loss = 0.69000 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:50:58.179436 ops/training.py:65 2019-01-16 19:50:58.179333: step 1289, loss = 0.69719 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 19:50:59.077111 ops/training.py:65 2019-01-16 19:50:59.077040: step 1290, loss = 0.68434 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:50:59.971876 ops/training.py:65 2019-01-16 19:50:59.971813: step 1291, loss = 0.68829 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:51:00.864918 ops/training.py:65 2019-01-16 19:51:00.864852: step 1292, loss = 0.67801 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:51:01.760966 ops/training.py:65 2019-01-16 19:51:01.760906: step 1293, loss = 0.70055 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:51:02.655158 ops/training.py:65 2019-01-16 19:51:02.655101: step 1294, loss = 0.69544 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:51:03.549424 ops/training.py:65 2019-01-16 19:51:03.549355: step 1295, loss = 0.70138 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:51:04.443643 ops/training.py:65 2019-01-16 19:51:04.443592: step 1296, loss = 0.69311 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:51:05.339417 ops/training.py:65 2019-01-16 19:51:05.339340: step 1297, loss = 0.70170 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:51:06.235533 ops/training.py:65 2019-01-16 19:51:06.235447: step 1298, loss = 0.71430 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:51:07.131959 ops/training.py:65 2019-01-16 19:51:07.131867: step 1299, loss = 0.69694 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:51:08.028041 ops/training.py:65 2019-01-16 19:51:08.027972: step 1300, loss = 0.69698 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:51:08.922049 ops/training.py:65 2019-01-16 19:51:08.921987: step 1301, loss = 0.69690 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:51:09.816760 ops/training.py:65 2019-01-16 19:51:09.816705: step 1302, loss = 0.68973 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:51:10.711474 ops/training.py:65 2019-01-16 19:51:10.711411: step 1303, loss = 0.69869 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:51:11.605919 ops/training.py:65 2019-01-16 19:51:11.605865: step 1304, loss = 0.69640 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:51:12.500276 ops/training.py:65 2019-01-16 19:51:12.500226: step 1305, loss = 0.70072 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:51:13.397900 ops/training.py:65 2019-01-16 19:51:13.397801: step 1306, loss = 0.68550 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:51:14.295506 ops/training.py:65 2019-01-16 19:51:14.295404: step 1307, loss = 0.68783 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:51:15.193035 ops/training.py:65 2019-01-16 19:51:15.192930: step 1308, loss = 0.68827 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:51:16.091358 ops/training.py:65 2019-01-16 19:51:16.091255: step 1309, loss = 0.69177 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:51:16.988554 ops/training.py:65 2019-01-16 19:51:16.988454: step 1310, loss = 0.68568 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:51:17.886135 ops/training.py:65 2019-01-16 19:51:17.886077: step 1311, loss = 0.70368 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:51:18.781423 ops/training.py:65 2019-01-16 19:51:18.781360: step 1312, loss = 0.68779 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:51:19.675462 ops/training.py:65 2019-01-16 19:51:19.675408: step 1313, loss = 0.70480 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 19:51:20.568869 ops/training.py:65 2019-01-16 19:51:20.568812: step 1314, loss = 0.69524 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:51:21.463405 ops/training.py:65 2019-01-16 19:51:21.463344: step 1315, loss = 0.68299 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:51:22.358609 ops/training.py:65 2019-01-16 19:51:22.358548: step 1316, loss = 0.69701 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:51:23.253703 ops/training.py:65 2019-01-16 19:51:23.253638: step 1317, loss = 0.69567 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:51:24.151167 ops/training.py:65 2019-01-16 19:51:24.151067: step 1318, loss = 0.68971 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:51:25.046439 ops/training.py:65 2019-01-16 19:51:25.046379: step 1319, loss = 0.68956 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:51:25.940295 ops/training.py:65 2019-01-16 19:51:25.940235: step 1320, loss = 0.69230 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:51:26.835827 ops/training.py:65 2019-01-16 19:51:26.835769: step 1321, loss = 0.69073 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:51:27.729614 ops/training.py:65 2019-01-16 19:51:27.729553: step 1322, loss = 0.69248 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:51:28.624811 ops/training.py:65 2019-01-16 19:51:28.624758: step 1323, loss = 0.68065 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:51:29.520188 ops/training.py:65 2019-01-16 19:51:29.520123: step 1324, loss = 0.69244 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:51:30.414579 ops/training.py:65 2019-01-16 19:51:30.414516: step 1325, loss = 0.70001 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:51:31.309346 ops/training.py:65 2019-01-16 19:51:31.309286: step 1326, loss = 0.69898 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 19:51:32.203779 ops/training.py:65 2019-01-16 19:51:32.203728: step 1327, loss = 0.70444 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:51:33.098836 ops/training.py:65 2019-01-16 19:51:33.098769: step 1328, loss = 0.68571 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:51:33.993313 ops/training.py:65 2019-01-16 19:51:33.993241: step 1329, loss = 0.69248 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:51:34.888566 ops/training.py:65 2019-01-16 19:51:34.888497: step 1330, loss = 0.68666 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:51:35.783769 ops/training.py:65 2019-01-16 19:51:35.783694: step 1331, loss = 0.69604 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:51:36.680184 ops/training.py:65 2019-01-16 19:51:36.680099: step 1332, loss = 0.69831 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:51:37.578494 ops/training.py:65 2019-01-16 19:51:37.578392: step 1333, loss = 0.68772 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:51:38.474899 ops/training.py:65 2019-01-16 19:51:38.474805: step 1334, loss = 0.69594 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:51:39.369946 ops/training.py:65 2019-01-16 19:51:39.369873: step 1335, loss = 0.69586 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:51:40.265436 ops/training.py:65 2019-01-16 19:51:40.265376: step 1336, loss = 0.67755 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:51:41.160451 ops/training.py:65 2019-01-16 19:51:41.160388: step 1337, loss = 0.68882 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:51:42.055046 ops/training.py:65 2019-01-16 19:51:42.054982: step 1338, loss = 0.69459 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:51:42.949859 ops/training.py:65 2019-01-16 19:51:42.949782: step 1339, loss = 0.68736 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:51:43.844836 ops/training.py:65 2019-01-16 19:51:43.844764: step 1340, loss = 0.70083 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:51:44.739966 ops/training.py:65 2019-01-16 19:51:44.739903: step 1341, loss = 0.69264 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:51:45.635462 ops/training.py:65 2019-01-16 19:51:45.635396: step 1342, loss = 0.70920 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 19:51:46.530705 ops/training.py:65 2019-01-16 19:51:46.530635: step 1343, loss = 0.69374 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:51:47.426238 ops/training.py:65 2019-01-16 19:51:47.426181: step 1344, loss = 0.69926 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:51:48.320631 ops/training.py:65 2019-01-16 19:51:48.320576: step 1345, loss = 0.69102 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:51:49.217270 ops/training.py:65 2019-01-16 19:51:49.217191: step 1346, loss = 0.69425 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:51:50.112907 ops/training.py:65 2019-01-16 19:51:50.112808: step 1347, loss = 0.67110 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:51:51.007671 ops/training.py:65 2019-01-16 19:51:51.007575: step 1348, loss = 0.69840 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:51:51.902565 ops/training.py:65 2019-01-16 19:51:51.902474: step 1349, loss = 0.68571 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:51:52.800745 ops/training.py:65 2019-01-16 19:51:52.800644: step 1350, loss = 0.69694 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:51:53.698941 ops/training.py:65 2019-01-16 19:51:53.698844: step 1351, loss = 0.69377 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:51:54.595358 ops/training.py:65 2019-01-16 19:51:54.595296: step 1352, loss = 0.69206 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:51:55.490647 ops/training.py:65 2019-01-16 19:51:55.490584: step 1353, loss = 0.69831 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:51:56.385866 ops/training.py:65 2019-01-16 19:51:56.385805: step 1354, loss = 0.70444 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:51:57.280418 ops/training.py:65 2019-01-16 19:51:57.280368: step 1355, loss = 0.70196 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:51:58.176096 ops/training.py:65 2019-01-16 19:51:58.175994: step 1356, loss = 0.68501 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:51:59.072885 ops/training.py:65 2019-01-16 19:51:59.072783: step 1357, loss = 0.69400 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:51:59.969801 ops/training.py:65 2019-01-16 19:51:59.969704: step 1358, loss = 0.70110 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:52:00.865228 ops/training.py:65 2019-01-16 19:52:00.865127: step 1359, loss = 0.70349 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:52:01.761099 ops/training.py:65 2019-01-16 19:52:01.761012: step 1360, loss = 0.69702 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:52:02.660412 ops/training.py:65 2019-01-16 19:52:02.660322: step 1361, loss = 0.69178 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:52:03.557554 ops/training.py:65 2019-01-16 19:52:03.557464: step 1362, loss = 0.69973 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:52:04.453117 ops/training.py:65 2019-01-16 19:52:04.453064: step 1363, loss = 0.69568 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:52:05.347723 ops/training.py:65 2019-01-16 19:52:05.347659: step 1364, loss = 0.68365 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:52:06.243391 ops/training.py:65 2019-01-16 19:52:06.243309: step 1365, loss = 0.66408 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 19:52:07.141615 ops/training.py:65 2019-01-16 19:52:07.141522: step 1366, loss = 0.71249 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:52:08.038002 ops/training.py:65 2019-01-16 19:52:08.037906: step 1367, loss = 0.68380 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:52:08.934352 ops/training.py:65 2019-01-16 19:52:08.934281: step 1368, loss = 0.67909 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:52:09.829495 ops/training.py:65 2019-01-16 19:52:09.829397: step 1369, loss = 0.67938 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:52:10.725767 ops/training.py:65 2019-01-16 19:52:10.725678: step 1370, loss = 0.71662 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:52:11.623065 ops/training.py:65 2019-01-16 19:52:11.622966: step 1371, loss = 0.68863 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:52:12.517751 ops/training.py:65 2019-01-16 19:52:12.517656: step 1372, loss = 0.70887 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:52:13.412190 ops/training.py:65 2019-01-16 19:52:13.412132: step 1373, loss = 0.68659 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:52:14.306220 ops/training.py:65 2019-01-16 19:52:14.306163: step 1374, loss = 0.71230 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:52:15.200523 ops/training.py:65 2019-01-16 19:52:15.200464: step 1375, loss = 0.70237 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:52:16.094067 ops/training.py:65 2019-01-16 19:52:16.094012: step 1376, loss = 0.68040 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:52:16.987749 ops/training.py:65 2019-01-16 19:52:16.987694: step 1377, loss = 0.68834 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:52:17.882744 ops/training.py:65 2019-01-16 19:52:17.882692: step 1378, loss = 0.70233 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:52:18.778616 ops/training.py:65 2019-01-16 19:52:18.778516: step 1379, loss = 0.69812 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:52:19.674859 ops/training.py:65 2019-01-16 19:52:19.674777: step 1380, loss = 0.70436 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:52:20.570740 ops/training.py:65 2019-01-16 19:52:20.570639: step 1381, loss = 0.68768 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:52:21.466521 ops/training.py:65 2019-01-16 19:52:21.466422: step 1382, loss = 0.70407 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:52:22.361724 ops/training.py:65 2019-01-16 19:52:22.361625: step 1383, loss = 0.69636 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:52:23.260810 ops/training.py:65 2019-01-16 19:52:23.260718: step 1384, loss = 0.69658 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:52:24.157121 ops/training.py:65 2019-01-16 19:52:24.157021: step 1385, loss = 0.70757 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:52:25.054386 ops/training.py:65 2019-01-16 19:52:25.054284: step 1386, loss = 0.70019 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:52:25.951369 ops/training.py:65 2019-01-16 19:52:25.951263: step 1387, loss = 0.68252 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:52:26.846235 ops/training.py:65 2019-01-16 19:52:26.846183: step 1388, loss = 0.70215 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:52:27.739704 ops/training.py:65 2019-01-16 19:52:27.739651: step 1389, loss = 0.69742 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 19:52:28.632668 ops/training.py:65 2019-01-16 19:52:28.632609: step 1390, loss = 0.68539 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:52:29.526912 ops/training.py:65 2019-01-16 19:52:29.526863: step 1391, loss = 0.69104 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:52:30.420888 ops/training.py:65 2019-01-16 19:52:30.420836: step 1392, loss = 0.68945 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:52:31.313790 ops/training.py:65 2019-01-16 19:52:31.313735: step 1393, loss = 0.69643 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:52:32.207332 ops/training.py:65 2019-01-16 19:52:32.207282: step 1394, loss = 0.70331 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:52:33.102488 ops/training.py:65 2019-01-16 19:52:33.102428: step 1395, loss = 0.69230 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:52:33.998042 ops/training.py:65 2019-01-16 19:52:33.997953: step 1396, loss = 0.68722 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:52:34.893663 ops/training.py:65 2019-01-16 19:52:34.893587: step 1397, loss = 0.68943 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:52:35.789414 ops/training.py:65 2019-01-16 19:52:35.789333: step 1398, loss = 0.69447 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:52:36.684906 ops/training.py:65 2019-01-16 19:52:36.684824: step 1399, loss = 0.68903 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:52:37.581328 ops/training.py:65 2019-01-16 19:52:37.581225: step 1400, loss = 0.69241 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:52:38.479452 ops/training.py:65 2019-01-16 19:52:38.479354: step 1401, loss = 0.69182 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:52:39.376815 ops/training.py:65 2019-01-16 19:52:39.376718: step 1402, loss = 0.68846 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:52:40.274505 ops/training.py:65 2019-01-16 19:52:40.274409: step 1403, loss = 0.69262 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:52:41.171534 ops/training.py:65 2019-01-16 19:52:41.171444: step 1404, loss = 0.69275 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:52:42.067868 ops/training.py:65 2019-01-16 19:52:42.067818: step 1405, loss = 0.69303 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:52:42.965751 ops/training.py:65 2019-01-16 19:52:42.965652: step 1406, loss = 0.69418 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:52:43.862807 ops/training.py:65 2019-01-16 19:52:43.862704: step 1407, loss = 0.68785 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:52:44.760774 ops/training.py:65 2019-01-16 19:52:44.760672: step 1408, loss = 0.69292 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:52:45.657847 ops/training.py:65 2019-01-16 19:52:45.657744: step 1409, loss = 0.70115 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:52:46.553651 ops/training.py:65 2019-01-16 19:52:46.553557: step 1410, loss = 0.70792 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 19:52:47.449583 ops/training.py:65 2019-01-16 19:52:47.449502: step 1411, loss = 0.70044 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:52:48.346114 ops/training.py:65 2019-01-16 19:52:48.346019: step 1412, loss = 0.69741 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:52:49.241408 ops/training.py:65 2019-01-16 19:52:49.241328: step 1413, loss = 0.69919 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:52:50.137265 ops/training.py:65 2019-01-16 19:52:50.137161: step 1414, loss = 0.69931 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:52:51.031425 ops/training.py:65 2019-01-16 19:52:51.031328: step 1415, loss = 0.69216 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:52:51.927154 ops/training.py:65 2019-01-16 19:52:51.927048: step 1416, loss = 0.70014 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:52:52.822710 ops/training.py:65 2019-01-16 19:52:52.822606: step 1417, loss = 0.69296 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:52:53.717627 ops/training.py:65 2019-01-16 19:52:53.717523: step 1418, loss = 0.69747 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:52:54.613119 ops/training.py:65 2019-01-16 19:52:54.613008: step 1419, loss = 0.70140 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:52:55.508194 ops/training.py:65 2019-01-16 19:52:55.508130: step 1420, loss = 0.69468 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:52:56.402834 ops/training.py:65 2019-01-16 19:52:56.402779: step 1421, loss = 0.69355 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:52:57.297015 ops/training.py:65 2019-01-16 19:52:57.296954: step 1422, loss = 0.69657 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:52:58.190667 ops/training.py:65 2019-01-16 19:52:58.190609: step 1423, loss = 0.69588 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:52:59.084763 ops/training.py:65 2019-01-16 19:52:59.084706: step 1424, loss = 0.69439 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:52:59.978724 ops/training.py:65 2019-01-16 19:52:59.978672: step 1425, loss = 0.68458 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:53:00.872424 ops/training.py:65 2019-01-16 19:53:00.872358: step 1426, loss = 0.69187 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:53:01.766472 ops/training.py:65 2019-01-16 19:53:01.766420: step 1427, loss = 0.69018 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:53:02.659416 ops/training.py:65 2019-01-16 19:53:02.659363: step 1428, loss = 0.68948 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:53:03.553913 ops/training.py:65 2019-01-16 19:53:03.553853: step 1429, loss = 0.69708 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:53:04.447194 ops/training.py:65 2019-01-16 19:53:04.447143: step 1430, loss = 0.69991 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:53:05.340696 ops/training.py:65 2019-01-16 19:53:05.340637: step 1431, loss = 0.69232 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:53:06.233980 ops/training.py:65 2019-01-16 19:53:06.233908: step 1432, loss = 0.68752 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:53:07.128105 ops/training.py:65 2019-01-16 19:53:07.128018: step 1433, loss = 0.68740 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:53:08.023283 ops/training.py:65 2019-01-16 19:53:08.023193: step 1434, loss = 0.69983 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:53:08.917270 ops/training.py:65 2019-01-16 19:53:08.917211: step 1435, loss = 0.69363 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:53:09.811919 ops/training.py:65 2019-01-16 19:53:09.811864: step 1436, loss = 0.69467 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:53:10.706815 ops/training.py:65 2019-01-16 19:53:10.706765: step 1437, loss = 0.70355 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:53:11.605098 ops/training.py:65 2019-01-16 19:53:11.605002: step 1438, loss = 0.70235 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:53:12.500730 ops/training.py:65 2019-01-16 19:53:12.500631: step 1439, loss = 0.68929 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:53:13.397236 ops/training.py:65 2019-01-16 19:53:13.397139: step 1440, loss = 0.69821 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:53:14.294613 ops/training.py:65 2019-01-16 19:53:14.294515: step 1441, loss = 0.68535 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:53:15.191077 ops/training.py:65 2019-01-16 19:53:15.191019: step 1442, loss = 0.69176 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:53:16.085115 ops/training.py:65 2019-01-16 19:53:16.085058: step 1443, loss = 0.68634 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:53:16.979013 ops/training.py:65 2019-01-16 19:53:16.978954: step 1444, loss = 0.69787 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:53:17.872306 ops/training.py:65 2019-01-16 19:53:17.872252: step 1445, loss = 0.70095 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:53:18.765664 ops/training.py:65 2019-01-16 19:53:18.765608: step 1446, loss = 0.69487 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:53:19.662328 ops/training.py:65 2019-01-16 19:53:19.662271: step 1447, loss = 0.68952 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:53:20.579999 ops/training.py:65 2019-01-16 19:53:20.579901: step 1448, loss = 0.70494 (34.9 examples/sec; 0.917 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:53:21.475948 ops/training.py:65 2019-01-16 19:53:21.475846: step 1449, loss = 0.69630 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:53:22.371487 ops/training.py:65 2019-01-16 19:53:22.371428: step 1450, loss = 0.68903 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:53:23.266731 ops/training.py:65 2019-01-16 19:53:23.266676: step 1451, loss = 0.69293 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:53:24.161094 ops/training.py:65 2019-01-16 19:53:24.161041: step 1452, loss = 0.67909 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:53:25.055240 ops/training.py:65 2019-01-16 19:53:25.055181: step 1453, loss = 0.69953 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:53:25.950454 ops/training.py:65 2019-01-16 19:53:25.950399: step 1454, loss = 0.68930 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:53:26.844511 ops/training.py:65 2019-01-16 19:53:26.844460: step 1455, loss = 0.68605 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:53:27.742355 ops/training.py:65 2019-01-16 19:53:27.742254: step 1456, loss = 0.69285 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:53:28.638919 ops/training.py:65 2019-01-16 19:53:28.638866: step 1457, loss = 0.69680 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:53:29.534708 ops/training.py:65 2019-01-16 19:53:29.534605: step 1458, loss = 0.70468 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:53:30.433022 ops/training.py:65 2019-01-16 19:53:30.432919: step 1459, loss = 0.69143 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:53:31.329105 ops/training.py:65 2019-01-16 19:53:31.329004: step 1460, loss = 0.70078 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:53:32.223777 ops/training.py:65 2019-01-16 19:53:32.223728: step 1461, loss = 0.69562 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:53:33.117803 ops/training.py:65 2019-01-16 19:53:33.117742: step 1462, loss = 0.68884 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:53:34.012205 ops/training.py:65 2019-01-16 19:53:34.012121: step 1463, loss = 0.68404 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:53:34.905983 ops/training.py:65 2019-01-16 19:53:34.905905: step 1464, loss = 0.70137 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:53:35.800082 ops/training.py:65 2019-01-16 19:53:35.800005: step 1465, loss = 0.69014 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:53:36.694576 ops/training.py:65 2019-01-16 19:53:36.694476: step 1466, loss = 0.69478 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:53:37.588091 ops/training.py:65 2019-01-16 19:53:37.588019: step 1467, loss = 0.69055 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:53:38.483044 ops/training.py:65 2019-01-16 19:53:38.482960: step 1468, loss = 0.68896 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:53:39.379332 ops/training.py:65 2019-01-16 19:53:39.379257: step 1469, loss = 0.70652 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:53:40.275950 ops/training.py:65 2019-01-16 19:53:40.275847: step 1470, loss = 0.69696 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:53:41.172308 ops/training.py:65 2019-01-16 19:53:41.172220: step 1471, loss = 0.69204 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:53:42.066968 ops/training.py:65 2019-01-16 19:53:42.066878: step 1472, loss = 0.70596 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:53:42.961334 ops/training.py:65 2019-01-16 19:53:42.961263: step 1473, loss = 0.69609 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:53:43.856278 ops/training.py:65 2019-01-16 19:53:43.856176: step 1474, loss = 0.68424 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:53:44.749947 ops/training.py:65 2019-01-16 19:53:44.749850: step 1475, loss = 0.69109 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:53:45.644968 ops/training.py:65 2019-01-16 19:53:45.644866: step 1476, loss = 0.69131 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:53:46.540640 ops/training.py:65 2019-01-16 19:53:46.540533: step 1477, loss = 0.69335 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:53:47.436854 ops/training.py:65 2019-01-16 19:53:47.436766: step 1478, loss = 0.70234 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 19:53:48.334094 ops/training.py:65 2019-01-16 19:53:48.333983: step 1479, loss = 0.69832 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:53:49.230235 ops/training.py:65 2019-01-16 19:53:49.230156: step 1480, loss = 0.68735 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:53:50.126085 ops/training.py:65 2019-01-16 19:53:50.125980: step 1481, loss = 0.70196 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:53:51.021461 ops/training.py:65 2019-01-16 19:53:51.021358: step 1482, loss = 0.68980 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:53:51.917129 ops/training.py:65 2019-01-16 19:53:51.917028: step 1483, loss = 0.69256 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:53:52.812529 ops/training.py:65 2019-01-16 19:53:52.812421: step 1484, loss = 0.67897 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 19:53:53.708714 ops/training.py:65 2019-01-16 19:53:53.708613: step 1485, loss = 0.69280 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:53:54.603476 ops/training.py:65 2019-01-16 19:53:54.603381: step 1486, loss = 0.69407 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:53:55.500349 ops/training.py:65 2019-01-16 19:53:55.500247: step 1487, loss = 0.69588 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:53:56.396248 ops/training.py:65 2019-01-16 19:53:56.396144: step 1488, loss = 0.69396 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:53:57.291956 ops/training.py:65 2019-01-16 19:53:57.291852: step 1489, loss = 0.68965 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:53:58.186983 ops/training.py:65 2019-01-16 19:53:58.186878: step 1490, loss = 0.69809 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:53:59.081873 ops/training.py:65 2019-01-16 19:53:59.081775: step 1491, loss = 0.69666 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:53:59.977317 ops/training.py:65 2019-01-16 19:53:59.977212: step 1492, loss = 0.69210 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:54:00.873217 ops/training.py:65 2019-01-16 19:54:00.873114: step 1493, loss = 0.69560 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:54:01.769532 ops/training.py:65 2019-01-16 19:54:01.769439: step 1494, loss = 0.69351 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:54:02.665706 ops/training.py:65 2019-01-16 19:54:02.665625: step 1495, loss = 0.69637 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:54:03.562830 ops/training.py:65 2019-01-16 19:54:03.562729: step 1496, loss = 0.69122 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:54:04.458041 ops/training.py:65 2019-01-16 19:54:04.457957: step 1497, loss = 0.69592 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:54:05.353707 ops/training.py:65 2019-01-16 19:54:05.353602: step 1498, loss = 0.69798 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:54:06.250070 ops/training.py:65 2019-01-16 19:54:06.249992: step 1499, loss = 0.69344 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:54:07.147242 ops/training.py:65 2019-01-16 19:54:07.147151: step 1500, loss = 0.68735 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:54:08.042290 ops/training.py:65 2019-01-16 19:54:08.042185: step 1501, loss = 0.69230 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:54:08.938696 ops/training.py:65 2019-01-16 19:54:08.938597: step 1502, loss = 0.69703 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:54:09.832539 ops/training.py:65 2019-01-16 19:54:09.832439: step 1503, loss = 0.69041 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:54:10.727866 ops/training.py:65 2019-01-16 19:54:10.727787: step 1504, loss = 0.69023 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:54:11.623705 ops/training.py:65 2019-01-16 19:54:11.623603: step 1505, loss = 0.70068 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:54:12.519471 ops/training.py:65 2019-01-16 19:54:12.519375: step 1506, loss = 0.69442 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:54:13.414545 ops/training.py:65 2019-01-16 19:54:13.414443: step 1507, loss = 0.69381 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:54:14.310077 ops/training.py:65 2019-01-16 19:54:14.309981: step 1508, loss = 0.68182 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:54:15.205584 ops/training.py:65 2019-01-16 19:54:15.205488: step 1509, loss = 0.70232 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:54:16.101637 ops/training.py:65 2019-01-16 19:54:16.101531: step 1510, loss = 0.69407 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:54:16.996716 ops/training.py:65 2019-01-16 19:54:16.996607: step 1511, loss = 0.69343 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:54:17.891533 ops/training.py:65 2019-01-16 19:54:17.891448: step 1512, loss = 0.70061 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 19:54:18.790097 ops/training.py:65 2019-01-16 19:54:18.790008: step 1513, loss = 0.68156 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:54:19.685635 ops/training.py:65 2019-01-16 19:54:19.685555: step 1514, loss = 0.69514 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:54:20.585815 ops/training.py:65 2019-01-16 19:54:20.585725: step 1515, loss = 0.68543 (35.6 examples/sec; 0.899 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:54:21.480731 ops/training.py:65 2019-01-16 19:54:21.480641: step 1516, loss = 0.69953 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:54:22.376158 ops/training.py:65 2019-01-16 19:54:22.376067: step 1517, loss = 0.68989 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:54:23.272904 ops/training.py:65 2019-01-16 19:54:23.272807: step 1518, loss = 0.69485 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:54:24.170115 ops/training.py:65 2019-01-16 19:54:24.170014: step 1519, loss = 0.68779 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:54:25.065904 ops/training.py:65 2019-01-16 19:54:25.065811: step 1520, loss = 0.68815 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:54:25.961892 ops/training.py:65 2019-01-16 19:54:25.961795: step 1521, loss = 0.69845 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:54:26.857408 ops/training.py:65 2019-01-16 19:54:26.857309: step 1522, loss = 0.69862 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:54:27.752095 ops/training.py:65 2019-01-16 19:54:27.751993: step 1523, loss = 0.68902 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:54:28.645318 ops/training.py:65 2019-01-16 19:54:28.645216: step 1524, loss = 0.69112 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:54:29.541910 ops/training.py:65 2019-01-16 19:54:29.541820: step 1525, loss = 0.69326 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:54:30.437504 ops/training.py:65 2019-01-16 19:54:30.437412: step 1526, loss = 0.69341 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:54:31.332024 ops/training.py:65 2019-01-16 19:54:31.331930: step 1527, loss = 0.69242 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:54:32.226806 ops/training.py:65 2019-01-16 19:54:32.226738: step 1528, loss = 0.68228 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:54:33.123901 ops/training.py:65 2019-01-16 19:54:33.123805: step 1529, loss = 0.68961 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:54:34.018230 ops/training.py:65 2019-01-16 19:54:34.018138: step 1530, loss = 0.68512 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:54:34.912540 ops/training.py:65 2019-01-16 19:54:34.912461: step 1531, loss = 0.70157 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:54:35.808272 ops/training.py:65 2019-01-16 19:54:35.808186: step 1532, loss = 0.69332 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:54:36.704798 ops/training.py:65 2019-01-16 19:54:36.704700: step 1533, loss = 0.69629 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:54:37.599294 ops/training.py:65 2019-01-16 19:54:37.599198: step 1534, loss = 0.68314 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:54:38.494288 ops/training.py:65 2019-01-16 19:54:38.494196: step 1535, loss = 0.69018 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:54:39.390431 ops/training.py:65 2019-01-16 19:54:39.390332: step 1536, loss = 0.69115 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:54:40.285631 ops/training.py:65 2019-01-16 19:54:40.285535: step 1537, loss = 0.69065 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:54:41.181293 ops/training.py:65 2019-01-16 19:54:41.181205: step 1538, loss = 0.69581 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:54:42.077968 ops/training.py:65 2019-01-16 19:54:42.077880: step 1539, loss = 0.69211 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:54:42.972976 ops/training.py:65 2019-01-16 19:54:42.972875: step 1540, loss = 0.70192 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:54:43.866701 ops/training.py:65 2019-01-16 19:54:43.866594: step 1541, loss = 0.69979 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:54:44.758596 ops/training.py:65 2019-01-16 19:54:44.758507: step 1542, loss = 0.69272 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:54:45.655706 ops/training.py:65 2019-01-16 19:54:45.655614: step 1543, loss = 0.69728 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:54:46.553081 ops/training.py:65 2019-01-16 19:54:46.552985: step 1544, loss = 0.68625 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:54:47.450185 ops/training.py:65 2019-01-16 19:54:47.450086: step 1545, loss = 0.69056 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:54:48.348210 ops/training.py:65 2019-01-16 19:54:48.348108: step 1546, loss = 0.69717 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:54:49.244932 ops/training.py:65 2019-01-16 19:54:49.244846: step 1547, loss = 0.69798 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:54:50.141092 ops/training.py:65 2019-01-16 19:54:50.140991: step 1548, loss = 0.69158 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:54:51.036237 ops/training.py:65 2019-01-16 19:54:51.036149: step 1549, loss = 0.68814 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:54:51.934605 ops/training.py:65 2019-01-16 19:54:51.934517: step 1550, loss = 0.69875 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:54:52.832282 ops/training.py:65 2019-01-16 19:54:52.832191: step 1551, loss = 0.69861 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:54:53.729806 ops/training.py:65 2019-01-16 19:54:53.729711: step 1552, loss = 0.69551 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:54:54.627263 ops/training.py:65 2019-01-16 19:54:54.627168: step 1553, loss = 0.69765 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:54:55.524045 ops/training.py:65 2019-01-16 19:54:55.523950: step 1554, loss = 0.68743 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:54:56.420323 ops/training.py:65 2019-01-16 19:54:56.420226: step 1555, loss = 0.70204 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:54:57.317650 ops/training.py:65 2019-01-16 19:54:57.317558: step 1556, loss = 0.70544 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:54:58.214098 ops/training.py:65 2019-01-16 19:54:58.214005: step 1557, loss = 0.69176 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:54:59.110587 ops/training.py:65 2019-01-16 19:54:59.110521: step 1558, loss = 0.68344 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:55:00.006062 ops/training.py:65 2019-01-16 19:55:00.005964: step 1559, loss = 0.69828 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:55:00.902262 ops/training.py:65 2019-01-16 19:55:00.902157: step 1560, loss = 0.69810 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:55:01.799922 ops/training.py:65 2019-01-16 19:55:01.799838: step 1561, loss = 0.69624 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:55:02.695691 ops/training.py:65 2019-01-16 19:55:02.695622: step 1562, loss = 0.68253 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:55:03.594043 ops/training.py:65 2019-01-16 19:55:03.593943: step 1563, loss = 0.68431 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:55:04.490596 ops/training.py:65 2019-01-16 19:55:04.490517: step 1564, loss = 0.68771 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:55:05.386602 ops/training.py:65 2019-01-16 19:55:05.386537: step 1565, loss = 0.70655 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 19:55:06.280475 ops/training.py:65 2019-01-16 19:55:06.280385: step 1566, loss = 0.70966 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 19:55:07.175925 ops/training.py:65 2019-01-16 19:55:07.175826: step 1567, loss = 0.67891 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:55:08.071202 ops/training.py:65 2019-01-16 19:55:08.071125: step 1568, loss = 0.69452 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:55:08.966478 ops/training.py:65 2019-01-16 19:55:08.966415: step 1569, loss = 0.69215 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:55:09.860221 ops/training.py:65 2019-01-16 19:55:09.860160: step 1570, loss = 0.69783 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:55:10.755251 ops/training.py:65 2019-01-16 19:55:10.755184: step 1571, loss = 0.70888 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:55:11.649505 ops/training.py:65 2019-01-16 19:55:11.649445: step 1572, loss = 0.69292 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:55:12.544224 ops/training.py:65 2019-01-16 19:55:12.544159: step 1573, loss = 0.69047 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:55:13.440087 ops/training.py:65 2019-01-16 19:55:13.440016: step 1574, loss = 0.67269 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:55:14.334475 ops/training.py:65 2019-01-16 19:55:14.334414: step 1575, loss = 0.69202 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:55:15.228739 ops/training.py:65 2019-01-16 19:55:15.228678: step 1576, loss = 0.68547 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:55:16.124484 ops/training.py:65 2019-01-16 19:55:16.124413: step 1577, loss = 0.69418 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:55:17.019894 ops/training.py:65 2019-01-16 19:55:17.019832: step 1578, loss = 0.70123 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:55:17.916746 ops/training.py:65 2019-01-16 19:55:17.916689: step 1579, loss = 0.71353 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 19:55:18.812410 ops/training.py:65 2019-01-16 19:55:18.812305: step 1580, loss = 0.70392 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:55:19.708059 ops/training.py:65 2019-01-16 19:55:19.707975: step 1581, loss = 0.69985 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:55:20.605576 ops/training.py:65 2019-01-16 19:55:20.605480: step 1582, loss = 0.70362 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:55:21.502522 ops/training.py:65 2019-01-16 19:55:21.502413: step 1583, loss = 0.69690 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:55:22.400642 ops/training.py:65 2019-01-16 19:55:22.400501: step 1584, loss = 0.70347 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:55:23.297707 ops/training.py:65 2019-01-16 19:55:23.297599: step 1585, loss = 0.69887 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:55:24.194219 ops/training.py:65 2019-01-16 19:55:24.194114: step 1586, loss = 0.70028 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:55:25.090343 ops/training.py:65 2019-01-16 19:55:25.090282: step 1587, loss = 0.68000 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:55:25.984726 ops/training.py:65 2019-01-16 19:55:25.984677: step 1588, loss = 0.69832 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:55:26.882475 ops/training.py:65 2019-01-16 19:55:26.882370: step 1589, loss = 0.69160 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:55:27.780128 ops/training.py:65 2019-01-16 19:55:27.780071: step 1590, loss = 0.68890 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:55:28.674359 ops/training.py:65 2019-01-16 19:55:28.674298: step 1591, loss = 0.69577 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:55:29.570493 ops/training.py:65 2019-01-16 19:55:29.570389: step 1592, loss = 0.68998 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:55:30.466974 ops/training.py:65 2019-01-16 19:55:30.466875: step 1593, loss = 0.71411 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:55:31.362789 ops/training.py:65 2019-01-16 19:55:31.362688: step 1594, loss = 0.70694 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:55:32.259389 ops/training.py:65 2019-01-16 19:55:32.259290: step 1595, loss = 0.68474 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:55:33.157214 ops/training.py:65 2019-01-16 19:55:33.157107: step 1596, loss = 0.69159 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:55:34.052949 ops/training.py:65 2019-01-16 19:55:34.052853: step 1597, loss = 0.71104 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:55:34.948828 ops/training.py:65 2019-01-16 19:55:34.948732: step 1598, loss = 0.69808 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:55:35.845339 ops/training.py:65 2019-01-16 19:55:35.845258: step 1599, loss = 0.69859 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:55:36.740768 ops/training.py:65 2019-01-16 19:55:36.740672: step 1600, loss = 0.70797 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:55:37.636160 ops/training.py:65 2019-01-16 19:55:37.636095: step 1601, loss = 0.69414 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:55:38.531120 ops/training.py:65 2019-01-16 19:55:38.531033: step 1602, loss = 0.70187 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:55:39.425820 ops/training.py:65 2019-01-16 19:55:39.425754: step 1603, loss = 0.70051 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:55:40.319839 ops/training.py:65 2019-01-16 19:55:40.319773: step 1604, loss = 0.69184 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:55:41.213805 ops/training.py:65 2019-01-16 19:55:41.213743: step 1605, loss = 0.69394 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:55:42.107756 ops/training.py:65 2019-01-16 19:55:42.107691: step 1606, loss = 0.69399 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:55:43.001912 ops/training.py:65 2019-01-16 19:55:43.001844: step 1607, loss = 0.69768 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:55:43.895027 ops/training.py:65 2019-01-16 19:55:43.894958: step 1608, loss = 0.71038 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:55:44.789638 ops/training.py:65 2019-01-16 19:55:44.789591: step 1609, loss = 0.68179 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:55:45.684897 ops/training.py:65 2019-01-16 19:55:45.684852: step 1610, loss = 0.70113 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:55:46.578971 ops/training.py:65 2019-01-16 19:55:46.578920: step 1611, loss = 0.69612 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:55:47.473340 ops/training.py:65 2019-01-16 19:55:47.473291: step 1612, loss = 0.68476 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:55:48.367663 ops/training.py:65 2019-01-16 19:55:48.367599: step 1613, loss = 0.70446 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:55:49.262750 ops/training.py:65 2019-01-16 19:55:49.262696: step 1614, loss = 0.70680 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:55:50.156992 ops/training.py:65 2019-01-16 19:55:50.156945: step 1615, loss = 0.70239 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:55:51.052276 ops/training.py:65 2019-01-16 19:55:51.052224: step 1616, loss = 0.69474 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:55:51.947872 ops/training.py:65 2019-01-16 19:55:51.947803: step 1617, loss = 0.69709 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:55:52.841813 ops/training.py:65 2019-01-16 19:55:52.841763: step 1618, loss = 0.69520 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:55:53.734928 ops/training.py:65 2019-01-16 19:55:53.734869: step 1619, loss = 0.69682 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:55:54.630197 ops/training.py:65 2019-01-16 19:55:54.630148: step 1620, loss = 0.68708 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:55:55.523796 ops/training.py:65 2019-01-16 19:55:55.523723: step 1621, loss = 0.69278 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:55:56.417521 ops/training.py:65 2019-01-16 19:55:56.417458: step 1622, loss = 0.69523 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:55:57.313182 ops/training.py:65 2019-01-16 19:55:57.313140: step 1623, loss = 0.68129 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:55:58.210885 ops/training.py:65 2019-01-16 19:55:58.210851: step 1624, loss = 0.69824 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:55:59.106160 ops/training.py:65 2019-01-16 19:55:59.106127: step 1625, loss = 0.69851 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:56:00.003515 ops/training.py:65 2019-01-16 19:56:00.003442: step 1626, loss = 0.69972 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:56:00.897074 ops/training.py:65 2019-01-16 19:56:00.896996: step 1627, loss = 0.69010 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:56:01.790959 ops/training.py:65 2019-01-16 19:56:01.790897: step 1628, loss = 0.69669 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:56:02.685187 ops/training.py:65 2019-01-16 19:56:02.685118: step 1629, loss = 0.69588 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:56:03.578866 ops/training.py:65 2019-01-16 19:56:03.578780: step 1630, loss = 0.69520 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:56:04.472998 ops/training.py:65 2019-01-16 19:56:04.472925: step 1631, loss = 0.69516 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:56:05.366636 ops/training.py:65 2019-01-16 19:56:05.366550: step 1632, loss = 0.70027 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:56:06.260535 ops/training.py:65 2019-01-16 19:56:06.260449: step 1633, loss = 0.69509 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:56:07.155489 ops/training.py:65 2019-01-16 19:56:07.155455: step 1634, loss = 0.70115 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:56:08.050830 ops/training.py:65 2019-01-16 19:56:08.050796: step 1635, loss = 0.69956 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:56:08.946422 ops/training.py:65 2019-01-16 19:56:08.946352: step 1636, loss = 0.69060 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:56:09.841186 ops/training.py:65 2019-01-16 19:56:09.841124: step 1637, loss = 0.69400 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:56:10.738192 ops/training.py:65 2019-01-16 19:56:10.738127: step 1638, loss = 0.69456 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:56:11.632631 ops/training.py:65 2019-01-16 19:56:11.632570: step 1639, loss = 0.68827 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:56:12.529116 ops/training.py:65 2019-01-16 19:56:12.529036: step 1640, loss = 0.69272 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:56:13.427387 ops/training.py:65 2019-01-16 19:56:13.427259: step 1641, loss = 0.68946 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:56:14.326963 ops/training.py:65 2019-01-16 19:56:14.326859: step 1642, loss = 0.69136 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:56:15.222902 ops/training.py:65 2019-01-16 19:56:15.222837: step 1643, loss = 0.69362 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:56:16.117703 ops/training.py:65 2019-01-16 19:56:16.117630: step 1644, loss = 0.69206 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:56:17.012084 ops/training.py:65 2019-01-16 19:56:17.012021: step 1645, loss = 0.69976 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:56:17.906744 ops/training.py:65 2019-01-16 19:56:17.906692: step 1646, loss = 0.69494 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:56:18.800542 ops/training.py:65 2019-01-16 19:56:18.800479: step 1647, loss = 0.69394 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:56:19.694906 ops/training.py:65 2019-01-16 19:56:19.694850: step 1648, loss = 0.69814 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:56:20.589056 ops/training.py:65 2019-01-16 19:56:20.588973: step 1649, loss = 0.69842 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:56:21.483119 ops/training.py:65 2019-01-16 19:56:21.483061: step 1650, loss = 0.68685 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:56:22.376223 ops/training.py:65 2019-01-16 19:56:22.376169: step 1651, loss = 0.69116 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:56:23.270767 ops/training.py:65 2019-01-16 19:56:23.270704: step 1652, loss = 0.69217 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:56:24.164505 ops/training.py:65 2019-01-16 19:56:24.164449: step 1653, loss = 0.69226 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:56:25.059990 ops/training.py:65 2019-01-16 19:56:25.059915: step 1654, loss = 0.69009 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:56:25.956740 ops/training.py:65 2019-01-16 19:56:25.956642: step 1655, loss = 0.69674 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:56:26.853189 ops/training.py:65 2019-01-16 19:56:26.853092: step 1656, loss = 0.68829 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:56:27.748695 ops/training.py:65 2019-01-16 19:56:27.748624: step 1657, loss = 0.68752 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:56:28.642616 ops/training.py:65 2019-01-16 19:56:28.642547: step 1658, loss = 0.69451 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:56:29.538297 ops/training.py:65 2019-01-16 19:56:29.538218: step 1659, loss = 0.69749 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:56:30.435161 ops/training.py:65 2019-01-16 19:56:30.435062: step 1660, loss = 0.69264 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:56:31.332930 ops/training.py:65 2019-01-16 19:56:31.332824: step 1661, loss = 0.69503 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:56:32.229897 ops/training.py:65 2019-01-16 19:56:32.229797: step 1662, loss = 0.68301 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.75
I1280 2019-01-16 19:56:33.126843 ops/training.py:65 2019-01-16 19:56:33.126772: step 1663, loss = 0.70106 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:56:34.024772 ops/training.py:65 2019-01-16 19:56:34.024674: step 1664, loss = 0.70288 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:56:34.920826 ops/training.py:65 2019-01-16 19:56:34.920767: step 1665, loss = 0.68436 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:56:35.819298 ops/training.py:65 2019-01-16 19:56:35.819212: step 1666, loss = 0.70536 (35.7 examples/sec; 0.898 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:56:36.714375 ops/training.py:65 2019-01-16 19:56:36.714291: step 1667, loss = 0.69205 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:56:37.612740 ops/training.py:65 2019-01-16 19:56:37.612659: step 1668, loss = 0.69235 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:56:38.514388 ops/training.py:65 2019-01-16 19:56:38.514281: step 1669, loss = 0.69192 (35.5 examples/sec; 0.901 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:56:39.409303 ops/training.py:65 2019-01-16 19:56:39.409197: step 1670, loss = 0.69318 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:56:40.304877 ops/training.py:65 2019-01-16 19:56:40.304802: step 1671, loss = 0.69397 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:56:41.200247 ops/training.py:65 2019-01-16 19:56:41.200178: step 1672, loss = 0.68664 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:56:42.094796 ops/training.py:65 2019-01-16 19:56:42.094735: step 1673, loss = 0.69225 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:56:42.991479 ops/training.py:65 2019-01-16 19:56:42.991371: step 1674, loss = 0.68725 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:56:43.887868 ops/training.py:65 2019-01-16 19:56:43.887792: step 1675, loss = 0.69588 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:56:44.782592 ops/training.py:65 2019-01-16 19:56:44.782531: step 1676, loss = 0.69250 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:56:45.677245 ops/training.py:65 2019-01-16 19:56:45.677187: step 1677, loss = 0.69209 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:56:46.571511 ops/training.py:65 2019-01-16 19:56:46.571449: step 1678, loss = 0.69500 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:56:47.465515 ops/training.py:65 2019-01-16 19:56:47.465461: step 1679, loss = 0.68875 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:56:48.358948 ops/training.py:65 2019-01-16 19:56:48.358885: step 1680, loss = 0.69514 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:56:49.252845 ops/training.py:65 2019-01-16 19:56:49.252773: step 1681, loss = 0.69336 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:56:50.148464 ops/training.py:65 2019-01-16 19:56:50.148409: step 1682, loss = 0.69474 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:56:51.046404 ops/training.py:65 2019-01-16 19:56:51.046298: step 1683, loss = 0.68776 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:56:51.942792 ops/training.py:65 2019-01-16 19:56:51.942720: step 1684, loss = 0.68804 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:56:52.838499 ops/training.py:65 2019-01-16 19:56:52.838394: step 1685, loss = 0.68633 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:56:53.735581 ops/training.py:65 2019-01-16 19:56:53.735477: step 1686, loss = 0.70737 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:56:54.632982 ops/training.py:65 2019-01-16 19:56:54.632877: step 1687, loss = 0.68954 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:56:55.528336 ops/training.py:65 2019-01-16 19:56:55.528267: step 1688, loss = 0.69870 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:56:56.425894 ops/training.py:65 2019-01-16 19:56:56.425790: step 1689, loss = 0.69031 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:56:57.321813 ops/training.py:65 2019-01-16 19:56:57.321751: step 1690, loss = 0.69366 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:56:58.215444 ops/training.py:65 2019-01-16 19:56:58.215380: step 1691, loss = 0.67977 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:56:59.109298 ops/training.py:65 2019-01-16 19:56:59.109226: step 1692, loss = 0.69885 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:57:00.004790 ops/training.py:65 2019-01-16 19:57:00.004726: step 1693, loss = 0.69172 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:57:00.901397 ops/training.py:65 2019-01-16 19:57:00.901331: step 1694, loss = 0.69873 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:57:01.799382 ops/training.py:65 2019-01-16 19:57:01.799289: step 1695, loss = 0.70251 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:57:02.697262 ops/training.py:65 2019-01-16 19:57:02.697209: step 1696, loss = 0.69804 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:57:03.591631 ops/training.py:65 2019-01-16 19:57:03.591572: step 1697, loss = 0.69300 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:57:04.486969 ops/training.py:65 2019-01-16 19:57:04.486910: step 1698, loss = 0.69330 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:57:05.382144 ops/training.py:65 2019-01-16 19:57:05.382079: step 1699, loss = 0.69346 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:57:06.275393 ops/training.py:65 2019-01-16 19:57:06.275314: step 1700, loss = 0.69377 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:57:07.169535 ops/training.py:65 2019-01-16 19:57:07.169402: step 1701, loss = 0.68398 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:57:08.065952 ops/training.py:65 2019-01-16 19:57:08.065874: step 1702, loss = 0.69677 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:57:08.960609 ops/training.py:65 2019-01-16 19:57:08.960548: step 1703, loss = 0.69614 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:57:09.855155 ops/training.py:65 2019-01-16 19:57:09.855101: step 1704, loss = 0.68772 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:57:10.752947 ops/training.py:65 2019-01-16 19:57:10.752847: step 1705, loss = 0.70231 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:57:11.650849 ops/training.py:65 2019-01-16 19:57:11.650750: step 1706, loss = 0.70804 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:57:12.547389 ops/training.py:65 2019-01-16 19:57:12.547330: step 1707, loss = 0.69307 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:57:13.442713 ops/training.py:65 2019-01-16 19:57:13.442654: step 1708, loss = 0.68673 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:57:14.339599 ops/training.py:65 2019-01-16 19:57:14.339489: step 1709, loss = 0.70445 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:57:15.235334 ops/training.py:65 2019-01-16 19:57:15.235274: step 1710, loss = 0.68498 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:57:16.129428 ops/training.py:65 2019-01-16 19:57:16.129364: step 1711, loss = 0.69405 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:57:17.021964 ops/training.py:65 2019-01-16 19:57:17.021903: step 1712, loss = 0.69031 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:57:17.915543 ops/training.py:65 2019-01-16 19:57:17.915489: step 1713, loss = 0.69260 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:57:18.809900 ops/training.py:65 2019-01-16 19:57:18.809838: step 1714, loss = 0.69710 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:57:19.704292 ops/training.py:65 2019-01-16 19:57:19.704239: step 1715, loss = 0.69515 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:57:20.599911 ops/training.py:65 2019-01-16 19:57:20.599864: step 1716, loss = 0.69310 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:57:21.497601 ops/training.py:65 2019-01-16 19:57:21.497541: step 1717, loss = 0.69596 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:57:22.393030 ops/training.py:65 2019-01-16 19:57:22.392934: step 1718, loss = 0.69635 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:57:23.288117 ops/training.py:65 2019-01-16 19:57:23.288051: step 1719, loss = 0.70222 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:57:24.183270 ops/training.py:65 2019-01-16 19:57:24.183205: step 1720, loss = 0.68796 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:57:25.078652 ops/training.py:65 2019-01-16 19:57:25.078585: step 1721, loss = 0.69899 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:57:25.973930 ops/training.py:65 2019-01-16 19:57:25.973866: step 1722, loss = 0.68966 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:57:26.868615 ops/training.py:65 2019-01-16 19:57:26.868555: step 1723, loss = 0.68868 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:57:27.763298 ops/training.py:65 2019-01-16 19:57:27.763235: step 1724, loss = 0.70240 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:57:28.657931 ops/training.py:65 2019-01-16 19:57:28.657866: step 1725, loss = 0.69671 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:57:29.552443 ops/training.py:65 2019-01-16 19:57:29.552381: step 1726, loss = 0.69594 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:57:30.447565 ops/training.py:65 2019-01-16 19:57:30.447503: step 1727, loss = 0.69894 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:57:31.340965 ops/training.py:65 2019-01-16 19:57:31.340902: step 1728, loss = 0.69843 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:57:32.233223 ops/training.py:65 2019-01-16 19:57:32.233168: step 1729, loss = 0.69995 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:57:33.128507 ops/training.py:65 2019-01-16 19:57:33.128472: step 1730, loss = 0.68592 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:57:34.024182 ops/training.py:65 2019-01-16 19:57:34.024151: step 1731, loss = 0.69780 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:57:34.919556 ops/training.py:65 2019-01-16 19:57:34.919523: step 1732, loss = 0.69308 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:57:35.816496 ops/training.py:65 2019-01-16 19:57:35.816412: step 1733, loss = 0.68598 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:57:36.712246 ops/training.py:65 2019-01-16 19:57:36.712192: step 1734, loss = 0.69115 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:57:37.606824 ops/training.py:65 2019-01-16 19:57:37.606769: step 1735, loss = 0.70091 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:57:38.500613 ops/training.py:65 2019-01-16 19:57:38.500556: step 1736, loss = 0.70247 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:57:39.395811 ops/training.py:65 2019-01-16 19:57:39.395732: step 1737, loss = 0.69243 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:57:40.290547 ops/training.py:65 2019-01-16 19:57:40.290499: step 1738, loss = 0.69282 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:57:41.186650 ops/training.py:65 2019-01-16 19:57:41.186586: step 1739, loss = 0.68566 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:57:42.081867 ops/training.py:65 2019-01-16 19:57:42.081811: step 1740, loss = 0.68928 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:57:42.978517 ops/training.py:65 2019-01-16 19:57:42.978457: step 1741, loss = 0.69776 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:57:43.875233 ops/training.py:65 2019-01-16 19:57:43.875159: step 1742, loss = 0.69683 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:57:44.770860 ops/training.py:65 2019-01-16 19:57:44.770758: step 1743, loss = 0.68773 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:57:45.666718 ops/training.py:65 2019-01-16 19:57:45.666619: step 1744, loss = 0.69384 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:57:46.562238 ops/training.py:65 2019-01-16 19:57:46.562137: step 1745, loss = 0.69733 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:57:47.458523 ops/training.py:65 2019-01-16 19:57:47.458440: step 1746, loss = 0.69352 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:57:48.354851 ops/training.py:65 2019-01-16 19:57:48.354783: step 1747, loss = 0.69172 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:57:49.249605 ops/training.py:65 2019-01-16 19:57:49.249541: step 1748, loss = 0.69339 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:57:50.144417 ops/training.py:65 2019-01-16 19:57:50.144351: step 1749, loss = 0.69636 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:57:51.039272 ops/training.py:65 2019-01-16 19:57:51.039207: step 1750, loss = 0.68345 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:57:51.933354 ops/training.py:65 2019-01-16 19:57:51.933292: step 1751, loss = 0.68005 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:57:52.828328 ops/training.py:65 2019-01-16 19:57:52.828268: step 1752, loss = 0.68949 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:57:53.722327 ops/training.py:65 2019-01-16 19:57:53.722266: step 1753, loss = 0.68714 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:57:54.617126 ops/training.py:65 2019-01-16 19:57:54.617068: step 1754, loss = 0.68392 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:57:55.511111 ops/training.py:65 2019-01-16 19:57:55.511051: step 1755, loss = 0.68531 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:57:56.407295 ops/training.py:65 2019-01-16 19:57:56.407244: step 1756, loss = 0.68859 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:57:57.303659 ops/training.py:65 2019-01-16 19:57:57.303600: step 1757, loss = 0.68794 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:57:58.199260 ops/training.py:65 2019-01-16 19:57:58.199187: step 1758, loss = 0.69846 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:57:59.093893 ops/training.py:65 2019-01-16 19:57:59.093832: step 1759, loss = 0.69474 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:57:59.988601 ops/training.py:65 2019-01-16 19:57:59.988535: step 1760, loss = 0.69966 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:58:00.883692 ops/training.py:65 2019-01-16 19:58:00.883631: step 1761, loss = 0.70058 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:58:01.780921 ops/training.py:65 2019-01-16 19:58:01.780825: step 1762, loss = 0.68431 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:58:02.676887 ops/training.py:65 2019-01-16 19:58:02.676836: step 1763, loss = 0.69925 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:58:03.575106 ops/training.py:65 2019-01-16 19:58:03.574991: step 1764, loss = 0.68658 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:58:04.472047 ops/training.py:65 2019-01-16 19:58:04.471977: step 1765, loss = 0.68953 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:58:05.366572 ops/training.py:65 2019-01-16 19:58:05.366502: step 1766, loss = 0.69287 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:58:06.262584 ops/training.py:65 2019-01-16 19:58:06.262502: step 1767, loss = 0.70962 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:58:07.157756 ops/training.py:65 2019-01-16 19:58:07.157694: step 1768, loss = 0.69418 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:58:08.053002 ops/training.py:65 2019-01-16 19:58:08.052936: step 1769, loss = 0.68897 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:58:08.948867 ops/training.py:65 2019-01-16 19:58:08.948805: step 1770, loss = 0.68956 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:58:09.844825 ops/training.py:65 2019-01-16 19:58:09.844758: step 1771, loss = 0.69438 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:58:10.740795 ops/training.py:65 2019-01-16 19:58:10.740730: step 1772, loss = 0.69883 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:58:11.634955 ops/training.py:65 2019-01-16 19:58:11.634885: step 1773, loss = 0.68378 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:58:12.528890 ops/training.py:65 2019-01-16 19:58:12.528783: step 1774, loss = 0.69843 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:58:13.423980 ops/training.py:65 2019-01-16 19:58:13.423905: step 1775, loss = 0.69503 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:58:14.318103 ops/training.py:65 2019-01-16 19:58:14.318038: step 1776, loss = 0.70455 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:58:15.213360 ops/training.py:65 2019-01-16 19:58:15.213228: step 1777, loss = 0.70215 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:58:16.110578 ops/training.py:65 2019-01-16 19:58:16.110481: step 1778, loss = 0.69340 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:58:17.008016 ops/training.py:65 2019-01-16 19:58:17.007905: step 1779, loss = 0.69385 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:58:17.905041 ops/training.py:65 2019-01-16 19:58:17.904982: step 1780, loss = 0.69730 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:58:18.800493 ops/training.py:65 2019-01-16 19:58:18.800428: step 1781, loss = 0.68410 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:58:19.695889 ops/training.py:65 2019-01-16 19:58:19.695832: step 1782, loss = 0.69275 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:58:20.590286 ops/training.py:65 2019-01-16 19:58:20.590223: step 1783, loss = 0.68854 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:58:21.485203 ops/training.py:65 2019-01-16 19:58:21.485137: step 1784, loss = 0.69850 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:58:22.381127 ops/training.py:65 2019-01-16 19:58:22.381059: step 1785, loss = 0.70175 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:58:23.276365 ops/training.py:65 2019-01-16 19:58:23.276304: step 1786, loss = 0.69569 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:58:24.170372 ops/training.py:65 2019-01-16 19:58:24.170310: step 1787, loss = 0.68317 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:58:25.064807 ops/training.py:65 2019-01-16 19:58:25.064744: step 1788, loss = 0.69344 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:58:25.958961 ops/training.py:65 2019-01-16 19:58:25.958897: step 1789, loss = 0.68493 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:58:26.852845 ops/training.py:65 2019-01-16 19:58:26.852787: step 1790, loss = 0.68964 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:58:27.749028 ops/training.py:65 2019-01-16 19:58:27.748949: step 1791, loss = 0.69318 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:58:28.650069 ops/training.py:65 2019-01-16 19:58:28.649951: step 1792, loss = 0.69199 (35.6 examples/sec; 0.900 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:58:29.546112 ops/training.py:65 2019-01-16 19:58:29.546053: step 1793, loss = 0.69203 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:58:30.442340 ops/training.py:65 2019-01-16 19:58:30.442268: step 1794, loss = 0.69426 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:58:31.337574 ops/training.py:65 2019-01-16 19:58:31.337468: step 1795, loss = 0.69594 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:58:32.235343 ops/training.py:65 2019-01-16 19:58:32.235239: step 1796, loss = 0.71186 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:58:33.131834 ops/training.py:65 2019-01-16 19:58:33.131771: step 1797, loss = 0.70389 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:58:34.025802 ops/training.py:65 2019-01-16 19:58:34.025739: step 1798, loss = 0.70388 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:58:34.919200 ops/training.py:65 2019-01-16 19:58:34.919144: step 1799, loss = 0.69931 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:58:35.813483 ops/training.py:65 2019-01-16 19:58:35.813400: step 1800, loss = 0.68065 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:58:36.709290 ops/training.py:65 2019-01-16 19:58:36.709204: step 1801, loss = 0.69648 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:58:37.604918 ops/training.py:65 2019-01-16 19:58:37.604810: step 1802, loss = 0.70312 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:58:38.499464 ops/training.py:65 2019-01-16 19:58:38.499389: step 1803, loss = 0.70200 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:58:39.393328 ops/training.py:65 2019-01-16 19:58:39.393261: step 1804, loss = 0.68584 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:58:40.286746 ops/training.py:65 2019-01-16 19:58:40.286686: step 1805, loss = 0.67729 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:58:41.182808 ops/training.py:65 2019-01-16 19:58:41.182741: step 1806, loss = 0.70095 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:58:42.081137 ops/training.py:65 2019-01-16 19:58:42.081038: step 1807, loss = 0.70554 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:58:42.978556 ops/training.py:65 2019-01-16 19:58:42.978491: step 1808, loss = 0.68860 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:58:43.874586 ops/training.py:65 2019-01-16 19:58:43.874519: step 1809, loss = 0.70436 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:58:44.769189 ops/training.py:65 2019-01-16 19:58:44.769122: step 1810, loss = 0.70643 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:58:45.664856 ops/training.py:65 2019-01-16 19:58:45.664794: step 1811, loss = 0.70405 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:58:46.559585 ops/training.py:65 2019-01-16 19:58:46.559517: step 1812, loss = 0.69417 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:58:47.455219 ops/training.py:65 2019-01-16 19:58:47.455163: step 1813, loss = 0.69946 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:58:48.350113 ops/training.py:65 2019-01-16 19:58:48.350049: step 1814, loss = 0.70278 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:58:49.246537 ops/training.py:65 2019-01-16 19:58:49.246468: step 1815, loss = 0.69892 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:58:50.141427 ops/training.py:65 2019-01-16 19:58:50.141371: step 1816, loss = 0.68882 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:58:51.036808 ops/training.py:65 2019-01-16 19:58:51.036742: step 1817, loss = 0.69511 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:58:51.931531 ops/training.py:65 2019-01-16 19:58:51.931474: step 1818, loss = 0.69198 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:58:52.829404 ops/training.py:65 2019-01-16 19:58:52.829309: step 1819, loss = 0.67124 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 19:58:53.726767 ops/training.py:65 2019-01-16 19:58:53.726697: step 1820, loss = 0.69727 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:58:54.621579 ops/training.py:65 2019-01-16 19:58:54.621512: step 1821, loss = 0.68833 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:58:55.516872 ops/training.py:65 2019-01-16 19:58:55.516806: step 1822, loss = 0.71186 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:58:56.411988 ops/training.py:65 2019-01-16 19:58:56.411916: step 1823, loss = 0.69990 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:58:57.307441 ops/training.py:65 2019-01-16 19:58:57.307375: step 1824, loss = 0.68526 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:58:58.201947 ops/training.py:65 2019-01-16 19:58:58.201879: step 1825, loss = 0.68363 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:58:59.097269 ops/training.py:65 2019-01-16 19:58:59.097208: step 1826, loss = 0.70272 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:58:59.996669 ops/training.py:65 2019-01-16 19:58:59.996560: step 1827, loss = 0.68188 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:59:00.893772 ops/training.py:65 2019-01-16 19:59:00.893704: step 1828, loss = 0.68654 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:59:01.789383 ops/training.py:65 2019-01-16 19:59:01.789331: step 1829, loss = 0.68794 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:59:02.686749 ops/training.py:65 2019-01-16 19:59:02.686694: step 1830, loss = 0.69676 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:59:03.583010 ops/training.py:65 2019-01-16 19:59:03.582933: step 1831, loss = 0.69038 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:59:04.479026 ops/training.py:65 2019-01-16 19:59:04.478970: step 1832, loss = 0.67265 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:59:05.373773 ops/training.py:65 2019-01-16 19:59:05.373714: step 1833, loss = 0.67770 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:59:06.267036 ops/training.py:65 2019-01-16 19:59:06.266962: step 1834, loss = 0.71235 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:59:07.162302 ops/training.py:65 2019-01-16 19:59:07.162209: step 1835, loss = 0.66552 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:59:08.059540 ops/training.py:65 2019-01-16 19:59:08.059437: step 1836, loss = 0.71045 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:59:08.955010 ops/training.py:65 2019-01-16 19:59:08.954915: step 1837, loss = 0.69516 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:59:09.850489 ops/training.py:65 2019-01-16 19:59:09.850393: step 1838, loss = 0.71219 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:59:10.745502 ops/training.py:65 2019-01-16 19:59:10.745402: step 1839, loss = 0.68347 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:59:11.639902 ops/training.py:65 2019-01-16 19:59:11.639802: step 1840, loss = 0.69605 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:59:12.534753 ops/training.py:65 2019-01-16 19:59:12.534663: step 1841, loss = 0.69332 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:59:13.429830 ops/training.py:65 2019-01-16 19:59:13.429793: step 1842, loss = 0.70629 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:59:14.325273 ops/training.py:65 2019-01-16 19:59:14.325240: step 1843, loss = 0.68804 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:59:15.220262 ops/training.py:65 2019-01-16 19:59:15.220225: step 1844, loss = 0.71949 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 19:59:16.114451 ops/training.py:65 2019-01-16 19:59:16.114380: step 1845, loss = 0.70446 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:59:17.009642 ops/training.py:65 2019-01-16 19:59:17.009607: step 1846, loss = 0.69911 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:59:17.905319 ops/training.py:65 2019-01-16 19:59:17.905272: step 1847, loss = 0.70599 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:59:18.800855 ops/training.py:65 2019-01-16 19:59:18.800753: step 1848, loss = 0.68539 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:59:19.695652 ops/training.py:65 2019-01-16 19:59:19.695571: step 1849, loss = 0.69675 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:59:20.592100 ops/training.py:65 2019-01-16 19:59:20.592033: step 1850, loss = 0.71353 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:59:21.487726 ops/training.py:65 2019-01-16 19:59:21.487664: step 1851, loss = 0.69189 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:59:22.382960 ops/training.py:65 2019-01-16 19:59:22.382897: step 1852, loss = 0.66452 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:59:23.278421 ops/training.py:65 2019-01-16 19:59:23.278350: step 1853, loss = 0.70467 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:59:24.173452 ops/training.py:65 2019-01-16 19:59:24.173389: step 1854, loss = 0.66952 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 19:59:25.069264 ops/training.py:65 2019-01-16 19:59:25.069194: step 1855, loss = 0.69056 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:59:25.963373 ops/training.py:65 2019-01-16 19:59:25.963314: step 1856, loss = 0.67931 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:59:26.858749 ops/training.py:65 2019-01-16 19:59:26.858688: step 1857, loss = 0.68905 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:59:27.753609 ops/training.py:65 2019-01-16 19:59:27.753546: step 1858, loss = 0.68055 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:59:28.647643 ops/training.py:65 2019-01-16 19:59:28.647579: step 1859, loss = 0.69310 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:59:29.541883 ops/training.py:65 2019-01-16 19:59:29.541820: step 1860, loss = 0.68472 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:59:30.435265 ops/training.py:65 2019-01-16 19:59:30.435206: step 1861, loss = 0.70172 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:59:31.330076 ops/training.py:65 2019-01-16 19:59:31.330003: step 1862, loss = 0.69770 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:59:32.223419 ops/training.py:65 2019-01-16 19:59:32.223359: step 1863, loss = 0.69594 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:59:33.119264 ops/training.py:65 2019-01-16 19:59:33.119188: step 1864, loss = 0.70394 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:59:34.014389 ops/training.py:65 2019-01-16 19:59:34.014284: step 1865, loss = 0.68978 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:59:34.911732 ops/training.py:65 2019-01-16 19:59:34.911641: step 1866, loss = 0.70484 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:59:35.807780 ops/training.py:65 2019-01-16 19:59:35.807716: step 1867, loss = 0.68825 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:59:36.703307 ops/training.py:65 2019-01-16 19:59:36.703236: step 1868, loss = 0.66967 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:59:37.597805 ops/training.py:65 2019-01-16 19:59:37.597705: step 1869, loss = 0.69811 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:59:38.493139 ops/training.py:65 2019-01-16 19:59:38.493074: step 1870, loss = 0.69403 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:59:39.387837 ops/training.py:65 2019-01-16 19:59:39.387771: step 1871, loss = 0.69651 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:59:40.282456 ops/training.py:65 2019-01-16 19:59:40.282378: step 1872, loss = 0.70063 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:59:41.178351 ops/training.py:65 2019-01-16 19:59:41.178289: step 1873, loss = 0.69087 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:59:42.073763 ops/training.py:65 2019-01-16 19:59:42.073667: step 1874, loss = 0.71714 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:59:42.971885 ops/training.py:65 2019-01-16 19:59:42.971773: step 1875, loss = 0.70799 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 19:59:43.867206 ops/training.py:65 2019-01-16 19:59:43.867098: step 1876, loss = 0.70645 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:59:44.761874 ops/training.py:65 2019-01-16 19:59:44.761775: step 1877, loss = 0.69242 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:59:45.656538 ops/training.py:65 2019-01-16 19:59:45.656427: step 1878, loss = 0.67379 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:59:46.551150 ops/training.py:65 2019-01-16 19:59:46.551042: step 1879, loss = 0.70802 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 19:59:47.447431 ops/training.py:65 2019-01-16 19:59:47.447326: step 1880, loss = 0.69422 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:59:48.342981 ops/training.py:65 2019-01-16 19:59:48.342868: step 1881, loss = 0.70195 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:59:49.239003 ops/training.py:65 2019-01-16 19:59:49.238897: step 1882, loss = 0.67942 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:59:50.134752 ops/training.py:65 2019-01-16 19:59:50.134663: step 1883, loss = 0.69008 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 19:59:51.031604 ops/training.py:65 2019-01-16 19:59:51.031502: step 1884, loss = 0.69571 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 19:59:51.928871 ops/training.py:65 2019-01-16 19:59:51.928769: step 1885, loss = 0.69682 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:59:52.826588 ops/training.py:65 2019-01-16 19:59:52.826496: step 1886, loss = 0.68775 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:59:53.722599 ops/training.py:65 2019-01-16 19:59:53.722499: step 1887, loss = 0.67736 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 19:59:54.621209 ops/training.py:65 2019-01-16 19:59:54.621104: step 1888, loss = 0.69426 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:59:55.519474 ops/training.py:65 2019-01-16 19:59:55.519370: step 1889, loss = 0.67626 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 19:59:56.415691 ops/training.py:65 2019-01-16 19:59:56.415627: step 1890, loss = 0.70118 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 19:59:57.311022 ops/training.py:65 2019-01-16 19:59:57.310954: step 1891, loss = 0.69564 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 19:59:58.207959 ops/training.py:65 2019-01-16 19:59:58.207893: step 1892, loss = 0.69772 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 19:59:59.103713 ops/training.py:65 2019-01-16 19:59:59.103643: step 1893, loss = 0.68424 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 19:59:59.997535 ops/training.py:65 2019-01-16 19:59:59.997467: step 1894, loss = 0.68891 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:00:00.891516 ops/training.py:65 2019-01-16 20:00:00.891454: step 1895, loss = 0.67719 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:00:01.784383 ops/training.py:65 2019-01-16 20:00:01.784316: step 1896, loss = 0.67981 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:00:02.678133 ops/training.py:65 2019-01-16 20:00:02.678078: step 1897, loss = 0.71288 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:00:03.573399 ops/training.py:65 2019-01-16 20:00:03.573322: step 1898, loss = 0.69592 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:00:04.468283 ops/training.py:65 2019-01-16 20:00:04.468217: step 1899, loss = 0.71082 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:00:05.363382 ops/training.py:65 2019-01-16 20:00:05.363315: step 1900, loss = 0.69759 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:00:06.258106 ops/training.py:65 2019-01-16 20:00:06.258032: step 1901, loss = 0.69701 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:00:07.153711 ops/training.py:65 2019-01-16 20:00:07.153610: step 1902, loss = 0.68250 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:00:08.049751 ops/training.py:65 2019-01-16 20:00:08.049676: step 1903, loss = 0.69091 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:00:08.944356 ops/training.py:65 2019-01-16 20:00:08.944292: step 1904, loss = 0.68865 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:00:09.837797 ops/training.py:65 2019-01-16 20:00:09.837731: step 1905, loss = 0.71090 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:00:10.732830 ops/training.py:65 2019-01-16 20:00:10.732769: step 1906, loss = 0.70115 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:00:11.627719 ops/training.py:65 2019-01-16 20:00:11.627651: step 1907, loss = 0.70536 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:00:12.524760 ops/training.py:65 2019-01-16 20:00:12.524672: step 1908, loss = 0.69491 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:00:13.419702 ops/training.py:65 2019-01-16 20:00:13.419618: step 1909, loss = 0.68106 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:00:14.315728 ops/training.py:65 2019-01-16 20:00:14.315672: step 1910, loss = 0.68907 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:00:15.210147 ops/training.py:65 2019-01-16 20:00:15.210088: step 1911, loss = 0.69992 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:00:16.106347 ops/training.py:65 2019-01-16 20:00:16.106278: step 1912, loss = 0.69616 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:00:17.001893 ops/training.py:65 2019-01-16 20:00:17.001839: step 1913, loss = 0.68790 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:00:17.898031 ops/training.py:65 2019-01-16 20:00:17.897974: step 1914, loss = 0.69204 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:00:18.791691 ops/training.py:65 2019-01-16 20:00:18.791630: step 1915, loss = 0.70771 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:00:19.685451 ops/training.py:65 2019-01-16 20:00:19.685402: step 1916, loss = 0.68964 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:00:20.579775 ops/training.py:65 2019-01-16 20:00:20.579713: step 1917, loss = 0.70384 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:00:21.473929 ops/training.py:65 2019-01-16 20:00:21.473862: step 1918, loss = 0.68271 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:00:22.370776 ops/training.py:65 2019-01-16 20:00:22.370702: step 1919, loss = 0.69091 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:00:23.266457 ops/training.py:65 2019-01-16 20:00:23.266376: step 1920, loss = 0.69606 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:00:24.160948 ops/training.py:65 2019-01-16 20:00:24.160881: step 1921, loss = 0.68912 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:00:25.055160 ops/training.py:65 2019-01-16 20:00:25.055103: step 1922, loss = 0.68374 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:00:25.948875 ops/training.py:65 2019-01-16 20:00:25.948809: step 1923, loss = 0.68958 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:00:26.844890 ops/training.py:65 2019-01-16 20:00:26.844821: step 1924, loss = 0.69839 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:00:27.739662 ops/training.py:65 2019-01-16 20:00:27.739588: step 1925, loss = 0.69028 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:00:28.634128 ops/training.py:65 2019-01-16 20:00:28.634063: step 1926, loss = 0.68993 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:00:29.528239 ops/training.py:65 2019-01-16 20:00:29.528171: step 1927, loss = 0.69746 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:00:30.424337 ops/training.py:65 2019-01-16 20:00:30.424268: step 1928, loss = 0.70848 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:00:31.318749 ops/training.py:65 2019-01-16 20:00:31.318679: step 1929, loss = 0.69176 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:00:32.213742 ops/training.py:65 2019-01-16 20:00:32.213684: step 1930, loss = 0.70226 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:00:33.107695 ops/training.py:65 2019-01-16 20:00:33.107639: step 1931, loss = 0.69293 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:00:34.000763 ops/training.py:65 2019-01-16 20:00:34.000698: step 1932, loss = 0.70594 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:00:34.894038 ops/training.py:65 2019-01-16 20:00:34.893980: step 1933, loss = 0.69419 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:00:35.787230 ops/training.py:65 2019-01-16 20:00:35.787165: step 1934, loss = 0.68594 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:00:36.680209 ops/training.py:65 2019-01-16 20:00:36.680127: step 1935, loss = 0.70362 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:00:37.572866 ops/training.py:65 2019-01-16 20:00:37.572801: step 1936, loss = 0.70462 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:00:38.467138 ops/training.py:65 2019-01-16 20:00:38.467080: step 1937, loss = 0.70551 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:00:39.360608 ops/training.py:65 2019-01-16 20:00:39.360559: step 1938, loss = 0.70675 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:00:40.255523 ops/training.py:65 2019-01-16 20:00:40.255458: step 1939, loss = 0.69323 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:00:41.149321 ops/training.py:65 2019-01-16 20:00:41.149254: step 1940, loss = 0.69728 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:00:42.041870 ops/training.py:65 2019-01-16 20:00:42.041810: step 1941, loss = 0.69102 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:00:42.935715 ops/training.py:65 2019-01-16 20:00:42.935653: step 1942, loss = 0.69020 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:00:43.829191 ops/training.py:65 2019-01-16 20:00:43.829108: step 1943, loss = 0.68864 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:00:44.722029 ops/training.py:65 2019-01-16 20:00:44.721965: step 1944, loss = 0.69306 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:00:45.617774 ops/training.py:65 2019-01-16 20:00:45.617721: step 1945, loss = 0.69211 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:00:46.515562 ops/training.py:65 2019-01-16 20:00:46.515494: step 1946, loss = 0.69051 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:00:47.411608 ops/training.py:65 2019-01-16 20:00:47.411536: step 1947, loss = 0.68933 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:00:48.306496 ops/training.py:65 2019-01-16 20:00:48.306431: step 1948, loss = 0.70711 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 20:00:49.200866 ops/training.py:65 2019-01-16 20:00:49.200801: step 1949, loss = 0.68488 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:00:50.095284 ops/training.py:65 2019-01-16 20:00:50.095222: step 1950, loss = 0.69564 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:00:50.989152 ops/training.py:65 2019-01-16 20:00:50.989087: step 1951, loss = 0.69588 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:00:51.883427 ops/training.py:65 2019-01-16 20:00:51.883357: step 1952, loss = 0.70051 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:00:52.778932 ops/training.py:65 2019-01-16 20:00:52.778878: step 1953, loss = 0.69162 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:00:53.674904 ops/training.py:65 2019-01-16 20:00:53.674838: step 1954, loss = 0.69841 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:00:54.571250 ops/training.py:65 2019-01-16 20:00:54.571181: step 1955, loss = 0.68967 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:00:55.467550 ops/training.py:65 2019-01-16 20:00:55.467444: step 1956, loss = 0.69843 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:00:56.365073 ops/training.py:65 2019-01-16 20:00:56.364972: step 1957, loss = 0.69511 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:00:57.262948 ops/training.py:65 2019-01-16 20:00:57.262885: step 1958, loss = 0.69135 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:00:58.158858 ops/training.py:65 2019-01-16 20:00:58.158791: step 1959, loss = 0.68561 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:00:59.054414 ops/training.py:65 2019-01-16 20:00:59.054347: step 1960, loss = 0.70439 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:00:59.949002 ops/training.py:65 2019-01-16 20:00:59.948941: step 1961, loss = 0.69159 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:01:00.844827 ops/training.py:65 2019-01-16 20:01:00.844765: step 1962, loss = 0.68466 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:01:01.738997 ops/training.py:65 2019-01-16 20:01:01.738931: step 1963, loss = 0.70027 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:01:02.633039 ops/training.py:65 2019-01-16 20:01:02.632977: step 1964, loss = 0.70127 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:01:03.527926 ops/training.py:65 2019-01-16 20:01:03.527882: step 1965, loss = 0.70330 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:01:04.425659 ops/training.py:65 2019-01-16 20:01:04.425624: step 1966, loss = 0.67835 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:01:05.320196 ops/training.py:65 2019-01-16 20:01:05.320143: step 1967, loss = 0.68600 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:01:06.214946 ops/training.py:65 2019-01-16 20:01:06.214871: step 1968, loss = 0.69780 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:01:07.110465 ops/training.py:65 2019-01-16 20:01:07.110402: step 1969, loss = 0.69246 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:01:08.004931 ops/training.py:65 2019-01-16 20:01:08.004869: step 1970, loss = 0.69040 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:01:08.897944 ops/training.py:65 2019-01-16 20:01:08.897888: step 1971, loss = 0.69796 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:01:09.791701 ops/training.py:65 2019-01-16 20:01:09.791640: step 1972, loss = 0.68780 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:01:10.684595 ops/training.py:65 2019-01-16 20:01:10.684557: step 1973, loss = 0.69998 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 20:01:11.578874 ops/training.py:65 2019-01-16 20:01:11.578802: step 1974, loss = 0.69244 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:01:12.474383 ops/training.py:65 2019-01-16 20:01:12.474291: step 1975, loss = 0.69576 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:01:13.369446 ops/training.py:65 2019-01-16 20:01:13.369385: step 1976, loss = 0.69068 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:01:14.264650 ops/training.py:65 2019-01-16 20:01:14.264583: step 1977, loss = 0.70345 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:01:15.162432 ops/training.py:65 2019-01-16 20:01:15.162325: step 1978, loss = 0.69062 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:01:16.060015 ops/training.py:65 2019-01-16 20:01:16.059903: step 1979, loss = 0.70091 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:01:16.955430 ops/training.py:65 2019-01-16 20:01:16.955371: step 1980, loss = 0.69685 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:01:17.850103 ops/training.py:65 2019-01-16 20:01:17.850049: step 1981, loss = 0.69347 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:01:18.743495 ops/training.py:65 2019-01-16 20:01:18.743434: step 1982, loss = 0.69738 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:01:19.637885 ops/training.py:65 2019-01-16 20:01:19.637819: step 1983, loss = 0.69209 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:01:20.533544 ops/training.py:65 2019-01-16 20:01:20.533448: step 1984, loss = 0.69928 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:01:21.429383 ops/training.py:65 2019-01-16 20:01:21.429349: step 1985, loss = 0.69085 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:01:22.324514 ops/training.py:65 2019-01-16 20:01:22.324483: step 1986, loss = 0.68842 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:01:23.219223 ops/training.py:65 2019-01-16 20:01:23.219193: step 1987, loss = 0.69395 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:01:24.114307 ops/training.py:65 2019-01-16 20:01:24.114274: step 1988, loss = 0.70209 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:01:25.008419 ops/training.py:65 2019-01-16 20:01:25.008351: step 1989, loss = 0.69448 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:01:25.902938 ops/training.py:65 2019-01-16 20:01:25.902860: step 1990, loss = 0.69336 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:01:26.799262 ops/training.py:65 2019-01-16 20:01:26.799199: step 1991, loss = 0.68721 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:01:27.694875 ops/training.py:65 2019-01-16 20:01:27.694815: step 1992, loss = 0.69035 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:01:28.589634 ops/training.py:65 2019-01-16 20:01:28.589572: step 1993, loss = 0.70575 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:01:29.485314 ops/training.py:65 2019-01-16 20:01:29.485282: step 1994, loss = 0.69897 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:01:30.380866 ops/training.py:65 2019-01-16 20:01:30.380834: step 1995, loss = 0.69043 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:01:31.275720 ops/training.py:65 2019-01-16 20:01:31.275682: step 1996, loss = 0.69130 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:01:32.171235 ops/training.py:65 2019-01-16 20:01:32.171204: step 1997, loss = 0.69426 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:01:33.066528 ops/training.py:65 2019-01-16 20:01:33.066485: step 1998, loss = 0.69016 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:01:33.963130 ops/training.py:65 2019-01-16 20:01:33.963081: step 1999, loss = 0.69344 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:05:49.056732 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I1280 2019-01-16 20:05:49.057729 ops/training.py:41 2019-01-16 20:05:49.057672: step 2000, loss = 0.69 (0.1 examples/sec; 254.199 sec/batch) | Training accuracy = 0.625 | Validation accuracy = 0.4885 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_19_26_22_049623
I1280 2019-01-16 20:05:49.952983 ops/training.py:65 2019-01-16 20:05:49.952934: step 2001, loss = 0.69535 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:05:50.846050 ops/training.py:65 2019-01-16 20:05:50.845995: step 2002, loss = 0.69203 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:05:51.739201 ops/training.py:65 2019-01-16 20:05:51.739145: step 2003, loss = 0.69788 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:05:52.631512 ops/training.py:65 2019-01-16 20:05:52.631458: step 2004, loss = 0.69681 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:05:53.523689 ops/training.py:65 2019-01-16 20:05:53.523632: step 2005, loss = 0.69252 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:05:54.418227 ops/training.py:65 2019-01-16 20:05:54.418192: step 2006, loss = 0.69492 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:05:55.314097 ops/training.py:65 2019-01-16 20:05:55.314010: step 2007, loss = 0.70078 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:05:56.209138 ops/training.py:65 2019-01-16 20:05:56.209070: step 2008, loss = 0.69060 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:05:57.105756 ops/training.py:65 2019-01-16 20:05:57.105694: step 2009, loss = 0.70020 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:05:58.001753 ops/training.py:65 2019-01-16 20:05:58.001710: step 2010, loss = 0.68458 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:05:58.896796 ops/training.py:65 2019-01-16 20:05:58.896761: step 2011, loss = 0.69006 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:05:59.792105 ops/training.py:65 2019-01-16 20:05:59.792021: step 2012, loss = 0.69661 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:06:00.688433 ops/training.py:65 2019-01-16 20:06:00.688334: step 2013, loss = 0.70039 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:06:01.584797 ops/training.py:65 2019-01-16 20:06:01.584725: step 2014, loss = 0.69080 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:06:02.481482 ops/training.py:65 2019-01-16 20:06:02.481387: step 2015, loss = 0.69599 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:06:03.377206 ops/training.py:65 2019-01-16 20:06:03.377135: step 2016, loss = 0.69651 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:06:04.272890 ops/training.py:65 2019-01-16 20:06:04.272791: step 2017, loss = 0.69319 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:06:05.168089 ops/training.py:65 2019-01-16 20:06:05.168028: step 2018, loss = 0.69629 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:06:06.061753 ops/training.py:65 2019-01-16 20:06:06.061688: step 2019, loss = 0.69616 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:06:06.956064 ops/training.py:65 2019-01-16 20:06:06.955987: step 2020, loss = 0.69411 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:06:07.852527 ops/training.py:65 2019-01-16 20:06:07.852485: step 2021, loss = 0.70559 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.25
I1280 2019-01-16 20:06:08.748567 ops/training.py:65 2019-01-16 20:06:08.748518: step 2022, loss = 0.69257 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:06:09.645191 ops/training.py:65 2019-01-16 20:06:09.645156: step 2023, loss = 0.69474 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:06:10.539314 ops/training.py:65 2019-01-16 20:06:10.539283: step 2024, loss = 0.69019 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:06:11.433038 ops/training.py:65 2019-01-16 20:06:11.433007: step 2025, loss = 0.69173 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:06:12.326759 ops/training.py:65 2019-01-16 20:06:12.326708: step 2026, loss = 0.69139 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:06:13.220877 ops/training.py:65 2019-01-16 20:06:13.220820: step 2027, loss = 0.69098 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:06:14.115991 ops/training.py:65 2019-01-16 20:06:14.115928: step 2028, loss = 0.69003 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:06:15.009835 ops/training.py:65 2019-01-16 20:06:15.009773: step 2029, loss = 0.69476 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:06:15.906306 ops/training.py:65 2019-01-16 20:06:15.906253: step 2030, loss = 0.69687 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:06:16.802716 ops/training.py:65 2019-01-16 20:06:16.802656: step 2031, loss = 0.70089 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:06:17.697618 ops/training.py:65 2019-01-16 20:06:17.697559: step 2032, loss = 0.69315 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:06:18.595216 ops/training.py:65 2019-01-16 20:06:18.595184: step 2033, loss = 0.70266 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:06:19.490677 ops/training.py:65 2019-01-16 20:06:19.490629: step 2034, loss = 0.68883 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:06:20.387125 ops/training.py:65 2019-01-16 20:06:20.387089: step 2035, loss = 0.69209 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:06:21.283195 ops/training.py:65 2019-01-16 20:06:21.283138: step 2036, loss = 0.68713 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:06:22.181262 ops/training.py:65 2019-01-16 20:06:22.181228: step 2037, loss = 0.70314 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:06:23.076695 ops/training.py:65 2019-01-16 20:06:23.076664: step 2038, loss = 0.69170 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:06:23.972278 ops/training.py:65 2019-01-16 20:06:23.972247: step 2039, loss = 0.69528 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:06:24.867923 ops/training.py:65 2019-01-16 20:06:24.867892: step 2040, loss = 0.68899 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:06:25.763684 ops/training.py:65 2019-01-16 20:06:25.763653: step 2041, loss = 0.69240 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:06:26.660698 ops/training.py:65 2019-01-16 20:06:26.660600: step 2042, loss = 0.68872 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:06:27.557982 ops/training.py:65 2019-01-16 20:06:27.557908: step 2043, loss = 0.69026 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:06:28.453102 ops/training.py:65 2019-01-16 20:06:28.453033: step 2044, loss = 0.70183 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:06:29.347524 ops/training.py:65 2019-01-16 20:06:29.347461: step 2045, loss = 0.69457 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:06:30.242128 ops/training.py:65 2019-01-16 20:06:30.242065: step 2046, loss = 0.69735 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:06:31.136262 ops/training.py:65 2019-01-16 20:06:31.136199: step 2047, loss = 0.68785 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:06:32.031652 ops/training.py:65 2019-01-16 20:06:32.031590: step 2048, loss = 0.69549 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:06:32.926382 ops/training.py:65 2019-01-16 20:06:32.926331: step 2049, loss = 0.69137 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:06:33.820773 ops/training.py:65 2019-01-16 20:06:33.820706: step 2050, loss = 0.69880 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:06:34.716913 ops/training.py:65 2019-01-16 20:06:34.716835: step 2051, loss = 0.69365 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:06:35.614627 ops/training.py:65 2019-01-16 20:06:35.614521: step 2052, loss = 0.70519 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:06:36.511205 ops/training.py:65 2019-01-16 20:06:36.511122: step 2053, loss = 0.69307 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:06:37.406699 ops/training.py:65 2019-01-16 20:06:37.406632: step 2054, loss = 0.69149 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:06:38.303693 ops/training.py:65 2019-01-16 20:06:38.303640: step 2055, loss = 0.69344 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:06:39.200646 ops/training.py:65 2019-01-16 20:06:39.200582: step 2056, loss = 0.69409 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:06:40.095120 ops/training.py:65 2019-01-16 20:06:40.095051: step 2057, loss = 0.69646 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:06:40.989289 ops/training.py:65 2019-01-16 20:06:40.989228: step 2058, loss = 0.69761 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:06:41.881358 ops/training.py:65 2019-01-16 20:06:41.881305: step 2059, loss = 0.69480 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:06:42.774429 ops/training.py:65 2019-01-16 20:06:42.774371: step 2060, loss = 0.69281 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:06:43.668624 ops/training.py:65 2019-01-16 20:06:43.668556: step 2061, loss = 0.69023 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:06:44.561876 ops/training.py:65 2019-01-16 20:06:44.561818: step 2062, loss = 0.68744 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:06:45.454199 ops/training.py:65 2019-01-16 20:06:45.454141: step 2063, loss = 0.68842 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:06:46.349065 ops/training.py:65 2019-01-16 20:06:46.349016: step 2064, loss = 0.69589 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:06:47.244000 ops/training.py:65 2019-01-16 20:06:47.243938: step 2065, loss = 0.69305 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:06:48.138844 ops/training.py:65 2019-01-16 20:06:48.138805: step 2066, loss = 0.68912 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:06:49.034225 ops/training.py:65 2019-01-16 20:06:49.034188: step 2067, loss = 0.70206 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:06:49.926388 ops/training.py:65 2019-01-16 20:06:49.926351: step 2068, loss = 0.70098 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:06:50.821927 ops/training.py:65 2019-01-16 20:06:50.821897: step 2069, loss = 0.69641 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:06:51.718012 ops/training.py:65 2019-01-16 20:06:51.717982: step 2070, loss = 0.69505 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:06:52.613525 ops/training.py:65 2019-01-16 20:06:52.613479: step 2071, loss = 0.69210 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:06:53.507294 ops/training.py:65 2019-01-16 20:06:53.507242: step 2072, loss = 0.69234 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:06:54.402163 ops/training.py:65 2019-01-16 20:06:54.402076: step 2073, loss = 0.69108 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:06:55.297110 ops/training.py:65 2019-01-16 20:06:55.297054: step 2074, loss = 0.69684 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:06:56.193126 ops/training.py:65 2019-01-16 20:06:56.193093: step 2075, loss = 0.68236 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:06:57.088006 ops/training.py:65 2019-01-16 20:06:57.087973: step 2076, loss = 0.69337 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:06:57.981752 ops/training.py:65 2019-01-16 20:06:57.981719: step 2077, loss = 0.68625 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:06:58.875993 ops/training.py:65 2019-01-16 20:06:58.875920: step 2078, loss = 0.68573 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:06:59.772094 ops/training.py:65 2019-01-16 20:06:59.772044: step 2079, loss = 0.69431 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:07:00.668788 ops/training.py:65 2019-01-16 20:07:00.668756: step 2080, loss = 0.69415 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:07:01.564853 ops/training.py:65 2019-01-16 20:07:01.564764: step 2081, loss = 0.69177 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:07:02.460109 ops/training.py:65 2019-01-16 20:07:02.460028: step 2082, loss = 0.69020 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:07:03.355065 ops/training.py:65 2019-01-16 20:07:03.354986: step 2083, loss = 0.69009 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:07:04.250237 ops/training.py:65 2019-01-16 20:07:04.250130: step 2084, loss = 0.68939 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:07:05.145348 ops/training.py:65 2019-01-16 20:07:05.145269: step 2085, loss = 0.68697 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:07:06.039018 ops/training.py:65 2019-01-16 20:07:06.038932: step 2086, loss = 0.69386 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:07:06.933717 ops/training.py:65 2019-01-16 20:07:06.933642: step 2087, loss = 0.68979 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:07:07.829375 ops/training.py:65 2019-01-16 20:07:07.829275: step 2088, loss = 0.69821 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:07:08.722479 ops/training.py:65 2019-01-16 20:07:08.722419: step 2089, loss = 0.69551 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:07:09.617352 ops/training.py:65 2019-01-16 20:07:09.617302: step 2090, loss = 0.68868 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:07:10.513584 ops/training.py:65 2019-01-16 20:07:10.513536: step 2091, loss = 0.69372 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:07:11.408550 ops/training.py:65 2019-01-16 20:07:11.408467: step 2092, loss = 0.69794 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:07:12.302929 ops/training.py:65 2019-01-16 20:07:12.302887: step 2093, loss = 0.69632 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:07:13.199164 ops/training.py:65 2019-01-16 20:07:13.199100: step 2094, loss = 0.69499 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:07:14.094422 ops/training.py:65 2019-01-16 20:07:14.094372: step 2095, loss = 0.69791 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:07:14.989539 ops/training.py:65 2019-01-16 20:07:14.989504: step 2096, loss = 0.69198 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:07:15.883839 ops/training.py:65 2019-01-16 20:07:15.883809: step 2097, loss = 0.69318 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:07:16.777118 ops/training.py:65 2019-01-16 20:07:16.777087: step 2098, loss = 0.68981 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:07:17.673151 ops/training.py:65 2019-01-16 20:07:17.673119: step 2099, loss = 0.69094 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:07:18.567328 ops/training.py:65 2019-01-16 20:07:18.567297: step 2100, loss = 0.69221 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:07:19.461895 ops/training.py:65 2019-01-16 20:07:19.461863: step 2101, loss = 0.69066 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:07:20.356553 ops/training.py:65 2019-01-16 20:07:20.356523: step 2102, loss = 0.69475 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:07:21.252479 ops/training.py:65 2019-01-16 20:07:21.252450: step 2103, loss = 0.69449 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:07:22.148030 ops/training.py:65 2019-01-16 20:07:22.147935: step 2104, loss = 0.69550 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:07:23.043828 ops/training.py:65 2019-01-16 20:07:23.043793: step 2105, loss = 0.68943 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:07:23.939867 ops/training.py:65 2019-01-16 20:07:23.939836: step 2106, loss = 0.69638 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:07:24.835166 ops/training.py:65 2019-01-16 20:07:24.835135: step 2107, loss = 0.69435 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:07:25.730320 ops/training.py:65 2019-01-16 20:07:25.730287: step 2108, loss = 0.69554 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:07:26.625166 ops/training.py:65 2019-01-16 20:07:26.625136: step 2109, loss = 0.69199 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:07:27.520102 ops/training.py:65 2019-01-16 20:07:27.520070: step 2110, loss = 0.69891 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:07:28.417261 ops/training.py:65 2019-01-16 20:07:28.417231: step 2111, loss = 0.69926 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:07:29.312363 ops/training.py:65 2019-01-16 20:07:29.312333: step 2112, loss = 0.69180 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:07:30.207795 ops/training.py:65 2019-01-16 20:07:30.207765: step 2113, loss = 0.69499 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:07:31.103689 ops/training.py:65 2019-01-16 20:07:31.103657: step 2114, loss = 0.69658 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:07:31.999925 ops/training.py:65 2019-01-16 20:07:31.999894: step 2115, loss = 0.69695 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:07:32.895479 ops/training.py:65 2019-01-16 20:07:32.895449: step 2116, loss = 0.69306 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:07:33.793199 ops/training.py:65 2019-01-16 20:07:33.793170: step 2117, loss = 0.69126 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:07:34.688275 ops/training.py:65 2019-01-16 20:07:34.688245: step 2118, loss = 0.68936 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:07:35.585064 ops/training.py:65 2019-01-16 20:07:35.585036: step 2119, loss = 0.69762 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:07:36.480500 ops/training.py:65 2019-01-16 20:07:36.480451: step 2120, loss = 0.69267 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:07:37.374886 ops/training.py:65 2019-01-16 20:07:37.374856: step 2121, loss = 0.69766 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:07:38.269932 ops/training.py:65 2019-01-16 20:07:38.269880: step 2122, loss = 0.68873 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:07:39.164840 ops/training.py:65 2019-01-16 20:07:39.164804: step 2123, loss = 0.69382 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:07:40.060193 ops/training.py:65 2019-01-16 20:07:40.060162: step 2124, loss = 0.69387 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:07:40.957028 ops/training.py:65 2019-01-16 20:07:40.956998: step 2125, loss = 0.69779 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:07:41.852853 ops/training.py:65 2019-01-16 20:07:41.852820: step 2126, loss = 0.69506 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:07:42.748460 ops/training.py:65 2019-01-16 20:07:42.748430: step 2127, loss = 0.69138 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:07:43.643344 ops/training.py:65 2019-01-16 20:07:43.643315: step 2128, loss = 0.69131 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:07:44.539963 ops/training.py:65 2019-01-16 20:07:44.539933: step 2129, loss = 0.69620 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:07:45.436635 ops/training.py:65 2019-01-16 20:07:45.436605: step 2130, loss = 0.69438 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:07:46.332636 ops/training.py:65 2019-01-16 20:07:46.332605: step 2131, loss = 0.69042 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:07:47.229025 ops/training.py:65 2019-01-16 20:07:47.228986: step 2132, loss = 0.69295 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:07:48.125082 ops/training.py:65 2019-01-16 20:07:48.125051: step 2133, loss = 0.69150 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:07:49.021127 ops/training.py:65 2019-01-16 20:07:49.021096: step 2134, loss = 0.69050 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:07:49.921348 ops/training.py:65 2019-01-16 20:07:49.921316: step 2135, loss = 0.69551 (35.6 examples/sec; 0.899 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:07:50.815827 ops/training.py:65 2019-01-16 20:07:50.815798: step 2136, loss = 0.68653 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:07:51.711185 ops/training.py:65 2019-01-16 20:07:51.711150: step 2137, loss = 0.69383 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:07:52.606318 ops/training.py:65 2019-01-16 20:07:52.606225: step 2138, loss = 0.69604 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:07:53.500665 ops/training.py:65 2019-01-16 20:07:53.500606: step 2139, loss = 0.70351 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:07:54.395673 ops/training.py:65 2019-01-16 20:07:54.395629: step 2140, loss = 0.69398 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:07:55.290970 ops/training.py:65 2019-01-16 20:07:55.290939: step 2141, loss = 0.68688 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:07:56.187208 ops/training.py:65 2019-01-16 20:07:56.187177: step 2142, loss = 0.70474 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:07:57.082734 ops/training.py:65 2019-01-16 20:07:57.082683: step 2143, loss = 0.70604 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:07:57.976088 ops/training.py:65 2019-01-16 20:07:57.976025: step 2144, loss = 0.68839 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:07:58.871825 ops/training.py:65 2019-01-16 20:07:58.871793: step 2145, loss = 0.69922 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:07:59.768034 ops/training.py:65 2019-01-16 20:07:59.767997: step 2146, loss = 0.69247 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:08:00.664551 ops/training.py:65 2019-01-16 20:08:00.664509: step 2147, loss = 0.70100 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:08:01.558720 ops/training.py:65 2019-01-16 20:08:01.558656: step 2148, loss = 0.69124 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:08:02.455471 ops/training.py:65 2019-01-16 20:08:02.455431: step 2149, loss = 0.68758 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:08:03.350962 ops/training.py:65 2019-01-16 20:08:03.350926: step 2150, loss = 0.69611 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:08:04.246494 ops/training.py:65 2019-01-16 20:08:04.246460: step 2151, loss = 0.69432 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:08:05.140581 ops/training.py:65 2019-01-16 20:08:05.140516: step 2152, loss = 0.69057 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:08:06.033863 ops/training.py:65 2019-01-16 20:08:06.033803: step 2153, loss = 0.69074 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:08:06.927028 ops/training.py:65 2019-01-16 20:08:06.926939: step 2154, loss = 0.68650 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:08:07.820148 ops/training.py:65 2019-01-16 20:08:07.820089: step 2155, loss = 0.69240 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:08:08.712533 ops/training.py:65 2019-01-16 20:08:08.712471: step 2156, loss = 0.69037 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:08:09.605554 ops/training.py:65 2019-01-16 20:08:09.605496: step 2157, loss = 0.69173 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:08:10.498623 ops/training.py:65 2019-01-16 20:08:10.498566: step 2158, loss = 0.69241 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:08:11.390941 ops/training.py:65 2019-01-16 20:08:11.390887: step 2159, loss = 0.69185 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:08:12.283659 ops/training.py:65 2019-01-16 20:08:12.283590: step 2160, loss = 0.69705 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:08:13.176891 ops/training.py:65 2019-01-16 20:08:13.176835: step 2161, loss = 0.70301 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:08:14.071999 ops/training.py:65 2019-01-16 20:08:14.071966: step 2162, loss = 0.69943 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:08:14.966101 ops/training.py:65 2019-01-16 20:08:14.966034: step 2163, loss = 0.69097 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:08:15.860300 ops/training.py:65 2019-01-16 20:08:15.860236: step 2164, loss = 0.69054 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:08:16.753925 ops/training.py:65 2019-01-16 20:08:16.753862: step 2165, loss = 0.70102 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:08:17.647866 ops/training.py:65 2019-01-16 20:08:17.647811: step 2166, loss = 0.68541 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:08:18.541217 ops/training.py:65 2019-01-16 20:08:18.541161: step 2167, loss = 0.69384 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:08:19.435472 ops/training.py:65 2019-01-16 20:08:19.435428: step 2168, loss = 0.68932 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:08:20.333399 ops/training.py:65 2019-01-16 20:08:20.333335: step 2169, loss = 0.69778 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:08:21.228049 ops/training.py:65 2019-01-16 20:08:21.227989: step 2170, loss = 0.69449 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:08:22.122997 ops/training.py:65 2019-01-16 20:08:22.122896: step 2171, loss = 0.68315 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:08:23.021658 ops/training.py:65 2019-01-16 20:08:23.021546: step 2172, loss = 0.68991 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:08:23.918227 ops/training.py:65 2019-01-16 20:08:23.918116: step 2173, loss = 0.69211 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:08:24.814729 ops/training.py:65 2019-01-16 20:08:24.814623: step 2174, loss = 0.69005 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:08:25.710917 ops/training.py:65 2019-01-16 20:08:25.710804: step 2175, loss = 0.70225 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:08:26.607521 ops/training.py:65 2019-01-16 20:08:26.607464: step 2176, loss = 0.70153 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.25
I1280 2019-01-16 20:08:27.505091 ops/training.py:65 2019-01-16 20:08:27.504983: step 2177, loss = 0.68802 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:08:28.401269 ops/training.py:65 2019-01-16 20:08:28.401206: step 2178, loss = 0.69589 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:08:29.296380 ops/training.py:65 2019-01-16 20:08:29.296321: step 2179, loss = 0.69204 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:08:30.194051 ops/training.py:65 2019-01-16 20:08:30.193952: step 2180, loss = 0.68460 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:08:31.090117 ops/training.py:65 2019-01-16 20:08:31.090057: step 2181, loss = 0.69458 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:08:31.984986 ops/training.py:65 2019-01-16 20:08:31.984928: step 2182, loss = 0.68774 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:08:32.880578 ops/training.py:65 2019-01-16 20:08:32.880524: step 2183, loss = 0.68686 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:08:33.778416 ops/training.py:65 2019-01-16 20:08:33.778317: step 2184, loss = 0.69065 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:08:34.674253 ops/training.py:65 2019-01-16 20:08:34.674201: step 2185, loss = 0.68906 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:08:35.572103 ops/training.py:65 2019-01-16 20:08:35.572004: step 2186, loss = 0.68678 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:08:36.468095 ops/training.py:65 2019-01-16 20:08:36.468025: step 2187, loss = 0.68531 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:08:37.361610 ops/training.py:65 2019-01-16 20:08:37.361546: step 2188, loss = 0.69364 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:08:38.256886 ops/training.py:65 2019-01-16 20:08:38.256820: step 2189, loss = 0.69535 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:08:39.153732 ops/training.py:65 2019-01-16 20:08:39.153637: step 2190, loss = 0.68937 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:08:40.050538 ops/training.py:65 2019-01-16 20:08:40.050442: step 2191, loss = 0.69065 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:08:40.946858 ops/training.py:65 2019-01-16 20:08:40.946799: step 2192, loss = 0.68754 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:08:41.841148 ops/training.py:65 2019-01-16 20:08:41.841090: step 2193, loss = 0.69260 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:08:42.737352 ops/training.py:65 2019-01-16 20:08:42.737297: step 2194, loss = 0.69424 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:08:43.632765 ops/training.py:65 2019-01-16 20:08:43.632698: step 2195, loss = 0.70007 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:08:44.527584 ops/training.py:65 2019-01-16 20:08:44.527528: step 2196, loss = 0.69130 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:08:45.422999 ops/training.py:65 2019-01-16 20:08:45.422942: step 2197, loss = 0.69086 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:08:46.318225 ops/training.py:65 2019-01-16 20:08:46.318137: step 2198, loss = 0.68322 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.75
I1280 2019-01-16 20:08:47.214209 ops/training.py:65 2019-01-16 20:08:47.214142: step 2199, loss = 0.68562 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:08:48.110019 ops/training.py:65 2019-01-16 20:08:48.109923: step 2200, loss = 0.69572 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:08:49.006676 ops/training.py:65 2019-01-16 20:08:49.006619: step 2201, loss = 0.68778 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:08:49.900964 ops/training.py:65 2019-01-16 20:08:49.900909: step 2202, loss = 0.69193 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 20:08:50.796419 ops/training.py:65 2019-01-16 20:08:50.796328: step 2203, loss = 0.69803 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:08:51.692436 ops/training.py:65 2019-01-16 20:08:51.692352: step 2204, loss = 0.69411 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:08:52.589545 ops/training.py:65 2019-01-16 20:08:52.589463: step 2205, loss = 0.69903 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:08:53.485561 ops/training.py:65 2019-01-16 20:08:53.485474: step 2206, loss = 0.69585 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:08:54.381819 ops/training.py:65 2019-01-16 20:08:54.381758: step 2207, loss = 0.69423 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:08:55.275438 ops/training.py:65 2019-01-16 20:08:55.275381: step 2208, loss = 0.69926 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:08:56.169405 ops/training.py:65 2019-01-16 20:08:56.169344: step 2209, loss = 0.68927 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:08:57.065450 ops/training.py:65 2019-01-16 20:08:57.065377: step 2210, loss = 0.69746 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:08:57.961061 ops/training.py:65 2019-01-16 20:08:57.960975: step 2211, loss = 0.70423 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:08:58.858323 ops/training.py:65 2019-01-16 20:08:58.858231: step 2212, loss = 0.69801 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:08:59.755343 ops/training.py:65 2019-01-16 20:08:59.755281: step 2213, loss = 0.68872 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:09:00.650051 ops/training.py:65 2019-01-16 20:09:00.649995: step 2214, loss = 0.69313 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:09:01.544361 ops/training.py:65 2019-01-16 20:09:01.544306: step 2215, loss = 0.68971 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:09:02.439095 ops/training.py:65 2019-01-16 20:09:02.439043: step 2216, loss = 0.69671 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:09:03.333925 ops/training.py:65 2019-01-16 20:09:03.333870: step 2217, loss = 0.69126 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:09:04.229508 ops/training.py:65 2019-01-16 20:09:04.229463: step 2218, loss = 0.70276 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:09:05.124225 ops/training.py:65 2019-01-16 20:09:05.124169: step 2219, loss = 0.69489 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:09:06.018922 ops/training.py:65 2019-01-16 20:09:06.018868: step 2220, loss = 0.69675 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:09:06.913902 ops/training.py:65 2019-01-16 20:09:06.913816: step 2221, loss = 0.68343 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:09:07.809440 ops/training.py:65 2019-01-16 20:09:07.809362: step 2222, loss = 0.68819 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:09:08.705446 ops/training.py:65 2019-01-16 20:09:08.705387: step 2223, loss = 0.68903 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:09:09.601054 ops/training.py:65 2019-01-16 20:09:09.600997: step 2224, loss = 0.69670 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:09:10.495548 ops/training.py:65 2019-01-16 20:09:10.495493: step 2225, loss = 0.68739 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:09:11.389422 ops/training.py:65 2019-01-16 20:09:11.389368: step 2226, loss = 0.69339 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:09:12.282919 ops/training.py:65 2019-01-16 20:09:12.282868: step 2227, loss = 0.69775 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:09:13.177539 ops/training.py:65 2019-01-16 20:09:13.177483: step 2228, loss = 0.70115 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:09:14.071283 ops/training.py:65 2019-01-16 20:09:14.071225: step 2229, loss = 0.68780 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:09:14.965480 ops/training.py:65 2019-01-16 20:09:14.965418: step 2230, loss = 0.69992 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:09:15.859686 ops/training.py:65 2019-01-16 20:09:15.859604: step 2231, loss = 0.69784 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:09:16.752670 ops/training.py:65 2019-01-16 20:09:16.752616: step 2232, loss = 0.70356 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:09:17.646557 ops/training.py:65 2019-01-16 20:09:17.646508: step 2233, loss = 0.69162 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:09:18.541502 ops/training.py:65 2019-01-16 20:09:18.541446: step 2234, loss = 0.69530 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:09:19.436695 ops/training.py:65 2019-01-16 20:09:19.436647: step 2235, loss = 0.69436 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:09:20.331055 ops/training.py:65 2019-01-16 20:09:20.331000: step 2236, loss = 0.69273 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:09:21.224775 ops/training.py:65 2019-01-16 20:09:21.224724: step 2237, loss = 0.68699 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:09:22.120585 ops/training.py:65 2019-01-16 20:09:22.120523: step 2238, loss = 0.69171 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:09:23.016308 ops/training.py:65 2019-01-16 20:09:23.016221: step 2239, loss = 0.69499 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:09:23.913837 ops/training.py:65 2019-01-16 20:09:23.913747: step 2240, loss = 0.69441 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:09:24.810249 ops/training.py:65 2019-01-16 20:09:24.810193: step 2241, loss = 0.69688 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:09:25.706106 ops/training.py:65 2019-01-16 20:09:25.706051: step 2242, loss = 0.69283 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:09:26.600813 ops/training.py:65 2019-01-16 20:09:26.600758: step 2243, loss = 0.68666 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:09:27.497318 ops/training.py:65 2019-01-16 20:09:27.497258: step 2244, loss = 0.69648 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:09:28.392252 ops/training.py:65 2019-01-16 20:09:28.392197: step 2245, loss = 0.68938 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:09:29.287222 ops/training.py:65 2019-01-16 20:09:29.287159: step 2246, loss = 0.69466 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:09:30.183214 ops/training.py:65 2019-01-16 20:09:30.183130: step 2247, loss = 0.69046 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:09:31.077938 ops/training.py:65 2019-01-16 20:09:31.077861: step 2248, loss = 0.69423 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:09:31.973036 ops/training.py:65 2019-01-16 20:09:31.972968: step 2249, loss = 0.70698 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:09:32.869398 ops/training.py:65 2019-01-16 20:09:32.869331: step 2250, loss = 0.68904 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:09:33.764814 ops/training.py:65 2019-01-16 20:09:33.764740: step 2251, loss = 0.69742 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:09:34.659219 ops/training.py:65 2019-01-16 20:09:34.659152: step 2252, loss = 0.68879 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:09:35.553399 ops/training.py:65 2019-01-16 20:09:35.553320: step 2253, loss = 0.68701 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:09:36.446958 ops/training.py:65 2019-01-16 20:09:36.446893: step 2254, loss = 0.69251 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:09:37.341435 ops/training.py:65 2019-01-16 20:09:37.341399: step 2255, loss = 0.69182 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:09:38.235927 ops/training.py:65 2019-01-16 20:09:38.235899: step 2256, loss = 0.70059 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:09:39.129808 ops/training.py:65 2019-01-16 20:09:39.129781: step 2257, loss = 0.69586 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:09:40.024508 ops/training.py:65 2019-01-16 20:09:40.024467: step 2258, loss = 0.68797 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:09:40.918397 ops/training.py:65 2019-01-16 20:09:40.918315: step 2259, loss = 0.69107 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:09:41.812774 ops/training.py:65 2019-01-16 20:09:41.812714: step 2260, loss = 0.69803 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:09:42.708453 ops/training.py:65 2019-01-16 20:09:42.708417: step 2261, loss = 0.69170 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:09:43.606563 ops/training.py:65 2019-01-16 20:09:43.606524: step 2262, loss = 0.69293 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:09:44.502538 ops/training.py:65 2019-01-16 20:09:44.502487: step 2263, loss = 0.69401 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:09:45.398688 ops/training.py:65 2019-01-16 20:09:45.398636: step 2264, loss = 0.69401 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:09:46.293985 ops/training.py:65 2019-01-16 20:09:46.293927: step 2265, loss = 0.69143 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:09:47.188459 ops/training.py:65 2019-01-16 20:09:47.188414: step 2266, loss = 0.69479 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:09:48.082861 ops/training.py:65 2019-01-16 20:09:48.082808: step 2267, loss = 0.68855 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:09:48.977179 ops/training.py:65 2019-01-16 20:09:48.977128: step 2268, loss = 0.69104 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:09:49.871367 ops/training.py:65 2019-01-16 20:09:49.871324: step 2269, loss = 0.69742 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:09:50.764969 ops/training.py:65 2019-01-16 20:09:50.764916: step 2270, loss = 0.68901 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:09:51.659123 ops/training.py:65 2019-01-16 20:09:51.659067: step 2271, loss = 0.69401 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:09:52.553796 ops/training.py:65 2019-01-16 20:09:52.553737: step 2272, loss = 0.69272 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:09:53.447718 ops/training.py:65 2019-01-16 20:09:53.447661: step 2273, loss = 0.68424 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:09:54.342741 ops/training.py:65 2019-01-16 20:09:54.342684: step 2274, loss = 0.69045 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:09:55.236368 ops/training.py:65 2019-01-16 20:09:55.236312: step 2275, loss = 0.69489 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:09:56.129966 ops/training.py:65 2019-01-16 20:09:56.129911: step 2276, loss = 0.69041 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:09:57.023047 ops/training.py:65 2019-01-16 20:09:57.022996: step 2277, loss = 0.69218 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:09:57.918738 ops/training.py:65 2019-01-16 20:09:57.918678: step 2278, loss = 0.69782 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:09:58.815464 ops/training.py:65 2019-01-16 20:09:58.815379: step 2279, loss = 0.69045 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:09:59.711428 ops/training.py:65 2019-01-16 20:09:59.711372: step 2280, loss = 0.69559 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:10:00.606410 ops/training.py:65 2019-01-16 20:10:00.606327: step 2281, loss = 0.68871 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:10:01.502678 ops/training.py:65 2019-01-16 20:10:01.502597: step 2282, loss = 0.69129 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:10:02.397630 ops/training.py:65 2019-01-16 20:10:02.397570: step 2283, loss = 0.69497 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:10:03.292808 ops/training.py:65 2019-01-16 20:10:03.292729: step 2284, loss = 0.68987 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 20:10:04.187477 ops/training.py:65 2019-01-16 20:10:04.187429: step 2285, loss = 0.69946 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:10:05.081756 ops/training.py:65 2019-01-16 20:10:05.081696: step 2286, loss = 0.68948 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:10:05.976293 ops/training.py:65 2019-01-16 20:10:05.976240: step 2287, loss = 0.69695 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:10:06.870450 ops/training.py:65 2019-01-16 20:10:06.870388: step 2288, loss = 0.68840 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:10:07.766510 ops/training.py:65 2019-01-16 20:10:07.766438: step 2289, loss = 0.68563 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:10:08.666335 ops/training.py:65 2019-01-16 20:10:08.666248: step 2290, loss = 0.68809 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:10:09.561343 ops/training.py:65 2019-01-16 20:10:09.561288: step 2291, loss = 0.69370 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:10:10.455012 ops/training.py:65 2019-01-16 20:10:10.454960: step 2292, loss = 0.68862 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:10:11.348487 ops/training.py:65 2019-01-16 20:10:11.348431: step 2293, loss = 0.68955 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:10:12.242783 ops/training.py:65 2019-01-16 20:10:12.242725: step 2294, loss = 0.69076 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:10:13.138519 ops/training.py:65 2019-01-16 20:10:13.138454: step 2295, loss = 0.69007 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:10:14.036328 ops/training.py:65 2019-01-16 20:10:14.036239: step 2296, loss = 0.69952 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:10:14.931733 ops/training.py:65 2019-01-16 20:10:14.931678: step 2297, loss = 0.69494 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:10:15.827107 ops/training.py:65 2019-01-16 20:10:15.827017: step 2298, loss = 0.69295 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:10:16.724557 ops/training.py:65 2019-01-16 20:10:16.724469: step 2299, loss = 0.69709 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:10:17.621721 ops/training.py:65 2019-01-16 20:10:17.621654: step 2300, loss = 0.69490 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:10:18.516634 ops/training.py:65 2019-01-16 20:10:18.516572: step 2301, loss = 0.69570 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:10:19.411193 ops/training.py:65 2019-01-16 20:10:19.411145: step 2302, loss = 0.69565 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:10:20.306252 ops/training.py:65 2019-01-16 20:10:20.306197: step 2303, loss = 0.69103 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:10:21.201458 ops/training.py:65 2019-01-16 20:10:21.201397: step 2304, loss = 0.70111 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:10:22.096891 ops/training.py:65 2019-01-16 20:10:22.096810: step 2305, loss = 0.69445 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:10:22.993680 ops/training.py:65 2019-01-16 20:10:22.993592: step 2306, loss = 0.69290 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:10:23.889925 ops/training.py:65 2019-01-16 20:10:23.889839: step 2307, loss = 0.70098 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:10:24.785539 ops/training.py:65 2019-01-16 20:10:24.785484: step 2308, loss = 0.69177 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:10:25.679400 ops/training.py:65 2019-01-16 20:10:25.679343: step 2309, loss = 0.69521 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:10:26.572660 ops/training.py:65 2019-01-16 20:10:26.572606: step 2310, loss = 0.69148 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:10:27.467006 ops/training.py:65 2019-01-16 20:10:27.466950: step 2311, loss = 0.70129 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:10:28.361731 ops/training.py:65 2019-01-16 20:10:28.361678: step 2312, loss = 0.69453 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:10:29.255625 ops/training.py:65 2019-01-16 20:10:29.255572: step 2313, loss = 0.69361 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:10:30.150553 ops/training.py:65 2019-01-16 20:10:30.150501: step 2314, loss = 0.70021 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:10:31.044671 ops/training.py:65 2019-01-16 20:10:31.044620: step 2315, loss = 0.69302 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:10:31.939523 ops/training.py:65 2019-01-16 20:10:31.939462: step 2316, loss = 0.68606 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:10:32.835225 ops/training.py:65 2019-01-16 20:10:32.835169: step 2317, loss = 0.69676 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:10:33.731155 ops/training.py:65 2019-01-16 20:10:33.731102: step 2318, loss = 0.70190 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:10:34.624825 ops/training.py:65 2019-01-16 20:10:34.624775: step 2319, loss = 0.70603 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.25
I1280 2019-01-16 20:10:35.520167 ops/training.py:65 2019-01-16 20:10:35.520110: step 2320, loss = 0.68447 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:10:36.415550 ops/training.py:65 2019-01-16 20:10:36.415497: step 2321, loss = 0.69507 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:10:37.309512 ops/training.py:65 2019-01-16 20:10:37.309446: step 2322, loss = 0.68965 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:10:38.205193 ops/training.py:65 2019-01-16 20:10:38.205114: step 2323, loss = 0.69042 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:10:39.100842 ops/training.py:65 2019-01-16 20:10:39.100751: step 2324, loss = 0.70150 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:10:39.995836 ops/training.py:65 2019-01-16 20:10:39.995770: step 2325, loss = 0.68612 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:10:40.891034 ops/training.py:65 2019-01-16 20:10:40.890975: step 2326, loss = 0.70606 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:10:41.785152 ops/training.py:65 2019-01-16 20:10:41.785098: step 2327, loss = 0.69079 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:10:42.680238 ops/training.py:65 2019-01-16 20:10:42.680186: step 2328, loss = 0.69131 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:10:43.574864 ops/training.py:65 2019-01-16 20:10:43.574805: step 2329, loss = 0.69341 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:10:44.469440 ops/training.py:65 2019-01-16 20:10:44.469384: step 2330, loss = 0.69472 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:10:45.363740 ops/training.py:65 2019-01-16 20:10:45.363689: step 2331, loss = 0.69759 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:10:46.258794 ops/training.py:65 2019-01-16 20:10:46.258740: step 2332, loss = 0.70269 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:10:47.153828 ops/training.py:65 2019-01-16 20:10:47.153774: step 2333, loss = 0.68810 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:10:48.048049 ops/training.py:65 2019-01-16 20:10:48.047993: step 2334, loss = 0.68826 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:10:48.942177 ops/training.py:65 2019-01-16 20:10:48.942123: step 2335, loss = 0.69335 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:10:49.836920 ops/training.py:65 2019-01-16 20:10:49.836865: step 2336, loss = 0.69533 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:10:50.732283 ops/training.py:65 2019-01-16 20:10:50.732228: step 2337, loss = 0.68612 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:10:51.626640 ops/training.py:65 2019-01-16 20:10:51.626582: step 2338, loss = 0.69712 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:10:52.523095 ops/training.py:65 2019-01-16 20:10:52.523012: step 2339, loss = 0.69002 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:10:53.418317 ops/training.py:65 2019-01-16 20:10:53.418229: step 2340, loss = 0.69156 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:10:54.313299 ops/training.py:65 2019-01-16 20:10:54.313211: step 2341, loss = 0.69836 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:10:55.209230 ops/training.py:65 2019-01-16 20:10:55.209142: step 2342, loss = 0.69735 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:10:56.105825 ops/training.py:65 2019-01-16 20:10:56.105736: step 2343, loss = 0.69395 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:10:57.002211 ops/training.py:65 2019-01-16 20:10:57.002152: step 2344, loss = 0.69905 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:10:57.896307 ops/training.py:65 2019-01-16 20:10:57.896251: step 2345, loss = 0.69780 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:10:58.790507 ops/training.py:65 2019-01-16 20:10:58.790450: step 2346, loss = 0.69454 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:10:59.684865 ops/training.py:65 2019-01-16 20:10:59.684813: step 2347, loss = 0.69121 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:11:00.579287 ops/training.py:65 2019-01-16 20:11:00.579230: step 2348, loss = 0.70057 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:11:01.473344 ops/training.py:65 2019-01-16 20:11:01.473289: step 2349, loss = 0.69145 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:11:02.368714 ops/training.py:65 2019-01-16 20:11:02.368666: step 2350, loss = 0.69132 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:11:03.264188 ops/training.py:65 2019-01-16 20:11:03.264124: step 2351, loss = 0.68182 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:11:04.158607 ops/training.py:65 2019-01-16 20:11:04.158548: step 2352, loss = 0.69499 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:11:05.055914 ops/training.py:65 2019-01-16 20:11:05.055837: step 2353, loss = 0.69510 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:11:05.951311 ops/training.py:65 2019-01-16 20:11:05.951229: step 2354, loss = 0.69222 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:11:06.848179 ops/training.py:65 2019-01-16 20:11:06.848110: step 2355, loss = 0.69302 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:11:07.745184 ops/training.py:65 2019-01-16 20:11:07.745100: step 2356, loss = 0.68893 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:11:08.641570 ops/training.py:65 2019-01-16 20:11:08.641484: step 2357, loss = 0.69477 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:11:09.539555 ops/training.py:65 2019-01-16 20:11:09.539470: step 2358, loss = 0.69064 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:11:10.436383 ops/training.py:65 2019-01-16 20:11:10.436293: step 2359, loss = 0.69740 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:11:11.331395 ops/training.py:65 2019-01-16 20:11:11.331329: step 2360, loss = 0.69317 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:11:12.227407 ops/training.py:65 2019-01-16 20:11:12.227347: step 2361, loss = 0.69294 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:11:13.121942 ops/training.py:65 2019-01-16 20:11:13.121888: step 2362, loss = 0.69959 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:11:14.016469 ops/training.py:65 2019-01-16 20:11:14.016418: step 2363, loss = 0.69298 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:11:14.910519 ops/training.py:65 2019-01-16 20:11:14.910464: step 2364, loss = 0.69002 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:11:15.806020 ops/training.py:65 2019-01-16 20:11:15.805963: step 2365, loss = 0.68868 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:11:16.701101 ops/training.py:65 2019-01-16 20:11:16.701034: step 2366, loss = 0.70045 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:11:17.596512 ops/training.py:65 2019-01-16 20:11:17.596458: step 2367, loss = 0.69379 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:11:18.491216 ops/training.py:65 2019-01-16 20:11:18.491160: step 2368, loss = 0.69128 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:11:19.386059 ops/training.py:65 2019-01-16 20:11:19.386010: step 2369, loss = 0.69745 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:11:20.281733 ops/training.py:65 2019-01-16 20:11:20.281682: step 2370, loss = 0.69506 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:11:21.176781 ops/training.py:65 2019-01-16 20:11:21.176730: step 2371, loss = 0.68456 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:11:22.071070 ops/training.py:65 2019-01-16 20:11:22.071012: step 2372, loss = 0.70458 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:11:22.967517 ops/training.py:65 2019-01-16 20:11:22.967447: step 2373, loss = 0.69145 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:11:23.863613 ops/training.py:65 2019-01-16 20:11:23.863527: step 2374, loss = 0.69870 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:11:24.760950 ops/training.py:65 2019-01-16 20:11:24.760860: step 2375, loss = 0.70059 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:11:25.656217 ops/training.py:65 2019-01-16 20:11:25.656128: step 2376, loss = 0.68915 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:11:26.552688 ops/training.py:65 2019-01-16 20:11:26.552603: step 2377, loss = 0.69099 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:11:27.449259 ops/training.py:65 2019-01-16 20:11:27.449199: step 2378, loss = 0.69157 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:11:28.346483 ops/training.py:65 2019-01-16 20:11:28.346395: step 2379, loss = 0.68989 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:11:29.242430 ops/training.py:65 2019-01-16 20:11:29.242377: step 2380, loss = 0.68565 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:11:30.138043 ops/training.py:65 2019-01-16 20:11:30.137992: step 2381, loss = 0.68374 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.75
I1280 2019-01-16 20:11:31.037011 ops/training.py:65 2019-01-16 20:11:31.036925: step 2382, loss = 0.70322 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:11:31.932985 ops/training.py:65 2019-01-16 20:11:31.932931: step 2383, loss = 0.69147 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:11:32.829190 ops/training.py:65 2019-01-16 20:11:32.829123: step 2384, loss = 0.69749 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:11:33.725668 ops/training.py:65 2019-01-16 20:11:33.725594: step 2385, loss = 0.69463 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:11:34.620925 ops/training.py:65 2019-01-16 20:11:34.620857: step 2386, loss = 0.69206 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:11:35.515757 ops/training.py:65 2019-01-16 20:11:35.515668: step 2387, loss = 0.70253 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:11:36.412356 ops/training.py:65 2019-01-16 20:11:36.412268: step 2388, loss = 0.70870 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:11:37.307172 ops/training.py:65 2019-01-16 20:11:37.307104: step 2389, loss = 0.69297 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:11:38.203506 ops/training.py:65 2019-01-16 20:11:38.203424: step 2390, loss = 0.68892 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:11:39.100540 ops/training.py:65 2019-01-16 20:11:39.100452: step 2391, loss = 0.68883 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:11:39.997342 ops/training.py:65 2019-01-16 20:11:39.997256: step 2392, loss = 0.69589 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:11:40.892551 ops/training.py:65 2019-01-16 20:11:40.892465: step 2393, loss = 0.69027 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:11:41.787697 ops/training.py:65 2019-01-16 20:11:41.787630: step 2394, loss = 0.69972 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:11:42.683264 ops/training.py:65 2019-01-16 20:11:42.683224: step 2395, loss = 0.69300 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:11:43.578226 ops/training.py:65 2019-01-16 20:11:43.578178: step 2396, loss = 0.69481 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:11:44.472825 ops/training.py:65 2019-01-16 20:11:44.472789: step 2397, loss = 0.68484 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:11:45.369477 ops/training.py:65 2019-01-16 20:11:45.369446: step 2398, loss = 0.69002 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:11:46.265549 ops/training.py:65 2019-01-16 20:11:46.265519: step 2399, loss = 0.70019 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:11:47.160218 ops/training.py:65 2019-01-16 20:11:47.160186: step 2400, loss = 0.68586 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:11:48.055217 ops/training.py:65 2019-01-16 20:11:48.055136: step 2401, loss = 0.69497 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:11:48.949248 ops/training.py:65 2019-01-16 20:11:48.949195: step 2402, loss = 0.68577 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:11:49.841927 ops/training.py:65 2019-01-16 20:11:49.841878: step 2403, loss = 0.68779 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:11:50.734442 ops/training.py:65 2019-01-16 20:11:50.734393: step 2404, loss = 0.69257 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:11:51.627044 ops/training.py:65 2019-01-16 20:11:51.626991: step 2405, loss = 0.69047 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:11:52.520632 ops/training.py:65 2019-01-16 20:11:52.520578: step 2406, loss = 0.69595 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:11:53.416545 ops/training.py:65 2019-01-16 20:11:53.416470: step 2407, loss = 0.69680 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:11:54.312514 ops/training.py:65 2019-01-16 20:11:54.312424: step 2408, loss = 0.69231 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:11:55.210151 ops/training.py:65 2019-01-16 20:11:55.210064: step 2409, loss = 0.67825 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:11:56.107484 ops/training.py:65 2019-01-16 20:11:56.107398: step 2410, loss = 0.69236 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:11:57.003782 ops/training.py:65 2019-01-16 20:11:57.003727: step 2411, loss = 0.68837 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:11:57.898960 ops/training.py:65 2019-01-16 20:11:57.898910: step 2412, loss = 0.68720 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:11:58.793332 ops/training.py:65 2019-01-16 20:11:58.793277: step 2413, loss = 0.69012 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:11:59.688378 ops/training.py:65 2019-01-16 20:11:59.688325: step 2414, loss = 0.69582 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:12:00.581624 ops/training.py:65 2019-01-16 20:12:00.581574: step 2415, loss = 0.68641 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:12:01.474400 ops/training.py:65 2019-01-16 20:12:01.474348: step 2416, loss = 0.69057 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:12:02.370447 ops/training.py:65 2019-01-16 20:12:02.370397: step 2417, loss = 0.69142 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:12:03.267826 ops/training.py:65 2019-01-16 20:12:03.267739: step 2418, loss = 0.70567 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:12:04.166090 ops/training.py:65 2019-01-16 20:12:04.166027: step 2419, loss = 0.69674 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:12:05.061202 ops/training.py:65 2019-01-16 20:12:05.061152: step 2420, loss = 0.69330 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:12:05.958807 ops/training.py:65 2019-01-16 20:12:05.958714: step 2421, loss = 0.69383 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:12:06.855407 ops/training.py:65 2019-01-16 20:12:06.855337: step 2422, loss = 0.70832 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 20:12:07.752336 ops/training.py:65 2019-01-16 20:12:07.752254: step 2423, loss = 0.68435 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:12:08.647414 ops/training.py:65 2019-01-16 20:12:08.647348: step 2424, loss = 0.69143 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:12:09.541038 ops/training.py:65 2019-01-16 20:12:09.540983: step 2425, loss = 0.68543 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:12:10.436107 ops/training.py:65 2019-01-16 20:12:10.436061: step 2426, loss = 0.69088 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:12:11.332397 ops/training.py:65 2019-01-16 20:12:11.332341: step 2427, loss = 0.68920 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:12:12.227683 ops/training.py:65 2019-01-16 20:12:12.227636: step 2428, loss = 0.69740 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:12:13.123498 ops/training.py:65 2019-01-16 20:12:13.123441: step 2429, loss = 0.69821 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:12:14.016745 ops/training.py:65 2019-01-16 20:12:14.016694: step 2430, loss = 0.70771 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:12:14.910141 ops/training.py:65 2019-01-16 20:12:14.910088: step 2431, loss = 0.69275 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:12:15.804604 ops/training.py:65 2019-01-16 20:12:15.804549: step 2432, loss = 0.69934 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:12:16.700628 ops/training.py:65 2019-01-16 20:12:16.700574: step 2433, loss = 0.68300 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:12:17.595194 ops/training.py:65 2019-01-16 20:12:17.595151: step 2434, loss = 0.68838 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:12:18.491352 ops/training.py:65 2019-01-16 20:12:18.491302: step 2435, loss = 0.68749 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:12:19.384218 ops/training.py:65 2019-01-16 20:12:19.384172: step 2436, loss = 0.69648 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:12:20.277627 ops/training.py:65 2019-01-16 20:12:20.277567: step 2437, loss = 0.68983 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:12:21.171190 ops/training.py:65 2019-01-16 20:12:21.171131: step 2438, loss = 0.69172 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:12:22.066184 ops/training.py:65 2019-01-16 20:12:22.066130: step 2439, loss = 0.68487 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:12:22.961023 ops/training.py:65 2019-01-16 20:12:22.960968: step 2440, loss = 0.69574 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:12:23.856263 ops/training.py:65 2019-01-16 20:12:23.856199: step 2441, loss = 0.69283 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:12:24.752060 ops/training.py:65 2019-01-16 20:12:24.751974: step 2442, loss = 0.70206 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:12:25.649723 ops/training.py:65 2019-01-16 20:12:25.649634: step 2443, loss = 0.68338 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:12:26.546272 ops/training.py:65 2019-01-16 20:12:26.546209: step 2444, loss = 0.69980 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:12:27.441079 ops/training.py:65 2019-01-16 20:12:27.441019: step 2445, loss = 0.68847 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:12:28.336811 ops/training.py:65 2019-01-16 20:12:28.336756: step 2446, loss = 0.68892 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:12:29.231508 ops/training.py:65 2019-01-16 20:12:29.231449: step 2447, loss = 0.68571 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:12:30.127247 ops/training.py:65 2019-01-16 20:12:30.127161: step 2448, loss = 0.70201 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:12:31.022619 ops/training.py:65 2019-01-16 20:12:31.022532: step 2449, loss = 0.68957 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:12:31.917438 ops/training.py:65 2019-01-16 20:12:31.917357: step 2450, loss = 0.68788 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:12:32.811474 ops/training.py:65 2019-01-16 20:12:32.811405: step 2451, loss = 0.69295 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:12:33.708543 ops/training.py:65 2019-01-16 20:12:33.708456: step 2452, loss = 0.69806 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:12:34.605392 ops/training.py:65 2019-01-16 20:12:34.605344: step 2453, loss = 0.69965 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:12:35.499936 ops/training.py:65 2019-01-16 20:12:35.499882: step 2454, loss = 0.68871 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:12:36.394767 ops/training.py:65 2019-01-16 20:12:36.394702: step 2455, loss = 0.69372 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:12:37.289141 ops/training.py:65 2019-01-16 20:12:37.289056: step 2456, loss = 0.69776 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:12:38.185349 ops/training.py:65 2019-01-16 20:12:38.185291: step 2457, loss = 0.69207 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:12:39.080995 ops/training.py:65 2019-01-16 20:12:39.080911: step 2458, loss = 0.69466 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:12:39.978659 ops/training.py:65 2019-01-16 20:12:39.978556: step 2459, loss = 0.69810 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:12:40.875086 ops/training.py:65 2019-01-16 20:12:40.875025: step 2460, loss = 0.70615 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:12:41.769761 ops/training.py:65 2019-01-16 20:12:41.769694: step 2461, loss = 0.69205 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:12:42.664094 ops/training.py:65 2019-01-16 20:12:42.664027: step 2462, loss = 0.67086 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:12:43.557773 ops/training.py:65 2019-01-16 20:12:43.557701: step 2463, loss = 0.70184 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:12:44.453477 ops/training.py:65 2019-01-16 20:12:44.453397: step 2464, loss = 0.69235 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:12:45.348798 ops/training.py:65 2019-01-16 20:12:45.348706: step 2465, loss = 0.69248 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:12:46.243583 ops/training.py:65 2019-01-16 20:12:46.243477: step 2466, loss = 0.68562 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:12:47.140135 ops/training.py:65 2019-01-16 20:12:47.140031: step 2467, loss = 0.69328 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:12:48.036691 ops/training.py:65 2019-01-16 20:12:48.036626: step 2468, loss = 0.69555 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:12:48.931719 ops/training.py:65 2019-01-16 20:12:48.931653: step 2469, loss = 0.69759 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:12:49.829980 ops/training.py:65 2019-01-16 20:12:49.829876: step 2470, loss = 0.69575 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:12:50.726133 ops/training.py:65 2019-01-16 20:12:50.726070: step 2471, loss = 0.69106 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:12:51.620159 ops/training.py:65 2019-01-16 20:12:51.620093: step 2472, loss = 0.69506 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:12:52.514458 ops/training.py:65 2019-01-16 20:12:52.514401: step 2473, loss = 0.70503 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:12:53.409844 ops/training.py:65 2019-01-16 20:12:53.409777: step 2474, loss = 0.69200 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:12:54.305353 ops/training.py:65 2019-01-16 20:12:54.305254: step 2475, loss = 0.68478 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:12:55.202642 ops/training.py:65 2019-01-16 20:12:55.202539: step 2476, loss = 0.69560 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:12:56.099632 ops/training.py:65 2019-01-16 20:12:56.099571: step 2477, loss = 0.69905 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:12:56.993751 ops/training.py:65 2019-01-16 20:12:56.993683: step 2478, loss = 0.70467 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:12:57.889485 ops/training.py:65 2019-01-16 20:12:57.889430: step 2479, loss = 0.68171 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:12:58.787282 ops/training.py:65 2019-01-16 20:12:58.787220: step 2480, loss = 0.68030 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:12:59.683086 ops/training.py:65 2019-01-16 20:12:59.683046: step 2481, loss = 0.69552 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:13:00.578796 ops/training.py:65 2019-01-16 20:13:00.578751: step 2482, loss = 0.68894 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:13:01.474420 ops/training.py:65 2019-01-16 20:13:01.474384: step 2483, loss = 0.69283 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:13:02.368687 ops/training.py:65 2019-01-16 20:13:02.368648: step 2484, loss = 0.70568 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:13:03.262009 ops/training.py:65 2019-01-16 20:13:03.261978: step 2485, loss = 0.69266 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:13:04.157065 ops/training.py:65 2019-01-16 20:13:04.156967: step 2486, loss = 0.69156 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:13:05.052705 ops/training.py:65 2019-01-16 20:13:05.052647: step 2487, loss = 0.69103 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:13:05.946537 ops/training.py:65 2019-01-16 20:13:05.946471: step 2488, loss = 0.69137 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:13:06.842227 ops/training.py:65 2019-01-16 20:13:06.842143: step 2489, loss = 0.69090 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:13:07.737911 ops/training.py:65 2019-01-16 20:13:07.737852: step 2490, loss = 0.71020 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:13:08.633735 ops/training.py:65 2019-01-16 20:13:08.633645: step 2491, loss = 0.69617 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:13:09.527893 ops/training.py:65 2019-01-16 20:13:09.527835: step 2492, loss = 0.69981 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:13:10.424375 ops/training.py:65 2019-01-16 20:13:10.424327: step 2493, loss = 0.70583 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:13:11.319799 ops/training.py:65 2019-01-16 20:13:11.319740: step 2494, loss = 0.69477 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:13:12.213846 ops/training.py:65 2019-01-16 20:13:12.213801: step 2495, loss = 0.68852 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:13:13.108742 ops/training.py:65 2019-01-16 20:13:13.108663: step 2496, loss = 0.69304 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:13:14.002130 ops/training.py:65 2019-01-16 20:13:14.002072: step 2497, loss = 0.70697 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:13:14.895501 ops/training.py:65 2019-01-16 20:13:14.895441: step 2498, loss = 0.69095 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:13:15.788309 ops/training.py:65 2019-01-16 20:13:15.788247: step 2499, loss = 0.68875 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:13:16.680746 ops/training.py:65 2019-01-16 20:13:16.680688: step 2500, loss = 0.69678 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:13:17.572606 ops/training.py:65 2019-01-16 20:13:17.572555: step 2501, loss = 0.69845 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:13:18.465354 ops/training.py:65 2019-01-16 20:13:18.465297: step 2502, loss = 0.69107 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:13:19.357708 ops/training.py:65 2019-01-16 20:13:19.357663: step 2503, loss = 0.68996 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:13:20.250280 ops/training.py:65 2019-01-16 20:13:20.250220: step 2504, loss = 0.68772 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:13:21.144923 ops/training.py:65 2019-01-16 20:13:21.144886: step 2505, loss = 0.69745 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:13:22.041144 ops/training.py:65 2019-01-16 20:13:22.041083: step 2506, loss = 0.68905 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:13:22.937187 ops/training.py:65 2019-01-16 20:13:22.937144: step 2507, loss = 0.69615 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:13:23.832898 ops/training.py:65 2019-01-16 20:13:23.832836: step 2508, loss = 0.68887 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:13:24.726662 ops/training.py:65 2019-01-16 20:13:24.726599: step 2509, loss = 0.69375 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:13:25.620852 ops/training.py:65 2019-01-16 20:13:25.620784: step 2510, loss = 0.70399 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:13:26.514461 ops/training.py:65 2019-01-16 20:13:26.514401: step 2511, loss = 0.69002 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:13:27.409211 ops/training.py:65 2019-01-16 20:13:27.409157: step 2512, loss = 0.70037 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:13:28.305921 ops/training.py:65 2019-01-16 20:13:28.305853: step 2513, loss = 0.69679 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:13:29.200792 ops/training.py:65 2019-01-16 20:13:29.200727: step 2514, loss = 0.69570 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:13:30.095625 ops/training.py:65 2019-01-16 20:13:30.095573: step 2515, loss = 0.69638 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:13:30.990689 ops/training.py:65 2019-01-16 20:13:30.990640: step 2516, loss = 0.69378 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:13:31.886207 ops/training.py:65 2019-01-16 20:13:31.886155: step 2517, loss = 0.70050 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:13:32.782365 ops/training.py:65 2019-01-16 20:13:32.782310: step 2518, loss = 0.68489 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:13:33.675910 ops/training.py:65 2019-01-16 20:13:33.675848: step 2519, loss = 0.69388 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:13:34.569431 ops/training.py:65 2019-01-16 20:13:34.569382: step 2520, loss = 0.69453 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:13:35.462346 ops/training.py:65 2019-01-16 20:13:35.462285: step 2521, loss = 0.69546 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:13:36.357236 ops/training.py:65 2019-01-16 20:13:36.357202: step 2522, loss = 0.69031 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:13:37.252348 ops/training.py:65 2019-01-16 20:13:37.252285: step 2523, loss = 0.69923 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:13:38.148114 ops/training.py:65 2019-01-16 20:13:38.148072: step 2524, loss = 0.69474 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:13:39.045421 ops/training.py:65 2019-01-16 20:13:39.045386: step 2525, loss = 0.68710 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:13:39.940518 ops/training.py:65 2019-01-16 20:13:39.940454: step 2526, loss = 0.69820 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:13:40.833336 ops/training.py:65 2019-01-16 20:13:40.833279: step 2527, loss = 0.69444 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:13:41.728113 ops/training.py:65 2019-01-16 20:13:41.728054: step 2528, loss = 0.69139 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:13:42.623417 ops/training.py:65 2019-01-16 20:13:42.623381: step 2529, loss = 0.69848 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:13:43.519205 ops/training.py:65 2019-01-16 20:13:43.519165: step 2530, loss = 0.69441 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:13:44.416511 ops/training.py:65 2019-01-16 20:13:44.416477: step 2531, loss = 0.68834 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:13:45.311757 ops/training.py:65 2019-01-16 20:13:45.311686: step 2532, loss = 0.69150 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:13:46.206180 ops/training.py:65 2019-01-16 20:13:46.206151: step 2533, loss = 0.69088 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:13:47.102019 ops/training.py:65 2019-01-16 20:13:47.101989: step 2534, loss = 0.69461 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:13:47.999202 ops/training.py:65 2019-01-16 20:13:47.999100: step 2535, loss = 0.70024 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:13:48.896362 ops/training.py:65 2019-01-16 20:13:48.896255: step 2536, loss = 0.69085 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:13:49.792229 ops/training.py:65 2019-01-16 20:13:49.792174: step 2537, loss = 0.68708 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:13:50.686316 ops/training.py:65 2019-01-16 20:13:50.686256: step 2538, loss = 0.68664 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:13:51.580822 ops/training.py:65 2019-01-16 20:13:51.580759: step 2539, loss = 0.69022 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:13:52.474760 ops/training.py:65 2019-01-16 20:13:52.474700: step 2540, loss = 0.68842 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:13:53.368700 ops/training.py:65 2019-01-16 20:13:53.368637: step 2541, loss = 0.68717 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:13:54.263439 ops/training.py:65 2019-01-16 20:13:54.263371: step 2542, loss = 0.69313 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:13:55.158056 ops/training.py:65 2019-01-16 20:13:55.157993: step 2543, loss = 0.68592 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:13:56.052423 ops/training.py:65 2019-01-16 20:13:56.052361: step 2544, loss = 0.69319 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:13:56.948329 ops/training.py:65 2019-01-16 20:13:56.948251: step 2545, loss = 0.69436 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:13:57.845226 ops/training.py:65 2019-01-16 20:13:57.845115: step 2546, loss = 0.69861 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:13:58.741468 ops/training.py:65 2019-01-16 20:13:58.741363: step 2547, loss = 0.69217 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:13:59.637448 ops/training.py:65 2019-01-16 20:13:59.637341: step 2548, loss = 0.70023 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 20:14:00.533593 ops/training.py:65 2019-01-16 20:14:00.533485: step 2549, loss = 0.69101 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:14:01.428006 ops/training.py:65 2019-01-16 20:14:01.427912: step 2550, loss = 0.69338 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:14:02.322424 ops/training.py:65 2019-01-16 20:14:02.322332: step 2551, loss = 0.68706 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:14:03.219347 ops/training.py:65 2019-01-16 20:14:03.219248: step 2552, loss = 0.70065 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:14:04.115634 ops/training.py:65 2019-01-16 20:14:04.115571: step 2553, loss = 0.68221 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.78125
I1280 2019-01-16 20:14:05.012216 ops/training.py:65 2019-01-16 20:14:05.012160: step 2554, loss = 0.69227 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:14:05.910006 ops/training.py:65 2019-01-16 20:14:05.909894: step 2555, loss = 0.70515 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:14:06.806131 ops/training.py:65 2019-01-16 20:14:06.806051: step 2556, loss = 0.70236 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 20:14:07.702340 ops/training.py:65 2019-01-16 20:14:07.702273: step 2557, loss = 0.68208 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:14:08.596625 ops/training.py:65 2019-01-16 20:14:08.596560: step 2558, loss = 0.69764 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:14:09.491941 ops/training.py:65 2019-01-16 20:14:09.491880: step 2559, loss = 0.69558 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:14:10.388755 ops/training.py:65 2019-01-16 20:14:10.388649: step 2560, loss = 0.69779 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:14:11.285208 ops/training.py:65 2019-01-16 20:14:11.285127: step 2561, loss = 0.69417 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:14:12.182281 ops/training.py:65 2019-01-16 20:14:12.182199: step 2562, loss = 0.68706 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:14:13.077907 ops/training.py:65 2019-01-16 20:14:13.077799: step 2563, loss = 0.70193 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:14:13.974799 ops/training.py:65 2019-01-16 20:14:13.974694: step 2564, loss = 0.69996 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:14:14.869931 ops/training.py:65 2019-01-16 20:14:14.869869: step 2565, loss = 0.69307 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:14:15.764848 ops/training.py:65 2019-01-16 20:14:15.764783: step 2566, loss = 0.68897 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:14:16.659876 ops/training.py:65 2019-01-16 20:14:16.659809: step 2567, loss = 0.69661 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:14:17.555286 ops/training.py:65 2019-01-16 20:14:17.555208: step 2568, loss = 0.70689 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:14:18.451793 ops/training.py:65 2019-01-16 20:14:18.451692: step 2569, loss = 0.69379 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:14:19.348448 ops/training.py:65 2019-01-16 20:14:19.348360: step 2570, loss = 0.69691 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:14:20.244425 ops/training.py:65 2019-01-16 20:14:20.244340: step 2571, loss = 0.68669 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:14:21.140661 ops/training.py:65 2019-01-16 20:14:21.140554: step 2572, loss = 0.69576 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:14:22.037138 ops/training.py:65 2019-01-16 20:14:22.037076: step 2573, loss = 0.69039 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:14:22.933581 ops/training.py:65 2019-01-16 20:14:22.933513: step 2574, loss = 0.68324 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:14:23.831708 ops/training.py:65 2019-01-16 20:14:23.831599: step 2575, loss = 0.69343 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:14:24.729309 ops/training.py:65 2019-01-16 20:14:24.729236: step 2576, loss = 0.69445 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:14:25.624465 ops/training.py:65 2019-01-16 20:14:25.624361: step 2577, loss = 0.69682 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:14:26.521939 ops/training.py:65 2019-01-16 20:14:26.521835: step 2578, loss = 0.67931 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.75
I1280 2019-01-16 20:14:27.417869 ops/training.py:65 2019-01-16 20:14:27.417801: step 2579, loss = 0.69198 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:14:28.315282 ops/training.py:65 2019-01-16 20:14:28.315173: step 2580, loss = 0.68217 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:14:29.211513 ops/training.py:65 2019-01-16 20:14:29.211445: step 2581, loss = 0.70238 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:14:30.105914 ops/training.py:65 2019-01-16 20:14:30.105850: step 2582, loss = 0.70245 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:14:31.001019 ops/training.py:65 2019-01-16 20:14:31.000946: step 2583, loss = 0.69366 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:14:31.898078 ops/training.py:65 2019-01-16 20:14:31.897970: step 2584, loss = 0.69616 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:14:32.796717 ops/training.py:65 2019-01-16 20:14:32.796618: step 2585, loss = 0.68918 (35.7 examples/sec; 0.898 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:14:33.693538 ops/training.py:65 2019-01-16 20:14:33.693463: step 2586, loss = 0.69541 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:14:34.587341 ops/training.py:65 2019-01-16 20:14:34.587289: step 2587, loss = 0.70029 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:14:35.482199 ops/training.py:65 2019-01-16 20:14:35.482136: step 2588, loss = 0.69922 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:14:36.376509 ops/training.py:65 2019-01-16 20:14:36.376449: step 2589, loss = 0.69062 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:14:37.270145 ops/training.py:65 2019-01-16 20:14:37.270063: step 2590, loss = 0.69828 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:14:38.166603 ops/training.py:65 2019-01-16 20:14:38.166516: step 2591, loss = 0.69734 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:14:39.062631 ops/training.py:65 2019-01-16 20:14:39.062525: step 2592, loss = 0.68208 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:14:39.957787 ops/training.py:65 2019-01-16 20:14:39.957680: step 2593, loss = 0.69323 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:14:40.854543 ops/training.py:65 2019-01-16 20:14:40.854441: step 2594, loss = 0.69433 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:14:41.750204 ops/training.py:65 2019-01-16 20:14:41.750136: step 2595, loss = 0.70096 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:14:42.646332 ops/training.py:65 2019-01-16 20:14:42.646226: step 2596, loss = 0.70523 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:14:43.543203 ops/training.py:65 2019-01-16 20:14:43.543095: step 2597, loss = 0.69850 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:14:44.439095 ops/training.py:65 2019-01-16 20:14:44.438988: step 2598, loss = 0.67643 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:14:45.333450 ops/training.py:65 2019-01-16 20:14:45.333377: step 2599, loss = 0.69930 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:14:46.227959 ops/training.py:65 2019-01-16 20:14:46.227890: step 2600, loss = 0.69195 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:14:47.124034 ops/training.py:65 2019-01-16 20:14:47.123966: step 2601, loss = 0.68670 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:14:48.021871 ops/training.py:65 2019-01-16 20:14:48.021764: step 2602, loss = 0.68515 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:14:48.917481 ops/training.py:65 2019-01-16 20:14:48.917422: step 2603, loss = 0.68512 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:14:49.811650 ops/training.py:65 2019-01-16 20:14:49.811597: step 2604, loss = 0.70133 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:14:50.705799 ops/training.py:65 2019-01-16 20:14:50.705747: step 2605, loss = 0.68959 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:14:51.602050 ops/training.py:65 2019-01-16 20:14:51.601989: step 2606, loss = 0.69584 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:14:52.495566 ops/training.py:65 2019-01-16 20:14:52.495502: step 2607, loss = 0.69647 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:14:53.390020 ops/training.py:65 2019-01-16 20:14:53.389948: step 2608, loss = 0.70193 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:14:54.285036 ops/training.py:65 2019-01-16 20:14:54.284964: step 2609, loss = 0.69350 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:14:55.178489 ops/training.py:65 2019-01-16 20:14:55.178421: step 2610, loss = 0.69187 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:14:56.072129 ops/training.py:65 2019-01-16 20:14:56.072062: step 2611, loss = 0.69188 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:14:56.965977 ops/training.py:65 2019-01-16 20:14:56.965912: step 2612, loss = 0.69969 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:14:57.860275 ops/training.py:65 2019-01-16 20:14:57.860211: step 2613, loss = 0.68699 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:14:58.754147 ops/training.py:65 2019-01-16 20:14:58.754088: step 2614, loss = 0.69649 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:14:59.647585 ops/training.py:65 2019-01-16 20:14:59.647523: step 2615, loss = 0.68436 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:15:00.541062 ops/training.py:65 2019-01-16 20:15:00.541004: step 2616, loss = 0.69098 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:15:01.434352 ops/training.py:65 2019-01-16 20:15:01.434285: step 2617, loss = 0.70092 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:15:02.329820 ops/training.py:65 2019-01-16 20:15:02.329766: step 2618, loss = 0.68895 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:15:03.224214 ops/training.py:65 2019-01-16 20:15:03.224159: step 2619, loss = 0.69356 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:15:04.118474 ops/training.py:65 2019-01-16 20:15:04.118412: step 2620, loss = 0.69162 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:15:05.011514 ops/training.py:65 2019-01-16 20:15:05.011455: step 2621, loss = 0.70225 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:15:05.904573 ops/training.py:65 2019-01-16 20:15:05.904512: step 2622, loss = 0.68847 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:15:06.799647 ops/training.py:65 2019-01-16 20:15:06.799567: step 2623, loss = 0.68156 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:15:07.694114 ops/training.py:65 2019-01-16 20:15:07.694047: step 2624, loss = 0.69982 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:15:08.588989 ops/training.py:65 2019-01-16 20:15:08.588928: step 2625, loss = 0.69282 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:15:09.483675 ops/training.py:65 2019-01-16 20:15:09.483614: step 2626, loss = 0.68701 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:15:10.377687 ops/training.py:65 2019-01-16 20:15:10.377630: step 2627, loss = 0.69239 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:15:11.271753 ops/training.py:65 2019-01-16 20:15:11.271695: step 2628, loss = 0.69932 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:15:12.165518 ops/training.py:65 2019-01-16 20:15:12.165459: step 2629, loss = 0.67849 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.75
I1280 2019-01-16 20:15:13.059275 ops/training.py:65 2019-01-16 20:15:13.059215: step 2630, loss = 0.70169 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:15:13.953619 ops/training.py:65 2019-01-16 20:15:13.953563: step 2631, loss = 0.69667 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:15:14.847834 ops/training.py:65 2019-01-16 20:15:14.847774: step 2632, loss = 0.68613 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:15:15.742049 ops/training.py:65 2019-01-16 20:15:15.741992: step 2633, loss = 0.70018 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:15:16.636481 ops/training.py:65 2019-01-16 20:15:16.636426: step 2634, loss = 0.69394 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:15:17.530468 ops/training.py:65 2019-01-16 20:15:17.530437: step 2635, loss = 0.70225 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:15:18.426767 ops/training.py:65 2019-01-16 20:15:18.426649: step 2636, loss = 0.69222 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:15:19.321440 ops/training.py:65 2019-01-16 20:15:19.321389: step 2637, loss = 0.70391 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:15:20.214641 ops/training.py:65 2019-01-16 20:15:20.214589: step 2638, loss = 0.69463 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:15:21.108708 ops/training.py:65 2019-01-16 20:15:21.108642: step 2639, loss = 0.68990 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:15:22.001437 ops/training.py:65 2019-01-16 20:15:22.001383: step 2640, loss = 0.69157 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:15:22.894196 ops/training.py:65 2019-01-16 20:15:22.894136: step 2641, loss = 0.69797 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:15:23.788325 ops/training.py:65 2019-01-16 20:15:23.788269: step 2642, loss = 0.70143 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:15:24.681454 ops/training.py:65 2019-01-16 20:15:24.681393: step 2643, loss = 0.69805 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:15:25.577124 ops/training.py:65 2019-01-16 20:15:25.577066: step 2644, loss = 0.69417 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:15:26.472722 ops/training.py:65 2019-01-16 20:15:26.472685: step 2645, loss = 0.68823 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:15:27.368398 ops/training.py:65 2019-01-16 20:15:27.368349: step 2646, loss = 0.69733 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:15:28.263230 ops/training.py:65 2019-01-16 20:15:28.263188: step 2647, loss = 0.68680 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:15:29.159211 ops/training.py:65 2019-01-16 20:15:29.159180: step 2648, loss = 0.67833 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 20:15:30.054218 ops/training.py:65 2019-01-16 20:15:30.054181: step 2649, loss = 0.70412 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:15:30.949088 ops/training.py:65 2019-01-16 20:15:30.949059: step 2650, loss = 0.68702 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:15:31.846007 ops/training.py:65 2019-01-16 20:15:31.845978: step 2651, loss = 0.68863 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:15:32.742086 ops/training.py:65 2019-01-16 20:15:32.742057: step 2652, loss = 0.69038 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:15:33.636847 ops/training.py:65 2019-01-16 20:15:33.636818: step 2653, loss = 0.69454 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:15:34.532604 ops/training.py:65 2019-01-16 20:15:34.532575: step 2654, loss = 0.69850 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:15:35.426986 ops/training.py:65 2019-01-16 20:15:35.426949: step 2655, loss = 0.68865 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:15:36.321797 ops/training.py:65 2019-01-16 20:15:36.321767: step 2656, loss = 0.68917 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:15:37.214839 ops/training.py:65 2019-01-16 20:15:37.214771: step 2657, loss = 0.69405 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:15:38.108310 ops/training.py:65 2019-01-16 20:15:38.108274: step 2658, loss = 0.69428 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:15:39.002036 ops/training.py:65 2019-01-16 20:15:39.002004: step 2659, loss = 0.68407 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:15:39.895690 ops/training.py:65 2019-01-16 20:15:39.895660: step 2660, loss = 0.69640 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:15:40.793236 ops/training.py:65 2019-01-16 20:15:40.793206: step 2661, loss = 0.69652 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:15:41.689528 ops/training.py:65 2019-01-16 20:15:41.689499: step 2662, loss = 0.69746 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:15:42.582946 ops/training.py:65 2019-01-16 20:15:42.582915: step 2663, loss = 0.69442 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:15:43.478957 ops/training.py:65 2019-01-16 20:15:43.478926: step 2664, loss = 0.69410 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:15:44.374473 ops/training.py:65 2019-01-16 20:15:44.374374: step 2665, loss = 0.68913 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:15:45.268621 ops/training.py:65 2019-01-16 20:15:45.268556: step 2666, loss = 0.69873 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:15:46.163779 ops/training.py:65 2019-01-16 20:15:46.163742: step 2667, loss = 0.68442 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:15:47.058870 ops/training.py:65 2019-01-16 20:15:47.058807: step 2668, loss = 0.69645 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:15:47.954948 ops/training.py:65 2019-01-16 20:15:47.954918: step 2669, loss = 0.69034 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:15:48.850626 ops/training.py:65 2019-01-16 20:15:48.850596: step 2670, loss = 0.69809 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:15:49.746866 ops/training.py:65 2019-01-16 20:15:49.746837: step 2671, loss = 0.68580 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:15:50.641978 ops/training.py:65 2019-01-16 20:15:50.641947: step 2672, loss = 0.69925 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:15:51.536552 ops/training.py:65 2019-01-16 20:15:51.536522: step 2673, loss = 0.68809 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:15:52.432967 ops/training.py:65 2019-01-16 20:15:52.432932: step 2674, loss = 0.68993 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:15:53.327651 ops/training.py:65 2019-01-16 20:15:53.327621: step 2675, loss = 0.69058 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:15:54.221586 ops/training.py:65 2019-01-16 20:15:54.221556: step 2676, loss = 0.69772 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:15:55.117212 ops/training.py:65 2019-01-16 20:15:55.117118: step 2677, loss = 0.68694 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:15:56.014742 ops/training.py:65 2019-01-16 20:15:56.014639: step 2678, loss = 0.68665 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:15:56.909127 ops/training.py:65 2019-01-16 20:15:56.909056: step 2679, loss = 0.68795 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:15:57.804336 ops/training.py:65 2019-01-16 20:15:57.804262: step 2680, loss = 0.69133 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:15:58.699762 ops/training.py:65 2019-01-16 20:15:58.699677: step 2681, loss = 0.68487 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:15:59.596971 ops/training.py:65 2019-01-16 20:15:59.596861: step 2682, loss = 0.69096 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:16:00.492217 ops/training.py:65 2019-01-16 20:16:00.492115: step 2683, loss = 0.67939 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:16:01.387997 ops/training.py:65 2019-01-16 20:16:01.387926: step 2684, loss = 0.69460 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:16:02.282456 ops/training.py:65 2019-01-16 20:16:02.282387: step 2685, loss = 0.68077 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:16:03.177658 ops/training.py:65 2019-01-16 20:16:03.177568: step 2686, loss = 0.69731 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:16:04.072651 ops/training.py:65 2019-01-16 20:16:04.072545: step 2687, loss = 0.69165 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:16:04.967415 ops/training.py:65 2019-01-16 20:16:04.967347: step 2688, loss = 0.69629 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:16:05.862282 ops/training.py:65 2019-01-16 20:16:05.862171: step 2689, loss = 0.70327 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:16:06.757706 ops/training.py:65 2019-01-16 20:16:06.757595: step 2690, loss = 0.69646 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:16:07.653795 ops/training.py:65 2019-01-16 20:16:07.653705: step 2691, loss = 0.68330 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:16:08.549941 ops/training.py:65 2019-01-16 20:16:08.549833: step 2692, loss = 0.69614 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:16:09.445392 ops/training.py:65 2019-01-16 20:16:09.445285: step 2693, loss = 0.69904 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:16:10.340386 ops/training.py:65 2019-01-16 20:16:10.340288: step 2694, loss = 0.70690 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:16:11.234802 ops/training.py:65 2019-01-16 20:16:11.234735: step 2695, loss = 0.68753 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:16:12.128907 ops/training.py:65 2019-01-16 20:16:12.128818: step 2696, loss = 0.69397 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:16:13.023477 ops/training.py:65 2019-01-16 20:16:13.023373: step 2697, loss = 0.69422 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:16:13.919066 ops/training.py:65 2019-01-16 20:16:13.918949: step 2698, loss = 0.69502 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:16:14.818145 ops/training.py:65 2019-01-16 20:16:14.818038: step 2699, loss = 0.69807 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:16:15.714788 ops/training.py:65 2019-01-16 20:16:15.714680: step 2700, loss = 0.69216 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:16:16.610185 ops/training.py:65 2019-01-16 20:16:16.610108: step 2701, loss = 0.68781 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:16:17.505405 ops/training.py:65 2019-01-16 20:16:17.505338: step 2702, loss = 0.69119 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:16:18.400065 ops/training.py:65 2019-01-16 20:16:18.399996: step 2703, loss = 0.69121 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:16:19.294231 ops/training.py:65 2019-01-16 20:16:19.294165: step 2704, loss = 0.69274 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:16:20.188350 ops/training.py:65 2019-01-16 20:16:20.188292: step 2705, loss = 0.69700 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:16:21.082459 ops/training.py:65 2019-01-16 20:16:21.082396: step 2706, loss = 0.69094 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:16:21.980267 ops/training.py:65 2019-01-16 20:16:21.980166: step 2707, loss = 0.70381 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:16:22.876001 ops/training.py:65 2019-01-16 20:16:22.875934: step 2708, loss = 0.69632 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:16:23.770373 ops/training.py:65 2019-01-16 20:16:23.770308: step 2709, loss = 0.69465 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:16:24.665129 ops/training.py:65 2019-01-16 20:16:24.665070: step 2710, loss = 0.70711 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:16:25.558901 ops/training.py:65 2019-01-16 20:16:25.558844: step 2711, loss = 0.69465 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:16:26.453150 ops/training.py:65 2019-01-16 20:16:26.453088: step 2712, loss = 0.69857 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:16:27.346075 ops/training.py:65 2019-01-16 20:16:27.346018: step 2713, loss = 0.70372 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:16:28.239884 ops/training.py:65 2019-01-16 20:16:28.239823: step 2714, loss = 0.69663 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:16:29.134076 ops/training.py:65 2019-01-16 20:16:29.134015: step 2715, loss = 0.68291 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:16:30.028772 ops/training.py:65 2019-01-16 20:16:30.028717: step 2716, loss = 0.69126 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:16:30.924938 ops/training.py:65 2019-01-16 20:16:30.924882: step 2717, loss = 0.70528 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:16:31.820237 ops/training.py:65 2019-01-16 20:16:31.820183: step 2718, loss = 0.69111 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:16:32.718993 ops/training.py:65 2019-01-16 20:16:32.718905: step 2719, loss = 0.68247 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:16:33.616570 ops/training.py:65 2019-01-16 20:16:33.616467: step 2720, loss = 0.69917 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:16:34.511779 ops/training.py:65 2019-01-16 20:16:34.511676: step 2721, loss = 0.68407 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:16:35.408971 ops/training.py:65 2019-01-16 20:16:35.408869: step 2722, loss = 0.70820 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:16:36.306194 ops/training.py:65 2019-01-16 20:16:36.306091: step 2723, loss = 0.69767 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:16:37.202375 ops/training.py:65 2019-01-16 20:16:37.202298: step 2724, loss = 0.69660 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:16:38.098048 ops/training.py:65 2019-01-16 20:16:38.097948: step 2725, loss = 0.68355 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:16:38.993468 ops/training.py:65 2019-01-16 20:16:38.993377: step 2726, loss = 0.68122 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:16:39.893523 ops/training.py:65 2019-01-16 20:16:39.893415: step 2727, loss = 0.69646 (35.6 examples/sec; 0.899 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:16:40.788965 ops/training.py:65 2019-01-16 20:16:40.788858: step 2728, loss = 0.69243 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:16:41.684463 ops/training.py:65 2019-01-16 20:16:41.684358: step 2729, loss = 0.69258 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:16:42.580649 ops/training.py:65 2019-01-16 20:16:42.580542: step 2730, loss = 0.69410 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:16:43.476335 ops/training.py:65 2019-01-16 20:16:43.476254: step 2731, loss = 0.69888 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:16:44.372122 ops/training.py:65 2019-01-16 20:16:44.372014: step 2732, loss = 0.69877 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:16:45.269052 ops/training.py:65 2019-01-16 20:16:45.268943: step 2733, loss = 0.68924 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:16:46.164201 ops/training.py:65 2019-01-16 20:16:46.164093: step 2734, loss = 0.70540 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:16:47.059849 ops/training.py:65 2019-01-16 20:16:47.059769: step 2735, loss = 0.68905 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:16:47.955527 ops/training.py:65 2019-01-16 20:16:47.955443: step 2736, loss = 0.69331 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:16:48.850530 ops/training.py:65 2019-01-16 20:16:48.850419: step 2737, loss = 0.67971 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:16:49.744818 ops/training.py:65 2019-01-16 20:16:49.744743: step 2738, loss = 0.68968 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:16:50.638465 ops/training.py:65 2019-01-16 20:16:50.638365: step 2739, loss = 0.69011 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:16:51.533072 ops/training.py:65 2019-01-16 20:16:51.532962: step 2740, loss = 0.69718 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:16:52.429158 ops/training.py:65 2019-01-16 20:16:52.429054: step 2741, loss = 0.68940 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:16:53.327612 ops/training.py:65 2019-01-16 20:16:53.327525: step 2742, loss = 0.68182 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:16:54.222041 ops/training.py:65 2019-01-16 20:16:54.221979: step 2743, loss = 0.69617 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:16:55.116187 ops/training.py:65 2019-01-16 20:16:55.116123: step 2744, loss = 0.69040 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:16:56.010277 ops/training.py:65 2019-01-16 20:16:56.010214: step 2745, loss = 0.69626 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:16:56.905347 ops/training.py:65 2019-01-16 20:16:56.905278: step 2746, loss = 0.69029 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:16:57.800959 ops/training.py:65 2019-01-16 20:16:57.800852: step 2747, loss = 0.70023 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:16:58.696249 ops/training.py:65 2019-01-16 20:16:58.696150: step 2748, loss = 0.69873 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:16:59.593589 ops/training.py:65 2019-01-16 20:16:59.593472: step 2749, loss = 0.69401 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:17:00.488541 ops/training.py:65 2019-01-16 20:17:00.488441: step 2750, loss = 0.69244 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:17:01.384188 ops/training.py:65 2019-01-16 20:17:01.384111: step 2751, loss = 0.69309 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:17:02.279185 ops/training.py:65 2019-01-16 20:17:02.279101: step 2752, loss = 0.68717 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:17:03.174167 ops/training.py:65 2019-01-16 20:17:03.174081: step 2753, loss = 0.68784 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:17:04.070390 ops/training.py:65 2019-01-16 20:17:04.070289: step 2754, loss = 0.69611 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:17:04.966242 ops/training.py:65 2019-01-16 20:17:04.966165: step 2755, loss = 0.69219 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:17:05.860428 ops/training.py:65 2019-01-16 20:17:05.860359: step 2756, loss = 0.68616 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:17:06.753861 ops/training.py:65 2019-01-16 20:17:06.753795: step 2757, loss = 0.69487 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:17:07.649205 ops/training.py:65 2019-01-16 20:17:07.649126: step 2758, loss = 0.69880 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:17:08.544222 ops/training.py:65 2019-01-16 20:17:08.544149: step 2759, loss = 0.69186 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:17:09.440080 ops/training.py:65 2019-01-16 20:17:09.440004: step 2760, loss = 0.69834 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:17:10.335812 ops/training.py:65 2019-01-16 20:17:10.335702: step 2761, loss = 0.69037 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:17:11.231688 ops/training.py:65 2019-01-16 20:17:11.231581: step 2762, loss = 0.68890 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:17:12.127234 ops/training.py:65 2019-01-16 20:17:12.127139: step 2763, loss = 0.69356 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:17:13.022202 ops/training.py:65 2019-01-16 20:17:13.022094: step 2764, loss = 0.69796 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:17:13.917258 ops/training.py:65 2019-01-16 20:17:13.917155: step 2765, loss = 0.69306 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:17:14.811565 ops/training.py:65 2019-01-16 20:17:14.811495: step 2766, loss = 0.68554 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:17:15.705565 ops/training.py:65 2019-01-16 20:17:15.705499: step 2767, loss = 0.69582 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:17:16.598146 ops/training.py:65 2019-01-16 20:17:16.598082: step 2768, loss = 0.69441 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:17:17.491901 ops/training.py:65 2019-01-16 20:17:17.491838: step 2769, loss = 0.71162 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.25
I1280 2019-01-16 20:17:18.389561 ops/training.py:65 2019-01-16 20:17:18.389454: step 2770, loss = 0.69836 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:17:19.285638 ops/training.py:65 2019-01-16 20:17:19.285578: step 2771, loss = 0.70108 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 20:17:20.179958 ops/training.py:65 2019-01-16 20:17:20.179897: step 2772, loss = 0.69089 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:17:21.073472 ops/training.py:65 2019-01-16 20:17:21.073407: step 2773, loss = 0.68596 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:17:21.968649 ops/training.py:65 2019-01-16 20:17:21.968589: step 2774, loss = 0.69242 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:17:22.866339 ops/training.py:65 2019-01-16 20:17:22.866239: step 2775, loss = 0.68553 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:17:23.763140 ops/training.py:65 2019-01-16 20:17:23.763066: step 2776, loss = 0.69896 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:17:24.658816 ops/training.py:65 2019-01-16 20:17:24.658749: step 2777, loss = 0.68997 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:17:25.554141 ops/training.py:65 2019-01-16 20:17:25.554066: step 2778, loss = 0.70854 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:17:26.451039 ops/training.py:65 2019-01-16 20:17:26.450936: step 2779, loss = 0.69716 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:17:27.346170 ops/training.py:65 2019-01-16 20:17:27.346064: step 2780, loss = 0.69254 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:17:28.241194 ops/training.py:65 2019-01-16 20:17:28.241105: step 2781, loss = 0.69191 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:17:29.135798 ops/training.py:65 2019-01-16 20:17:29.135706: step 2782, loss = 0.68331 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:17:30.031731 ops/training.py:65 2019-01-16 20:17:30.031638: step 2783, loss = 0.67961 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:17:30.926294 ops/training.py:65 2019-01-16 20:17:30.926233: step 2784, loss = 0.70258 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:17:31.821074 ops/training.py:65 2019-01-16 20:17:31.821041: step 2785, loss = 0.68738 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:17:32.716340 ops/training.py:65 2019-01-16 20:17:32.716271: step 2786, loss = 0.69398 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:17:33.613179 ops/training.py:65 2019-01-16 20:17:33.613087: step 2787, loss = 0.69112 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:17:34.507595 ops/training.py:65 2019-01-16 20:17:34.507505: step 2788, loss = 0.69360 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:17:35.403552 ops/training.py:65 2019-01-16 20:17:35.403468: step 2789, loss = 0.69007 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:17:36.297851 ops/training.py:65 2019-01-16 20:17:36.297816: step 2790, loss = 0.68567 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:17:37.192764 ops/training.py:65 2019-01-16 20:17:37.192710: step 2791, loss = 0.70678 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:17:38.088855 ops/training.py:65 2019-01-16 20:17:38.088817: step 2792, loss = 0.68308 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:17:38.982943 ops/training.py:65 2019-01-16 20:17:38.982911: step 2793, loss = 0.69115 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:17:39.878724 ops/training.py:65 2019-01-16 20:17:39.878692: step 2794, loss = 0.68447 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:17:40.775499 ops/training.py:65 2019-01-16 20:17:40.775455: step 2795, loss = 0.68511 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:17:41.670126 ops/training.py:65 2019-01-16 20:17:41.670093: step 2796, loss = 0.69908 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:17:42.566421 ops/training.py:65 2019-01-16 20:17:42.566389: step 2797, loss = 0.69055 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:17:43.460885 ops/training.py:65 2019-01-16 20:17:43.460852: step 2798, loss = 0.69921 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:17:44.355184 ops/training.py:65 2019-01-16 20:17:44.355133: step 2799, loss = 0.68966 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:17:45.249850 ops/training.py:65 2019-01-16 20:17:45.249812: step 2800, loss = 0.68837 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:17:46.144463 ops/training.py:65 2019-01-16 20:17:46.144430: step 2801, loss = 0.69462 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:17:47.039786 ops/training.py:65 2019-01-16 20:17:47.039755: step 2802, loss = 0.69202 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:17:47.935105 ops/training.py:65 2019-01-16 20:17:47.935073: step 2803, loss = 0.70093 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:17:48.829168 ops/training.py:65 2019-01-16 20:17:48.829138: step 2804, loss = 0.67621 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:17:49.721535 ops/training.py:65 2019-01-16 20:17:49.721505: step 2805, loss = 0.69032 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:17:50.614805 ops/training.py:65 2019-01-16 20:17:50.614772: step 2806, loss = 0.69070 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:17:51.507679 ops/training.py:65 2019-01-16 20:17:51.507648: step 2807, loss = 0.69628 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:17:52.402904 ops/training.py:65 2019-01-16 20:17:52.402862: step 2808, loss = 0.69553 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:17:53.298620 ops/training.py:65 2019-01-16 20:17:53.298589: step 2809, loss = 0.70993 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:17:54.193161 ops/training.py:65 2019-01-16 20:17:54.193131: step 2810, loss = 0.70229 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:17:55.087678 ops/training.py:65 2019-01-16 20:17:55.087646: step 2811, loss = 0.70200 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:17:55.982230 ops/training.py:65 2019-01-16 20:17:55.982189: step 2812, loss = 0.69000 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:17:56.875465 ops/training.py:65 2019-01-16 20:17:56.875425: step 2813, loss = 0.67686 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:17:57.771089 ops/training.py:65 2019-01-16 20:17:57.771042: step 2814, loss = 0.69394 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:17:58.664098 ops/training.py:65 2019-01-16 20:17:58.664054: step 2815, loss = 0.70591 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:17:59.558104 ops/training.py:65 2019-01-16 20:17:59.558070: step 2816, loss = 0.68878 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:18:00.454397 ops/training.py:65 2019-01-16 20:18:00.454362: step 2817, loss = 0.68556 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:18:01.351153 ops/training.py:65 2019-01-16 20:18:01.351117: step 2818, loss = 0.69447 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:18:02.248364 ops/training.py:65 2019-01-16 20:18:02.248335: step 2819, loss = 0.68912 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:18:03.144372 ops/training.py:65 2019-01-16 20:18:03.144343: step 2820, loss = 0.68827 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:18:04.039092 ops/training.py:65 2019-01-16 20:18:04.039062: step 2821, loss = 0.69074 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:18:04.934342 ops/training.py:65 2019-01-16 20:18:04.934314: step 2822, loss = 0.68965 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:18:05.830719 ops/training.py:65 2019-01-16 20:18:05.830688: step 2823, loss = 0.69299 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:18:06.725225 ops/training.py:65 2019-01-16 20:18:06.725196: step 2824, loss = 0.68641 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:18:07.621009 ops/training.py:65 2019-01-16 20:18:07.620940: step 2825, loss = 0.68950 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:18:08.515202 ops/training.py:65 2019-01-16 20:18:08.515126: step 2826, loss = 0.69132 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:18:09.408967 ops/training.py:65 2019-01-16 20:18:09.408927: step 2827, loss = 0.69951 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:18:10.304729 ops/training.py:65 2019-01-16 20:18:10.304681: step 2828, loss = 0.68829 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:18:11.200571 ops/training.py:65 2019-01-16 20:18:11.200491: step 2829, loss = 0.70154 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:18:12.098603 ops/training.py:65 2019-01-16 20:18:12.098503: step 2830, loss = 0.68717 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:18:12.994270 ops/training.py:65 2019-01-16 20:18:12.994196: step 2831, loss = 0.69015 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:18:13.891492 ops/training.py:65 2019-01-16 20:18:13.891388: step 2832, loss = 0.68038 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:18:14.786417 ops/training.py:65 2019-01-16 20:18:14.786346: step 2833, loss = 0.69174 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:18:15.681516 ops/training.py:65 2019-01-16 20:18:15.681440: step 2834, loss = 0.69110 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:18:16.576736 ops/training.py:65 2019-01-16 20:18:16.576670: step 2835, loss = 0.70068 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:18:17.471587 ops/training.py:65 2019-01-16 20:18:17.471524: step 2836, loss = 0.69945 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:18:18.366662 ops/training.py:65 2019-01-16 20:18:18.366600: step 2837, loss = 0.71382 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:18:19.261453 ops/training.py:65 2019-01-16 20:18:19.261389: step 2838, loss = 0.68479 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:18:20.155718 ops/training.py:65 2019-01-16 20:18:20.155661: step 2839, loss = 0.70219 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:18:21.050237 ops/training.py:65 2019-01-16 20:18:21.050174: step 2840, loss = 0.69653 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:18:21.944440 ops/training.py:65 2019-01-16 20:18:21.944379: step 2841, loss = 0.68767 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:18:22.838522 ops/training.py:65 2019-01-16 20:18:22.838462: step 2842, loss = 0.70945 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:18:23.732190 ops/training.py:65 2019-01-16 20:18:23.732124: step 2843, loss = 0.70152 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:18:24.626049 ops/training.py:65 2019-01-16 20:18:24.625978: step 2844, loss = 0.68224 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:18:25.521174 ops/training.py:65 2019-01-16 20:18:25.521103: step 2845, loss = 0.70425 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:18:26.415348 ops/training.py:65 2019-01-16 20:18:26.415278: step 2846, loss = 0.67741 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:18:27.309892 ops/training.py:65 2019-01-16 20:18:27.309825: step 2847, loss = 0.68720 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:18:28.204754 ops/training.py:65 2019-01-16 20:18:28.204687: step 2848, loss = 0.70612 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:18:29.099769 ops/training.py:65 2019-01-16 20:18:29.099701: step 2849, loss = 0.68971 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:18:29.995220 ops/training.py:65 2019-01-16 20:18:29.995152: step 2850, loss = 0.69136 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:18:30.889282 ops/training.py:65 2019-01-16 20:18:30.889214: step 2851, loss = 0.68383 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:18:31.784515 ops/training.py:65 2019-01-16 20:18:31.784447: step 2852, loss = 0.69968 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:18:32.679215 ops/training.py:65 2019-01-16 20:18:32.679168: step 2853, loss = 0.69071 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:18:33.572961 ops/training.py:65 2019-01-16 20:18:33.572899: step 2854, loss = 0.69878 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:18:34.466074 ops/training.py:65 2019-01-16 20:18:34.466014: step 2855, loss = 0.69965 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:18:35.359793 ops/training.py:65 2019-01-16 20:18:35.359737: step 2856, loss = 0.70040 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:18:36.253313 ops/training.py:65 2019-01-16 20:18:36.253246: step 2857, loss = 0.69097 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:18:37.146665 ops/training.py:65 2019-01-16 20:18:37.146589: step 2858, loss = 0.69524 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:18:38.040650 ops/training.py:65 2019-01-16 20:18:38.040544: step 2859, loss = 0.69840 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:18:38.936808 ops/training.py:65 2019-01-16 20:18:38.936704: step 2860, loss = 0.69655 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:18:39.832709 ops/training.py:65 2019-01-16 20:18:39.832633: step 2861, loss = 0.70011 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:18:40.727813 ops/training.py:65 2019-01-16 20:18:40.727740: step 2862, loss = 0.69085 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:18:41.623571 ops/training.py:65 2019-01-16 20:18:41.623468: step 2863, loss = 0.67822 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:18:42.517597 ops/training.py:65 2019-01-16 20:18:42.517531: step 2864, loss = 0.68810 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:18:43.411628 ops/training.py:65 2019-01-16 20:18:43.411555: step 2865, loss = 0.70303 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:18:44.307354 ops/training.py:65 2019-01-16 20:18:44.307281: step 2866, loss = 0.69505 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:18:45.202366 ops/training.py:65 2019-01-16 20:18:45.202312: step 2867, loss = 0.68568 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:18:46.096951 ops/training.py:65 2019-01-16 20:18:46.096879: step 2868, loss = 0.70056 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:18:46.990610 ops/training.py:65 2019-01-16 20:18:46.990550: step 2869, loss = 0.70118 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:18:47.884677 ops/training.py:65 2019-01-16 20:18:47.884614: step 2870, loss = 0.70281 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:18:48.779728 ops/training.py:65 2019-01-16 20:18:48.779625: step 2871, loss = 0.69742 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:18:49.674390 ops/training.py:65 2019-01-16 20:18:49.674346: step 2872, loss = 0.69553 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:18:50.567351 ops/training.py:65 2019-01-16 20:18:50.567289: step 2873, loss = 0.69948 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:18:51.460427 ops/training.py:65 2019-01-16 20:18:51.460369: step 2874, loss = 0.70391 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:18:52.354771 ops/training.py:65 2019-01-16 20:18:52.354704: step 2875, loss = 0.70539 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:18:53.250641 ops/training.py:65 2019-01-16 20:18:53.250535: step 2876, loss = 0.69788 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:18:54.146839 ops/training.py:65 2019-01-16 20:18:54.146740: step 2877, loss = 0.69256 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:18:55.043719 ops/training.py:65 2019-01-16 20:18:55.043610: step 2878, loss = 0.69403 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:18:55.939459 ops/training.py:65 2019-01-16 20:18:55.939363: step 2879, loss = 0.68881 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:18:56.834626 ops/training.py:65 2019-01-16 20:18:56.834525: step 2880, loss = 0.69515 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:18:57.731340 ops/training.py:65 2019-01-16 20:18:57.731237: step 2881, loss = 0.69572 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:18:58.627564 ops/training.py:65 2019-01-16 20:18:58.627485: step 2882, loss = 0.69659 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:18:59.521724 ops/training.py:65 2019-01-16 20:18:59.521662: step 2883, loss = 0.69514 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:19:00.417110 ops/training.py:65 2019-01-16 20:19:00.417049: step 2884, loss = 0.68878 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:19:01.314646 ops/training.py:65 2019-01-16 20:19:01.314543: step 2885, loss = 0.69213 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:19:02.211029 ops/training.py:65 2019-01-16 20:19:02.210939: step 2886, loss = 0.68789 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:19:03.106793 ops/training.py:65 2019-01-16 20:19:03.106711: step 2887, loss = 0.69086 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:19:04.001873 ops/training.py:65 2019-01-16 20:19:04.001767: step 2888, loss = 0.68721 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 20:19:04.896996 ops/training.py:65 2019-01-16 20:19:04.896912: step 2889, loss = 0.69857 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:19:05.793770 ops/training.py:65 2019-01-16 20:19:05.793642: step 2890, loss = 0.69559 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:19:06.690634 ops/training.py:65 2019-01-16 20:19:06.690532: step 2891, loss = 0.69306 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:19:07.585871 ops/training.py:65 2019-01-16 20:19:07.585794: step 2892, loss = 0.68752 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:19:08.482511 ops/training.py:65 2019-01-16 20:19:08.482407: step 2893, loss = 0.68850 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:19:09.376223 ops/training.py:65 2019-01-16 20:19:09.376124: step 2894, loss = 0.68334 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:19:10.269893 ops/training.py:65 2019-01-16 20:19:10.269810: step 2895, loss = 0.68905 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:19:11.165576 ops/training.py:65 2019-01-16 20:19:11.165475: step 2896, loss = 0.68900 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:19:12.062405 ops/training.py:65 2019-01-16 20:19:12.062310: step 2897, loss = 0.68837 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:19:12.958600 ops/training.py:65 2019-01-16 20:19:12.958497: step 2898, loss = 0.68033 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:19:13.854804 ops/training.py:65 2019-01-16 20:19:13.854699: step 2899, loss = 0.69136 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:19:14.748171 ops/training.py:65 2019-01-16 20:19:14.748068: step 2900, loss = 0.68917 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:19:15.642548 ops/training.py:65 2019-01-16 20:19:15.642447: step 2901, loss = 0.69393 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:19:16.536089 ops/training.py:65 2019-01-16 20:19:16.535994: step 2902, loss = 0.69751 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:19:17.430606 ops/training.py:65 2019-01-16 20:19:17.430506: step 2903, loss = 0.68720 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:19:18.324764 ops/training.py:65 2019-01-16 20:19:18.324667: step 2904, loss = 0.69591 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:19:19.219844 ops/training.py:65 2019-01-16 20:19:19.219743: step 2905, loss = 0.69450 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:19:20.116020 ops/training.py:65 2019-01-16 20:19:20.115939: step 2906, loss = 0.69761 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:19:21.011792 ops/training.py:65 2019-01-16 20:19:21.011689: step 2907, loss = 0.68888 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:19:21.908209 ops/training.py:65 2019-01-16 20:19:21.908119: step 2908, loss = 0.68528 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:19:22.803931 ops/training.py:65 2019-01-16 20:19:22.803827: step 2909, loss = 0.69584 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:19:23.698438 ops/training.py:65 2019-01-16 20:19:23.698328: step 2910, loss = 0.70009 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:19:24.593871 ops/training.py:65 2019-01-16 20:19:24.593803: step 2911, loss = 0.69366 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:19:25.489379 ops/training.py:65 2019-01-16 20:19:25.489275: step 2912, loss = 0.68771 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:19:26.385301 ops/training.py:65 2019-01-16 20:19:26.385198: step 2913, loss = 0.69472 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:19:27.280857 ops/training.py:65 2019-01-16 20:19:27.280761: step 2914, loss = 0.68286 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:19:28.177517 ops/training.py:65 2019-01-16 20:19:28.177420: step 2915, loss = 0.69716 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:19:29.073468 ops/training.py:65 2019-01-16 20:19:29.073361: step 2916, loss = 0.70009 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:19:29.968054 ops/training.py:65 2019-01-16 20:19:29.967993: step 2917, loss = 0.69947 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:19:30.861391 ops/training.py:65 2019-01-16 20:19:30.861326: step 2918, loss = 0.71023 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.25
I1280 2019-01-16 20:19:31.754994 ops/training.py:65 2019-01-16 20:19:31.754933: step 2919, loss = 0.70315 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:19:32.648846 ops/training.py:65 2019-01-16 20:19:32.648775: step 2920, loss = 0.68861 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:19:33.542045 ops/training.py:65 2019-01-16 20:19:33.541945: step 2921, loss = 0.70100 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:19:34.435378 ops/training.py:65 2019-01-16 20:19:34.435286: step 2922, loss = 0.69500 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:19:35.332724 ops/training.py:65 2019-01-16 20:19:35.332641: step 2923, loss = 0.69520 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:19:36.229327 ops/training.py:65 2019-01-16 20:19:36.229225: step 2924, loss = 0.69017 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:19:37.124758 ops/training.py:65 2019-01-16 20:19:37.124673: step 2925, loss = 0.68629 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:19:38.022345 ops/training.py:65 2019-01-16 20:19:38.022242: step 2926, loss = 0.69001 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:19:38.917290 ops/training.py:65 2019-01-16 20:19:38.917218: step 2927, loss = 0.70019 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:19:39.811928 ops/training.py:65 2019-01-16 20:19:39.811868: step 2928, loss = 0.68687 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:19:40.707115 ops/training.py:65 2019-01-16 20:19:40.707042: step 2929, loss = 0.69102 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:19:41.601825 ops/training.py:65 2019-01-16 20:19:41.601721: step 2930, loss = 0.69873 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:19:42.497012 ops/training.py:65 2019-01-16 20:19:42.496946: step 2931, loss = 0.67905 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 20:19:43.393506 ops/training.py:65 2019-01-16 20:19:43.393392: step 2932, loss = 0.69848 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:19:44.291029 ops/training.py:65 2019-01-16 20:19:44.290920: step 2933, loss = 0.68757 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:19:45.188275 ops/training.py:65 2019-01-16 20:19:45.188175: step 2934, loss = 0.68982 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:19:46.084560 ops/training.py:65 2019-01-16 20:19:46.084457: step 2935, loss = 0.70330 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:19:46.980117 ops/training.py:65 2019-01-16 20:19:46.980016: step 2936, loss = 0.70022 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:19:47.875453 ops/training.py:65 2019-01-16 20:19:47.875369: step 2937, loss = 0.68997 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:19:48.772563 ops/training.py:65 2019-01-16 20:19:48.772457: step 2938, loss = 0.69216 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:19:49.667556 ops/training.py:65 2019-01-16 20:19:49.667449: step 2939, loss = 0.69029 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:19:50.563012 ops/training.py:65 2019-01-16 20:19:50.562943: step 2940, loss = 0.69198 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:19:51.458443 ops/training.py:65 2019-01-16 20:19:51.458366: step 2941, loss = 0.69712 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:19:52.355274 ops/training.py:65 2019-01-16 20:19:52.355173: step 2942, loss = 0.69438 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:19:53.252407 ops/training.py:65 2019-01-16 20:19:53.252300: step 2943, loss = 0.69594 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:19:54.149852 ops/training.py:65 2019-01-16 20:19:54.149792: step 2944, loss = 0.68910 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:19:55.045164 ops/training.py:65 2019-01-16 20:19:55.045106: step 2945, loss = 0.69648 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:19:55.944569 ops/training.py:65 2019-01-16 20:19:55.944458: step 2946, loss = 0.69364 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:19:56.843143 ops/training.py:65 2019-01-16 20:19:56.843039: step 2947, loss = 0.69258 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:19:57.740012 ops/training.py:65 2019-01-16 20:19:57.739903: step 2948, loss = 0.69656 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:19:58.636722 ops/training.py:65 2019-01-16 20:19:58.636615: step 2949, loss = 0.69235 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:19:59.533763 ops/training.py:65 2019-01-16 20:19:59.533623: step 2950, loss = 0.69392 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:20:00.433137 ops/training.py:65 2019-01-16 20:20:00.433043: step 2951, loss = 0.69164 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:20:01.326899 ops/training.py:65 2019-01-16 20:20:01.326803: step 2952, loss = 0.69356 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:20:02.221642 ops/training.py:65 2019-01-16 20:20:02.221556: step 2953, loss = 0.69062 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:20:03.117521 ops/training.py:65 2019-01-16 20:20:03.117423: step 2954, loss = 0.69775 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:20:04.012723 ops/training.py:65 2019-01-16 20:20:04.012625: step 2955, loss = 0.69081 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:20:04.908961 ops/training.py:65 2019-01-16 20:20:04.908860: step 2956, loss = 0.68939 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:20:05.806737 ops/training.py:65 2019-01-16 20:20:05.806640: step 2957, loss = 0.69485 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:20:06.704758 ops/training.py:65 2019-01-16 20:20:06.704666: step 2958, loss = 0.68393 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:20:07.601076 ops/training.py:65 2019-01-16 20:20:07.600985: step 2959, loss = 0.68821 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:20:08.495508 ops/training.py:65 2019-01-16 20:20:08.495404: step 2960, loss = 0.68681 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:20:09.390894 ops/training.py:65 2019-01-16 20:20:09.390796: step 2961, loss = 0.70025 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:20:10.286316 ops/training.py:65 2019-01-16 20:20:10.286217: step 2962, loss = 0.69490 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:20:11.181517 ops/training.py:65 2019-01-16 20:20:11.181423: step 2963, loss = 0.69025 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:20:12.076778 ops/training.py:65 2019-01-16 20:20:12.076683: step 2964, loss = 0.70104 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:20:12.970694 ops/training.py:65 2019-01-16 20:20:12.970600: step 2965, loss = 0.69576 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:20:13.865072 ops/training.py:65 2019-01-16 20:20:13.864969: step 2966, loss = 0.69782 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:20:14.758630 ops/training.py:65 2019-01-16 20:20:14.758539: step 2967, loss = 0.69019 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:20:15.651484 ops/training.py:65 2019-01-16 20:20:15.651390: step 2968, loss = 0.68415 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:20:16.544483 ops/training.py:65 2019-01-16 20:20:16.544389: step 2969, loss = 0.68618 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:20:17.437120 ops/training.py:65 2019-01-16 20:20:17.437024: step 2970, loss = 0.68671 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:20:18.330452 ops/training.py:65 2019-01-16 20:20:18.330354: step 2971, loss = 0.69121 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:20:19.223343 ops/training.py:65 2019-01-16 20:20:19.223248: step 2972, loss = 0.68500 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 20:20:20.116646 ops/training.py:65 2019-01-16 20:20:20.116551: step 2973, loss = 0.69048 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:20:21.009545 ops/training.py:65 2019-01-16 20:20:21.009451: step 2974, loss = 0.69533 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:20:21.903409 ops/training.py:65 2019-01-16 20:20:21.903320: step 2975, loss = 0.69786 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:20:22.799959 ops/training.py:65 2019-01-16 20:20:22.799851: step 2976, loss = 0.68528 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:20:23.694739 ops/training.py:65 2019-01-16 20:20:23.694640: step 2977, loss = 0.70280 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:20:24.591131 ops/training.py:65 2019-01-16 20:20:24.591027: step 2978, loss = 0.68943 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:20:25.486314 ops/training.py:65 2019-01-16 20:20:25.486216: step 2979, loss = 0.68624 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:20:26.381413 ops/training.py:65 2019-01-16 20:20:26.381323: step 2980, loss = 0.70399 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:20:27.277411 ops/training.py:65 2019-01-16 20:20:27.277322: step 2981, loss = 0.69485 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:20:28.173680 ops/training.py:65 2019-01-16 20:20:28.173588: step 2982, loss = 0.69541 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:20:29.069901 ops/training.py:65 2019-01-16 20:20:29.069803: step 2983, loss = 0.68450 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:20:29.964774 ops/training.py:65 2019-01-16 20:20:29.964676: step 2984, loss = 0.69540 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:20:30.860432 ops/training.py:65 2019-01-16 20:20:30.860332: step 2985, loss = 0.69151 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:20:31.755702 ops/training.py:65 2019-01-16 20:20:31.755568: step 2986, loss = 0.68498 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:20:32.649754 ops/training.py:65 2019-01-16 20:20:32.649648: step 2987, loss = 0.69205 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:20:33.543236 ops/training.py:65 2019-01-16 20:20:33.543124: step 2988, loss = 0.69640 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:20:34.436794 ops/training.py:65 2019-01-16 20:20:34.436686: step 2989, loss = 0.68298 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:20:35.331411 ops/training.py:65 2019-01-16 20:20:35.331305: step 2990, loss = 0.69428 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:20:36.228253 ops/training.py:65 2019-01-16 20:20:36.228162: step 2991, loss = 0.68925 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:20:37.124005 ops/training.py:65 2019-01-16 20:20:37.123926: step 2992, loss = 0.69435 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:20:38.021768 ops/training.py:65 2019-01-16 20:20:38.021680: step 2993, loss = 0.69800 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:20:38.915995 ops/training.py:65 2019-01-16 20:20:38.915892: step 2994, loss = 0.69353 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:20:39.810570 ops/training.py:65 2019-01-16 20:20:39.810460: step 2995, loss = 0.69714 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:20:40.706206 ops/training.py:65 2019-01-16 20:20:40.706116: step 2996, loss = 0.69193 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:20:41.601096 ops/training.py:65 2019-01-16 20:20:41.601003: step 2997, loss = 0.69865 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:20:42.496606 ops/training.py:65 2019-01-16 20:20:42.496514: step 2998, loss = 0.68988 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:20:43.390941 ops/training.py:65 2019-01-16 20:20:43.390867: step 2999, loss = 0.69166 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:20:44.286087 ops/training.py:65 2019-01-16 20:20:44.285986: step 3000, loss = 0.69719 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:20:45.182462 ops/training.py:65 2019-01-16 20:20:45.182360: step 3001, loss = 0.69775 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:20:46.076974 ops/training.py:65 2019-01-16 20:20:46.076885: step 3002, loss = 0.70092 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:20:46.971794 ops/training.py:65 2019-01-16 20:20:46.971711: step 3003, loss = 0.69729 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:20:47.867602 ops/training.py:65 2019-01-16 20:20:47.867551: step 3004, loss = 0.68854 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:20:48.763356 ops/training.py:65 2019-01-16 20:20:48.763249: step 3005, loss = 0.69192 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:20:49.657651 ops/training.py:65 2019-01-16 20:20:49.657591: step 3006, loss = 0.69225 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:20:50.550325 ops/training.py:65 2019-01-16 20:20:50.550265: step 3007, loss = 0.68712 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:20:51.445301 ops/training.py:65 2019-01-16 20:20:51.445241: step 3008, loss = 0.70877 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:20:52.341206 ops/training.py:65 2019-01-16 20:20:52.341111: step 3009, loss = 0.68858 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:20:53.237082 ops/training.py:65 2019-01-16 20:20:53.236981: step 3010, loss = 0.69555 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:20:54.134695 ops/training.py:65 2019-01-16 20:20:54.134591: step 3011, loss = 0.69057 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:20:55.028834 ops/training.py:65 2019-01-16 20:20:55.028733: step 3012, loss = 0.69101 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:20:55.924164 ops/training.py:65 2019-01-16 20:20:55.924085: step 3013, loss = 0.70279 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:20:56.821862 ops/training.py:65 2019-01-16 20:20:56.821765: step 3014, loss = 0.68478 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:20:57.717859 ops/training.py:65 2019-01-16 20:20:57.717785: step 3015, loss = 0.69515 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:20:58.612576 ops/training.py:65 2019-01-16 20:20:58.612514: step 3016, loss = 0.69917 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:20:59.506777 ops/training.py:65 2019-01-16 20:20:59.506715: step 3017, loss = 0.68552 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:21:00.400921 ops/training.py:65 2019-01-16 20:21:00.400861: step 3018, loss = 0.68699 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:21:01.294975 ops/training.py:65 2019-01-16 20:21:01.294914: step 3019, loss = 0.69144 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:21:02.189537 ops/training.py:65 2019-01-16 20:21:02.189449: step 3020, loss = 0.70379 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:21:03.085248 ops/training.py:65 2019-01-16 20:21:03.085165: step 3021, loss = 0.70061 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:21:03.981194 ops/training.py:65 2019-01-16 20:21:03.981118: step 3022, loss = 0.68315 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:21:04.877718 ops/training.py:65 2019-01-16 20:21:04.877643: step 3023, loss = 0.68908 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:21:05.772596 ops/training.py:65 2019-01-16 20:21:05.772525: step 3024, loss = 0.68732 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:21:06.667793 ops/training.py:65 2019-01-16 20:21:06.667736: step 3025, loss = 0.70722 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:21:07.561560 ops/training.py:65 2019-01-16 20:21:07.561484: step 3026, loss = 0.70587 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:21:08.456867 ops/training.py:65 2019-01-16 20:21:08.456759: step 3027, loss = 0.69038 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:21:09.352565 ops/training.py:65 2019-01-16 20:21:09.352484: step 3028, loss = 0.69357 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:21:10.249396 ops/training.py:65 2019-01-16 20:21:10.249296: step 3029, loss = 0.69365 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:21:11.145569 ops/training.py:65 2019-01-16 20:21:11.145463: step 3030, loss = 0.69959 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:21:12.040819 ops/training.py:65 2019-01-16 20:21:12.040720: step 3031, loss = 0.70887 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:21:12.936022 ops/training.py:65 2019-01-16 20:21:12.935918: step 3032, loss = 0.69067 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:21:13.831911 ops/training.py:65 2019-01-16 20:21:13.831832: step 3033, loss = 0.68796 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:21:14.726696 ops/training.py:65 2019-01-16 20:21:14.726623: step 3034, loss = 0.69298 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:21:15.621706 ops/training.py:65 2019-01-16 20:21:15.621640: step 3035, loss = 0.68687 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:21:16.515987 ops/training.py:65 2019-01-16 20:21:16.515924: step 3036, loss = 0.69979 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:21:17.411716 ops/training.py:65 2019-01-16 20:21:17.411656: step 3037, loss = 0.69255 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:21:18.307145 ops/training.py:65 2019-01-16 20:21:18.307070: step 3038, loss = 0.68037 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:21:19.201744 ops/training.py:65 2019-01-16 20:21:19.201689: step 3039, loss = 0.69336 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:21:20.097058 ops/training.py:65 2019-01-16 20:21:20.096997: step 3040, loss = 0.70137 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:21:20.991585 ops/training.py:65 2019-01-16 20:21:20.991534: step 3041, loss = 0.68343 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:21:21.887055 ops/training.py:65 2019-01-16 20:21:21.887004: step 3042, loss = 0.69296 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:21:22.784870 ops/training.py:65 2019-01-16 20:21:22.784762: step 3043, loss = 0.68889 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:21:23.683115 ops/training.py:65 2019-01-16 20:21:23.683005: step 3044, loss = 0.69056 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:21:24.579757 ops/training.py:65 2019-01-16 20:21:24.579650: step 3045, loss = 0.70037 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:21:25.475905 ops/training.py:65 2019-01-16 20:21:25.475846: step 3046, loss = 0.69135 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:21:26.371516 ops/training.py:65 2019-01-16 20:21:26.371409: step 3047, loss = 0.69924 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:21:27.267505 ops/training.py:65 2019-01-16 20:21:27.267405: step 3048, loss = 0.69146 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:21:28.162500 ops/training.py:65 2019-01-16 20:21:28.162441: step 3049, loss = 0.69726 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:21:29.056433 ops/training.py:65 2019-01-16 20:21:29.056349: step 3050, loss = 0.68333 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 20:21:29.951230 ops/training.py:65 2019-01-16 20:21:29.951127: step 3051, loss = 0.67876 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:21:30.847140 ops/training.py:65 2019-01-16 20:21:30.846997: step 3052, loss = 0.69643 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:21:31.741298 ops/training.py:65 2019-01-16 20:21:31.741232: step 3053, loss = 0.70349 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:21:32.635504 ops/training.py:65 2019-01-16 20:21:32.635441: step 3054, loss = 0.68568 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:21:33.529191 ops/training.py:65 2019-01-16 20:21:33.529131: step 3055, loss = 0.68634 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:21:34.425456 ops/training.py:65 2019-01-16 20:21:34.425393: step 3056, loss = 0.69170 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:21:35.322810 ops/training.py:65 2019-01-16 20:21:35.322715: step 3057, loss = 0.69200 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:21:36.218100 ops/training.py:65 2019-01-16 20:21:36.218030: step 3058, loss = 0.70147 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:21:37.111372 ops/training.py:65 2019-01-16 20:21:37.111274: step 3059, loss = 0.69903 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:21:38.007124 ops/training.py:65 2019-01-16 20:21:38.007035: step 3060, loss = 0.70824 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:21:38.903258 ops/training.py:65 2019-01-16 20:21:38.903159: step 3061, loss = 0.69974 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:21:39.799529 ops/training.py:65 2019-01-16 20:21:39.799463: step 3062, loss = 0.70247 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:21:40.694477 ops/training.py:65 2019-01-16 20:21:40.694419: step 3063, loss = 0.70223 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:21:41.587869 ops/training.py:65 2019-01-16 20:21:41.587814: step 3064, loss = 0.68842 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:21:42.481722 ops/training.py:65 2019-01-16 20:21:42.481655: step 3065, loss = 0.70579 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:21:43.378203 ops/training.py:65 2019-01-16 20:21:43.378098: step 3066, loss = 0.68291 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:21:44.274564 ops/training.py:65 2019-01-16 20:21:44.274453: step 3067, loss = 0.68990 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:21:45.169572 ops/training.py:65 2019-01-16 20:21:45.169467: step 3068, loss = 0.69377 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:21:46.065079 ops/training.py:65 2019-01-16 20:21:46.064975: step 3069, loss = 0.68680 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:21:46.960509 ops/training.py:65 2019-01-16 20:21:46.960448: step 3070, loss = 0.68817 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:21:47.855650 ops/training.py:65 2019-01-16 20:21:47.855603: step 3071, loss = 0.69321 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:21:48.749795 ops/training.py:65 2019-01-16 20:21:48.749738: step 3072, loss = 0.70328 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:21:49.643634 ops/training.py:65 2019-01-16 20:21:49.643576: step 3073, loss = 0.69493 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:21:50.538607 ops/training.py:65 2019-01-16 20:21:50.538538: step 3074, loss = 0.69902 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:21:51.433378 ops/training.py:65 2019-01-16 20:21:51.433270: step 3075, loss = 0.70111 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:21:52.328054 ops/training.py:65 2019-01-16 20:21:52.327992: step 3076, loss = 0.67367 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.78125
I1280 2019-01-16 20:21:53.223105 ops/training.py:65 2019-01-16 20:21:53.223051: step 3077, loss = 0.71182 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:21:54.116864 ops/training.py:65 2019-01-16 20:21:54.116810: step 3078, loss = 0.69781 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:21:55.011307 ops/training.py:65 2019-01-16 20:21:55.011259: step 3079, loss = 0.70385 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:21:55.907215 ops/training.py:65 2019-01-16 20:21:55.907115: step 3080, loss = 0.68367 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:21:56.802351 ops/training.py:65 2019-01-16 20:21:56.802247: step 3081, loss = 0.70478 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:21:57.699621 ops/training.py:65 2019-01-16 20:21:57.699513: step 3082, loss = 0.69137 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:21:58.595985 ops/training.py:65 2019-01-16 20:21:58.595878: step 3083, loss = 0.71399 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 20:21:59.492169 ops/training.py:65 2019-01-16 20:21:59.492113: step 3084, loss = 0.70795 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:22:00.386312 ops/training.py:65 2019-01-16 20:22:00.386252: step 3085, loss = 0.70002 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:22:01.280039 ops/training.py:65 2019-01-16 20:22:01.279982: step 3086, loss = 0.69934 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:22:02.175705 ops/training.py:65 2019-01-16 20:22:02.175653: step 3087, loss = 0.69031 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:22:03.073542 ops/training.py:65 2019-01-16 20:22:03.073452: step 3088, loss = 0.68905 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:22:03.970603 ops/training.py:65 2019-01-16 20:22:03.970494: step 3089, loss = 0.68840 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:22:04.867576 ops/training.py:65 2019-01-16 20:22:04.867528: step 3090, loss = 0.70641 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:22:05.761871 ops/training.py:65 2019-01-16 20:22:05.761805: step 3091, loss = 0.67228 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.78125
I1280 2019-01-16 20:22:06.657399 ops/training.py:65 2019-01-16 20:22:06.657341: step 3092, loss = 0.68491 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:22:07.551193 ops/training.py:65 2019-01-16 20:22:07.551117: step 3093, loss = 0.69182 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:22:08.446192 ops/training.py:65 2019-01-16 20:22:08.446096: step 3094, loss = 0.70212 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:22:09.340590 ops/training.py:65 2019-01-16 20:22:09.340524: step 3095, loss = 0.69900 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:22:10.236276 ops/training.py:65 2019-01-16 20:22:10.236214: step 3096, loss = 0.69236 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:22:11.133689 ops/training.py:65 2019-01-16 20:22:11.133587: step 3097, loss = 0.68569 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:22:12.032387 ops/training.py:65 2019-01-16 20:22:12.032275: step 3098, loss = 0.68953 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:22:12.928971 ops/training.py:65 2019-01-16 20:22:12.928834: step 3099, loss = 0.68975 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:22:13.826346 ops/training.py:65 2019-01-16 20:22:13.826240: step 3100, loss = 0.70298 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:22:14.723140 ops/training.py:65 2019-01-16 20:22:14.722997: step 3101, loss = 0.69407 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:22:15.619769 ops/training.py:65 2019-01-16 20:22:15.619666: step 3102, loss = 0.68831 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:22:16.514315 ops/training.py:65 2019-01-16 20:22:16.514185: step 3103, loss = 0.70261 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:22:17.408599 ops/training.py:65 2019-01-16 20:22:17.408490: step 3104, loss = 0.69769 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:22:18.302751 ops/training.py:65 2019-01-16 20:22:18.302666: step 3105, loss = 0.70141 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:22:19.196213 ops/training.py:65 2019-01-16 20:22:19.196118: step 3106, loss = 0.69301 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:22:20.090465 ops/training.py:65 2019-01-16 20:22:20.090361: step 3107, loss = 0.70380 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:22:20.983964 ops/training.py:65 2019-01-16 20:22:20.983866: step 3108, loss = 0.69255 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:22:21.877700 ops/training.py:65 2019-01-16 20:22:21.877610: step 3109, loss = 0.69712 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:22:22.771139 ops/training.py:65 2019-01-16 20:22:22.771045: step 3110, loss = 0.69073 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:22:23.664301 ops/training.py:65 2019-01-16 20:22:23.664201: step 3111, loss = 0.68990 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:22:24.558895 ops/training.py:65 2019-01-16 20:22:24.558800: step 3112, loss = 0.71019 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:22:25.453793 ops/training.py:65 2019-01-16 20:22:25.453694: step 3113, loss = 0.68269 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:22:26.349120 ops/training.py:65 2019-01-16 20:22:26.349016: step 3114, loss = 0.69729 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:22:27.245221 ops/training.py:65 2019-01-16 20:22:27.245116: step 3115, loss = 0.67263 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.78125
I1280 2019-01-16 20:22:28.141786 ops/training.py:65 2019-01-16 20:22:28.141683: step 3116, loss = 0.69561 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:22:29.037637 ops/training.py:65 2019-01-16 20:22:29.037543: step 3117, loss = 0.70231 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:22:29.932590 ops/training.py:65 2019-01-16 20:22:29.932497: step 3118, loss = 0.70953 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:22:30.827253 ops/training.py:65 2019-01-16 20:22:30.827153: step 3119, loss = 0.69748 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:22:31.721435 ops/training.py:65 2019-01-16 20:22:31.721341: step 3120, loss = 0.69216 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:22:32.615302 ops/training.py:65 2019-01-16 20:22:32.615203: step 3121, loss = 0.71409 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:22:33.509532 ops/training.py:65 2019-01-16 20:22:33.509431: step 3122, loss = 0.70010 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:22:34.404869 ops/training.py:65 2019-01-16 20:22:34.404776: step 3123, loss = 0.69845 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:22:35.302521 ops/training.py:65 2019-01-16 20:22:35.302421: step 3124, loss = 0.69230 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:22:36.198558 ops/training.py:65 2019-01-16 20:22:36.198458: step 3125, loss = 0.68819 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:22:37.093228 ops/training.py:65 2019-01-16 20:22:37.093128: step 3126, loss = 0.70063 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:22:37.990724 ops/training.py:65 2019-01-16 20:22:37.990626: step 3127, loss = 0.70310 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:22:38.887361 ops/training.py:65 2019-01-16 20:22:38.887264: step 3128, loss = 0.69842 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:22:39.784093 ops/training.py:65 2019-01-16 20:22:39.783994: step 3129, loss = 0.68496 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:22:40.678303 ops/training.py:65 2019-01-16 20:22:40.678201: step 3130, loss = 0.69553 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:22:41.574099 ops/training.py:65 2019-01-16 20:22:41.573997: step 3131, loss = 0.69330 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:22:42.469151 ops/training.py:65 2019-01-16 20:22:42.469053: step 3132, loss = 0.69461 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:22:43.364555 ops/training.py:65 2019-01-16 20:22:43.364457: step 3133, loss = 0.69626 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:22:44.259751 ops/training.py:65 2019-01-16 20:22:44.259645: step 3134, loss = 0.69582 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:22:45.155447 ops/training.py:65 2019-01-16 20:22:45.155346: step 3135, loss = 0.69278 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:22:46.052838 ops/training.py:65 2019-01-16 20:22:46.052735: step 3136, loss = 0.69394 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:22:46.948710 ops/training.py:65 2019-01-16 20:22:46.948605: step 3137, loss = 0.69900 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:22:47.844528 ops/training.py:65 2019-01-16 20:22:47.844424: step 3138, loss = 0.68828 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:22:48.741087 ops/training.py:65 2019-01-16 20:22:48.740948: step 3139, loss = 0.69296 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:22:49.635932 ops/training.py:65 2019-01-16 20:22:49.635789: step 3140, loss = 0.69426 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:22:50.530727 ops/training.py:65 2019-01-16 20:22:50.530631: step 3141, loss = 0.69467 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:22:51.428616 ops/training.py:65 2019-01-16 20:22:51.428512: step 3142, loss = 0.69229 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:22:52.323941 ops/training.py:65 2019-01-16 20:22:52.323838: step 3143, loss = 0.69309 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:22:53.218430 ops/training.py:65 2019-01-16 20:22:53.218377: step 3144, loss = 0.68987 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:22:54.114355 ops/training.py:65 2019-01-16 20:22:54.114247: step 3145, loss = 0.70032 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:22:55.009951 ops/training.py:65 2019-01-16 20:22:55.009851: step 3146, loss = 0.68857 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:22:55.905357 ops/training.py:65 2019-01-16 20:22:55.905256: step 3147, loss = 0.69383 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:22:56.800929 ops/training.py:65 2019-01-16 20:22:56.800827: step 3148, loss = 0.69331 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:22:57.697169 ops/training.py:65 2019-01-16 20:22:57.697055: step 3149, loss = 0.69830 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:22:58.594452 ops/training.py:65 2019-01-16 20:22:58.594356: step 3150, loss = 0.68668 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:22:59.489125 ops/training.py:65 2019-01-16 20:22:59.489021: step 3151, loss = 0.69140 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:23:00.385071 ops/training.py:65 2019-01-16 20:23:00.384969: step 3152, loss = 0.69600 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:23:01.281236 ops/training.py:65 2019-01-16 20:23:01.281095: step 3153, loss = 0.69604 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:23:02.176852 ops/training.py:65 2019-01-16 20:23:02.176766: step 3154, loss = 0.69449 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:23:03.071739 ops/training.py:65 2019-01-16 20:23:03.071671: step 3155, loss = 0.69739 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:23:03.965583 ops/training.py:65 2019-01-16 20:23:03.965530: step 3156, loss = 0.69718 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:23:04.859952 ops/training.py:65 2019-01-16 20:23:04.859897: step 3157, loss = 0.69018 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:23:05.754451 ops/training.py:65 2019-01-16 20:23:05.754388: step 3158, loss = 0.69303 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:23:06.649998 ops/training.py:65 2019-01-16 20:23:06.649881: step 3159, loss = 0.69349 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:23:07.544046 ops/training.py:65 2019-01-16 20:23:07.543957: step 3160, loss = 0.69000 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:23:08.441481 ops/training.py:65 2019-01-16 20:23:08.441378: step 3161, loss = 0.69064 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:23:09.338049 ops/training.py:65 2019-01-16 20:23:09.337942: step 3162, loss = 0.68760 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:23:10.234252 ops/training.py:65 2019-01-16 20:23:10.234153: step 3163, loss = 0.69176 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:23:11.128672 ops/training.py:65 2019-01-16 20:23:11.128599: step 3164, loss = 0.69943 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:23:12.023114 ops/training.py:65 2019-01-16 20:23:12.023047: step 3165, loss = 0.69193 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:23:12.919186 ops/training.py:65 2019-01-16 20:23:12.919076: step 3166, loss = 0.69273 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:23:13.814722 ops/training.py:65 2019-01-16 20:23:13.814662: step 3167, loss = 0.69692 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:23:14.707938 ops/training.py:65 2019-01-16 20:23:14.707868: step 3168, loss = 0.69226 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:23:15.603752 ops/training.py:65 2019-01-16 20:23:15.603647: step 3169, loss = 0.70110 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:23:16.501004 ops/training.py:65 2019-01-16 20:23:16.500901: step 3170, loss = 0.69374 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:23:17.396201 ops/training.py:65 2019-01-16 20:23:17.396098: step 3171, loss = 0.70060 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:23:18.291121 ops/training.py:65 2019-01-16 20:23:18.291043: step 3172, loss = 0.69242 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:23:19.186234 ops/training.py:65 2019-01-16 20:23:19.186131: step 3173, loss = 0.69518 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:23:20.083313 ops/training.py:65 2019-01-16 20:23:20.083225: step 3174, loss = 0.69642 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:23:20.978543 ops/training.py:65 2019-01-16 20:23:20.978438: step 3175, loss = 0.69579 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:23:21.872721 ops/training.py:65 2019-01-16 20:23:21.872628: step 3176, loss = 0.69082 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:23:22.771130 ops/training.py:65 2019-01-16 20:23:22.771024: step 3177, loss = 0.69861 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:23:23.669571 ops/training.py:65 2019-01-16 20:23:23.669466: step 3178, loss = 0.69098 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:23:24.565876 ops/training.py:65 2019-01-16 20:23:24.565805: step 3179, loss = 0.69417 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:23:25.461379 ops/training.py:65 2019-01-16 20:23:25.461277: step 3180, loss = 0.69623 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:23:26.356915 ops/training.py:65 2019-01-16 20:23:26.356806: step 3181, loss = 0.69513 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:23:27.252551 ops/training.py:65 2019-01-16 20:23:27.252492: step 3182, loss = 0.69875 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:23:28.147868 ops/training.py:65 2019-01-16 20:23:28.147813: step 3183, loss = 0.69221 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:23:29.042334 ops/training.py:65 2019-01-16 20:23:29.042272: step 3184, loss = 0.70661 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 20:23:29.936740 ops/training.py:65 2019-01-16 20:23:29.936634: step 3185, loss = 0.69321 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:23:30.830845 ops/training.py:65 2019-01-16 20:23:30.830786: step 3186, loss = 0.69478 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:23:31.724889 ops/training.py:65 2019-01-16 20:23:31.724820: step 3187, loss = 0.69508 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:23:32.619411 ops/training.py:65 2019-01-16 20:23:32.619319: step 3188, loss = 0.69338 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:23:33.515047 ops/training.py:65 2019-01-16 20:23:33.514936: step 3189, loss = 0.69331 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:23:34.409938 ops/training.py:65 2019-01-16 20:23:34.409835: step 3190, loss = 0.68987 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:23:35.305151 ops/training.py:65 2019-01-16 20:23:35.305066: step 3191, loss = 0.69523 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:23:36.200054 ops/training.py:65 2019-01-16 20:23:36.199928: step 3192, loss = 0.68673 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:23:37.096564 ops/training.py:65 2019-01-16 20:23:37.096401: step 3193, loss = 0.69886 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:23:37.994329 ops/training.py:65 2019-01-16 20:23:37.994237: step 3194, loss = 0.69259 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:23:38.891670 ops/training.py:65 2019-01-16 20:23:38.891573: step 3195, loss = 0.69896 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:23:39.788379 ops/training.py:65 2019-01-16 20:23:39.788274: step 3196, loss = 0.68102 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:23:40.685161 ops/training.py:65 2019-01-16 20:23:40.685057: step 3197, loss = 0.70018 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:23:41.580609 ops/training.py:65 2019-01-16 20:23:41.580509: step 3198, loss = 0.69053 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:23:42.475259 ops/training.py:65 2019-01-16 20:23:42.475191: step 3199, loss = 0.69191 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:23:43.372493 ops/training.py:65 2019-01-16 20:23:43.372388: step 3200, loss = 0.69055 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:23:44.268144 ops/training.py:65 2019-01-16 20:23:44.268033: step 3201, loss = 0.68493 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:23:45.164247 ops/training.py:65 2019-01-16 20:23:45.164145: step 3202, loss = 0.68844 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:23:46.058639 ops/training.py:65 2019-01-16 20:23:46.058534: step 3203, loss = 0.70229 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:23:46.956354 ops/training.py:65 2019-01-16 20:23:46.956249: step 3204, loss = 0.69792 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:23:47.853329 ops/training.py:65 2019-01-16 20:23:47.853226: step 3205, loss = 0.68884 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:23:48.748238 ops/training.py:65 2019-01-16 20:23:48.748128: step 3206, loss = 0.69527 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:23:49.643985 ops/training.py:65 2019-01-16 20:23:49.643885: step 3207, loss = 0.69596 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:23:50.540137 ops/training.py:65 2019-01-16 20:23:50.540060: step 3208, loss = 0.68654 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:23:51.435165 ops/training.py:65 2019-01-16 20:23:51.435070: step 3209, loss = 0.68790 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:23:52.330253 ops/training.py:65 2019-01-16 20:23:52.330159: step 3210, loss = 0.69739 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:23:53.227973 ops/training.py:65 2019-01-16 20:23:53.227871: step 3211, loss = 0.69289 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:23:54.124508 ops/training.py:65 2019-01-16 20:23:54.124408: step 3212, loss = 0.68882 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:23:55.019578 ops/training.py:65 2019-01-16 20:23:55.019494: step 3213, loss = 0.69664 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:23:55.915479 ops/training.py:65 2019-01-16 20:23:55.915374: step 3214, loss = 0.68791 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:23:56.810845 ops/training.py:65 2019-01-16 20:23:56.810741: step 3215, loss = 0.69786 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:23:57.706660 ops/training.py:65 2019-01-16 20:23:57.706588: step 3216, loss = 0.69407 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:23:58.602035 ops/training.py:65 2019-01-16 20:23:58.601962: step 3217, loss = 0.68456 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:23:59.498319 ops/training.py:65 2019-01-16 20:23:59.498210: step 3218, loss = 0.69384 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:24:00.397312 ops/training.py:65 2019-01-16 20:24:00.397207: step 3219, loss = 0.68760 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:24:01.292999 ops/training.py:65 2019-01-16 20:24:01.292898: step 3220, loss = 0.68388 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:24:02.190673 ops/training.py:65 2019-01-16 20:24:02.190586: step 3221, loss = 0.69635 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:24:03.088414 ops/training.py:65 2019-01-16 20:24:03.088332: step 3222, loss = 0.68912 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:24:03.985638 ops/training.py:65 2019-01-16 20:24:03.985534: step 3223, loss = 0.68986 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:24:04.882887 ops/training.py:65 2019-01-16 20:24:04.882813: step 3224, loss = 0.69226 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:24:05.778460 ops/training.py:65 2019-01-16 20:24:05.778381: step 3225, loss = 0.69546 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:24:06.673000 ops/training.py:65 2019-01-16 20:24:06.672939: step 3226, loss = 0.69731 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:24:07.568212 ops/training.py:65 2019-01-16 20:24:07.568137: step 3227, loss = 0.68637 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:24:08.463322 ops/training.py:65 2019-01-16 20:24:08.463213: step 3228, loss = 0.70809 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:24:09.360971 ops/training.py:65 2019-01-16 20:24:09.360870: step 3229, loss = 0.69744 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:24:10.255801 ops/training.py:65 2019-01-16 20:24:10.255698: step 3230, loss = 0.68459 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:24:11.150643 ops/training.py:65 2019-01-16 20:24:11.150521: step 3231, loss = 0.68778 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:24:12.052550 ops/training.py:65 2019-01-16 20:24:12.052445: step 3232, loss = 0.69669 (35.5 examples/sec; 0.900 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:24:12.948499 ops/training.py:65 2019-01-16 20:24:12.948398: step 3233, loss = 0.69117 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:24:13.843954 ops/training.py:65 2019-01-16 20:24:13.843845: step 3234, loss = 0.69200 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:24:14.740301 ops/training.py:65 2019-01-16 20:24:14.740194: step 3235, loss = 0.70073 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:24:15.636600 ops/training.py:65 2019-01-16 20:24:15.636496: step 3236, loss = 0.69208 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:24:16.533050 ops/training.py:65 2019-01-16 20:24:16.532967: step 3237, loss = 0.68763 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:24:17.427387 ops/training.py:65 2019-01-16 20:24:17.427303: step 3238, loss = 0.70146 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:24:18.323298 ops/training.py:65 2019-01-16 20:24:18.323216: step 3239, loss = 0.69068 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:24:19.221136 ops/training.py:65 2019-01-16 20:24:19.221018: step 3240, loss = 0.69286 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:24:20.119161 ops/training.py:65 2019-01-16 20:24:20.119085: step 3241, loss = 0.68513 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:24:21.015508 ops/training.py:65 2019-01-16 20:24:21.015424: step 3242, loss = 0.69837 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:24:21.913057 ops/training.py:65 2019-01-16 20:24:21.912964: step 3243, loss = 0.69479 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:24:22.809784 ops/training.py:65 2019-01-16 20:24:22.809678: step 3244, loss = 0.70064 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:24:23.706193 ops/training.py:65 2019-01-16 20:24:23.706092: step 3245, loss = 0.69759 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:24:24.601588 ops/training.py:65 2019-01-16 20:24:24.601510: step 3246, loss = 0.71304 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:24:25.500280 ops/training.py:65 2019-01-16 20:24:25.500177: step 3247, loss = 0.70385 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:24:26.395154 ops/training.py:65 2019-01-16 20:24:26.395078: step 3248, loss = 0.69870 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:24:27.289289 ops/training.py:65 2019-01-16 20:24:27.289214: step 3249, loss = 0.69945 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:24:28.183095 ops/training.py:65 2019-01-16 20:24:28.183023: step 3250, loss = 0.70351 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:24:29.078180 ops/training.py:65 2019-01-16 20:24:29.078073: step 3251, loss = 0.68657 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:24:29.976336 ops/training.py:65 2019-01-16 20:24:29.976194: step 3252, loss = 0.69950 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:24:30.873261 ops/training.py:65 2019-01-16 20:24:30.873161: step 3253, loss = 0.68670 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:24:31.770765 ops/training.py:65 2019-01-16 20:24:31.770669: step 3254, loss = 0.69412 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:24:32.667644 ops/training.py:65 2019-01-16 20:24:32.667569: step 3255, loss = 0.67272 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:24:33.562169 ops/training.py:65 2019-01-16 20:24:33.562103: step 3256, loss = 0.69997 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:24:34.455711 ops/training.py:65 2019-01-16 20:24:34.455646: step 3257, loss = 0.69296 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:24:35.349679 ops/training.py:65 2019-01-16 20:24:35.349618: step 3258, loss = 0.67945 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.75
I1280 2019-01-16 20:24:36.244675 ops/training.py:65 2019-01-16 20:24:36.244611: step 3259, loss = 0.69403 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:24:37.139220 ops/training.py:65 2019-01-16 20:24:37.139158: step 3260, loss = 0.70115 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:24:38.033487 ops/training.py:65 2019-01-16 20:24:38.033407: step 3261, loss = 0.68947 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:24:38.929591 ops/training.py:65 2019-01-16 20:24:38.929493: step 3262, loss = 0.69355 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:24:39.825190 ops/training.py:65 2019-01-16 20:24:39.825085: step 3263, loss = 0.69637 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:24:40.720726 ops/training.py:65 2019-01-16 20:24:40.720627: step 3264, loss = 0.68547 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:24:41.616706 ops/training.py:65 2019-01-16 20:24:41.616603: step 3265, loss = 0.68928 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:24:42.513774 ops/training.py:65 2019-01-16 20:24:42.513685: step 3266, loss = 0.69275 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:24:43.409868 ops/training.py:65 2019-01-16 20:24:43.409765: step 3267, loss = 0.69300 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:24:44.305460 ops/training.py:65 2019-01-16 20:24:44.305361: step 3268, loss = 0.70166 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:24:45.200671 ops/training.py:65 2019-01-16 20:24:45.200574: step 3269, loss = 0.69102 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:24:46.095803 ops/training.py:65 2019-01-16 20:24:46.095701: step 3270, loss = 0.69325 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:24:46.993399 ops/training.py:65 2019-01-16 20:24:46.993295: step 3271, loss = 0.69242 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:24:47.889133 ops/training.py:65 2019-01-16 20:24:47.889033: step 3272, loss = 0.68970 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:24:48.784560 ops/training.py:65 2019-01-16 20:24:48.784464: step 3273, loss = 0.69724 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:24:49.679673 ops/training.py:65 2019-01-16 20:24:49.679574: step 3274, loss = 0.69376 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:24:50.574850 ops/training.py:65 2019-01-16 20:24:50.574756: step 3275, loss = 0.70006 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:24:51.470947 ops/training.py:65 2019-01-16 20:24:51.470842: step 3276, loss = 0.69664 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:24:52.365428 ops/training.py:65 2019-01-16 20:24:52.365325: step 3277, loss = 0.68964 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:24:53.261528 ops/training.py:65 2019-01-16 20:24:53.261429: step 3278, loss = 0.69778 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:24:54.156755 ops/training.py:65 2019-01-16 20:24:54.156652: step 3279, loss = 0.69206 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:24:55.051238 ops/training.py:65 2019-01-16 20:24:55.051151: step 3280, loss = 0.69080 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:24:55.946780 ops/training.py:65 2019-01-16 20:24:55.946681: step 3281, loss = 0.68772 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:24:56.842642 ops/training.py:65 2019-01-16 20:24:56.842543: step 3282, loss = 0.69115 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:24:57.738381 ops/training.py:65 2019-01-16 20:24:57.738281: step 3283, loss = 0.68979 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:24:58.634386 ops/training.py:65 2019-01-16 20:24:58.634287: step 3284, loss = 0.68778 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:24:59.529467 ops/training.py:65 2019-01-16 20:24:59.529374: step 3285, loss = 0.68324 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:25:00.424971 ops/training.py:65 2019-01-16 20:25:00.424873: step 3286, loss = 0.69118 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:25:01.320891 ops/training.py:65 2019-01-16 20:25:01.320788: step 3287, loss = 0.69068 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:25:02.216804 ops/training.py:65 2019-01-16 20:25:02.216712: step 3288, loss = 0.68867 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:25:03.112696 ops/training.py:65 2019-01-16 20:25:03.112619: step 3289, loss = 0.69062 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:25:04.011495 ops/training.py:65 2019-01-16 20:25:04.011398: step 3290, loss = 0.68663 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:25:04.905801 ops/training.py:65 2019-01-16 20:25:04.905700: step 3291, loss = 0.69697 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:25:05.801349 ops/training.py:65 2019-01-16 20:25:05.801246: step 3292, loss = 0.69500 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:25:06.696941 ops/training.py:65 2019-01-16 20:25:06.696840: step 3293, loss = 0.68966 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:25:07.594101 ops/training.py:65 2019-01-16 20:25:07.594013: step 3294, loss = 0.70099 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:25:08.490457 ops/training.py:65 2019-01-16 20:25:08.490288: step 3295, loss = 0.70033 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:25:09.386306 ops/training.py:65 2019-01-16 20:25:09.386197: step 3296, loss = 0.69604 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:25:10.281760 ops/training.py:65 2019-01-16 20:25:10.281657: step 3297, loss = 0.69559 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:25:11.177224 ops/training.py:65 2019-01-16 20:25:11.177118: step 3298, loss = 0.69519 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:25:12.074327 ops/training.py:65 2019-01-16 20:25:12.074223: step 3299, loss = 0.69520 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:25:12.969534 ops/training.py:65 2019-01-16 20:25:12.969428: step 3300, loss = 0.69781 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:25:13.866640 ops/training.py:65 2019-01-16 20:25:13.866539: step 3301, loss = 0.69132 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:25:14.761678 ops/training.py:65 2019-01-16 20:25:14.761572: step 3302, loss = 0.70579 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:25:15.656621 ops/training.py:65 2019-01-16 20:25:15.656517: step 3303, loss = 0.68894 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:25:16.552483 ops/training.py:65 2019-01-16 20:25:16.552384: step 3304, loss = 0.69007 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:25:17.447553 ops/training.py:65 2019-01-16 20:25:17.447454: step 3305, loss = 0.69668 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:25:18.342540 ops/training.py:65 2019-01-16 20:25:18.342449: step 3306, loss = 0.69326 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:25:19.236039 ops/training.py:65 2019-01-16 20:25:19.235942: step 3307, loss = 0.69111 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:25:20.130443 ops/training.py:65 2019-01-16 20:25:20.130371: step 3308, loss = 0.69243 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:25:21.027294 ops/training.py:65 2019-01-16 20:25:21.027194: step 3309, loss = 0.68081 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:25:21.922542 ops/training.py:65 2019-01-16 20:25:21.922442: step 3310, loss = 0.69199 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:25:22.816245 ops/training.py:65 2019-01-16 20:25:22.816149: step 3311, loss = 0.69109 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:25:23.710986 ops/training.py:65 2019-01-16 20:25:23.710923: step 3312, loss = 0.69389 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:25:24.605081 ops/training.py:65 2019-01-16 20:25:24.605029: step 3313, loss = 0.69237 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:25:25.502841 ops/training.py:65 2019-01-16 20:25:25.502697: step 3314, loss = 0.69509 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:25:26.399843 ops/training.py:65 2019-01-16 20:25:26.399733: step 3315, loss = 0.69540 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:25:27.296521 ops/training.py:65 2019-01-16 20:25:27.296413: step 3316, loss = 0.69507 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:25:28.192738 ops/training.py:65 2019-01-16 20:25:28.192630: step 3317, loss = 0.68936 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:25:29.090006 ops/training.py:65 2019-01-16 20:25:29.089892: step 3318, loss = 0.69780 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:25:29.986784 ops/training.py:65 2019-01-16 20:25:29.986677: step 3319, loss = 0.68897 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:25:30.883605 ops/training.py:65 2019-01-16 20:25:30.883502: step 3320, loss = 0.69467 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:25:31.779683 ops/training.py:65 2019-01-16 20:25:31.779576: step 3321, loss = 0.69261 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:25:32.675291 ops/training.py:65 2019-01-16 20:25:32.675185: step 3322, loss = 0.69878 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:25:33.571672 ops/training.py:65 2019-01-16 20:25:33.571559: step 3323, loss = 0.69075 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:25:34.468120 ops/training.py:65 2019-01-16 20:25:34.468013: step 3324, loss = 0.69208 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:25:35.363995 ops/training.py:65 2019-01-16 20:25:35.363912: step 3325, loss = 0.68968 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:25:36.260552 ops/training.py:65 2019-01-16 20:25:36.260442: step 3326, loss = 0.69204 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:25:37.155289 ops/training.py:65 2019-01-16 20:25:37.155181: step 3327, loss = 0.69135 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:25:38.050182 ops/training.py:65 2019-01-16 20:25:38.050083: step 3328, loss = 0.68809 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:25:38.946156 ops/training.py:65 2019-01-16 20:25:38.946053: step 3329, loss = 0.69044 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:25:39.840713 ops/training.py:65 2019-01-16 20:25:39.840611: step 3330, loss = 0.69610 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:25:40.735427 ops/training.py:65 2019-01-16 20:25:40.735324: step 3331, loss = 0.69407 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:25:41.630476 ops/training.py:65 2019-01-16 20:25:41.630374: step 3332, loss = 0.69171 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:25:42.527265 ops/training.py:65 2019-01-16 20:25:42.527166: step 3333, loss = 0.69831 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:25:43.422645 ops/training.py:65 2019-01-16 20:25:43.422540: step 3334, loss = 0.69363 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:25:44.318267 ops/training.py:65 2019-01-16 20:25:44.318160: step 3335, loss = 0.68653 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:25:45.212789 ops/training.py:65 2019-01-16 20:25:45.212685: step 3336, loss = 0.69304 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:25:46.107796 ops/training.py:65 2019-01-16 20:25:46.107738: step 3337, loss = 0.69316 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:25:47.002782 ops/training.py:65 2019-01-16 20:25:47.002672: step 3338, loss = 0.69849 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:25:47.900829 ops/training.py:65 2019-01-16 20:25:47.900720: step 3339, loss = 0.69401 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:25:48.798059 ops/training.py:65 2019-01-16 20:25:48.797952: step 3340, loss = 0.69403 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:25:49.694971 ops/training.py:65 2019-01-16 20:25:49.694853: step 3341, loss = 0.69640 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:25:50.592357 ops/training.py:65 2019-01-16 20:25:50.592249: step 3342, loss = 0.69206 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:25:51.488660 ops/training.py:65 2019-01-16 20:25:51.488543: step 3343, loss = 0.69373 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:25:52.386178 ops/training.py:65 2019-01-16 20:25:52.386076: step 3344, loss = 0.69512 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:25:53.282212 ops/training.py:65 2019-01-16 20:25:53.282104: step 3345, loss = 0.68633 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:25:54.179830 ops/training.py:65 2019-01-16 20:25:54.179722: step 3346, loss = 0.69213 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:25:55.076728 ops/training.py:65 2019-01-16 20:25:55.076618: step 3347, loss = 0.70353 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:25:55.974401 ops/training.py:65 2019-01-16 20:25:55.974290: step 3348, loss = 0.69975 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:25:56.872745 ops/training.py:65 2019-01-16 20:25:56.872633: step 3349, loss = 0.69318 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:25:57.768403 ops/training.py:65 2019-01-16 20:25:57.768302: step 3350, loss = 0.69375 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:25:58.666180 ops/training.py:65 2019-01-16 20:25:58.666070: step 3351, loss = 0.69729 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:25:59.563606 ops/training.py:65 2019-01-16 20:25:59.563493: step 3352, loss = 0.69948 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 20:26:00.459714 ops/training.py:65 2019-01-16 20:26:00.459611: step 3353, loss = 0.69828 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:26:01.357517 ops/training.py:65 2019-01-16 20:26:01.357405: step 3354, loss = 0.69501 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:26:02.254702 ops/training.py:65 2019-01-16 20:26:02.254612: step 3355, loss = 0.69811 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:26:03.150880 ops/training.py:65 2019-01-16 20:26:03.150798: step 3356, loss = 0.69267 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:26:04.046104 ops/training.py:65 2019-01-16 20:26:04.046028: step 3357, loss = 0.69378 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:26:04.942990 ops/training.py:65 2019-01-16 20:26:04.942850: step 3358, loss = 0.69652 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:26:05.841023 ops/training.py:65 2019-01-16 20:26:05.840917: step 3359, loss = 0.69120 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:26:06.736518 ops/training.py:65 2019-01-16 20:26:06.736412: step 3360, loss = 0.69305 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:26:07.632696 ops/training.py:65 2019-01-16 20:26:07.632609: step 3361, loss = 0.69185 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:26:08.530267 ops/training.py:65 2019-01-16 20:26:08.530163: step 3362, loss = 0.69069 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:26:09.426181 ops/training.py:65 2019-01-16 20:26:09.426077: step 3363, loss = 0.69225 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:26:10.320487 ops/training.py:65 2019-01-16 20:26:10.320378: step 3364, loss = 0.69398 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:26:11.215719 ops/training.py:65 2019-01-16 20:26:11.215662: step 3365, loss = 0.69421 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:26:12.110207 ops/training.py:65 2019-01-16 20:26:12.110102: step 3366, loss = 0.69765 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:26:13.005082 ops/training.py:65 2019-01-16 20:26:13.005000: step 3367, loss = 0.69104 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:26:13.902321 ops/training.py:65 2019-01-16 20:26:13.902211: step 3368, loss = 0.69770 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:26:14.797463 ops/training.py:65 2019-01-16 20:26:14.797350: step 3369, loss = 0.69647 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:26:15.694565 ops/training.py:65 2019-01-16 20:26:15.694453: step 3370, loss = 0.69348 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:26:16.589417 ops/training.py:65 2019-01-16 20:26:16.589306: step 3371, loss = 0.69407 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:26:17.486229 ops/training.py:65 2019-01-16 20:26:17.486132: step 3372, loss = 0.69594 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:26:18.382136 ops/training.py:65 2019-01-16 20:26:18.382023: step 3373, loss = 0.69858 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:26:19.276890 ops/training.py:65 2019-01-16 20:26:19.276799: step 3374, loss = 0.69875 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:26:20.171602 ops/training.py:65 2019-01-16 20:26:20.171491: step 3375, loss = 0.69377 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:26:21.069022 ops/training.py:65 2019-01-16 20:26:21.068917: step 3376, loss = 0.69269 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:26:21.965764 ops/training.py:65 2019-01-16 20:26:21.965654: step 3377, loss = 0.69902 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 20:26:22.863266 ops/training.py:65 2019-01-16 20:26:22.863153: step 3378, loss = 0.69128 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:26:23.759916 ops/training.py:65 2019-01-16 20:26:23.759806: step 3379, loss = 0.68724 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:26:24.660487 ops/training.py:65 2019-01-16 20:26:24.660318: step 3380, loss = 0.68200 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.75
I1280 2019-01-16 20:26:25.559968 ops/training.py:65 2019-01-16 20:26:25.559843: step 3381, loss = 0.69460 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:26:26.454146 ops/training.py:65 2019-01-16 20:26:26.454020: step 3382, loss = 0.69075 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:26:27.350397 ops/training.py:65 2019-01-16 20:26:27.350296: step 3383, loss = 0.69027 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:26:28.245424 ops/training.py:65 2019-01-16 20:26:28.245322: step 3384, loss = 0.69351 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:26:29.142586 ops/training.py:65 2019-01-16 20:26:29.142482: step 3385, loss = 0.69232 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:26:30.038325 ops/training.py:65 2019-01-16 20:26:30.038220: step 3386, loss = 0.69409 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:26:30.940766 ops/training.py:65 2019-01-16 20:26:30.940656: step 3387, loss = 0.69447 (35.5 examples/sec; 0.901 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:26:31.836477 ops/training.py:65 2019-01-16 20:26:31.836382: step 3388, loss = 0.69706 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:26:32.733010 ops/training.py:65 2019-01-16 20:26:32.732895: step 3389, loss = 0.69478 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:26:33.629433 ops/training.py:65 2019-01-16 20:26:33.629327: step 3390, loss = 0.69440 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:26:34.524828 ops/training.py:65 2019-01-16 20:26:34.524720: step 3391, loss = 0.68656 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:26:35.421392 ops/training.py:65 2019-01-16 20:26:35.421284: step 3392, loss = 0.68768 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:26:36.315450 ops/training.py:65 2019-01-16 20:26:36.315348: step 3393, loss = 0.69318 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:26:37.210031 ops/training.py:65 2019-01-16 20:26:37.209927: step 3394, loss = 0.70072 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:26:38.103174 ops/training.py:65 2019-01-16 20:26:38.103085: step 3395, loss = 0.69350 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:26:38.997250 ops/training.py:65 2019-01-16 20:26:38.997142: step 3396, loss = 0.68712 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:26:39.891633 ops/training.py:65 2019-01-16 20:26:39.891522: step 3397, loss = 0.68432 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:26:40.790928 ops/training.py:65 2019-01-16 20:26:40.790822: step 3398, loss = 0.69106 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:26:41.687361 ops/training.py:65 2019-01-16 20:26:41.687256: step 3399, loss = 0.69365 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:26:42.584256 ops/training.py:65 2019-01-16 20:26:42.584152: step 3400, loss = 0.69330 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:26:43.480269 ops/training.py:65 2019-01-16 20:26:43.480164: step 3401, loss = 0.69966 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:26:44.376373 ops/training.py:65 2019-01-16 20:26:44.376265: step 3402, loss = 0.69162 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:26:45.271320 ops/training.py:65 2019-01-16 20:26:45.271184: step 3403, loss = 0.69141 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:26:46.166201 ops/training.py:65 2019-01-16 20:26:46.166099: step 3404, loss = 0.68520 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:26:47.064093 ops/training.py:65 2019-01-16 20:26:47.064012: step 3405, loss = 0.68985 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:26:47.960277 ops/training.py:65 2019-01-16 20:26:47.960173: step 3406, loss = 0.69614 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:26:48.857054 ops/training.py:65 2019-01-16 20:26:48.856950: step 3407, loss = 0.70926 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:26:49.752819 ops/training.py:65 2019-01-16 20:26:49.752716: step 3408, loss = 0.69209 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:26:50.648320 ops/training.py:65 2019-01-16 20:26:50.648216: step 3409, loss = 0.69507 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:26:51.542973 ops/training.py:65 2019-01-16 20:26:51.542868: step 3410, loss = 0.69459 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:26:52.440757 ops/training.py:65 2019-01-16 20:26:52.440629: step 3411, loss = 0.70033 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:26:53.335711 ops/training.py:65 2019-01-16 20:26:53.335609: step 3412, loss = 0.68861 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:26:54.231106 ops/training.py:65 2019-01-16 20:26:54.230999: step 3413, loss = 0.69934 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:26:55.127494 ops/training.py:65 2019-01-16 20:26:55.127396: step 3414, loss = 0.68814 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:26:56.022888 ops/training.py:65 2019-01-16 20:26:56.022782: step 3415, loss = 0.69753 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:26:56.918170 ops/training.py:65 2019-01-16 20:26:56.918070: step 3416, loss = 0.70076 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:26:57.813852 ops/training.py:65 2019-01-16 20:26:57.813743: step 3417, loss = 0.69962 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:26:58.709111 ops/training.py:65 2019-01-16 20:26:58.709003: step 3418, loss = 0.69196 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:26:59.603692 ops/training.py:65 2019-01-16 20:26:59.603593: step 3419, loss = 0.69758 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:27:00.499597 ops/training.py:65 2019-01-16 20:27:00.499562: step 3420, loss = 0.70422 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:27:01.394753 ops/training.py:65 2019-01-16 20:27:01.394720: step 3421, loss = 0.69131 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:27:02.289597 ops/training.py:65 2019-01-16 20:27:02.289568: step 3422, loss = 0.68678 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:27:03.183898 ops/training.py:65 2019-01-16 20:27:03.183869: step 3423, loss = 0.69997 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:27:04.077693 ops/training.py:65 2019-01-16 20:27:04.077664: step 3424, loss = 0.69114 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:27:04.974869 ops/training.py:65 2019-01-16 20:27:04.974838: step 3425, loss = 0.68772 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:27:05.870906 ops/training.py:65 2019-01-16 20:27:05.870877: step 3426, loss = 0.68556 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:27:06.766107 ops/training.py:65 2019-01-16 20:27:06.766079: step 3427, loss = 0.69911 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:27:07.661012 ops/training.py:65 2019-01-16 20:27:07.660954: step 3428, loss = 0.69440 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:27:08.555355 ops/training.py:65 2019-01-16 20:27:08.555327: step 3429, loss = 0.68336 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:27:09.450712 ops/training.py:65 2019-01-16 20:27:09.450683: step 3430, loss = 0.68928 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:27:10.345707 ops/training.py:65 2019-01-16 20:27:10.345679: step 3431, loss = 0.69219 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:27:11.239193 ops/training.py:65 2019-01-16 20:27:11.239099: step 3432, loss = 0.69092 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:27:12.135990 ops/training.py:65 2019-01-16 20:27:12.135952: step 3433, loss = 0.69851 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:27:13.031508 ops/training.py:65 2019-01-16 20:27:13.031478: step 3434, loss = 0.69320 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:27:13.928174 ops/training.py:65 2019-01-16 20:27:13.928146: step 3435, loss = 0.69517 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:27:14.823024 ops/training.py:65 2019-01-16 20:27:14.822993: step 3436, loss = 0.69769 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:27:15.719043 ops/training.py:65 2019-01-16 20:27:15.719013: step 3437, loss = 0.68997 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:27:16.615347 ops/training.py:65 2019-01-16 20:27:16.615316: step 3438, loss = 0.69315 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:27:17.511752 ops/training.py:65 2019-01-16 20:27:17.511722: step 3439, loss = 0.69245 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:27:18.405637 ops/training.py:65 2019-01-16 20:27:18.405559: step 3440, loss = 0.69608 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:27:19.301447 ops/training.py:65 2019-01-16 20:27:19.301384: step 3441, loss = 0.69587 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:27:20.197899 ops/training.py:65 2019-01-16 20:27:20.197848: step 3442, loss = 0.69632 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:27:21.093570 ops/training.py:65 2019-01-16 20:27:21.093522: step 3443, loss = 0.69967 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:27:21.989923 ops/training.py:65 2019-01-16 20:27:21.989867: step 3444, loss = 0.69310 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:27:22.886917 ops/training.py:65 2019-01-16 20:27:22.886880: step 3445, loss = 0.68285 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:27:23.782210 ops/training.py:65 2019-01-16 20:27:23.782138: step 3446, loss = 0.68388 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:27:24.675526 ops/training.py:65 2019-01-16 20:27:24.675456: step 3447, loss = 0.69716 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:27:25.569598 ops/training.py:65 2019-01-16 20:27:25.569541: step 3448, loss = 0.68777 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:27:26.462701 ops/training.py:65 2019-01-16 20:27:26.462646: step 3449, loss = 0.70599 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:27:27.357588 ops/training.py:65 2019-01-16 20:27:27.357555: step 3450, loss = 0.68404 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:27:28.255344 ops/training.py:65 2019-01-16 20:27:28.255314: step 3451, loss = 0.69937 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:27:29.150694 ops/training.py:65 2019-01-16 20:27:29.150663: step 3452, loss = 0.70541 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:27:30.046258 ops/training.py:65 2019-01-16 20:27:30.046231: step 3453, loss = 0.69510 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:27:30.943654 ops/training.py:65 2019-01-16 20:27:30.943599: step 3454, loss = 0.69346 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:27:31.839733 ops/training.py:65 2019-01-16 20:27:31.839650: step 3455, loss = 0.70401 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:27:32.734808 ops/training.py:65 2019-01-16 20:27:32.734737: step 3456, loss = 0.69085 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:27:33.629804 ops/training.py:65 2019-01-16 20:27:33.629722: step 3457, loss = 0.68840 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:27:34.524866 ops/training.py:65 2019-01-16 20:27:34.524816: step 3458, loss = 0.70041 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:27:35.419988 ops/training.py:65 2019-01-16 20:27:35.419949: step 3459, loss = 0.67787 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:27:36.316060 ops/training.py:65 2019-01-16 20:27:36.316000: step 3460, loss = 0.69511 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:27:37.210973 ops/training.py:65 2019-01-16 20:27:37.210874: step 3461, loss = 0.70260 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:27:38.105997 ops/training.py:65 2019-01-16 20:27:38.105912: step 3462, loss = 0.68693 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:27:39.002582 ops/training.py:65 2019-01-16 20:27:39.002540: step 3463, loss = 0.69405 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:27:39.897717 ops/training.py:65 2019-01-16 20:27:39.897648: step 3464, loss = 0.69665 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:27:40.791914 ops/training.py:65 2019-01-16 20:27:40.791854: step 3465, loss = 0.70270 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:27:41.686245 ops/training.py:65 2019-01-16 20:27:41.686181: step 3466, loss = 0.69049 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:27:42.580315 ops/training.py:65 2019-01-16 20:27:42.580253: step 3467, loss = 0.69953 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:27:43.474195 ops/training.py:65 2019-01-16 20:27:43.474125: step 3468, loss = 0.70287 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:27:44.367740 ops/training.py:65 2019-01-16 20:27:44.367660: step 3469, loss = 0.69786 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:27:45.261059 ops/training.py:65 2019-01-16 20:27:45.260999: step 3470, loss = 0.69166 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:27:46.155100 ops/training.py:65 2019-01-16 20:27:46.155034: step 3471, loss = 0.69731 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:27:47.049535 ops/training.py:65 2019-01-16 20:27:47.049470: step 3472, loss = 0.67920 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:27:47.943511 ops/training.py:65 2019-01-16 20:27:47.943451: step 3473, loss = 0.69136 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:27:48.838821 ops/training.py:65 2019-01-16 20:27:48.838778: step 3474, loss = 0.69983 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:27:49.734257 ops/training.py:65 2019-01-16 20:27:49.734190: step 3475, loss = 0.68681 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:27:50.631567 ops/training.py:65 2019-01-16 20:27:50.631458: step 3476, loss = 0.69378 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:27:51.529521 ops/training.py:65 2019-01-16 20:27:51.529409: step 3477, loss = 0.70041 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:27:52.428197 ops/training.py:65 2019-01-16 20:27:52.428095: step 3478, loss = 0.68684 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:27:53.323523 ops/training.py:65 2019-01-16 20:27:53.323462: step 3479, loss = 0.69309 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:27:54.221270 ops/training.py:65 2019-01-16 20:27:54.221160: step 3480, loss = 0.69666 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:27:55.117012 ops/training.py:65 2019-01-16 20:27:55.116921: step 3481, loss = 0.69032 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:27:56.011941 ops/training.py:65 2019-01-16 20:27:56.011871: step 3482, loss = 0.69016 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:27:56.906990 ops/training.py:65 2019-01-16 20:27:56.906925: step 3483, loss = 0.68459 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:27:57.801320 ops/training.py:65 2019-01-16 20:27:57.801255: step 3484, loss = 0.69556 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:27:58.695885 ops/training.py:65 2019-01-16 20:27:58.695817: step 3485, loss = 0.68951 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:27:59.591129 ops/training.py:65 2019-01-16 20:27:59.591033: step 3486, loss = 0.69725 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:28:00.486312 ops/training.py:65 2019-01-16 20:28:00.486248: step 3487, loss = 0.69174 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:28:01.380405 ops/training.py:65 2019-01-16 20:28:01.380338: step 3488, loss = 0.70632 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:28:02.274998 ops/training.py:65 2019-01-16 20:28:02.274915: step 3489, loss = 0.69744 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:28:03.170382 ops/training.py:65 2019-01-16 20:28:03.170272: step 3490, loss = 0.69069 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:28:04.065998 ops/training.py:65 2019-01-16 20:28:04.065899: step 3491, loss = 0.68138 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 20:28:04.964097 ops/training.py:65 2019-01-16 20:28:04.963984: step 3492, loss = 0.68710 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:28:05.860990 ops/training.py:65 2019-01-16 20:28:05.860918: step 3493, loss = 0.69317 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:28:06.756448 ops/training.py:65 2019-01-16 20:28:06.756370: step 3494, loss = 0.70367 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:28:07.650754 ops/training.py:65 2019-01-16 20:28:07.650673: step 3495, loss = 0.70167 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:28:08.546792 ops/training.py:65 2019-01-16 20:28:08.546691: step 3496, loss = 0.69434 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:28:09.443873 ops/training.py:65 2019-01-16 20:28:09.443766: step 3497, loss = 0.69645 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:28:10.340290 ops/training.py:65 2019-01-16 20:28:10.340179: step 3498, loss = 0.68388 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:28:11.235130 ops/training.py:65 2019-01-16 20:28:11.235057: step 3499, loss = 0.69334 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:28:12.128961 ops/training.py:65 2019-01-16 20:28:12.128900: step 3500, loss = 0.69242 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:28:13.022355 ops/training.py:65 2019-01-16 20:28:13.022279: step 3501, loss = 0.69745 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:28:13.915814 ops/training.py:65 2019-01-16 20:28:13.915750: step 3502, loss = 0.69730 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:28:14.809936 ops/training.py:65 2019-01-16 20:28:14.809833: step 3503, loss = 0.69301 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:28:15.704997 ops/training.py:65 2019-01-16 20:28:15.704919: step 3504, loss = 0.69890 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:28:16.599077 ops/training.py:65 2019-01-16 20:28:16.599006: step 3505, loss = 0.69632 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:28:17.493343 ops/training.py:65 2019-01-16 20:28:17.493285: step 3506, loss = 0.69228 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:28:18.388540 ops/training.py:65 2019-01-16 20:28:18.388466: step 3507, loss = 0.69946 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:28:19.283777 ops/training.py:65 2019-01-16 20:28:19.283719: step 3508, loss = 0.69897 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:28:20.179288 ops/training.py:65 2019-01-16 20:28:20.179213: step 3509, loss = 0.69700 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:28:21.075284 ops/training.py:65 2019-01-16 20:28:21.075217: step 3510, loss = 0.69058 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:28:21.970260 ops/training.py:65 2019-01-16 20:28:21.970190: step 3511, loss = 0.69947 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:28:22.865177 ops/training.py:65 2019-01-16 20:28:22.865114: step 3512, loss = 0.69815 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:28:23.763038 ops/training.py:65 2019-01-16 20:28:23.762919: step 3513, loss = 0.69539 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:28:24.659176 ops/training.py:65 2019-01-16 20:28:24.659075: step 3514, loss = 0.69657 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:28:25.553946 ops/training.py:65 2019-01-16 20:28:25.553847: step 3515, loss = 0.70364 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 20:28:26.449911 ops/training.py:65 2019-01-16 20:28:26.449801: step 3516, loss = 0.69321 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:28:27.345659 ops/training.py:65 2019-01-16 20:28:27.345576: step 3517, loss = 0.68703 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:28:28.241172 ops/training.py:65 2019-01-16 20:28:28.241064: step 3518, loss = 0.69303 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:28:29.137515 ops/training.py:65 2019-01-16 20:28:29.137419: step 3519, loss = 0.68516 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:28:30.032555 ops/training.py:65 2019-01-16 20:28:30.032459: step 3520, loss = 0.68600 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:28:30.926660 ops/training.py:65 2019-01-16 20:28:30.926589: step 3521, loss = 0.69603 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:28:31.821417 ops/training.py:65 2019-01-16 20:28:31.821313: step 3522, loss = 0.68504 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:28:32.717148 ops/training.py:65 2019-01-16 20:28:32.717080: step 3523, loss = 0.69235 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:28:33.611987 ops/training.py:65 2019-01-16 20:28:33.611875: step 3524, loss = 0.68447 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:28:34.507673 ops/training.py:65 2019-01-16 20:28:34.507591: step 3525, loss = 0.70013 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:28:35.402446 ops/training.py:65 2019-01-16 20:28:35.402334: step 3526, loss = 0.69076 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:28:36.298045 ops/training.py:65 2019-01-16 20:28:36.297933: step 3527, loss = 0.68852 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:28:37.193567 ops/training.py:65 2019-01-16 20:28:37.193465: step 3528, loss = 0.68403 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:28:38.089677 ops/training.py:65 2019-01-16 20:28:38.089593: step 3529, loss = 0.68921 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:28:38.986527 ops/training.py:65 2019-01-16 20:28:38.986417: step 3530, loss = 0.67718 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:28:39.882757 ops/training.py:65 2019-01-16 20:28:39.882686: step 3531, loss = 0.68708 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:28:40.777722 ops/training.py:65 2019-01-16 20:28:40.777607: step 3532, loss = 0.68750 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:28:41.672890 ops/training.py:65 2019-01-16 20:28:41.672816: step 3533, loss = 0.69164 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:28:42.566173 ops/training.py:65 2019-01-16 20:28:42.566078: step 3534, loss = 0.70907 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:28:43.462020 ops/training.py:65 2019-01-16 20:28:43.461928: step 3535, loss = 0.70149 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:28:44.357722 ops/training.py:65 2019-01-16 20:28:44.357571: step 3536, loss = 0.69002 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:28:45.256583 ops/training.py:65 2019-01-16 20:28:45.256409: step 3537, loss = 0.70453 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:28:46.155959 ops/training.py:65 2019-01-16 20:28:46.155802: step 3538, loss = 0.68577 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:28:47.052105 ops/training.py:65 2019-01-16 20:28:47.051974: step 3539, loss = 0.68645 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:28:47.947997 ops/training.py:65 2019-01-16 20:28:47.947818: step 3540, loss = 0.69674 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:28:48.844414 ops/training.py:65 2019-01-16 20:28:48.844265: step 3541, loss = 0.69186 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:28:49.741698 ops/training.py:65 2019-01-16 20:28:49.741598: step 3542, loss = 0.69087 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:28:50.639182 ops/training.py:65 2019-01-16 20:28:50.639066: step 3543, loss = 0.69470 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:28:51.537320 ops/training.py:65 2019-01-16 20:28:51.537166: step 3544, loss = 0.68762 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:28:52.433883 ops/training.py:65 2019-01-16 20:28:52.433778: step 3545, loss = 0.69713 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:28:53.329190 ops/training.py:65 2019-01-16 20:28:53.329089: step 3546, loss = 0.70172 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:28:54.224157 ops/training.py:65 2019-01-16 20:28:54.224066: step 3547, loss = 0.69749 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:28:55.118901 ops/training.py:65 2019-01-16 20:28:55.118762: step 3548, loss = 0.69426 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:28:56.014588 ops/training.py:65 2019-01-16 20:28:56.014455: step 3549, loss = 0.68664 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:28:56.910631 ops/training.py:65 2019-01-16 20:28:56.910476: step 3550, loss = 0.69174 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:28:57.806619 ops/training.py:65 2019-01-16 20:28:57.806517: step 3551, loss = 0.69577 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:28:58.701028 ops/training.py:65 2019-01-16 20:28:58.700925: step 3552, loss = 0.70065 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:28:59.594604 ops/training.py:65 2019-01-16 20:28:59.594491: step 3553, loss = 0.69513 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:29:00.487514 ops/training.py:65 2019-01-16 20:29:00.487405: step 3554, loss = 0.68857 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:29:01.380438 ops/training.py:65 2019-01-16 20:29:01.380333: step 3555, loss = 0.70279 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:29:02.274850 ops/training.py:65 2019-01-16 20:29:02.274751: step 3556, loss = 0.69571 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:29:03.169602 ops/training.py:65 2019-01-16 20:29:03.169504: step 3557, loss = 0.69761 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:29:04.063899 ops/training.py:65 2019-01-16 20:29:04.063813: step 3558, loss = 0.69439 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:29:04.958927 ops/training.py:65 2019-01-16 20:29:04.958843: step 3559, loss = 0.69290 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:29:05.853019 ops/training.py:65 2019-01-16 20:29:05.852926: step 3560, loss = 0.69693 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:29:06.747368 ops/training.py:65 2019-01-16 20:29:06.747263: step 3561, loss = 0.69414 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:29:07.641782 ops/training.py:65 2019-01-16 20:29:07.641692: step 3562, loss = 0.69760 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:29:08.536435 ops/training.py:65 2019-01-16 20:29:08.536346: step 3563, loss = 0.69095 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:29:09.431236 ops/training.py:65 2019-01-16 20:29:09.431127: step 3564, loss = 0.69239 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:29:10.325625 ops/training.py:65 2019-01-16 20:29:10.325514: step 3565, loss = 0.69212 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:29:11.220875 ops/training.py:65 2019-01-16 20:29:11.220763: step 3566, loss = 0.69483 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:29:12.117517 ops/training.py:65 2019-01-16 20:29:12.117417: step 3567, loss = 0.69110 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:29:13.013094 ops/training.py:65 2019-01-16 20:29:13.012984: step 3568, loss = 0.69520 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:29:13.908491 ops/training.py:65 2019-01-16 20:29:13.908388: step 3569, loss = 0.68949 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:29:14.804513 ops/training.py:65 2019-01-16 20:29:14.804405: step 3570, loss = 0.69067 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:29:15.700936 ops/training.py:65 2019-01-16 20:29:15.700821: step 3571, loss = 0.70054 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:29:16.596847 ops/training.py:65 2019-01-16 20:29:16.596742: step 3572, loss = 0.68930 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:29:17.492182 ops/training.py:65 2019-01-16 20:29:17.492077: step 3573, loss = 0.69131 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:29:18.387477 ops/training.py:65 2019-01-16 20:29:18.387374: step 3574, loss = 0.69036 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:29:19.282473 ops/training.py:65 2019-01-16 20:29:19.282393: step 3575, loss = 0.69114 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:29:20.178217 ops/training.py:65 2019-01-16 20:29:20.178112: step 3576, loss = 0.69421 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:29:21.073908 ops/training.py:65 2019-01-16 20:29:21.073804: step 3577, loss = 0.69236 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:29:21.970512 ops/training.py:65 2019-01-16 20:29:21.970404: step 3578, loss = 0.68793 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:29:22.866566 ops/training.py:65 2019-01-16 20:29:22.866460: step 3579, loss = 0.69659 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:29:23.762275 ops/training.py:65 2019-01-16 20:29:23.762169: step 3580, loss = 0.69412 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:29:24.657939 ops/training.py:65 2019-01-16 20:29:24.657829: step 3581, loss = 0.69784 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:29:25.554336 ops/training.py:65 2019-01-16 20:29:25.554226: step 3582, loss = 0.68728 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:29:26.451620 ops/training.py:65 2019-01-16 20:29:26.451513: step 3583, loss = 0.69291 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:29:27.348596 ops/training.py:65 2019-01-16 20:29:27.348489: step 3584, loss = 0.69487 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:29:28.245071 ops/training.py:65 2019-01-16 20:29:28.244967: step 3585, loss = 0.69502 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:29:29.142986 ops/training.py:65 2019-01-16 20:29:29.142875: step 3586, loss = 0.69599 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:29:30.039112 ops/training.py:65 2019-01-16 20:29:30.039005: step 3587, loss = 0.69755 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:29:30.934931 ops/training.py:65 2019-01-16 20:29:30.934825: step 3588, loss = 0.70185 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:29:31.832297 ops/training.py:65 2019-01-16 20:29:31.832184: step 3589, loss = 0.69424 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:29:32.728010 ops/training.py:65 2019-01-16 20:29:32.727905: step 3590, loss = 0.69344 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:29:33.622138 ops/training.py:65 2019-01-16 20:29:33.622030: step 3591, loss = 0.69715 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:29:34.515747 ops/training.py:65 2019-01-16 20:29:34.515642: step 3592, loss = 0.69876 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:29:35.409965 ops/training.py:65 2019-01-16 20:29:35.409845: step 3593, loss = 0.69656 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:29:36.308905 ops/training.py:65 2019-01-16 20:29:36.308789: step 3594, loss = 0.69384 (35.7 examples/sec; 0.898 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:29:37.203888 ops/training.py:65 2019-01-16 20:29:37.203777: step 3595, loss = 0.68695 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:29:38.102516 ops/training.py:65 2019-01-16 20:29:38.102419: step 3596, loss = 0.70070 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:29:38.996686 ops/training.py:65 2019-01-16 20:29:38.996584: step 3597, loss = 0.69063 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:29:39.891772 ops/training.py:65 2019-01-16 20:29:39.891668: step 3598, loss = 0.68806 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:29:40.790855 ops/training.py:65 2019-01-16 20:29:40.790749: step 3599, loss = 0.69504 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:29:41.687636 ops/training.py:65 2019-01-16 20:29:41.687530: step 3600, loss = 0.69182 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:29:42.583062 ops/training.py:65 2019-01-16 20:29:42.582962: step 3601, loss = 0.69330 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:29:43.479552 ops/training.py:65 2019-01-16 20:29:43.479444: step 3602, loss = 0.69423 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:29:44.376419 ops/training.py:65 2019-01-16 20:29:44.376304: step 3603, loss = 0.69884 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:29:45.272914 ops/training.py:65 2019-01-16 20:29:45.272807: step 3604, loss = 0.69447 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:29:46.166943 ops/training.py:65 2019-01-16 20:29:46.166836: step 3605, loss = 0.69137 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:29:47.064340 ops/training.py:65 2019-01-16 20:29:47.064228: step 3606, loss = 0.69719 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:29:47.960144 ops/training.py:65 2019-01-16 20:29:47.960042: step 3607, loss = 0.69200 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:29:48.855414 ops/training.py:65 2019-01-16 20:29:48.855278: step 3608, loss = 0.69314 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:29:49.751255 ops/training.py:65 2019-01-16 20:29:49.751118: step 3609, loss = 0.69145 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:29:50.645420 ops/training.py:65 2019-01-16 20:29:50.645316: step 3610, loss = 0.69475 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:29:51.539892 ops/training.py:65 2019-01-16 20:29:51.539785: step 3611, loss = 0.68794 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:29:52.436803 ops/training.py:65 2019-01-16 20:29:52.436692: step 3612, loss = 0.69052 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:29:53.332960 ops/training.py:65 2019-01-16 20:29:53.332850: step 3613, loss = 0.68889 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:29:54.230315 ops/training.py:65 2019-01-16 20:29:54.230203: step 3614, loss = 0.70163 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:29:55.125088 ops/training.py:65 2019-01-16 20:29:55.124976: step 3615, loss = 0.69471 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:29:56.020257 ops/training.py:65 2019-01-16 20:29:56.020150: step 3616, loss = 0.68887 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:29:56.915590 ops/training.py:65 2019-01-16 20:29:56.915485: step 3617, loss = 0.69845 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:29:57.812034 ops/training.py:65 2019-01-16 20:29:57.811928: step 3618, loss = 0.69137 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:29:58.708327 ops/training.py:65 2019-01-16 20:29:58.708224: step 3619, loss = 0.69386 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:29:59.603802 ops/training.py:65 2019-01-16 20:29:59.603697: step 3620, loss = 0.69125 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:30:00.499771 ops/training.py:65 2019-01-16 20:30:00.499666: step 3621, loss = 0.69051 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:30:01.395748 ops/training.py:65 2019-01-16 20:30:01.395644: step 3622, loss = 0.69181 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:30:02.291372 ops/training.py:65 2019-01-16 20:30:02.291293: step 3623, loss = 0.69167 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:30:03.187406 ops/training.py:65 2019-01-16 20:30:03.187304: step 3624, loss = 0.69693 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:30:04.083336 ops/training.py:65 2019-01-16 20:30:04.083227: step 3625, loss = 0.69488 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:30:04.979111 ops/training.py:65 2019-01-16 20:30:04.979009: step 3626, loss = 0.69188 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:30:05.874170 ops/training.py:65 2019-01-16 20:30:05.874045: step 3627, loss = 0.68966 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:30:06.771890 ops/training.py:65 2019-01-16 20:30:06.771787: step 3628, loss = 0.69841 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:30:07.668232 ops/training.py:65 2019-01-16 20:30:07.668116: step 3629, loss = 0.69506 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:30:08.568829 ops/training.py:65 2019-01-16 20:30:08.568723: step 3630, loss = 0.69485 (35.6 examples/sec; 0.899 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:30:09.464286 ops/training.py:65 2019-01-16 20:30:09.464178: step 3631, loss = 0.69642 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:30:10.360176 ops/training.py:65 2019-01-16 20:30:10.360072: step 3632, loss = 0.69245 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:30:11.256918 ops/training.py:65 2019-01-16 20:30:11.256805: step 3633, loss = 0.69333 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:30:12.152693 ops/training.py:65 2019-01-16 20:30:12.152594: step 3634, loss = 0.69158 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:30:13.048535 ops/training.py:65 2019-01-16 20:30:13.048431: step 3635, loss = 0.69575 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:30:13.943926 ops/training.py:65 2019-01-16 20:30:13.943836: step 3636, loss = 0.69331 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:30:14.839273 ops/training.py:65 2019-01-16 20:30:14.839169: step 3637, loss = 0.69813 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:30:15.736093 ops/training.py:65 2019-01-16 20:30:15.735991: step 3638, loss = 0.69881 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.25
I1280 2019-01-16 20:30:16.632425 ops/training.py:65 2019-01-16 20:30:16.632315: step 3639, loss = 0.68779 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:30:17.530334 ops/training.py:65 2019-01-16 20:30:17.530245: step 3640, loss = 0.69326 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:30:18.426488 ops/training.py:65 2019-01-16 20:30:18.426380: step 3641, loss = 0.68871 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:30:19.322058 ops/training.py:65 2019-01-16 20:30:19.321980: step 3642, loss = 0.69951 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:30:20.218028 ops/training.py:65 2019-01-16 20:30:20.217926: step 3643, loss = 0.69458 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:30:21.114356 ops/training.py:65 2019-01-16 20:30:21.114249: step 3644, loss = 0.69557 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:30:22.009216 ops/training.py:65 2019-01-16 20:30:22.009117: step 3645, loss = 0.68905 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:30:22.904172 ops/training.py:65 2019-01-16 20:30:22.904063: step 3646, loss = 0.69317 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:30:23.801141 ops/training.py:65 2019-01-16 20:30:23.801030: step 3647, loss = 0.69117 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:30:24.698015 ops/training.py:65 2019-01-16 20:30:24.697905: step 3648, loss = 0.69557 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:30:25.594169 ops/training.py:65 2019-01-16 20:30:25.594056: step 3649, loss = 0.68825 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:30:26.490358 ops/training.py:65 2019-01-16 20:30:26.490250: step 3650, loss = 0.68999 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:30:27.386594 ops/training.py:65 2019-01-16 20:30:27.386484: step 3651, loss = 0.68663 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 20:30:28.282124 ops/training.py:65 2019-01-16 20:30:28.282017: step 3652, loss = 0.69550 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:30:29.179758 ops/training.py:65 2019-01-16 20:30:29.179645: step 3653, loss = 0.69695 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:30:30.074585 ops/training.py:65 2019-01-16 20:30:30.074496: step 3654, loss = 0.69711 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:30:30.969058 ops/training.py:65 2019-01-16 20:30:30.968950: step 3655, loss = 0.69892 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:30:31.864760 ops/training.py:65 2019-01-16 20:30:31.864684: step 3656, loss = 0.69874 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:30:32.760232 ops/training.py:65 2019-01-16 20:30:32.760134: step 3657, loss = 0.69267 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:30:33.655279 ops/training.py:65 2019-01-16 20:30:33.655170: step 3658, loss = 0.68798 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:30:34.551621 ops/training.py:65 2019-01-16 20:30:34.551526: step 3659, loss = 0.69513 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:30:35.446254 ops/training.py:65 2019-01-16 20:30:35.446146: step 3660, loss = 0.68754 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:30:36.341631 ops/training.py:65 2019-01-16 20:30:36.341515: step 3661, loss = 0.70132 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:30:37.237487 ops/training.py:65 2019-01-16 20:30:37.237381: step 3662, loss = 0.69487 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:30:38.132731 ops/training.py:65 2019-01-16 20:30:38.132646: step 3663, loss = 0.69826 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:30:39.028139 ops/training.py:65 2019-01-16 20:30:39.028033: step 3664, loss = 0.69375 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:30:39.922633 ops/training.py:65 2019-01-16 20:30:39.922531: step 3665, loss = 0.69437 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:30:40.818441 ops/training.py:65 2019-01-16 20:30:40.818340: step 3666, loss = 0.69602 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:30:41.715624 ops/training.py:65 2019-01-16 20:30:41.715518: step 3667, loss = 0.69869 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:30:42.611924 ops/training.py:65 2019-01-16 20:30:42.611790: step 3668, loss = 0.69504 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:30:43.509432 ops/training.py:65 2019-01-16 20:30:43.509325: step 3669, loss = 0.69522 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:30:44.406154 ops/training.py:65 2019-01-16 20:30:44.406045: step 3670, loss = 0.69161 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:30:45.302599 ops/training.py:65 2019-01-16 20:30:45.302491: step 3671, loss = 0.69101 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:30:46.198680 ops/training.py:65 2019-01-16 20:30:46.198572: step 3672, loss = 0.69483 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:30:47.095354 ops/training.py:65 2019-01-16 20:30:47.095248: step 3673, loss = 0.69626 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:30:47.991025 ops/training.py:65 2019-01-16 20:30:47.990921: step 3674, loss = 0.69515 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:30:48.887745 ops/training.py:65 2019-01-16 20:30:48.887638: step 3675, loss = 0.69626 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:30:49.783331 ops/training.py:65 2019-01-16 20:30:49.783250: step 3676, loss = 0.69161 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:30:50.677710 ops/training.py:65 2019-01-16 20:30:50.677645: step 3677, loss = 0.69628 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:30:51.573299 ops/training.py:65 2019-01-16 20:30:51.573191: step 3678, loss = 0.68883 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:30:52.471912 ops/training.py:65 2019-01-16 20:30:52.471817: step 3679, loss = 0.69219 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:30:53.368387 ops/training.py:65 2019-01-16 20:30:53.368276: step 3680, loss = 0.69316 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:30:54.266604 ops/training.py:65 2019-01-16 20:30:54.266495: step 3681, loss = 0.69468 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:30:55.164494 ops/training.py:65 2019-01-16 20:30:55.164381: step 3682, loss = 0.68869 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:30:56.061691 ops/training.py:65 2019-01-16 20:30:56.061630: step 3683, loss = 0.69744 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:30:56.956173 ops/training.py:65 2019-01-16 20:30:56.956111: step 3684, loss = 0.69355 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:30:57.851683 ops/training.py:65 2019-01-16 20:30:57.851570: step 3685, loss = 0.69213 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:30:58.748416 ops/training.py:65 2019-01-16 20:30:58.748300: step 3686, loss = 0.69892 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:30:59.644457 ops/training.py:65 2019-01-16 20:30:59.644402: step 3687, loss = 0.69051 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:31:00.545333 ops/training.py:65 2019-01-16 20:31:00.545227: step 3688, loss = 0.69408 (35.6 examples/sec; 0.900 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:31:01.443739 ops/training.py:65 2019-01-16 20:31:01.443618: step 3689, loss = 0.68821 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:31:02.343976 ops/training.py:65 2019-01-16 20:31:02.343841: step 3690, loss = 0.68768 (35.6 examples/sec; 0.899 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:31:03.240762 ops/training.py:65 2019-01-16 20:31:03.240614: step 3691, loss = 0.69134 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:31:04.141616 ops/training.py:65 2019-01-16 20:31:04.141506: step 3692, loss = 0.68693 (35.6 examples/sec; 0.899 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:31:05.037855 ops/training.py:65 2019-01-16 20:31:05.037723: step 3693, loss = 0.68982 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:31:05.934072 ops/training.py:65 2019-01-16 20:31:05.933945: step 3694, loss = 0.69081 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:31:06.829721 ops/training.py:65 2019-01-16 20:31:06.829614: step 3695, loss = 0.69483 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:31:07.726049 ops/training.py:65 2019-01-16 20:31:07.725958: step 3696, loss = 0.69426 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:31:08.622755 ops/training.py:65 2019-01-16 20:31:08.622676: step 3697, loss = 0.69875 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:31:09.518986 ops/training.py:65 2019-01-16 20:31:09.518879: step 3698, loss = 0.69790 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:31:10.413634 ops/training.py:65 2019-01-16 20:31:10.413565: step 3699, loss = 0.69743 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:31:11.308783 ops/training.py:65 2019-01-16 20:31:11.308710: step 3700, loss = 0.68926 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:31:12.203339 ops/training.py:65 2019-01-16 20:31:12.203274: step 3701, loss = 0.69143 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:31:13.097408 ops/training.py:65 2019-01-16 20:31:13.097333: step 3702, loss = 0.68508 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:31:13.992104 ops/training.py:65 2019-01-16 20:31:13.992040: step 3703, loss = 0.69483 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:31:14.887116 ops/training.py:65 2019-01-16 20:31:14.887045: step 3704, loss = 0.69797 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:31:15.782254 ops/training.py:65 2019-01-16 20:31:15.782180: step 3705, loss = 0.68820 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:31:16.676931 ops/training.py:65 2019-01-16 20:31:16.676863: step 3706, loss = 0.69314 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:31:17.570724 ops/training.py:65 2019-01-16 20:31:17.570660: step 3707, loss = 0.68904 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:31:18.464002 ops/training.py:65 2019-01-16 20:31:18.463934: step 3708, loss = 0.69406 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:31:19.360521 ops/training.py:65 2019-01-16 20:31:19.360470: step 3709, loss = 0.69982 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:31:20.255997 ops/training.py:65 2019-01-16 20:31:20.255892: step 3710, loss = 0.69732 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:31:21.151555 ops/training.py:65 2019-01-16 20:31:21.151444: step 3711, loss = 0.69158 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:31:22.046948 ops/training.py:65 2019-01-16 20:31:22.046849: step 3712, loss = 0.69182 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:31:22.941278 ops/training.py:65 2019-01-16 20:31:22.941174: step 3713, loss = 0.69405 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:31:23.836279 ops/training.py:65 2019-01-16 20:31:23.836170: step 3714, loss = 0.69409 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:31:24.731767 ops/training.py:65 2019-01-16 20:31:24.731660: step 3715, loss = 0.69470 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:31:25.627322 ops/training.py:65 2019-01-16 20:31:25.627218: step 3716, loss = 0.70008 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:31:26.523055 ops/training.py:65 2019-01-16 20:31:26.522957: step 3717, loss = 0.69623 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:31:27.420412 ops/training.py:65 2019-01-16 20:31:27.420310: step 3718, loss = 0.69221 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:31:28.316621 ops/training.py:65 2019-01-16 20:31:28.316522: step 3719, loss = 0.69332 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:31:29.211674 ops/training.py:65 2019-01-16 20:31:29.211573: step 3720, loss = 0.69462 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:31:30.107720 ops/training.py:65 2019-01-16 20:31:30.107614: step 3721, loss = 0.69629 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:31:31.003119 ops/training.py:65 2019-01-16 20:31:31.003025: step 3722, loss = 0.69454 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:31:31.901676 ops/training.py:65 2019-01-16 20:31:31.901578: step 3723, loss = 0.69828 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:31:32.796948 ops/training.py:65 2019-01-16 20:31:32.796843: step 3724, loss = 0.70032 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:31:33.692778 ops/training.py:65 2019-01-16 20:31:33.692677: step 3725, loss = 0.68924 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:31:34.587291 ops/training.py:65 2019-01-16 20:31:34.587189: step 3726, loss = 0.69605 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:31:35.480867 ops/training.py:65 2019-01-16 20:31:35.480769: step 3727, loss = 0.68876 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:31:36.375411 ops/training.py:65 2019-01-16 20:31:36.375314: step 3728, loss = 0.69845 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:31:37.271737 ops/training.py:65 2019-01-16 20:31:37.271636: step 3729, loss = 0.69509 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:31:38.166777 ops/training.py:65 2019-01-16 20:31:38.166693: step 3730, loss = 0.69985 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:31:39.062111 ops/training.py:65 2019-01-16 20:31:39.062005: step 3731, loss = 0.69081 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:31:39.958118 ops/training.py:65 2019-01-16 20:31:39.958020: step 3732, loss = 0.69512 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:31:40.856155 ops/training.py:65 2019-01-16 20:31:40.856050: step 3733, loss = 0.69112 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:31:41.752711 ops/training.py:65 2019-01-16 20:31:41.752601: step 3734, loss = 0.69242 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:31:42.648808 ops/training.py:65 2019-01-16 20:31:42.648713: step 3735, loss = 0.69883 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:31:43.545052 ops/training.py:65 2019-01-16 20:31:43.544944: step 3736, loss = 0.68844 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:31:44.442104 ops/training.py:65 2019-01-16 20:31:44.442002: step 3737, loss = 0.69554 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:31:45.337708 ops/training.py:65 2019-01-16 20:31:45.337604: step 3738, loss = 0.70021 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:31:46.232866 ops/training.py:65 2019-01-16 20:31:46.232765: step 3739, loss = 0.68576 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:31:47.128668 ops/training.py:65 2019-01-16 20:31:47.128561: step 3740, loss = 0.68780 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:31:48.023880 ops/training.py:65 2019-01-16 20:31:48.023773: step 3741, loss = 0.70376 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:31:48.920072 ops/training.py:65 2019-01-16 20:31:48.919963: step 3742, loss = 0.70169 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:31:49.816071 ops/training.py:65 2019-01-16 20:31:49.815960: step 3743, loss = 0.69176 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:31:50.711189 ops/training.py:65 2019-01-16 20:31:50.711086: step 3744, loss = 0.69626 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:31:51.607046 ops/training.py:65 2019-01-16 20:31:51.606940: step 3745, loss = 0.69126 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:31:52.504474 ops/training.py:65 2019-01-16 20:31:52.504369: step 3746, loss = 0.69010 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:31:53.402979 ops/training.py:65 2019-01-16 20:31:53.402878: step 3747, loss = 0.69419 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:31:54.299959 ops/training.py:65 2019-01-16 20:31:54.299862: step 3748, loss = 0.69348 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:31:55.195030 ops/training.py:65 2019-01-16 20:31:55.194932: step 3749, loss = 0.70046 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:31:56.091336 ops/training.py:65 2019-01-16 20:31:56.091235: step 3750, loss = 0.69909 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:31:56.987668 ops/training.py:65 2019-01-16 20:31:56.987559: step 3751, loss = 0.69522 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:31:57.883328 ops/training.py:65 2019-01-16 20:31:57.883237: step 3752, loss = 0.69711 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:31:58.779451 ops/training.py:65 2019-01-16 20:31:58.779352: step 3753, loss = 0.68888 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:31:59.675480 ops/training.py:65 2019-01-16 20:31:59.675378: step 3754, loss = 0.69811 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:32:00.570706 ops/training.py:65 2019-01-16 20:32:00.570601: step 3755, loss = 0.69692 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:32:01.466496 ops/training.py:65 2019-01-16 20:32:01.466397: step 3756, loss = 0.69819 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:32:02.362366 ops/training.py:65 2019-01-16 20:32:02.362286: step 3757, loss = 0.68510 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:32:03.259419 ops/training.py:65 2019-01-16 20:32:03.259274: step 3758, loss = 0.69745 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:32:04.154812 ops/training.py:65 2019-01-16 20:32:04.154711: step 3759, loss = 0.70418 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:32:05.050404 ops/training.py:65 2019-01-16 20:32:05.050301: step 3760, loss = 0.69718 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:32:05.946151 ops/training.py:65 2019-01-16 20:32:05.946049: step 3761, loss = 0.69244 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:32:06.841524 ops/training.py:65 2019-01-16 20:32:06.841424: step 3762, loss = 0.69033 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:32:07.736401 ops/training.py:65 2019-01-16 20:32:07.736296: step 3763, loss = 0.69143 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:32:08.632291 ops/training.py:65 2019-01-16 20:32:08.632199: step 3764, loss = 0.68681 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:32:09.528916 ops/training.py:65 2019-01-16 20:32:09.528811: step 3765, loss = 0.69580 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:32:10.426465 ops/training.py:65 2019-01-16 20:32:10.426340: step 3766, loss = 0.69031 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:32:11.328150 ops/training.py:65 2019-01-16 20:32:11.328044: step 3767, loss = 0.69716 (35.6 examples/sec; 0.900 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:32:12.224386 ops/training.py:65 2019-01-16 20:32:12.224278: step 3768, loss = 0.69450 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:32:13.121224 ops/training.py:65 2019-01-16 20:32:13.121115: step 3769, loss = 0.70054 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:32:14.019662 ops/training.py:65 2019-01-16 20:32:14.019560: step 3770, loss = 0.69698 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:32:14.915540 ops/training.py:65 2019-01-16 20:32:14.915444: step 3771, loss = 0.70031 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:32:15.810734 ops/training.py:65 2019-01-16 20:32:15.810628: step 3772, loss = 0.69358 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:32:16.707404 ops/training.py:65 2019-01-16 20:32:16.707301: step 3773, loss = 0.69224 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:32:17.601977 ops/training.py:65 2019-01-16 20:32:17.601890: step 3774, loss = 0.69246 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:32:18.496876 ops/training.py:65 2019-01-16 20:32:18.496772: step 3775, loss = 0.69116 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:32:19.391981 ops/training.py:65 2019-01-16 20:32:19.391902: step 3776, loss = 0.69672 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:32:20.286952 ops/training.py:65 2019-01-16 20:32:20.286852: step 3777, loss = 0.69265 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:32:21.183933 ops/training.py:65 2019-01-16 20:32:21.183864: step 3778, loss = 0.69586 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:32:22.083517 ops/training.py:65 2019-01-16 20:32:22.083403: step 3779, loss = 0.69284 (35.6 examples/sec; 0.899 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:32:22.979048 ops/training.py:65 2019-01-16 20:32:22.978942: step 3780, loss = 0.69272 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:32:23.874718 ops/training.py:65 2019-01-16 20:32:23.874602: step 3781, loss = 0.69098 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:32:24.771396 ops/training.py:65 2019-01-16 20:32:24.771290: step 3782, loss = 0.68927 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:32:25.668659 ops/training.py:65 2019-01-16 20:32:25.668559: step 3783, loss = 0.69598 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:32:26.565705 ops/training.py:65 2019-01-16 20:32:26.565596: step 3784, loss = 0.69179 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:32:27.460467 ops/training.py:65 2019-01-16 20:32:27.460358: step 3785, loss = 0.69631 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:32:28.356995 ops/training.py:65 2019-01-16 20:32:28.356887: step 3786, loss = 0.69395 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:32:29.252083 ops/training.py:65 2019-01-16 20:32:29.251980: step 3787, loss = 0.69696 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:32:30.147900 ops/training.py:65 2019-01-16 20:32:30.147782: step 3788, loss = 0.68972 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:32:31.043269 ops/training.py:65 2019-01-16 20:32:31.043160: step 3789, loss = 0.69005 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:32:31.939324 ops/training.py:65 2019-01-16 20:32:31.939222: step 3790, loss = 0.69412 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:32:32.836737 ops/training.py:65 2019-01-16 20:32:32.836649: step 3791, loss = 0.69201 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:32:33.733510 ops/training.py:65 2019-01-16 20:32:33.733404: step 3792, loss = 0.69914 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:32:34.628768 ops/training.py:65 2019-01-16 20:32:34.628687: step 3793, loss = 0.69438 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:32:35.523838 ops/training.py:65 2019-01-16 20:32:35.523741: step 3794, loss = 0.69866 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:32:36.420465 ops/training.py:65 2019-01-16 20:32:36.420365: step 3795, loss = 0.68908 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:32:37.316876 ops/training.py:65 2019-01-16 20:32:37.316775: step 3796, loss = 0.69077 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:32:38.213114 ops/training.py:65 2019-01-16 20:32:38.213029: step 3797, loss = 0.69694 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:32:39.108166 ops/training.py:65 2019-01-16 20:32:39.108061: step 3798, loss = 0.69535 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:32:40.004919 ops/training.py:65 2019-01-16 20:32:40.004814: step 3799, loss = 0.69820 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:32:40.900867 ops/training.py:65 2019-01-16 20:32:40.900764: step 3800, loss = 0.69015 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:32:41.796752 ops/training.py:65 2019-01-16 20:32:41.796654: step 3801, loss = 0.69214 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:32:42.691750 ops/training.py:65 2019-01-16 20:32:42.691644: step 3802, loss = 0.69350 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:32:43.590385 ops/training.py:65 2019-01-16 20:32:43.590276: step 3803, loss = 0.69485 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:32:44.486510 ops/training.py:65 2019-01-16 20:32:44.486403: step 3804, loss = 0.69324 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:32:45.382204 ops/training.py:65 2019-01-16 20:32:45.382096: step 3805, loss = 0.69178 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:32:46.277558 ops/training.py:65 2019-01-16 20:32:46.277450: step 3806, loss = 0.69243 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:32:47.173637 ops/training.py:65 2019-01-16 20:32:47.173528: step 3807, loss = 0.69515 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:32:48.069835 ops/training.py:65 2019-01-16 20:32:48.069727: step 3808, loss = 0.68833 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:32:48.966875 ops/training.py:65 2019-01-16 20:32:48.966762: step 3809, loss = 0.69117 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:32:49.862351 ops/training.py:65 2019-01-16 20:32:49.862272: step 3810, loss = 0.69235 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:32:50.759452 ops/training.py:65 2019-01-16 20:32:50.759344: step 3811, loss = 0.68873 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:32:51.654712 ops/training.py:65 2019-01-16 20:32:51.654568: step 3812, loss = 0.69169 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:32:52.551101 ops/training.py:65 2019-01-16 20:32:52.550982: step 3813, loss = 0.69333 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:32:53.447053 ops/training.py:65 2019-01-16 20:32:53.446953: step 3814, loss = 0.69039 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:32:54.342492 ops/training.py:65 2019-01-16 20:32:54.342413: step 3815, loss = 0.69506 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:32:55.238437 ops/training.py:65 2019-01-16 20:32:55.238351: step 3816, loss = 0.69426 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:32:56.134192 ops/training.py:65 2019-01-16 20:32:56.134082: step 3817, loss = 0.69715 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:32:57.031352 ops/training.py:65 2019-01-16 20:32:57.031243: step 3818, loss = 0.68958 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:32:57.927841 ops/training.py:65 2019-01-16 20:32:57.927733: step 3819, loss = 0.69372 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:32:58.824307 ops/training.py:65 2019-01-16 20:32:58.824200: step 3820, loss = 0.69187 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:32:59.720398 ops/training.py:65 2019-01-16 20:32:59.720286: step 3821, loss = 0.69377 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:33:00.616460 ops/training.py:65 2019-01-16 20:33:00.616348: step 3822, loss = 0.69123 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:33:01.514151 ops/training.py:65 2019-01-16 20:33:01.514023: step 3823, loss = 0.69273 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:33:02.411340 ops/training.py:65 2019-01-16 20:33:02.411263: step 3824, loss = 0.69024 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:33:03.308343 ops/training.py:65 2019-01-16 20:33:03.308241: step 3825, loss = 0.68881 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:33:04.203957 ops/training.py:65 2019-01-16 20:33:04.203847: step 3826, loss = 0.69597 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:33:05.100067 ops/training.py:65 2019-01-16 20:33:05.099953: step 3827, loss = 0.70266 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:33:05.995060 ops/training.py:65 2019-01-16 20:33:05.994956: step 3828, loss = 0.69972 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:33:06.890869 ops/training.py:65 2019-01-16 20:33:06.890765: step 3829, loss = 0.69361 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:33:07.786307 ops/training.py:65 2019-01-16 20:33:07.786196: step 3830, loss = 0.68901 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:33:08.684220 ops/training.py:65 2019-01-16 20:33:08.684136: step 3831, loss = 0.69539 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:33:09.579583 ops/training.py:65 2019-01-16 20:33:09.579478: step 3832, loss = 0.69642 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:33:10.474448 ops/training.py:65 2019-01-16 20:33:10.474348: step 3833, loss = 0.69550 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:33:11.370111 ops/training.py:65 2019-01-16 20:33:11.370037: step 3834, loss = 0.68900 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:33:12.265164 ops/training.py:65 2019-01-16 20:33:12.265057: step 3835, loss = 0.69471 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:33:13.159748 ops/training.py:65 2019-01-16 20:33:13.159645: step 3836, loss = 0.69264 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:33:14.055363 ops/training.py:65 2019-01-16 20:33:14.055275: step 3837, loss = 0.69189 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:33:14.949720 ops/training.py:65 2019-01-16 20:33:14.949656: step 3838, loss = 0.69781 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:33:15.846060 ops/training.py:65 2019-01-16 20:33:15.845971: step 3839, loss = 0.69515 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:33:16.743219 ops/training.py:65 2019-01-16 20:33:16.743130: step 3840, loss = 0.69211 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:33:17.642298 ops/training.py:65 2019-01-16 20:33:17.642199: step 3841, loss = 0.69522 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:33:18.539741 ops/training.py:65 2019-01-16 20:33:18.539636: step 3842, loss = 0.68879 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:33:19.437873 ops/training.py:65 2019-01-16 20:33:19.437779: step 3843, loss = 0.68589 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:33:20.332438 ops/training.py:65 2019-01-16 20:33:20.332340: step 3844, loss = 0.70380 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:33:21.226990 ops/training.py:65 2019-01-16 20:33:21.226868: step 3845, loss = 0.69871 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:33:22.123914 ops/training.py:65 2019-01-16 20:33:22.123764: step 3846, loss = 0.70051 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:33:23.020938 ops/training.py:65 2019-01-16 20:33:23.020801: step 3847, loss = 0.69424 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:33:23.916425 ops/training.py:65 2019-01-16 20:33:23.916320: step 3848, loss = 0.69033 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:33:24.812326 ops/training.py:65 2019-01-16 20:33:24.812228: step 3849, loss = 0.68556 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:33:25.708915 ops/training.py:65 2019-01-16 20:33:25.708816: step 3850, loss = 0.69217 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:33:26.604222 ops/training.py:65 2019-01-16 20:33:26.604133: step 3851, loss = 0.69343 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:33:27.499940 ops/training.py:65 2019-01-16 20:33:27.499842: step 3852, loss = 0.69089 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:33:28.396496 ops/training.py:65 2019-01-16 20:33:28.396396: step 3853, loss = 0.69506 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:33:29.292955 ops/training.py:65 2019-01-16 20:33:29.292849: step 3854, loss = 0.69496 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:33:30.187209 ops/training.py:65 2019-01-16 20:33:30.187107: step 3855, loss = 0.69357 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:33:31.082371 ops/training.py:65 2019-01-16 20:33:31.082272: step 3856, loss = 0.69090 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:33:31.977781 ops/training.py:65 2019-01-16 20:33:31.977681: step 3857, loss = 0.68535 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:33:32.873237 ops/training.py:65 2019-01-16 20:33:32.873139: step 3858, loss = 0.69709 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:33:33.769948 ops/training.py:65 2019-01-16 20:33:33.769849: step 3859, loss = 0.69079 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:33:34.667299 ops/training.py:65 2019-01-16 20:33:34.667198: step 3860, loss = 0.68872 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:33:35.562781 ops/training.py:65 2019-01-16 20:33:35.562680: step 3861, loss = 0.69168 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:33:36.464479 ops/training.py:65 2019-01-16 20:33:36.464375: step 3862, loss = 0.68845 (35.6 examples/sec; 0.900 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:33:37.360603 ops/training.py:65 2019-01-16 20:33:37.360507: step 3863, loss = 0.69185 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:33:38.258734 ops/training.py:65 2019-01-16 20:33:38.258646: step 3864, loss = 0.69378 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:33:39.154950 ops/training.py:65 2019-01-16 20:33:39.154847: step 3865, loss = 0.68427 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:33:40.049382 ops/training.py:65 2019-01-16 20:33:40.049275: step 3866, loss = 0.69487 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:33:40.946384 ops/training.py:65 2019-01-16 20:33:40.946279: step 3867, loss = 0.68859 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:33:41.844550 ops/training.py:65 2019-01-16 20:33:41.844446: step 3868, loss = 0.69092 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:33:42.740554 ops/training.py:65 2019-01-16 20:33:42.740432: step 3869, loss = 0.68926 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:33:43.636770 ops/training.py:65 2019-01-16 20:33:43.636661: step 3870, loss = 0.69062 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:33:44.531043 ops/training.py:65 2019-01-16 20:33:44.530940: step 3871, loss = 0.70017 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:33:45.428405 ops/training.py:65 2019-01-16 20:33:45.428310: step 3872, loss = 0.69241 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:33:46.325852 ops/training.py:65 2019-01-16 20:33:46.325753: step 3873, loss = 0.69126 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:33:47.223124 ops/training.py:65 2019-01-16 20:33:47.223023: step 3874, loss = 0.69968 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:33:48.121832 ops/training.py:65 2019-01-16 20:33:48.121729: step 3875, loss = 0.69332 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:33:49.018403 ops/training.py:65 2019-01-16 20:33:49.018306: step 3876, loss = 0.70486 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:33:49.914587 ops/training.py:65 2019-01-16 20:33:49.914487: step 3877, loss = 0.68500 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:33:50.810848 ops/training.py:65 2019-01-16 20:33:50.810746: step 3878, loss = 0.69374 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:33:51.707015 ops/training.py:65 2019-01-16 20:33:51.706911: step 3879, loss = 0.69197 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:33:52.603440 ops/training.py:65 2019-01-16 20:33:52.603343: step 3880, loss = 0.68664 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:33:53.499620 ops/training.py:65 2019-01-16 20:33:53.499510: step 3881, loss = 0.69350 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:33:54.398192 ops/training.py:65 2019-01-16 20:33:54.398092: step 3882, loss = 0.69461 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:33:55.293524 ops/training.py:65 2019-01-16 20:33:55.293446: step 3883, loss = 0.68130 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:33:56.187206 ops/training.py:65 2019-01-16 20:33:56.187129: step 3884, loss = 0.68772 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:33:57.080648 ops/training.py:65 2019-01-16 20:33:57.080570: step 3885, loss = 0.68452 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:33:57.974836 ops/training.py:65 2019-01-16 20:33:57.974751: step 3886, loss = 0.70798 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:33:58.868378 ops/training.py:65 2019-01-16 20:33:58.868313: step 3887, loss = 0.68450 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:33:59.763032 ops/training.py:65 2019-01-16 20:33:59.762962: step 3888, loss = 0.70078 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:34:00.655706 ops/training.py:65 2019-01-16 20:34:00.655642: step 3889, loss = 0.69533 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:34:01.549034 ops/training.py:65 2019-01-16 20:34:01.548956: step 3890, loss = 0.69188 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:34:02.443508 ops/training.py:65 2019-01-16 20:34:02.443454: step 3891, loss = 0.69650 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:34:03.339643 ops/training.py:65 2019-01-16 20:34:03.339537: step 3892, loss = 0.69289 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:34:04.235149 ops/training.py:65 2019-01-16 20:34:04.235040: step 3893, loss = 0.69741 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:34:05.129287 ops/training.py:65 2019-01-16 20:34:05.129226: step 3894, loss = 0.69598 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:34:06.023026 ops/training.py:65 2019-01-16 20:34:06.022919: step 3895, loss = 0.69289 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:34:06.918106 ops/training.py:65 2019-01-16 20:34:06.917998: step 3896, loss = 0.69147 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:34:07.814114 ops/training.py:65 2019-01-16 20:34:07.814036: step 3897, loss = 0.69107 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:34:08.709594 ops/training.py:65 2019-01-16 20:34:08.709511: step 3898, loss = 0.69310 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:34:09.604633 ops/training.py:65 2019-01-16 20:34:09.604573: step 3899, loss = 0.69610 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:34:10.500132 ops/training.py:65 2019-01-16 20:34:10.500050: step 3900, loss = 0.70610 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:34:11.395450 ops/training.py:65 2019-01-16 20:34:11.395346: step 3901, loss = 0.69840 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:34:12.291708 ops/training.py:65 2019-01-16 20:34:12.291605: step 3902, loss = 0.69751 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:34:13.187339 ops/training.py:65 2019-01-16 20:34:13.187228: step 3903, loss = 0.69461 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:34:14.107009 ops/training.py:65 2019-01-16 20:34:14.106915: step 3904, loss = 0.69554 (34.8 examples/sec; 0.919 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:34:15.002429 ops/training.py:65 2019-01-16 20:34:15.002355: step 3905, loss = 0.69458 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:34:15.900048 ops/training.py:65 2019-01-16 20:34:15.899939: step 3906, loss = 0.69507 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:34:16.794770 ops/training.py:65 2019-01-16 20:34:16.794666: step 3907, loss = 0.69604 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:34:17.690893 ops/training.py:65 2019-01-16 20:34:17.690834: step 3908, loss = 0.69270 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:34:18.588822 ops/training.py:65 2019-01-16 20:34:18.588708: step 3909, loss = 0.69669 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:34:19.483720 ops/training.py:65 2019-01-16 20:34:19.483669: step 3910, loss = 0.69699 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:34:20.381370 ops/training.py:65 2019-01-16 20:34:20.381264: step 3911, loss = 0.69205 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:34:21.277351 ops/training.py:65 2019-01-16 20:34:21.277248: step 3912, loss = 0.69366 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:34:22.171597 ops/training.py:65 2019-01-16 20:34:22.171532: step 3913, loss = 0.69218 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:34:23.065315 ops/training.py:65 2019-01-16 20:34:23.065246: step 3914, loss = 0.69205 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:34:23.959189 ops/training.py:65 2019-01-16 20:34:23.959118: step 3915, loss = 0.69567 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:34:24.852472 ops/training.py:65 2019-01-16 20:34:24.852394: step 3916, loss = 0.69210 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:34:25.746679 ops/training.py:65 2019-01-16 20:34:25.746616: step 3917, loss = 0.69290 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:34:26.641316 ops/training.py:65 2019-01-16 20:34:26.641248: step 3918, loss = 0.69874 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:34:27.536609 ops/training.py:65 2019-01-16 20:34:27.536500: step 3919, loss = 0.69366 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:34:28.434893 ops/training.py:65 2019-01-16 20:34:28.434777: step 3920, loss = 0.69211 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:34:29.331102 ops/training.py:65 2019-01-16 20:34:29.330991: step 3921, loss = 0.69225 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:34:30.225796 ops/training.py:65 2019-01-16 20:34:30.225689: step 3922, loss = 0.68911 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:34:31.122884 ops/training.py:65 2019-01-16 20:34:31.122776: step 3923, loss = 0.69534 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:34:32.020188 ops/training.py:65 2019-01-16 20:34:32.020083: step 3924, loss = 0.69291 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:34:32.914638 ops/training.py:65 2019-01-16 20:34:32.914530: step 3925, loss = 0.69917 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:34:33.813264 ops/training.py:65 2019-01-16 20:34:33.813159: step 3926, loss = 0.69687 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:34:34.709148 ops/training.py:65 2019-01-16 20:34:34.709045: step 3927, loss = 0.69239 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:34:35.605930 ops/training.py:65 2019-01-16 20:34:35.605823: step 3928, loss = 0.69149 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:34:36.501993 ops/training.py:65 2019-01-16 20:34:36.501889: step 3929, loss = 0.69305 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:34:37.396599 ops/training.py:65 2019-01-16 20:34:37.396494: step 3930, loss = 0.69262 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:34:38.292602 ops/training.py:65 2019-01-16 20:34:38.292490: step 3931, loss = 0.69689 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:34:39.187312 ops/training.py:65 2019-01-16 20:34:39.187205: step 3932, loss = 0.69099 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:34:40.080730 ops/training.py:65 2019-01-16 20:34:40.080617: step 3933, loss = 0.69331 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:34:40.974691 ops/training.py:65 2019-01-16 20:34:40.974588: step 3934, loss = 0.69599 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:34:41.869767 ops/training.py:65 2019-01-16 20:34:41.869664: step 3935, loss = 0.69405 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:34:42.764301 ops/training.py:65 2019-01-16 20:34:42.764197: step 3936, loss = 0.69361 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:34:43.658358 ops/training.py:65 2019-01-16 20:34:43.658245: step 3937, loss = 0.69578 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:34:44.554183 ops/training.py:65 2019-01-16 20:34:44.554074: step 3938, loss = 0.69383 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:34:45.452517 ops/training.py:65 2019-01-16 20:34:45.452414: step 3939, loss = 0.69669 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:34:46.346186 ops/training.py:65 2019-01-16 20:34:46.346087: step 3940, loss = 0.68811 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 20:34:47.240445 ops/training.py:65 2019-01-16 20:34:47.240380: step 3941, loss = 0.69345 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:34:48.134234 ops/training.py:65 2019-01-16 20:34:48.134176: step 3942, loss = 0.69636 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:34:49.028329 ops/training.py:65 2019-01-16 20:34:49.028221: step 3943, loss = 0.69331 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:34:49.922228 ops/training.py:65 2019-01-16 20:34:49.922124: step 3944, loss = 0.68988 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:34:50.817650 ops/training.py:65 2019-01-16 20:34:50.817542: step 3945, loss = 0.69451 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:34:51.713158 ops/training.py:65 2019-01-16 20:34:51.713050: step 3946, loss = 0.69408 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:34:52.609733 ops/training.py:65 2019-01-16 20:34:52.609627: step 3947, loss = 0.69189 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:34:53.505882 ops/training.py:65 2019-01-16 20:34:53.505769: step 3948, loss = 0.69875 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:34:54.399697 ops/training.py:65 2019-01-16 20:34:54.399590: step 3949, loss = 0.69686 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:34:55.294841 ops/training.py:65 2019-01-16 20:34:55.294736: step 3950, loss = 0.69324 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:34:56.189233 ops/training.py:65 2019-01-16 20:34:56.189131: step 3951, loss = 0.69673 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:34:57.083574 ops/training.py:65 2019-01-16 20:34:57.083463: step 3952, loss = 0.69269 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:34:57.977481 ops/training.py:65 2019-01-16 20:34:57.977382: step 3953, loss = 0.69825 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:34:58.872067 ops/training.py:65 2019-01-16 20:34:58.871956: step 3954, loss = 0.69667 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:34:59.766954 ops/training.py:65 2019-01-16 20:34:59.766842: step 3955, loss = 0.69312 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:35:00.662472 ops/training.py:65 2019-01-16 20:35:00.662333: step 3956, loss = 0.69579 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:35:01.557415 ops/training.py:65 2019-01-16 20:35:01.557312: step 3957, loss = 0.69138 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:35:02.452213 ops/training.py:65 2019-01-16 20:35:02.452118: step 3958, loss = 0.68920 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:35:03.345392 ops/training.py:65 2019-01-16 20:35:03.345269: step 3959, loss = 0.69412 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:35:04.239614 ops/training.py:65 2019-01-16 20:35:04.239509: step 3960, loss = 0.68932 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:35:05.136632 ops/training.py:65 2019-01-16 20:35:05.136530: step 3961, loss = 0.69224 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:35:06.033331 ops/training.py:65 2019-01-16 20:35:06.033226: step 3962, loss = 0.68705 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:35:06.926402 ops/training.py:65 2019-01-16 20:35:06.926299: step 3963, loss = 0.69268 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:35:07.820832 ops/training.py:65 2019-01-16 20:35:07.820724: step 3964, loss = 0.69657 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:35:08.715304 ops/training.py:65 2019-01-16 20:35:08.715222: step 3965, loss = 0.69404 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:35:09.609951 ops/training.py:65 2019-01-16 20:35:09.609847: step 3966, loss = 0.69373 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:35:10.506884 ops/training.py:65 2019-01-16 20:35:10.506780: step 3967, loss = 0.69014 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:35:11.400560 ops/training.py:65 2019-01-16 20:35:11.400453: step 3968, loss = 0.69723 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:35:12.295051 ops/training.py:65 2019-01-16 20:35:12.294951: step 3969, loss = 0.69086 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:35:13.188883 ops/training.py:65 2019-01-16 20:35:13.188740: step 3970, loss = 0.69302 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:35:14.083820 ops/training.py:65 2019-01-16 20:35:14.083717: step 3971, loss = 0.69708 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:35:14.978239 ops/training.py:65 2019-01-16 20:35:14.978137: step 3972, loss = 0.69288 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:35:15.873217 ops/training.py:65 2019-01-16 20:35:15.873110: step 3973, loss = 0.68933 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:35:16.768774 ops/training.py:65 2019-01-16 20:35:16.768668: step 3974, loss = 0.69051 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:35:17.665410 ops/training.py:65 2019-01-16 20:35:17.665304: step 3975, loss = 0.69268 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:35:18.559043 ops/training.py:65 2019-01-16 20:35:18.558938: step 3976, loss = 0.69646 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:35:19.454033 ops/training.py:65 2019-01-16 20:35:19.453953: step 3977, loss = 0.69489 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:35:20.350994 ops/training.py:65 2019-01-16 20:35:20.350886: step 3978, loss = 0.68841 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:35:21.246259 ops/training.py:65 2019-01-16 20:35:21.246152: step 3979, loss = 0.69909 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 20:35:22.142562 ops/training.py:65 2019-01-16 20:35:22.142460: step 3980, loss = 0.69596 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:35:23.036274 ops/training.py:65 2019-01-16 20:35:23.036170: step 3981, loss = 0.69687 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:35:23.933220 ops/training.py:65 2019-01-16 20:35:23.933135: step 3982, loss = 0.69524 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:35:24.829979 ops/training.py:65 2019-01-16 20:35:24.829872: step 3983, loss = 0.69445 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:35:25.726075 ops/training.py:65 2019-01-16 20:35:25.725972: step 3984, loss = 0.69118 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:35:26.622277 ops/training.py:65 2019-01-16 20:35:26.622150: step 3985, loss = 0.69125 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:35:27.520531 ops/training.py:65 2019-01-16 20:35:27.520422: step 3986, loss = 0.69148 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:35:28.417536 ops/training.py:65 2019-01-16 20:35:28.417417: step 3987, loss = 0.69206 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:35:29.313071 ops/training.py:65 2019-01-16 20:35:29.312968: step 3988, loss = 0.69495 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:35:30.207756 ops/training.py:65 2019-01-16 20:35:30.207652: step 3989, loss = 0.69219 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:35:31.102050 ops/training.py:65 2019-01-16 20:35:31.101944: step 3990, loss = 0.69175 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:35:31.999105 ops/training.py:65 2019-01-16 20:35:31.998966: step 3991, loss = 0.68923 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:35:32.895158 ops/training.py:65 2019-01-16 20:35:32.895053: step 3992, loss = 0.70106 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:35:33.793245 ops/training.py:65 2019-01-16 20:35:33.793096: step 3993, loss = 0.69257 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:35:34.689484 ops/training.py:65 2019-01-16 20:35:34.689383: step 3994, loss = 0.68958 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:35:35.584375 ops/training.py:65 2019-01-16 20:35:35.584273: step 3995, loss = 0.69069 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:35:36.479452 ops/training.py:65 2019-01-16 20:35:36.479347: step 3996, loss = 0.69304 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:35:37.376541 ops/training.py:65 2019-01-16 20:35:37.376437: step 3997, loss = 0.69434 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:35:38.270442 ops/training.py:65 2019-01-16 20:35:38.270332: step 3998, loss = 0.69214 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:35:39.165777 ops/training.py:65 2019-01-16 20:35:39.165673: step 3999, loss = 0.69023 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:39:54.155879 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I1280 2019-01-16 20:39:54.156839 ops/training.py:41 2019-01-16 20:39:54.156777: step 4000, loss = 0.69 (0.1 examples/sec; 254.095 sec/batch) | Training accuracy = 0.53125 | Validation accuracy = 0.4923 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_19_26_22_049623
I1280 2019-01-16 20:39:55.054727 ops/training.py:65 2019-01-16 20:39:55.054624: step 4001, loss = 0.69307 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:39:55.951240 ops/training.py:65 2019-01-16 20:39:55.951124: step 4002, loss = 0.69373 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:39:56.848708 ops/training.py:65 2019-01-16 20:39:56.848601: step 4003, loss = 0.69315 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:39:57.742068 ops/training.py:65 2019-01-16 20:39:57.741968: step 4004, loss = 0.68963 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:39:58.636658 ops/training.py:65 2019-01-16 20:39:58.636551: step 4005, loss = 0.69130 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:39:59.533134 ops/training.py:65 2019-01-16 20:39:59.533020: step 4006, loss = 0.69680 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:40:00.431094 ops/training.py:65 2019-01-16 20:40:00.430979: step 4007, loss = 0.69779 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:40:01.327853 ops/training.py:65 2019-01-16 20:40:01.327746: step 4008, loss = 0.69234 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:40:02.225060 ops/training.py:65 2019-01-16 20:40:02.224977: step 4009, loss = 0.69449 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:40:03.122395 ops/training.py:65 2019-01-16 20:40:03.122306: step 4010, loss = 0.69343 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:40:04.016855 ops/training.py:65 2019-01-16 20:40:04.016756: step 4011, loss = 0.69687 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:40:04.913518 ops/training.py:65 2019-01-16 20:40:04.913418: step 4012, loss = 0.68922 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:40:05.809590 ops/training.py:65 2019-01-16 20:40:05.809497: step 4013, loss = 0.69542 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:40:06.705203 ops/training.py:65 2019-01-16 20:40:06.705111: step 4014, loss = 0.69637 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:40:07.600488 ops/training.py:65 2019-01-16 20:40:07.600388: step 4015, loss = 0.69156 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:40:08.495196 ops/training.py:65 2019-01-16 20:40:08.495117: step 4016, loss = 0.69727 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:40:09.389706 ops/training.py:65 2019-01-16 20:40:09.389609: step 4017, loss = 0.69497 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:40:10.284133 ops/training.py:65 2019-01-16 20:40:10.284032: step 4018, loss = 0.69399 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:40:11.180053 ops/training.py:65 2019-01-16 20:40:11.179997: step 4019, loss = 0.69439 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:40:12.077142 ops/training.py:65 2019-01-16 20:40:12.077053: step 4020, loss = 0.69040 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:40:12.974102 ops/training.py:65 2019-01-16 20:40:12.973998: step 4021, loss = 0.69080 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:40:13.874628 ops/training.py:65 2019-01-16 20:40:13.874534: step 4022, loss = 0.69488 (35.6 examples/sec; 0.899 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:40:14.770215 ops/training.py:65 2019-01-16 20:40:14.770107: step 4023, loss = 0.69677 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:40:15.667488 ops/training.py:65 2019-01-16 20:40:15.667385: step 4024, loss = 0.69383 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:40:16.563990 ops/training.py:65 2019-01-16 20:40:16.563887: step 4025, loss = 0.69580 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:40:17.460707 ops/training.py:65 2019-01-16 20:40:17.460607: step 4026, loss = 0.69218 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:40:18.357112 ops/training.py:65 2019-01-16 20:40:18.357007: step 4027, loss = 0.68705 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.75
I1280 2019-01-16 20:40:19.251847 ops/training.py:65 2019-01-16 20:40:19.251742: step 4028, loss = 0.69497 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:40:20.145592 ops/training.py:65 2019-01-16 20:40:20.145524: step 4029, loss = 0.69471 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:40:21.040895 ops/training.py:65 2019-01-16 20:40:21.040802: step 4030, loss = 0.69781 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:40:21.938354 ops/training.py:65 2019-01-16 20:40:21.938259: step 4031, loss = 0.68306 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.78125
I1280 2019-01-16 20:40:22.834745 ops/training.py:65 2019-01-16 20:40:22.834673: step 4032, loss = 0.69497 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:40:23.729733 ops/training.py:65 2019-01-16 20:40:23.729667: step 4033, loss = 0.69469 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:40:24.622940 ops/training.py:65 2019-01-16 20:40:24.622882: step 4034, loss = 0.69310 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:40:25.516161 ops/training.py:65 2019-01-16 20:40:25.516100: step 4035, loss = 0.69260 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:40:26.410087 ops/training.py:65 2019-01-16 20:40:26.410020: step 4036, loss = 0.69512 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:40:27.306784 ops/training.py:65 2019-01-16 20:40:27.306694: step 4037, loss = 0.69220 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:40:28.203570 ops/training.py:65 2019-01-16 20:40:28.203441: step 4038, loss = 0.69624 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:40:29.100830 ops/training.py:65 2019-01-16 20:40:29.100717: step 4039, loss = 0.69430 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:40:29.998530 ops/training.py:65 2019-01-16 20:40:29.998426: step 4040, loss = 0.68952 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:40:30.895484 ops/training.py:65 2019-01-16 20:40:30.895379: step 4041, loss = 0.69452 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:40:31.791597 ops/training.py:65 2019-01-16 20:40:31.791474: step 4042, loss = 0.69369 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:40:32.688346 ops/training.py:65 2019-01-16 20:40:32.688235: step 4043, loss = 0.69430 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:40:33.583792 ops/training.py:65 2019-01-16 20:40:33.583687: step 4044, loss = 0.69626 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:40:34.479454 ops/training.py:65 2019-01-16 20:40:34.479372: step 4045, loss = 0.69900 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 20:40:35.376027 ops/training.py:65 2019-01-16 20:40:35.375932: step 4046, loss = 0.69254 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:40:36.271781 ops/training.py:65 2019-01-16 20:40:36.271680: step 4047, loss = 0.69511 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:40:37.168837 ops/training.py:65 2019-01-16 20:40:37.168774: step 4048, loss = 0.68963 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:40:38.063246 ops/training.py:65 2019-01-16 20:40:38.063178: step 4049, loss = 0.68902 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:40:38.958282 ops/training.py:65 2019-01-16 20:40:38.958196: step 4050, loss = 0.69341 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:40:39.853726 ops/training.py:65 2019-01-16 20:40:39.853601: step 4051, loss = 0.68784 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:40:40.755555 ops/training.py:65 2019-01-16 20:40:40.755423: step 4052, loss = 0.69274 (35.5 examples/sec; 0.900 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:40:41.652525 ops/training.py:65 2019-01-16 20:40:41.652416: step 4053, loss = 0.69106 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:40:42.547273 ops/training.py:65 2019-01-16 20:40:42.547171: step 4054, loss = 0.69353 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:40:43.442161 ops/training.py:65 2019-01-16 20:40:43.442067: step 4055, loss = 0.69246 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:40:44.339375 ops/training.py:65 2019-01-16 20:40:44.339268: step 4056, loss = 0.68822 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:40:45.234822 ops/training.py:65 2019-01-16 20:40:45.234722: step 4057, loss = 0.69518 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:40:46.129648 ops/training.py:65 2019-01-16 20:40:46.129588: step 4058, loss = 0.69694 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:40:47.023209 ops/training.py:65 2019-01-16 20:40:47.023155: step 4059, loss = 0.69416 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:40:47.917378 ops/training.py:65 2019-01-16 20:40:47.917318: step 4060, loss = 0.69341 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:40:48.811848 ops/training.py:65 2019-01-16 20:40:48.811793: step 4061, loss = 0.69302 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:40:49.704503 ops/training.py:65 2019-01-16 20:40:49.704447: step 4062, loss = 0.69666 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:40:50.597743 ops/training.py:65 2019-01-16 20:40:50.597686: step 4063, loss = 0.69197 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:40:51.490712 ops/training.py:65 2019-01-16 20:40:51.490643: step 4064, loss = 0.69471 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:40:52.383836 ops/training.py:65 2019-01-16 20:40:52.383738: step 4065, loss = 0.69508 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:40:53.280067 ops/training.py:65 2019-01-16 20:40:53.279955: step 4066, loss = 0.69533 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:40:54.176970 ops/training.py:65 2019-01-16 20:40:54.176870: step 4067, loss = 0.69966 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:40:55.075587 ops/training.py:65 2019-01-16 20:40:55.075483: step 4068, loss = 0.69410 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:40:55.973118 ops/training.py:65 2019-01-16 20:40:55.973053: step 4069, loss = 0.69176 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:40:56.868730 ops/training.py:65 2019-01-16 20:40:56.868668: step 4070, loss = 0.69548 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:40:57.764172 ops/training.py:65 2019-01-16 20:40:57.764067: step 4071, loss = 0.69378 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:40:58.662321 ops/training.py:65 2019-01-16 20:40:58.662215: step 4072, loss = 0.69383 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:40:59.559211 ops/training.py:65 2019-01-16 20:40:59.559148: step 4073, loss = 0.69313 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:41:00.455453 ops/training.py:65 2019-01-16 20:41:00.455350: step 4074, loss = 0.68961 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:41:01.352334 ops/training.py:65 2019-01-16 20:41:01.352226: step 4075, loss = 0.70260 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:41:02.248009 ops/training.py:65 2019-01-16 20:41:02.247916: step 4076, loss = 0.69604 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:41:03.144941 ops/training.py:65 2019-01-16 20:41:03.144856: step 4077, loss = 0.69557 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:41:04.042124 ops/training.py:65 2019-01-16 20:41:04.041999: step 4078, loss = 0.68752 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:41:04.938386 ops/training.py:65 2019-01-16 20:41:04.938261: step 4079, loss = 0.68945 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:41:05.833112 ops/training.py:65 2019-01-16 20:41:05.832984: step 4080, loss = 0.69174 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:41:06.728377 ops/training.py:65 2019-01-16 20:41:06.728282: step 4081, loss = 0.69238 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:41:07.625753 ops/training.py:65 2019-01-16 20:41:07.625648: step 4082, loss = 0.69361 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:41:08.521853 ops/training.py:65 2019-01-16 20:41:08.521737: step 4083, loss = 0.69006 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:41:09.416303 ops/training.py:65 2019-01-16 20:41:09.416184: step 4084, loss = 0.69330 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:41:10.311183 ops/training.py:65 2019-01-16 20:41:10.311098: step 4085, loss = 0.69167 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:41:11.206673 ops/training.py:65 2019-01-16 20:41:11.206576: step 4086, loss = 0.69685 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:41:12.101664 ops/training.py:65 2019-01-16 20:41:12.101547: step 4087, loss = 0.69789 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:41:12.997180 ops/training.py:65 2019-01-16 20:41:12.997061: step 4088, loss = 0.69182 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:41:13.893314 ops/training.py:65 2019-01-16 20:41:13.893214: step 4089, loss = 0.69395 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:41:14.788316 ops/training.py:65 2019-01-16 20:41:14.788192: step 4090, loss = 0.69608 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:41:15.682959 ops/training.py:65 2019-01-16 20:41:15.682867: step 4091, loss = 0.68770 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:41:16.577444 ops/training.py:65 2019-01-16 20:41:16.577351: step 4092, loss = 0.69529 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:41:17.472772 ops/training.py:65 2019-01-16 20:41:17.472672: step 4093, loss = 0.68829 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:41:18.368846 ops/training.py:65 2019-01-16 20:41:18.368748: step 4094, loss = 0.69160 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:41:19.264807 ops/training.py:65 2019-01-16 20:41:19.264704: step 4095, loss = 0.69488 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:41:20.159858 ops/training.py:65 2019-01-16 20:41:20.159752: step 4096, loss = 0.69215 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:41:21.056658 ops/training.py:65 2019-01-16 20:41:21.056564: step 4097, loss = 0.69606 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:41:21.952858 ops/training.py:65 2019-01-16 20:41:21.952765: step 4098, loss = 0.68920 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:41:22.849446 ops/training.py:65 2019-01-16 20:41:22.849349: step 4099, loss = 0.69327 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:41:23.744583 ops/training.py:65 2019-01-16 20:41:23.744485: step 4100, loss = 0.69513 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:41:24.642455 ops/training.py:65 2019-01-16 20:41:24.642339: step 4101, loss = 0.69294 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:41:25.539473 ops/training.py:65 2019-01-16 20:41:25.539371: step 4102, loss = 0.69591 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:41:26.434941 ops/training.py:65 2019-01-16 20:41:26.434843: step 4103, loss = 0.69322 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:41:27.330279 ops/training.py:65 2019-01-16 20:41:27.330187: step 4104, loss = 0.69705 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:41:28.226114 ops/training.py:65 2019-01-16 20:41:28.226019: step 4105, loss = 0.69048 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:41:29.122786 ops/training.py:65 2019-01-16 20:41:29.122688: step 4106, loss = 0.69234 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:41:30.017589 ops/training.py:65 2019-01-16 20:41:30.017496: step 4107, loss = 0.68590 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:41:30.913265 ops/training.py:65 2019-01-16 20:41:30.913167: step 4108, loss = 0.69200 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:41:31.810937 ops/training.py:65 2019-01-16 20:41:31.810842: step 4109, loss = 0.69523 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:41:32.705181 ops/training.py:65 2019-01-16 20:41:32.705083: step 4110, loss = 0.69522 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:41:33.600297 ops/training.py:65 2019-01-16 20:41:33.600200: step 4111, loss = 0.69473 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:41:34.494366 ops/training.py:65 2019-01-16 20:41:34.494274: step 4112, loss = 0.70008 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 20:41:35.387609 ops/training.py:65 2019-01-16 20:41:35.387475: step 4113, loss = 0.68903 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:41:36.282940 ops/training.py:65 2019-01-16 20:41:36.282841: step 4114, loss = 0.69600 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:41:37.178308 ops/training.py:65 2019-01-16 20:41:37.178204: step 4115, loss = 0.69573 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:41:38.076676 ops/training.py:65 2019-01-16 20:41:38.076573: step 4116, loss = 0.69109 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:41:38.972317 ops/training.py:65 2019-01-16 20:41:38.972228: step 4117, loss = 0.69261 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:41:39.866874 ops/training.py:65 2019-01-16 20:41:39.866770: step 4118, loss = 0.69410 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:41:40.762319 ops/training.py:65 2019-01-16 20:41:40.762184: step 4119, loss = 0.69269 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:41:41.657745 ops/training.py:65 2019-01-16 20:41:41.657643: step 4120, loss = 0.69619 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:41:42.552451 ops/training.py:65 2019-01-16 20:41:42.552345: step 4121, loss = 0.69801 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:41:43.448737 ops/training.py:65 2019-01-16 20:41:43.448633: step 4122, loss = 0.69534 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:41:44.345054 ops/training.py:65 2019-01-16 20:41:44.344964: step 4123, loss = 0.69608 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:41:45.240612 ops/training.py:65 2019-01-16 20:41:45.240497: step 4124, loss = 0.68995 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:41:46.140644 ops/training.py:65 2019-01-16 20:41:46.140533: step 4125, loss = 0.69655 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:41:47.035541 ops/training.py:65 2019-01-16 20:41:47.035438: step 4126, loss = 0.69263 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:41:47.931869 ops/training.py:65 2019-01-16 20:41:47.931776: step 4127, loss = 0.69228 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:41:48.829357 ops/training.py:65 2019-01-16 20:41:48.829256: step 4128, loss = 0.69166 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:41:49.722996 ops/training.py:65 2019-01-16 20:41:49.722894: step 4129, loss = 0.69059 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:41:50.617423 ops/training.py:65 2019-01-16 20:41:50.617317: step 4130, loss = 0.69039 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:41:51.512237 ops/training.py:65 2019-01-16 20:41:51.512127: step 4131, loss = 0.69488 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:41:52.409154 ops/training.py:65 2019-01-16 20:41:52.409062: step 4132, loss = 0.69475 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:41:53.304494 ops/training.py:65 2019-01-16 20:41:53.304394: step 4133, loss = 0.68922 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:41:54.200409 ops/training.py:65 2019-01-16 20:41:54.200342: step 4134, loss = 0.69719 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:41:55.096345 ops/training.py:65 2019-01-16 20:41:55.096250: step 4135, loss = 0.69512 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:41:55.992424 ops/training.py:65 2019-01-16 20:41:55.992354: step 4136, loss = 0.69727 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:41:56.889192 ops/training.py:65 2019-01-16 20:41:56.889114: step 4137, loss = 0.69615 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:41:57.787785 ops/training.py:65 2019-01-16 20:41:57.787676: step 4138, loss = 0.69702 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:41:58.683598 ops/training.py:65 2019-01-16 20:41:58.683527: step 4139, loss = 0.68874 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:41:59.577552 ops/training.py:65 2019-01-16 20:41:59.577486: step 4140, loss = 0.69488 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:42:00.471141 ops/training.py:65 2019-01-16 20:42:00.471069: step 4141, loss = 0.69774 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:42:01.364188 ops/training.py:65 2019-01-16 20:42:01.364118: step 4142, loss = 0.69185 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:42:02.257908 ops/training.py:65 2019-01-16 20:42:02.257831: step 4143, loss = 0.69030 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:42:03.153225 ops/training.py:65 2019-01-16 20:42:03.153127: step 4144, loss = 0.69667 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:42:04.047583 ops/training.py:65 2019-01-16 20:42:04.047515: step 4145, loss = 0.69377 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:42:04.941440 ops/training.py:65 2019-01-16 20:42:04.941381: step 4146, loss = 0.69117 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:42:05.835273 ops/training.py:65 2019-01-16 20:42:05.835206: step 4147, loss = 0.69224 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:42:06.728067 ops/training.py:65 2019-01-16 20:42:06.728005: step 4148, loss = 0.69488 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:42:07.623405 ops/training.py:65 2019-01-16 20:42:07.623331: step 4149, loss = 0.69047 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:42:08.519750 ops/training.py:65 2019-01-16 20:42:08.519653: step 4150, loss = 0.69733 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 20:42:09.415352 ops/training.py:65 2019-01-16 20:42:09.415252: step 4151, loss = 0.69482 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:42:10.310319 ops/training.py:65 2019-01-16 20:42:10.310217: step 4152, loss = 0.69192 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:42:11.207007 ops/training.py:65 2019-01-16 20:42:11.206901: step 4153, loss = 0.69285 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:42:12.102831 ops/training.py:65 2019-01-16 20:42:12.102761: step 4154, loss = 0.69790 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:42:12.997181 ops/training.py:65 2019-01-16 20:42:12.997113: step 4155, loss = 0.69225 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:42:13.891813 ops/training.py:65 2019-01-16 20:42:13.891743: step 4156, loss = 0.69244 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:42:14.786796 ops/training.py:65 2019-01-16 20:42:14.786691: step 4157, loss = 0.69476 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:42:15.683918 ops/training.py:65 2019-01-16 20:42:15.683813: step 4158, loss = 0.69281 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:42:16.579854 ops/training.py:65 2019-01-16 20:42:16.579784: step 4159, loss = 0.69141 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:42:17.474459 ops/training.py:65 2019-01-16 20:42:17.474389: step 4160, loss = 0.68882 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:42:18.371649 ops/training.py:65 2019-01-16 20:42:18.371578: step 4161, loss = 0.68862 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:42:19.270142 ops/training.py:65 2019-01-16 20:42:19.270034: step 4162, loss = 0.68995 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:42:20.166727 ops/training.py:65 2019-01-16 20:42:20.166655: step 4163, loss = 0.69368 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:42:21.063338 ops/training.py:65 2019-01-16 20:42:21.063261: step 4164, loss = 0.69525 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:42:21.959950 ops/training.py:65 2019-01-16 20:42:21.959817: step 4165, loss = 0.69541 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:42:22.856302 ops/training.py:65 2019-01-16 20:42:22.856209: step 4166, loss = 0.68521 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:42:23.750015 ops/training.py:65 2019-01-16 20:42:23.749959: step 4167, loss = 0.68925 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:42:24.644090 ops/training.py:65 2019-01-16 20:42:24.643991: step 4168, loss = 0.68928 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:42:25.540686 ops/training.py:65 2019-01-16 20:42:25.540579: step 4169, loss = 0.69139 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:42:26.438092 ops/training.py:65 2019-01-16 20:42:26.437976: step 4170, loss = 0.69153 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:42:27.335065 ops/training.py:65 2019-01-16 20:42:27.334972: step 4171, loss = 0.69418 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:42:28.230842 ops/training.py:65 2019-01-16 20:42:28.230747: step 4172, loss = 0.69520 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:42:29.125798 ops/training.py:65 2019-01-16 20:42:29.125739: step 4173, loss = 0.69219 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:42:30.018710 ops/training.py:65 2019-01-16 20:42:30.018654: step 4174, loss = 0.69282 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:42:30.913019 ops/training.py:65 2019-01-16 20:42:30.912953: step 4175, loss = 0.69440 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:42:31.809540 ops/training.py:65 2019-01-16 20:42:31.809474: step 4176, loss = 0.69499 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:42:32.705491 ops/training.py:65 2019-01-16 20:42:32.705436: step 4177, loss = 0.69092 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:42:33.599962 ops/training.py:65 2019-01-16 20:42:33.599898: step 4178, loss = 0.69434 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:42:34.495261 ops/training.py:65 2019-01-16 20:42:34.495207: step 4179, loss = 0.69150 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:42:35.390851 ops/training.py:65 2019-01-16 20:42:35.390770: step 4180, loss = 0.69603 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:42:36.286260 ops/training.py:65 2019-01-16 20:42:36.286201: step 4181, loss = 0.69364 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:42:37.179482 ops/training.py:65 2019-01-16 20:42:37.179422: step 4182, loss = 0.69298 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:42:38.073669 ops/training.py:65 2019-01-16 20:42:38.073613: step 4183, loss = 0.69324 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:42:38.966528 ops/training.py:65 2019-01-16 20:42:38.966462: step 4184, loss = 0.70025 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.25
I1280 2019-01-16 20:42:39.861890 ops/training.py:65 2019-01-16 20:42:39.861804: step 4185, loss = 0.69508 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:42:40.756842 ops/training.py:65 2019-01-16 20:42:40.756779: step 4186, loss = 0.69548 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:42:41.651367 ops/training.py:65 2019-01-16 20:42:41.651309: step 4187, loss = 0.69274 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:42:42.545222 ops/training.py:65 2019-01-16 20:42:42.545169: step 4188, loss = 0.68803 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:42:43.438802 ops/training.py:65 2019-01-16 20:42:43.438743: step 4189, loss = 0.69489 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:42:44.333380 ops/training.py:65 2019-01-16 20:42:44.333319: step 4190, loss = 0.69345 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:42:45.226931 ops/training.py:65 2019-01-16 20:42:45.226888: step 4191, loss = 0.69296 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:42:46.123190 ops/training.py:65 2019-01-16 20:42:46.123145: step 4192, loss = 0.69240 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:42:47.021429 ops/training.py:65 2019-01-16 20:42:47.021365: step 4193, loss = 0.69638 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:42:47.915659 ops/training.py:65 2019-01-16 20:42:47.915601: step 4194, loss = 0.68898 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:42:48.809550 ops/training.py:65 2019-01-16 20:42:48.809497: step 4195, loss = 0.69209 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:42:49.702697 ops/training.py:65 2019-01-16 20:42:49.702639: step 4196, loss = 0.68986 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:42:50.596472 ops/training.py:65 2019-01-16 20:42:50.596409: step 4197, loss = 0.69232 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:42:51.490886 ops/training.py:65 2019-01-16 20:42:51.490828: step 4198, loss = 0.69306 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:42:52.385681 ops/training.py:65 2019-01-16 20:42:52.385627: step 4199, loss = 0.69155 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:42:53.281558 ops/training.py:65 2019-01-16 20:42:53.281502: step 4200, loss = 0.69016 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:42:54.177719 ops/training.py:65 2019-01-16 20:42:54.177661: step 4201, loss = 0.69332 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:42:55.071833 ops/training.py:65 2019-01-16 20:42:55.071774: step 4202, loss = 0.69390 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:42:55.966212 ops/training.py:65 2019-01-16 20:42:55.966155: step 4203, loss = 0.69312 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:42:56.860753 ops/training.py:65 2019-01-16 20:42:56.860690: step 4204, loss = 0.69586 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:42:57.754188 ops/training.py:65 2019-01-16 20:42:57.754134: step 4205, loss = 0.69273 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:42:58.648669 ops/training.py:65 2019-01-16 20:42:58.648618: step 4206, loss = 0.69459 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:42:59.545040 ops/training.py:65 2019-01-16 20:42:59.544972: step 4207, loss = 0.68778 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:43:00.443931 ops/training.py:65 2019-01-16 20:43:00.443835: step 4208, loss = 0.69466 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:43:01.341933 ops/training.py:65 2019-01-16 20:43:01.341840: step 4209, loss = 0.69480 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:43:02.237642 ops/training.py:65 2019-01-16 20:43:02.237593: step 4210, loss = 0.69061 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:43:03.133385 ops/training.py:65 2019-01-16 20:43:03.133321: step 4211, loss = 0.68987 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:43:04.028496 ops/training.py:65 2019-01-16 20:43:04.028442: step 4212, loss = 0.69359 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:43:04.922924 ops/training.py:65 2019-01-16 20:43:04.922866: step 4213, loss = 0.69767 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:43:05.816463 ops/training.py:65 2019-01-16 20:43:05.816405: step 4214, loss = 0.68924 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:43:06.711335 ops/training.py:65 2019-01-16 20:43:06.711280: step 4215, loss = 0.69287 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:43:07.606568 ops/training.py:65 2019-01-16 20:43:07.606509: step 4216, loss = 0.69682 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:43:08.500343 ops/training.py:65 2019-01-16 20:43:08.500283: step 4217, loss = 0.69224 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:43:09.395582 ops/training.py:65 2019-01-16 20:43:09.395512: step 4218, loss = 0.69191 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:43:10.291721 ops/training.py:65 2019-01-16 20:43:10.291637: step 4219, loss = 0.69143 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:43:11.186551 ops/training.py:65 2019-01-16 20:43:11.186463: step 4220, loss = 0.69222 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:43:12.082520 ops/training.py:65 2019-01-16 20:43:12.082440: step 4221, loss = 0.69425 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:43:12.978628 ops/training.py:65 2019-01-16 20:43:12.978539: step 4222, loss = 0.69764 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:43:13.875114 ops/training.py:65 2019-01-16 20:43:13.875021: step 4223, loss = 0.69153 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:43:14.772369 ops/training.py:65 2019-01-16 20:43:14.772285: step 4224, loss = 0.69192 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:43:15.666344 ops/training.py:65 2019-01-16 20:43:15.666277: step 4225, loss = 0.69535 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:43:16.561549 ops/training.py:65 2019-01-16 20:43:16.561487: step 4226, loss = 0.69181 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:43:17.456674 ops/training.py:65 2019-01-16 20:43:17.456613: step 4227, loss = 0.69240 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:43:18.352586 ops/training.py:65 2019-01-16 20:43:18.352529: step 4228, loss = 0.69268 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:43:19.247632 ops/training.py:65 2019-01-16 20:43:19.247575: step 4229, loss = 0.69240 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:43:20.142294 ops/training.py:65 2019-01-16 20:43:20.142235: step 4230, loss = 0.68926 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:43:21.035360 ops/training.py:65 2019-01-16 20:43:21.035302: step 4231, loss = 0.69310 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:43:21.930334 ops/training.py:65 2019-01-16 20:43:21.930276: step 4232, loss = 0.69167 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:43:22.824611 ops/training.py:65 2019-01-16 20:43:22.824553: step 4233, loss = 0.69446 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:43:23.718334 ops/training.py:65 2019-01-16 20:43:23.718271: step 4234, loss = 0.69632 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:43:24.613264 ops/training.py:65 2019-01-16 20:43:24.613208: step 4235, loss = 0.69007 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:43:25.507874 ops/training.py:65 2019-01-16 20:43:25.507804: step 4236, loss = 0.69281 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:43:26.405399 ops/training.py:65 2019-01-16 20:43:26.405341: step 4237, loss = 0.69927 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:43:27.303998 ops/training.py:65 2019-01-16 20:43:27.303906: step 4238, loss = 0.69295 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:43:28.200227 ops/training.py:65 2019-01-16 20:43:28.200174: step 4239, loss = 0.69584 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:43:29.095186 ops/training.py:65 2019-01-16 20:43:29.095128: step 4240, loss = 0.69511 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:43:29.991229 ops/training.py:65 2019-01-16 20:43:29.991146: step 4241, loss = 0.69835 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:43:30.887918 ops/training.py:65 2019-01-16 20:43:30.887830: step 4242, loss = 0.69652 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:43:31.783744 ops/training.py:65 2019-01-16 20:43:31.783684: step 4243, loss = 0.69280 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:43:32.678307 ops/training.py:65 2019-01-16 20:43:32.678241: step 4244, loss = 0.69165 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:43:33.573344 ops/training.py:65 2019-01-16 20:43:33.573290: step 4245, loss = 0.69612 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:43:34.468333 ops/training.py:65 2019-01-16 20:43:34.468279: step 4246, loss = 0.69709 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:43:35.364716 ops/training.py:65 2019-01-16 20:43:35.364658: step 4247, loss = 0.69528 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:43:36.258978 ops/training.py:65 2019-01-16 20:43:36.258924: step 4248, loss = 0.69471 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:43:37.152995 ops/training.py:65 2019-01-16 20:43:37.152939: step 4249, loss = 0.69449 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:43:38.048513 ops/training.py:65 2019-01-16 20:43:38.048450: step 4250, loss = 0.69084 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:43:38.946032 ops/training.py:65 2019-01-16 20:43:38.945952: step 4251, loss = 0.69585 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:43:39.842353 ops/training.py:65 2019-01-16 20:43:39.842266: step 4252, loss = 0.68897 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:43:40.737260 ops/training.py:65 2019-01-16 20:43:40.737190: step 4253, loss = 0.69397 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:43:41.632014 ops/training.py:65 2019-01-16 20:43:41.631958: step 4254, loss = 0.69261 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:43:42.525714 ops/training.py:65 2019-01-16 20:43:42.525658: step 4255, loss = 0.69208 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:43:43.418955 ops/training.py:65 2019-01-16 20:43:43.418897: step 4256, loss = 0.69530 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:43:44.313552 ops/training.py:65 2019-01-16 20:43:44.313486: step 4257, loss = 0.69063 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:43:45.206143 ops/training.py:65 2019-01-16 20:43:45.206092: step 4258, loss = 0.68650 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:43:46.100013 ops/training.py:65 2019-01-16 20:43:46.099951: step 4259, loss = 0.69189 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:43:46.995414 ops/training.py:65 2019-01-16 20:43:46.995325: step 4260, loss = 0.68830 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:43:47.891784 ops/training.py:65 2019-01-16 20:43:47.891696: step 4261, loss = 0.69140 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:43:48.788523 ops/training.py:65 2019-01-16 20:43:48.788430: step 4262, loss = 0.69224 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:43:49.684249 ops/training.py:65 2019-01-16 20:43:49.684161: step 4263, loss = 0.69082 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:43:50.578364 ops/training.py:65 2019-01-16 20:43:50.578277: step 4264, loss = 0.69376 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:43:51.473064 ops/training.py:65 2019-01-16 20:43:51.472973: step 4265, loss = 0.69628 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:43:52.366989 ops/training.py:65 2019-01-16 20:43:52.366912: step 4266, loss = 0.70132 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:43:53.260959 ops/training.py:65 2019-01-16 20:43:53.260870: step 4267, loss = 0.69141 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:43:54.157728 ops/training.py:65 2019-01-16 20:43:54.157637: step 4268, loss = 0.69313 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:43:55.053518 ops/training.py:65 2019-01-16 20:43:55.053444: step 4269, loss = 0.69553 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:43:55.949426 ops/training.py:65 2019-01-16 20:43:55.949333: step 4270, loss = 0.69330 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:43:56.846030 ops/training.py:65 2019-01-16 20:43:56.845959: step 4271, loss = 0.69965 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:43:57.742645 ops/training.py:65 2019-01-16 20:43:57.742563: step 4272, loss = 0.69555 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:43:58.639784 ops/training.py:65 2019-01-16 20:43:58.639697: step 4273, loss = 0.69221 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:43:59.536800 ops/training.py:65 2019-01-16 20:43:59.536710: step 4274, loss = 0.70228 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:44:00.434802 ops/training.py:65 2019-01-16 20:44:00.434715: step 4275, loss = 0.69071 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:44:01.331518 ops/training.py:65 2019-01-16 20:44:01.331457: step 4276, loss = 0.68941 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:44:02.226405 ops/training.py:65 2019-01-16 20:44:02.226354: step 4277, loss = 0.69871 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:44:03.123373 ops/training.py:65 2019-01-16 20:44:03.123265: step 4278, loss = 0.69644 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:44:04.020576 ops/training.py:65 2019-01-16 20:44:04.020490: step 4279, loss = 0.69208 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:44:04.916039 ops/training.py:65 2019-01-16 20:44:04.915980: step 4280, loss = 0.68818 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:44:05.809456 ops/training.py:65 2019-01-16 20:44:05.809402: step 4281, loss = 0.69238 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:44:06.703108 ops/training.py:65 2019-01-16 20:44:06.703051: step 4282, loss = 0.69326 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:44:07.597133 ops/training.py:65 2019-01-16 20:44:07.597076: step 4283, loss = 0.69958 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:44:08.491629 ops/training.py:65 2019-01-16 20:44:08.491566: step 4284, loss = 0.69190 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:44:09.386141 ops/training.py:65 2019-01-16 20:44:09.386071: step 4285, loss = 0.69383 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:44:10.281691 ops/training.py:65 2019-01-16 20:44:10.281603: step 4286, loss = 0.69521 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:44:11.177785 ops/training.py:65 2019-01-16 20:44:11.177726: step 4287, loss = 0.69602 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:44:12.071446 ops/training.py:65 2019-01-16 20:44:12.071394: step 4288, loss = 0.68955 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:44:12.966821 ops/training.py:65 2019-01-16 20:44:12.966768: step 4289, loss = 0.69307 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:44:13.859670 ops/training.py:65 2019-01-16 20:44:13.859606: step 4290, loss = 0.69227 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:44:14.752414 ops/training.py:65 2019-01-16 20:44:14.752352: step 4291, loss = 0.69347 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:44:15.648556 ops/training.py:65 2019-01-16 20:44:15.648483: step 4292, loss = 0.69601 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:44:16.544502 ops/training.py:65 2019-01-16 20:44:16.544411: step 4293, loss = 0.69314 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:44:17.441456 ops/training.py:65 2019-01-16 20:44:17.441363: step 4294, loss = 0.69097 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:44:18.337066 ops/training.py:65 2019-01-16 20:44:18.337001: step 4295, loss = 0.68876 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:44:19.234475 ops/training.py:65 2019-01-16 20:44:19.234384: step 4296, loss = 0.68709 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:44:20.130386 ops/training.py:65 2019-01-16 20:44:20.130328: step 4297, loss = 0.69091 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:44:21.025494 ops/training.py:65 2019-01-16 20:44:21.025436: step 4298, loss = 0.69541 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:44:21.923460 ops/training.py:65 2019-01-16 20:44:21.923384: step 4299, loss = 0.68991 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:44:22.820412 ops/training.py:65 2019-01-16 20:44:22.820328: step 4300, loss = 0.68924 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:44:23.717871 ops/training.py:65 2019-01-16 20:44:23.717775: step 4301, loss = 0.69310 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:44:24.613808 ops/training.py:65 2019-01-16 20:44:24.613750: step 4302, loss = 0.69603 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:44:25.508025 ops/training.py:65 2019-01-16 20:44:25.507964: step 4303, loss = 0.69383 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:44:26.402208 ops/training.py:65 2019-01-16 20:44:26.402151: step 4304, loss = 0.69387 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:44:27.295920 ops/training.py:65 2019-01-16 20:44:27.295866: step 4305, loss = 0.69683 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:44:28.190988 ops/training.py:65 2019-01-16 20:44:28.190935: step 4306, loss = 0.69575 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:44:29.086787 ops/training.py:65 2019-01-16 20:44:29.086717: step 4307, loss = 0.69677 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:44:29.982660 ops/training.py:65 2019-01-16 20:44:29.982567: step 4308, loss = 0.69843 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:44:30.878648 ops/training.py:65 2019-01-16 20:44:30.878595: step 4309, loss = 0.69509 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:44:31.773110 ops/training.py:65 2019-01-16 20:44:31.773056: step 4310, loss = 0.69147 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:44:32.666979 ops/training.py:65 2019-01-16 20:44:32.666920: step 4311, loss = 0.70251 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.25
I1280 2019-01-16 20:44:33.561763 ops/training.py:65 2019-01-16 20:44:33.561709: step 4312, loss = 0.69486 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:44:34.456744 ops/training.py:65 2019-01-16 20:44:34.456680: step 4313, loss = 0.69496 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:44:35.352288 ops/training.py:65 2019-01-16 20:44:35.352228: step 4314, loss = 0.69033 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:44:36.248308 ops/training.py:65 2019-01-16 20:44:36.248250: step 4315, loss = 0.69424 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:44:37.142083 ops/training.py:65 2019-01-16 20:44:37.142026: step 4316, loss = 0.69416 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:44:38.037149 ops/training.py:65 2019-01-16 20:44:38.037090: step 4317, loss = 0.69425 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:44:38.932441 ops/training.py:65 2019-01-16 20:44:38.932365: step 4318, loss = 0.69077 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:44:39.828735 ops/training.py:65 2019-01-16 20:44:39.828645: step 4319, loss = 0.69689 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:44:40.723765 ops/training.py:65 2019-01-16 20:44:40.723686: step 4320, loss = 0.68931 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:44:41.620009 ops/training.py:65 2019-01-16 20:44:41.619914: step 4321, loss = 0.69416 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:44:42.514917 ops/training.py:65 2019-01-16 20:44:42.514829: step 4322, loss = 0.69228 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:44:43.409482 ops/training.py:65 2019-01-16 20:44:43.409392: step 4323, loss = 0.69097 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:44:44.304813 ops/training.py:65 2019-01-16 20:44:44.304724: step 4324, loss = 0.69248 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:44:45.201204 ops/training.py:65 2019-01-16 20:44:45.201119: step 4325, loss = 0.69600 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:44:46.095989 ops/training.py:65 2019-01-16 20:44:46.095901: step 4326, loss = 0.69661 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:44:46.991996 ops/training.py:65 2019-01-16 20:44:46.991908: step 4327, loss = 0.69065 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:44:47.886709 ops/training.py:65 2019-01-16 20:44:47.886618: step 4328, loss = 0.69510 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:44:48.780844 ops/training.py:65 2019-01-16 20:44:48.780751: step 4329, loss = 0.69420 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:44:49.676867 ops/training.py:65 2019-01-16 20:44:49.676780: step 4330, loss = 0.68828 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:44:50.571264 ops/training.py:65 2019-01-16 20:44:50.571176: step 4331, loss = 0.69858 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:44:51.465590 ops/training.py:65 2019-01-16 20:44:51.465499: step 4332, loss = 0.69784 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:44:52.359774 ops/training.py:65 2019-01-16 20:44:52.359690: step 4333, loss = 0.69303 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:44:53.254964 ops/training.py:65 2019-01-16 20:44:53.254875: step 4334, loss = 0.70032 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:44:54.150874 ops/training.py:65 2019-01-16 20:44:54.150787: step 4335, loss = 0.69186 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:44:55.045553 ops/training.py:65 2019-01-16 20:44:55.045486: step 4336, loss = 0.69186 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:44:55.941175 ops/training.py:65 2019-01-16 20:44:55.941085: step 4337, loss = 0.68590 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:44:56.834983 ops/training.py:65 2019-01-16 20:44:56.834902: step 4338, loss = 0.69639 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:44:57.728594 ops/training.py:65 2019-01-16 20:44:57.728502: step 4339, loss = 0.69017 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:44:58.622788 ops/training.py:65 2019-01-16 20:44:58.622697: step 4340, loss = 0.69280 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:44:59.520276 ops/training.py:65 2019-01-16 20:44:59.520185: step 4341, loss = 0.69145 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:45:00.414740 ops/training.py:65 2019-01-16 20:45:00.414651: step 4342, loss = 0.68928 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:45:01.308945 ops/training.py:65 2019-01-16 20:45:01.308858: step 4343, loss = 0.69745 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:45:02.201797 ops/training.py:65 2019-01-16 20:45:02.201719: step 4344, loss = 0.69711 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:45:03.097885 ops/training.py:65 2019-01-16 20:45:03.097801: step 4345, loss = 0.69828 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:45:03.991652 ops/training.py:65 2019-01-16 20:45:03.991591: step 4346, loss = 0.68737 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:45:04.885041 ops/training.py:65 2019-01-16 20:45:04.884971: step 4347, loss = 0.69144 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:45:05.778652 ops/training.py:65 2019-01-16 20:45:05.778567: step 4348, loss = 0.69980 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:45:06.672661 ops/training.py:65 2019-01-16 20:45:06.672581: step 4349, loss = 0.69551 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:45:07.567963 ops/training.py:65 2019-01-16 20:45:07.567877: step 4350, loss = 0.69543 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:45:08.462920 ops/training.py:65 2019-01-16 20:45:08.462837: step 4351, loss = 0.68802 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:45:09.356986 ops/training.py:65 2019-01-16 20:45:09.356918: step 4352, loss = 0.70249 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 20:45:10.251093 ops/training.py:65 2019-01-16 20:45:10.251008: step 4353, loss = 0.69368 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:45:11.144621 ops/training.py:65 2019-01-16 20:45:11.144568: step 4354, loss = 0.68956 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:45:12.037656 ops/training.py:65 2019-01-16 20:45:12.037604: step 4355, loss = 0.69262 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:45:12.930491 ops/training.py:65 2019-01-16 20:45:12.930437: step 4356, loss = 0.69257 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:45:13.824434 ops/training.py:65 2019-01-16 20:45:13.824377: step 4357, loss = 0.68809 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:45:14.718489 ops/training.py:65 2019-01-16 20:45:14.718448: step 4358, loss = 0.69336 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:45:15.612461 ops/training.py:65 2019-01-16 20:45:15.612425: step 4359, loss = 0.69343 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:45:16.506125 ops/training.py:65 2019-01-16 20:45:16.506091: step 4360, loss = 0.69312 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:45:17.399992 ops/training.py:65 2019-01-16 20:45:17.399949: step 4361, loss = 0.69409 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:45:18.294439 ops/training.py:65 2019-01-16 20:45:18.294398: step 4362, loss = 0.69357 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:45:19.189188 ops/training.py:65 2019-01-16 20:45:19.189147: step 4363, loss = 0.69265 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:45:20.084754 ops/training.py:65 2019-01-16 20:45:20.084711: step 4364, loss = 0.69279 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:45:20.979210 ops/training.py:65 2019-01-16 20:45:20.979159: step 4365, loss = 0.69142 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:45:21.872625 ops/training.py:65 2019-01-16 20:45:21.872576: step 4366, loss = 0.69626 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:45:22.764929 ops/training.py:65 2019-01-16 20:45:22.764880: step 4367, loss = 0.69136 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:45:23.658591 ops/training.py:65 2019-01-16 20:45:23.658539: step 4368, loss = 0.69486 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:45:24.555527 ops/training.py:65 2019-01-16 20:45:24.555495: step 4369, loss = 0.69458 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:45:25.452955 ops/training.py:65 2019-01-16 20:45:25.452927: step 4370, loss = 0.68800 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:45:26.349276 ops/training.py:65 2019-01-16 20:45:26.349248: step 4371, loss = 0.69265 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:45:27.243222 ops/training.py:65 2019-01-16 20:45:27.243188: step 4372, loss = 0.69380 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:45:28.137069 ops/training.py:65 2019-01-16 20:45:28.137027: step 4373, loss = 0.69174 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:45:29.031674 ops/training.py:65 2019-01-16 20:45:29.031634: step 4374, loss = 0.69069 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:45:29.927090 ops/training.py:65 2019-01-16 20:45:29.927061: step 4375, loss = 0.69244 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:45:30.821300 ops/training.py:65 2019-01-16 20:45:30.821266: step 4376, loss = 0.69554 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:45:31.717466 ops/training.py:65 2019-01-16 20:45:31.717383: step 4377, loss = 0.68666 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:45:32.612564 ops/training.py:65 2019-01-16 20:45:32.612487: step 4378, loss = 0.69070 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:45:33.506695 ops/training.py:65 2019-01-16 20:45:33.506639: step 4379, loss = 0.69322 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:45:34.402989 ops/training.py:65 2019-01-16 20:45:34.402927: step 4380, loss = 0.69180 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:45:35.299478 ops/training.py:65 2019-01-16 20:45:35.299399: step 4381, loss = 0.69634 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:45:36.195658 ops/training.py:65 2019-01-16 20:45:36.195589: step 4382, loss = 0.69045 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:45:37.091160 ops/training.py:65 2019-01-16 20:45:37.091100: step 4383, loss = 0.69476 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:45:37.988358 ops/training.py:65 2019-01-16 20:45:37.988286: step 4384, loss = 0.69715 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:45:38.885769 ops/training.py:65 2019-01-16 20:45:38.885700: step 4385, loss = 0.69462 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:45:39.782150 ops/training.py:65 2019-01-16 20:45:39.782073: step 4386, loss = 0.69017 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:45:40.679607 ops/training.py:65 2019-01-16 20:45:40.679525: step 4387, loss = 0.69194 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:45:41.575330 ops/training.py:65 2019-01-16 20:45:41.575249: step 4388, loss = 0.68837 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:45:42.469497 ops/training.py:65 2019-01-16 20:45:42.469438: step 4389, loss = 0.69845 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:45:43.363030 ops/training.py:65 2019-01-16 20:45:43.362956: step 4390, loss = 0.68807 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:45:44.259069 ops/training.py:65 2019-01-16 20:45:44.258986: step 4391, loss = 0.69092 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:45:45.156313 ops/training.py:65 2019-01-16 20:45:45.156226: step 4392, loss = 0.68987 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:45:46.051836 ops/training.py:65 2019-01-16 20:45:46.051763: step 4393, loss = 0.69713 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:45:46.945751 ops/training.py:65 2019-01-16 20:45:46.945699: step 4394, loss = 0.69106 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:45:47.839460 ops/training.py:65 2019-01-16 20:45:47.839403: step 4395, loss = 0.69451 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:45:48.733635 ops/training.py:65 2019-01-16 20:45:48.733581: step 4396, loss = 0.68700 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:45:49.627501 ops/training.py:65 2019-01-16 20:45:49.627447: step 4397, loss = 0.69597 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:45:50.521372 ops/training.py:65 2019-01-16 20:45:50.521312: step 4398, loss = 0.69141 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:45:51.414825 ops/training.py:65 2019-01-16 20:45:51.414768: step 4399, loss = 0.69289 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:45:52.309457 ops/training.py:65 2019-01-16 20:45:52.309390: step 4400, loss = 0.69231 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:45:53.203061 ops/training.py:65 2019-01-16 20:45:53.203007: step 4401, loss = 0.68986 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:45:54.096035 ops/training.py:65 2019-01-16 20:45:54.095979: step 4402, loss = 0.69566 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:45:54.988860 ops/training.py:65 2019-01-16 20:45:54.988804: step 4403, loss = 0.69104 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:45:55.881412 ops/training.py:65 2019-01-16 20:45:55.881352: step 4404, loss = 0.69524 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:45:56.774400 ops/training.py:65 2019-01-16 20:45:56.774338: step 4405, loss = 0.69498 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:45:57.668540 ops/training.py:65 2019-01-16 20:45:57.668453: step 4406, loss = 0.69356 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:45:58.562600 ops/training.py:65 2019-01-16 20:45:58.562516: step 4407, loss = 0.69484 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:45:59.456268 ops/training.py:65 2019-01-16 20:45:59.456210: step 4408, loss = 0.68545 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:46:00.349110 ops/training.py:65 2019-01-16 20:46:00.349054: step 4409, loss = 0.69330 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:46:01.241876 ops/training.py:65 2019-01-16 20:46:01.241822: step 4410, loss = 0.69055 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:46:02.134929 ops/training.py:65 2019-01-16 20:46:02.134871: step 4411, loss = 0.69190 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:46:03.031075 ops/training.py:65 2019-01-16 20:46:03.031020: step 4412, loss = 0.68870 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:46:03.927564 ops/training.py:65 2019-01-16 20:46:03.927480: step 4413, loss = 0.69497 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:46:04.823617 ops/training.py:65 2019-01-16 20:46:04.823537: step 4414, loss = 0.69489 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:46:05.718939 ops/training.py:65 2019-01-16 20:46:05.718888: step 4415, loss = 0.69297 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:46:06.613704 ops/training.py:65 2019-01-16 20:46:06.613628: step 4416, loss = 0.69055 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:46:07.508775 ops/training.py:65 2019-01-16 20:46:07.508693: step 4417, loss = 0.69585 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:46:08.405693 ops/training.py:65 2019-01-16 20:46:08.405602: step 4418, loss = 0.70011 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:46:09.302953 ops/training.py:65 2019-01-16 20:46:09.302881: step 4419, loss = 0.69311 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:46:10.200253 ops/training.py:65 2019-01-16 20:46:10.200167: step 4420, loss = 0.69400 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:46:11.094844 ops/training.py:65 2019-01-16 20:46:11.094761: step 4421, loss = 0.69274 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:46:11.988784 ops/training.py:65 2019-01-16 20:46:11.988723: step 4422, loss = 0.69041 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:46:12.883277 ops/training.py:65 2019-01-16 20:46:12.883217: step 4423, loss = 0.68837 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:46:13.777593 ops/training.py:65 2019-01-16 20:46:13.777534: step 4424, loss = 0.68146 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.875
I1280 2019-01-16 20:46:14.672439 ops/training.py:65 2019-01-16 20:46:14.672344: step 4425, loss = 0.69764 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:46:15.568141 ops/training.py:65 2019-01-16 20:46:15.568050: step 4426, loss = 0.69191 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:46:16.462851 ops/training.py:65 2019-01-16 20:46:16.462772: step 4427, loss = 0.69516 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:46:17.355744 ops/training.py:65 2019-01-16 20:46:17.355688: step 4428, loss = 0.68856 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:46:18.249690 ops/training.py:65 2019-01-16 20:46:18.249638: step 4429, loss = 0.68707 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:46:19.143909 ops/training.py:65 2019-01-16 20:46:19.143852: step 4430, loss = 0.69547 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:46:20.040885 ops/training.py:65 2019-01-16 20:46:20.040813: step 4431, loss = 0.69498 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:46:20.935628 ops/training.py:65 2019-01-16 20:46:20.935573: step 4432, loss = 0.69809 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:46:21.829494 ops/training.py:65 2019-01-16 20:46:21.829437: step 4433, loss = 0.69096 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:46:22.722591 ops/training.py:65 2019-01-16 20:46:22.722528: step 4434, loss = 0.69721 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:46:23.617122 ops/training.py:65 2019-01-16 20:46:23.617045: step 4435, loss = 0.69323 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:46:24.511104 ops/training.py:65 2019-01-16 20:46:24.511052: step 4436, loss = 0.69005 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:46:25.406724 ops/training.py:65 2019-01-16 20:46:25.406686: step 4437, loss = 0.69349 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:46:26.302972 ops/training.py:65 2019-01-16 20:46:26.302917: step 4438, loss = 0.69540 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:46:27.199431 ops/training.py:65 2019-01-16 20:46:27.199370: step 4439, loss = 0.69980 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:46:28.096539 ops/training.py:65 2019-01-16 20:46:28.096450: step 4440, loss = 0.68634 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:46:28.993358 ops/training.py:65 2019-01-16 20:46:28.993284: step 4441, loss = 0.69340 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:46:29.888591 ops/training.py:65 2019-01-16 20:46:29.888526: step 4442, loss = 0.69347 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:46:30.783103 ops/training.py:65 2019-01-16 20:46:30.783009: step 4443, loss = 0.69363 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:46:31.681171 ops/training.py:65 2019-01-16 20:46:31.681060: step 4444, loss = 0.69774 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:46:32.577782 ops/training.py:65 2019-01-16 20:46:32.577678: step 4445, loss = 0.69358 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:46:33.474819 ops/training.py:65 2019-01-16 20:46:33.474713: step 4446, loss = 0.68807 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:46:34.371657 ops/training.py:65 2019-01-16 20:46:34.371590: step 4447, loss = 0.69682 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:46:35.265546 ops/training.py:65 2019-01-16 20:46:35.265476: step 4448, loss = 0.69025 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:46:36.158752 ops/training.py:65 2019-01-16 20:46:36.158683: step 4449, loss = 0.69732 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:46:37.052139 ops/training.py:65 2019-01-16 20:46:37.052074: step 4450, loss = 0.69654 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:46:37.946814 ops/training.py:65 2019-01-16 20:46:37.946745: step 4451, loss = 0.69337 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:46:38.840640 ops/training.py:65 2019-01-16 20:46:38.840558: step 4452, loss = 0.69370 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:46:39.737248 ops/training.py:65 2019-01-16 20:46:39.737150: step 4453, loss = 0.68747 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:46:40.631784 ops/training.py:65 2019-01-16 20:46:40.631681: step 4454, loss = 0.69027 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:46:41.526386 ops/training.py:65 2019-01-16 20:46:41.526307: step 4455, loss = 0.69205 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:46:42.419856 ops/training.py:65 2019-01-16 20:46:42.419796: step 4456, loss = 0.68537 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:46:43.313042 ops/training.py:65 2019-01-16 20:46:43.312978: step 4457, loss = 0.68690 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:46:44.208331 ops/training.py:65 2019-01-16 20:46:44.208262: step 4458, loss = 0.69071 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:46:45.103146 ops/training.py:65 2019-01-16 20:46:45.103086: step 4459, loss = 0.69160 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:46:45.997937 ops/training.py:65 2019-01-16 20:46:45.997876: step 4460, loss = 0.69475 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:46:46.891576 ops/training.py:65 2019-01-16 20:46:46.891516: step 4461, loss = 0.69600 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:46:47.784491 ops/training.py:65 2019-01-16 20:46:47.784416: step 4462, loss = 0.69358 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:46:48.679793 ops/training.py:65 2019-01-16 20:46:48.679728: step 4463, loss = 0.68987 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:46:49.577807 ops/training.py:65 2019-01-16 20:46:49.577695: step 4464, loss = 0.69662 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:46:50.474806 ops/training.py:65 2019-01-16 20:46:50.474708: step 4465, loss = 0.69675 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:46:51.369145 ops/training.py:65 2019-01-16 20:46:51.369086: step 4466, loss = 0.68818 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:46:52.264005 ops/training.py:65 2019-01-16 20:46:52.263947: step 4467, loss = 0.69411 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:46:53.160815 ops/training.py:65 2019-01-16 20:46:53.160730: step 4468, loss = 0.69475 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:46:54.058226 ops/training.py:65 2019-01-16 20:46:54.058118: step 4469, loss = 0.68763 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:46:54.953835 ops/training.py:65 2019-01-16 20:46:54.953728: step 4470, loss = 0.68599 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:46:55.850754 ops/training.py:65 2019-01-16 20:46:55.850688: step 4471, loss = 0.70323 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:46:56.745055 ops/training.py:65 2019-01-16 20:46:56.744986: step 4472, loss = 0.69516 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:46:57.640894 ops/training.py:65 2019-01-16 20:46:57.640839: step 4473, loss = 0.69360 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:46:58.536499 ops/training.py:65 2019-01-16 20:46:58.536422: step 4474, loss = 0.70239 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:46:59.436764 ops/training.py:65 2019-01-16 20:46:59.436664: step 4475, loss = 0.70014 (35.6 examples/sec; 0.899 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:47:00.333944 ops/training.py:65 2019-01-16 20:47:00.333848: step 4476, loss = 0.68947 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:47:01.230297 ops/training.py:65 2019-01-16 20:47:01.230197: step 4477, loss = 0.69248 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:47:02.128453 ops/training.py:65 2019-01-16 20:47:02.128363: step 4478, loss = 0.69528 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:47:03.026367 ops/training.py:65 2019-01-16 20:47:03.026267: step 4479, loss = 0.68756 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:47:03.924037 ops/training.py:65 2019-01-16 20:47:03.923929: step 4480, loss = 0.69599 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:47:04.822057 ops/training.py:65 2019-01-16 20:47:04.821965: step 4481, loss = 0.69381 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:47:05.718040 ops/training.py:65 2019-01-16 20:47:05.717937: step 4482, loss = 0.70044 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:47:06.613871 ops/training.py:65 2019-01-16 20:47:06.613745: step 4483, loss = 0.69654 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:47:07.511852 ops/training.py:65 2019-01-16 20:47:07.511747: step 4484, loss = 0.69640 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:47:08.406924 ops/training.py:65 2019-01-16 20:47:08.406820: step 4485, loss = 0.69987 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:47:09.300680 ops/training.py:65 2019-01-16 20:47:09.300600: step 4486, loss = 0.68991 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:47:10.194707 ops/training.py:65 2019-01-16 20:47:10.194605: step 4487, loss = 0.69800 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:47:11.088223 ops/training.py:65 2019-01-16 20:47:11.088129: step 4488, loss = 0.69278 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:47:11.983065 ops/training.py:65 2019-01-16 20:47:11.983001: step 4489, loss = 0.69340 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:47:12.881232 ops/training.py:65 2019-01-16 20:47:12.881124: step 4490, loss = 0.69496 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:47:13.778574 ops/training.py:65 2019-01-16 20:47:13.778473: step 4491, loss = 0.69468 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:47:14.675799 ops/training.py:65 2019-01-16 20:47:14.675687: step 4492, loss = 0.69153 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:47:15.571795 ops/training.py:65 2019-01-16 20:47:15.571694: step 4493, loss = 0.69459 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:47:16.467442 ops/training.py:65 2019-01-16 20:47:16.467349: step 4494, loss = 0.69508 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:47:17.362050 ops/training.py:65 2019-01-16 20:47:17.361950: step 4495, loss = 0.68820 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:47:18.257869 ops/training.py:65 2019-01-16 20:47:18.257805: step 4496, loss = 0.69094 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:47:19.152041 ops/training.py:65 2019-01-16 20:47:19.151975: step 4497, loss = 0.69332 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:47:20.046164 ops/training.py:65 2019-01-16 20:47:20.046098: step 4498, loss = 0.69330 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:47:20.939815 ops/training.py:65 2019-01-16 20:47:20.939753: step 4499, loss = 0.69424 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:47:21.833845 ops/training.py:65 2019-01-16 20:47:21.833784: step 4500, loss = 0.68965 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:47:22.728934 ops/training.py:65 2019-01-16 20:47:22.728865: step 4501, loss = 0.69434 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:47:23.627642 ops/training.py:65 2019-01-16 20:47:23.627540: step 4502, loss = 0.69435 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:47:24.523753 ops/training.py:65 2019-01-16 20:47:24.523668: step 4503, loss = 0.69439 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:47:25.419925 ops/training.py:65 2019-01-16 20:47:25.419843: step 4504, loss = 0.69246 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:47:26.317745 ops/training.py:65 2019-01-16 20:47:26.317639: step 4505, loss = 0.69890 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:47:27.215657 ops/training.py:65 2019-01-16 20:47:27.215572: step 4506, loss = 0.69661 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:47:28.110384 ops/training.py:65 2019-01-16 20:47:28.110321: step 4507, loss = 0.68904 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:47:29.005398 ops/training.py:65 2019-01-16 20:47:29.005339: step 4508, loss = 0.69219 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:47:29.900287 ops/training.py:65 2019-01-16 20:47:29.900204: step 4509, loss = 0.69539 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:47:30.793361 ops/training.py:65 2019-01-16 20:47:30.793294: step 4510, loss = 0.69044 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:47:31.687989 ops/training.py:65 2019-01-16 20:47:31.687926: step 4511, loss = 0.69330 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:47:32.582171 ops/training.py:65 2019-01-16 20:47:32.582101: step 4512, loss = 0.69707 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:47:33.477000 ops/training.py:65 2019-01-16 20:47:33.476911: step 4513, loss = 0.69837 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:47:34.371848 ops/training.py:65 2019-01-16 20:47:34.371786: step 4514, loss = 0.69671 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:47:35.267046 ops/training.py:65 2019-01-16 20:47:35.266973: step 4515, loss = 0.69560 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:47:36.162708 ops/training.py:65 2019-01-16 20:47:36.162606: step 4516, loss = 0.69340 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:47:37.060962 ops/training.py:65 2019-01-16 20:47:37.060851: step 4517, loss = 0.69028 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:47:37.958587 ops/training.py:65 2019-01-16 20:47:37.958487: step 4518, loss = 0.68772 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 20:47:38.855866 ops/training.py:65 2019-01-16 20:47:38.855776: step 4519, loss = 0.69745 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:47:39.753285 ops/training.py:65 2019-01-16 20:47:39.753193: step 4520, loss = 0.69130 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:47:40.648103 ops/training.py:65 2019-01-16 20:47:40.647993: step 4521, loss = 0.69291 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:47:41.544759 ops/training.py:65 2019-01-16 20:47:41.544674: step 4522, loss = 0.69402 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:47:42.440840 ops/training.py:65 2019-01-16 20:47:42.440741: step 4523, loss = 0.69767 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:47:43.337999 ops/training.py:65 2019-01-16 20:47:43.337894: step 4524, loss = 0.69298 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:47:44.234638 ops/training.py:65 2019-01-16 20:47:44.234536: step 4525, loss = 0.68853 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:47:45.129850 ops/training.py:65 2019-01-16 20:47:45.129754: step 4526, loss = 0.69757 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:47:46.025689 ops/training.py:65 2019-01-16 20:47:46.025622: step 4527, loss = 0.69094 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:47:46.921608 ops/training.py:65 2019-01-16 20:47:46.921506: step 4528, loss = 0.68879 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:47:47.819815 ops/training.py:65 2019-01-16 20:47:47.819706: step 4529, loss = 0.68804 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:47:48.716757 ops/training.py:65 2019-01-16 20:47:48.716651: step 4530, loss = 0.69266 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:47:49.612997 ops/training.py:65 2019-01-16 20:47:49.612906: step 4531, loss = 0.68839 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:47:50.506416 ops/training.py:65 2019-01-16 20:47:50.506354: step 4532, loss = 0.69332 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:47:51.399906 ops/training.py:65 2019-01-16 20:47:51.399847: step 4533, loss = 0.69080 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:47:52.294033 ops/training.py:65 2019-01-16 20:47:52.293974: step 4534, loss = 0.69497 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:47:53.187697 ops/training.py:65 2019-01-16 20:47:53.187630: step 4535, loss = 0.68549 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:47:54.084188 ops/training.py:65 2019-01-16 20:47:54.084108: step 4536, loss = 0.68207 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 20:47:54.982536 ops/training.py:65 2019-01-16 20:47:54.982430: step 4537, loss = 0.69066 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:47:55.880234 ops/training.py:65 2019-01-16 20:47:55.880120: step 4538, loss = 0.69511 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:47:56.776916 ops/training.py:65 2019-01-16 20:47:56.776819: step 4539, loss = 0.69737 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:47:57.671564 ops/training.py:65 2019-01-16 20:47:57.671506: step 4540, loss = 0.68568 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:47:58.565118 ops/training.py:65 2019-01-16 20:47:58.565025: step 4541, loss = 0.69675 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:47:59.459410 ops/training.py:65 2019-01-16 20:47:59.459347: step 4542, loss = 0.69584 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:48:00.353958 ops/training.py:65 2019-01-16 20:48:00.353888: step 4543, loss = 0.69541 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:48:01.247962 ops/training.py:65 2019-01-16 20:48:01.247901: step 4544, loss = 0.69207 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:48:02.141811 ops/training.py:65 2019-01-16 20:48:02.141760: step 4545, loss = 0.70318 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:48:03.035520 ops/training.py:65 2019-01-16 20:48:03.035457: step 4546, loss = 0.69459 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:48:03.929635 ops/training.py:65 2019-01-16 20:48:03.929570: step 4547, loss = 0.69027 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:48:04.824044 ops/training.py:65 2019-01-16 20:48:04.823981: step 4548, loss = 0.68533 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:48:05.718037 ops/training.py:65 2019-01-16 20:48:05.717975: step 4549, loss = 0.70208 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:48:06.611969 ops/training.py:65 2019-01-16 20:48:06.611906: step 4550, loss = 0.68991 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:48:07.505788 ops/training.py:65 2019-01-16 20:48:07.505724: step 4551, loss = 0.69727 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:48:08.398970 ops/training.py:65 2019-01-16 20:48:08.398908: step 4552, loss = 0.69184 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:48:09.292243 ops/training.py:65 2019-01-16 20:48:09.292151: step 4553, loss = 0.68573 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:48:10.185949 ops/training.py:65 2019-01-16 20:48:10.185842: step 4554, loss = 0.69626 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:48:11.079789 ops/training.py:65 2019-01-16 20:48:11.079702: step 4555, loss = 0.69054 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:48:11.973557 ops/training.py:65 2019-01-16 20:48:11.973502: step 4556, loss = 0.68774 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:48:12.867995 ops/training.py:65 2019-01-16 20:48:12.867929: step 4557, loss = 0.69722 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:48:13.760931 ops/training.py:65 2019-01-16 20:48:13.760864: step 4558, loss = 0.68930 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:48:14.656508 ops/training.py:65 2019-01-16 20:48:14.656397: step 4559, loss = 0.68661 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 20:48:15.551121 ops/training.py:65 2019-01-16 20:48:15.551013: step 4560, loss = 0.69608 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:48:16.445747 ops/training.py:65 2019-01-16 20:48:16.445682: step 4561, loss = 0.69806 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:48:17.339878 ops/training.py:65 2019-01-16 20:48:17.339815: step 4562, loss = 0.70026 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:48:18.233710 ops/training.py:65 2019-01-16 20:48:18.233650: step 4563, loss = 0.68795 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:48:19.128278 ops/training.py:65 2019-01-16 20:48:19.128210: step 4564, loss = 0.68751 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:48:20.022238 ops/training.py:65 2019-01-16 20:48:20.022175: step 4565, loss = 0.69743 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:48:20.917477 ops/training.py:65 2019-01-16 20:48:20.917396: step 4566, loss = 0.69698 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:48:21.815770 ops/training.py:65 2019-01-16 20:48:21.815660: step 4567, loss = 0.68988 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:48:22.712542 ops/training.py:65 2019-01-16 20:48:22.712442: step 4568, loss = 0.69780 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:48:23.607777 ops/training.py:65 2019-01-16 20:48:23.607712: step 4569, loss = 0.69118 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:48:24.502063 ops/training.py:65 2019-01-16 20:48:24.501973: step 4570, loss = 0.69498 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:48:25.397675 ops/training.py:65 2019-01-16 20:48:25.397566: step 4571, loss = 0.69178 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:48:26.296591 ops/training.py:65 2019-01-16 20:48:26.296485: step 4572, loss = 0.69155 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:48:27.190060 ops/training.py:65 2019-01-16 20:48:27.190002: step 4573, loss = 0.69041 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:48:28.091944 ops/training.py:65 2019-01-16 20:48:28.091850: step 4574, loss = 0.69385 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:48:28.989257 ops/training.py:65 2019-01-16 20:48:28.989168: step 4575, loss = 0.69402 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:48:29.885940 ops/training.py:65 2019-01-16 20:48:29.885832: step 4576, loss = 0.69003 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:48:30.782348 ops/training.py:65 2019-01-16 20:48:30.782237: step 4577, loss = 0.69524 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:48:31.680523 ops/training.py:65 2019-01-16 20:48:31.680416: step 4578, loss = 0.69541 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:48:32.576242 ops/training.py:65 2019-01-16 20:48:32.576139: step 4579, loss = 0.69270 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:48:33.472408 ops/training.py:65 2019-01-16 20:48:33.472305: step 4580, loss = 0.69643 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:48:34.370266 ops/training.py:65 2019-01-16 20:48:34.370157: step 4581, loss = 0.68784 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:48:35.266597 ops/training.py:65 2019-01-16 20:48:35.266534: step 4582, loss = 0.69476 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:48:36.163117 ops/training.py:65 2019-01-16 20:48:36.163018: step 4583, loss = 0.69232 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:48:37.058523 ops/training.py:65 2019-01-16 20:48:37.058463: step 4584, loss = 0.69152 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:48:37.952720 ops/training.py:65 2019-01-16 20:48:37.952657: step 4585, loss = 0.69364 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:48:38.848504 ops/training.py:65 2019-01-16 20:48:38.848414: step 4586, loss = 0.69124 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:48:39.744466 ops/training.py:65 2019-01-16 20:48:39.744373: step 4587, loss = 0.69185 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:48:40.640269 ops/training.py:65 2019-01-16 20:48:40.640164: step 4588, loss = 0.69115 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:48:41.535277 ops/training.py:65 2019-01-16 20:48:41.535174: step 4589, loss = 0.69323 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:48:42.430047 ops/training.py:65 2019-01-16 20:48:42.429985: step 4590, loss = 0.69377 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:48:43.324439 ops/training.py:65 2019-01-16 20:48:43.324378: step 4591, loss = 0.69684 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:48:44.218385 ops/training.py:65 2019-01-16 20:48:44.218315: step 4592, loss = 0.69144 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:48:45.112852 ops/training.py:65 2019-01-16 20:48:45.112761: step 4593, loss = 0.69444 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:48:46.007222 ops/training.py:65 2019-01-16 20:48:46.007121: step 4594, loss = 0.69178 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:48:46.903159 ops/training.py:65 2019-01-16 20:48:46.903094: step 4595, loss = 0.69433 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:48:47.798322 ops/training.py:65 2019-01-16 20:48:47.798252: step 4596, loss = 0.69060 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:48:48.692930 ops/training.py:65 2019-01-16 20:48:48.692831: step 4597, loss = 0.69175 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:48:49.588441 ops/training.py:65 2019-01-16 20:48:49.588331: step 4598, loss = 0.68809 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:48:50.483720 ops/training.py:65 2019-01-16 20:48:50.483621: step 4599, loss = 0.69435 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:48:51.376221 ops/training.py:65 2019-01-16 20:48:51.376160: step 4600, loss = 0.68757 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:48:52.271862 ops/training.py:65 2019-01-16 20:48:52.271761: step 4601, loss = 0.69407 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:48:53.168206 ops/training.py:65 2019-01-16 20:48:53.168100: step 4602, loss = 0.69219 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:48:54.065715 ops/training.py:65 2019-01-16 20:48:54.065611: step 4603, loss = 0.69116 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:48:54.960932 ops/training.py:65 2019-01-16 20:48:54.960834: step 4604, loss = 0.69290 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:48:55.855341 ops/training.py:65 2019-01-16 20:48:55.855231: step 4605, loss = 0.69312 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:48:56.749944 ops/training.py:65 2019-01-16 20:48:56.749846: step 4606, loss = 0.69264 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:48:57.644067 ops/training.py:65 2019-01-16 20:48:57.644005: step 4607, loss = 0.69335 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:48:58.538658 ops/training.py:65 2019-01-16 20:48:58.538556: step 4608, loss = 0.69155 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:48:59.432407 ops/training.py:65 2019-01-16 20:48:59.432348: step 4609, loss = 0.69301 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:49:00.325493 ops/training.py:65 2019-01-16 20:49:00.325433: step 4610, loss = 0.69564 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:49:01.219333 ops/training.py:65 2019-01-16 20:49:01.219272: step 4611, loss = 0.68609 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:49:02.113338 ops/training.py:65 2019-01-16 20:49:02.113277: step 4612, loss = 0.69915 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:49:03.007259 ops/training.py:65 2019-01-16 20:49:03.007188: step 4613, loss = 0.69333 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:49:03.901205 ops/training.py:65 2019-01-16 20:49:03.901099: step 4614, loss = 0.69101 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:49:04.795501 ops/training.py:65 2019-01-16 20:49:04.795410: step 4615, loss = 0.69766 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:49:05.688529 ops/training.py:65 2019-01-16 20:49:05.688469: step 4616, loss = 0.69369 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:49:06.580836 ops/training.py:65 2019-01-16 20:49:06.580766: step 4617, loss = 0.69553 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:49:07.473895 ops/training.py:65 2019-01-16 20:49:07.473830: step 4618, loss = 0.69095 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:49:08.366796 ops/training.py:65 2019-01-16 20:49:08.366731: step 4619, loss = 0.69228 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:49:09.260229 ops/training.py:65 2019-01-16 20:49:09.260150: step 4620, loss = 0.69619 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:49:10.154375 ops/training.py:65 2019-01-16 20:49:10.154271: step 4621, loss = 0.69220 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:49:11.050998 ops/training.py:65 2019-01-16 20:49:11.050900: step 4622, loss = 0.68969 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:49:11.947706 ops/training.py:65 2019-01-16 20:49:11.947611: step 4623, loss = 0.69666 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:49:12.844148 ops/training.py:65 2019-01-16 20:49:12.844042: step 4624, loss = 0.69565 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:49:13.738724 ops/training.py:65 2019-01-16 20:49:13.738625: step 4625, loss = 0.69225 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:49:14.633877 ops/training.py:65 2019-01-16 20:49:14.633771: step 4626, loss = 0.69377 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:49:15.529364 ops/training.py:65 2019-01-16 20:49:15.529254: step 4627, loss = 0.69330 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:49:16.423847 ops/training.py:65 2019-01-16 20:49:16.423741: step 4628, loss = 0.69302 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:49:17.318041 ops/training.py:65 2019-01-16 20:49:17.317980: step 4629, loss = 0.69905 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:49:18.212501 ops/training.py:65 2019-01-16 20:49:18.212403: step 4630, loss = 0.69481 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:49:19.105937 ops/training.py:65 2019-01-16 20:49:19.105873: step 4631, loss = 0.69421 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:49:20.000020 ops/training.py:65 2019-01-16 20:49:19.999955: step 4632, loss = 0.68792 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:49:20.894442 ops/training.py:65 2019-01-16 20:49:20.894342: step 4633, loss = 0.69138 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:49:21.788035 ops/training.py:65 2019-01-16 20:49:21.787966: step 4634, loss = 0.69018 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:49:22.682556 ops/training.py:65 2019-01-16 20:49:22.682490: step 4635, loss = 0.68981 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:49:23.576755 ops/training.py:65 2019-01-16 20:49:23.576663: step 4636, loss = 0.69051 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:49:24.471083 ops/training.py:65 2019-01-16 20:49:24.470981: step 4637, loss = 0.68785 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:49:25.367871 ops/training.py:65 2019-01-16 20:49:25.367775: step 4638, loss = 0.69654 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:49:26.264505 ops/training.py:65 2019-01-16 20:49:26.264397: step 4639, loss = 0.70167 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:49:27.160094 ops/training.py:65 2019-01-16 20:49:27.159991: step 4640, loss = 0.69006 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:49:28.054881 ops/training.py:65 2019-01-16 20:49:28.054792: step 4641, loss = 0.69335 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:49:28.948826 ops/training.py:65 2019-01-16 20:49:28.948718: step 4642, loss = 0.69485 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:49:29.844585 ops/training.py:65 2019-01-16 20:49:29.844487: step 4643, loss = 0.69542 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:49:30.740717 ops/training.py:65 2019-01-16 20:49:30.740609: step 4644, loss = 0.69415 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:49:31.636730 ops/training.py:65 2019-01-16 20:49:31.636631: step 4645, loss = 0.69655 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:49:32.533112 ops/training.py:65 2019-01-16 20:49:32.533020: step 4646, loss = 0.69274 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:49:33.427513 ops/training.py:65 2019-01-16 20:49:33.427424: step 4647, loss = 0.70014 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:49:34.323512 ops/training.py:65 2019-01-16 20:49:34.323439: step 4648, loss = 0.68795 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:49:35.220392 ops/training.py:65 2019-01-16 20:49:35.220283: step 4649, loss = 0.69289 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:49:36.117317 ops/training.py:65 2019-01-16 20:49:36.117233: step 4650, loss = 0.68551 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:49:37.011504 ops/training.py:65 2019-01-16 20:49:37.011441: step 4651, loss = 0.69813 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:49:37.905334 ops/training.py:65 2019-01-16 20:49:37.905236: step 4652, loss = 0.69362 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:49:38.799998 ops/training.py:65 2019-01-16 20:49:38.799890: step 4653, loss = 0.69332 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:49:39.695933 ops/training.py:65 2019-01-16 20:49:39.695829: step 4654, loss = 0.69489 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:49:40.590293 ops/training.py:65 2019-01-16 20:49:40.590184: step 4655, loss = 0.69512 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:49:41.484475 ops/training.py:65 2019-01-16 20:49:41.484375: step 4656, loss = 0.69450 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:49:42.379074 ops/training.py:65 2019-01-16 20:49:42.378988: step 4657, loss = 0.69449 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:49:43.273846 ops/training.py:65 2019-01-16 20:49:43.273783: step 4658, loss = 0.68927 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:49:44.169568 ops/training.py:65 2019-01-16 20:49:44.169456: step 4659, loss = 0.69622 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:49:45.067133 ops/training.py:65 2019-01-16 20:49:45.067038: step 4660, loss = 0.69155 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:49:45.964433 ops/training.py:65 2019-01-16 20:49:45.964332: step 4661, loss = 0.68557 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:49:46.863207 ops/training.py:65 2019-01-16 20:49:46.863113: step 4662, loss = 0.68704 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:49:47.760246 ops/training.py:65 2019-01-16 20:49:47.760143: step 4663, loss = 0.69302 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:49:48.656801 ops/training.py:65 2019-01-16 20:49:48.656700: step 4664, loss = 0.68938 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:49:49.554491 ops/training.py:65 2019-01-16 20:49:49.554415: step 4665, loss = 0.68633 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:49:50.451530 ops/training.py:65 2019-01-16 20:49:50.451425: step 4666, loss = 0.69292 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:49:51.347894 ops/training.py:65 2019-01-16 20:49:51.347798: step 4667, loss = 0.68801 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:49:52.243236 ops/training.py:65 2019-01-16 20:49:52.243139: step 4668, loss = 0.69400 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:49:53.141155 ops/training.py:65 2019-01-16 20:49:53.141063: step 4669, loss = 0.69205 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:49:54.035841 ops/training.py:65 2019-01-16 20:49:54.035779: step 4670, loss = 0.69079 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:49:54.931421 ops/training.py:65 2019-01-16 20:49:54.931333: step 4671, loss = 0.69478 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:49:55.826999 ops/training.py:65 2019-01-16 20:49:55.826905: step 4672, loss = 0.69890 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:49:56.721095 ops/training.py:65 2019-01-16 20:49:56.721023: step 4673, loss = 0.69114 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:49:57.613981 ops/training.py:65 2019-01-16 20:49:57.613914: step 4674, loss = 0.69292 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:49:58.508063 ops/training.py:65 2019-01-16 20:49:58.507967: step 4675, loss = 0.68893 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:49:59.401556 ops/training.py:65 2019-01-16 20:49:59.401445: step 4676, loss = 0.69578 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:50:00.298945 ops/training.py:65 2019-01-16 20:50:00.298858: step 4677, loss = 0.69175 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:50:01.196214 ops/training.py:65 2019-01-16 20:50:01.196112: step 4678, loss = 0.69121 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:50:02.091734 ops/training.py:65 2019-01-16 20:50:02.091653: step 4679, loss = 0.69105 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:50:02.987258 ops/training.py:65 2019-01-16 20:50:02.987157: step 4680, loss = 0.69450 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:50:03.882238 ops/training.py:65 2019-01-16 20:50:03.882133: step 4681, loss = 0.69441 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:50:04.776638 ops/training.py:65 2019-01-16 20:50:04.776575: step 4682, loss = 0.68963 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:50:05.670217 ops/training.py:65 2019-01-16 20:50:05.670124: step 4683, loss = 0.69020 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:50:06.563232 ops/training.py:65 2019-01-16 20:50:06.563164: step 4684, loss = 0.69042 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:50:07.457012 ops/training.py:65 2019-01-16 20:50:07.456949: step 4685, loss = 0.69445 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:50:08.350973 ops/training.py:65 2019-01-16 20:50:08.350866: step 4686, loss = 0.68532 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:50:09.246528 ops/training.py:65 2019-01-16 20:50:09.246441: step 4687, loss = 0.68313 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:50:10.143394 ops/training.py:65 2019-01-16 20:50:10.143290: step 4688, loss = 0.69888 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:50:11.038998 ops/training.py:65 2019-01-16 20:50:11.038905: step 4689, loss = 0.69371 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:50:11.933155 ops/training.py:65 2019-01-16 20:50:11.933104: step 4690, loss = 0.68826 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:50:12.827344 ops/training.py:65 2019-01-16 20:50:12.827246: step 4691, loss = 0.68723 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:50:13.721854 ops/training.py:65 2019-01-16 20:50:13.721777: step 4692, loss = 0.69354 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:50:14.616344 ops/training.py:65 2019-01-16 20:50:14.616282: step 4693, loss = 0.69291 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:50:15.510037 ops/training.py:65 2019-01-16 20:50:15.509930: step 4694, loss = 0.69561 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:50:16.403680 ops/training.py:65 2019-01-16 20:50:16.403610: step 4695, loss = 0.69424 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:50:17.296872 ops/training.py:65 2019-01-16 20:50:17.296810: step 4696, loss = 0.69287 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:50:18.189978 ops/training.py:65 2019-01-16 20:50:18.189910: step 4697, loss = 0.69113 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:50:19.084957 ops/training.py:65 2019-01-16 20:50:19.084838: step 4698, loss = 0.69723 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:50:19.979194 ops/training.py:65 2019-01-16 20:50:19.979131: step 4699, loss = 0.70034 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:50:20.872250 ops/training.py:65 2019-01-16 20:50:20.872185: step 4700, loss = 0.69535 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:50:21.768579 ops/training.py:65 2019-01-16 20:50:21.768520: step 4701, loss = 0.69271 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:50:22.664257 ops/training.py:65 2019-01-16 20:50:22.664176: step 4702, loss = 0.69385 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:50:23.560541 ops/training.py:65 2019-01-16 20:50:23.560460: step 4703, loss = 0.68883 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:50:24.457105 ops/training.py:65 2019-01-16 20:50:24.457003: step 4704, loss = 0.69058 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:50:25.352869 ops/training.py:65 2019-01-16 20:50:25.352762: step 4705, loss = 0.69686 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:50:26.248276 ops/training.py:65 2019-01-16 20:50:26.248217: step 4706, loss = 0.69397 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:50:27.140581 ops/training.py:65 2019-01-16 20:50:27.140524: step 4707, loss = 0.69285 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:50:28.034864 ops/training.py:65 2019-01-16 20:50:28.034798: step 4708, loss = 0.69244 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:50:28.929684 ops/training.py:65 2019-01-16 20:50:28.929613: step 4709, loss = 0.69053 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:50:29.825175 ops/training.py:65 2019-01-16 20:50:29.825101: step 4710, loss = 0.68977 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:50:30.722753 ops/training.py:65 2019-01-16 20:50:30.722638: step 4711, loss = 0.69507 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:50:31.620060 ops/training.py:65 2019-01-16 20:50:31.619946: step 4712, loss = 0.69418 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:50:32.517531 ops/training.py:65 2019-01-16 20:50:32.517434: step 4713, loss = 0.69260 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:50:33.413249 ops/training.py:65 2019-01-16 20:50:33.413151: step 4714, loss = 0.68911 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:50:34.309744 ops/training.py:65 2019-01-16 20:50:34.309653: step 4715, loss = 0.69170 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:50:35.205663 ops/training.py:65 2019-01-16 20:50:35.205599: step 4716, loss = 0.69353 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:50:36.105122 ops/training.py:65 2019-01-16 20:50:36.105024: step 4717, loss = 0.68838 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:50:37.001104 ops/training.py:65 2019-01-16 20:50:37.001021: step 4718, loss = 0.69249 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:50:37.897786 ops/training.py:65 2019-01-16 20:50:37.897693: step 4719, loss = 0.68787 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:50:38.794814 ops/training.py:65 2019-01-16 20:50:38.794714: step 4720, loss = 0.69347 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:50:39.692123 ops/training.py:65 2019-01-16 20:50:39.692034: step 4721, loss = 0.69598 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:50:40.589300 ops/training.py:65 2019-01-16 20:50:40.589193: step 4722, loss = 0.69202 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:50:41.484108 ops/training.py:65 2019-01-16 20:50:41.484013: step 4723, loss = 0.68997 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:50:42.377755 ops/training.py:65 2019-01-16 20:50:42.377698: step 4724, loss = 0.68986 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:50:43.270821 ops/training.py:65 2019-01-16 20:50:43.270758: step 4725, loss = 0.69110 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:50:44.168413 ops/training.py:65 2019-01-16 20:50:44.168337: step 4726, loss = 0.69222 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:50:45.065433 ops/training.py:65 2019-01-16 20:50:45.065326: step 4727, loss = 0.70066 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:50:45.962741 ops/training.py:65 2019-01-16 20:50:45.962635: step 4728, loss = 0.68767 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:50:46.859050 ops/training.py:65 2019-01-16 20:50:46.858957: step 4729, loss = 0.70002 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:50:47.753623 ops/training.py:65 2019-01-16 20:50:47.753520: step 4730, loss = 0.69188 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:50:48.649354 ops/training.py:65 2019-01-16 20:50:48.649268: step 4731, loss = 0.69166 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:50:49.544195 ops/training.py:65 2019-01-16 20:50:49.544132: step 4732, loss = 0.69758 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:50:50.439423 ops/training.py:65 2019-01-16 20:50:50.439321: step 4733, loss = 0.69039 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:50:51.334212 ops/training.py:65 2019-01-16 20:50:51.334149: step 4734, loss = 0.69665 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:50:52.228053 ops/training.py:65 2019-01-16 20:50:52.227971: step 4735, loss = 0.69335 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:50:53.122233 ops/training.py:65 2019-01-16 20:50:53.122129: step 4736, loss = 0.68811 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:50:54.016654 ops/training.py:65 2019-01-16 20:50:54.016548: step 4737, loss = 0.68904 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:50:54.910714 ops/training.py:65 2019-01-16 20:50:54.910651: step 4738, loss = 0.69785 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:50:55.804854 ops/training.py:65 2019-01-16 20:50:55.804795: step 4739, loss = 0.68772 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:50:56.699817 ops/training.py:65 2019-01-16 20:50:56.699756: step 4740, loss = 0.69473 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:50:57.594510 ops/training.py:65 2019-01-16 20:50:57.594441: step 4741, loss = 0.69115 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:50:58.491700 ops/training.py:65 2019-01-16 20:50:58.491597: step 4742, loss = 0.68672 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:50:59.388884 ops/training.py:65 2019-01-16 20:50:59.388787: step 4743, loss = 0.70712 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:51:00.283602 ops/training.py:65 2019-01-16 20:51:00.283537: step 4744, loss = 0.69467 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:51:01.179558 ops/training.py:65 2019-01-16 20:51:01.179474: step 4745, loss = 0.69610 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:51:02.076055 ops/training.py:65 2019-01-16 20:51:02.075967: step 4746, loss = 0.69280 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:51:02.971395 ops/training.py:65 2019-01-16 20:51:02.971305: step 4747, loss = 0.68821 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:51:03.866778 ops/training.py:65 2019-01-16 20:51:03.866689: step 4748, loss = 0.69114 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:51:04.763237 ops/training.py:65 2019-01-16 20:51:04.763171: step 4749, loss = 0.69325 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:51:05.659381 ops/training.py:65 2019-01-16 20:51:05.659281: step 4750, loss = 0.68383 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:51:06.554774 ops/training.py:65 2019-01-16 20:51:06.554671: step 4751, loss = 0.69441 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:51:07.451303 ops/training.py:65 2019-01-16 20:51:07.451239: step 4752, loss = 0.69004 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:51:08.346960 ops/training.py:65 2019-01-16 20:51:08.346854: step 4753, loss = 0.68814 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:51:09.241296 ops/training.py:65 2019-01-16 20:51:09.241215: step 4754, loss = 0.68922 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:51:10.137339 ops/training.py:65 2019-01-16 20:51:10.137247: step 4755, loss = 0.68950 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:51:11.033423 ops/training.py:65 2019-01-16 20:51:11.033327: step 4756, loss = 0.68763 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:51:11.927742 ops/training.py:65 2019-01-16 20:51:11.927665: step 4757, loss = 0.68357 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:51:12.821650 ops/training.py:65 2019-01-16 20:51:12.821584: step 4758, loss = 0.69492 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:51:13.714463 ops/training.py:65 2019-01-16 20:51:13.714400: step 4759, loss = 0.69419 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:51:14.610809 ops/training.py:65 2019-01-16 20:51:14.610731: step 4760, loss = 0.69642 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:51:15.506927 ops/training.py:65 2019-01-16 20:51:15.506847: step 4761, loss = 0.69044 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:51:16.403965 ops/training.py:65 2019-01-16 20:51:16.403865: step 4762, loss = 0.69696 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:51:17.300810 ops/training.py:65 2019-01-16 20:51:17.300705: step 4763, loss = 0.69407 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:51:18.199004 ops/training.py:65 2019-01-16 20:51:18.198940: step 4764, loss = 0.70848 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 20:51:19.094533 ops/training.py:65 2019-01-16 20:51:19.094428: step 4765, loss = 0.69465 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:51:19.991385 ops/training.py:65 2019-01-16 20:51:19.991338: step 4766, loss = 0.69436 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:51:20.888010 ops/training.py:65 2019-01-16 20:51:20.887954: step 4767, loss = 0.69167 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:51:21.783499 ops/training.py:65 2019-01-16 20:51:21.783394: step 4768, loss = 0.69151 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:51:22.678393 ops/training.py:65 2019-01-16 20:51:22.678334: step 4769, loss = 0.68907 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:51:23.571894 ops/training.py:65 2019-01-16 20:51:23.571833: step 4770, loss = 0.68329 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:51:24.465176 ops/training.py:65 2019-01-16 20:51:24.465116: step 4771, loss = 0.69135 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:51:25.361923 ops/training.py:65 2019-01-16 20:51:25.361862: step 4772, loss = 0.69913 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:51:26.258740 ops/training.py:65 2019-01-16 20:51:26.258660: step 4773, loss = 0.68771 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:51:27.154818 ops/training.py:65 2019-01-16 20:51:27.154709: step 4774, loss = 0.69774 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:51:28.050431 ops/training.py:65 2019-01-16 20:51:28.050372: step 4775, loss = 0.68566 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:51:28.947739 ops/training.py:65 2019-01-16 20:51:28.947706: step 4776, loss = 0.69636 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:51:29.846012 ops/training.py:65 2019-01-16 20:51:29.845975: step 4777, loss = 0.70118 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:51:30.741438 ops/training.py:65 2019-01-16 20:51:30.741334: step 4778, loss = 0.69654 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:51:31.636673 ops/training.py:65 2019-01-16 20:51:31.636608: step 4779, loss = 0.68913 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:51:32.533180 ops/training.py:65 2019-01-16 20:51:32.533144: step 4780, loss = 0.69285 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:51:33.430053 ops/training.py:65 2019-01-16 20:51:33.429911: step 4781, loss = 0.69426 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:51:34.325307 ops/training.py:65 2019-01-16 20:51:34.325202: step 4782, loss = 0.70569 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:51:35.220855 ops/training.py:65 2019-01-16 20:51:35.220793: step 4783, loss = 0.70205 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:51:36.114802 ops/training.py:65 2019-01-16 20:51:36.114738: step 4784, loss = 0.69124 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:51:37.007341 ops/training.py:65 2019-01-16 20:51:37.007288: step 4785, loss = 0.69286 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:51:37.900113 ops/training.py:65 2019-01-16 20:51:37.900036: step 4786, loss = 0.70804 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 20:51:38.796202 ops/training.py:65 2019-01-16 20:51:38.796163: step 4787, loss = 0.70013 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:51:39.693055 ops/training.py:65 2019-01-16 20:51:39.692977: step 4788, loss = 0.69152 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:51:40.589060 ops/training.py:65 2019-01-16 20:51:40.589011: step 4789, loss = 0.69424 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:51:41.484868 ops/training.py:65 2019-01-16 20:51:41.484802: step 4790, loss = 0.68604 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:51:42.379815 ops/training.py:65 2019-01-16 20:51:42.379716: step 4791, loss = 0.69243 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:51:43.272902 ops/training.py:65 2019-01-16 20:51:43.272841: step 4792, loss = 0.69464 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:51:44.165483 ops/training.py:65 2019-01-16 20:51:44.165417: step 4793, loss = 0.70022 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:51:45.058453 ops/training.py:65 2019-01-16 20:51:45.058391: step 4794, loss = 0.69505 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:51:45.951211 ops/training.py:65 2019-01-16 20:51:45.951158: step 4795, loss = 0.69030 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:51:46.846537 ops/training.py:65 2019-01-16 20:51:46.846471: step 4796, loss = 0.68554 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:51:47.741873 ops/training.py:65 2019-01-16 20:51:47.741761: step 4797, loss = 0.69399 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:51:48.637881 ops/training.py:65 2019-01-16 20:51:48.637817: step 4798, loss = 0.69369 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:51:49.534570 ops/training.py:65 2019-01-16 20:51:49.534507: step 4799, loss = 0.69490 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:51:50.430806 ops/training.py:65 2019-01-16 20:51:50.430702: step 4800, loss = 0.69369 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:51:51.327054 ops/training.py:65 2019-01-16 20:51:51.326960: step 4801, loss = 0.68745 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:51:52.222964 ops/training.py:65 2019-01-16 20:51:52.222865: step 4802, loss = 0.69949 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:51:53.118894 ops/training.py:65 2019-01-16 20:51:53.118829: step 4803, loss = 0.69427 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:51:54.014580 ops/training.py:65 2019-01-16 20:51:54.014486: step 4804, loss = 0.69510 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:51:54.910924 ops/training.py:65 2019-01-16 20:51:54.910838: step 4805, loss = 0.69715 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:51:55.806525 ops/training.py:65 2019-01-16 20:51:55.806419: step 4806, loss = 0.68735 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:51:56.701490 ops/training.py:65 2019-01-16 20:51:56.701427: step 4807, loss = 0.69643 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:51:57.595772 ops/training.py:65 2019-01-16 20:51:57.595711: step 4808, loss = 0.68666 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:51:58.488788 ops/training.py:65 2019-01-16 20:51:58.488731: step 4809, loss = 0.69546 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:51:59.384474 ops/training.py:65 2019-01-16 20:51:59.384391: step 4810, loss = 0.69690 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:52:00.281474 ops/training.py:65 2019-01-16 20:52:00.281364: step 4811, loss = 0.69320 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:52:01.178648 ops/training.py:65 2019-01-16 20:52:01.178555: step 4812, loss = 0.68837 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:52:02.074462 ops/training.py:65 2019-01-16 20:52:02.074372: step 4813, loss = 0.68901 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:52:02.969827 ops/training.py:65 2019-01-16 20:52:02.969717: step 4814, loss = 0.69861 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:52:03.865136 ops/training.py:65 2019-01-16 20:52:03.865076: step 4815, loss = 0.69834 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:52:04.758025 ops/training.py:65 2019-01-16 20:52:04.757966: step 4816, loss = 0.69216 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:52:05.651288 ops/training.py:65 2019-01-16 20:52:05.651233: step 4817, loss = 0.69615 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:52:06.544683 ops/training.py:65 2019-01-16 20:52:06.544626: step 4818, loss = 0.68737 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:52:07.440039 ops/training.py:65 2019-01-16 20:52:07.440005: step 4819, loss = 0.69785 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:52:08.335437 ops/training.py:65 2019-01-16 20:52:08.335344: step 4820, loss = 0.68986 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:52:09.232649 ops/training.py:65 2019-01-16 20:52:09.232591: step 4821, loss = 0.69826 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:52:10.130527 ops/training.py:65 2019-01-16 20:52:10.130388: step 4822, loss = 0.68487 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:52:11.026190 ops/training.py:65 2019-01-16 20:52:11.026151: step 4823, loss = 0.68788 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:52:11.920674 ops/training.py:65 2019-01-16 20:52:11.920643: step 4824, loss = 0.68184 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:52:12.817374 ops/training.py:65 2019-01-16 20:52:12.817345: step 4825, loss = 0.69584 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:52:13.714595 ops/training.py:65 2019-01-16 20:52:13.714554: step 4826, loss = 0.68110 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:52:14.609783 ops/training.py:65 2019-01-16 20:52:14.609752: step 4827, loss = 0.70646 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:52:15.504320 ops/training.py:65 2019-01-16 20:52:15.504293: step 4828, loss = 0.69252 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:52:16.399298 ops/training.py:65 2019-01-16 20:52:16.399205: step 4829, loss = 0.68824 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:52:17.295452 ops/training.py:65 2019-01-16 20:52:17.295410: step 4830, loss = 0.70645 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:52:18.189916 ops/training.py:65 2019-01-16 20:52:18.189884: step 4831, loss = 0.70090 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:52:19.084230 ops/training.py:65 2019-01-16 20:52:19.084199: step 4832, loss = 0.69144 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:52:19.980309 ops/training.py:65 2019-01-16 20:52:19.980279: step 4833, loss = 0.68382 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:52:20.875950 ops/training.py:65 2019-01-16 20:52:20.875920: step 4834, loss = 0.68558 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:52:21.770895 ops/training.py:65 2019-01-16 20:52:21.770866: step 4835, loss = 0.69166 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:52:22.665656 ops/training.py:65 2019-01-16 20:52:22.665626: step 4836, loss = 0.68332 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:52:23.559956 ops/training.py:65 2019-01-16 20:52:23.559900: step 4837, loss = 0.69098 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:52:24.454972 ops/training.py:65 2019-01-16 20:52:24.454871: step 4838, loss = 0.69299 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:52:25.351088 ops/training.py:65 2019-01-16 20:52:25.351050: step 4839, loss = 0.69355 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:52:26.246236 ops/training.py:65 2019-01-16 20:52:26.246176: step 4840, loss = 0.70074 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:52:27.141531 ops/training.py:65 2019-01-16 20:52:27.141450: step 4841, loss = 0.69670 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:52:28.037315 ops/training.py:65 2019-01-16 20:52:28.037215: step 4842, loss = 0.68529 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:52:28.931738 ops/training.py:65 2019-01-16 20:52:28.931673: step 4843, loss = 0.69182 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:52:29.824696 ops/training.py:65 2019-01-16 20:52:29.824644: step 4844, loss = 0.69215 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:52:30.717316 ops/training.py:65 2019-01-16 20:52:30.717262: step 4845, loss = 0.69439 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:52:31.610293 ops/training.py:65 2019-01-16 20:52:31.610246: step 4846, loss = 0.69856 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 20:52:32.503703 ops/training.py:65 2019-01-16 20:52:32.503653: step 4847, loss = 0.69264 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:52:33.399900 ops/training.py:65 2019-01-16 20:52:33.399815: step 4848, loss = 0.68776 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:52:34.295552 ops/training.py:65 2019-01-16 20:52:34.295445: step 4849, loss = 0.69417 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:52:35.188343 ops/training.py:65 2019-01-16 20:52:35.188243: step 4850, loss = 0.69083 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:52:36.082881 ops/training.py:65 2019-01-16 20:52:36.082823: step 4851, loss = 0.69591 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:52:36.975519 ops/training.py:65 2019-01-16 20:52:36.975463: step 4852, loss = 0.69065 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:52:37.868433 ops/training.py:65 2019-01-16 20:52:37.868372: step 4853, loss = 0.69149 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:52:38.762405 ops/training.py:65 2019-01-16 20:52:38.762343: step 4854, loss = 0.69055 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:52:39.655760 ops/training.py:65 2019-01-16 20:52:39.655682: step 4855, loss = 0.69080 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:52:40.549900 ops/training.py:65 2019-01-16 20:52:40.549811: step 4856, loss = 0.68909 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:52:41.444520 ops/training.py:65 2019-01-16 20:52:41.444448: step 4857, loss = 0.69329 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:52:42.337716 ops/training.py:65 2019-01-16 20:52:42.337659: step 4858, loss = 0.69075 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:52:43.230477 ops/training.py:65 2019-01-16 20:52:43.230417: step 4859, loss = 0.69233 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:52:44.124982 ops/training.py:65 2019-01-16 20:52:44.124910: step 4860, loss = 0.68956 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:52:45.019143 ops/training.py:65 2019-01-16 20:52:45.019072: step 4861, loss = 0.69589 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:52:45.915162 ops/training.py:65 2019-01-16 20:52:45.915100: step 4862, loss = 0.69065 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:52:46.808151 ops/training.py:65 2019-01-16 20:52:46.808081: step 4863, loss = 0.69693 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:52:47.700830 ops/training.py:65 2019-01-16 20:52:47.700762: step 4864, loss = 0.69236 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:52:48.593994 ops/training.py:65 2019-01-16 20:52:48.593938: step 4865, loss = 0.69247 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:52:49.486239 ops/training.py:65 2019-01-16 20:52:49.486177: step 4866, loss = 0.69553 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:52:50.379675 ops/training.py:65 2019-01-16 20:52:50.379576: step 4867, loss = 0.68715 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:52:51.273312 ops/training.py:65 2019-01-16 20:52:51.273228: step 4868, loss = 0.68479 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:52:52.167339 ops/training.py:65 2019-01-16 20:52:52.167241: step 4869, loss = 0.69980 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:52:53.064988 ops/training.py:65 2019-01-16 20:52:53.064892: step 4870, loss = 0.68219 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:52:53.963291 ops/training.py:65 2019-01-16 20:52:53.963192: step 4871, loss = 0.69255 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:52:54.858375 ops/training.py:65 2019-01-16 20:52:54.858276: step 4872, loss = 0.68743 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:52:55.753495 ops/training.py:65 2019-01-16 20:52:55.753392: step 4873, loss = 0.69218 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:52:56.648862 ops/training.py:65 2019-01-16 20:52:56.648761: step 4874, loss = 0.69425 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:52:57.544522 ops/training.py:65 2019-01-16 20:52:57.544421: step 4875, loss = 0.70186 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:52:58.439697 ops/training.py:65 2019-01-16 20:52:58.439594: step 4876, loss = 0.69175 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:52:59.335842 ops/training.py:65 2019-01-16 20:52:59.335734: step 4877, loss = 0.68025 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:53:00.232858 ops/training.py:65 2019-01-16 20:53:00.232762: step 4878, loss = 0.68218 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:53:01.129251 ops/training.py:65 2019-01-16 20:53:01.129153: step 4879, loss = 0.69652 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:53:02.024538 ops/training.py:65 2019-01-16 20:53:02.024455: step 4880, loss = 0.69958 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:53:02.920138 ops/training.py:65 2019-01-16 20:53:02.920042: step 4881, loss = 0.69057 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:53:03.814089 ops/training.py:65 2019-01-16 20:53:03.813993: step 4882, loss = 0.70624 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:53:04.709504 ops/training.py:65 2019-01-16 20:53:04.709396: step 4883, loss = 0.68847 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:53:05.605209 ops/training.py:65 2019-01-16 20:53:05.605113: step 4884, loss = 0.70188 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:53:06.501286 ops/training.py:65 2019-01-16 20:53:06.501185: step 4885, loss = 0.69199 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:53:07.398696 ops/training.py:65 2019-01-16 20:53:07.398592: step 4886, loss = 0.69635 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:53:08.294079 ops/training.py:65 2019-01-16 20:53:08.293971: step 4887, loss = 0.69071 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:53:09.190891 ops/training.py:65 2019-01-16 20:53:09.190783: step 4888, loss = 0.70529 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:53:10.087025 ops/training.py:65 2019-01-16 20:53:10.086900: step 4889, loss = 0.69381 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:53:10.981879 ops/training.py:65 2019-01-16 20:53:10.981774: step 4890, loss = 0.69969 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:53:11.878026 ops/training.py:65 2019-01-16 20:53:11.877890: step 4891, loss = 0.69659 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:53:12.774288 ops/training.py:65 2019-01-16 20:53:12.774189: step 4892, loss = 0.69089 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:53:13.669118 ops/training.py:65 2019-01-16 20:53:13.669012: step 4893, loss = 0.68551 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:53:14.563321 ops/training.py:65 2019-01-16 20:53:14.563177: step 4894, loss = 0.70163 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:53:15.459309 ops/training.py:65 2019-01-16 20:53:15.459218: step 4895, loss = 0.69799 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:53:16.354190 ops/training.py:65 2019-01-16 20:53:16.354090: step 4896, loss = 0.69172 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:53:17.247493 ops/training.py:65 2019-01-16 20:53:17.247401: step 4897, loss = 0.68747 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:53:18.143034 ops/training.py:65 2019-01-16 20:53:18.142918: step 4898, loss = 0.68910 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:53:19.044061 ops/training.py:65 2019-01-16 20:53:19.043933: step 4899, loss = 0.70209 (35.6 examples/sec; 0.899 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:53:19.942781 ops/training.py:65 2019-01-16 20:53:19.942699: step 4900, loss = 0.70208 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:53:20.835522 ops/training.py:65 2019-01-16 20:53:20.835450: step 4901, loss = 0.69314 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:53:21.728811 ops/training.py:65 2019-01-16 20:53:21.728717: step 4902, loss = 0.68199 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:53:22.622453 ops/training.py:65 2019-01-16 20:53:22.622354: step 4903, loss = 0.70372 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:53:23.517295 ops/training.py:65 2019-01-16 20:53:23.517200: step 4904, loss = 0.70684 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:53:24.411324 ops/training.py:65 2019-01-16 20:53:24.411225: step 4905, loss = 0.70179 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:53:25.305046 ops/training.py:65 2019-01-16 20:53:25.304943: step 4906, loss = 0.69112 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:53:26.200492 ops/training.py:65 2019-01-16 20:53:26.200394: step 4907, loss = 0.69498 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:53:27.097012 ops/training.py:65 2019-01-16 20:53:27.096912: step 4908, loss = 0.70784 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:53:27.991374 ops/training.py:65 2019-01-16 20:53:27.991311: step 4909, loss = 0.69911 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:53:28.886111 ops/training.py:65 2019-01-16 20:53:28.886003: step 4910, loss = 0.69055 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:53:29.782725 ops/training.py:65 2019-01-16 20:53:29.782621: step 4911, loss = 0.70151 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:53:30.679262 ops/training.py:65 2019-01-16 20:53:30.679154: step 4912, loss = 0.68980 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:53:31.574550 ops/training.py:65 2019-01-16 20:53:31.574444: step 4913, loss = 0.69141 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:53:32.469595 ops/training.py:65 2019-01-16 20:53:32.469498: step 4914, loss = 0.69977 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:53:33.364694 ops/training.py:65 2019-01-16 20:53:33.364592: step 4915, loss = 0.68141 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:53:34.260092 ops/training.py:65 2019-01-16 20:53:34.259987: step 4916, loss = 0.69359 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:53:35.154804 ops/training.py:65 2019-01-16 20:53:35.154748: step 4917, loss = 0.68908 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:53:36.048926 ops/training.py:65 2019-01-16 20:53:36.048784: step 4918, loss = 0.69035 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:53:36.942705 ops/training.py:65 2019-01-16 20:53:36.942605: step 4919, loss = 0.69715 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:53:37.837393 ops/training.py:65 2019-01-16 20:53:37.837286: step 4920, loss = 0.68479 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:53:38.732743 ops/training.py:65 2019-01-16 20:53:38.732639: step 4921, loss = 0.69606 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:53:39.626556 ops/training.py:65 2019-01-16 20:53:39.626478: step 4922, loss = 0.69980 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:53:40.522381 ops/training.py:65 2019-01-16 20:53:40.522248: step 4923, loss = 0.68654 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:53:41.417291 ops/training.py:65 2019-01-16 20:53:41.417194: step 4924, loss = 0.70906 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:53:42.314108 ops/training.py:65 2019-01-16 20:53:42.313986: step 4925, loss = 0.69697 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:53:43.211710 ops/training.py:65 2019-01-16 20:53:43.211611: step 4926, loss = 0.69161 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:53:44.105673 ops/training.py:65 2019-01-16 20:53:44.105574: step 4927, loss = 0.68543 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:53:44.998854 ops/training.py:65 2019-01-16 20:53:44.998751: step 4928, loss = 0.69722 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:53:45.894356 ops/training.py:65 2019-01-16 20:53:45.894285: step 4929, loss = 0.70068 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:53:46.790226 ops/training.py:65 2019-01-16 20:53:46.790127: step 4930, loss = 0.69074 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:53:47.686567 ops/training.py:65 2019-01-16 20:53:47.686460: step 4931, loss = 0.69550 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:53:48.582228 ops/training.py:65 2019-01-16 20:53:48.582128: step 4932, loss = 0.69736 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:53:49.478589 ops/training.py:65 2019-01-16 20:53:49.478452: step 4933, loss = 0.69151 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:53:50.374941 ops/training.py:65 2019-01-16 20:53:50.374844: step 4934, loss = 0.68831 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:53:51.273055 ops/training.py:65 2019-01-16 20:53:51.272956: step 4935, loss = 0.69149 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:53:52.170015 ops/training.py:65 2019-01-16 20:53:52.169909: step 4936, loss = 0.70339 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:53:53.066844 ops/training.py:65 2019-01-16 20:53:53.066747: step 4937, loss = 0.69055 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:53:53.964977 ops/training.py:65 2019-01-16 20:53:53.964880: step 4938, loss = 0.67506 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.78125
I1280 2019-01-16 20:53:54.863078 ops/training.py:65 2019-01-16 20:53:54.862982: step 4939, loss = 0.69385 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:53:55.759983 ops/training.py:65 2019-01-16 20:53:55.759873: step 4940, loss = 0.69237 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:53:56.653351 ops/training.py:65 2019-01-16 20:53:56.653252: step 4941, loss = 0.69934 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:53:57.548223 ops/training.py:65 2019-01-16 20:53:57.548152: step 4942, loss = 0.70449 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:53:58.441777 ops/training.py:65 2019-01-16 20:53:58.441721: step 4943, loss = 0.68479 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:53:59.335694 ops/training.py:65 2019-01-16 20:53:59.335638: step 4944, loss = 0.69828 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:54:00.228619 ops/training.py:65 2019-01-16 20:54:00.228518: step 4945, loss = 0.70980 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:54:01.123334 ops/training.py:65 2019-01-16 20:54:01.123280: step 4946, loss = 0.70941 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:54:02.018217 ops/training.py:65 2019-01-16 20:54:02.018133: step 4947, loss = 0.69498 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:54:02.911617 ops/training.py:65 2019-01-16 20:54:02.911512: step 4948, loss = 0.68534 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:54:03.806348 ops/training.py:65 2019-01-16 20:54:03.806265: step 4949, loss = 0.67650 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:54:04.699723 ops/training.py:65 2019-01-16 20:54:04.699645: step 4950, loss = 0.70767 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:54:05.593570 ops/training.py:65 2019-01-16 20:54:05.593514: step 4951, loss = 0.68744 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:54:06.488661 ops/training.py:65 2019-01-16 20:54:06.488579: step 4952, loss = 0.68633 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:54:07.385805 ops/training.py:65 2019-01-16 20:54:07.385719: step 4953, loss = 0.67978 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:54:08.282708 ops/training.py:65 2019-01-16 20:54:08.282620: step 4954, loss = 0.69121 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:54:09.178055 ops/training.py:65 2019-01-16 20:54:09.177960: step 4955, loss = 0.70864 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:54:10.071945 ops/training.py:65 2019-01-16 20:54:10.071862: step 4956, loss = 0.69041 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:54:10.969151 ops/training.py:65 2019-01-16 20:54:10.969028: step 4957, loss = 0.68701 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:54:11.867688 ops/training.py:65 2019-01-16 20:54:11.867584: step 4958, loss = 0.69791 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:54:12.767115 ops/training.py:65 2019-01-16 20:54:12.766993: step 4959, loss = 0.69447 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:54:13.664590 ops/training.py:65 2019-01-16 20:54:13.664467: step 4960, loss = 0.68537 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:54:14.562233 ops/training.py:65 2019-01-16 20:54:14.562100: step 4961, loss = 0.69969 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:54:15.458575 ops/training.py:65 2019-01-16 20:54:15.458469: step 4962, loss = 0.67981 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:54:16.354989 ops/training.py:65 2019-01-16 20:54:16.354889: step 4963, loss = 0.69466 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:54:17.249382 ops/training.py:65 2019-01-16 20:54:17.249277: step 4964, loss = 0.68859 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:54:18.143879 ops/training.py:65 2019-01-16 20:54:18.143774: step 4965, loss = 0.69694 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:54:19.039060 ops/training.py:65 2019-01-16 20:54:19.038953: step 4966, loss = 0.69691 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:54:19.934485 ops/training.py:65 2019-01-16 20:54:19.934379: step 4967, loss = 0.69515 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:54:20.828664 ops/training.py:65 2019-01-16 20:54:20.828558: step 4968, loss = 0.68491 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:54:21.725660 ops/training.py:65 2019-01-16 20:54:21.725569: step 4969, loss = 0.69572 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:54:22.621494 ops/training.py:65 2019-01-16 20:54:22.621394: step 4970, loss = 0.69620 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:54:23.518197 ops/training.py:65 2019-01-16 20:54:23.518103: step 4971, loss = 0.69100 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:54:24.414794 ops/training.py:65 2019-01-16 20:54:24.414699: step 4972, loss = 0.68085 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:54:25.311686 ops/training.py:65 2019-01-16 20:54:25.311589: step 4973, loss = 0.69318 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:54:26.207896 ops/training.py:65 2019-01-16 20:54:26.207794: step 4974, loss = 0.69963 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:54:27.102425 ops/training.py:65 2019-01-16 20:54:27.102328: step 4975, loss = 0.69928 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:54:27.997388 ops/training.py:65 2019-01-16 20:54:27.997293: step 4976, loss = 0.69505 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:54:28.893251 ops/training.py:65 2019-01-16 20:54:28.893152: step 4977, loss = 0.71166 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:54:29.788715 ops/training.py:65 2019-01-16 20:54:29.788617: step 4978, loss = 0.70782 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:54:30.683470 ops/training.py:65 2019-01-16 20:54:30.683373: step 4979, loss = 0.69326 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:54:31.579879 ops/training.py:65 2019-01-16 20:54:31.579774: step 4980, loss = 0.69318 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:54:32.477613 ops/training.py:65 2019-01-16 20:54:32.477520: step 4981, loss = 0.68601 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:54:33.371972 ops/training.py:65 2019-01-16 20:54:33.371846: step 4982, loss = 0.69045 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:54:34.266872 ops/training.py:65 2019-01-16 20:54:34.266774: step 4983, loss = 0.68899 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:54:35.160336 ops/training.py:65 2019-01-16 20:54:35.160242: step 4984, loss = 0.70068 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:54:36.055680 ops/training.py:65 2019-01-16 20:54:36.055582: step 4985, loss = 0.70900 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:54:36.952801 ops/training.py:65 2019-01-16 20:54:36.952703: step 4986, loss = 0.71597 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 20:54:37.849294 ops/training.py:65 2019-01-16 20:54:37.849195: step 4987, loss = 0.69681 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:54:38.744057 ops/training.py:65 2019-01-16 20:54:38.743963: step 4988, loss = 0.68622 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:54:39.639501 ops/training.py:65 2019-01-16 20:54:39.639419: step 4989, loss = 0.69999 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:54:40.539538 ops/training.py:65 2019-01-16 20:54:40.539438: step 4990, loss = 0.68866 (35.6 examples/sec; 0.899 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:54:41.438288 ops/training.py:65 2019-01-16 20:54:41.438188: step 4991, loss = 0.69416 (35.7 examples/sec; 0.898 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:54:42.334519 ops/training.py:65 2019-01-16 20:54:42.334417: step 4992, loss = 0.69585 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:54:43.231709 ops/training.py:65 2019-01-16 20:54:43.231586: step 4993, loss = 0.70728 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:54:44.129029 ops/training.py:65 2019-01-16 20:54:44.128936: step 4994, loss = 0.67646 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:54:45.025048 ops/training.py:65 2019-01-16 20:54:45.024949: step 4995, loss = 0.69922 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:54:45.920497 ops/training.py:65 2019-01-16 20:54:45.920400: step 4996, loss = 0.68999 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:54:46.815266 ops/training.py:65 2019-01-16 20:54:46.815168: step 4997, loss = 0.69659 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:54:47.711358 ops/training.py:65 2019-01-16 20:54:47.711242: step 4998, loss = 0.68532 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:54:48.607738 ops/training.py:65 2019-01-16 20:54:48.607621: step 4999, loss = 0.69288 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:54:49.502143 ops/training.py:65 2019-01-16 20:54:49.502022: step 5000, loss = 0.69737 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:54:50.398188 ops/training.py:65 2019-01-16 20:54:50.398036: step 5001, loss = 0.68926 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:54:51.297157 ops/training.py:65 2019-01-16 20:54:51.297057: step 5002, loss = 0.69569 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:54:52.193101 ops/training.py:65 2019-01-16 20:54:52.193010: step 5003, loss = 0.68225 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:54:53.087421 ops/training.py:65 2019-01-16 20:54:53.087337: step 5004, loss = 0.68872 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:54:53.981838 ops/training.py:65 2019-01-16 20:54:53.981743: step 5005, loss = 0.69650 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:54:54.875575 ops/training.py:65 2019-01-16 20:54:54.875458: step 5006, loss = 0.69661 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:54:55.769595 ops/training.py:65 2019-01-16 20:54:55.769494: step 5007, loss = 0.70415 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:54:56.664727 ops/training.py:65 2019-01-16 20:54:56.664624: step 5008, loss = 0.69610 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:54:57.562815 ops/training.py:65 2019-01-16 20:54:57.562717: step 5009, loss = 0.69791 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:54:58.459789 ops/training.py:65 2019-01-16 20:54:58.459691: step 5010, loss = 0.68151 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:54:59.354284 ops/training.py:65 2019-01-16 20:54:59.354187: step 5011, loss = 0.69481 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:55:00.249451 ops/training.py:65 2019-01-16 20:55:00.249353: step 5012, loss = 0.69383 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:55:01.145550 ops/training.py:65 2019-01-16 20:55:01.145453: step 5013, loss = 0.69687 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:55:02.045935 ops/training.py:65 2019-01-16 20:55:02.045856: step 5014, loss = 0.69545 (35.6 examples/sec; 0.899 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:55:02.941163 ops/training.py:65 2019-01-16 20:55:02.941084: step 5015, loss = 0.70165 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:55:03.836545 ops/training.py:65 2019-01-16 20:55:03.836450: step 5016, loss = 0.68907 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:55:04.731979 ops/training.py:65 2019-01-16 20:55:04.731877: step 5017, loss = 0.69755 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:55:05.627242 ops/training.py:65 2019-01-16 20:55:05.627138: step 5018, loss = 0.69491 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:55:06.521957 ops/training.py:65 2019-01-16 20:55:06.521855: step 5019, loss = 0.69659 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:55:07.417320 ops/training.py:65 2019-01-16 20:55:07.417217: step 5020, loss = 0.69071 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:55:08.317369 ops/training.py:65 2019-01-16 20:55:08.317265: step 5021, loss = 0.68665 (35.6 examples/sec; 0.899 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:55:09.212963 ops/training.py:65 2019-01-16 20:55:09.212875: step 5022, loss = 0.69096 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:55:10.110281 ops/training.py:65 2019-01-16 20:55:10.110199: step 5023, loss = 0.69417 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:55:11.005186 ops/training.py:65 2019-01-16 20:55:11.005084: step 5024, loss = 0.69159 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:55:11.904230 ops/training.py:65 2019-01-16 20:55:11.904130: step 5025, loss = 0.69600 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:55:12.802998 ops/training.py:65 2019-01-16 20:55:12.802927: step 5026, loss = 0.69065 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:55:13.698704 ops/training.py:65 2019-01-16 20:55:13.698655: step 5027, loss = 0.69150 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:55:14.595594 ops/training.py:65 2019-01-16 20:55:14.595562: step 5028, loss = 0.69529 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:55:15.491469 ops/training.py:65 2019-01-16 20:55:15.491393: step 5029, loss = 0.68654 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:55:16.385926 ops/training.py:65 2019-01-16 20:55:16.385854: step 5030, loss = 0.69685 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:55:17.279714 ops/training.py:65 2019-01-16 20:55:17.279643: step 5031, loss = 0.68989 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:55:18.175345 ops/training.py:65 2019-01-16 20:55:18.175315: step 5032, loss = 0.69218 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:55:19.069729 ops/training.py:65 2019-01-16 20:55:19.069660: step 5033, loss = 0.67293 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 20:55:19.964036 ops/training.py:65 2019-01-16 20:55:19.963977: step 5034, loss = 0.71415 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:55:20.857946 ops/training.py:65 2019-01-16 20:55:20.857891: step 5035, loss = 0.70035 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:55:21.752552 ops/training.py:65 2019-01-16 20:55:21.752498: step 5036, loss = 0.68952 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:55:22.647600 ops/training.py:65 2019-01-16 20:55:22.647534: step 5037, loss = 0.70859 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:55:23.543160 ops/training.py:65 2019-01-16 20:55:23.543088: step 5038, loss = 0.67730 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:55:24.438019 ops/training.py:65 2019-01-16 20:55:24.437950: step 5039, loss = 0.67593 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:55:25.330869 ops/training.py:65 2019-01-16 20:55:25.330800: step 5040, loss = 0.71638 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:55:26.223583 ops/training.py:65 2019-01-16 20:55:26.223491: step 5041, loss = 0.69557 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:55:27.117518 ops/training.py:65 2019-01-16 20:55:27.117454: step 5042, loss = 0.68275 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:55:28.011228 ops/training.py:65 2019-01-16 20:55:28.011168: step 5043, loss = 0.71580 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:55:28.907426 ops/training.py:65 2019-01-16 20:55:28.907348: step 5044, loss = 0.70528 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:55:29.807830 ops/training.py:65 2019-01-16 20:55:29.807788: step 5045, loss = 0.69412 (35.6 examples/sec; 0.899 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:55:30.700851 ops/training.py:65 2019-01-16 20:55:30.700761: step 5046, loss = 0.68883 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:55:31.596404 ops/training.py:65 2019-01-16 20:55:31.596365: step 5047, loss = 0.68683 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:55:32.494162 ops/training.py:65 2019-01-16 20:55:32.494093: step 5048, loss = 0.68850 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:55:33.389318 ops/training.py:65 2019-01-16 20:55:33.389283: step 5049, loss = 0.67570 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:55:34.285522 ops/training.py:65 2019-01-16 20:55:34.285469: step 5050, loss = 0.68097 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:55:35.180476 ops/training.py:65 2019-01-16 20:55:35.180445: step 5051, loss = 0.70148 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:55:36.080226 ops/training.py:65 2019-01-16 20:55:36.080191: step 5052, loss = 0.70441 (35.6 examples/sec; 0.899 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:55:36.975862 ops/training.py:65 2019-01-16 20:55:36.975792: step 5053, loss = 0.69790 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:55:37.869976 ops/training.py:65 2019-01-16 20:55:37.869902: step 5054, loss = 0.67155 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 20:55:38.764344 ops/training.py:65 2019-01-16 20:55:38.764274: step 5055, loss = 0.70078 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:55:39.659265 ops/training.py:65 2019-01-16 20:55:39.659180: step 5056, loss = 0.69522 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:55:40.554092 ops/training.py:65 2019-01-16 20:55:40.553986: step 5057, loss = 0.68981 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:55:41.449283 ops/training.py:65 2019-01-16 20:55:41.449183: step 5058, loss = 0.68615 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:55:42.346951 ops/training.py:65 2019-01-16 20:55:42.346861: step 5059, loss = 0.68362 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:55:43.244359 ops/training.py:65 2019-01-16 20:55:43.244276: step 5060, loss = 0.68880 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:55:44.138829 ops/training.py:65 2019-01-16 20:55:44.138759: step 5061, loss = 0.68947 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:55:45.033378 ops/training.py:65 2019-01-16 20:55:45.033312: step 5062, loss = 0.69661 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:55:45.928873 ops/training.py:65 2019-01-16 20:55:45.928809: step 5063, loss = 0.68148 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:55:46.823106 ops/training.py:65 2019-01-16 20:55:46.823046: step 5064, loss = 0.69313 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:55:47.718774 ops/training.py:65 2019-01-16 20:55:47.718726: step 5065, loss = 0.67590 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:55:48.615985 ops/training.py:65 2019-01-16 20:55:48.615951: step 5066, loss = 0.66862 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:55:49.512692 ops/training.py:65 2019-01-16 20:55:49.512621: step 5067, loss = 0.70239 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:55:50.406718 ops/training.py:65 2019-01-16 20:55:50.406665: step 5068, loss = 0.69491 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:55:51.301455 ops/training.py:65 2019-01-16 20:55:51.301391: step 5069, loss = 0.67442 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:55:52.194838 ops/training.py:65 2019-01-16 20:55:52.194779: step 5070, loss = 0.70569 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:55:53.092179 ops/training.py:65 2019-01-16 20:55:53.092130: step 5071, loss = 0.69077 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:55:53.988149 ops/training.py:65 2019-01-16 20:55:53.988091: step 5072, loss = 0.71961 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:55:54.882882 ops/training.py:65 2019-01-16 20:55:54.882823: step 5073, loss = 0.69099 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:55:55.779056 ops/training.py:65 2019-01-16 20:55:55.779004: step 5074, loss = 0.71353 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:55:56.676330 ops/training.py:65 2019-01-16 20:55:56.676287: step 5075, loss = 0.67500 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:55:57.571813 ops/training.py:65 2019-01-16 20:55:57.571758: step 5076, loss = 0.68960 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:55:58.467648 ops/training.py:65 2019-01-16 20:55:58.467595: step 5077, loss = 0.68538 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:55:59.364319 ops/training.py:65 2019-01-16 20:55:59.364250: step 5078, loss = 0.67435 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:56:00.259210 ops/training.py:65 2019-01-16 20:56:00.259167: step 5079, loss = 0.71427 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:56:01.155130 ops/training.py:65 2019-01-16 20:56:01.155097: step 5080, loss = 0.69948 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:56:02.050207 ops/training.py:65 2019-01-16 20:56:02.050163: step 5081, loss = 0.68342 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:56:02.945265 ops/training.py:65 2019-01-16 20:56:02.945176: step 5082, loss = 0.69373 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:56:03.842271 ops/training.py:65 2019-01-16 20:56:03.842226: step 5083, loss = 0.70037 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:56:04.738033 ops/training.py:65 2019-01-16 20:56:04.737982: step 5084, loss = 0.69705 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:56:05.632604 ops/training.py:65 2019-01-16 20:56:05.632514: step 5085, loss = 0.69813 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:56:06.527734 ops/training.py:65 2019-01-16 20:56:06.527687: step 5086, loss = 0.70665 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:56:07.422271 ops/training.py:65 2019-01-16 20:56:07.422193: step 5087, loss = 0.67931 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:56:08.315868 ops/training.py:65 2019-01-16 20:56:08.315809: step 5088, loss = 0.68861 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:56:09.209283 ops/training.py:65 2019-01-16 20:56:09.209228: step 5089, loss = 0.72001 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:56:10.103697 ops/training.py:65 2019-01-16 20:56:10.103642: step 5090, loss = 0.69038 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:56:10.997325 ops/training.py:65 2019-01-16 20:56:10.997255: step 5091, loss = 0.69905 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:56:11.891692 ops/training.py:65 2019-01-16 20:56:11.891662: step 5092, loss = 0.67440 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.75
I1280 2019-01-16 20:56:12.786732 ops/training.py:65 2019-01-16 20:56:12.786685: step 5093, loss = 0.71876 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.21875
I1280 2019-01-16 20:56:13.681789 ops/training.py:65 2019-01-16 20:56:13.681753: step 5094, loss = 0.69743 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:56:14.575367 ops/training.py:65 2019-01-16 20:56:14.575296: step 5095, loss = 0.68788 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:56:15.470417 ops/training.py:65 2019-01-16 20:56:15.470347: step 5096, loss = 0.69982 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:56:16.364031 ops/training.py:65 2019-01-16 20:56:16.363968: step 5097, loss = 0.69483 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:56:17.258865 ops/training.py:65 2019-01-16 20:56:17.258801: step 5098, loss = 0.70354 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:56:18.152744 ops/training.py:65 2019-01-16 20:56:18.152675: step 5099, loss = 0.68880 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:56:19.045752 ops/training.py:65 2019-01-16 20:56:19.045694: step 5100, loss = 0.68391 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:56:19.939439 ops/training.py:65 2019-01-16 20:56:19.939378: step 5101, loss = 0.69342 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:56:20.833501 ops/training.py:65 2019-01-16 20:56:20.833437: step 5102, loss = 0.70039 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:56:21.728913 ops/training.py:65 2019-01-16 20:56:21.728864: step 5103, loss = 0.69443 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:56:22.626714 ops/training.py:65 2019-01-16 20:56:22.626682: step 5104, loss = 0.69997 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:56:23.523623 ops/training.py:65 2019-01-16 20:56:23.523570: step 5105, loss = 0.68802 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:56:24.420185 ops/training.py:65 2019-01-16 20:56:24.420102: step 5106, loss = 0.70023 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:56:25.314170 ops/training.py:65 2019-01-16 20:56:25.314117: step 5107, loss = 0.68989 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:56:26.210063 ops/training.py:65 2019-01-16 20:56:26.210023: step 5108, loss = 0.68940 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:56:27.105500 ops/training.py:65 2019-01-16 20:56:27.105441: step 5109, loss = 0.69951 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:56:28.003711 ops/training.py:65 2019-01-16 20:56:28.003676: step 5110, loss = 0.70170 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:56:28.899337 ops/training.py:65 2019-01-16 20:56:28.899278: step 5111, loss = 0.68882 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:56:29.795734 ops/training.py:65 2019-01-16 20:56:29.795685: step 5112, loss = 0.69996 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:56:30.690708 ops/training.py:65 2019-01-16 20:56:30.690654: step 5113, loss = 0.69072 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:56:31.587079 ops/training.py:65 2019-01-16 20:56:31.587018: step 5114, loss = 0.69087 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:56:32.483343 ops/training.py:65 2019-01-16 20:56:32.483298: step 5115, loss = 0.71103 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:56:33.379647 ops/training.py:65 2019-01-16 20:56:33.379597: step 5116, loss = 0.69312 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:56:34.276860 ops/training.py:65 2019-01-16 20:56:34.276778: step 5117, loss = 0.71660 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:56:35.171770 ops/training.py:65 2019-01-16 20:56:35.171709: step 5118, loss = 0.70439 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:56:36.066266 ops/training.py:65 2019-01-16 20:56:36.066198: step 5119, loss = 0.70375 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:56:36.959984 ops/training.py:65 2019-01-16 20:56:36.959907: step 5120, loss = 0.72695 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:56:37.856803 ops/training.py:65 2019-01-16 20:56:37.856733: step 5121, loss = 0.69848 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:56:38.753437 ops/training.py:65 2019-01-16 20:56:38.753334: step 5122, loss = 0.68851 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:56:39.649956 ops/training.py:65 2019-01-16 20:56:39.649878: step 5123, loss = 0.68623 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:56:40.546005 ops/training.py:65 2019-01-16 20:56:40.545910: step 5124, loss = 0.69633 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:56:41.441372 ops/training.py:65 2019-01-16 20:56:41.441309: step 5125, loss = 0.71070 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:56:42.338469 ops/training.py:65 2019-01-16 20:56:42.338375: step 5126, loss = 0.71249 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:56:43.235324 ops/training.py:65 2019-01-16 20:56:43.235248: step 5127, loss = 0.70567 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:56:44.132125 ops/training.py:65 2019-01-16 20:56:44.132024: step 5128, loss = 0.68813 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:56:45.028640 ops/training.py:65 2019-01-16 20:56:45.028573: step 5129, loss = 0.69291 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:56:45.924395 ops/training.py:65 2019-01-16 20:56:45.924297: step 5130, loss = 0.64943 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 20:56:46.819782 ops/training.py:65 2019-01-16 20:56:46.819681: step 5131, loss = 0.73549 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:56:47.716208 ops/training.py:65 2019-01-16 20:56:47.716104: step 5132, loss = 0.72654 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:56:48.612209 ops/training.py:65 2019-01-16 20:56:48.612144: step 5133, loss = 0.70185 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:56:49.507625 ops/training.py:65 2019-01-16 20:56:49.507558: step 5134, loss = 0.71298 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:56:50.402678 ops/training.py:65 2019-01-16 20:56:50.402576: step 5135, loss = 0.68937 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:56:51.299671 ops/training.py:65 2019-01-16 20:56:51.299568: step 5136, loss = 0.72316 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:56:52.195718 ops/training.py:65 2019-01-16 20:56:52.195624: step 5137, loss = 0.67787 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:56:53.092331 ops/training.py:65 2019-01-16 20:56:53.092228: step 5138, loss = 0.71052 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:56:53.991003 ops/training.py:65 2019-01-16 20:56:53.990904: step 5139, loss = 0.71067 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:56:54.886115 ops/training.py:65 2019-01-16 20:56:54.886013: step 5140, loss = 0.70116 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:56:55.781899 ops/training.py:65 2019-01-16 20:56:55.781793: step 5141, loss = 0.70152 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:56:56.679205 ops/training.py:65 2019-01-16 20:56:56.679101: step 5142, loss = 0.70657 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:56:57.572552 ops/training.py:65 2019-01-16 20:56:57.572456: step 5143, loss = 0.68618 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:56:58.465577 ops/training.py:65 2019-01-16 20:56:58.465477: step 5144, loss = 0.70855 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:56:59.361025 ops/training.py:65 2019-01-16 20:56:59.360925: step 5145, loss = 0.69914 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:57:00.254639 ops/training.py:65 2019-01-16 20:57:00.254572: step 5146, loss = 0.69885 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:57:01.151354 ops/training.py:65 2019-01-16 20:57:01.151272: step 5147, loss = 0.68747 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:57:02.047358 ops/training.py:65 2019-01-16 20:57:02.047283: step 5148, loss = 0.68138 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:57:02.943231 ops/training.py:65 2019-01-16 20:57:02.943126: step 5149, loss = 0.67902 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:57:03.837136 ops/training.py:65 2019-01-16 20:57:03.837052: step 5150, loss = 0.68537 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:57:04.731158 ops/training.py:65 2019-01-16 20:57:04.731069: step 5151, loss = 0.68698 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:57:05.626633 ops/training.py:65 2019-01-16 20:57:05.626531: step 5152, loss = 0.70391 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:57:06.522091 ops/training.py:65 2019-01-16 20:57:06.521990: step 5153, loss = 0.69346 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:57:07.417729 ops/training.py:65 2019-01-16 20:57:07.417628: step 5154, loss = 0.68118 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:57:08.314436 ops/training.py:65 2019-01-16 20:57:08.314374: step 5155, loss = 0.69726 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:57:09.211439 ops/training.py:65 2019-01-16 20:57:09.211390: step 5156, loss = 0.68253 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:57:10.108100 ops/training.py:65 2019-01-16 20:57:10.108017: step 5157, loss = 0.68374 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:57:11.003855 ops/training.py:65 2019-01-16 20:57:11.003824: step 5158, loss = 0.68693 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:57:11.898171 ops/training.py:65 2019-01-16 20:57:11.898140: step 5159, loss = 0.71987 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 20:57:12.792471 ops/training.py:65 2019-01-16 20:57:12.792440: step 5160, loss = 0.71493 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:57:13.688090 ops/training.py:65 2019-01-16 20:57:13.688059: step 5161, loss = 0.68854 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:57:14.584665 ops/training.py:65 2019-01-16 20:57:14.584635: step 5162, loss = 0.70214 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:57:15.479733 ops/training.py:65 2019-01-16 20:57:15.479694: step 5163, loss = 0.67870 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:57:16.373475 ops/training.py:65 2019-01-16 20:57:16.373435: step 5164, loss = 0.70523 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:57:17.267607 ops/training.py:65 2019-01-16 20:57:17.267548: step 5165, loss = 0.69722 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:57:18.161640 ops/training.py:65 2019-01-16 20:57:18.161565: step 5166, loss = 0.69598 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:57:19.055909 ops/training.py:65 2019-01-16 20:57:19.055843: step 5167, loss = 0.68765 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:57:19.950273 ops/training.py:65 2019-01-16 20:57:19.950202: step 5168, loss = 0.72087 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:57:20.846366 ops/training.py:65 2019-01-16 20:57:20.846302: step 5169, loss = 0.67630 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:57:21.742785 ops/training.py:65 2019-01-16 20:57:21.742715: step 5170, loss = 0.68727 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:57:22.639167 ops/training.py:65 2019-01-16 20:57:22.639067: step 5171, loss = 0.70716 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:57:23.534688 ops/training.py:65 2019-01-16 20:57:23.534591: step 5172, loss = 0.69273 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:57:24.430314 ops/training.py:65 2019-01-16 20:57:24.430214: step 5173, loss = 0.67895 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:57:25.325881 ops/training.py:65 2019-01-16 20:57:25.325823: step 5174, loss = 0.69764 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:57:26.222564 ops/training.py:65 2019-01-16 20:57:26.222500: step 5175, loss = 0.68127 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:57:27.119302 ops/training.py:65 2019-01-16 20:57:27.119193: step 5176, loss = 0.67893 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:57:28.016654 ops/training.py:65 2019-01-16 20:57:28.016555: step 5177, loss = 0.69122 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:57:28.912014 ops/training.py:65 2019-01-16 20:57:28.911944: step 5178, loss = 0.69307 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:57:29.806303 ops/training.py:65 2019-01-16 20:57:29.806212: step 5179, loss = 0.70458 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:57:30.702327 ops/training.py:65 2019-01-16 20:57:30.702231: step 5180, loss = 0.69425 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:57:31.598925 ops/training.py:65 2019-01-16 20:57:31.598817: step 5181, loss = 0.68970 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:57:32.496466 ops/training.py:65 2019-01-16 20:57:32.496368: step 5182, loss = 0.69262 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:57:33.393037 ops/training.py:65 2019-01-16 20:57:33.392934: step 5183, loss = 0.68798 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:57:34.293798 ops/training.py:65 2019-01-16 20:57:34.293682: step 5184, loss = 0.69826 (35.6 examples/sec; 0.900 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:57:35.187362 ops/training.py:65 2019-01-16 20:57:35.187272: step 5185, loss = 0.70206 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:57:36.080859 ops/training.py:65 2019-01-16 20:57:36.080764: step 5186, loss = 0.69492 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:57:36.974611 ops/training.py:65 2019-01-16 20:57:36.974495: step 5187, loss = 0.69516 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:57:37.870014 ops/training.py:65 2019-01-16 20:57:37.869904: step 5188, loss = 0.69484 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:57:38.763937 ops/training.py:65 2019-01-16 20:57:38.763835: step 5189, loss = 0.69793 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:57:39.657810 ops/training.py:65 2019-01-16 20:57:39.657732: step 5190, loss = 0.69417 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:57:40.552197 ops/training.py:65 2019-01-16 20:57:40.552098: step 5191, loss = 0.69060 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:57:41.445755 ops/training.py:65 2019-01-16 20:57:41.445684: step 5192, loss = 0.68963 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:57:42.339967 ops/training.py:65 2019-01-16 20:57:42.339872: step 5193, loss = 0.69919 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:57:43.238741 ops/training.py:65 2019-01-16 20:57:43.238627: step 5194, loss = 0.68925 (35.7 examples/sec; 0.898 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:57:44.139818 ops/training.py:65 2019-01-16 20:57:44.139713: step 5195, loss = 0.69329 (35.6 examples/sec; 0.900 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:57:45.035817 ops/training.py:65 2019-01-16 20:57:45.035711: step 5196, loss = 0.69196 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:57:45.931971 ops/training.py:65 2019-01-16 20:57:45.931871: step 5197, loss = 0.69347 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:57:46.827862 ops/training.py:65 2019-01-16 20:57:46.827785: step 5198, loss = 0.68911 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:57:47.725284 ops/training.py:65 2019-01-16 20:57:47.725175: step 5199, loss = 0.69650 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:57:48.618381 ops/training.py:65 2019-01-16 20:57:48.618278: step 5200, loss = 0.70207 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:57:49.512290 ops/training.py:65 2019-01-16 20:57:49.512181: step 5201, loss = 0.69888 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:57:50.409640 ops/training.py:65 2019-01-16 20:57:50.409541: step 5202, loss = 0.69545 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:57:51.307510 ops/training.py:65 2019-01-16 20:57:51.307400: step 5203, loss = 0.69483 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:57:52.204229 ops/training.py:65 2019-01-16 20:57:52.204132: step 5204, loss = 0.69331 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:57:53.100166 ops/training.py:65 2019-01-16 20:57:53.100065: step 5205, loss = 0.68993 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:57:53.996831 ops/training.py:65 2019-01-16 20:57:53.996729: step 5206, loss = 0.69705 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:57:54.890887 ops/training.py:65 2019-01-16 20:57:54.890822: step 5207, loss = 0.70375 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:57:55.783481 ops/training.py:65 2019-01-16 20:57:55.783414: step 5208, loss = 0.69867 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:57:56.676578 ops/training.py:65 2019-01-16 20:57:56.676506: step 5209, loss = 0.69083 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:57:57.572906 ops/training.py:65 2019-01-16 20:57:57.572800: step 5210, loss = 0.69634 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:57:58.470393 ops/training.py:65 2019-01-16 20:57:58.470285: step 5211, loss = 0.69363 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:57:59.368321 ops/training.py:65 2019-01-16 20:57:59.368219: step 5212, loss = 0.69064 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:58:00.264216 ops/training.py:65 2019-01-16 20:58:00.264082: step 5213, loss = 0.69038 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:58:01.159894 ops/training.py:65 2019-01-16 20:58:01.159794: step 5214, loss = 0.69120 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:58:02.054245 ops/training.py:65 2019-01-16 20:58:02.054181: step 5215, loss = 0.69342 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:58:02.948396 ops/training.py:65 2019-01-16 20:58:02.948336: step 5216, loss = 0.68598 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:58:03.842334 ops/training.py:65 2019-01-16 20:58:03.842273: step 5217, loss = 0.68905 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:58:04.735532 ops/training.py:65 2019-01-16 20:58:04.735476: step 5218, loss = 0.68590 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:58:05.628618 ops/training.py:65 2019-01-16 20:58:05.628560: step 5219, loss = 0.69072 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:58:06.523788 ops/training.py:65 2019-01-16 20:58:06.523707: step 5220, loss = 0.69155 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:58:07.422572 ops/training.py:65 2019-01-16 20:58:07.422473: step 5221, loss = 0.69809 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:58:08.320459 ops/training.py:65 2019-01-16 20:58:08.320369: step 5222, loss = 0.69882 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:58:09.215301 ops/training.py:65 2019-01-16 20:58:09.215193: step 5223, loss = 0.69127 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:58:10.110575 ops/training.py:65 2019-01-16 20:58:10.110483: step 5224, loss = 0.70091 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:58:11.005325 ops/training.py:65 2019-01-16 20:58:11.005261: step 5225, loss = 0.68951 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:58:11.899068 ops/training.py:65 2019-01-16 20:58:11.898996: step 5226, loss = 0.69380 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:58:12.793645 ops/training.py:65 2019-01-16 20:58:12.793575: step 5227, loss = 0.68952 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:58:13.687839 ops/training.py:65 2019-01-16 20:58:13.687763: step 5228, loss = 0.68501 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:58:14.584142 ops/training.py:65 2019-01-16 20:58:14.584069: step 5229, loss = 0.68927 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:58:15.481935 ops/training.py:65 2019-01-16 20:58:15.481840: step 5230, loss = 0.69177 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:58:16.378336 ops/training.py:65 2019-01-16 20:58:16.378242: step 5231, loss = 0.67826 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.75
I1280 2019-01-16 20:58:17.273639 ops/training.py:65 2019-01-16 20:58:17.273565: step 5232, loss = 0.68755 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:58:18.168637 ops/training.py:65 2019-01-16 20:58:18.168575: step 5233, loss = 0.68610 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:58:19.063467 ops/training.py:65 2019-01-16 20:58:19.063402: step 5234, loss = 0.68640 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:58:19.958847 ops/training.py:65 2019-01-16 20:58:19.958777: step 5235, loss = 0.70222 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:58:20.852926 ops/training.py:65 2019-01-16 20:58:20.852860: step 5236, loss = 0.67995 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:58:21.746854 ops/training.py:65 2019-01-16 20:58:21.746793: step 5237, loss = 0.69601 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:58:22.641457 ops/training.py:65 2019-01-16 20:58:22.641401: step 5238, loss = 0.69606 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:58:23.535709 ops/training.py:65 2019-01-16 20:58:23.535641: step 5239, loss = 0.68975 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:58:24.429379 ops/training.py:65 2019-01-16 20:58:24.429269: step 5240, loss = 0.67174 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 20:58:25.324421 ops/training.py:65 2019-01-16 20:58:25.324318: step 5241, loss = 0.70064 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:58:26.217718 ops/training.py:65 2019-01-16 20:58:26.217658: step 5242, loss = 0.69387 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:58:27.114515 ops/training.py:65 2019-01-16 20:58:27.114460: step 5243, loss = 0.69183 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:58:28.015813 ops/training.py:65 2019-01-16 20:58:28.015703: step 5244, loss = 0.69318 (35.5 examples/sec; 0.900 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:58:28.912231 ops/training.py:65 2019-01-16 20:58:28.912121: step 5245, loss = 0.68432 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:58:29.807477 ops/training.py:65 2019-01-16 20:58:29.807378: step 5246, loss = 0.69409 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:58:30.703977 ops/training.py:65 2019-01-16 20:58:30.703866: step 5247, loss = 0.70743 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:58:31.600444 ops/training.py:65 2019-01-16 20:58:31.600336: step 5248, loss = 0.68852 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:58:32.497650 ops/training.py:65 2019-01-16 20:58:32.497549: step 5249, loss = 0.68998 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:58:33.392201 ops/training.py:65 2019-01-16 20:58:33.392099: step 5250, loss = 0.68517 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:58:34.287472 ops/training.py:65 2019-01-16 20:58:34.287412: step 5251, loss = 0.69216 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:58:35.184513 ops/training.py:65 2019-01-16 20:58:35.184428: step 5252, loss = 0.69611 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:58:36.079528 ops/training.py:65 2019-01-16 20:58:36.079455: step 5253, loss = 0.69076 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:58:36.976359 ops/training.py:65 2019-01-16 20:58:36.976255: step 5254, loss = 0.69419 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:58:37.873227 ops/training.py:65 2019-01-16 20:58:37.873119: step 5255, loss = 0.69898 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:58:38.768154 ops/training.py:65 2019-01-16 20:58:38.768056: step 5256, loss = 0.68510 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:58:39.662046 ops/training.py:65 2019-01-16 20:58:39.661965: step 5257, loss = 0.71446 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:58:40.555895 ops/training.py:65 2019-01-16 20:58:40.555793: step 5258, loss = 0.70614 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:58:41.449022 ops/training.py:65 2019-01-16 20:58:41.448951: step 5259, loss = 0.69880 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:58:42.341773 ops/training.py:65 2019-01-16 20:58:42.341708: step 5260, loss = 0.66787 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:58:43.234095 ops/training.py:65 2019-01-16 20:58:43.234029: step 5261, loss = 0.71031 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:58:44.126517 ops/training.py:65 2019-01-16 20:58:44.126452: step 5262, loss = 0.68400 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:58:45.019277 ops/training.py:65 2019-01-16 20:58:45.019208: step 5263, loss = 0.71078 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 20:58:45.914062 ops/training.py:65 2019-01-16 20:58:45.913999: step 5264, loss = 0.72139 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 20:58:46.809157 ops/training.py:65 2019-01-16 20:58:46.809054: step 5265, loss = 0.71026 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:58:47.704815 ops/training.py:65 2019-01-16 20:58:47.704711: step 5266, loss = 0.69506 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:58:48.599346 ops/training.py:65 2019-01-16 20:58:48.599240: step 5267, loss = 0.68761 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:58:49.494617 ops/training.py:65 2019-01-16 20:58:49.494508: step 5268, loss = 0.69604 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:58:50.389354 ops/training.py:65 2019-01-16 20:58:50.389250: step 5269, loss = 0.71731 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:58:51.286807 ops/training.py:65 2019-01-16 20:58:51.286703: step 5270, loss = 0.68764 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:58:52.183299 ops/training.py:65 2019-01-16 20:58:52.183203: step 5271, loss = 0.67740 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:58:53.079054 ops/training.py:65 2019-01-16 20:58:53.078983: step 5272, loss = 0.68155 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:58:53.973949 ops/training.py:65 2019-01-16 20:58:53.973885: step 5273, loss = 0.69661 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:58:54.868278 ops/training.py:65 2019-01-16 20:58:54.868215: step 5274, loss = 0.71326 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:58:55.763375 ops/training.py:65 2019-01-16 20:58:55.763316: step 5275, loss = 0.70350 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:58:56.658248 ops/training.py:65 2019-01-16 20:58:56.658181: step 5276, loss = 0.68124 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:58:57.553176 ops/training.py:65 2019-01-16 20:58:57.553104: step 5277, loss = 0.69007 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:58:58.448119 ops/training.py:65 2019-01-16 20:58:58.448051: step 5278, loss = 0.68456 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:58:59.342913 ops/training.py:65 2019-01-16 20:58:59.342856: step 5279, loss = 0.68026 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:59:00.236183 ops/training.py:65 2019-01-16 20:59:00.236115: step 5280, loss = 0.69199 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:59:01.129877 ops/training.py:65 2019-01-16 20:59:01.129792: step 5281, loss = 0.71020 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:59:02.022301 ops/training.py:65 2019-01-16 20:59:02.022232: step 5282, loss = 0.69736 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:59:02.918152 ops/training.py:65 2019-01-16 20:59:02.918077: step 5283, loss = 0.69155 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:59:03.813408 ops/training.py:65 2019-01-16 20:59:03.813336: step 5284, loss = 0.69483 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:59:04.709910 ops/training.py:65 2019-01-16 20:59:04.709803: step 5285, loss = 0.68729 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:59:05.605201 ops/training.py:65 2019-01-16 20:59:05.605092: step 5286, loss = 0.69610 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:59:06.500065 ops/training.py:65 2019-01-16 20:59:06.499956: step 5287, loss = 0.68990 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:59:07.395964 ops/training.py:65 2019-01-16 20:59:07.395866: step 5288, loss = 0.70530 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:59:08.293371 ops/training.py:65 2019-01-16 20:59:08.293265: step 5289, loss = 0.69627 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:59:09.189962 ops/training.py:65 2019-01-16 20:59:09.189898: step 5290, loss = 0.69521 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:59:10.084702 ops/training.py:65 2019-01-16 20:59:10.084623: step 5291, loss = 0.68743 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:59:10.981131 ops/training.py:65 2019-01-16 20:59:10.981018: step 5292, loss = 0.70723 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:59:11.879272 ops/training.py:65 2019-01-16 20:59:11.879159: step 5293, loss = 0.70997 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:59:12.776515 ops/training.py:65 2019-01-16 20:59:12.776416: step 5294, loss = 0.68897 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:59:13.672723 ops/training.py:65 2019-01-16 20:59:13.672631: step 5295, loss = 0.69083 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:59:14.569911 ops/training.py:65 2019-01-16 20:59:14.569803: step 5296, loss = 0.68686 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:59:15.467895 ops/training.py:65 2019-01-16 20:59:15.467788: step 5297, loss = 0.68454 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:59:16.365393 ops/training.py:65 2019-01-16 20:59:16.365281: step 5298, loss = 0.67736 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:59:17.265415 ops/training.py:65 2019-01-16 20:59:17.265319: step 5299, loss = 0.68401 (35.6 examples/sec; 0.899 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:59:18.160472 ops/training.py:65 2019-01-16 20:59:18.160396: step 5300, loss = 0.71312 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:59:19.055464 ops/training.py:65 2019-01-16 20:59:19.055403: step 5301, loss = 0.67441 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:59:19.949901 ops/training.py:65 2019-01-16 20:59:19.949839: step 5302, loss = 0.70468 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:59:20.845379 ops/training.py:65 2019-01-16 20:59:20.845314: step 5303, loss = 0.70755 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:59:21.742841 ops/training.py:65 2019-01-16 20:59:21.742740: step 5304, loss = 0.68919 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:59:22.641304 ops/training.py:65 2019-01-16 20:59:22.641178: step 5305, loss = 0.69219 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:59:23.539530 ops/training.py:65 2019-01-16 20:59:23.539395: step 5306, loss = 0.69360 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 20:59:24.437061 ops/training.py:65 2019-01-16 20:59:24.436956: step 5307, loss = 0.68911 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:59:25.334037 ops/training.py:65 2019-01-16 20:59:25.333941: step 5308, loss = 0.69795 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:59:26.230338 ops/training.py:65 2019-01-16 20:59:26.230237: step 5309, loss = 0.69620 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:59:27.125375 ops/training.py:65 2019-01-16 20:59:27.125268: step 5310, loss = 0.66386 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 20:59:28.020699 ops/training.py:65 2019-01-16 20:59:28.020546: step 5311, loss = 0.68829 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:59:28.918035 ops/training.py:65 2019-01-16 20:59:28.917923: step 5312, loss = 0.69259 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:59:29.817527 ops/training.py:65 2019-01-16 20:59:29.817418: step 5313, loss = 0.67538 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 20:59:30.711843 ops/training.py:65 2019-01-16 20:59:30.711716: step 5314, loss = 0.70764 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:59:31.607475 ops/training.py:65 2019-01-16 20:59:31.607357: step 5315, loss = 0.71358 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:59:32.503053 ops/training.py:65 2019-01-16 20:59:32.502953: step 5316, loss = 0.69190 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:59:33.399262 ops/training.py:65 2019-01-16 20:59:33.399152: step 5317, loss = 0.70153 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:59:34.294301 ops/training.py:65 2019-01-16 20:59:34.294203: step 5318, loss = 0.69199 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:59:35.189073 ops/training.py:65 2019-01-16 20:59:35.188982: step 5319, loss = 0.67958 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:59:36.083391 ops/training.py:65 2019-01-16 20:59:36.083291: step 5320, loss = 0.68206 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:59:36.977911 ops/training.py:65 2019-01-16 20:59:36.977788: step 5321, loss = 0.70682 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 20:59:37.873508 ops/training.py:65 2019-01-16 20:59:37.873400: step 5322, loss = 0.67670 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 20:59:38.769442 ops/training.py:65 2019-01-16 20:59:38.769343: step 5323, loss = 0.69025 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 20:59:39.664214 ops/training.py:65 2019-01-16 20:59:39.664134: step 5324, loss = 0.71605 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:59:40.559140 ops/training.py:65 2019-01-16 20:59:40.559104: step 5325, loss = 0.68049 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:59:41.454614 ops/training.py:65 2019-01-16 20:59:41.454580: step 5326, loss = 0.68365 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:59:42.347796 ops/training.py:65 2019-01-16 20:59:42.347752: step 5327, loss = 0.69746 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:59:43.241645 ops/training.py:65 2019-01-16 20:59:43.241579: step 5328, loss = 0.69077 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:59:44.136270 ops/training.py:65 2019-01-16 20:59:44.136221: step 5329, loss = 0.69424 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:59:45.032921 ops/training.py:65 2019-01-16 20:59:45.032890: step 5330, loss = 0.68874 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:59:45.928334 ops/training.py:65 2019-01-16 20:59:45.928302: step 5331, loss = 0.69990 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:59:46.822663 ops/training.py:65 2019-01-16 20:59:46.822632: step 5332, loss = 0.71060 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:59:47.715462 ops/training.py:65 2019-01-16 20:59:47.715425: step 5333, loss = 0.69481 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:59:48.608321 ops/training.py:65 2019-01-16 20:59:48.608288: step 5334, loss = 0.70773 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 20:59:49.502928 ops/training.py:65 2019-01-16 20:59:49.502895: step 5335, loss = 0.69261 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:59:50.399291 ops/training.py:65 2019-01-16 20:59:50.399256: step 5336, loss = 0.69364 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 20:59:51.295266 ops/training.py:65 2019-01-16 20:59:51.295223: step 5337, loss = 0.69024 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:59:52.192785 ops/training.py:65 2019-01-16 20:59:52.192752: step 5338, loss = 0.70763 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:59:53.090279 ops/training.py:65 2019-01-16 20:59:53.090242: step 5339, loss = 0.69895 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 20:59:54.032903 ops/training.py:65 2019-01-16 20:59:54.032871: step 5340, loss = 0.68990 (34.4 examples/sec; 0.929 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 20:59:54.929253 ops/training.py:65 2019-01-16 20:59:54.929222: step 5341, loss = 0.69800 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 20:59:55.825258 ops/training.py:65 2019-01-16 20:59:55.825228: step 5342, loss = 0.69576 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:59:56.721356 ops/training.py:65 2019-01-16 20:59:56.721326: step 5343, loss = 0.69195 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:59:57.617609 ops/training.py:65 2019-01-16 20:59:57.617578: step 5344, loss = 0.69599 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 20:59:58.512242 ops/training.py:65 2019-01-16 20:59:58.512198: step 5345, loss = 0.68909 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 20:59:59.406341 ops/training.py:65 2019-01-16 20:59:59.406306: step 5346, loss = 0.69530 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:00:00.302709 ops/training.py:65 2019-01-16 21:00:00.302663: step 5347, loss = 0.69076 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:00:01.199894 ops/training.py:65 2019-01-16 21:00:01.199828: step 5348, loss = 0.70382 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.25
I1280 2019-01-16 21:00:02.095086 ops/training.py:65 2019-01-16 21:00:02.095029: step 5349, loss = 0.69611 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:00:02.992022 ops/training.py:65 2019-01-16 21:00:02.991932: step 5350, loss = 0.69610 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:00:03.888748 ops/training.py:65 2019-01-16 21:00:03.888690: step 5351, loss = 0.69702 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:00:04.783573 ops/training.py:65 2019-01-16 21:00:04.783508: step 5352, loss = 0.69627 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:00:05.678554 ops/training.py:65 2019-01-16 21:00:05.678500: step 5353, loss = 0.69021 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:00:06.573400 ops/training.py:65 2019-01-16 21:00:06.573347: step 5354, loss = 0.69060 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:00:07.470128 ops/training.py:65 2019-01-16 21:00:07.470064: step 5355, loss = 0.69204 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:00:08.364951 ops/training.py:65 2019-01-16 21:00:08.364877: step 5356, loss = 0.69588 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:00:09.259301 ops/training.py:65 2019-01-16 21:00:09.259230: step 5357, loss = 0.70351 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:00:10.156473 ops/training.py:65 2019-01-16 21:00:10.156391: step 5358, loss = 0.69194 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:00:11.053915 ops/training.py:65 2019-01-16 21:00:11.053815: step 5359, loss = 0.68636 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:00:11.949161 ops/training.py:65 2019-01-16 21:00:11.949072: step 5360, loss = 0.69920 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:00:12.844385 ops/training.py:65 2019-01-16 21:00:12.844311: step 5361, loss = 0.70234 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:00:13.739457 ops/training.py:65 2019-01-16 21:00:13.739389: step 5362, loss = 0.69029 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:00:14.634122 ops/training.py:65 2019-01-16 21:00:14.634050: step 5363, loss = 0.69996 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:00:15.530386 ops/training.py:65 2019-01-16 21:00:15.530289: step 5364, loss = 0.68475 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:00:16.427501 ops/training.py:65 2019-01-16 21:00:16.427390: step 5365, loss = 0.69419 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:00:17.325049 ops/training.py:65 2019-01-16 21:00:17.324953: step 5366, loss = 0.69593 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:00:18.222183 ops/training.py:65 2019-01-16 21:00:18.222091: step 5367, loss = 0.68777 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:00:19.118242 ops/training.py:65 2019-01-16 21:00:19.118140: step 5368, loss = 0.68607 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:00:20.014468 ops/training.py:65 2019-01-16 21:00:20.014402: step 5369, loss = 0.69939 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:00:20.910129 ops/training.py:65 2019-01-16 21:00:20.910057: step 5370, loss = 0.68365 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:00:21.806628 ops/training.py:65 2019-01-16 21:00:21.806559: step 5371, loss = 0.68802 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:00:22.702273 ops/training.py:65 2019-01-16 21:00:22.702210: step 5372, loss = 0.71000 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:00:23.599308 ops/training.py:65 2019-01-16 21:00:23.599195: step 5373, loss = 0.68569 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:00:24.495674 ops/training.py:65 2019-01-16 21:00:24.495605: step 5374, loss = 0.70182 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:00:25.391902 ops/training.py:65 2019-01-16 21:00:25.391802: step 5375, loss = 0.70716 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:00:26.288135 ops/training.py:65 2019-01-16 21:00:26.288073: step 5376, loss = 0.69889 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:00:27.184341 ops/training.py:65 2019-01-16 21:00:27.184247: step 5377, loss = 0.69347 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:00:28.079549 ops/training.py:65 2019-01-16 21:00:28.079480: step 5378, loss = 0.69002 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:00:28.973705 ops/training.py:65 2019-01-16 21:00:28.973642: step 5379, loss = 0.70166 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:00:29.869472 ops/training.py:65 2019-01-16 21:00:29.869409: step 5380, loss = 0.69793 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:00:30.766442 ops/training.py:65 2019-01-16 21:00:30.766343: step 5381, loss = 0.68204 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:00:31.662222 ops/training.py:65 2019-01-16 21:00:31.662151: step 5382, loss = 0.71889 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:00:32.557324 ops/training.py:65 2019-01-16 21:00:32.557260: step 5383, loss = 0.69748 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:00:33.452527 ops/training.py:65 2019-01-16 21:00:33.452459: step 5384, loss = 0.67380 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:00:34.346715 ops/training.py:65 2019-01-16 21:00:34.346652: step 5385, loss = 0.68446 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:00:35.240362 ops/training.py:65 2019-01-16 21:00:35.240295: step 5386, loss = 0.71983 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:00:36.135557 ops/training.py:65 2019-01-16 21:00:36.135494: step 5387, loss = 0.72934 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:00:37.030311 ops/training.py:65 2019-01-16 21:00:37.030241: step 5388, loss = 0.64285 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 21:00:37.928885 ops/training.py:65 2019-01-16 21:00:37.928777: step 5389, loss = 0.65379 (35.7 examples/sec; 0.898 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:00:38.824848 ops/training.py:65 2019-01-16 21:00:38.824784: step 5390, loss = 0.71497 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:00:39.721356 ops/training.py:65 2019-01-16 21:00:39.721270: step 5391, loss = 0.71795 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:00:40.618243 ops/training.py:65 2019-01-16 21:00:40.618147: step 5392, loss = 0.70106 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:00:41.513135 ops/training.py:65 2019-01-16 21:00:41.513041: step 5393, loss = 0.68805 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:00:42.408068 ops/training.py:65 2019-01-16 21:00:42.407970: step 5394, loss = 0.71796 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:00:43.305622 ops/training.py:65 2019-01-16 21:00:43.305527: step 5395, loss = 0.69703 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:00:44.201731 ops/training.py:65 2019-01-16 21:00:44.201651: step 5396, loss = 0.72571 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:00:45.096419 ops/training.py:65 2019-01-16 21:00:45.096347: step 5397, loss = 0.71559 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:00:45.990184 ops/training.py:65 2019-01-16 21:00:45.990119: step 5398, loss = 0.73048 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:00:46.883856 ops/training.py:65 2019-01-16 21:00:46.883788: step 5399, loss = 0.70415 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:00:47.778449 ops/training.py:65 2019-01-16 21:00:47.778373: step 5400, loss = 0.71407 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:00:48.673140 ops/training.py:65 2019-01-16 21:00:48.673077: step 5401, loss = 0.71081 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:00:49.568058 ops/training.py:65 2019-01-16 21:00:49.567984: step 5402, loss = 0.66716 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:00:50.464597 ops/training.py:65 2019-01-16 21:00:50.464498: step 5403, loss = 0.68242 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:00:51.361732 ops/training.py:65 2019-01-16 21:00:51.361665: step 5404, loss = 0.68529 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:00:52.258078 ops/training.py:65 2019-01-16 21:00:52.257974: step 5405, loss = 0.66259 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:00:53.154709 ops/training.py:65 2019-01-16 21:00:53.154641: step 5406, loss = 0.68589 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:00:54.048997 ops/training.py:65 2019-01-16 21:00:54.048927: step 5407, loss = 0.71708 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:00:54.944044 ops/training.py:65 2019-01-16 21:00:54.943966: step 5408, loss = 0.69416 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:00:55.839433 ops/training.py:65 2019-01-16 21:00:55.839329: step 5409, loss = 0.71296 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:00:56.733815 ops/training.py:65 2019-01-16 21:00:56.733711: step 5410, loss = 0.68904 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:00:57.627519 ops/training.py:65 2019-01-16 21:00:57.627422: step 5411, loss = 0.71080 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:00:58.523738 ops/training.py:65 2019-01-16 21:00:58.523646: step 5412, loss = 0.71235 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:00:59.420750 ops/training.py:65 2019-01-16 21:00:59.420672: step 5413, loss = 0.70398 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:01:00.314985 ops/training.py:65 2019-01-16 21:01:00.314916: step 5414, loss = 0.69594 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:01:01.211035 ops/training.py:65 2019-01-16 21:01:01.210963: step 5415, loss = 0.71352 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:01:02.106526 ops/training.py:65 2019-01-16 21:01:02.106440: step 5416, loss = 0.72496 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:01:03.001180 ops/training.py:65 2019-01-16 21:01:03.001083: step 5417, loss = 0.70635 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:01:03.896096 ops/training.py:65 2019-01-16 21:01:03.895991: step 5418, loss = 0.70113 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:01:04.790644 ops/training.py:65 2019-01-16 21:01:04.790546: step 5419, loss = 0.66992 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:01:05.687785 ops/training.py:65 2019-01-16 21:01:05.687686: step 5420, loss = 0.72538 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:01:06.582738 ops/training.py:65 2019-01-16 21:01:06.582665: step 5421, loss = 0.71207 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:01:07.477066 ops/training.py:65 2019-01-16 21:01:07.476996: step 5422, loss = 0.67934 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:01:08.372884 ops/training.py:65 2019-01-16 21:01:08.372813: step 5423, loss = 0.71476 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:01:09.267356 ops/training.py:65 2019-01-16 21:01:09.267288: step 5424, loss = 0.67863 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:01:10.162703 ops/training.py:65 2019-01-16 21:01:10.162618: step 5425, loss = 0.70602 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:01:11.056870 ops/training.py:65 2019-01-16 21:01:11.056794: step 5426, loss = 0.69349 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:01:11.952757 ops/training.py:65 2019-01-16 21:01:11.952695: step 5427, loss = 0.70135 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:01:12.850253 ops/training.py:65 2019-01-16 21:01:12.850147: step 5428, loss = 0.69116 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:01:13.745385 ops/training.py:65 2019-01-16 21:01:13.745315: step 5429, loss = 0.69897 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:01:14.640440 ops/training.py:65 2019-01-16 21:01:14.640380: step 5430, loss = 0.69403 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:01:15.535775 ops/training.py:65 2019-01-16 21:01:15.535667: step 5431, loss = 0.70097 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:01:16.433143 ops/training.py:65 2019-01-16 21:01:16.433040: step 5432, loss = 0.68844 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:01:17.329237 ops/training.py:65 2019-01-16 21:01:17.329151: step 5433, loss = 0.69155 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:01:18.225517 ops/training.py:65 2019-01-16 21:01:18.225439: step 5434, loss = 0.69102 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:01:19.119195 ops/training.py:65 2019-01-16 21:01:19.119127: step 5435, loss = 0.68627 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:01:20.016257 ops/training.py:65 2019-01-16 21:01:20.016149: step 5436, loss = 0.68965 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:01:20.912396 ops/training.py:65 2019-01-16 21:01:20.912322: step 5437, loss = 0.71416 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 21:01:21.806759 ops/training.py:65 2019-01-16 21:01:21.806686: step 5438, loss = 0.70005 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:01:22.699969 ops/training.py:65 2019-01-16 21:01:22.699895: step 5439, loss = 0.69068 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:01:23.594800 ops/training.py:65 2019-01-16 21:01:23.594732: step 5440, loss = 0.68604 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:01:24.489138 ops/training.py:65 2019-01-16 21:01:24.489052: step 5441, loss = 0.69839 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:01:25.384573 ops/training.py:65 2019-01-16 21:01:25.384495: step 5442, loss = 0.69587 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:01:26.278563 ops/training.py:65 2019-01-16 21:01:26.278490: step 5443, loss = 0.70740 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.25
I1280 2019-01-16 21:01:27.173707 ops/training.py:65 2019-01-16 21:01:27.173643: step 5444, loss = 0.68293 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:01:28.068208 ops/training.py:65 2019-01-16 21:01:28.068112: step 5445, loss = 0.68436 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:01:28.963604 ops/training.py:65 2019-01-16 21:01:28.963530: step 5446, loss = 0.69812 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:01:29.858057 ops/training.py:65 2019-01-16 21:01:29.857993: step 5447, loss = 0.69331 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:01:30.754021 ops/training.py:65 2019-01-16 21:01:30.753924: step 5448, loss = 0.69330 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:01:31.650274 ops/training.py:65 2019-01-16 21:01:31.650204: step 5449, loss = 0.70204 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:01:32.543474 ops/training.py:65 2019-01-16 21:01:32.543380: step 5450, loss = 0.69186 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:01:33.440171 ops/training.py:65 2019-01-16 21:01:33.440074: step 5451, loss = 0.68357 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:01:34.334392 ops/training.py:65 2019-01-16 21:01:34.334319: step 5452, loss = 0.68714 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:01:35.229570 ops/training.py:65 2019-01-16 21:01:35.229502: step 5453, loss = 0.69480 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:01:36.126057 ops/training.py:65 2019-01-16 21:01:36.125982: step 5454, loss = 0.70262 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:01:37.020803 ops/training.py:65 2019-01-16 21:01:37.020703: step 5455, loss = 0.69919 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:01:37.916856 ops/training.py:65 2019-01-16 21:01:37.916789: step 5456, loss = 0.68583 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:01:38.813103 ops/training.py:65 2019-01-16 21:01:38.813008: step 5457, loss = 0.68073 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:01:39.708213 ops/training.py:65 2019-01-16 21:01:39.708135: step 5458, loss = 0.70466 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:01:40.604153 ops/training.py:65 2019-01-16 21:01:40.604084: step 5459, loss = 0.67796 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:01:41.497925 ops/training.py:65 2019-01-16 21:01:41.497859: step 5460, loss = 0.67568 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.75
I1280 2019-01-16 21:01:42.391460 ops/training.py:65 2019-01-16 21:01:42.391408: step 5461, loss = 0.68524 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:01:43.286419 ops/training.py:65 2019-01-16 21:01:43.286364: step 5462, loss = 0.68840 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:01:44.182467 ops/training.py:65 2019-01-16 21:01:44.182399: step 5463, loss = 0.68891 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:01:45.077511 ops/training.py:65 2019-01-16 21:01:45.077465: step 5464, loss = 0.70202 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:01:45.973685 ops/training.py:65 2019-01-16 21:01:45.973625: step 5465, loss = 0.69663 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:01:46.867769 ops/training.py:65 2019-01-16 21:01:46.867703: step 5466, loss = 0.69254 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:01:47.762261 ops/training.py:65 2019-01-16 21:01:47.762187: step 5467, loss = 0.69743 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:01:48.656644 ops/training.py:65 2019-01-16 21:01:48.656579: step 5468, loss = 0.69230 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:01:49.549548 ops/training.py:65 2019-01-16 21:01:49.549481: step 5469, loss = 0.68437 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:01:50.444550 ops/training.py:65 2019-01-16 21:01:50.444482: step 5470, loss = 0.69633 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:01:51.341718 ops/training.py:65 2019-01-16 21:01:51.341614: step 5471, loss = 0.70511 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:01:52.236918 ops/training.py:65 2019-01-16 21:01:52.236852: step 5472, loss = 0.70637 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:01:53.132925 ops/training.py:65 2019-01-16 21:01:53.132855: step 5473, loss = 0.71237 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:01:54.028547 ops/training.py:65 2019-01-16 21:01:54.028439: step 5474, loss = 0.70338 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:01:54.922828 ops/training.py:65 2019-01-16 21:01:54.922729: step 5475, loss = 0.69406 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:01:55.818887 ops/training.py:65 2019-01-16 21:01:55.818784: step 5476, loss = 0.68570 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:01:56.714671 ops/training.py:65 2019-01-16 21:01:56.714600: step 5477, loss = 0.69512 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:01:57.610280 ops/training.py:65 2019-01-16 21:01:57.610177: step 5478, loss = 0.69070 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:01:58.507200 ops/training.py:65 2019-01-16 21:01:58.507096: step 5479, loss = 0.69225 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:01:59.404154 ops/training.py:65 2019-01-16 21:01:59.404077: step 5480, loss = 0.69044 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:02:00.301335 ops/training.py:65 2019-01-16 21:02:00.301230: step 5481, loss = 0.68970 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:02:01.197825 ops/training.py:65 2019-01-16 21:02:01.197770: step 5482, loss = 0.69655 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:02:02.091103 ops/training.py:65 2019-01-16 21:02:02.091053: step 5483, loss = 0.68525 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:02:02.986119 ops/training.py:65 2019-01-16 21:02:02.986038: step 5484, loss = 0.70416 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:02:03.882104 ops/training.py:65 2019-01-16 21:02:03.882071: step 5485, loss = 0.69136 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:02:04.779450 ops/training.py:65 2019-01-16 21:02:04.779409: step 5486, loss = 0.69278 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:02:05.674895 ops/training.py:65 2019-01-16 21:02:05.674828: step 5487, loss = 0.70219 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:02:06.571459 ops/training.py:65 2019-01-16 21:02:06.571392: step 5488, loss = 0.68547 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:02:07.468197 ops/training.py:65 2019-01-16 21:02:07.468133: step 5489, loss = 0.68980 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:02:08.364362 ops/training.py:65 2019-01-16 21:02:08.364309: step 5490, loss = 0.68874 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:02:09.260268 ops/training.py:65 2019-01-16 21:02:09.260220: step 5491, loss = 0.69319 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:02:10.154409 ops/training.py:65 2019-01-16 21:02:10.154354: step 5492, loss = 0.68692 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:02:11.047338 ops/training.py:65 2019-01-16 21:02:11.047287: step 5493, loss = 0.70032 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:02:11.940796 ops/training.py:65 2019-01-16 21:02:11.940723: step 5494, loss = 0.70039 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:02:12.833916 ops/training.py:65 2019-01-16 21:02:12.833836: step 5495, loss = 0.68831 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:02:13.727416 ops/training.py:65 2019-01-16 21:02:13.727334: step 5496, loss = 0.69489 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:02:14.621413 ops/training.py:65 2019-01-16 21:02:14.621346: step 5497, loss = 0.69527 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:02:15.516759 ops/training.py:65 2019-01-16 21:02:15.516695: step 5498, loss = 0.69248 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:02:16.412589 ops/training.py:65 2019-01-16 21:02:16.412513: step 5499, loss = 0.69952 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:02:17.307631 ops/training.py:65 2019-01-16 21:02:17.307589: step 5500, loss = 0.68280 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:02:18.203140 ops/training.py:65 2019-01-16 21:02:18.203072: step 5501, loss = 0.69184 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:02:19.097395 ops/training.py:65 2019-01-16 21:02:19.097349: step 5502, loss = 0.68534 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:02:19.991734 ops/training.py:65 2019-01-16 21:02:19.991684: step 5503, loss = 0.71715 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:02:20.885181 ops/training.py:65 2019-01-16 21:02:20.885145: step 5504, loss = 0.69572 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:02:21.781237 ops/training.py:65 2019-01-16 21:02:21.781205: step 5505, loss = 0.69594 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:02:22.677701 ops/training.py:65 2019-01-16 21:02:22.677664: step 5506, loss = 0.69013 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:02:23.573971 ops/training.py:65 2019-01-16 21:02:23.573925: step 5507, loss = 0.70585 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:02:24.470091 ops/training.py:65 2019-01-16 21:02:24.470050: step 5508, loss = 0.71091 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:02:25.363389 ops/training.py:65 2019-01-16 21:02:25.363337: step 5509, loss = 0.68778 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:02:26.256034 ops/training.py:65 2019-01-16 21:02:26.255979: step 5510, loss = 0.70307 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:02:27.149698 ops/training.py:65 2019-01-16 21:02:27.149648: step 5511, loss = 0.70840 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:02:28.044425 ops/training.py:65 2019-01-16 21:02:28.044377: step 5512, loss = 0.67582 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:02:28.940315 ops/training.py:65 2019-01-16 21:02:28.940224: step 5513, loss = 0.68153 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:02:29.835702 ops/training.py:65 2019-01-16 21:02:29.835664: step 5514, loss = 0.69484 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:02:30.731412 ops/training.py:65 2019-01-16 21:02:30.731324: step 5515, loss = 0.69012 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:02:31.626690 ops/training.py:65 2019-01-16 21:02:31.626650: step 5516, loss = 0.69872 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:02:32.521388 ops/training.py:65 2019-01-16 21:02:32.521326: step 5517, loss = 0.68573 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:02:33.416699 ops/training.py:65 2019-01-16 21:02:33.416670: step 5518, loss = 0.69824 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:02:34.313272 ops/training.py:65 2019-01-16 21:02:34.313242: step 5519, loss = 0.70802 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:02:35.209581 ops/training.py:65 2019-01-16 21:02:35.209550: step 5520, loss = 0.69602 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:02:36.104278 ops/training.py:65 2019-01-16 21:02:36.104247: step 5521, loss = 0.70123 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:02:36.999071 ops/training.py:65 2019-01-16 21:02:36.999036: step 5522, loss = 0.69431 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:02:37.894898 ops/training.py:65 2019-01-16 21:02:37.894814: step 5523, loss = 0.70813 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:02:38.789736 ops/training.py:65 2019-01-16 21:02:38.789633: step 5524, loss = 0.71124 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:02:39.686025 ops/training.py:65 2019-01-16 21:02:39.685941: step 5525, loss = 0.70654 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:02:40.583358 ops/training.py:65 2019-01-16 21:02:40.583267: step 5526, loss = 0.69098 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:02:41.480277 ops/training.py:65 2019-01-16 21:02:41.480175: step 5527, loss = 0.68794 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:02:42.376157 ops/training.py:65 2019-01-16 21:02:42.376080: step 5528, loss = 0.69304 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:02:43.271562 ops/training.py:65 2019-01-16 21:02:43.271496: step 5529, loss = 0.68692 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:02:44.166608 ops/training.py:65 2019-01-16 21:02:44.166535: step 5530, loss = 0.69650 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:02:45.060865 ops/training.py:65 2019-01-16 21:02:45.060796: step 5531, loss = 0.69058 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:02:45.957278 ops/training.py:65 2019-01-16 21:02:45.957174: step 5532, loss = 0.68938 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:02:46.853499 ops/training.py:65 2019-01-16 21:02:46.853419: step 5533, loss = 0.70369 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:02:47.748629 ops/training.py:65 2019-01-16 21:02:47.748527: step 5534, loss = 0.68557 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:02:48.642790 ops/training.py:65 2019-01-16 21:02:48.642691: step 5535, loss = 0.68723 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:02:49.539672 ops/training.py:65 2019-01-16 21:02:49.539565: step 5536, loss = 0.69479 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:02:50.436695 ops/training.py:65 2019-01-16 21:02:50.436606: step 5537, loss = 0.69306 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:02:51.332480 ops/training.py:65 2019-01-16 21:02:51.332403: step 5538, loss = 0.69267 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:02:52.228443 ops/training.py:65 2019-01-16 21:02:52.228364: step 5539, loss = 0.70275 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:02:53.123685 ops/training.py:65 2019-01-16 21:02:53.123616: step 5540, loss = 0.68993 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:02:54.019019 ops/training.py:65 2019-01-16 21:02:54.018948: step 5541, loss = 0.70997 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:02:54.913382 ops/training.py:65 2019-01-16 21:02:54.913316: step 5542, loss = 0.69618 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:02:55.811431 ops/training.py:65 2019-01-16 21:02:55.811334: step 5543, loss = 0.69244 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:02:56.707801 ops/training.py:65 2019-01-16 21:02:56.707711: step 5544, loss = 0.70323 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:02:57.603983 ops/training.py:65 2019-01-16 21:02:57.603903: step 5545, loss = 0.69042 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:02:58.499643 ops/training.py:65 2019-01-16 21:02:58.499561: step 5546, loss = 0.69837 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:02:59.394982 ops/training.py:65 2019-01-16 21:02:59.394885: step 5547, loss = 0.68797 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:03:00.290476 ops/training.py:65 2019-01-16 21:03:00.290373: step 5548, loss = 0.69857 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:03:01.186742 ops/training.py:65 2019-01-16 21:03:01.186688: step 5549, loss = 0.69669 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:03:02.081870 ops/training.py:65 2019-01-16 21:03:02.081806: step 5550, loss = 0.69920 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:03:02.976110 ops/training.py:65 2019-01-16 21:03:02.976045: step 5551, loss = 0.70489 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:03:03.870597 ops/training.py:65 2019-01-16 21:03:03.870521: step 5552, loss = 0.69772 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:03:04.765929 ops/training.py:65 2019-01-16 21:03:04.765867: step 5553, loss = 0.71475 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:03:05.660366 ops/training.py:65 2019-01-16 21:03:05.660304: step 5554, loss = 0.69101 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:03:06.557275 ops/training.py:65 2019-01-16 21:03:06.557170: step 5555, loss = 0.68088 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:03:07.452052 ops/training.py:65 2019-01-16 21:03:07.451984: step 5556, loss = 0.69371 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:03:08.345599 ops/training.py:65 2019-01-16 21:03:08.345532: step 5557, loss = 0.69848 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:03:09.240522 ops/training.py:65 2019-01-16 21:03:09.240452: step 5558, loss = 0.70221 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:03:10.134414 ops/training.py:65 2019-01-16 21:03:10.134332: step 5559, loss = 0.69652 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:03:11.028985 ops/training.py:65 2019-01-16 21:03:11.028917: step 5560, loss = 0.70274 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:03:11.924957 ops/training.py:65 2019-01-16 21:03:11.924907: step 5561, loss = 0.69566 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:03:12.819752 ops/training.py:65 2019-01-16 21:03:12.819719: step 5562, loss = 0.69037 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:03:13.715050 ops/training.py:65 2019-01-16 21:03:13.715017: step 5563, loss = 0.70854 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:03:14.611960 ops/training.py:65 2019-01-16 21:03:14.611928: step 5564, loss = 0.70675 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:03:15.507517 ops/training.py:65 2019-01-16 21:03:15.507485: step 5565, loss = 0.69978 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:03:16.402750 ops/training.py:65 2019-01-16 21:03:16.402720: step 5566, loss = 0.69482 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:03:17.296112 ops/training.py:65 2019-01-16 21:03:17.296083: step 5567, loss = 0.68994 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:03:18.193158 ops/training.py:65 2019-01-16 21:03:18.193128: step 5568, loss = 0.69563 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:03:19.090282 ops/training.py:65 2019-01-16 21:03:19.090253: step 5569, loss = 0.69395 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:03:19.987608 ops/training.py:65 2019-01-16 21:03:19.987578: step 5570, loss = 0.69386 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:03:20.883131 ops/training.py:65 2019-01-16 21:03:20.883101: step 5571, loss = 0.69541 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:03:21.781155 ops/training.py:65 2019-01-16 21:03:21.781125: step 5572, loss = 0.68571 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:03:22.677501 ops/training.py:65 2019-01-16 21:03:22.677471: step 5573, loss = 0.69837 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:03:23.572316 ops/training.py:65 2019-01-16 21:03:23.572286: step 5574, loss = 0.68881 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:03:24.466259 ops/training.py:65 2019-01-16 21:03:24.466229: step 5575, loss = 0.69380 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:03:25.361756 ops/training.py:65 2019-01-16 21:03:25.361726: step 5576, loss = 0.69282 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:03:26.257447 ops/training.py:65 2019-01-16 21:03:26.257418: step 5577, loss = 0.69176 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:03:27.154352 ops/training.py:65 2019-01-16 21:03:27.154315: step 5578, loss = 0.69508 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:03:28.049433 ops/training.py:65 2019-01-16 21:03:28.049335: step 5579, loss = 0.68913 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:03:28.943858 ops/training.py:65 2019-01-16 21:03:28.943778: step 5580, loss = 0.69010 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:03:29.837876 ops/training.py:65 2019-01-16 21:03:29.837816: step 5581, loss = 0.68331 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:03:30.737458 ops/training.py:65 2019-01-16 21:03:30.737400: step 5582, loss = 0.67847 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 21:03:31.632138 ops/training.py:65 2019-01-16 21:03:31.632069: step 5583, loss = 0.69945 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:03:32.528626 ops/training.py:65 2019-01-16 21:03:32.528595: step 5584, loss = 0.69185 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:03:33.425233 ops/training.py:65 2019-01-16 21:03:33.425197: step 5585, loss = 0.69004 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:03:34.319958 ops/training.py:65 2019-01-16 21:03:34.319909: step 5586, loss = 0.70079 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:03:35.214347 ops/training.py:65 2019-01-16 21:03:35.214277: step 5587, loss = 0.72109 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:03:36.110044 ops/training.py:65 2019-01-16 21:03:36.109931: step 5588, loss = 0.68337 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:03:37.004985 ops/training.py:65 2019-01-16 21:03:37.004919: step 5589, loss = 0.69395 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:03:37.900081 ops/training.py:65 2019-01-16 21:03:37.900038: step 5590, loss = 0.68443 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:03:38.795392 ops/training.py:65 2019-01-16 21:03:38.795351: step 5591, loss = 0.70093 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:03:39.691467 ops/training.py:65 2019-01-16 21:03:39.691436: step 5592, loss = 0.68094 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:03:40.586298 ops/training.py:65 2019-01-16 21:03:40.586216: step 5593, loss = 0.70365 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:03:41.481886 ops/training.py:65 2019-01-16 21:03:41.481792: step 5594, loss = 0.67723 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:03:42.377959 ops/training.py:65 2019-01-16 21:03:42.377917: step 5595, loss = 0.68756 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:03:43.273196 ops/training.py:65 2019-01-16 21:03:43.273159: step 5596, loss = 0.70159 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:03:44.167482 ops/training.py:65 2019-01-16 21:03:44.167395: step 5597, loss = 0.70776 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:03:45.061688 ops/training.py:65 2019-01-16 21:03:45.061625: step 5598, loss = 0.69625 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:03:45.957063 ops/training.py:65 2019-01-16 21:03:45.957032: step 5599, loss = 0.69092 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:03:46.852993 ops/training.py:65 2019-01-16 21:03:46.852962: step 5600, loss = 0.69678 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:03:47.746614 ops/training.py:65 2019-01-16 21:03:47.746581: step 5601, loss = 0.68935 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:03:48.640541 ops/training.py:65 2019-01-16 21:03:48.640487: step 5602, loss = 0.68537 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:03:49.535483 ops/training.py:65 2019-01-16 21:03:49.535426: step 5603, loss = 0.68055 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:03:50.429869 ops/training.py:65 2019-01-16 21:03:50.429828: step 5604, loss = 0.71310 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 21:03:51.326309 ops/training.py:65 2019-01-16 21:03:51.326276: step 5605, loss = 0.70709 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:03:52.221570 ops/training.py:65 2019-01-16 21:03:52.221504: step 5606, loss = 0.69226 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:03:53.116839 ops/training.py:65 2019-01-16 21:03:53.116762: step 5607, loss = 0.70592 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:03:54.012410 ops/training.py:65 2019-01-16 21:03:54.012313: step 5608, loss = 0.68398 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:03:54.907423 ops/training.py:65 2019-01-16 21:03:54.907320: step 5609, loss = 0.69392 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:03:55.804641 ops/training.py:65 2019-01-16 21:03:55.804536: step 5610, loss = 0.69573 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:03:56.701974 ops/training.py:65 2019-01-16 21:03:56.701870: step 5611, loss = 0.69146 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:03:57.597808 ops/training.py:65 2019-01-16 21:03:57.597703: step 5612, loss = 0.68634 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:03:58.494059 ops/training.py:65 2019-01-16 21:03:58.493971: step 5613, loss = 0.69046 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:03:59.388870 ops/training.py:65 2019-01-16 21:03:59.388760: step 5614, loss = 0.68541 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:04:00.285644 ops/training.py:65 2019-01-16 21:04:00.285538: step 5615, loss = 0.69014 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:04:01.181610 ops/training.py:65 2019-01-16 21:04:01.181543: step 5616, loss = 0.68927 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:04:02.079075 ops/training.py:65 2019-01-16 21:04:02.078985: step 5617, loss = 0.69792 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:04:02.977159 ops/training.py:65 2019-01-16 21:04:02.977097: step 5618, loss = 0.69201 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:04:03.874137 ops/training.py:65 2019-01-16 21:04:03.874032: step 5619, loss = 0.69280 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:04:04.769928 ops/training.py:65 2019-01-16 21:04:04.769829: step 5620, loss = 0.69712 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:04:05.664841 ops/training.py:65 2019-01-16 21:04:05.664735: step 5621, loss = 0.69146 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:04:06.563868 ops/training.py:65 2019-01-16 21:04:06.563769: step 5622, loss = 0.69949 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:04:07.459821 ops/training.py:65 2019-01-16 21:04:07.459722: step 5623, loss = 0.69014 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:04:08.355252 ops/training.py:65 2019-01-16 21:04:08.355193: step 5624, loss = 0.69007 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:04:09.248484 ops/training.py:65 2019-01-16 21:04:09.248416: step 5625, loss = 0.68775 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:04:10.143827 ops/training.py:65 2019-01-16 21:04:10.143756: step 5626, loss = 0.68873 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:04:11.041387 ops/training.py:65 2019-01-16 21:04:11.041288: step 5627, loss = 0.69094 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:04:11.938731 ops/training.py:65 2019-01-16 21:04:11.938625: step 5628, loss = 0.69105 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:04:12.834465 ops/training.py:65 2019-01-16 21:04:12.834386: step 5629, loss = 0.69344 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:04:13.729109 ops/training.py:65 2019-01-16 21:04:13.729044: step 5630, loss = 0.70040 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:04:14.624587 ops/training.py:65 2019-01-16 21:04:14.624487: step 5631, loss = 0.68474 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:04:15.520364 ops/training.py:65 2019-01-16 21:04:15.520295: step 5632, loss = 0.68407 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:04:16.413870 ops/training.py:65 2019-01-16 21:04:16.413797: step 5633, loss = 0.69084 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:04:17.308678 ops/training.py:65 2019-01-16 21:04:17.308588: step 5634, loss = 0.69957 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:04:18.204597 ops/training.py:65 2019-01-16 21:04:18.204533: step 5635, loss = 0.68961 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:04:19.098723 ops/training.py:65 2019-01-16 21:04:19.098621: step 5636, loss = 0.70319 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:04:19.995060 ops/training.py:65 2019-01-16 21:04:19.994954: step 5637, loss = 0.69520 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:04:20.891095 ops/training.py:65 2019-01-16 21:04:20.891027: step 5638, loss = 0.69263 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:04:21.786122 ops/training.py:65 2019-01-16 21:04:21.786018: step 5639, loss = 0.68952 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:04:22.682844 ops/training.py:65 2019-01-16 21:04:22.682744: step 5640, loss = 0.69593 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:04:23.579432 ops/training.py:65 2019-01-16 21:04:23.579361: step 5641, loss = 0.69796 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:04:24.473917 ops/training.py:65 2019-01-16 21:04:24.473819: step 5642, loss = 0.69847 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:04:25.368760 ops/training.py:65 2019-01-16 21:04:25.368660: step 5643, loss = 0.68707 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:04:26.264391 ops/training.py:65 2019-01-16 21:04:26.264292: step 5644, loss = 0.69130 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:04:27.160195 ops/training.py:65 2019-01-16 21:04:27.160095: step 5645, loss = 0.69595 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:04:28.054558 ops/training.py:65 2019-01-16 21:04:28.054497: step 5646, loss = 0.68866 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:04:28.948199 ops/training.py:65 2019-01-16 21:04:28.948141: step 5647, loss = 0.68737 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:04:29.842857 ops/training.py:65 2019-01-16 21:04:29.842788: step 5648, loss = 0.69706 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:04:30.738240 ops/training.py:65 2019-01-16 21:04:30.738145: step 5649, loss = 0.69334 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:04:31.634506 ops/training.py:65 2019-01-16 21:04:31.634397: step 5650, loss = 0.69516 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:04:32.530116 ops/training.py:65 2019-01-16 21:04:32.530047: step 5651, loss = 0.69029 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:04:33.425194 ops/training.py:65 2019-01-16 21:04:33.425085: step 5652, loss = 0.69266 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:04:34.320361 ops/training.py:65 2019-01-16 21:04:34.320261: step 5653, loss = 0.69738 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:04:35.215397 ops/training.py:65 2019-01-16 21:04:35.215291: step 5654, loss = 0.68741 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:04:36.111828 ops/training.py:65 2019-01-16 21:04:36.111726: step 5655, loss = 0.68994 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:04:37.007466 ops/training.py:65 2019-01-16 21:04:37.007409: step 5656, loss = 0.68707 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:04:37.903740 ops/training.py:65 2019-01-16 21:04:37.903635: step 5657, loss = 0.69737 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:04:38.800417 ops/training.py:65 2019-01-16 21:04:38.800317: step 5658, loss = 0.68760 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:04:39.697346 ops/training.py:65 2019-01-16 21:04:39.697277: step 5659, loss = 0.69852 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:04:40.593956 ops/training.py:65 2019-01-16 21:04:40.593875: step 5660, loss = 0.69076 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:04:41.491755 ops/training.py:65 2019-01-16 21:04:41.491649: step 5661, loss = 0.69309 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:04:42.386708 ops/training.py:65 2019-01-16 21:04:42.386647: step 5662, loss = 0.68676 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:04:43.283163 ops/training.py:65 2019-01-16 21:04:43.283062: step 5663, loss = 0.69156 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:04:44.179438 ops/training.py:65 2019-01-16 21:04:44.179354: step 5664, loss = 0.69260 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:04:45.076534 ops/training.py:65 2019-01-16 21:04:45.076401: step 5665, loss = 0.69608 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:04:45.971604 ops/training.py:65 2019-01-16 21:04:45.971462: step 5666, loss = 0.69653 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:04:46.870806 ops/training.py:65 2019-01-16 21:04:46.870700: step 5667, loss = 0.69449 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:04:47.768272 ops/training.py:65 2019-01-16 21:04:47.768139: step 5668, loss = 0.69887 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:04:48.663797 ops/training.py:65 2019-01-16 21:04:48.663694: step 5669, loss = 0.68882 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:04:49.561582 ops/training.py:65 2019-01-16 21:04:49.561491: step 5670, loss = 0.69107 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:04:50.458635 ops/training.py:65 2019-01-16 21:04:50.458538: step 5671, loss = 0.69176 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:04:51.355296 ops/training.py:65 2019-01-16 21:04:51.355200: step 5672, loss = 0.69147 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:04:52.252540 ops/training.py:65 2019-01-16 21:04:52.252449: step 5673, loss = 0.69603 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:04:53.146857 ops/training.py:65 2019-01-16 21:04:53.146760: step 5674, loss = 0.69627 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:04:54.043044 ops/training.py:65 2019-01-16 21:04:54.042953: step 5675, loss = 0.69526 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:04:54.939886 ops/training.py:65 2019-01-16 21:04:54.939783: step 5676, loss = 0.69050 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:04:55.835470 ops/training.py:65 2019-01-16 21:04:55.835371: step 5677, loss = 0.68707 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:04:56.731148 ops/training.py:65 2019-01-16 21:04:56.731054: step 5678, loss = 0.69720 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:04:57.628154 ops/training.py:65 2019-01-16 21:04:57.628065: step 5679, loss = 0.69777 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:04:58.525046 ops/training.py:65 2019-01-16 21:04:58.524947: step 5680, loss = 0.69557 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:04:59.419617 ops/training.py:65 2019-01-16 21:04:59.419515: step 5681, loss = 0.69326 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:05:00.315970 ops/training.py:65 2019-01-16 21:05:00.315872: step 5682, loss = 0.68870 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:05:01.211446 ops/training.py:65 2019-01-16 21:05:01.211365: step 5683, loss = 0.69367 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:05:02.107129 ops/training.py:65 2019-01-16 21:05:02.107051: step 5684, loss = 0.68982 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:05:03.002153 ops/training.py:65 2019-01-16 21:05:03.002047: step 5685, loss = 0.69338 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:05:03.897509 ops/training.py:65 2019-01-16 21:05:03.897405: step 5686, loss = 0.69658 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:05:04.793793 ops/training.py:65 2019-01-16 21:05:04.793684: step 5687, loss = 0.69155 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:05:05.690397 ops/training.py:65 2019-01-16 21:05:05.690292: step 5688, loss = 0.69250 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:05:06.585224 ops/training.py:65 2019-01-16 21:05:06.585129: step 5689, loss = 0.68596 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:05:07.481673 ops/training.py:65 2019-01-16 21:05:07.481539: step 5690, loss = 0.69630 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:05:08.377153 ops/training.py:65 2019-01-16 21:05:08.377056: step 5691, loss = 0.69793 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:05:09.271113 ops/training.py:65 2019-01-16 21:05:09.271012: step 5692, loss = 0.69053 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:05:10.169128 ops/training.py:65 2019-01-16 21:05:10.169042: step 5693, loss = 0.69815 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:05:11.064972 ops/training.py:65 2019-01-16 21:05:11.064839: step 5694, loss = 0.69079 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:05:11.960370 ops/training.py:65 2019-01-16 21:05:11.960271: step 5695, loss = 0.69076 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:05:12.856590 ops/training.py:65 2019-01-16 21:05:12.856487: step 5696, loss = 0.69257 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:05:13.751791 ops/training.py:65 2019-01-16 21:05:13.751689: step 5697, loss = 0.69857 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:05:14.647876 ops/training.py:65 2019-01-16 21:05:14.647767: step 5698, loss = 0.69721 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:05:15.542648 ops/training.py:65 2019-01-16 21:05:15.542538: step 5699, loss = 0.68730 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:05:16.439022 ops/training.py:65 2019-01-16 21:05:16.438932: step 5700, loss = 0.70258 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.125
I1280 2019-01-16 21:05:17.335201 ops/training.py:65 2019-01-16 21:05:17.335108: step 5701, loss = 0.69490 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:05:18.230773 ops/training.py:65 2019-01-16 21:05:18.230682: step 5702, loss = 0.69130 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:05:19.128072 ops/training.py:65 2019-01-16 21:05:19.127976: step 5703, loss = 0.68991 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:05:20.024690 ops/training.py:65 2019-01-16 21:05:20.024597: step 5704, loss = 0.69395 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:05:20.920113 ops/training.py:65 2019-01-16 21:05:20.919979: step 5705, loss = 0.69303 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:05:21.816878 ops/training.py:65 2019-01-16 21:05:21.816779: step 5706, loss = 0.69711 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:05:22.714288 ops/training.py:65 2019-01-16 21:05:22.714190: step 5707, loss = 0.69173 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:05:23.610612 ops/training.py:65 2019-01-16 21:05:23.610520: step 5708, loss = 0.69215 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:05:24.507373 ops/training.py:65 2019-01-16 21:05:24.507280: step 5709, loss = 0.69317 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:05:25.403941 ops/training.py:65 2019-01-16 21:05:25.403845: step 5710, loss = 0.69760 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:05:26.299138 ops/training.py:65 2019-01-16 21:05:26.299080: step 5711, loss = 0.69291 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:05:27.193826 ops/training.py:65 2019-01-16 21:05:27.193761: step 5712, loss = 0.69441 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:05:28.088887 ops/training.py:65 2019-01-16 21:05:28.088780: step 5713, loss = 0.70252 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:05:28.984596 ops/training.py:65 2019-01-16 21:05:28.984493: step 5714, loss = 0.69459 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:05:29.879030 ops/training.py:65 2019-01-16 21:05:29.878924: step 5715, loss = 0.68783 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:05:30.778574 ops/training.py:65 2019-01-16 21:05:30.778474: step 5716, loss = 0.69511 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:05:31.675997 ops/training.py:65 2019-01-16 21:05:31.675891: step 5717, loss = 0.69411 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:05:32.572357 ops/training.py:65 2019-01-16 21:05:32.572259: step 5718, loss = 0.69323 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:05:33.468200 ops/training.py:65 2019-01-16 21:05:33.468099: step 5719, loss = 0.69390 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:05:34.364909 ops/training.py:65 2019-01-16 21:05:34.364800: step 5720, loss = 0.69122 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:05:35.260497 ops/training.py:65 2019-01-16 21:05:35.260391: step 5721, loss = 0.69624 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:05:36.155013 ops/training.py:65 2019-01-16 21:05:36.154950: step 5722, loss = 0.69309 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:05:37.049531 ops/training.py:65 2019-01-16 21:05:37.049467: step 5723, loss = 0.69342 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:05:37.944389 ops/training.py:65 2019-01-16 21:05:37.944283: step 5724, loss = 0.69195 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:05:38.840721 ops/training.py:65 2019-01-16 21:05:38.840621: step 5725, loss = 0.69429 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:05:39.737261 ops/training.py:65 2019-01-16 21:05:39.737161: step 5726, loss = 0.69059 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:05:40.634001 ops/training.py:65 2019-01-16 21:05:40.633913: step 5727, loss = 0.68931 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:05:41.529503 ops/training.py:65 2019-01-16 21:05:41.529405: step 5728, loss = 0.69130 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:05:42.423831 ops/training.py:65 2019-01-16 21:05:42.423733: step 5729, loss = 0.69962 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:05:43.319327 ops/training.py:65 2019-01-16 21:05:43.319229: step 5730, loss = 0.69429 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:05:44.213428 ops/training.py:65 2019-01-16 21:05:44.213328: step 5731, loss = 0.68834 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:05:45.106245 ops/training.py:65 2019-01-16 21:05:45.106156: step 5732, loss = 0.69054 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:05:46.002037 ops/training.py:65 2019-01-16 21:05:46.001945: step 5733, loss = 0.69445 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:05:46.897068 ops/training.py:65 2019-01-16 21:05:46.896996: step 5734, loss = 0.69260 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:05:47.791790 ops/training.py:65 2019-01-16 21:05:47.791717: step 5735, loss = 0.68715 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:05:48.686928 ops/training.py:65 2019-01-16 21:05:48.686868: step 5736, loss = 0.69007 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:05:49.581871 ops/training.py:65 2019-01-16 21:05:49.581785: step 5737, loss = 0.69304 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:05:50.476233 ops/training.py:65 2019-01-16 21:05:50.476160: step 5738, loss = 0.69404 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:05:51.371676 ops/training.py:65 2019-01-16 21:05:51.371605: step 5739, loss = 0.69365 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:05:52.266335 ops/training.py:65 2019-01-16 21:05:52.266257: step 5740, loss = 0.69257 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:05:53.161122 ops/training.py:65 2019-01-16 21:05:53.161010: step 5741, loss = 0.69156 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:05:54.057085 ops/training.py:65 2019-01-16 21:05:54.056975: step 5742, loss = 0.69426 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:05:54.954554 ops/training.py:65 2019-01-16 21:05:54.954451: step 5743, loss = 0.69554 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:05:55.850823 ops/training.py:65 2019-01-16 21:05:55.850754: step 5744, loss = 0.69681 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:05:56.745491 ops/training.py:65 2019-01-16 21:05:56.745438: step 5745, loss = 0.69086 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:05:57.641101 ops/training.py:65 2019-01-16 21:05:57.640994: step 5746, loss = 0.69248 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:05:58.536661 ops/training.py:65 2019-01-16 21:05:58.536559: step 5747, loss = 0.69644 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:05:59.433959 ops/training.py:65 2019-01-16 21:05:59.433850: step 5748, loss = 0.69672 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:06:00.330688 ops/training.py:65 2019-01-16 21:06:00.330618: step 5749, loss = 0.69305 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:06:01.224675 ops/training.py:65 2019-01-16 21:06:01.224622: step 5750, loss = 0.69389 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:06:02.119339 ops/training.py:65 2019-01-16 21:06:02.119244: step 5751, loss = 0.69201 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:06:03.014091 ops/training.py:65 2019-01-16 21:06:03.013992: step 5752, loss = 0.69171 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:06:03.911915 ops/training.py:65 2019-01-16 21:06:03.911808: step 5753, loss = 0.69503 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:06:04.807228 ops/training.py:65 2019-01-16 21:06:04.807127: step 5754, loss = 0.69023 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:06:05.703668 ops/training.py:65 2019-01-16 21:06:05.703563: step 5755, loss = 0.69762 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:06:06.600379 ops/training.py:65 2019-01-16 21:06:06.600312: step 5756, loss = 0.69522 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:06:07.496473 ops/training.py:65 2019-01-16 21:06:07.496401: step 5757, loss = 0.69678 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:06:08.392654 ops/training.py:65 2019-01-16 21:06:08.392586: step 5758, loss = 0.68630 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:06:09.286375 ops/training.py:65 2019-01-16 21:06:09.286307: step 5759, loss = 0.69923 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:06:10.181570 ops/training.py:65 2019-01-16 21:06:10.181485: step 5760, loss = 0.68887 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:06:11.077524 ops/training.py:65 2019-01-16 21:06:11.077428: step 5761, loss = 0.69032 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:06:11.971447 ops/training.py:65 2019-01-16 21:06:11.971345: step 5762, loss = 0.69119 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:06:12.866482 ops/training.py:65 2019-01-16 21:06:12.866379: step 5763, loss = 0.69625 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:06:13.760899 ops/training.py:65 2019-01-16 21:06:13.760802: step 5764, loss = 0.69508 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:06:14.656652 ops/training.py:65 2019-01-16 21:06:14.656553: step 5765, loss = 0.69395 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:06:15.551185 ops/training.py:65 2019-01-16 21:06:15.551090: step 5766, loss = 0.69428 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:06:16.446693 ops/training.py:65 2019-01-16 21:06:16.446585: step 5767, loss = 0.69012 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:06:17.341054 ops/training.py:65 2019-01-16 21:06:17.340951: step 5768, loss = 0.69366 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:06:18.235278 ops/training.py:65 2019-01-16 21:06:18.235176: step 5769, loss = 0.68838 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:06:19.133763 ops/training.py:65 2019-01-16 21:06:19.133665: step 5770, loss = 0.68558 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:06:20.030361 ops/training.py:65 2019-01-16 21:06:20.030258: step 5771, loss = 0.69484 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:06:20.926351 ops/training.py:65 2019-01-16 21:06:20.926248: step 5772, loss = 0.70439 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 21:06:21.822262 ops/training.py:65 2019-01-16 21:06:21.822186: step 5773, loss = 0.69702 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:06:22.718321 ops/training.py:65 2019-01-16 21:06:22.718229: step 5774, loss = 0.68993 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:06:23.614457 ops/training.py:65 2019-01-16 21:06:23.614364: step 5775, loss = 0.70085 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:06:24.508636 ops/training.py:65 2019-01-16 21:06:24.508544: step 5776, loss = 0.68764 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:06:25.404766 ops/training.py:65 2019-01-16 21:06:25.404670: step 5777, loss = 0.69283 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:06:26.300265 ops/training.py:65 2019-01-16 21:06:26.300168: step 5778, loss = 0.68978 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:06:27.196724 ops/training.py:65 2019-01-16 21:06:27.196632: step 5779, loss = 0.69343 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:06:28.092395 ops/training.py:65 2019-01-16 21:06:28.092326: step 5780, loss = 0.68970 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:06:28.987575 ops/training.py:65 2019-01-16 21:06:28.987502: step 5781, loss = 0.69446 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:06:29.883601 ops/training.py:65 2019-01-16 21:06:29.883509: step 5782, loss = 0.69256 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:06:30.779348 ops/training.py:65 2019-01-16 21:06:30.779271: step 5783, loss = 0.68541 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:06:31.674169 ops/training.py:65 2019-01-16 21:06:31.674061: step 5784, loss = 0.69861 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:06:32.569076 ops/training.py:65 2019-01-16 21:06:32.568976: step 5785, loss = 0.68947 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:06:33.463172 ops/training.py:65 2019-01-16 21:06:33.463075: step 5786, loss = 0.69345 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:06:34.356606 ops/training.py:65 2019-01-16 21:06:34.356503: step 5787, loss = 0.70239 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:06:35.251052 ops/training.py:65 2019-01-16 21:06:35.250946: step 5788, loss = 0.69126 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:06:36.148062 ops/training.py:65 2019-01-16 21:06:36.147959: step 5789, loss = 0.70363 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:06:37.044441 ops/training.py:65 2019-01-16 21:06:37.044341: step 5790, loss = 0.68296 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.84375
I1280 2019-01-16 21:06:37.940206 ops/training.py:65 2019-01-16 21:06:37.940146: step 5791, loss = 0.69640 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:06:38.836550 ops/training.py:65 2019-01-16 21:06:38.836470: step 5792, loss = 0.69047 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:06:39.732349 ops/training.py:65 2019-01-16 21:06:39.732252: step 5793, loss = 0.69651 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:06:40.627517 ops/training.py:65 2019-01-16 21:06:40.627433: step 5794, loss = 0.69905 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:06:41.521575 ops/training.py:65 2019-01-16 21:06:41.521481: step 5795, loss = 0.69300 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:06:42.417230 ops/training.py:65 2019-01-16 21:06:42.417136: step 5796, loss = 0.69148 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:06:43.313144 ops/training.py:65 2019-01-16 21:06:43.313078: step 5797, loss = 0.69470 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:06:44.208466 ops/training.py:65 2019-01-16 21:06:44.208395: step 5798, loss = 0.68975 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:06:45.104399 ops/training.py:65 2019-01-16 21:06:45.104327: step 5799, loss = 0.69769 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:06:45.998828 ops/training.py:65 2019-01-16 21:06:45.998752: step 5800, loss = 0.69829 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:06:46.894817 ops/training.py:65 2019-01-16 21:06:46.894781: step 5801, loss = 0.69467 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:06:47.789190 ops/training.py:65 2019-01-16 21:06:47.789120: step 5802, loss = 0.69522 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:06:48.685123 ops/training.py:65 2019-01-16 21:06:48.685054: step 5803, loss = 0.69598 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:06:49.580648 ops/training.py:65 2019-01-16 21:06:49.580613: step 5804, loss = 0.69344 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:06:50.475615 ops/training.py:65 2019-01-16 21:06:50.475540: step 5805, loss = 0.69071 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:06:51.370068 ops/training.py:65 2019-01-16 21:06:51.369960: step 5806, loss = 0.68782 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:06:52.267462 ops/training.py:65 2019-01-16 21:06:52.267362: step 5807, loss = 0.69753 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:06:53.163418 ops/training.py:65 2019-01-16 21:06:53.163353: step 5808, loss = 0.69102 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:06:54.057611 ops/training.py:65 2019-01-16 21:06:54.057545: step 5809, loss = 0.68917 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:06:54.953847 ops/training.py:65 2019-01-16 21:06:54.953782: step 5810, loss = 0.68763 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:06:55.850784 ops/training.py:65 2019-01-16 21:06:55.850673: step 5811, loss = 0.69674 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:06:56.747422 ops/training.py:65 2019-01-16 21:06:56.747357: step 5812, loss = 0.68944 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:06:57.641297 ops/training.py:65 2019-01-16 21:06:57.641230: step 5813, loss = 0.69568 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:06:58.536490 ops/training.py:65 2019-01-16 21:06:58.536418: step 5814, loss = 0.69288 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:06:59.431703 ops/training.py:65 2019-01-16 21:06:59.431641: step 5815, loss = 0.69041 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:07:00.326182 ops/training.py:65 2019-01-16 21:07:00.326116: step 5816, loss = 0.68906 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:07:01.221780 ops/training.py:65 2019-01-16 21:07:01.221715: step 5817, loss = 0.69635 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:07:02.116344 ops/training.py:65 2019-01-16 21:07:02.116250: step 5818, loss = 0.68319 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:07:03.013416 ops/training.py:65 2019-01-16 21:07:03.013316: step 5819, loss = 0.69095 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:07:03.910567 ops/training.py:65 2019-01-16 21:07:03.910499: step 5820, loss = 0.69177 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:07:04.806553 ops/training.py:65 2019-01-16 21:07:04.806493: step 5821, loss = 0.69336 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:07:05.701186 ops/training.py:65 2019-01-16 21:07:05.701121: step 5822, loss = 0.69417 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:07:06.596292 ops/training.py:65 2019-01-16 21:07:06.596218: step 5823, loss = 0.69310 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:07:07.491338 ops/training.py:65 2019-01-16 21:07:07.491274: step 5824, loss = 0.69646 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:07:08.385473 ops/training.py:65 2019-01-16 21:07:08.385413: step 5825, loss = 0.69718 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:07:09.283112 ops/training.py:65 2019-01-16 21:07:09.283007: step 5826, loss = 0.69577 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:07:10.178624 ops/training.py:65 2019-01-16 21:07:10.178552: step 5827, loss = 0.70107 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:07:11.072732 ops/training.py:65 2019-01-16 21:07:11.072669: step 5828, loss = 0.69246 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:07:11.969633 ops/training.py:65 2019-01-16 21:07:11.969534: step 5829, loss = 0.69315 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:07:12.866376 ops/training.py:65 2019-01-16 21:07:12.866297: step 5830, loss = 0.69675 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:07:13.762819 ops/training.py:65 2019-01-16 21:07:13.762719: step 5831, loss = 0.68394 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:07:14.660613 ops/training.py:65 2019-01-16 21:07:14.660538: step 5832, loss = 0.69239 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:07:15.557122 ops/training.py:65 2019-01-16 21:07:15.557058: step 5833, loss = 0.68823 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:07:16.452898 ops/training.py:65 2019-01-16 21:07:16.452839: step 5834, loss = 0.69777 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:07:17.348781 ops/training.py:65 2019-01-16 21:07:17.348679: step 5835, loss = 0.69620 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:07:18.246484 ops/training.py:65 2019-01-16 21:07:18.246378: step 5836, loss = 0.69130 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:07:19.143388 ops/training.py:65 2019-01-16 21:07:19.143288: step 5837, loss = 0.69472 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:07:20.039267 ops/training.py:65 2019-01-16 21:07:20.039203: step 5838, loss = 0.71127 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 21:07:20.932962 ops/training.py:65 2019-01-16 21:07:20.932893: step 5839, loss = 0.69481 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:07:21.826812 ops/training.py:65 2019-01-16 21:07:21.826748: step 5840, loss = 0.68761 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:07:22.720258 ops/training.py:65 2019-01-16 21:07:22.720196: step 5841, loss = 0.69326 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:07:23.614237 ops/training.py:65 2019-01-16 21:07:23.614161: step 5842, loss = 0.69667 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:07:24.509092 ops/training.py:65 2019-01-16 21:07:24.509022: step 5843, loss = 0.69350 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:07:25.404634 ops/training.py:65 2019-01-16 21:07:25.404566: step 5844, loss = 0.69070 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:07:26.300215 ops/training.py:65 2019-01-16 21:07:26.300146: step 5845, loss = 0.67615 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 21:07:27.195542 ops/training.py:65 2019-01-16 21:07:27.195470: step 5846, loss = 0.68028 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 21:07:28.090769 ops/training.py:65 2019-01-16 21:07:28.090686: step 5847, loss = 0.69688 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:07:28.986059 ops/training.py:65 2019-01-16 21:07:28.985993: step 5848, loss = 0.68711 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:07:29.879722 ops/training.py:65 2019-01-16 21:07:29.879654: step 5849, loss = 0.70424 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:07:30.775004 ops/training.py:65 2019-01-16 21:07:30.774940: step 5850, loss = 0.69289 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:07:31.669130 ops/training.py:65 2019-01-16 21:07:31.669067: step 5851, loss = 0.69018 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:07:32.564122 ops/training.py:65 2019-01-16 21:07:32.564063: step 5852, loss = 0.69056 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:07:33.458296 ops/training.py:65 2019-01-16 21:07:33.458235: step 5853, loss = 0.68888 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:07:34.351214 ops/training.py:65 2019-01-16 21:07:34.351153: step 5854, loss = 0.70275 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:07:35.245963 ops/training.py:65 2019-01-16 21:07:35.245901: step 5855, loss = 0.69107 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:07:36.140792 ops/training.py:65 2019-01-16 21:07:36.140724: step 5856, loss = 0.68657 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:07:37.034953 ops/training.py:65 2019-01-16 21:07:37.034887: step 5857, loss = 0.70258 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:07:37.929761 ops/training.py:65 2019-01-16 21:07:37.929700: step 5858, loss = 0.68751 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:07:38.825649 ops/training.py:65 2019-01-16 21:07:38.825547: step 5859, loss = 0.69355 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:07:39.723822 ops/training.py:65 2019-01-16 21:07:39.723724: step 5860, loss = 0.69275 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:07:40.618462 ops/training.py:65 2019-01-16 21:07:40.618381: step 5861, loss = 0.69803 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:07:41.515113 ops/training.py:65 2019-01-16 21:07:41.515013: step 5862, loss = 0.69126 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:07:42.410941 ops/training.py:65 2019-01-16 21:07:42.410843: step 5863, loss = 0.69836 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:07:43.307568 ops/training.py:65 2019-01-16 21:07:43.307464: step 5864, loss = 0.69764 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:07:44.203839 ops/training.py:65 2019-01-16 21:07:44.203741: step 5865, loss = 0.69232 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:07:45.099520 ops/training.py:65 2019-01-16 21:07:45.099427: step 5866, loss = 0.69192 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:07:45.994031 ops/training.py:65 2019-01-16 21:07:45.993928: step 5867, loss = 0.69835 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:07:46.889380 ops/training.py:65 2019-01-16 21:07:46.889285: step 5868, loss = 0.69105 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:07:47.785486 ops/training.py:65 2019-01-16 21:07:47.785388: step 5869, loss = 0.70031 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:07:48.682494 ops/training.py:65 2019-01-16 21:07:48.682391: step 5870, loss = 0.69366 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:07:49.579759 ops/training.py:65 2019-01-16 21:07:49.579657: step 5871, loss = 0.69297 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:07:50.476296 ops/training.py:65 2019-01-16 21:07:50.476188: step 5872, loss = 0.69562 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:07:51.370254 ops/training.py:65 2019-01-16 21:07:51.370120: step 5873, loss = 0.69232 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:07:52.266668 ops/training.py:65 2019-01-16 21:07:52.266599: step 5874, loss = 0.68780 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:07:53.164436 ops/training.py:65 2019-01-16 21:07:53.164333: step 5875, loss = 0.69502 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:07:54.060920 ops/training.py:65 2019-01-16 21:07:54.060829: step 5876, loss = 0.69500 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:07:54.956100 ops/training.py:65 2019-01-16 21:07:54.956036: step 5877, loss = 0.69239 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:07:55.850305 ops/training.py:65 2019-01-16 21:07:55.850204: step 5878, loss = 0.69043 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:07:56.747683 ops/training.py:65 2019-01-16 21:07:56.747586: step 5879, loss = 0.69507 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:07:57.643888 ops/training.py:65 2019-01-16 21:07:57.643818: step 5880, loss = 0.69695 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:07:58.541855 ops/training.py:65 2019-01-16 21:07:58.541753: step 5881, loss = 0.68889 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:07:59.438071 ops/training.py:65 2019-01-16 21:07:59.437970: step 5882, loss = 0.68908 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:08:00.335250 ops/training.py:65 2019-01-16 21:08:00.335156: step 5883, loss = 0.69361 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:08:01.231549 ops/training.py:65 2019-01-16 21:08:01.231457: step 5884, loss = 0.69726 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:08:02.125892 ops/training.py:65 2019-01-16 21:08:02.125801: step 5885, loss = 0.69533 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:08:03.022603 ops/training.py:65 2019-01-16 21:08:03.022501: step 5886, loss = 0.69458 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:08:03.918258 ops/training.py:65 2019-01-16 21:08:03.918155: step 5887, loss = 0.69317 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:08:04.814518 ops/training.py:65 2019-01-16 21:08:04.814413: step 5888, loss = 0.69322 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:08:05.710456 ops/training.py:65 2019-01-16 21:08:05.710403: step 5889, loss = 0.69379 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:08:06.605517 ops/training.py:65 2019-01-16 21:08:06.605414: step 5890, loss = 0.69468 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:08:07.501149 ops/training.py:65 2019-01-16 21:08:07.501048: step 5891, loss = 0.69345 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:08:08.398373 ops/training.py:65 2019-01-16 21:08:08.398268: step 5892, loss = 0.69647 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:08:09.296085 ops/training.py:65 2019-01-16 21:08:09.295983: step 5893, loss = 0.69472 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:08:10.192481 ops/training.py:65 2019-01-16 21:08:10.192395: step 5894, loss = 0.69564 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:08:11.088860 ops/training.py:65 2019-01-16 21:08:11.088767: step 5895, loss = 0.69297 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:08:11.983713 ops/training.py:65 2019-01-16 21:08:11.983606: step 5896, loss = 0.69497 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:08:12.880837 ops/training.py:65 2019-01-16 21:08:12.880731: step 5897, loss = 0.69657 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:08:13.776448 ops/training.py:65 2019-01-16 21:08:13.776374: step 5898, loss = 0.69583 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:08:14.672177 ops/training.py:65 2019-01-16 21:08:14.672092: step 5899, loss = 0.69445 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:08:15.569523 ops/training.py:65 2019-01-16 21:08:15.569424: step 5900, loss = 0.69337 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:08:16.469796 ops/training.py:65 2019-01-16 21:08:16.469693: step 5901, loss = 0.69228 (35.6 examples/sec; 0.899 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:08:17.367246 ops/training.py:65 2019-01-16 21:08:17.367144: step 5902, loss = 0.69630 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:08:18.263073 ops/training.py:65 2019-01-16 21:08:18.263001: step 5903, loss = 0.69391 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:08:19.158747 ops/training.py:65 2019-01-16 21:08:19.158679: step 5904, loss = 0.69523 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:08:20.053435 ops/training.py:65 2019-01-16 21:08:20.053365: step 5905, loss = 0.69320 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:08:20.948610 ops/training.py:65 2019-01-16 21:08:20.948541: step 5906, loss = 0.69351 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:08:21.843490 ops/training.py:65 2019-01-16 21:08:21.843416: step 5907, loss = 0.69525 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:08:22.739598 ops/training.py:65 2019-01-16 21:08:22.739502: step 5908, loss = 0.69479 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:08:23.635538 ops/training.py:65 2019-01-16 21:08:23.635467: step 5909, loss = 0.69026 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:08:24.530873 ops/training.py:65 2019-01-16 21:08:24.530808: step 5910, loss = 0.69466 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:08:25.427074 ops/training.py:65 2019-01-16 21:08:25.426929: step 5911, loss = 0.69732 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:08:26.323342 ops/training.py:65 2019-01-16 21:08:26.323237: step 5912, loss = 0.69537 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:08:27.219176 ops/training.py:65 2019-01-16 21:08:27.219074: step 5913, loss = 0.69546 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:08:28.116311 ops/training.py:65 2019-01-16 21:08:28.116212: step 5914, loss = 0.69402 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:08:29.012858 ops/training.py:65 2019-01-16 21:08:29.012787: step 5915, loss = 0.69468 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:08:29.908326 ops/training.py:65 2019-01-16 21:08:29.908259: step 5916, loss = 0.69091 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:08:30.803009 ops/training.py:65 2019-01-16 21:08:30.802945: step 5917, loss = 0.69210 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:08:31.697278 ops/training.py:65 2019-01-16 21:08:31.697212: step 5918, loss = 0.68449 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 21:08:32.592645 ops/training.py:65 2019-01-16 21:08:32.592575: step 5919, loss = 0.69193 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:08:33.487762 ops/training.py:65 2019-01-16 21:08:33.487695: step 5920, loss = 0.68839 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:08:34.382244 ops/training.py:65 2019-01-16 21:08:34.382174: step 5921, loss = 0.69430 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:08:35.277366 ops/training.py:65 2019-01-16 21:08:35.277301: step 5922, loss = 0.69340 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:08:36.171365 ops/training.py:65 2019-01-16 21:08:36.171299: step 5923, loss = 0.68828 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:08:37.065807 ops/training.py:65 2019-01-16 21:08:37.065731: step 5924, loss = 0.68936 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:08:37.962091 ops/training.py:65 2019-01-16 21:08:37.961987: step 5925, loss = 0.70380 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:08:38.859118 ops/training.py:65 2019-01-16 21:08:38.859015: step 5926, loss = 0.69774 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:08:39.755600 ops/training.py:65 2019-01-16 21:08:39.755496: step 5927, loss = 0.69033 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:08:40.650978 ops/training.py:65 2019-01-16 21:08:40.650894: step 5928, loss = 0.68814 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:08:41.547486 ops/training.py:65 2019-01-16 21:08:41.547389: step 5929, loss = 0.69405 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:08:42.444639 ops/training.py:65 2019-01-16 21:08:42.444547: step 5930, loss = 0.69954 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:08:43.341356 ops/training.py:65 2019-01-16 21:08:43.341257: step 5931, loss = 0.69657 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:08:44.237384 ops/training.py:65 2019-01-16 21:08:44.237282: step 5932, loss = 0.69412 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:08:45.132611 ops/training.py:65 2019-01-16 21:08:45.132519: step 5933, loss = 0.69944 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:08:46.026409 ops/training.py:65 2019-01-16 21:08:46.026312: step 5934, loss = 0.69053 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:08:46.920833 ops/training.py:65 2019-01-16 21:08:46.920737: step 5935, loss = 0.70977 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:08:47.815188 ops/training.py:65 2019-01-16 21:08:47.815093: step 5936, loss = 0.68707 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:08:48.711879 ops/training.py:65 2019-01-16 21:08:48.711813: step 5937, loss = 0.69300 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:08:49.606220 ops/training.py:65 2019-01-16 21:08:49.606158: step 5938, loss = 0.69784 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:08:50.501043 ops/training.py:65 2019-01-16 21:08:50.500941: step 5939, loss = 0.69041 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:08:51.395384 ops/training.py:65 2019-01-16 21:08:51.395286: step 5940, loss = 0.69326 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:08:52.292940 ops/training.py:65 2019-01-16 21:08:52.292836: step 5941, loss = 0.69568 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:08:53.190039 ops/training.py:65 2019-01-16 21:08:53.189930: step 5942, loss = 0.69066 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:08:54.086657 ops/training.py:65 2019-01-16 21:08:54.086593: step 5943, loss = 0.69092 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:08:54.979189 ops/training.py:65 2019-01-16 21:08:54.979130: step 5944, loss = 0.70399 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:08:55.874271 ops/training.py:65 2019-01-16 21:08:55.874213: step 5945, loss = 0.69802 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:08:56.769915 ops/training.py:65 2019-01-16 21:08:56.769864: step 5946, loss = 0.70316 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:08:57.664083 ops/training.py:65 2019-01-16 21:08:57.664024: step 5947, loss = 0.69690 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:08:58.557285 ops/training.py:65 2019-01-16 21:08:58.557218: step 5948, loss = 0.69234 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:08:59.449874 ops/training.py:65 2019-01-16 21:08:59.449818: step 5949, loss = 0.70096 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:09:00.342686 ops/training.py:65 2019-01-16 21:09:00.342621: step 5950, loss = 0.69326 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:09:01.235390 ops/training.py:65 2019-01-16 21:09:01.235324: step 5951, loss = 0.68874 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:09:02.128287 ops/training.py:65 2019-01-16 21:09:02.128232: step 5952, loss = 0.68909 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:09:03.022654 ops/training.py:65 2019-01-16 21:09:03.022618: step 5953, loss = 0.68555 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:09:03.920043 ops/training.py:65 2019-01-16 21:09:03.920012: step 5954, loss = 0.69436 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:09:04.816659 ops/training.py:65 2019-01-16 21:09:04.816624: step 5955, loss = 0.69385 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:09:05.712828 ops/training.py:65 2019-01-16 21:09:05.712795: step 5956, loss = 0.69147 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:09:06.605803 ops/training.py:65 2019-01-16 21:09:06.605773: step 5957, loss = 0.68397 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:09:07.499803 ops/training.py:65 2019-01-16 21:09:07.499773: step 5958, loss = 0.69422 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:09:08.393679 ops/training.py:65 2019-01-16 21:09:08.393584: step 5959, loss = 0.69417 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:09:09.288873 ops/training.py:65 2019-01-16 21:09:09.288817: step 5960, loss = 0.69803 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:09:10.184371 ops/training.py:65 2019-01-16 21:09:10.184289: step 5961, loss = 0.69477 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:09:11.080624 ops/training.py:65 2019-01-16 21:09:11.080521: step 5962, loss = 0.69707 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:09:11.976047 ops/training.py:65 2019-01-16 21:09:11.975978: step 5963, loss = 0.69552 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:09:12.871559 ops/training.py:65 2019-01-16 21:09:12.871480: step 5964, loss = 0.69709 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:09:13.768372 ops/training.py:65 2019-01-16 21:09:13.768269: step 5965, loss = 0.69290 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:09:14.664801 ops/training.py:65 2019-01-16 21:09:14.664707: step 5966, loss = 0.69676 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:09:15.560560 ops/training.py:65 2019-01-16 21:09:15.560495: step 5967, loss = 0.69026 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:09:16.457150 ops/training.py:65 2019-01-16 21:09:16.457048: step 5968, loss = 0.69215 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:09:17.352170 ops/training.py:65 2019-01-16 21:09:17.352098: step 5969, loss = 0.68711 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:09:18.247634 ops/training.py:65 2019-01-16 21:09:18.247577: step 5970, loss = 0.69299 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:09:19.142140 ops/training.py:65 2019-01-16 21:09:19.142071: step 5971, loss = 0.69056 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:09:20.036101 ops/training.py:65 2019-01-16 21:09:20.036032: step 5972, loss = 0.68751 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:09:20.930773 ops/training.py:65 2019-01-16 21:09:20.930691: step 5973, loss = 0.69644 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:09:21.825688 ops/training.py:65 2019-01-16 21:09:21.825587: step 5974, loss = 0.69556 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:09:22.722519 ops/training.py:65 2019-01-16 21:09:22.722420: step 5975, loss = 0.69608 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:09:23.617290 ops/training.py:65 2019-01-16 21:09:23.617216: step 5976, loss = 0.69584 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:09:24.512546 ops/training.py:65 2019-01-16 21:09:24.512484: step 5977, loss = 0.69230 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:09:25.407481 ops/training.py:65 2019-01-16 21:09:25.407403: step 5978, loss = 0.68775 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:09:26.302341 ops/training.py:65 2019-01-16 21:09:26.302242: step 5979, loss = 0.69306 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:09:27.198842 ops/training.py:65 2019-01-16 21:09:27.198750: step 5980, loss = 0.69424 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:09:28.094198 ops/training.py:65 2019-01-16 21:09:28.094131: step 5981, loss = 0.69873 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:09:28.989622 ops/training.py:65 2019-01-16 21:09:28.989547: step 5982, loss = 0.69655 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:09:29.885392 ops/training.py:65 2019-01-16 21:09:29.885329: step 5983, loss = 0.69084 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:09:30.779601 ops/training.py:65 2019-01-16 21:09:30.779537: step 5984, loss = 0.69141 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:09:31.677359 ops/training.py:65 2019-01-16 21:09:31.677252: step 5985, loss = 0.69614 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:09:32.573297 ops/training.py:65 2019-01-16 21:09:32.573228: step 5986, loss = 0.69210 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:09:33.468670 ops/training.py:65 2019-01-16 21:09:33.468610: step 5987, loss = 0.69404 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:09:34.362459 ops/training.py:65 2019-01-16 21:09:34.362399: step 5988, loss = 0.69517 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:09:35.255945 ops/training.py:65 2019-01-16 21:09:35.255879: step 5989, loss = 0.69236 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:09:36.150307 ops/training.py:65 2019-01-16 21:09:36.150237: step 5990, loss = 0.69564 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:09:37.047941 ops/training.py:65 2019-01-16 21:09:37.047837: step 5991, loss = 0.69097 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:09:37.945328 ops/training.py:65 2019-01-16 21:09:37.945222: step 5992, loss = 0.68559 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:09:38.842565 ops/training.py:65 2019-01-16 21:09:38.842470: step 5993, loss = 0.69224 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:09:39.739266 ops/training.py:65 2019-01-16 21:09:39.739210: step 5994, loss = 0.68417 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:09:40.633806 ops/training.py:65 2019-01-16 21:09:40.633722: step 5995, loss = 0.69385 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:09:41.529326 ops/training.py:65 2019-01-16 21:09:41.529249: step 5996, loss = 0.69375 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:09:42.423731 ops/training.py:65 2019-01-16 21:09:42.423635: step 5997, loss = 0.69388 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:09:43.318593 ops/training.py:65 2019-01-16 21:09:43.318491: step 5998, loss = 0.69038 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:09:44.215258 ops/training.py:65 2019-01-16 21:09:44.215151: step 5999, loss = 0.69342 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:13:59.200441 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I1280 2019-01-16 21:13:59.201461 ops/training.py:41 2019-01-16 21:13:59.201401: step 6000, loss = 0.70 (0.1 examples/sec; 254.088 sec/batch) | Training accuracy = 0.40625 | Validation accuracy = 0.50565 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_19_26_22_049623
I1280 2019-01-16 21:14:00.103831 ops/training.py:65 2019-01-16 21:14:00.103725: step 6001, loss = 0.68731 (35.5 examples/sec; 0.901 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:14:00.999623 ops/training.py:65 2019-01-16 21:14:00.999529: step 6002, loss = 0.69497 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:14:01.895656 ops/training.py:65 2019-01-16 21:14:01.895575: step 6003, loss = 0.69082 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:14:02.791076 ops/training.py:65 2019-01-16 21:14:02.791012: step 6004, loss = 0.68861 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:14:03.686144 ops/training.py:65 2019-01-16 21:14:03.686083: step 6005, loss = 0.68818 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:14:04.581562 ops/training.py:65 2019-01-16 21:14:04.581462: step 6006, loss = 0.69810 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:14:05.475934 ops/training.py:65 2019-01-16 21:14:05.475844: step 6007, loss = 0.69198 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:14:06.370289 ops/training.py:65 2019-01-16 21:14:06.370192: step 6008, loss = 0.68787 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:14:07.264600 ops/training.py:65 2019-01-16 21:14:07.264496: step 6009, loss = 0.69623 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:14:08.161734 ops/training.py:65 2019-01-16 21:14:08.161628: step 6010, loss = 0.69884 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:14:09.058048 ops/training.py:65 2019-01-16 21:14:09.057941: step 6011, loss = 0.69949 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:14:09.955197 ops/training.py:65 2019-01-16 21:14:09.955097: step 6012, loss = 0.70226 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:14:10.852158 ops/training.py:65 2019-01-16 21:14:10.852071: step 6013, loss = 0.70089 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:14:11.750272 ops/training.py:65 2019-01-16 21:14:11.750173: step 6014, loss = 0.69011 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:14:12.644708 ops/training.py:65 2019-01-16 21:14:12.644637: step 6015, loss = 0.68973 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:14:13.539447 ops/training.py:65 2019-01-16 21:14:13.539381: step 6016, loss = 0.69564 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:14:14.434428 ops/training.py:65 2019-01-16 21:14:14.434362: step 6017, loss = 0.68984 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:14:15.329271 ops/training.py:65 2019-01-16 21:14:15.329199: step 6018, loss = 0.69224 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:14:16.223856 ops/training.py:65 2019-01-16 21:14:16.223784: step 6019, loss = 0.70485 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:14:17.120153 ops/training.py:65 2019-01-16 21:14:17.120053: step 6020, loss = 0.69847 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:14:18.015394 ops/training.py:65 2019-01-16 21:14:18.015296: step 6021, loss = 0.69902 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:14:18.909909 ops/training.py:65 2019-01-16 21:14:18.909846: step 6022, loss = 0.70187 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:14:19.804790 ops/training.py:65 2019-01-16 21:14:19.804719: step 6023, loss = 0.68991 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:14:20.699533 ops/training.py:65 2019-01-16 21:14:20.699466: step 6024, loss = 0.69867 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:14:21.595029 ops/training.py:65 2019-01-16 21:14:21.594958: step 6025, loss = 0.70055 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:14:22.491090 ops/training.py:65 2019-01-16 21:14:22.491017: step 6026, loss = 0.70214 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:14:23.384894 ops/training.py:65 2019-01-16 21:14:23.384828: step 6027, loss = 0.69790 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:14:24.279696 ops/training.py:65 2019-01-16 21:14:24.279636: step 6028, loss = 0.68425 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:14:25.174499 ops/training.py:65 2019-01-16 21:14:25.174441: step 6029, loss = 0.69569 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:14:26.070999 ops/training.py:65 2019-01-16 21:14:26.070903: step 6030, loss = 0.69774 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:14:26.967407 ops/training.py:65 2019-01-16 21:14:26.967307: step 6031, loss = 0.69934 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:14:27.861682 ops/training.py:65 2019-01-16 21:14:27.861611: step 6032, loss = 0.70062 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:14:28.759213 ops/training.py:65 2019-01-16 21:14:28.759120: step 6033, loss = 0.69368 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:14:29.654145 ops/training.py:65 2019-01-16 21:14:29.654090: step 6034, loss = 0.70044 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:14:30.548948 ops/training.py:65 2019-01-16 21:14:30.548878: step 6035, loss = 0.70277 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:14:31.446666 ops/training.py:65 2019-01-16 21:14:31.446565: step 6036, loss = 0.68847 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:14:32.342514 ops/training.py:65 2019-01-16 21:14:32.342412: step 6037, loss = 0.69070 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:14:33.239166 ops/training.py:65 2019-01-16 21:14:33.239067: step 6038, loss = 0.69789 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:14:34.135986 ops/training.py:65 2019-01-16 21:14:34.135885: step 6039, loss = 0.70193 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:14:35.032274 ops/training.py:65 2019-01-16 21:14:35.032208: step 6040, loss = 0.69997 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:14:35.926563 ops/training.py:65 2019-01-16 21:14:35.926436: step 6041, loss = 0.69293 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:14:36.822223 ops/training.py:65 2019-01-16 21:14:36.822160: step 6042, loss = 0.68772 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:14:37.716568 ops/training.py:65 2019-01-16 21:14:37.716507: step 6043, loss = 0.69039 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:14:38.610544 ops/training.py:65 2019-01-16 21:14:38.610476: step 6044, loss = 0.69033 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:14:39.503384 ops/training.py:65 2019-01-16 21:14:39.503317: step 6045, loss = 0.68477 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:14:40.397001 ops/training.py:65 2019-01-16 21:14:40.396924: step 6046, loss = 0.69900 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:14:41.291922 ops/training.py:65 2019-01-16 21:14:41.291846: step 6047, loss = 0.69127 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:14:42.186220 ops/training.py:65 2019-01-16 21:14:42.186127: step 6048, loss = 0.69561 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:14:43.083926 ops/training.py:65 2019-01-16 21:14:43.083859: step 6049, loss = 0.68858 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:14:43.980537 ops/training.py:65 2019-01-16 21:14:43.980430: step 6050, loss = 0.69561 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:14:44.874490 ops/training.py:65 2019-01-16 21:14:44.874423: step 6051, loss = 0.69991 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:14:45.768918 ops/training.py:65 2019-01-16 21:14:45.768850: step 6052, loss = 0.69238 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:14:46.661858 ops/training.py:65 2019-01-16 21:14:46.661796: step 6053, loss = 0.68737 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:14:47.555636 ops/training.py:65 2019-01-16 21:14:47.555572: step 6054, loss = 0.69525 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:14:48.452050 ops/training.py:65 2019-01-16 21:14:48.451982: step 6055, loss = 0.68994 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:14:49.348552 ops/training.py:65 2019-01-16 21:14:49.348445: step 6056, loss = 0.69460 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:14:50.244767 ops/training.py:65 2019-01-16 21:14:50.244657: step 6057, loss = 0.69270 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:14:51.141093 ops/training.py:65 2019-01-16 21:14:51.140998: step 6058, loss = 0.68886 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:14:52.037343 ops/training.py:65 2019-01-16 21:14:52.037252: step 6059, loss = 0.69472 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:14:52.933678 ops/training.py:65 2019-01-16 21:14:52.933585: step 6060, loss = 0.68924 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:14:53.828824 ops/training.py:65 2019-01-16 21:14:53.828762: step 6061, loss = 0.69325 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:14:54.721967 ops/training.py:65 2019-01-16 21:14:54.721908: step 6062, loss = 0.70275 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:14:55.616944 ops/training.py:65 2019-01-16 21:14:55.616868: step 6063, loss = 0.69367 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:14:56.512472 ops/training.py:65 2019-01-16 21:14:56.512365: step 6064, loss = 0.68795 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:14:57.409617 ops/training.py:65 2019-01-16 21:14:57.409512: step 6065, loss = 0.69647 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:14:58.305759 ops/training.py:65 2019-01-16 21:14:58.305694: step 6066, loss = 0.69341 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:14:59.199634 ops/training.py:65 2019-01-16 21:14:59.199572: step 6067, loss = 0.69288 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:15:00.092500 ops/training.py:65 2019-01-16 21:15:00.092436: step 6068, loss = 0.69725 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:15:00.987354 ops/training.py:65 2019-01-16 21:15:00.987289: step 6069, loss = 0.68989 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:15:01.881839 ops/training.py:65 2019-01-16 21:15:01.881781: step 6070, loss = 0.69729 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:15:02.776065 ops/training.py:65 2019-01-16 21:15:02.775995: step 6071, loss = 0.69224 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:15:03.670234 ops/training.py:65 2019-01-16 21:15:03.670170: step 6072, loss = 0.69171 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:15:04.564750 ops/training.py:65 2019-01-16 21:15:04.564692: step 6073, loss = 0.69001 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:15:05.460884 ops/training.py:65 2019-01-16 21:15:05.460777: step 6074, loss = 0.69286 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:15:06.358613 ops/training.py:65 2019-01-16 21:15:06.358509: step 6075, loss = 0.69430 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:15:07.256023 ops/training.py:65 2019-01-16 21:15:07.255920: step 6076, loss = 0.68988 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:15:08.152641 ops/training.py:65 2019-01-16 21:15:08.152577: step 6077, loss = 0.69267 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:15:09.047718 ops/training.py:65 2019-01-16 21:15:09.047660: step 6078, loss = 0.68591 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:15:09.941049 ops/training.py:65 2019-01-16 21:15:09.940988: step 6079, loss = 0.69025 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:15:10.835922 ops/training.py:65 2019-01-16 21:15:10.835846: step 6080, loss = 0.68739 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:15:11.731643 ops/training.py:65 2019-01-16 21:15:11.731549: step 6081, loss = 0.69055 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:15:12.626859 ops/training.py:65 2019-01-16 21:15:12.626762: step 6082, loss = 0.69088 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:15:13.521615 ops/training.py:65 2019-01-16 21:15:13.521542: step 6083, loss = 0.68585 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:15:14.419509 ops/training.py:65 2019-01-16 21:15:14.419409: step 6084, loss = 0.69165 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:15:15.314592 ops/training.py:65 2019-01-16 21:15:15.314489: step 6085, loss = 0.69163 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:15:16.208380 ops/training.py:65 2019-01-16 21:15:16.208312: step 6086, loss = 0.68725 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:15:17.101750 ops/training.py:65 2019-01-16 21:15:17.101687: step 6087, loss = 0.69528 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:15:17.995814 ops/training.py:65 2019-01-16 21:15:17.995751: step 6088, loss = 0.69224 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:15:18.890464 ops/training.py:65 2019-01-16 21:15:18.890402: step 6089, loss = 0.70293 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:15:19.785713 ops/training.py:65 2019-01-16 21:15:19.785647: step 6090, loss = 0.70022 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:15:20.682133 ops/training.py:65 2019-01-16 21:15:20.682027: step 6091, loss = 0.69239 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:15:21.578345 ops/training.py:65 2019-01-16 21:15:21.578241: step 6092, loss = 0.70254 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:15:22.474583 ops/training.py:65 2019-01-16 21:15:22.474511: step 6093, loss = 0.69712 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:15:23.368631 ops/training.py:65 2019-01-16 21:15:23.368559: step 6094, loss = 0.69250 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:15:24.261975 ops/training.py:65 2019-01-16 21:15:24.261909: step 6095, loss = 0.69126 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:15:25.155459 ops/training.py:65 2019-01-16 21:15:25.155402: step 6096, loss = 0.70209 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:15:26.049880 ops/training.py:65 2019-01-16 21:15:26.049820: step 6097, loss = 0.70124 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:15:26.944745 ops/training.py:65 2019-01-16 21:15:26.944687: step 6098, loss = 0.69512 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:15:27.839489 ops/training.py:65 2019-01-16 21:15:27.839422: step 6099, loss = 0.68860 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:15:28.733244 ops/training.py:65 2019-01-16 21:15:28.733168: step 6100, loss = 0.70650 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:15:29.627955 ops/training.py:65 2019-01-16 21:15:29.627888: step 6101, loss = 0.70060 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:15:30.521504 ops/training.py:65 2019-01-16 21:15:30.521447: step 6102, loss = 0.69127 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:15:31.415023 ops/training.py:65 2019-01-16 21:15:31.414956: step 6103, loss = 0.68929 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:15:32.308089 ops/training.py:65 2019-01-16 21:15:32.308031: step 6104, loss = 0.67867 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:15:33.201010 ops/training.py:65 2019-01-16 21:15:33.200944: step 6105, loss = 0.70069 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:15:34.094980 ops/training.py:65 2019-01-16 21:15:34.094921: step 6106, loss = 0.69506 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:15:34.993014 ops/training.py:65 2019-01-16 21:15:34.992910: step 6107, loss = 0.69780 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:15:35.889357 ops/training.py:65 2019-01-16 21:15:35.889248: step 6108, loss = 0.69745 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:15:36.786485 ops/training.py:65 2019-01-16 21:15:36.786387: step 6109, loss = 0.69021 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:15:37.682731 ops/training.py:65 2019-01-16 21:15:37.682633: step 6110, loss = 0.69428 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:15:38.577839 ops/training.py:65 2019-01-16 21:15:38.577782: step 6111, loss = 0.68901 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:15:39.473976 ops/training.py:65 2019-01-16 21:15:39.473904: step 6112, loss = 0.69320 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:15:40.369628 ops/training.py:65 2019-01-16 21:15:40.369525: step 6113, loss = 0.69147 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:15:41.264349 ops/training.py:65 2019-01-16 21:15:41.264263: step 6114, loss = 0.69313 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:15:42.158022 ops/training.py:65 2019-01-16 21:15:42.157931: step 6115, loss = 0.69486 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:15:43.054646 ops/training.py:65 2019-01-16 21:15:43.054546: step 6116, loss = 0.70056 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:15:43.949257 ops/training.py:65 2019-01-16 21:15:43.949155: step 6117, loss = 0.69366 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:15:44.846142 ops/training.py:65 2019-01-16 21:15:44.846042: step 6118, loss = 0.69366 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:15:45.741936 ops/training.py:65 2019-01-16 21:15:45.741840: step 6119, loss = 0.69239 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:15:46.636895 ops/training.py:65 2019-01-16 21:15:46.636826: step 6120, loss = 0.68586 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:15:47.531505 ops/training.py:65 2019-01-16 21:15:47.531439: step 6121, loss = 0.69758 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:15:48.425768 ops/training.py:65 2019-01-16 21:15:48.425706: step 6122, loss = 0.69794 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:15:49.319854 ops/training.py:65 2019-01-16 21:15:49.319785: step 6123, loss = 0.68478 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:15:50.213547 ops/training.py:65 2019-01-16 21:15:50.213483: step 6124, loss = 0.70375 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:15:51.107616 ops/training.py:65 2019-01-16 21:15:51.107548: step 6125, loss = 0.67771 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.78125
I1280 2019-01-16 21:15:52.001847 ops/training.py:65 2019-01-16 21:15:52.001777: step 6126, loss = 0.69450 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:15:52.897572 ops/training.py:65 2019-01-16 21:15:52.897488: step 6127, loss = 0.69205 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:15:53.793542 ops/training.py:65 2019-01-16 21:15:53.793441: step 6128, loss = 0.68774 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:15:54.688413 ops/training.py:65 2019-01-16 21:15:54.688311: step 6129, loss = 0.69185 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:15:55.584330 ops/training.py:65 2019-01-16 21:15:55.584261: step 6130, loss = 0.69347 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:15:56.478763 ops/training.py:65 2019-01-16 21:15:56.478699: step 6131, loss = 0.69144 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:15:57.374564 ops/training.py:65 2019-01-16 21:15:57.374460: step 6132, loss = 0.69000 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:15:58.269722 ops/training.py:65 2019-01-16 21:15:58.269610: step 6133, loss = 0.69510 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:15:59.165484 ops/training.py:65 2019-01-16 21:15:59.165387: step 6134, loss = 0.69047 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:16:00.062535 ops/training.py:65 2019-01-16 21:16:00.062434: step 6135, loss = 0.69709 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:16:00.957778 ops/training.py:65 2019-01-16 21:16:00.957680: step 6136, loss = 0.68508 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:16:01.852384 ops/training.py:65 2019-01-16 21:16:01.852289: step 6137, loss = 0.70630 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:16:02.747561 ops/training.py:65 2019-01-16 21:16:02.747464: step 6138, loss = 0.69207 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:16:03.644056 ops/training.py:65 2019-01-16 21:16:03.643952: step 6139, loss = 0.69529 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:16:04.541288 ops/training.py:65 2019-01-16 21:16:04.541186: step 6140, loss = 0.68992 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:16:05.438910 ops/training.py:65 2019-01-16 21:16:05.438810: step 6141, loss = 0.69304 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:16:06.336023 ops/training.py:65 2019-01-16 21:16:06.335923: step 6142, loss = 0.69118 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:16:07.233616 ops/training.py:65 2019-01-16 21:16:07.233514: step 6143, loss = 0.69667 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:16:08.130659 ops/training.py:65 2019-01-16 21:16:08.130549: step 6144, loss = 0.69501 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:16:09.027507 ops/training.py:65 2019-01-16 21:16:09.027406: step 6145, loss = 0.68614 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:16:09.922586 ops/training.py:65 2019-01-16 21:16:09.922486: step 6146, loss = 0.67999 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:16:10.818714 ops/training.py:65 2019-01-16 21:16:10.818633: step 6147, loss = 0.70202 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:16:11.713642 ops/training.py:65 2019-01-16 21:16:11.713535: step 6148, loss = 0.70631 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 21:16:12.611165 ops/training.py:65 2019-01-16 21:16:12.611110: step 6149, loss = 0.70788 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:16:13.506386 ops/training.py:65 2019-01-16 21:16:13.506354: step 6150, loss = 0.70874 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:16:14.401635 ops/training.py:65 2019-01-16 21:16:14.401594: step 6151, loss = 0.68484 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:16:15.295116 ops/training.py:65 2019-01-16 21:16:15.295075: step 6152, loss = 0.70065 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:16:16.188222 ops/training.py:65 2019-01-16 21:16:16.188159: step 6153, loss = 0.70722 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:16:17.082079 ops/training.py:65 2019-01-16 21:16:17.082016: step 6154, loss = 0.69262 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:16:17.978709 ops/training.py:65 2019-01-16 21:16:17.978674: step 6155, loss = 0.68950 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:16:18.875147 ops/training.py:65 2019-01-16 21:16:18.875103: step 6156, loss = 0.69517 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:16:19.771545 ops/training.py:65 2019-01-16 21:16:19.771458: step 6157, loss = 0.70148 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:16:20.668029 ops/training.py:65 2019-01-16 21:16:20.667998: step 6158, loss = 0.69924 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:16:21.562985 ops/training.py:65 2019-01-16 21:16:21.562950: step 6159, loss = 0.69433 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:16:22.457165 ops/training.py:65 2019-01-16 21:16:22.457125: step 6160, loss = 0.70028 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:16:23.351209 ops/training.py:65 2019-01-16 21:16:23.351149: step 6161, loss = 0.69163 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:16:24.246897 ops/training.py:65 2019-01-16 21:16:24.246834: step 6162, loss = 0.69549 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:16:25.141067 ops/training.py:65 2019-01-16 21:16:25.141010: step 6163, loss = 0.69374 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:16:26.034378 ops/training.py:65 2019-01-16 21:16:26.034318: step 6164, loss = 0.70698 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:16:26.928329 ops/training.py:65 2019-01-16 21:16:26.928301: step 6165, loss = 0.69865 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:16:27.823873 ops/training.py:65 2019-01-16 21:16:27.823846: step 6166, loss = 0.69152 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:16:28.719008 ops/training.py:65 2019-01-16 21:16:28.718978: step 6167, loss = 0.69209 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:16:29.614227 ops/training.py:65 2019-01-16 21:16:29.614188: step 6168, loss = 0.68985 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:16:30.512435 ops/training.py:65 2019-01-16 21:16:30.512407: step 6169, loss = 0.67756 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:16:31.407801 ops/training.py:65 2019-01-16 21:16:31.407756: step 6170, loss = 0.68515 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:16:32.301699 ops/training.py:65 2019-01-16 21:16:32.301669: step 6171, loss = 0.69874 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:16:33.198086 ops/training.py:65 2019-01-16 21:16:33.198057: step 6172, loss = 0.69593 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:16:34.091633 ops/training.py:65 2019-01-16 21:16:34.091601: step 6173, loss = 0.69272 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:16:34.985830 ops/training.py:65 2019-01-16 21:16:34.985765: step 6174, loss = 0.69429 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:16:35.879122 ops/training.py:65 2019-01-16 21:16:35.879062: step 6175, loss = 0.68259 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:16:36.772833 ops/training.py:65 2019-01-16 21:16:36.772773: step 6176, loss = 0.69766 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:16:37.667777 ops/training.py:65 2019-01-16 21:16:37.667750: step 6177, loss = 0.70030 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:16:38.563245 ops/training.py:65 2019-01-16 21:16:38.563177: step 6178, loss = 0.69229 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:16:39.456632 ops/training.py:65 2019-01-16 21:16:39.456565: step 6179, loss = 0.69742 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:16:40.349653 ops/training.py:65 2019-01-16 21:16:40.349588: step 6180, loss = 0.69931 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:16:41.244164 ops/training.py:65 2019-01-16 21:16:41.244119: step 6181, loss = 0.68993 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:16:42.140991 ops/training.py:65 2019-01-16 21:16:42.140963: step 6182, loss = 0.68461 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:16:43.034859 ops/training.py:65 2019-01-16 21:16:43.034770: step 6183, loss = 0.69169 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:16:43.930834 ops/training.py:65 2019-01-16 21:16:43.930745: step 6184, loss = 0.68607 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:16:44.828048 ops/training.py:65 2019-01-16 21:16:44.827964: step 6185, loss = 0.70230 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:16:45.724614 ops/training.py:65 2019-01-16 21:16:45.724548: step 6186, loss = 0.67986 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 21:16:46.620733 ops/training.py:65 2019-01-16 21:16:46.620674: step 6187, loss = 0.69541 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:16:47.515173 ops/training.py:65 2019-01-16 21:16:47.515134: step 6188, loss = 0.70446 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:16:48.410174 ops/training.py:65 2019-01-16 21:16:48.410098: step 6189, loss = 0.67894 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:16:49.304001 ops/training.py:65 2019-01-16 21:16:49.303948: step 6190, loss = 0.69469 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:16:50.197781 ops/training.py:65 2019-01-16 21:16:50.197723: step 6191, loss = 0.69787 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:16:51.091742 ops/training.py:65 2019-01-16 21:16:51.091686: step 6192, loss = 0.69051 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:16:51.987901 ops/training.py:65 2019-01-16 21:16:51.987818: step 6193, loss = 0.69745 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:16:52.887036 ops/training.py:65 2019-01-16 21:16:52.886957: step 6194, loss = 0.69464 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:16:53.783636 ops/training.py:65 2019-01-16 21:16:53.783551: step 6195, loss = 0.69298 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:16:54.680958 ops/training.py:65 2019-01-16 21:16:54.680871: step 6196, loss = 0.68277 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:16:55.577352 ops/training.py:65 2019-01-16 21:16:55.577263: step 6197, loss = 0.68933 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:16:56.472648 ops/training.py:65 2019-01-16 21:16:56.472595: step 6198, loss = 0.69419 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:16:57.366049 ops/training.py:65 2019-01-16 21:16:57.365991: step 6199, loss = 0.69513 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:16:58.260080 ops/training.py:65 2019-01-16 21:16:58.260025: step 6200, loss = 0.69028 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:16:59.153813 ops/training.py:65 2019-01-16 21:16:59.153758: step 6201, loss = 0.69452 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:17:00.046628 ops/training.py:65 2019-01-16 21:17:00.046569: step 6202, loss = 0.69833 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:17:00.939058 ops/training.py:65 2019-01-16 21:17:00.939007: step 6203, loss = 0.69114 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:17:01.832949 ops/training.py:65 2019-01-16 21:17:01.832900: step 6204, loss = 0.69759 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:17:02.727195 ops/training.py:65 2019-01-16 21:17:02.727145: step 6205, loss = 0.69703 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:17:03.620908 ops/training.py:65 2019-01-16 21:17:03.620854: step 6206, loss = 0.69474 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:17:04.514718 ops/training.py:65 2019-01-16 21:17:04.514662: step 6207, loss = 0.69957 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 21:17:05.409702 ops/training.py:65 2019-01-16 21:17:05.409639: step 6208, loss = 0.69835 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:17:06.306105 ops/training.py:65 2019-01-16 21:17:06.306019: step 6209, loss = 0.69613 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:17:07.201102 ops/training.py:65 2019-01-16 21:17:07.201021: step 6210, loss = 0.69393 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:17:08.096212 ops/training.py:65 2019-01-16 21:17:08.096155: step 6211, loss = 0.69467 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:17:08.988665 ops/training.py:65 2019-01-16 21:17:08.988614: step 6212, loss = 0.69406 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:17:09.881200 ops/training.py:65 2019-01-16 21:17:09.881147: step 6213, loss = 0.69015 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:17:10.774133 ops/training.py:65 2019-01-16 21:17:10.774072: step 6214, loss = 0.69654 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:17:11.669201 ops/training.py:65 2019-01-16 21:17:11.669120: step 6215, loss = 0.69535 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:17:12.563998 ops/training.py:65 2019-01-16 21:17:12.563942: step 6216, loss = 0.69380 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:17:13.458226 ops/training.py:65 2019-01-16 21:17:13.458170: step 6217, loss = 0.69083 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:17:14.350867 ops/training.py:65 2019-01-16 21:17:14.350814: step 6218, loss = 0.69570 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:17:15.243006 ops/training.py:65 2019-01-16 21:17:15.242952: step 6219, loss = 0.69958 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:17:16.135973 ops/training.py:65 2019-01-16 21:17:16.135921: step 6220, loss = 0.69071 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:17:17.031957 ops/training.py:65 2019-01-16 21:17:17.031921: step 6221, loss = 0.69580 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:17:17.928203 ops/training.py:65 2019-01-16 21:17:17.928167: step 6222, loss = 0.69736 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:17:18.823971 ops/training.py:65 2019-01-16 21:17:18.823931: step 6223, loss = 0.69548 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:17:19.719655 ops/training.py:65 2019-01-16 21:17:19.719607: step 6224, loss = 0.69159 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:17:20.616589 ops/training.py:65 2019-01-16 21:17:20.616534: step 6225, loss = 0.68404 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 21:17:21.510812 ops/training.py:65 2019-01-16 21:17:21.510758: step 6226, loss = 0.69852 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:17:22.406399 ops/training.py:65 2019-01-16 21:17:22.406359: step 6227, loss = 0.69620 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:17:23.302962 ops/training.py:65 2019-01-16 21:17:23.302905: step 6228, loss = 0.69768 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:17:24.197965 ops/training.py:65 2019-01-16 21:17:24.197911: step 6229, loss = 0.69165 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:17:25.092456 ops/training.py:65 2019-01-16 21:17:25.092412: step 6230, loss = 0.68699 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:17:25.987949 ops/training.py:65 2019-01-16 21:17:25.987902: step 6231, loss = 0.69911 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:17:26.883367 ops/training.py:65 2019-01-16 21:17:26.883317: step 6232, loss = 0.69687 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:17:27.777523 ops/training.py:65 2019-01-16 21:17:27.777492: step 6233, loss = 0.70389 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:17:28.673153 ops/training.py:65 2019-01-16 21:17:28.673123: step 6234, loss = 0.69182 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:17:29.568587 ops/training.py:65 2019-01-16 21:17:29.568547: step 6235, loss = 0.68539 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:17:30.466286 ops/training.py:65 2019-01-16 21:17:30.466258: step 6236, loss = 0.69738 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:17:31.362777 ops/training.py:65 2019-01-16 21:17:31.362748: step 6237, loss = 0.68409 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:17:32.259875 ops/training.py:65 2019-01-16 21:17:32.259825: step 6238, loss = 0.68613 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:17:33.151724 ops/training.py:65 2019-01-16 21:17:33.151669: step 6239, loss = 0.70077 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:17:34.050391 ops/training.py:65 2019-01-16 21:17:34.050358: step 6240, loss = 0.69017 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:17:34.945286 ops/training.py:65 2019-01-16 21:17:34.945236: step 6241, loss = 0.68126 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:17:35.841116 ops/training.py:65 2019-01-16 21:17:35.841033: step 6242, loss = 0.68749 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:17:36.734475 ops/training.py:65 2019-01-16 21:17:36.734403: step 6243, loss = 0.69609 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:17:37.628286 ops/training.py:65 2019-01-16 21:17:37.628230: step 6244, loss = 0.69001 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:17:38.520994 ops/training.py:65 2019-01-16 21:17:38.520941: step 6245, loss = 0.69211 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:17:39.414608 ops/training.py:65 2019-01-16 21:17:39.414552: step 6246, loss = 0.68852 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:17:40.310253 ops/training.py:65 2019-01-16 21:17:40.310198: step 6247, loss = 0.69658 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:17:41.204607 ops/training.py:65 2019-01-16 21:17:41.204542: step 6248, loss = 0.69028 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:17:42.101050 ops/training.py:65 2019-01-16 21:17:42.100952: step 6249, loss = 0.69123 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:17:42.995666 ops/training.py:65 2019-01-16 21:17:42.995579: step 6250, loss = 0.69926 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:17:43.891326 ops/training.py:65 2019-01-16 21:17:43.891262: step 6251, loss = 0.69554 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:17:44.788165 ops/training.py:65 2019-01-16 21:17:44.788076: step 6252, loss = 0.69453 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:17:45.682699 ops/training.py:65 2019-01-16 21:17:45.682611: step 6253, loss = 0.68779 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:17:46.577699 ops/training.py:65 2019-01-16 21:17:46.577639: step 6254, loss = 0.68314 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:17:47.472681 ops/training.py:65 2019-01-16 21:17:47.472624: step 6255, loss = 0.69657 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:17:48.366000 ops/training.py:65 2019-01-16 21:17:48.365942: step 6256, loss = 0.70246 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:17:49.260946 ops/training.py:65 2019-01-16 21:17:49.260874: step 6257, loss = 0.69231 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:17:50.156078 ops/training.py:65 2019-01-16 21:17:50.155992: step 6258, loss = 0.69836 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:17:51.052642 ops/training.py:65 2019-01-16 21:17:51.052550: step 6259, loss = 0.69572 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:17:51.946679 ops/training.py:65 2019-01-16 21:17:51.946621: step 6260, loss = 0.69118 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:17:52.839910 ops/training.py:65 2019-01-16 21:17:52.839856: step 6261, loss = 0.69171 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:17:53.732876 ops/training.py:65 2019-01-16 21:17:53.732817: step 6262, loss = 0.68341 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:17:54.625984 ops/training.py:65 2019-01-16 21:17:54.625931: step 6263, loss = 0.69159 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:17:55.520364 ops/training.py:65 2019-01-16 21:17:55.520307: step 6264, loss = 0.70172 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:17:56.414316 ops/training.py:65 2019-01-16 21:17:56.414264: step 6265, loss = 0.69376 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:17:57.308224 ops/training.py:65 2019-01-16 21:17:57.308175: step 6266, loss = 0.69049 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:17:58.201307 ops/training.py:65 2019-01-16 21:17:58.201257: step 6267, loss = 0.69525 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:17:59.094875 ops/training.py:65 2019-01-16 21:17:59.094822: step 6268, loss = 0.69476 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:17:59.988455 ops/training.py:65 2019-01-16 21:17:59.988404: step 6269, loss = 0.69746 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:18:00.883749 ops/training.py:65 2019-01-16 21:18:00.883693: step 6270, loss = 0.69121 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:18:01.779830 ops/training.py:65 2019-01-16 21:18:01.779750: step 6271, loss = 0.68985 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:18:02.676024 ops/training.py:65 2019-01-16 21:18:02.675949: step 6272, loss = 0.70001 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 21:18:03.571895 ops/training.py:65 2019-01-16 21:18:03.571812: step 6273, loss = 0.68629 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:18:04.467381 ops/training.py:65 2019-01-16 21:18:04.467301: step 6274, loss = 0.70027 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:18:05.362685 ops/training.py:65 2019-01-16 21:18:05.362603: step 6275, loss = 0.69110 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:18:06.257205 ops/training.py:65 2019-01-16 21:18:06.257118: step 6276, loss = 0.70079 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:18:07.154061 ops/training.py:65 2019-01-16 21:18:07.153981: step 6277, loss = 0.68978 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:18:08.051136 ops/training.py:65 2019-01-16 21:18:08.051053: step 6278, loss = 0.69416 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:18:08.947283 ops/training.py:65 2019-01-16 21:18:08.947226: step 6279, loss = 0.69668 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:18:09.841320 ops/training.py:65 2019-01-16 21:18:09.841259: step 6280, loss = 0.69530 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:18:10.737620 ops/training.py:65 2019-01-16 21:18:10.737552: step 6281, loss = 0.69234 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:18:11.633014 ops/training.py:65 2019-01-16 21:18:11.632928: step 6282, loss = 0.68531 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:18:12.526573 ops/training.py:65 2019-01-16 21:18:12.526489: step 6283, loss = 0.69075 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:18:13.420395 ops/training.py:65 2019-01-16 21:18:13.420333: step 6284, loss = 0.69248 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:18:14.314174 ops/training.py:65 2019-01-16 21:18:14.314118: step 6285, loss = 0.68859 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:18:15.206959 ops/training.py:65 2019-01-16 21:18:15.206909: step 6286, loss = 0.69398 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:18:16.100005 ops/training.py:65 2019-01-16 21:18:16.099936: step 6287, loss = 0.69480 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:18:16.993417 ops/training.py:65 2019-01-16 21:18:16.993361: step 6288, loss = 0.69178 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:18:17.887866 ops/training.py:65 2019-01-16 21:18:17.887808: step 6289, loss = 0.68806 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:18:18.784563 ops/training.py:65 2019-01-16 21:18:18.784481: step 6290, loss = 0.69515 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:18:19.681049 ops/training.py:65 2019-01-16 21:18:19.680967: step 6291, loss = 0.69574 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:18:20.577466 ops/training.py:65 2019-01-16 21:18:20.577380: step 6292, loss = 0.69421 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:18:21.473946 ops/training.py:65 2019-01-16 21:18:21.473866: step 6293, loss = 0.69284 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:18:22.369525 ops/training.py:65 2019-01-16 21:18:22.369450: step 6294, loss = 0.68435 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:18:23.266363 ops/training.py:65 2019-01-16 21:18:23.266255: step 6295, loss = 0.69284 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:18:24.162593 ops/training.py:65 2019-01-16 21:18:24.162511: step 6296, loss = 0.68801 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:18:25.056753 ops/training.py:65 2019-01-16 21:18:25.056697: step 6297, loss = 0.69738 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:18:25.949706 ops/training.py:65 2019-01-16 21:18:25.949656: step 6298, loss = 0.68763 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:18:26.844288 ops/training.py:65 2019-01-16 21:18:26.844238: step 6299, loss = 0.68466 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:18:27.740236 ops/training.py:65 2019-01-16 21:18:27.740187: step 6300, loss = 0.69189 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:18:28.635241 ops/training.py:65 2019-01-16 21:18:28.635189: step 6301, loss = 0.69815 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:18:29.529607 ops/training.py:65 2019-01-16 21:18:29.529560: step 6302, loss = 0.69455 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:18:30.425824 ops/training.py:65 2019-01-16 21:18:30.425744: step 6303, loss = 0.68961 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:18:31.320559 ops/training.py:65 2019-01-16 21:18:31.320510: step 6304, loss = 0.69464 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:18:32.213052 ops/training.py:65 2019-01-16 21:18:32.213005: step 6305, loss = 0.69470 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:18:33.106715 ops/training.py:65 2019-01-16 21:18:33.106665: step 6306, loss = 0.69184 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:18:33.998964 ops/training.py:65 2019-01-16 21:18:33.998914: step 6307, loss = 0.69127 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:18:34.895084 ops/training.py:65 2019-01-16 21:18:34.895011: step 6308, loss = 0.69034 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:18:35.792276 ops/training.py:65 2019-01-16 21:18:35.792195: step 6309, loss = 0.69629 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:18:36.687957 ops/training.py:65 2019-01-16 21:18:36.687879: step 6310, loss = 0.69710 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:18:37.583921 ops/training.py:65 2019-01-16 21:18:37.583856: step 6311, loss = 0.69289 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:18:38.479293 ops/training.py:65 2019-01-16 21:18:38.479208: step 6312, loss = 0.69284 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:18:39.375980 ops/training.py:65 2019-01-16 21:18:39.375896: step 6313, loss = 0.69297 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 21:18:40.270952 ops/training.py:65 2019-01-16 21:18:40.270901: step 6314, loss = 0.68700 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:18:41.164430 ops/training.py:65 2019-01-16 21:18:41.164364: step 6315, loss = 0.69069 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:18:42.058661 ops/training.py:65 2019-01-16 21:18:42.058584: step 6316, loss = 0.69032 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:18:42.952568 ops/training.py:65 2019-01-16 21:18:42.952489: step 6317, loss = 0.69298 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:18:43.846214 ops/training.py:65 2019-01-16 21:18:43.846156: step 6318, loss = 0.69317 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:18:44.739194 ops/training.py:65 2019-01-16 21:18:44.739137: step 6319, loss = 0.68440 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:18:45.632660 ops/training.py:65 2019-01-16 21:18:45.632602: step 6320, loss = 0.69937 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:18:46.525592 ops/training.py:65 2019-01-16 21:18:46.525539: step 6321, loss = 0.68834 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:18:47.417208 ops/training.py:65 2019-01-16 21:18:47.417154: step 6322, loss = 0.69806 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:18:48.309961 ops/training.py:65 2019-01-16 21:18:48.309909: step 6323, loss = 0.69485 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:18:49.201739 ops/training.py:65 2019-01-16 21:18:49.201688: step 6324, loss = 0.70238 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:18:50.093474 ops/training.py:65 2019-01-16 21:18:50.093417: step 6325, loss = 0.68965 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:18:50.986733 ops/training.py:65 2019-01-16 21:18:50.986678: step 6326, loss = 0.68499 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:18:51.880236 ops/training.py:65 2019-01-16 21:18:51.880177: step 6327, loss = 0.68872 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:18:52.773054 ops/training.py:65 2019-01-16 21:18:52.773001: step 6328, loss = 0.69980 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:18:53.665792 ops/training.py:65 2019-01-16 21:18:53.665736: step 6329, loss = 0.69418 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:18:54.560267 ops/training.py:65 2019-01-16 21:18:54.560223: step 6330, loss = 0.69450 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:18:55.455876 ops/training.py:65 2019-01-16 21:18:55.455794: step 6331, loss = 0.69638 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:18:56.351470 ops/training.py:65 2019-01-16 21:18:56.351387: step 6332, loss = 0.68883 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:18:57.245712 ops/training.py:65 2019-01-16 21:18:57.245628: step 6333, loss = 0.69197 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:18:58.140273 ops/training.py:65 2019-01-16 21:18:58.140192: step 6334, loss = 0.69737 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:18:59.035947 ops/training.py:65 2019-01-16 21:18:59.035857: step 6335, loss = 0.69858 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:18:59.931714 ops/training.py:65 2019-01-16 21:18:59.931629: step 6336, loss = 0.69229 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:19:00.827531 ops/training.py:65 2019-01-16 21:19:00.827481: step 6337, loss = 0.69829 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:19:01.722224 ops/training.py:65 2019-01-16 21:19:01.722163: step 6338, loss = 0.69471 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:19:02.618575 ops/training.py:65 2019-01-16 21:19:02.618495: step 6339, loss = 0.69017 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:19:03.514747 ops/training.py:65 2019-01-16 21:19:03.514663: step 6340, loss = 0.68888 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:19:04.410191 ops/training.py:65 2019-01-16 21:19:04.410111: step 6341, loss = 0.70583 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 21:19:05.304556 ops/training.py:65 2019-01-16 21:19:05.304505: step 6342, loss = 0.69686 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:19:06.197566 ops/training.py:65 2019-01-16 21:19:06.197516: step 6343, loss = 0.68574 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:19:07.090848 ops/training.py:65 2019-01-16 21:19:07.090794: step 6344, loss = 0.69087 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:19:07.984336 ops/training.py:65 2019-01-16 21:19:07.984285: step 6345, loss = 0.68766 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:19:08.878515 ops/training.py:65 2019-01-16 21:19:08.878425: step 6346, loss = 0.68723 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:19:09.775922 ops/training.py:65 2019-01-16 21:19:09.775871: step 6347, loss = 0.68807 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:19:10.671195 ops/training.py:65 2019-01-16 21:19:10.671111: step 6348, loss = 0.69165 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:19:11.566267 ops/training.py:65 2019-01-16 21:19:11.566199: step 6349, loss = 0.69170 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:19:12.459255 ops/training.py:65 2019-01-16 21:19:12.459173: step 6350, loss = 0.68758 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:19:13.355451 ops/training.py:65 2019-01-16 21:19:13.355372: step 6351, loss = 0.69476 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:19:14.250964 ops/training.py:65 2019-01-16 21:19:14.250881: step 6352, loss = 0.69317 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:19:15.145647 ops/training.py:65 2019-01-16 21:19:15.145566: step 6353, loss = 0.69977 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:19:16.040019 ops/training.py:65 2019-01-16 21:19:16.039955: step 6354, loss = 0.69794 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:19:16.932754 ops/training.py:65 2019-01-16 21:19:16.932703: step 6355, loss = 0.69380 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:19:17.824479 ops/training.py:65 2019-01-16 21:19:17.824427: step 6356, loss = 0.69231 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:19:18.718128 ops/training.py:65 2019-01-16 21:19:18.718075: step 6357, loss = 0.69360 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:19:19.611654 ops/training.py:65 2019-01-16 21:19:19.611604: step 6358, loss = 0.68715 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:19:20.508326 ops/training.py:65 2019-01-16 21:19:20.508244: step 6359, loss = 0.69959 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:19:21.403443 ops/training.py:65 2019-01-16 21:19:21.403390: step 6360, loss = 0.69524 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:19:22.296610 ops/training.py:65 2019-01-16 21:19:22.296560: step 6361, loss = 0.68526 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:19:23.188866 ops/training.py:65 2019-01-16 21:19:23.188818: step 6362, loss = 0.68819 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.75
I1280 2019-01-16 21:19:24.080662 ops/training.py:65 2019-01-16 21:19:24.080613: step 6363, loss = 0.69582 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:19:24.972793 ops/training.py:65 2019-01-16 21:19:24.972740: step 6364, loss = 0.69193 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:19:25.866012 ops/training.py:65 2019-01-16 21:19:25.865957: step 6365, loss = 0.69602 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:19:26.758428 ops/training.py:65 2019-01-16 21:19:26.758369: step 6366, loss = 0.69799 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:19:27.650831 ops/training.py:65 2019-01-16 21:19:27.650777: step 6367, loss = 0.68818 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:19:28.544609 ops/training.py:65 2019-01-16 21:19:28.544557: step 6368, loss = 0.68567 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:19:29.440039 ops/training.py:65 2019-01-16 21:19:29.439981: step 6369, loss = 0.68877 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:19:30.336831 ops/training.py:65 2019-01-16 21:19:30.336748: step 6370, loss = 0.69634 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:19:31.233989 ops/training.py:65 2019-01-16 21:19:31.233907: step 6371, loss = 0.68740 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:19:32.131083 ops/training.py:65 2019-01-16 21:19:32.131004: step 6372, loss = 0.69531 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:19:33.027434 ops/training.py:65 2019-01-16 21:19:33.027346: step 6373, loss = 0.69549 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:19:33.923525 ops/training.py:65 2019-01-16 21:19:33.923441: step 6374, loss = 0.69445 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:19:34.820265 ops/training.py:65 2019-01-16 21:19:34.820178: step 6375, loss = 0.69192 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:19:35.715176 ops/training.py:65 2019-01-16 21:19:35.715090: step 6376, loss = 0.68189 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.75
I1280 2019-01-16 21:19:36.610573 ops/training.py:65 2019-01-16 21:19:36.610523: step 6377, loss = 0.68808 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:19:37.504334 ops/training.py:65 2019-01-16 21:19:37.504281: step 6378, loss = 0.69380 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:19:38.398174 ops/training.py:65 2019-01-16 21:19:38.398121: step 6379, loss = 0.69197 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:19:39.290900 ops/training.py:65 2019-01-16 21:19:39.290846: step 6380, loss = 0.69208 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:19:40.184478 ops/training.py:65 2019-01-16 21:19:40.184424: step 6381, loss = 0.69439 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:19:41.079508 ops/training.py:65 2019-01-16 21:19:41.079448: step 6382, loss = 0.68728 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:19:41.975718 ops/training.py:65 2019-01-16 21:19:41.975640: step 6383, loss = 0.69691 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:19:42.870595 ops/training.py:65 2019-01-16 21:19:42.870514: step 6384, loss = 0.69416 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:19:43.765012 ops/training.py:65 2019-01-16 21:19:43.764956: step 6385, loss = 0.69100 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:19:44.659888 ops/training.py:65 2019-01-16 21:19:44.659823: step 6386, loss = 0.68398 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 21:19:45.555041 ops/training.py:65 2019-01-16 21:19:45.554961: step 6387, loss = 0.69501 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:19:46.449576 ops/training.py:65 2019-01-16 21:19:46.449496: step 6388, loss = 0.69285 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:19:47.345192 ops/training.py:65 2019-01-16 21:19:47.345111: step 6389, loss = 0.69189 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:19:48.241580 ops/training.py:65 2019-01-16 21:19:48.241531: step 6390, loss = 0.69776 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:19:49.137275 ops/training.py:65 2019-01-16 21:19:49.137237: step 6391, loss = 0.69032 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:19:50.031941 ops/training.py:65 2019-01-16 21:19:50.031860: step 6392, loss = 0.69268 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:19:50.926802 ops/training.py:65 2019-01-16 21:19:50.926718: step 6393, loss = 0.69499 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:19:51.822561 ops/training.py:65 2019-01-16 21:19:51.822475: step 6394, loss = 0.70197 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 21:19:52.718596 ops/training.py:65 2019-01-16 21:19:52.718509: step 6395, loss = 0.69726 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:19:53.615933 ops/training.py:65 2019-01-16 21:19:53.615847: step 6396, loss = 0.69200 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:19:54.511685 ops/training.py:65 2019-01-16 21:19:54.511600: step 6397, loss = 0.69917 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:19:55.407835 ops/training.py:65 2019-01-16 21:19:55.407777: step 6398, loss = 0.69867 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:19:56.302258 ops/training.py:65 2019-01-16 21:19:56.302203: step 6399, loss = 0.68669 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:19:57.197515 ops/training.py:65 2019-01-16 21:19:57.197460: step 6400, loss = 0.68908 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:19:58.091408 ops/training.py:65 2019-01-16 21:19:58.091353: step 6401, loss = 0.68928 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:19:58.984884 ops/training.py:65 2019-01-16 21:19:58.984830: step 6402, loss = 0.69627 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:19:59.879205 ops/training.py:65 2019-01-16 21:19:59.879142: step 6403, loss = 0.69133 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:20:00.772948 ops/training.py:65 2019-01-16 21:20:00.772894: step 6404, loss = 0.70340 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:20:01.665834 ops/training.py:65 2019-01-16 21:20:01.665773: step 6405, loss = 0.68958 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:20:02.558447 ops/training.py:65 2019-01-16 21:20:02.558366: step 6406, loss = 0.69349 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:20:03.452316 ops/training.py:65 2019-01-16 21:20:03.452261: step 6407, loss = 0.68764 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:20:04.345413 ops/training.py:65 2019-01-16 21:20:04.345358: step 6408, loss = 0.68941 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:20:05.237701 ops/training.py:65 2019-01-16 21:20:05.237649: step 6409, loss = 0.69280 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:20:06.130424 ops/training.py:65 2019-01-16 21:20:06.130363: step 6410, loss = 0.69903 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:20:07.024579 ops/training.py:65 2019-01-16 21:20:07.024525: step 6411, loss = 0.68360 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:20:07.919242 ops/training.py:65 2019-01-16 21:20:07.919186: step 6412, loss = 0.69284 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:20:08.815379 ops/training.py:65 2019-01-16 21:20:08.815321: step 6413, loss = 0.69084 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:20:09.709901 ops/training.py:65 2019-01-16 21:20:09.709851: step 6414, loss = 0.69569 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:20:10.602735 ops/training.py:65 2019-01-16 21:20:10.602685: step 6415, loss = 0.68862 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:20:11.496064 ops/training.py:65 2019-01-16 21:20:11.496008: step 6416, loss = 0.69357 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:20:12.392124 ops/training.py:65 2019-01-16 21:20:12.392042: step 6417, loss = 0.69337 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:20:13.287252 ops/training.py:65 2019-01-16 21:20:13.287172: step 6418, loss = 0.68771 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:20:14.181767 ops/training.py:65 2019-01-16 21:20:14.181710: step 6419, loss = 0.69007 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:20:15.074691 ops/training.py:65 2019-01-16 21:20:15.074641: step 6420, loss = 0.69368 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:20:15.966735 ops/training.py:65 2019-01-16 21:20:15.966682: step 6421, loss = 0.68692 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:20:16.859237 ops/training.py:65 2019-01-16 21:20:16.859182: step 6422, loss = 0.69026 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:20:17.751492 ops/training.py:65 2019-01-16 21:20:17.751441: step 6423, loss = 0.68530 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:20:18.645027 ops/training.py:65 2019-01-16 21:20:18.644977: step 6424, loss = 0.70213 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:20:19.538835 ops/training.py:65 2019-01-16 21:20:19.538783: step 6425, loss = 0.69512 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:20:20.430612 ops/training.py:65 2019-01-16 21:20:20.430565: step 6426, loss = 0.69071 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:20:21.322268 ops/training.py:65 2019-01-16 21:20:21.322216: step 6427, loss = 0.69879 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:20:22.215371 ops/training.py:65 2019-01-16 21:20:22.215322: step 6428, loss = 0.70680 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:20:23.109486 ops/training.py:65 2019-01-16 21:20:23.109452: step 6429, loss = 0.69910 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:20:24.007819 ops/training.py:65 2019-01-16 21:20:24.007773: step 6430, loss = 0.68518 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:20:24.904078 ops/training.py:65 2019-01-16 21:20:24.904050: step 6431, loss = 0.69226 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:20:25.799979 ops/training.py:65 2019-01-16 21:20:25.799902: step 6432, loss = 0.69619 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:20:26.694525 ops/training.py:65 2019-01-16 21:20:26.694487: step 6433, loss = 0.70514 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:20:27.592636 ops/training.py:65 2019-01-16 21:20:27.592582: step 6434, loss = 0.69270 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:20:28.488510 ops/training.py:65 2019-01-16 21:20:28.488474: step 6435, loss = 0.69703 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:20:29.385016 ops/training.py:65 2019-01-16 21:20:29.384985: step 6436, loss = 0.70103 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:20:30.280566 ops/training.py:65 2019-01-16 21:20:30.280536: step 6437, loss = 0.68864 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:20:31.175331 ops/training.py:65 2019-01-16 21:20:31.175297: step 6438, loss = 0.69917 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:20:32.070195 ops/training.py:65 2019-01-16 21:20:32.070156: step 6439, loss = 0.68506 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:20:32.965237 ops/training.py:65 2019-01-16 21:20:32.965205: step 6440, loss = 0.68633 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:20:33.861514 ops/training.py:65 2019-01-16 21:20:33.861483: step 6441, loss = 0.70113 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:20:34.757739 ops/training.py:65 2019-01-16 21:20:34.757710: step 6442, loss = 0.69419 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:20:35.654161 ops/training.py:65 2019-01-16 21:20:35.654131: step 6443, loss = 0.69730 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:20:36.550061 ops/training.py:65 2019-01-16 21:20:36.550030: step 6444, loss = 0.69021 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:20:37.444828 ops/training.py:65 2019-01-16 21:20:37.444797: step 6445, loss = 0.68605 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:20:38.339485 ops/training.py:65 2019-01-16 21:20:38.339455: step 6446, loss = 0.68809 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:20:39.236523 ops/training.py:65 2019-01-16 21:20:39.236494: step 6447, loss = 0.68663 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:20:40.132594 ops/training.py:65 2019-01-16 21:20:40.132561: step 6448, loss = 0.71031 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:20:41.028370 ops/training.py:65 2019-01-16 21:20:41.028338: step 6449, loss = 0.69811 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:20:41.923682 ops/training.py:65 2019-01-16 21:20:41.923605: step 6450, loss = 0.68722 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:20:42.817473 ops/training.py:65 2019-01-16 21:20:42.817370: step 6451, loss = 0.68444 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:20:43.712899 ops/training.py:65 2019-01-16 21:20:43.712791: step 6452, loss = 0.69679 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:20:44.608609 ops/training.py:65 2019-01-16 21:20:44.608526: step 6453, loss = 0.69834 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:20:45.503404 ops/training.py:65 2019-01-16 21:20:45.503316: step 6454, loss = 0.69145 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:20:46.397476 ops/training.py:65 2019-01-16 21:20:46.397421: step 6455, loss = 0.69646 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:20:47.291932 ops/training.py:65 2019-01-16 21:20:47.291855: step 6456, loss = 0.68493 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:20:48.187996 ops/training.py:65 2019-01-16 21:20:48.187904: step 6457, loss = 0.70473 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:20:49.084456 ops/training.py:65 2019-01-16 21:20:49.084364: step 6458, loss = 0.70237 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:20:49.979470 ops/training.py:65 2019-01-16 21:20:49.979409: step 6459, loss = 0.69054 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:20:50.873103 ops/training.py:65 2019-01-16 21:20:50.873040: step 6460, loss = 0.69097 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:20:51.765277 ops/training.py:65 2019-01-16 21:20:51.765218: step 6461, loss = 0.69228 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:20:52.658117 ops/training.py:65 2019-01-16 21:20:52.658059: step 6462, loss = 0.68795 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:20:53.550737 ops/training.py:65 2019-01-16 21:20:53.550682: step 6463, loss = 0.69157 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:20:54.445505 ops/training.py:65 2019-01-16 21:20:54.445446: step 6464, loss = 0.69453 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:20:55.341756 ops/training.py:65 2019-01-16 21:20:55.341718: step 6465, loss = 0.69195 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:20:56.236852 ops/training.py:65 2019-01-16 21:20:56.236805: step 6466, loss = 0.69860 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:20:57.135406 ops/training.py:65 2019-01-16 21:20:57.135350: step 6467, loss = 0.69671 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:20:58.031257 ops/training.py:65 2019-01-16 21:20:58.031184: step 6468, loss = 0.68820 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:20:58.926177 ops/training.py:65 2019-01-16 21:20:58.926134: step 6469, loss = 0.68900 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:20:59.820936 ops/training.py:65 2019-01-16 21:20:59.820873: step 6470, loss = 0.68923 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:21:00.714988 ops/training.py:65 2019-01-16 21:21:00.714934: step 6471, loss = 0.68422 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:21:01.608664 ops/training.py:65 2019-01-16 21:21:01.608608: step 6472, loss = 0.69539 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:21:02.502527 ops/training.py:65 2019-01-16 21:21:02.502480: step 6473, loss = 0.69402 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:21:03.397609 ops/training.py:65 2019-01-16 21:21:03.397561: step 6474, loss = 0.69241 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:21:04.294872 ops/training.py:65 2019-01-16 21:21:04.294839: step 6475, loss = 0.68522 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:21:05.190499 ops/training.py:65 2019-01-16 21:21:05.190469: step 6476, loss = 0.69102 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:21:06.084556 ops/training.py:65 2019-01-16 21:21:06.084496: step 6477, loss = 0.68955 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:21:06.980054 ops/training.py:65 2019-01-16 21:21:06.979950: step 6478, loss = 0.68061 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:21:07.875420 ops/training.py:65 2019-01-16 21:21:07.875311: step 6479, loss = 0.70196 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:21:08.771443 ops/training.py:65 2019-01-16 21:21:08.771341: step 6480, loss = 0.69409 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:21:09.667310 ops/training.py:65 2019-01-16 21:21:09.667234: step 6481, loss = 0.70260 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:21:10.566406 ops/training.py:65 2019-01-16 21:21:10.566326: step 6482, loss = 0.69126 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:21:11.461337 ops/training.py:65 2019-01-16 21:21:11.461254: step 6483, loss = 0.68447 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:21:12.355894 ops/training.py:65 2019-01-16 21:21:12.355793: step 6484, loss = 0.68860 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:21:13.250881 ops/training.py:65 2019-01-16 21:21:13.250814: step 6485, loss = 0.70108 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:21:14.145304 ops/training.py:65 2019-01-16 21:21:14.145242: step 6486, loss = 0.69669 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:21:15.038974 ops/training.py:65 2019-01-16 21:21:15.038917: step 6487, loss = 0.70035 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:21:15.933258 ops/training.py:65 2019-01-16 21:21:15.933157: step 6488, loss = 0.69149 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:21:16.827906 ops/training.py:65 2019-01-16 21:21:16.827842: step 6489, loss = 0.69649 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:21:17.721033 ops/training.py:65 2019-01-16 21:21:17.720971: step 6490, loss = 0.69291 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:21:18.615430 ops/training.py:65 2019-01-16 21:21:18.615371: step 6491, loss = 0.69992 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:21:19.509189 ops/training.py:65 2019-01-16 21:21:19.509125: step 6492, loss = 0.69016 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:21:20.403750 ops/training.py:65 2019-01-16 21:21:20.403687: step 6493, loss = 0.69785 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:21:21.298572 ops/training.py:65 2019-01-16 21:21:21.298487: step 6494, loss = 0.69888 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:21:22.194043 ops/training.py:65 2019-01-16 21:21:22.193979: step 6495, loss = 0.68693 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:21:23.088268 ops/training.py:65 2019-01-16 21:21:23.088205: step 6496, loss = 0.68829 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:21:23.982932 ops/training.py:65 2019-01-16 21:21:23.982872: step 6497, loss = 0.69888 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:21:24.875941 ops/training.py:65 2019-01-16 21:21:24.875881: step 6498, loss = 0.69261 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:21:25.770103 ops/training.py:65 2019-01-16 21:21:25.770043: step 6499, loss = 0.69692 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:21:26.664032 ops/training.py:65 2019-01-16 21:21:26.663971: step 6500, loss = 0.69210 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:21:27.557096 ops/training.py:65 2019-01-16 21:21:27.557040: step 6501, loss = 0.69133 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:21:28.451726 ops/training.py:65 2019-01-16 21:21:28.451667: step 6502, loss = 0.69336 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:21:29.345702 ops/training.py:65 2019-01-16 21:21:29.345632: step 6503, loss = 0.69231 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:21:30.240235 ops/training.py:65 2019-01-16 21:21:30.240139: step 6504, loss = 0.69548 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:21:31.137015 ops/training.py:65 2019-01-16 21:21:31.136916: step 6505, loss = 0.69416 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:21:32.032805 ops/training.py:65 2019-01-16 21:21:32.032709: step 6506, loss = 0.69235 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:21:32.927336 ops/training.py:65 2019-01-16 21:21:32.927278: step 6507, loss = 0.69530 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:21:33.820136 ops/training.py:65 2019-01-16 21:21:33.820071: step 6508, loss = 0.68315 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 21:21:34.714407 ops/training.py:65 2019-01-16 21:21:34.714338: step 6509, loss = 0.69043 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:21:35.608779 ops/training.py:65 2019-01-16 21:21:35.608711: step 6510, loss = 0.68823 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:21:36.502269 ops/training.py:65 2019-01-16 21:21:36.502211: step 6511, loss = 0.69751 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:21:37.395681 ops/training.py:65 2019-01-16 21:21:37.395622: step 6512, loss = 0.69400 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:21:38.290471 ops/training.py:65 2019-01-16 21:21:38.290403: step 6513, loss = 0.69509 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:21:39.185108 ops/training.py:65 2019-01-16 21:21:39.185045: step 6514, loss = 0.69115 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:21:40.078296 ops/training.py:65 2019-01-16 21:21:40.078235: step 6515, loss = 0.70033 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:21:40.971731 ops/training.py:65 2019-01-16 21:21:40.971655: step 6516, loss = 0.69049 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:21:41.865673 ops/training.py:65 2019-01-16 21:21:41.865587: step 6517, loss = 0.69853 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:21:42.759336 ops/training.py:65 2019-01-16 21:21:42.759250: step 6518, loss = 0.68737 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:21:43.653450 ops/training.py:65 2019-01-16 21:21:43.653383: step 6519, loss = 0.69697 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:21:44.547142 ops/training.py:65 2019-01-16 21:21:44.547079: step 6520, loss = 0.69106 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:21:45.440845 ops/training.py:65 2019-01-16 21:21:45.440781: step 6521, loss = 0.68888 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:21:46.335048 ops/training.py:65 2019-01-16 21:21:46.334989: step 6522, loss = 0.69428 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:21:47.230721 ops/training.py:65 2019-01-16 21:21:47.230652: step 6523, loss = 0.69484 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:21:48.126425 ops/training.py:65 2019-01-16 21:21:48.126358: step 6524, loss = 0.69547 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:21:49.019996 ops/training.py:65 2019-01-16 21:21:49.019934: step 6525, loss = 0.69187 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:21:49.913482 ops/training.py:65 2019-01-16 21:21:49.913418: step 6526, loss = 0.68854 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:21:50.808140 ops/training.py:65 2019-01-16 21:21:50.808073: step 6527, loss = 0.69844 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:21:51.701615 ops/training.py:65 2019-01-16 21:21:51.701555: step 6528, loss = 0.69161 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:21:52.594742 ops/training.py:65 2019-01-16 21:21:52.594686: step 6529, loss = 0.70328 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:21:53.487467 ops/training.py:65 2019-01-16 21:21:53.487406: step 6530, loss = 0.69573 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:21:54.380124 ops/training.py:65 2019-01-16 21:21:54.380066: step 6531, loss = 0.68600 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:21:55.274480 ops/training.py:65 2019-01-16 21:21:55.274425: step 6532, loss = 0.69648 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:21:56.170212 ops/training.py:65 2019-01-16 21:21:56.170113: step 6533, loss = 0.67949 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:21:57.064314 ops/training.py:65 2019-01-16 21:21:57.064247: step 6534, loss = 0.69074 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:21:57.957506 ops/training.py:65 2019-01-16 21:21:57.957440: step 6535, loss = 0.69485 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:21:58.851623 ops/training.py:65 2019-01-16 21:21:58.851554: step 6536, loss = 0.70671 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:21:59.745422 ops/training.py:65 2019-01-16 21:21:59.745359: step 6537, loss = 0.70302 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:22:00.638282 ops/training.py:65 2019-01-16 21:22:00.638221: step 6538, loss = 0.69421 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:22:01.530793 ops/training.py:65 2019-01-16 21:22:01.530734: step 6539, loss = 0.69360 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:22:02.423213 ops/training.py:65 2019-01-16 21:22:02.423155: step 6540, loss = 0.70060 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:22:03.317952 ops/training.py:65 2019-01-16 21:22:03.317885: step 6541, loss = 0.68922 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:22:04.212219 ops/training.py:65 2019-01-16 21:22:04.212157: step 6542, loss = 0.69188 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:22:05.106367 ops/training.py:65 2019-01-16 21:22:05.106304: step 6543, loss = 0.70236 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:22:05.999581 ops/training.py:65 2019-01-16 21:22:05.999515: step 6544, loss = 0.68609 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:22:06.893786 ops/training.py:65 2019-01-16 21:22:06.893724: step 6545, loss = 0.69096 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:22:07.788293 ops/training.py:65 2019-01-16 21:22:07.788229: step 6546, loss = 0.68419 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:22:08.682520 ops/training.py:65 2019-01-16 21:22:08.682455: step 6547, loss = 0.70079 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:22:09.577353 ops/training.py:65 2019-01-16 21:22:09.577288: step 6548, loss = 0.70141 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:22:10.472068 ops/training.py:65 2019-01-16 21:22:10.472016: step 6549, loss = 0.69416 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:22:11.366091 ops/training.py:65 2019-01-16 21:22:11.366019: step 6550, loss = 0.68393 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:22:12.259608 ops/training.py:65 2019-01-16 21:22:12.259544: step 6551, loss = 0.70210 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:22:13.153209 ops/training.py:65 2019-01-16 21:22:13.153109: step 6552, loss = 0.68898 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:22:14.046469 ops/training.py:65 2019-01-16 21:22:14.046406: step 6553, loss = 0.69313 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:22:14.938820 ops/training.py:65 2019-01-16 21:22:14.938757: step 6554, loss = 0.69143 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:22:15.831473 ops/training.py:65 2019-01-16 21:22:15.831415: step 6555, loss = 0.67868 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 21:22:16.723182 ops/training.py:65 2019-01-16 21:22:16.723118: step 6556, loss = 0.69290 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:22:17.616225 ops/training.py:65 2019-01-16 21:22:17.616163: step 6557, loss = 0.68939 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:22:18.508883 ops/training.py:65 2019-01-16 21:22:18.508818: step 6558, loss = 0.68706 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:22:19.402882 ops/training.py:65 2019-01-16 21:22:19.402801: step 6559, loss = 0.69905 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:22:20.297357 ops/training.py:65 2019-01-16 21:22:20.297298: step 6560, loss = 0.69075 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:22:21.192585 ops/training.py:65 2019-01-16 21:22:21.192520: step 6561, loss = 0.69641 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:22:22.086901 ops/training.py:65 2019-01-16 21:22:22.086843: step 6562, loss = 0.68806 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:22:22.980952 ops/training.py:65 2019-01-16 21:22:22.980892: step 6563, loss = 0.68500 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:22:23.874060 ops/training.py:65 2019-01-16 21:22:23.873999: step 6564, loss = 0.70645 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:22:24.768122 ops/training.py:65 2019-01-16 21:22:24.768056: step 6565, loss = 0.68608 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:22:25.661261 ops/training.py:65 2019-01-16 21:22:25.661200: step 6566, loss = 0.70598 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:22:26.555514 ops/training.py:65 2019-01-16 21:22:26.555455: step 6567, loss = 0.69105 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:22:27.450972 ops/training.py:65 2019-01-16 21:22:27.450888: step 6568, loss = 0.69185 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:22:28.345447 ops/training.py:65 2019-01-16 21:22:28.345363: step 6569, loss = 0.68555 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:22:29.238708 ops/training.py:65 2019-01-16 21:22:29.238630: step 6570, loss = 0.67829 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:22:30.133036 ops/training.py:65 2019-01-16 21:22:30.132940: step 6571, loss = 0.67353 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:22:31.028087 ops/training.py:65 2019-01-16 21:22:31.028006: step 6572, loss = 0.70952 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:22:31.923894 ops/training.py:65 2019-01-16 21:22:31.923796: step 6573, loss = 0.67017 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 21:22:32.818467 ops/training.py:65 2019-01-16 21:22:32.818413: step 6574, loss = 0.70022 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:22:33.711479 ops/training.py:65 2019-01-16 21:22:33.711418: step 6575, loss = 0.69281 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:22:34.604068 ops/training.py:65 2019-01-16 21:22:34.604009: step 6576, loss = 0.70192 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:22:35.497380 ops/training.py:65 2019-01-16 21:22:35.497317: step 6577, loss = 0.69524 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:22:36.391837 ops/training.py:65 2019-01-16 21:22:36.391778: step 6578, loss = 0.68175 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:22:37.285479 ops/training.py:65 2019-01-16 21:22:37.285425: step 6579, loss = 0.70408 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:22:38.180207 ops/training.py:65 2019-01-16 21:22:38.180146: step 6580, loss = 0.70729 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:22:39.072951 ops/training.py:65 2019-01-16 21:22:39.072895: step 6581, loss = 0.70719 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:22:39.967480 ops/training.py:65 2019-01-16 21:22:39.967441: step 6582, loss = 0.69925 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:22:40.860455 ops/training.py:65 2019-01-16 21:22:40.860403: step 6583, loss = 0.71499 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:22:41.753179 ops/training.py:65 2019-01-16 21:22:41.753109: step 6584, loss = 0.69147 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:22:42.646503 ops/training.py:65 2019-01-16 21:22:42.646445: step 6585, loss = 0.68959 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:22:43.539776 ops/training.py:65 2019-01-16 21:22:43.539718: step 6586, loss = 0.69681 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:22:44.431854 ops/training.py:65 2019-01-16 21:22:44.431798: step 6587, loss = 0.69322 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:22:45.324614 ops/training.py:65 2019-01-16 21:22:45.324576: step 6588, loss = 0.70718 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:22:46.218346 ops/training.py:65 2019-01-16 21:22:46.218286: step 6589, loss = 0.69332 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:22:47.112130 ops/training.py:65 2019-01-16 21:22:47.112078: step 6590, loss = 0.69195 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:22:48.005302 ops/training.py:65 2019-01-16 21:22:48.005241: step 6591, loss = 0.66793 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.75
I1280 2019-01-16 21:22:48.899330 ops/training.py:65 2019-01-16 21:22:48.899283: step 6592, loss = 0.67705 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:22:49.793378 ops/training.py:65 2019-01-16 21:22:49.793339: step 6593, loss = 0.70285 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:22:50.685730 ops/training.py:65 2019-01-16 21:22:50.685677: step 6594, loss = 0.69524 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:22:51.580561 ops/training.py:65 2019-01-16 21:22:51.580524: step 6595, loss = 0.68929 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:22:52.473501 ops/training.py:65 2019-01-16 21:22:52.473446: step 6596, loss = 0.70379 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:22:53.366339 ops/training.py:65 2019-01-16 21:22:53.366282: step 6597, loss = 0.68878 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:22:54.259177 ops/training.py:65 2019-01-16 21:22:54.259120: step 6598, loss = 0.69826 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:22:55.152796 ops/training.py:65 2019-01-16 21:22:55.152739: step 6599, loss = 0.70529 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:22:56.045090 ops/training.py:65 2019-01-16 21:22:56.045026: step 6600, loss = 0.68852 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:22:56.937940 ops/training.py:65 2019-01-16 21:22:56.937875: step 6601, loss = 0.70289 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:22:57.830721 ops/training.py:65 2019-01-16 21:22:57.830659: step 6602, loss = 0.69210 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:22:58.724640 ops/training.py:65 2019-01-16 21:22:58.724583: step 6603, loss = 0.68983 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:22:59.618942 ops/training.py:65 2019-01-16 21:22:59.618878: step 6604, loss = 0.69223 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:23:00.512845 ops/training.py:65 2019-01-16 21:23:00.512781: step 6605, loss = 0.70822 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:23:01.406504 ops/training.py:65 2019-01-16 21:23:01.406451: step 6606, loss = 0.69813 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:23:02.301036 ops/training.py:65 2019-01-16 21:23:02.300977: step 6607, loss = 0.68696 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:23:03.198190 ops/training.py:65 2019-01-16 21:23:03.198090: step 6608, loss = 0.69642 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:23:04.094035 ops/training.py:65 2019-01-16 21:23:04.093935: step 6609, loss = 0.69234 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:23:04.990200 ops/training.py:65 2019-01-16 21:23:04.990133: step 6610, loss = 0.67815 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:23:05.885270 ops/training.py:65 2019-01-16 21:23:05.885167: step 6611, loss = 0.69289 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:23:06.780445 ops/training.py:65 2019-01-16 21:23:06.780342: step 6612, loss = 0.70292 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:23:07.675244 ops/training.py:65 2019-01-16 21:23:07.675148: step 6613, loss = 0.69298 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:23:08.571823 ops/training.py:65 2019-01-16 21:23:08.571725: step 6614, loss = 0.68237 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:23:09.467702 ops/training.py:65 2019-01-16 21:23:09.467640: step 6615, loss = 0.69231 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:23:10.381595 ops/training.py:65 2019-01-16 21:23:10.381495: step 6616, loss = 0.70724 (35.1 examples/sec; 0.913 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:23:11.277880 ops/training.py:65 2019-01-16 21:23:11.277800: step 6617, loss = 0.68789 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:23:12.172522 ops/training.py:65 2019-01-16 21:23:12.172433: step 6618, loss = 0.67837 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:23:13.067065 ops/training.py:65 2019-01-16 21:23:13.066963: step 6619, loss = 0.68524 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:23:13.961139 ops/training.py:65 2019-01-16 21:23:13.961074: step 6620, loss = 0.68358 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:23:14.854983 ops/training.py:65 2019-01-16 21:23:14.854920: step 6621, loss = 0.68927 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:23:15.748749 ops/training.py:65 2019-01-16 21:23:15.748689: step 6622, loss = 0.66905 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.75
I1280 2019-01-16 21:23:16.642182 ops/training.py:65 2019-01-16 21:23:16.642119: step 6623, loss = 0.69144 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:23:17.535307 ops/training.py:65 2019-01-16 21:23:17.535249: step 6624, loss = 0.67653 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:23:18.428241 ops/training.py:65 2019-01-16 21:23:18.428182: step 6625, loss = 0.68961 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:23:19.322330 ops/training.py:65 2019-01-16 21:23:19.322271: step 6626, loss = 0.67924 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:23:20.215235 ops/training.py:65 2019-01-16 21:23:20.215174: step 6627, loss = 0.68237 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:23:21.109188 ops/training.py:65 2019-01-16 21:23:21.109124: step 6628, loss = 0.68682 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:23:22.007002 ops/training.py:65 2019-01-16 21:23:22.006901: step 6629, loss = 0.71564 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:23:22.902692 ops/training.py:65 2019-01-16 21:23:22.902594: step 6630, loss = 0.70356 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:23:23.799498 ops/training.py:65 2019-01-16 21:23:23.799397: step 6631, loss = 0.68227 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:23:24.694619 ops/training.py:65 2019-01-16 21:23:24.694557: step 6632, loss = 0.69696 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:23:25.587243 ops/training.py:65 2019-01-16 21:23:25.587189: step 6633, loss = 0.69231 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:23:26.480392 ops/training.py:65 2019-01-16 21:23:26.480335: step 6634, loss = 0.69916 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:23:27.372993 ops/training.py:65 2019-01-16 21:23:27.372939: step 6635, loss = 0.70499 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:23:28.264844 ops/training.py:65 2019-01-16 21:23:28.264786: step 6636, loss = 0.69654 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:23:29.156498 ops/training.py:65 2019-01-16 21:23:29.156442: step 6637, loss = 0.70357 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:23:30.049921 ops/training.py:65 2019-01-16 21:23:30.049872: step 6638, loss = 0.70639 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:23:30.949560 ops/training.py:65 2019-01-16 21:23:30.949529: step 6639, loss = 0.69886 (35.6 examples/sec; 0.899 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:23:31.844834 ops/training.py:65 2019-01-16 21:23:31.844801: step 6640, loss = 0.69293 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:23:32.739431 ops/training.py:65 2019-01-16 21:23:32.739400: step 6641, loss = 0.69285 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:23:33.633161 ops/training.py:65 2019-01-16 21:23:33.633057: step 6642, loss = 0.69857 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:23:34.530604 ops/training.py:65 2019-01-16 21:23:34.530506: step 6643, loss = 0.69841 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:23:35.424410 ops/training.py:65 2019-01-16 21:23:35.424338: step 6644, loss = 0.69665 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:23:36.319016 ops/training.py:65 2019-01-16 21:23:36.318919: step 6645, loss = 0.68450 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:23:37.213139 ops/training.py:65 2019-01-16 21:23:37.213052: step 6646, loss = 0.69178 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:23:38.107259 ops/training.py:65 2019-01-16 21:23:38.107201: step 6647, loss = 0.70076 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:23:39.000148 ops/training.py:65 2019-01-16 21:23:39.000080: step 6648, loss = 0.67876 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:23:39.894987 ops/training.py:65 2019-01-16 21:23:39.894911: step 6649, loss = 0.69280 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:23:40.789907 ops/training.py:65 2019-01-16 21:23:40.789861: step 6650, loss = 0.69108 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:23:41.683099 ops/training.py:65 2019-01-16 21:23:41.683022: step 6651, loss = 0.69389 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:23:42.575944 ops/training.py:65 2019-01-16 21:23:42.575875: step 6652, loss = 0.69825 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:23:43.470167 ops/training.py:65 2019-01-16 21:23:43.470066: step 6653, loss = 0.71010 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.25
I1280 2019-01-16 21:23:44.363199 ops/training.py:65 2019-01-16 21:23:44.363099: step 6654, loss = 0.68431 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:23:45.256306 ops/training.py:65 2019-01-16 21:23:45.256207: step 6655, loss = 0.69582 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:23:46.150223 ops/training.py:65 2019-01-16 21:23:46.150121: step 6656, loss = 0.69754 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:23:47.044312 ops/training.py:65 2019-01-16 21:23:47.044237: step 6657, loss = 0.69037 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:23:47.938139 ops/training.py:65 2019-01-16 21:23:47.938035: step 6658, loss = 0.68529 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:23:48.833251 ops/training.py:65 2019-01-16 21:23:48.833150: step 6659, loss = 0.69795 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 21:23:49.730991 ops/training.py:65 2019-01-16 21:23:49.730904: step 6660, loss = 0.70073 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:23:50.625329 ops/training.py:65 2019-01-16 21:23:50.625240: step 6661, loss = 0.69599 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:23:51.520041 ops/training.py:65 2019-01-16 21:23:51.519939: step 6662, loss = 0.68950 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:23:52.414086 ops/training.py:65 2019-01-16 21:23:52.413993: step 6663, loss = 0.68881 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:23:53.308828 ops/training.py:65 2019-01-16 21:23:53.308731: step 6664, loss = 0.68592 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:23:54.203112 ops/training.py:65 2019-01-16 21:23:54.203008: step 6665, loss = 0.69565 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:23:55.097269 ops/training.py:65 2019-01-16 21:23:55.097167: step 6666, loss = 0.69326 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:23:55.991585 ops/training.py:65 2019-01-16 21:23:55.991479: step 6667, loss = 0.69465 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:23:56.885797 ops/training.py:65 2019-01-16 21:23:56.885696: step 6668, loss = 0.70152 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:23:57.779632 ops/training.py:65 2019-01-16 21:23:57.779531: step 6669, loss = 0.69133 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:23:58.673115 ops/training.py:65 2019-01-16 21:23:58.673015: step 6670, loss = 0.69487 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:23:59.566868 ops/training.py:65 2019-01-16 21:23:59.566800: step 6671, loss = 0.69050 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:24:00.460300 ops/training.py:65 2019-01-16 21:24:00.460199: step 6672, loss = 0.69745 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:24:01.355123 ops/training.py:65 2019-01-16 21:24:01.355031: step 6673, loss = 0.69839 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:24:02.250381 ops/training.py:65 2019-01-16 21:24:02.250291: step 6674, loss = 0.70009 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.25
I1280 2019-01-16 21:24:03.144590 ops/training.py:65 2019-01-16 21:24:03.144487: step 6675, loss = 0.68612 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:24:04.039155 ops/training.py:65 2019-01-16 21:24:04.039048: step 6676, loss = 0.69474 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:24:04.934570 ops/training.py:65 2019-01-16 21:24:04.934475: step 6677, loss = 0.69049 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:24:05.828816 ops/training.py:65 2019-01-16 21:24:05.828714: step 6678, loss = 0.70043 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:24:06.722636 ops/training.py:65 2019-01-16 21:24:06.722541: step 6679, loss = 0.68665 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:24:07.616431 ops/training.py:65 2019-01-16 21:24:07.616333: step 6680, loss = 0.68889 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:24:08.510302 ops/training.py:65 2019-01-16 21:24:08.510215: step 6681, loss = 0.69232 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:24:09.405123 ops/training.py:65 2019-01-16 21:24:09.405056: step 6682, loss = 0.69586 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:24:10.298073 ops/training.py:65 2019-01-16 21:24:10.297975: step 6683, loss = 0.69091 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:24:11.191980 ops/training.py:65 2019-01-16 21:24:11.191901: step 6684, loss = 0.69165 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:24:12.085625 ops/training.py:65 2019-01-16 21:24:12.085528: step 6685, loss = 0.69019 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:24:12.979779 ops/training.py:65 2019-01-16 21:24:12.979686: step 6686, loss = 0.69243 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:24:13.874975 ops/training.py:65 2019-01-16 21:24:13.874877: step 6687, loss = 0.69330 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:24:14.769532 ops/training.py:65 2019-01-16 21:24:14.769432: step 6688, loss = 0.70003 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:24:15.662920 ops/training.py:65 2019-01-16 21:24:15.662844: step 6689, loss = 0.69117 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:24:16.557487 ops/training.py:65 2019-01-16 21:24:16.557408: step 6690, loss = 0.69316 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:24:17.452275 ops/training.py:65 2019-01-16 21:24:17.452173: step 6691, loss = 0.69770 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:24:18.346423 ops/training.py:65 2019-01-16 21:24:18.346289: step 6692, loss = 0.69403 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:24:19.241400 ops/training.py:65 2019-01-16 21:24:19.241298: step 6693, loss = 0.70228 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:24:20.136209 ops/training.py:65 2019-01-16 21:24:20.136110: step 6694, loss = 0.69197 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:24:21.033391 ops/training.py:65 2019-01-16 21:24:21.033292: step 6695, loss = 0.68950 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:24:21.928073 ops/training.py:65 2019-01-16 21:24:21.927976: step 6696, loss = 0.69442 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:24:22.825402 ops/training.py:65 2019-01-16 21:24:22.825304: step 6697, loss = 0.69522 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:24:23.720323 ops/training.py:65 2019-01-16 21:24:23.720223: step 6698, loss = 0.69802 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:24:24.614076 ops/training.py:65 2019-01-16 21:24:24.614010: step 6699, loss = 0.68864 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:24:25.507618 ops/training.py:65 2019-01-16 21:24:25.507562: step 6700, loss = 0.69019 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:24:26.401376 ops/training.py:65 2019-01-16 21:24:26.401278: step 6701, loss = 0.68736 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:24:27.296008 ops/training.py:65 2019-01-16 21:24:27.295907: step 6702, loss = 0.69599 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:24:28.192586 ops/training.py:65 2019-01-16 21:24:28.192487: step 6703, loss = 0.69345 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:24:29.086642 ops/training.py:65 2019-01-16 21:24:29.086544: step 6704, loss = 0.68647 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:24:29.979646 ops/training.py:65 2019-01-16 21:24:29.979553: step 6705, loss = 0.69322 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:24:30.874572 ops/training.py:65 2019-01-16 21:24:30.874468: step 6706, loss = 0.69413 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:24:31.769865 ops/training.py:65 2019-01-16 21:24:31.769721: step 6707, loss = 0.69419 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:24:32.664219 ops/training.py:65 2019-01-16 21:24:32.664128: step 6708, loss = 0.68191 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:24:33.559031 ops/training.py:65 2019-01-16 21:24:33.558929: step 6709, loss = 0.69257 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:24:34.454936 ops/training.py:65 2019-01-16 21:24:34.454838: step 6710, loss = 0.69011 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:24:35.347909 ops/training.py:65 2019-01-16 21:24:35.347806: step 6711, loss = 0.69569 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:24:36.240656 ops/training.py:65 2019-01-16 21:24:36.240554: step 6712, loss = 0.70153 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:24:37.135251 ops/training.py:65 2019-01-16 21:24:37.135148: step 6713, loss = 0.68843 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:24:38.030266 ops/training.py:65 2019-01-16 21:24:38.030163: step 6714, loss = 0.71386 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 21:24:38.926681 ops/training.py:65 2019-01-16 21:24:38.926581: step 6715, loss = 0.68941 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:24:39.823224 ops/training.py:65 2019-01-16 21:24:39.823120: step 6716, loss = 0.69274 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:24:40.718136 ops/training.py:65 2019-01-16 21:24:40.718049: step 6717, loss = 0.69439 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:24:41.613142 ops/training.py:65 2019-01-16 21:24:41.613066: step 6718, loss = 0.68940 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:24:42.506331 ops/training.py:65 2019-01-16 21:24:42.506238: step 6719, loss = 0.69168 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:24:43.400008 ops/training.py:65 2019-01-16 21:24:43.399897: step 6720, loss = 0.69300 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:24:44.295915 ops/training.py:65 2019-01-16 21:24:44.295813: step 6721, loss = 0.68903 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:24:45.191280 ops/training.py:65 2019-01-16 21:24:45.191165: step 6722, loss = 0.69387 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:24:46.086543 ops/training.py:65 2019-01-16 21:24:46.086448: step 6723, loss = 0.69688 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:24:46.981988 ops/training.py:65 2019-01-16 21:24:46.981906: step 6724, loss = 0.69433 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:24:47.878271 ops/training.py:65 2019-01-16 21:24:47.878142: step 6725, loss = 0.69240 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:24:48.777577 ops/training.py:65 2019-01-16 21:24:48.777434: step 6726, loss = 0.69501 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:24:49.674610 ops/training.py:65 2019-01-16 21:24:49.674504: step 6727, loss = 0.69986 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:24:50.572626 ops/training.py:65 2019-01-16 21:24:50.572531: step 6728, loss = 0.69165 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:24:51.467125 ops/training.py:65 2019-01-16 21:24:51.467023: step 6729, loss = 0.69607 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:24:52.362102 ops/training.py:65 2019-01-16 21:24:52.361996: step 6730, loss = 0.69259 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:24:53.257575 ops/training.py:65 2019-01-16 21:24:53.257481: step 6731, loss = 0.69531 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:24:54.153258 ops/training.py:65 2019-01-16 21:24:54.153165: step 6732, loss = 0.69444 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:24:55.047223 ops/training.py:65 2019-01-16 21:24:55.047138: step 6733, loss = 0.69392 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:24:55.940941 ops/training.py:65 2019-01-16 21:24:55.940857: step 6734, loss = 0.69275 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:24:56.837439 ops/training.py:65 2019-01-16 21:24:56.837339: step 6735, loss = 0.69103 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:24:57.730868 ops/training.py:65 2019-01-16 21:24:57.730773: step 6736, loss = 0.68929 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:24:58.624542 ops/training.py:65 2019-01-16 21:24:58.624445: step 6737, loss = 0.69367 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:24:59.517837 ops/training.py:65 2019-01-16 21:24:59.517742: step 6738, loss = 0.69179 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:25:00.412411 ops/training.py:65 2019-01-16 21:25:00.412315: step 6739, loss = 0.69560 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:25:01.310833 ops/training.py:65 2019-01-16 21:25:01.310735: step 6740, loss = 0.69279 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:25:02.206715 ops/training.py:65 2019-01-16 21:25:02.206621: step 6741, loss = 0.69491 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:25:03.102025 ops/training.py:65 2019-01-16 21:25:03.101928: step 6742, loss = 0.68951 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:25:03.996931 ops/training.py:65 2019-01-16 21:25:03.996835: step 6743, loss = 0.69399 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:25:04.892336 ops/training.py:65 2019-01-16 21:25:04.892241: step 6744, loss = 0.69682 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:25:05.787559 ops/training.py:65 2019-01-16 21:25:05.787481: step 6745, loss = 0.69460 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:25:06.682661 ops/training.py:65 2019-01-16 21:25:06.682560: step 6746, loss = 0.69594 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:25:07.577615 ops/training.py:65 2019-01-16 21:25:07.577503: step 6747, loss = 0.69266 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:25:08.471361 ops/training.py:65 2019-01-16 21:25:08.471255: step 6748, loss = 0.69661 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:25:09.364254 ops/training.py:65 2019-01-16 21:25:09.364158: step 6749, loss = 0.69370 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:25:10.257919 ops/training.py:65 2019-01-16 21:25:10.257825: step 6750, loss = 0.69574 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:25:11.151483 ops/training.py:65 2019-01-16 21:25:11.151410: step 6751, loss = 0.69090 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:25:12.045429 ops/training.py:65 2019-01-16 21:25:12.045344: step 6752, loss = 0.69569 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:25:12.938930 ops/training.py:65 2019-01-16 21:25:12.938852: step 6753, loss = 0.69358 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:25:13.832713 ops/training.py:65 2019-01-16 21:25:13.832630: step 6754, loss = 0.69498 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:25:14.727023 ops/training.py:65 2019-01-16 21:25:14.726933: step 6755, loss = 0.69852 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:25:15.620701 ops/training.py:65 2019-01-16 21:25:15.620599: step 6756, loss = 0.69022 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:25:16.516287 ops/training.py:65 2019-01-16 21:25:16.516189: step 6757, loss = 0.69192 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:25:17.412720 ops/training.py:65 2019-01-16 21:25:17.412631: step 6758, loss = 0.68922 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:25:18.307814 ops/training.py:65 2019-01-16 21:25:18.307748: step 6759, loss = 0.69417 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:25:19.201449 ops/training.py:65 2019-01-16 21:25:19.201386: step 6760, loss = 0.69282 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:25:20.097651 ops/training.py:65 2019-01-16 21:25:20.097581: step 6761, loss = 0.68931 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:25:20.992241 ops/training.py:65 2019-01-16 21:25:20.992169: step 6762, loss = 0.68743 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:25:21.886534 ops/training.py:65 2019-01-16 21:25:21.886462: step 6763, loss = 0.68415 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:25:22.781302 ops/training.py:65 2019-01-16 21:25:22.781239: step 6764, loss = 0.67702 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:25:23.676967 ops/training.py:65 2019-01-16 21:25:23.676889: step 6765, loss = 0.70038 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:25:24.573582 ops/training.py:65 2019-01-16 21:25:24.573486: step 6766, loss = 0.70395 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:25:25.471671 ops/training.py:65 2019-01-16 21:25:25.471596: step 6767, loss = 0.68451 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:25:26.366986 ops/training.py:65 2019-01-16 21:25:26.366892: step 6768, loss = 0.67651 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:25:27.261107 ops/training.py:65 2019-01-16 21:25:27.261008: step 6769, loss = 0.68795 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:25:28.156051 ops/training.py:65 2019-01-16 21:25:28.155945: step 6770, loss = 0.71936 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:25:29.050035 ops/training.py:65 2019-01-16 21:25:29.049924: step 6771, loss = 0.70579 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:25:29.945748 ops/training.py:65 2019-01-16 21:25:29.945651: step 6772, loss = 0.71663 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:25:30.842281 ops/training.py:65 2019-01-16 21:25:30.842200: step 6773, loss = 0.67476 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:25:31.736737 ops/training.py:65 2019-01-16 21:25:31.736670: step 6774, loss = 0.68973 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:25:32.631458 ops/training.py:65 2019-01-16 21:25:32.631394: step 6775, loss = 0.70234 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:25:33.526090 ops/training.py:65 2019-01-16 21:25:33.526026: step 6776, loss = 0.67206 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:25:34.421843 ops/training.py:65 2019-01-16 21:25:34.421740: step 6777, loss = 0.70457 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:25:35.320024 ops/training.py:65 2019-01-16 21:25:35.319912: step 6778, loss = 0.69726 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:25:36.216275 ops/training.py:65 2019-01-16 21:25:36.216135: step 6779, loss = 0.71992 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:25:37.111408 ops/training.py:65 2019-01-16 21:25:37.111347: step 6780, loss = 0.69795 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:25:38.004654 ops/training.py:65 2019-01-16 21:25:38.004596: step 6781, loss = 0.72448 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:25:38.897805 ops/training.py:65 2019-01-16 21:25:38.897743: step 6782, loss = 0.68011 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:25:39.791964 ops/training.py:65 2019-01-16 21:25:39.791894: step 6783, loss = 0.66170 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:25:40.687392 ops/training.py:65 2019-01-16 21:25:40.687316: step 6784, loss = 0.66519 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:25:41.581236 ops/training.py:65 2019-01-16 21:25:41.581146: step 6785, loss = 0.69131 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:25:42.474624 ops/training.py:65 2019-01-16 21:25:42.474557: step 6786, loss = 0.69088 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:25:43.368596 ops/training.py:65 2019-01-16 21:25:43.368537: step 6787, loss = 0.70957 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:25:44.262317 ops/training.py:65 2019-01-16 21:25:44.262251: step 6788, loss = 0.69565 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:25:45.155895 ops/training.py:65 2019-01-16 21:25:45.155820: step 6789, loss = 0.68314 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:25:46.051210 ops/training.py:65 2019-01-16 21:25:46.051136: step 6790, loss = 0.64545 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 21:25:46.946773 ops/training.py:65 2019-01-16 21:25:46.946676: step 6791, loss = 0.67877 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:25:47.843615 ops/training.py:65 2019-01-16 21:25:47.843513: step 6792, loss = 0.72639 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:25:48.741327 ops/training.py:65 2019-01-16 21:25:48.741225: step 6793, loss = 0.72623 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:25:49.637967 ops/training.py:65 2019-01-16 21:25:49.637866: step 6794, loss = 0.69366 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:25:50.533156 ops/training.py:65 2019-01-16 21:25:50.533059: step 6795, loss = 0.70762 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:25:51.428066 ops/training.py:65 2019-01-16 21:25:51.427978: step 6796, loss = 0.71374 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:25:52.322843 ops/training.py:65 2019-01-16 21:25:52.322790: step 6797, loss = 0.66769 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:25:53.215458 ops/training.py:65 2019-01-16 21:25:53.215407: step 6798, loss = 0.69716 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:25:54.109027 ops/training.py:65 2019-01-16 21:25:54.108994: step 6799, loss = 0.68904 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:25:55.008326 ops/training.py:65 2019-01-16 21:25:55.008270: step 6800, loss = 0.70081 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:25:55.903964 ops/training.py:65 2019-01-16 21:25:55.903922: step 6801, loss = 0.71235 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:25:56.800122 ops/training.py:65 2019-01-16 21:25:56.800084: step 6802, loss = 0.67291 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:25:57.696124 ops/training.py:65 2019-01-16 21:25:57.696087: step 6803, loss = 0.68616 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:25:58.592572 ops/training.py:65 2019-01-16 21:25:58.592531: step 6804, loss = 0.68565 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:25:59.488469 ops/training.py:65 2019-01-16 21:25:59.488420: step 6805, loss = 0.67417 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:26:00.383321 ops/training.py:65 2019-01-16 21:26:00.383274: step 6806, loss = 0.69508 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:26:01.278232 ops/training.py:65 2019-01-16 21:26:01.278192: step 6807, loss = 0.70916 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:26:02.172805 ops/training.py:65 2019-01-16 21:26:02.172748: step 6808, loss = 0.69225 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:26:03.068235 ops/training.py:65 2019-01-16 21:26:03.068184: step 6809, loss = 0.70384 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:26:03.962997 ops/training.py:65 2019-01-16 21:26:03.962931: step 6810, loss = 0.68250 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:26:04.859121 ops/training.py:65 2019-01-16 21:26:04.859053: step 6811, loss = 0.70279 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:26:05.753737 ops/training.py:65 2019-01-16 21:26:05.753679: step 6812, loss = 0.71951 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:26:06.648496 ops/training.py:65 2019-01-16 21:26:06.648442: step 6813, loss = 0.70825 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:26:07.541474 ops/training.py:65 2019-01-16 21:26:07.541442: step 6814, loss = 0.70048 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:26:08.434845 ops/training.py:65 2019-01-16 21:26:08.434813: step 6815, loss = 0.71977 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:26:09.328675 ops/training.py:65 2019-01-16 21:26:09.328639: step 6816, loss = 0.68126 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:26:10.222087 ops/training.py:65 2019-01-16 21:26:10.222028: step 6817, loss = 0.69670 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:26:11.117899 ops/training.py:65 2019-01-16 21:26:11.117858: step 6818, loss = 0.70662 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:26:12.012604 ops/training.py:65 2019-01-16 21:26:12.012536: step 6819, loss = 0.70887 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:26:12.906834 ops/training.py:65 2019-01-16 21:26:12.906803: step 6820, loss = 0.72258 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:26:13.801176 ops/training.py:65 2019-01-16 21:26:13.801145: step 6821, loss = 0.72553 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 21:26:14.694030 ops/training.py:65 2019-01-16 21:26:14.693999: step 6822, loss = 0.73049 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:26:15.586986 ops/training.py:65 2019-01-16 21:26:15.586957: step 6823, loss = 0.69432 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:26:16.485704 ops/training.py:65 2019-01-16 21:26:16.485637: step 6824, loss = 0.67959 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:26:17.381058 ops/training.py:65 2019-01-16 21:26:17.381023: step 6825, loss = 0.69487 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:26:18.275216 ops/training.py:65 2019-01-16 21:26:18.275181: step 6826, loss = 0.72093 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:26:19.168537 ops/training.py:65 2019-01-16 21:26:19.168492: step 6827, loss = 0.70419 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:26:20.061799 ops/training.py:65 2019-01-16 21:26:20.061720: step 6828, loss = 0.70626 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:26:20.956979 ops/training.py:65 2019-01-16 21:26:20.956879: step 6829, loss = 0.68625 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:26:21.852451 ops/training.py:65 2019-01-16 21:26:21.852347: step 6830, loss = 0.71128 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:26:22.748019 ops/training.py:65 2019-01-16 21:26:22.747947: step 6831, loss = 0.71103 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:26:23.642573 ops/training.py:65 2019-01-16 21:26:23.642475: step 6832, loss = 0.69017 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:26:24.536891 ops/training.py:65 2019-01-16 21:26:24.536799: step 6833, loss = 0.69711 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:26:25.430927 ops/training.py:65 2019-01-16 21:26:25.430825: step 6834, loss = 0.73333 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.25
I1280 2019-01-16 21:26:26.326607 ops/training.py:65 2019-01-16 21:26:26.326512: step 6835, loss = 0.69923 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:26:27.222905 ops/training.py:65 2019-01-16 21:26:27.222815: step 6836, loss = 0.68865 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:26:28.118198 ops/training.py:65 2019-01-16 21:26:28.118099: step 6837, loss = 0.68866 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:26:29.013394 ops/training.py:65 2019-01-16 21:26:29.013293: step 6838, loss = 0.69103 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:26:29.909409 ops/training.py:65 2019-01-16 21:26:29.909316: step 6839, loss = 0.67424 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:26:30.805086 ops/training.py:65 2019-01-16 21:26:30.805003: step 6840, loss = 0.70154 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:26:31.698931 ops/training.py:65 2019-01-16 21:26:31.698872: step 6841, loss = 0.67975 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:26:32.592772 ops/training.py:65 2019-01-16 21:26:32.592713: step 6842, loss = 0.70169 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:26:33.485870 ops/training.py:65 2019-01-16 21:26:33.485774: step 6843, loss = 0.69970 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:26:34.380061 ops/training.py:65 2019-01-16 21:26:34.379958: step 6844, loss = 0.65650 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 21:26:35.273479 ops/training.py:65 2019-01-16 21:26:35.273402: step 6845, loss = 0.67620 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:26:36.167426 ops/training.py:65 2019-01-16 21:26:36.167356: step 6846, loss = 0.69204 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:26:37.061742 ops/training.py:65 2019-01-16 21:26:37.061682: step 6847, loss = 0.65668 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:26:37.958926 ops/training.py:65 2019-01-16 21:26:37.958820: step 6848, loss = 0.71834 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:26:38.854325 ops/training.py:65 2019-01-16 21:26:38.854227: step 6849, loss = 0.70633 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:26:39.750707 ops/training.py:65 2019-01-16 21:26:39.750636: step 6850, loss = 0.67711 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:26:40.648910 ops/training.py:65 2019-01-16 21:26:40.648833: step 6851, loss = 0.70176 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:26:41.543173 ops/training.py:65 2019-01-16 21:26:41.543074: step 6852, loss = 0.69727 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:26:42.436902 ops/training.py:65 2019-01-16 21:26:42.436805: step 6853, loss = 0.69108 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:26:43.331596 ops/training.py:65 2019-01-16 21:26:43.331436: step 6854, loss = 0.69208 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:26:44.227593 ops/training.py:65 2019-01-16 21:26:44.227468: step 6855, loss = 0.70679 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:26:45.124678 ops/training.py:65 2019-01-16 21:26:45.124516: step 6856, loss = 0.70313 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:26:46.020153 ops/training.py:65 2019-01-16 21:26:46.020046: step 6857, loss = 0.69328 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:26:46.915690 ops/training.py:65 2019-01-16 21:26:46.915547: step 6858, loss = 0.67212 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:26:47.811712 ops/training.py:65 2019-01-16 21:26:47.811612: step 6859, loss = 0.69988 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:26:48.707966 ops/training.py:65 2019-01-16 21:26:48.707865: step 6860, loss = 0.67839 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:26:49.603380 ops/training.py:65 2019-01-16 21:26:49.603281: step 6861, loss = 0.67966 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:26:50.500894 ops/training.py:65 2019-01-16 21:26:50.500795: step 6862, loss = 0.69002 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:26:51.394859 ops/training.py:65 2019-01-16 21:26:51.394766: step 6863, loss = 0.69580 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:26:52.287686 ops/training.py:65 2019-01-16 21:26:52.287587: step 6864, loss = 0.69757 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:26:53.180508 ops/training.py:65 2019-01-16 21:26:53.180403: step 6865, loss = 0.69264 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:26:54.076315 ops/training.py:65 2019-01-16 21:26:54.076209: step 6866, loss = 0.70335 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:26:54.971677 ops/training.py:65 2019-01-16 21:26:54.971573: step 6867, loss = 0.68478 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:26:55.870362 ops/training.py:65 2019-01-16 21:26:55.870283: step 6868, loss = 0.67213 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:26:56.766160 ops/training.py:65 2019-01-16 21:26:56.766058: step 6869, loss = 0.69189 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:26:57.661246 ops/training.py:65 2019-01-16 21:26:57.661149: step 6870, loss = 0.71101 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:26:58.556561 ops/training.py:65 2019-01-16 21:26:58.556465: step 6871, loss = 0.70348 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:26:59.450897 ops/training.py:65 2019-01-16 21:26:59.450792: step 6872, loss = 0.68476 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:27:00.345523 ops/training.py:65 2019-01-16 21:27:00.345422: step 6873, loss = 0.70936 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:27:01.241445 ops/training.py:65 2019-01-16 21:27:01.241357: step 6874, loss = 0.70232 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:27:02.137267 ops/training.py:65 2019-01-16 21:27:02.137170: step 6875, loss = 0.68515 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:27:03.032027 ops/training.py:65 2019-01-16 21:27:03.031931: step 6876, loss = 0.71291 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:27:03.926418 ops/training.py:65 2019-01-16 21:27:03.926322: step 6877, loss = 0.70043 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:27:04.822526 ops/training.py:65 2019-01-16 21:27:04.822430: step 6878, loss = 0.67662 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:27:05.719643 ops/training.py:65 2019-01-16 21:27:05.719549: step 6879, loss = 0.70762 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:27:06.614311 ops/training.py:65 2019-01-16 21:27:06.614179: step 6880, loss = 0.68967 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:27:07.508606 ops/training.py:65 2019-01-16 21:27:07.508537: step 6881, loss = 0.70078 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:27:08.403229 ops/training.py:65 2019-01-16 21:27:08.403164: step 6882, loss = 0.69308 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:27:09.298818 ops/training.py:65 2019-01-16 21:27:09.298719: step 6883, loss = 0.69950 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:27:10.195105 ops/training.py:65 2019-01-16 21:27:10.195016: step 6884, loss = 0.67947 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:27:11.088989 ops/training.py:65 2019-01-16 21:27:11.088905: step 6885, loss = 0.69803 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:27:11.982856 ops/training.py:65 2019-01-16 21:27:11.982755: step 6886, loss = 0.70432 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:27:12.878194 ops/training.py:65 2019-01-16 21:27:12.878091: step 6887, loss = 0.69815 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:27:13.773560 ops/training.py:65 2019-01-16 21:27:13.773461: step 6888, loss = 0.70440 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:27:14.670547 ops/training.py:65 2019-01-16 21:27:14.670417: step 6889, loss = 0.68816 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:27:15.567727 ops/training.py:65 2019-01-16 21:27:15.567624: step 6890, loss = 0.70405 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:27:16.463102 ops/training.py:65 2019-01-16 21:27:16.463006: step 6891, loss = 0.69772 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:27:17.357593 ops/training.py:65 2019-01-16 21:27:17.357497: step 6892, loss = 0.69202 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:27:18.252690 ops/training.py:65 2019-01-16 21:27:18.252591: step 6893, loss = 0.69283 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:27:19.149841 ops/training.py:65 2019-01-16 21:27:19.149748: step 6894, loss = 0.68599 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:27:20.046138 ops/training.py:65 2019-01-16 21:27:20.046038: step 6895, loss = 0.69575 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:27:20.941607 ops/training.py:65 2019-01-16 21:27:20.941515: step 6896, loss = 0.69086 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:27:21.835398 ops/training.py:65 2019-01-16 21:27:21.835308: step 6897, loss = 0.69456 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:27:22.730512 ops/training.py:65 2019-01-16 21:27:22.730417: step 6898, loss = 0.69440 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:27:23.625075 ops/training.py:65 2019-01-16 21:27:23.624978: step 6899, loss = 0.69157 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:27:24.520274 ops/training.py:65 2019-01-16 21:27:24.520143: step 6900, loss = 0.69297 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:27:25.414464 ops/training.py:65 2019-01-16 21:27:25.414332: step 6901, loss = 0.69927 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:27:26.308959 ops/training.py:65 2019-01-16 21:27:26.308863: step 6902, loss = 0.68947 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:27:27.203759 ops/training.py:65 2019-01-16 21:27:27.203628: step 6903, loss = 0.68766 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:27:28.098577 ops/training.py:65 2019-01-16 21:27:28.098476: step 6904, loss = 0.68761 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:27:28.992511 ops/training.py:65 2019-01-16 21:27:28.992377: step 6905, loss = 0.68235 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:27:29.887781 ops/training.py:65 2019-01-16 21:27:29.887648: step 6906, loss = 0.69120 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:27:30.782584 ops/training.py:65 2019-01-16 21:27:30.782486: step 6907, loss = 0.68377 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:27:31.677025 ops/training.py:65 2019-01-16 21:27:31.676925: step 6908, loss = 0.69773 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:27:32.571723 ops/training.py:65 2019-01-16 21:27:32.571633: step 6909, loss = 0.70258 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:27:33.465725 ops/training.py:65 2019-01-16 21:27:33.465627: step 6910, loss = 0.68788 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:27:34.361172 ops/training.py:65 2019-01-16 21:27:34.361104: step 6911, loss = 0.70950 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 21:27:35.257106 ops/training.py:65 2019-01-16 21:27:35.257004: step 6912, loss = 0.69013 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:27:36.355843 ops/training.py:65 2019-01-16 21:27:36.355747: step 6913, loss = 0.69499 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:27:37.252273 ops/training.py:65 2019-01-16 21:27:37.252176: step 6914, loss = 0.69925 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:27:38.149509 ops/training.py:65 2019-01-16 21:27:38.149412: step 6915, loss = 0.69544 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:27:39.043791 ops/training.py:65 2019-01-16 21:27:39.043694: step 6916, loss = 0.69884 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:27:39.938134 ops/training.py:65 2019-01-16 21:27:39.938041: step 6917, loss = 0.69606 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:27:40.832516 ops/training.py:65 2019-01-16 21:27:40.832415: step 6918, loss = 0.69693 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:27:41.727431 ops/training.py:65 2019-01-16 21:27:41.727335: step 6919, loss = 0.70367 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:27:42.622049 ops/training.py:65 2019-01-16 21:27:42.621956: step 6920, loss = 0.68738 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:27:43.518105 ops/training.py:65 2019-01-16 21:27:43.518005: step 6921, loss = 0.69824 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:27:44.412364 ops/training.py:65 2019-01-16 21:27:44.412261: step 6922, loss = 0.69508 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:27:45.309145 ops/training.py:65 2019-01-16 21:27:45.309056: step 6923, loss = 0.69522 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:27:46.204011 ops/training.py:65 2019-01-16 21:27:46.203879: step 6924, loss = 0.69546 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:27:47.098582 ops/training.py:65 2019-01-16 21:27:47.098483: step 6925, loss = 0.69258 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:27:47.993780 ops/training.py:65 2019-01-16 21:27:47.993682: step 6926, loss = 0.68911 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:27:48.888350 ops/training.py:65 2019-01-16 21:27:48.888253: step 6927, loss = 0.69428 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:27:49.783115 ops/training.py:65 2019-01-16 21:27:49.783005: step 6928, loss = 0.69299 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:27:50.681076 ops/training.py:65 2019-01-16 21:27:50.680976: step 6929, loss = 0.69185 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:27:51.575998 ops/training.py:65 2019-01-16 21:27:51.575897: step 6930, loss = 0.69517 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:27:52.471149 ops/training.py:65 2019-01-16 21:27:52.471044: step 6931, loss = 0.69843 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:27:53.367673 ops/training.py:65 2019-01-16 21:27:53.367576: step 6932, loss = 0.69599 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:27:54.261976 ops/training.py:65 2019-01-16 21:27:54.261888: step 6933, loss = 0.69152 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:27:55.156696 ops/training.py:65 2019-01-16 21:27:55.156594: step 6934, loss = 0.69334 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:27:56.050872 ops/training.py:65 2019-01-16 21:27:56.050777: step 6935, loss = 0.69352 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:27:56.943795 ops/training.py:65 2019-01-16 21:27:56.943696: step 6936, loss = 0.69643 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:27:57.839552 ops/training.py:65 2019-01-16 21:27:57.839461: step 6937, loss = 0.69634 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:27:58.735748 ops/training.py:65 2019-01-16 21:27:58.735652: step 6938, loss = 0.69236 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:27:59.629529 ops/training.py:65 2019-01-16 21:27:59.629437: step 6939, loss = 0.69548 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:28:00.524345 ops/training.py:65 2019-01-16 21:28:00.524247: step 6940, loss = 0.69221 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:28:01.419278 ops/training.py:65 2019-01-16 21:28:01.419194: step 6941, loss = 0.69261 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:28:02.313711 ops/training.py:65 2019-01-16 21:28:02.313624: step 6942, loss = 0.69270 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:28:03.209170 ops/training.py:65 2019-01-16 21:28:03.209072: step 6943, loss = 0.69707 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:28:04.104666 ops/training.py:65 2019-01-16 21:28:04.104574: step 6944, loss = 0.69388 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:28:04.998768 ops/training.py:65 2019-01-16 21:28:04.998673: step 6945, loss = 0.69038 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:28:05.893614 ops/training.py:65 2019-01-16 21:28:05.893521: step 6946, loss = 0.69633 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:28:06.788848 ops/training.py:65 2019-01-16 21:28:06.788752: step 6947, loss = 0.69719 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:28:07.683726 ops/training.py:65 2019-01-16 21:28:07.683626: step 6948, loss = 0.69159 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:28:08.578476 ops/training.py:65 2019-01-16 21:28:08.578373: step 6949, loss = 0.69521 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:28:09.473926 ops/training.py:65 2019-01-16 21:28:09.473826: step 6950, loss = 0.69195 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:28:10.369929 ops/training.py:65 2019-01-16 21:28:10.369844: step 6951, loss = 0.69154 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:28:11.265055 ops/training.py:65 2019-01-16 21:28:11.264946: step 6952, loss = 0.69324 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:28:12.159016 ops/training.py:65 2019-01-16 21:28:12.158906: step 6953, loss = 0.70084 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:28:13.053690 ops/training.py:65 2019-01-16 21:28:13.053585: step 6954, loss = 0.68923 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:28:13.949943 ops/training.py:65 2019-01-16 21:28:13.949849: step 6955, loss = 0.69097 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:28:14.846509 ops/training.py:65 2019-01-16 21:28:14.846422: step 6956, loss = 0.69422 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:28:15.741704 ops/training.py:65 2019-01-16 21:28:15.741622: step 6957, loss = 0.69059 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:28:16.637719 ops/training.py:65 2019-01-16 21:28:16.637624: step 6958, loss = 0.68648 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:28:17.533203 ops/training.py:65 2019-01-16 21:28:17.533105: step 6959, loss = 0.68714 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:28:18.428040 ops/training.py:65 2019-01-16 21:28:18.427974: step 6960, loss = 0.68993 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:28:19.323521 ops/training.py:65 2019-01-16 21:28:19.323417: step 6961, loss = 0.69042 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:28:20.220836 ops/training.py:65 2019-01-16 21:28:20.220734: step 6962, loss = 0.69626 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:28:21.116910 ops/training.py:65 2019-01-16 21:28:21.116821: step 6963, loss = 0.69483 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:28:22.010870 ops/training.py:65 2019-01-16 21:28:22.010771: step 6964, loss = 0.69286 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:28:22.906556 ops/training.py:65 2019-01-16 21:28:22.906467: step 6965, loss = 0.69222 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:28:23.803544 ops/training.py:65 2019-01-16 21:28:23.803440: step 6966, loss = 0.68427 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.75
I1280 2019-01-16 21:28:24.698758 ops/training.py:65 2019-01-16 21:28:24.698666: step 6967, loss = 0.69479 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:28:25.595134 ops/training.py:65 2019-01-16 21:28:25.595066: step 6968, loss = 0.68441 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 21:28:26.488863 ops/training.py:65 2019-01-16 21:28:26.488798: step 6969, loss = 0.69283 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:28:27.384229 ops/training.py:65 2019-01-16 21:28:27.384157: step 6970, loss = 0.69403 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:28:28.278369 ops/training.py:65 2019-01-16 21:28:28.278267: step 6971, loss = 0.69353 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:28:29.175792 ops/training.py:65 2019-01-16 21:28:29.175694: step 6972, loss = 0.69866 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:28:30.071890 ops/training.py:65 2019-01-16 21:28:30.071792: step 6973, loss = 0.69107 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:28:30.966562 ops/training.py:65 2019-01-16 21:28:30.966457: step 6974, loss = 0.68970 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:28:31.863284 ops/training.py:65 2019-01-16 21:28:31.863183: step 6975, loss = 0.68613 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 21:28:32.759411 ops/training.py:65 2019-01-16 21:28:32.759314: step 6976, loss = 0.69711 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:28:33.654075 ops/training.py:65 2019-01-16 21:28:33.653980: step 6977, loss = 0.69295 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:28:34.550101 ops/training.py:65 2019-01-16 21:28:34.550008: step 6978, loss = 0.69739 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:28:35.446523 ops/training.py:65 2019-01-16 21:28:35.446431: step 6979, loss = 0.69750 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:28:36.340442 ops/training.py:65 2019-01-16 21:28:36.340380: step 6980, loss = 0.69555 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:28:37.235322 ops/training.py:65 2019-01-16 21:28:37.235253: step 6981, loss = 0.69713 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:28:38.129794 ops/training.py:65 2019-01-16 21:28:38.129705: step 6982, loss = 0.70026 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:28:39.024248 ops/training.py:65 2019-01-16 21:28:39.024184: step 6983, loss = 0.68708 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:28:39.918809 ops/training.py:65 2019-01-16 21:28:39.918740: step 6984, loss = 0.69980 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:28:40.813541 ops/training.py:65 2019-01-16 21:28:40.813464: step 6985, loss = 0.69156 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:28:41.709209 ops/training.py:65 2019-01-16 21:28:41.709107: step 6986, loss = 0.69625 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:28:42.603235 ops/training.py:65 2019-01-16 21:28:42.603148: step 6987, loss = 0.69898 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:28:43.500333 ops/training.py:65 2019-01-16 21:28:43.500233: step 6988, loss = 0.69722 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:28:44.394942 ops/training.py:65 2019-01-16 21:28:44.394849: step 6989, loss = 0.69495 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:28:45.288583 ops/training.py:65 2019-01-16 21:28:45.288511: step 6990, loss = 0.69502 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:28:46.182694 ops/training.py:65 2019-01-16 21:28:46.182621: step 6991, loss = 0.68979 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:28:47.077367 ops/training.py:65 2019-01-16 21:28:47.077298: step 6992, loss = 0.69682 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:28:47.972211 ops/training.py:65 2019-01-16 21:28:47.972136: step 6993, loss = 0.68519 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:28:48.867289 ops/training.py:65 2019-01-16 21:28:48.867228: step 6994, loss = 0.69251 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:28:49.761151 ops/training.py:65 2019-01-16 21:28:49.761088: step 6995, loss = 0.69336 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:28:50.656111 ops/training.py:65 2019-01-16 21:28:50.656046: step 6996, loss = 0.68800 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:28:51.552258 ops/training.py:65 2019-01-16 21:28:51.552192: step 6997, loss = 0.69207 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:28:52.446980 ops/training.py:65 2019-01-16 21:28:52.446916: step 6998, loss = 0.69764 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:28:53.345657 ops/training.py:65 2019-01-16 21:28:53.345554: step 6999, loss = 0.69519 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:28:54.243639 ops/training.py:65 2019-01-16 21:28:54.243534: step 7000, loss = 0.69318 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:28:55.138381 ops/training.py:65 2019-01-16 21:28:55.138309: step 7001, loss = 0.68895 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:28:56.036117 ops/training.py:65 2019-01-16 21:28:56.036024: step 7002, loss = 0.69847 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:28:56.932390 ops/training.py:65 2019-01-16 21:28:56.932293: step 7003, loss = 0.69876 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:28:57.826718 ops/training.py:65 2019-01-16 21:28:57.826616: step 7004, loss = 0.69789 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:28:58.721350 ops/training.py:65 2019-01-16 21:28:58.721244: step 7005, loss = 0.69257 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:28:59.617304 ops/training.py:65 2019-01-16 21:28:59.617203: step 7006, loss = 0.69122 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:29:00.511348 ops/training.py:65 2019-01-16 21:29:00.511284: step 7007, loss = 0.69639 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:29:01.404854 ops/training.py:65 2019-01-16 21:29:01.404797: step 7008, loss = 0.69275 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:29:02.297408 ops/training.py:65 2019-01-16 21:29:02.297347: step 7009, loss = 0.68801 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:29:03.192614 ops/training.py:65 2019-01-16 21:29:03.192547: step 7010, loss = 0.68898 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:29:04.087814 ops/training.py:65 2019-01-16 21:29:04.087752: step 7011, loss = 0.68975 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:29:04.981810 ops/training.py:65 2019-01-16 21:29:04.981748: step 7012, loss = 0.69481 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:29:05.876586 ops/training.py:65 2019-01-16 21:29:05.876520: step 7013, loss = 0.68625 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:29:06.770705 ops/training.py:65 2019-01-16 21:29:06.770633: step 7014, loss = 0.69479 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:29:07.664366 ops/training.py:65 2019-01-16 21:29:07.664305: step 7015, loss = 0.68397 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:29:08.559207 ops/training.py:65 2019-01-16 21:29:08.559150: step 7016, loss = 0.68922 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:29:09.455095 ops/training.py:65 2019-01-16 21:29:09.454995: step 7017, loss = 0.69214 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:29:10.350909 ops/training.py:65 2019-01-16 21:29:10.350830: step 7018, loss = 0.69038 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:29:11.249326 ops/training.py:65 2019-01-16 21:29:11.249232: step 7019, loss = 0.69130 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:29:12.146349 ops/training.py:65 2019-01-16 21:29:12.146247: step 7020, loss = 0.70406 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:29:13.041929 ops/training.py:65 2019-01-16 21:29:13.041857: step 7021, loss = 0.69861 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:29:13.938042 ops/training.py:65 2019-01-16 21:29:13.937972: step 7022, loss = 0.68119 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:29:14.832437 ops/training.py:65 2019-01-16 21:29:14.832376: step 7023, loss = 0.69178 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:29:15.730326 ops/training.py:65 2019-01-16 21:29:15.730222: step 7024, loss = 0.69228 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:29:16.624946 ops/training.py:65 2019-01-16 21:29:16.624844: step 7025, loss = 0.68883 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:29:17.521803 ops/training.py:65 2019-01-16 21:29:17.521706: step 7026, loss = 0.67605 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:29:18.417048 ops/training.py:65 2019-01-16 21:29:18.416951: step 7027, loss = 0.69930 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:29:19.311758 ops/training.py:65 2019-01-16 21:29:19.311697: step 7028, loss = 0.70207 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:29:20.206494 ops/training.py:65 2019-01-16 21:29:20.206398: step 7029, loss = 0.69846 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:29:21.101211 ops/training.py:65 2019-01-16 21:29:21.101115: step 7030, loss = 0.68614 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:29:21.998742 ops/training.py:65 2019-01-16 21:29:21.998636: step 7031, loss = 0.69508 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:29:22.893534 ops/training.py:65 2019-01-16 21:29:22.893441: step 7032, loss = 0.68465 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:29:23.790220 ops/training.py:65 2019-01-16 21:29:23.790117: step 7033, loss = 0.69814 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:29:24.686770 ops/training.py:65 2019-01-16 21:29:24.686669: step 7034, loss = 0.69008 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:29:25.583283 ops/training.py:65 2019-01-16 21:29:25.583209: step 7035, loss = 0.69258 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:29:26.477932 ops/training.py:65 2019-01-16 21:29:26.477872: step 7036, loss = 0.70488 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:29:27.371834 ops/training.py:65 2019-01-16 21:29:27.371769: step 7037, loss = 0.68537 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:29:28.265726 ops/training.py:65 2019-01-16 21:29:28.265665: step 7038, loss = 0.69553 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:29:29.159841 ops/training.py:65 2019-01-16 21:29:29.159776: step 7039, loss = 0.68601 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:29:30.053389 ops/training.py:65 2019-01-16 21:29:30.053326: step 7040, loss = 0.68521 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:29:30.947149 ops/training.py:65 2019-01-16 21:29:30.947082: step 7041, loss = 0.69877 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:29:31.841451 ops/training.py:65 2019-01-16 21:29:31.841377: step 7042, loss = 0.69267 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:29:32.736201 ops/training.py:65 2019-01-16 21:29:32.736141: step 7043, loss = 0.69985 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:29:33.631433 ops/training.py:65 2019-01-16 21:29:33.631374: step 7044, loss = 0.69511 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:29:34.526168 ops/training.py:65 2019-01-16 21:29:34.526099: step 7045, loss = 0.69031 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:29:35.421158 ops/training.py:65 2019-01-16 21:29:35.421095: step 7046, loss = 0.71109 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.21875
I1280 2019-01-16 21:29:36.315053 ops/training.py:65 2019-01-16 21:29:36.314991: step 7047, loss = 0.70385 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:29:37.208435 ops/training.py:65 2019-01-16 21:29:37.208381: step 7048, loss = 0.68730 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:29:38.103741 ops/training.py:65 2019-01-16 21:29:38.103637: step 7049, loss = 0.69387 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:29:39.002541 ops/training.py:65 2019-01-16 21:29:39.002438: step 7050, loss = 0.69821 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:29:39.898807 ops/training.py:65 2019-01-16 21:29:39.898700: step 7051, loss = 0.69246 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:29:40.795106 ops/training.py:65 2019-01-16 21:29:40.795038: step 7052, loss = 0.68705 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:29:41.693967 ops/training.py:65 2019-01-16 21:29:41.693881: step 7053, loss = 0.69433 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:29:42.588827 ops/training.py:65 2019-01-16 21:29:42.588734: step 7054, loss = 0.67964 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:29:43.483056 ops/training.py:65 2019-01-16 21:29:43.482986: step 7055, loss = 0.69420 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:29:44.377810 ops/training.py:65 2019-01-16 21:29:44.377739: step 7056, loss = 0.68956 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 21:29:45.272013 ops/training.py:65 2019-01-16 21:29:45.271951: step 7057, loss = 0.68455 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:29:46.166168 ops/training.py:65 2019-01-16 21:29:46.166108: step 7058, loss = 0.69790 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:29:47.059579 ops/training.py:65 2019-01-16 21:29:47.059511: step 7059, loss = 0.68008 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.75
I1280 2019-01-16 21:29:47.954096 ops/training.py:65 2019-01-16 21:29:47.954031: step 7060, loss = 0.69549 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:29:48.848393 ops/training.py:65 2019-01-16 21:29:48.848330: step 7061, loss = 0.70016 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:29:49.742053 ops/training.py:65 2019-01-16 21:29:49.741996: step 7062, loss = 0.70194 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:29:50.640647 ops/training.py:65 2019-01-16 21:29:50.640559: step 7063, loss = 0.69279 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:29:51.538447 ops/training.py:65 2019-01-16 21:29:51.538344: step 7064, loss = 0.68403 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:29:52.435681 ops/training.py:65 2019-01-16 21:29:52.435587: step 7065, loss = 0.70338 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:29:53.333776 ops/training.py:65 2019-01-16 21:29:53.333677: step 7066, loss = 0.68828 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:29:54.228346 ops/training.py:65 2019-01-16 21:29:54.228287: step 7067, loss = 0.69396 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:29:55.126121 ops/training.py:65 2019-01-16 21:29:55.126014: step 7068, loss = 0.69402 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:29:56.021992 ops/training.py:65 2019-01-16 21:29:56.021899: step 7069, loss = 0.69335 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:29:56.918065 ops/training.py:65 2019-01-16 21:29:56.917959: step 7070, loss = 0.69396 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:29:57.813182 ops/training.py:65 2019-01-16 21:29:57.813125: step 7071, loss = 0.68900 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:29:58.707324 ops/training.py:65 2019-01-16 21:29:58.707260: step 7072, loss = 0.68532 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:29:59.602579 ops/training.py:65 2019-01-16 21:29:59.602476: step 7073, loss = 0.69061 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:30:00.495843 ops/training.py:65 2019-01-16 21:30:00.495745: step 7074, loss = 0.69310 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:30:01.389487 ops/training.py:65 2019-01-16 21:30:01.389413: step 7075, loss = 0.68713 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:30:02.283461 ops/training.py:65 2019-01-16 21:30:02.283372: step 7076, loss = 0.69243 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:30:03.177191 ops/training.py:65 2019-01-16 21:30:03.177087: step 7077, loss = 0.68343 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:30:04.071537 ops/training.py:65 2019-01-16 21:30:04.071434: step 7078, loss = 0.70431 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:30:04.965102 ops/training.py:65 2019-01-16 21:30:04.965002: step 7079, loss = 0.68653 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:30:05.859607 ops/training.py:65 2019-01-16 21:30:05.859505: step 7080, loss = 0.68945 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:30:06.753661 ops/training.py:65 2019-01-16 21:30:06.753583: step 7081, loss = 0.70312 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:30:07.648222 ops/training.py:65 2019-01-16 21:30:07.648163: step 7082, loss = 0.70136 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:30:08.543243 ops/training.py:65 2019-01-16 21:30:08.543141: step 7083, loss = 0.68931 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:30:09.438785 ops/training.py:65 2019-01-16 21:30:09.438687: step 7084, loss = 0.70708 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:30:10.333288 ops/training.py:65 2019-01-16 21:30:10.333207: step 7085, loss = 0.68988 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:30:11.228657 ops/training.py:65 2019-01-16 21:30:11.228565: step 7086, loss = 0.69168 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:30:12.124177 ops/training.py:65 2019-01-16 21:30:12.124075: step 7087, loss = 0.69123 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:30:13.020540 ops/training.py:65 2019-01-16 21:30:13.020439: step 7088, loss = 0.70918 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:30:13.914891 ops/training.py:65 2019-01-16 21:30:13.914789: step 7089, loss = 0.68983 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:30:14.809957 ops/training.py:65 2019-01-16 21:30:14.809889: step 7090, loss = 0.70243 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:30:15.705559 ops/training.py:65 2019-01-16 21:30:15.705468: step 7091, loss = 0.68601 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:30:16.602500 ops/training.py:65 2019-01-16 21:30:16.602398: step 7092, loss = 0.68013 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:30:17.497450 ops/training.py:65 2019-01-16 21:30:17.497349: step 7093, loss = 0.69386 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:30:18.391746 ops/training.py:65 2019-01-16 21:30:18.391646: step 7094, loss = 0.69571 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:30:19.289495 ops/training.py:65 2019-01-16 21:30:19.289397: step 7095, loss = 0.69289 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:30:20.185713 ops/training.py:65 2019-01-16 21:30:20.185623: step 7096, loss = 0.69661 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:30:21.082212 ops/training.py:65 2019-01-16 21:30:21.082116: step 7097, loss = 0.70389 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:30:21.977880 ops/training.py:65 2019-01-16 21:30:21.977783: step 7098, loss = 0.70297 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:30:22.873862 ops/training.py:65 2019-01-16 21:30:22.873696: step 7099, loss = 0.68537 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:30:23.770113 ops/training.py:65 2019-01-16 21:30:23.770009: step 7100, loss = 0.67930 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:30:24.665691 ops/training.py:65 2019-01-16 21:30:24.665593: step 7101, loss = 0.68665 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:30:25.560983 ops/training.py:65 2019-01-16 21:30:25.560889: step 7102, loss = 0.69032 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:30:26.455127 ops/training.py:65 2019-01-16 21:30:26.455030: step 7103, loss = 0.67663 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.75
I1280 2019-01-16 21:30:27.354817 ops/training.py:65 2019-01-16 21:30:27.354711: step 7104, loss = 0.69398 (35.6 examples/sec; 0.899 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:30:28.249444 ops/training.py:65 2019-01-16 21:30:28.249354: step 7105, loss = 0.69846 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:30:29.142994 ops/training.py:65 2019-01-16 21:30:29.142902: step 7106, loss = 0.70387 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:30:30.036903 ops/training.py:65 2019-01-16 21:30:30.036815: step 7107, loss = 0.70216 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:30:30.930501 ops/training.py:65 2019-01-16 21:30:30.930407: step 7108, loss = 0.69155 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:30:31.825908 ops/training.py:65 2019-01-16 21:30:31.825815: step 7109, loss = 0.68462 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:30:32.720738 ops/training.py:65 2019-01-16 21:30:32.720619: step 7110, loss = 0.70131 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:30:33.615334 ops/training.py:65 2019-01-16 21:30:33.615240: step 7111, loss = 0.69890 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:30:34.510161 ops/training.py:65 2019-01-16 21:30:34.510071: step 7112, loss = 0.68943 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:30:35.405188 ops/training.py:65 2019-01-16 21:30:35.405090: step 7113, loss = 0.70071 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:30:36.300496 ops/training.py:65 2019-01-16 21:30:36.300403: step 7114, loss = 0.69306 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:30:37.195438 ops/training.py:65 2019-01-16 21:30:37.195344: step 7115, loss = 0.69166 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:30:38.091575 ops/training.py:65 2019-01-16 21:30:38.091480: step 7116, loss = 0.69844 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:30:38.986664 ops/training.py:65 2019-01-16 21:30:38.986571: step 7117, loss = 0.68907 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:30:39.879929 ops/training.py:65 2019-01-16 21:30:39.879841: step 7118, loss = 0.68678 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:30:40.773757 ops/training.py:65 2019-01-16 21:30:40.773665: step 7119, loss = 0.69495 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:30:41.668163 ops/training.py:65 2019-01-16 21:30:41.668073: step 7120, loss = 0.69337 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:30:42.563231 ops/training.py:65 2019-01-16 21:30:42.563141: step 7121, loss = 0.69165 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:30:43.458481 ops/training.py:65 2019-01-16 21:30:43.458385: step 7122, loss = 0.68910 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:30:44.352465 ops/training.py:65 2019-01-16 21:30:44.352356: step 7123, loss = 0.69781 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:30:45.249414 ops/training.py:65 2019-01-16 21:30:45.249319: step 7124, loss = 0.69864 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:30:46.144157 ops/training.py:65 2019-01-16 21:30:46.144057: step 7125, loss = 0.69639 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:30:47.039382 ops/training.py:65 2019-01-16 21:30:47.039293: step 7126, loss = 0.68885 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:30:47.934639 ops/training.py:65 2019-01-16 21:30:47.934544: step 7127, loss = 0.69791 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:30:48.830066 ops/training.py:65 2019-01-16 21:30:48.829964: step 7128, loss = 0.69112 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:30:49.724891 ops/training.py:65 2019-01-16 21:30:49.724794: step 7129, loss = 0.69457 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:30:50.620274 ops/training.py:65 2019-01-16 21:30:50.620179: step 7130, loss = 0.70184 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:30:51.514809 ops/training.py:65 2019-01-16 21:30:51.514744: step 7131, loss = 0.69450 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:30:52.409035 ops/training.py:65 2019-01-16 21:30:52.408964: step 7132, loss = 0.69462 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:30:53.304785 ops/training.py:65 2019-01-16 21:30:53.304689: step 7133, loss = 0.68814 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:30:54.198631 ops/training.py:65 2019-01-16 21:30:54.198531: step 7134, loss = 0.69147 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:30:55.093186 ops/training.py:65 2019-01-16 21:30:55.093085: step 7135, loss = 0.69042 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:30:55.987474 ops/training.py:65 2019-01-16 21:30:55.987379: step 7136, loss = 0.69926 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:30:56.881371 ops/training.py:65 2019-01-16 21:30:56.881239: step 7137, loss = 0.69482 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:30:57.774774 ops/training.py:65 2019-01-16 21:30:57.774679: step 7138, loss = 0.69295 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:30:58.669629 ops/training.py:65 2019-01-16 21:30:58.669526: step 7139, loss = 0.69339 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:30:59.566645 ops/training.py:65 2019-01-16 21:30:59.566556: step 7140, loss = 0.69544 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:31:00.461051 ops/training.py:65 2019-01-16 21:31:00.460956: step 7141, loss = 0.69541 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:31:01.355012 ops/training.py:65 2019-01-16 21:31:01.354924: step 7142, loss = 0.69206 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:31:02.248440 ops/training.py:65 2019-01-16 21:31:02.248347: step 7143, loss = 0.69473 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:31:03.143805 ops/training.py:65 2019-01-16 21:31:03.143709: step 7144, loss = 0.69852 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:31:04.040009 ops/training.py:65 2019-01-16 21:31:04.039896: step 7145, loss = 0.68936 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:31:04.934786 ops/training.py:65 2019-01-16 21:31:04.934688: step 7146, loss = 0.69525 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:31:05.831646 ops/training.py:65 2019-01-16 21:31:05.831553: step 7147, loss = 0.68812 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:31:06.725989 ops/training.py:65 2019-01-16 21:31:06.725894: step 7148, loss = 0.69797 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:31:07.621461 ops/training.py:65 2019-01-16 21:31:07.621368: step 7149, loss = 0.69534 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:31:08.515751 ops/training.py:65 2019-01-16 21:31:08.515659: step 7150, loss = 0.68945 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:31:09.410002 ops/training.py:65 2019-01-16 21:31:09.409909: step 7151, loss = 0.69149 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:31:10.303555 ops/training.py:65 2019-01-16 21:31:10.303469: step 7152, loss = 0.69212 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:31:11.198041 ops/training.py:65 2019-01-16 21:31:11.197945: step 7153, loss = 0.69021 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:31:12.092919 ops/training.py:65 2019-01-16 21:31:12.092815: step 7154, loss = 0.69768 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:31:12.987053 ops/training.py:65 2019-01-16 21:31:12.986959: step 7155, loss = 0.68846 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:31:13.882820 ops/training.py:65 2019-01-16 21:31:13.882704: step 7156, loss = 0.69528 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:31:14.780613 ops/training.py:65 2019-01-16 21:31:14.780489: step 7157, loss = 0.69475 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:31:15.675440 ops/training.py:65 2019-01-16 21:31:15.675332: step 7158, loss = 0.69738 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:31:16.571512 ops/training.py:65 2019-01-16 21:31:16.571413: step 7159, loss = 0.69110 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:31:17.467720 ops/training.py:65 2019-01-16 21:31:17.467631: step 7160, loss = 0.69368 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:31:18.363734 ops/training.py:65 2019-01-16 21:31:18.363638: step 7161, loss = 0.70320 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:31:19.258236 ops/training.py:65 2019-01-16 21:31:19.258139: step 7162, loss = 0.69260 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:31:20.152599 ops/training.py:65 2019-01-16 21:31:20.152504: step 7163, loss = 0.69180 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:31:21.046880 ops/training.py:65 2019-01-16 21:31:21.046783: step 7164, loss = 0.68695 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:31:21.942022 ops/training.py:65 2019-01-16 21:31:21.941930: step 7165, loss = 0.69187 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:31:22.836397 ops/training.py:65 2019-01-16 21:31:22.836307: step 7166, loss = 0.70127 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:31:23.731160 ops/training.py:65 2019-01-16 21:31:23.731060: step 7167, loss = 0.69524 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:31:24.626679 ops/training.py:65 2019-01-16 21:31:24.626582: step 7168, loss = 0.69582 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:31:25.521649 ops/training.py:65 2019-01-16 21:31:25.521555: step 7169, loss = 0.70196 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 21:31:26.417790 ops/training.py:65 2019-01-16 21:31:26.417694: step 7170, loss = 0.68908 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:31:27.313885 ops/training.py:65 2019-01-16 21:31:27.313791: step 7171, loss = 0.69381 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:31:28.209306 ops/training.py:65 2019-01-16 21:31:28.209173: step 7172, loss = 0.69547 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:31:29.104162 ops/training.py:65 2019-01-16 21:31:29.104069: step 7173, loss = 0.69754 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:31:29.997058 ops/training.py:65 2019-01-16 21:31:29.996977: step 7174, loss = 0.69107 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:31:30.891652 ops/training.py:65 2019-01-16 21:31:30.891571: step 7175, loss = 0.69538 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:31:31.788138 ops/training.py:65 2019-01-16 21:31:31.788036: step 7176, loss = 0.69431 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:31:32.684591 ops/training.py:65 2019-01-16 21:31:32.684476: step 7177, loss = 0.68850 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:31:33.584687 ops/training.py:65 2019-01-16 21:31:33.584582: step 7178, loss = 0.69819 (35.6 examples/sec; 0.899 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:31:34.480593 ops/training.py:65 2019-01-16 21:31:34.480499: step 7179, loss = 0.69435 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:31:35.375835 ops/training.py:65 2019-01-16 21:31:35.375732: step 7180, loss = 0.69330 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:31:36.270962 ops/training.py:65 2019-01-16 21:31:36.270866: step 7181, loss = 0.68590 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:31:37.165957 ops/training.py:65 2019-01-16 21:31:37.165862: step 7182, loss = 0.69390 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:31:38.062952 ops/training.py:65 2019-01-16 21:31:38.062854: step 7183, loss = 0.69342 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:31:38.957651 ops/training.py:65 2019-01-16 21:31:38.957562: step 7184, loss = 0.69305 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:31:39.852375 ops/training.py:65 2019-01-16 21:31:39.852315: step 7185, loss = 0.68643 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:31:40.746637 ops/training.py:65 2019-01-16 21:31:40.746561: step 7186, loss = 0.69208 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:31:41.641300 ops/training.py:65 2019-01-16 21:31:41.641173: step 7187, loss = 0.68826 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:31:42.535037 ops/training.py:65 2019-01-16 21:31:42.534950: step 7188, loss = 0.69702 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:31:43.432572 ops/training.py:65 2019-01-16 21:31:43.432471: step 7189, loss = 0.69169 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:31:44.327970 ops/training.py:65 2019-01-16 21:31:44.327874: step 7190, loss = 0.69565 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:31:45.224589 ops/training.py:65 2019-01-16 21:31:45.224483: step 7191, loss = 0.69521 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:31:46.118963 ops/training.py:65 2019-01-16 21:31:46.118864: step 7192, loss = 0.68947 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:31:47.014794 ops/training.py:65 2019-01-16 21:31:47.014697: step 7193, loss = 0.68418 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.78125
I1280 2019-01-16 21:31:47.909769 ops/training.py:65 2019-01-16 21:31:47.909673: step 7194, loss = 0.69356 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:31:48.805822 ops/training.py:65 2019-01-16 21:31:48.805723: step 7195, loss = 0.69837 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:31:49.700710 ops/training.py:65 2019-01-16 21:31:49.700612: step 7196, loss = 0.68308 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:31:50.595612 ops/training.py:65 2019-01-16 21:31:50.595517: step 7197, loss = 0.68974 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:31:51.491421 ops/training.py:65 2019-01-16 21:31:51.491316: step 7198, loss = 0.69435 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:31:52.386143 ops/training.py:65 2019-01-16 21:31:52.386054: step 7199, loss = 0.69109 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:31:53.280059 ops/training.py:65 2019-01-16 21:31:53.279950: step 7200, loss = 0.69447 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:31:54.174861 ops/training.py:65 2019-01-16 21:31:54.174767: step 7201, loss = 0.69462 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:31:55.070954 ops/training.py:65 2019-01-16 21:31:55.070857: step 7202, loss = 0.69876 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:31:55.965341 ops/training.py:65 2019-01-16 21:31:55.965260: step 7203, loss = 0.69440 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:31:56.860037 ops/training.py:65 2019-01-16 21:31:56.859936: step 7204, loss = 0.69161 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:31:57.754339 ops/training.py:65 2019-01-16 21:31:57.754242: step 7205, loss = 0.69096 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:31:58.649187 ops/training.py:65 2019-01-16 21:31:58.649090: step 7206, loss = 0.68908 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:31:59.543017 ops/training.py:65 2019-01-16 21:31:59.542921: step 7207, loss = 0.69307 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:32:00.436942 ops/training.py:65 2019-01-16 21:32:00.436846: step 7208, loss = 0.69519 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:32:01.330226 ops/training.py:65 2019-01-16 21:32:01.330136: step 7209, loss = 0.70217 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:32:02.227974 ops/training.py:65 2019-01-16 21:32:02.227886: step 7210, loss = 0.70341 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:32:03.123464 ops/training.py:65 2019-01-16 21:32:03.123364: step 7211, loss = 0.69143 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:32:04.017809 ops/training.py:65 2019-01-16 21:32:04.017714: step 7212, loss = 0.68963 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:32:04.913001 ops/training.py:65 2019-01-16 21:32:04.912910: step 7213, loss = 0.69179 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:32:05.810616 ops/training.py:65 2019-01-16 21:32:05.810515: step 7214, loss = 0.69469 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:32:06.706790 ops/training.py:65 2019-01-16 21:32:06.706696: step 7215, loss = 0.69110 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:32:07.602661 ops/training.py:65 2019-01-16 21:32:07.602562: step 7216, loss = 0.68955 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:32:08.497942 ops/training.py:65 2019-01-16 21:32:08.497812: step 7217, loss = 0.70020 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:32:09.393183 ops/training.py:65 2019-01-16 21:32:09.393088: step 7218, loss = 0.69590 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:32:10.288373 ops/training.py:65 2019-01-16 21:32:10.288275: step 7219, loss = 0.69309 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:32:11.183321 ops/training.py:65 2019-01-16 21:32:11.183246: step 7220, loss = 0.69962 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:32:12.078439 ops/training.py:65 2019-01-16 21:32:12.078345: step 7221, loss = 0.69317 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:32:12.972968 ops/training.py:65 2019-01-16 21:32:12.972870: step 7222, loss = 0.69420 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:32:13.867272 ops/training.py:65 2019-01-16 21:32:13.867180: step 7223, loss = 0.69421 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:32:14.761723 ops/training.py:65 2019-01-16 21:32:14.761616: step 7224, loss = 0.69421 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:32:15.658606 ops/training.py:65 2019-01-16 21:32:15.658513: step 7225, loss = 0.69150 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:32:16.555090 ops/training.py:65 2019-01-16 21:32:16.555009: step 7226, loss = 0.68749 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:32:17.452087 ops/training.py:65 2019-01-16 21:32:17.451992: step 7227, loss = 0.69874 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:32:18.347433 ops/training.py:65 2019-01-16 21:32:18.347334: step 7228, loss = 0.69392 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:32:19.242652 ops/training.py:65 2019-01-16 21:32:19.242550: step 7229, loss = 0.69352 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:32:20.139986 ops/training.py:65 2019-01-16 21:32:20.139879: step 7230, loss = 0.69570 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:32:21.034707 ops/training.py:65 2019-01-16 21:32:21.034606: step 7231, loss = 0.69114 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:32:21.930518 ops/training.py:65 2019-01-16 21:32:21.930422: step 7232, loss = 0.69341 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:32:22.825918 ops/training.py:65 2019-01-16 21:32:22.825823: step 7233, loss = 0.68832 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:32:23.721983 ops/training.py:65 2019-01-16 21:32:23.721882: step 7234, loss = 0.68921 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:32:24.616684 ops/training.py:65 2019-01-16 21:32:24.616590: step 7235, loss = 0.69049 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:32:25.511207 ops/training.py:65 2019-01-16 21:32:25.511107: step 7236, loss = 0.69458 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:32:26.405556 ops/training.py:65 2019-01-16 21:32:26.405458: step 7237, loss = 0.68949 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:32:27.302566 ops/training.py:65 2019-01-16 21:32:27.302465: step 7238, loss = 0.69144 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:32:28.198683 ops/training.py:65 2019-01-16 21:32:28.198580: step 7239, loss = 0.69903 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:32:29.094650 ops/training.py:65 2019-01-16 21:32:29.094537: step 7240, loss = 0.69196 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:32:29.988760 ops/training.py:65 2019-01-16 21:32:29.988664: step 7241, loss = 0.69512 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:32:30.883550 ops/training.py:65 2019-01-16 21:32:30.883496: step 7242, loss = 0.69927 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:32:31.779910 ops/training.py:65 2019-01-16 21:32:31.779815: step 7243, loss = 0.69522 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:32:32.675723 ops/training.py:65 2019-01-16 21:32:32.675631: step 7244, loss = 0.69413 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:32:33.573231 ops/training.py:65 2019-01-16 21:32:33.573134: step 7245, loss = 0.68769 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:32:34.470448 ops/training.py:65 2019-01-16 21:32:34.470350: step 7246, loss = 0.69737 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:32:35.366650 ops/training.py:65 2019-01-16 21:32:35.366584: step 7247, loss = 0.69041 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:32:36.261576 ops/training.py:65 2019-01-16 21:32:36.261477: step 7248, loss = 0.69908 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:32:37.157217 ops/training.py:65 2019-01-16 21:32:37.157116: step 7249, loss = 0.69830 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:32:38.054601 ops/training.py:65 2019-01-16 21:32:38.054499: step 7250, loss = 0.69359 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:32:38.950605 ops/training.py:65 2019-01-16 21:32:38.950509: step 7251, loss = 0.68072 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:32:39.848564 ops/training.py:65 2019-01-16 21:32:39.848460: step 7252, loss = 0.69276 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:32:40.744361 ops/training.py:65 2019-01-16 21:32:40.744286: step 7253, loss = 0.70094 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:32:41.639565 ops/training.py:65 2019-01-16 21:32:41.639466: step 7254, loss = 0.69502 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:32:42.534593 ops/training.py:65 2019-01-16 21:32:42.534502: step 7255, loss = 0.68974 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:32:43.429619 ops/training.py:65 2019-01-16 21:32:43.429550: step 7256, loss = 0.68309 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:32:44.324797 ops/training.py:65 2019-01-16 21:32:44.324683: step 7257, loss = 0.69099 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:32:45.221485 ops/training.py:65 2019-01-16 21:32:45.221386: step 7258, loss = 0.70412 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:32:46.116378 ops/training.py:65 2019-01-16 21:32:46.116282: step 7259, loss = 0.69924 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:32:47.010360 ops/training.py:65 2019-01-16 21:32:47.010266: step 7260, loss = 0.69929 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:32:47.906238 ops/training.py:65 2019-01-16 21:32:47.906137: step 7261, loss = 0.69316 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:32:48.802831 ops/training.py:65 2019-01-16 21:32:48.802733: step 7262, loss = 0.69268 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:32:49.697622 ops/training.py:65 2019-01-16 21:32:49.697515: step 7263, loss = 0.68983 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:32:50.596161 ops/training.py:65 2019-01-16 21:32:50.596066: step 7264, loss = 0.69423 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:32:51.492167 ops/training.py:65 2019-01-16 21:32:51.492072: step 7265, loss = 0.70691 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:32:52.388710 ops/training.py:65 2019-01-16 21:32:52.388621: step 7266, loss = 0.69522 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:32:53.284753 ops/training.py:65 2019-01-16 21:32:53.284659: step 7267, loss = 0.70911 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 21:32:54.181289 ops/training.py:65 2019-01-16 21:32:54.181190: step 7268, loss = 0.67943 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:32:55.076409 ops/training.py:65 2019-01-16 21:32:55.076316: step 7269, loss = 0.68483 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:32:55.973290 ops/training.py:65 2019-01-16 21:32:55.973194: step 7270, loss = 0.69236 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:32:56.869144 ops/training.py:65 2019-01-16 21:32:56.869045: step 7271, loss = 0.69369 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:32:57.766380 ops/training.py:65 2019-01-16 21:32:57.766281: step 7272, loss = 0.68901 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:32:58.661724 ops/training.py:65 2019-01-16 21:32:58.661602: step 7273, loss = 0.69456 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:32:59.558663 ops/training.py:65 2019-01-16 21:32:59.558566: step 7274, loss = 0.69370 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:33:00.453172 ops/training.py:65 2019-01-16 21:33:00.453070: step 7275, loss = 0.69656 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:33:01.349569 ops/training.py:65 2019-01-16 21:33:01.349486: step 7276, loss = 0.68686 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:33:02.244518 ops/training.py:65 2019-01-16 21:33:02.244424: step 7277, loss = 0.69800 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:33:03.140426 ops/training.py:65 2019-01-16 21:33:03.140330: step 7278, loss = 0.69126 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:33:04.035268 ops/training.py:65 2019-01-16 21:33:04.035179: step 7279, loss = 0.69402 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:33:04.931050 ops/training.py:65 2019-01-16 21:33:04.930954: step 7280, loss = 0.69027 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:33:05.826207 ops/training.py:65 2019-01-16 21:33:05.826112: step 7281, loss = 0.68750 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.75
I1280 2019-01-16 21:33:06.721457 ops/training.py:65 2019-01-16 21:33:06.721357: step 7282, loss = 0.69073 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:33:07.616262 ops/training.py:65 2019-01-16 21:33:07.616162: step 7283, loss = 0.69340 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:33:08.513308 ops/training.py:65 2019-01-16 21:33:08.513218: step 7284, loss = 0.69627 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:33:09.408198 ops/training.py:65 2019-01-16 21:33:09.408101: step 7285, loss = 0.70239 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:33:10.304667 ops/training.py:65 2019-01-16 21:33:10.304573: step 7286, loss = 0.68935 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:33:11.202071 ops/training.py:65 2019-01-16 21:33:11.201981: step 7287, loss = 0.69334 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:33:12.098176 ops/training.py:65 2019-01-16 21:33:12.098080: step 7288, loss = 0.69735 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:33:12.993693 ops/training.py:65 2019-01-16 21:33:12.993592: step 7289, loss = 0.69069 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:33:13.890966 ops/training.py:65 2019-01-16 21:33:13.890870: step 7290, loss = 0.69448 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:33:14.786203 ops/training.py:65 2019-01-16 21:33:14.786106: step 7291, loss = 0.69360 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:33:15.681511 ops/training.py:65 2019-01-16 21:33:15.681393: step 7292, loss = 0.69270 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:33:16.576953 ops/training.py:65 2019-01-16 21:33:16.576852: step 7293, loss = 0.69456 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:33:17.470682 ops/training.py:65 2019-01-16 21:33:17.470581: step 7294, loss = 0.69545 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:33:18.365098 ops/training.py:65 2019-01-16 21:33:18.364994: step 7295, loss = 0.70582 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:33:19.259719 ops/training.py:65 2019-01-16 21:33:19.259625: step 7296, loss = 0.69374 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:33:20.155827 ops/training.py:65 2019-01-16 21:33:20.155738: step 7297, loss = 0.69197 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:33:21.052060 ops/training.py:65 2019-01-16 21:33:21.051969: step 7298, loss = 0.69708 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:33:21.949380 ops/training.py:65 2019-01-16 21:33:21.949279: step 7299, loss = 0.70097 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:33:22.847031 ops/training.py:65 2019-01-16 21:33:22.846931: step 7300, loss = 0.69450 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:33:23.741477 ops/training.py:65 2019-01-16 21:33:23.741380: step 7301, loss = 0.69717 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:33:24.635084 ops/training.py:65 2019-01-16 21:33:24.635023: step 7302, loss = 0.68963 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:33:25.527468 ops/training.py:65 2019-01-16 21:33:25.527406: step 7303, loss = 0.69054 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:33:26.422253 ops/training.py:65 2019-01-16 21:33:26.422200: step 7304, loss = 0.69399 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:33:27.317700 ops/training.py:65 2019-01-16 21:33:27.317635: step 7305, loss = 0.69397 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:33:28.211909 ops/training.py:65 2019-01-16 21:33:28.211801: step 7306, loss = 0.69671 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:33:29.108961 ops/training.py:65 2019-01-16 21:33:29.108863: step 7307, loss = 0.70245 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:33:30.005173 ops/training.py:65 2019-01-16 21:33:30.005077: step 7308, loss = 0.70206 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:33:30.900391 ops/training.py:65 2019-01-16 21:33:30.900306: step 7309, loss = 0.68564 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:33:31.794502 ops/training.py:65 2019-01-16 21:33:31.794428: step 7310, loss = 0.69638 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:33:32.689317 ops/training.py:65 2019-01-16 21:33:32.689222: step 7311, loss = 0.69378 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:33:33.584433 ops/training.py:65 2019-01-16 21:33:33.584330: step 7312, loss = 0.68859 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:33:34.479137 ops/training.py:65 2019-01-16 21:33:34.479041: step 7313, loss = 0.69575 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:33:35.373244 ops/training.py:65 2019-01-16 21:33:35.373143: step 7314, loss = 0.68547 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:33:36.269697 ops/training.py:65 2019-01-16 21:33:36.269601: step 7315, loss = 0.68409 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:33:37.166858 ops/training.py:65 2019-01-16 21:33:37.166763: step 7316, loss = 0.69161 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:33:38.063496 ops/training.py:65 2019-01-16 21:33:38.063394: step 7317, loss = 0.69656 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:33:38.960857 ops/training.py:65 2019-01-16 21:33:38.960756: step 7318, loss = 0.69701 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:33:39.858556 ops/training.py:65 2019-01-16 21:33:39.858456: step 7319, loss = 0.69733 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:33:40.754089 ops/training.py:65 2019-01-16 21:33:40.754010: step 7320, loss = 0.69028 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:33:41.651838 ops/training.py:65 2019-01-16 21:33:41.651738: step 7321, loss = 0.69474 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:33:42.547947 ops/training.py:65 2019-01-16 21:33:42.547852: step 7322, loss = 0.69094 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:33:43.443658 ops/training.py:65 2019-01-16 21:33:43.443557: step 7323, loss = 0.69243 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:33:44.340681 ops/training.py:65 2019-01-16 21:33:44.340587: step 7324, loss = 0.69155 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:33:45.235601 ops/training.py:65 2019-01-16 21:33:45.235504: step 7325, loss = 0.69410 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:33:46.132953 ops/training.py:65 2019-01-16 21:33:46.132858: step 7326, loss = 0.69474 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:33:47.027588 ops/training.py:65 2019-01-16 21:33:47.027497: step 7327, loss = 0.69235 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:33:47.922911 ops/training.py:65 2019-01-16 21:33:47.922813: step 7328, loss = 0.68800 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:33:48.817815 ops/training.py:65 2019-01-16 21:33:48.817720: step 7329, loss = 0.70121 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:33:49.713379 ops/training.py:65 2019-01-16 21:33:49.713288: step 7330, loss = 0.70320 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:33:50.608833 ops/training.py:65 2019-01-16 21:33:50.608763: step 7331, loss = 0.68133 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:33:51.502831 ops/training.py:65 2019-01-16 21:33:51.502761: step 7332, loss = 0.68682 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 21:33:52.397164 ops/training.py:65 2019-01-16 21:33:52.397100: step 7333, loss = 0.68904 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:33:53.291253 ops/training.py:65 2019-01-16 21:33:53.291151: step 7334, loss = 0.69155 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:33:54.186508 ops/training.py:65 2019-01-16 21:33:54.186399: step 7335, loss = 0.68743 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:33:55.081489 ops/training.py:65 2019-01-16 21:33:55.081386: step 7336, loss = 0.69811 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:33:55.977212 ops/training.py:65 2019-01-16 21:33:55.977126: step 7337, loss = 0.69251 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:33:56.873404 ops/training.py:65 2019-01-16 21:33:56.873300: step 7338, loss = 0.69253 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:33:57.767604 ops/training.py:65 2019-01-16 21:33:57.767507: step 7339, loss = 0.69094 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:33:58.663714 ops/training.py:65 2019-01-16 21:33:58.663619: step 7340, loss = 0.68511 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:33:59.559257 ops/training.py:65 2019-01-16 21:33:59.559161: step 7341, loss = 0.69836 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:34:00.454704 ops/training.py:65 2019-01-16 21:34:00.454599: step 7342, loss = 0.68951 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:34:01.349284 ops/training.py:65 2019-01-16 21:34:01.349197: step 7343, loss = 0.68405 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:34:02.244581 ops/training.py:65 2019-01-16 21:34:02.244493: step 7344, loss = 0.69344 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:34:03.141186 ops/training.py:65 2019-01-16 21:34:03.141084: step 7345, loss = 0.68766 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:34:04.037470 ops/training.py:65 2019-01-16 21:34:04.037380: step 7346, loss = 0.69518 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:34:04.935066 ops/training.py:65 2019-01-16 21:34:04.934961: step 7347, loss = 0.69692 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:34:05.831021 ops/training.py:65 2019-01-16 21:34:05.830920: step 7348, loss = 0.69381 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:34:06.727730 ops/training.py:65 2019-01-16 21:34:06.727628: step 7349, loss = 0.69170 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:34:07.624681 ops/training.py:65 2019-01-16 21:34:07.624581: step 7350, loss = 0.69663 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:34:08.519596 ops/training.py:65 2019-01-16 21:34:08.519500: step 7351, loss = 0.69209 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:34:09.415134 ops/training.py:65 2019-01-16 21:34:09.415035: step 7352, loss = 0.69382 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:34:10.309903 ops/training.py:65 2019-01-16 21:34:10.309806: step 7353, loss = 0.70953 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:34:11.205161 ops/training.py:65 2019-01-16 21:34:11.205091: step 7354, loss = 0.69130 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:34:12.099877 ops/training.py:65 2019-01-16 21:34:12.099781: step 7355, loss = 0.69266 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:34:12.995837 ops/training.py:65 2019-01-16 21:34:12.995742: step 7356, loss = 0.69251 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:34:13.892960 ops/training.py:65 2019-01-16 21:34:13.892843: step 7357, loss = 0.70118 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:34:14.788213 ops/training.py:65 2019-01-16 21:34:14.788117: step 7358, loss = 0.70990 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:34:15.683941 ops/training.py:65 2019-01-16 21:34:15.683862: step 7359, loss = 0.68929 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:34:16.579551 ops/training.py:65 2019-01-16 21:34:16.579457: step 7360, loss = 0.70154 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:34:17.474299 ops/training.py:65 2019-01-16 21:34:17.474200: step 7361, loss = 0.69487 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:34:18.370905 ops/training.py:65 2019-01-16 21:34:18.370810: step 7362, loss = 0.69201 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:34:19.265437 ops/training.py:65 2019-01-16 21:34:19.265300: step 7363, loss = 0.69107 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:34:20.160452 ops/training.py:65 2019-01-16 21:34:20.160350: step 7364, loss = 0.68560 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:34:21.055039 ops/training.py:65 2019-01-16 21:34:21.054937: step 7365, loss = 0.69391 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:34:21.950561 ops/training.py:65 2019-01-16 21:34:21.950454: step 7366, loss = 0.68245 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:34:22.844946 ops/training.py:65 2019-01-16 21:34:22.844847: step 7367, loss = 0.70456 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:34:23.744718 ops/training.py:65 2019-01-16 21:34:23.744610: step 7368, loss = 0.70105 (35.6 examples/sec; 0.899 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:34:24.641200 ops/training.py:65 2019-01-16 21:34:24.641109: step 7369, loss = 0.69406 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:34:25.536375 ops/training.py:65 2019-01-16 21:34:25.536286: step 7370, loss = 0.69242 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:34:26.433647 ops/training.py:65 2019-01-16 21:34:26.433516: step 7371, loss = 0.69202 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:34:27.330301 ops/training.py:65 2019-01-16 21:34:27.330206: step 7372, loss = 0.69932 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:34:28.225015 ops/training.py:65 2019-01-16 21:34:28.224909: step 7373, loss = 0.69620 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:34:29.120999 ops/training.py:65 2019-01-16 21:34:29.120896: step 7374, loss = 0.69212 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:34:30.016218 ops/training.py:65 2019-01-16 21:34:30.016130: step 7375, loss = 0.69600 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:34:30.912699 ops/training.py:65 2019-01-16 21:34:30.912600: step 7376, loss = 0.69177 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:34:31.809058 ops/training.py:65 2019-01-16 21:34:31.808961: step 7377, loss = 0.69213 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:34:32.704386 ops/training.py:65 2019-01-16 21:34:32.704285: step 7378, loss = 0.69210 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:34:33.599289 ops/training.py:65 2019-01-16 21:34:33.599160: step 7379, loss = 0.69167 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:34:34.495119 ops/training.py:65 2019-01-16 21:34:34.495024: step 7380, loss = 0.69965 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:34:35.391500 ops/training.py:65 2019-01-16 21:34:35.391401: step 7381, loss = 0.69891 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:34:36.284478 ops/training.py:65 2019-01-16 21:34:36.284389: step 7382, loss = 0.69204 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:34:37.179661 ops/training.py:65 2019-01-16 21:34:37.179563: step 7383, loss = 0.68956 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:34:38.076843 ops/training.py:65 2019-01-16 21:34:38.076747: step 7384, loss = 0.69250 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:34:38.973684 ops/training.py:65 2019-01-16 21:34:38.973585: step 7385, loss = 0.69066 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:34:39.870235 ops/training.py:65 2019-01-16 21:34:39.870140: step 7386, loss = 0.69559 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:34:40.766058 ops/training.py:65 2019-01-16 21:34:40.765984: step 7387, loss = 0.68789 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:34:41.661250 ops/training.py:65 2019-01-16 21:34:41.661155: step 7388, loss = 0.69552 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:34:42.556651 ops/training.py:65 2019-01-16 21:34:42.556523: step 7389, loss = 0.68954 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:34:43.452918 ops/training.py:65 2019-01-16 21:34:43.452816: step 7390, loss = 0.69481 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:34:44.347952 ops/training.py:65 2019-01-16 21:34:44.347855: step 7391, loss = 0.69130 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:34:45.242821 ops/training.py:65 2019-01-16 21:34:45.242725: step 7392, loss = 0.69288 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:34:46.137693 ops/training.py:65 2019-01-16 21:34:46.137590: step 7393, loss = 0.69519 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:34:47.032034 ops/training.py:65 2019-01-16 21:34:47.031937: step 7394, loss = 0.69031 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:34:47.926897 ops/training.py:65 2019-01-16 21:34:47.926799: step 7395, loss = 0.69725 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:34:48.823365 ops/training.py:65 2019-01-16 21:34:48.823269: step 7396, loss = 0.69340 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:34:49.717615 ops/training.py:65 2019-01-16 21:34:49.717485: step 7397, loss = 0.69352 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:34:50.611605 ops/training.py:65 2019-01-16 21:34:50.611508: step 7398, loss = 0.70103 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:34:51.506652 ops/training.py:65 2019-01-16 21:34:51.506558: step 7399, loss = 0.69782 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:34:52.401705 ops/training.py:65 2019-01-16 21:34:52.401571: step 7400, loss = 0.69352 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:34:53.296916 ops/training.py:65 2019-01-16 21:34:53.296817: step 7401, loss = 0.69416 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:34:54.190923 ops/training.py:65 2019-01-16 21:34:54.190866: step 7402, loss = 0.69125 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:34:55.083933 ops/training.py:65 2019-01-16 21:34:55.083874: step 7403, loss = 0.69348 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:34:55.976679 ops/training.py:65 2019-01-16 21:34:55.976636: step 7404, loss = 0.69098 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:34:56.870652 ops/training.py:65 2019-01-16 21:34:56.870550: step 7405, loss = 0.69209 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:34:57.766024 ops/training.py:65 2019-01-16 21:34:57.765920: step 7406, loss = 0.69034 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:34:58.660124 ops/training.py:65 2019-01-16 21:34:58.660021: step 7407, loss = 0.69157 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:34:59.553556 ops/training.py:65 2019-01-16 21:34:59.553462: step 7408, loss = 0.69791 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:35:00.447120 ops/training.py:65 2019-01-16 21:35:00.447021: step 7409, loss = 0.69440 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:35:01.341759 ops/training.py:65 2019-01-16 21:35:01.341651: step 7410, loss = 0.69348 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:35:02.235421 ops/training.py:65 2019-01-16 21:35:02.235372: step 7411, loss = 0.69652 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:35:03.129256 ops/training.py:65 2019-01-16 21:35:03.129196: step 7412, loss = 0.69347 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:35:04.023685 ops/training.py:65 2019-01-16 21:35:04.023584: step 7413, loss = 0.69261 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:35:04.918212 ops/training.py:65 2019-01-16 21:35:04.918116: step 7414, loss = 0.69901 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:35:05.814664 ops/training.py:65 2019-01-16 21:35:05.814558: step 7415, loss = 0.69872 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:35:06.711422 ops/training.py:65 2019-01-16 21:35:06.711320: step 7416, loss = 0.69470 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:35:07.606049 ops/training.py:65 2019-01-16 21:35:07.605952: step 7417, loss = 0.69455 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:35:08.501091 ops/training.py:65 2019-01-16 21:35:08.500987: step 7418, loss = 0.69179 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:35:09.399512 ops/training.py:65 2019-01-16 21:35:09.399412: step 7419, loss = 0.69275 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:35:10.295318 ops/training.py:65 2019-01-16 21:35:10.295211: step 7420, loss = 0.69121 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:35:11.190829 ops/training.py:65 2019-01-16 21:35:11.190736: step 7421, loss = 0.69653 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:35:12.083932 ops/training.py:65 2019-01-16 21:35:12.083832: step 7422, loss = 0.69505 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:35:12.979691 ops/training.py:65 2019-01-16 21:35:12.979659: step 7423, loss = 0.69304 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:35:13.880117 ops/training.py:65 2019-01-16 21:35:13.880086: step 7424, loss = 0.69136 (35.6 examples/sec; 0.900 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:35:14.773206 ops/training.py:65 2019-01-16 21:35:14.773111: step 7425, loss = 0.69166 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:35:15.667402 ops/training.py:65 2019-01-16 21:35:15.667370: step 7426, loss = 0.69071 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:35:16.561349 ops/training.py:65 2019-01-16 21:35:16.561305: step 7427, loss = 0.69288 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:35:17.455212 ops/training.py:65 2019-01-16 21:35:17.455158: step 7428, loss = 0.69490 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:35:18.348275 ops/training.py:65 2019-01-16 21:35:18.348174: step 7429, loss = 0.69137 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:35:19.242186 ops/training.py:65 2019-01-16 21:35:19.242147: step 7430, loss = 0.69282 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:35:20.139118 ops/training.py:65 2019-01-16 21:35:20.139077: step 7431, loss = 0.69324 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:35:21.035968 ops/training.py:65 2019-01-16 21:35:21.035908: step 7432, loss = 0.69355 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:35:21.932203 ops/training.py:65 2019-01-16 21:35:21.932102: step 7433, loss = 0.69241 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:35:22.827484 ops/training.py:65 2019-01-16 21:35:22.827380: step 7434, loss = 0.69306 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:35:23.722970 ops/training.py:65 2019-01-16 21:35:23.722861: step 7435, loss = 0.69380 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:35:24.618078 ops/training.py:65 2019-01-16 21:35:24.617992: step 7436, loss = 0.69111 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:35:25.514090 ops/training.py:65 2019-01-16 21:35:25.514013: step 7437, loss = 0.69973 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:35:26.410716 ops/training.py:65 2019-01-16 21:35:26.410642: step 7438, loss = 0.69137 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:35:27.304216 ops/training.py:65 2019-01-16 21:35:27.304153: step 7439, loss = 0.69093 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:35:28.201477 ops/training.py:65 2019-01-16 21:35:28.201383: step 7440, loss = 0.69571 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:35:29.097535 ops/training.py:65 2019-01-16 21:35:29.097472: step 7441, loss = 0.69205 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:35:29.991100 ops/training.py:65 2019-01-16 21:35:29.991040: step 7442, loss = 0.69647 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:35:30.885925 ops/training.py:65 2019-01-16 21:35:30.885846: step 7443, loss = 0.69561 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:35:31.781356 ops/training.py:65 2019-01-16 21:35:31.781255: step 7444, loss = 0.69184 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:35:32.677594 ops/training.py:65 2019-01-16 21:35:32.677496: step 7445, loss = 0.69712 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:35:33.573200 ops/training.py:65 2019-01-16 21:35:33.573136: step 7446, loss = 0.69281 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:35:34.467127 ops/training.py:65 2019-01-16 21:35:34.467063: step 7447, loss = 0.69395 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:35:35.360860 ops/training.py:65 2019-01-16 21:35:35.360799: step 7448, loss = 0.69554 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:35:36.255121 ops/training.py:65 2019-01-16 21:35:36.255057: step 7449, loss = 0.69501 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:35:37.151670 ops/training.py:65 2019-01-16 21:35:37.151588: step 7450, loss = 0.68878 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:35:38.047669 ops/training.py:65 2019-01-16 21:35:38.047564: step 7451, loss = 0.69294 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:35:38.945718 ops/training.py:65 2019-01-16 21:35:38.945614: step 7452, loss = 0.69626 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:35:39.842356 ops/training.py:65 2019-01-16 21:35:39.842296: step 7453, loss = 0.69117 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:35:40.735399 ops/training.py:65 2019-01-16 21:35:40.735321: step 7454, loss = 0.69586 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:35:41.629345 ops/training.py:65 2019-01-16 21:35:41.629271: step 7455, loss = 0.69231 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:35:42.523119 ops/training.py:65 2019-01-16 21:35:42.523062: step 7456, loss = 0.69377 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:35:43.418926 ops/training.py:65 2019-01-16 21:35:43.418862: step 7457, loss = 0.69093 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:35:44.315354 ops/training.py:65 2019-01-16 21:35:44.315261: step 7458, loss = 0.69066 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:35:45.212584 ops/training.py:65 2019-01-16 21:35:45.212483: step 7459, loss = 0.69319 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:35:46.109121 ops/training.py:65 2019-01-16 21:35:46.109017: step 7460, loss = 0.69447 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:35:47.004543 ops/training.py:65 2019-01-16 21:35:47.004434: step 7461, loss = 0.69431 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:35:47.899752 ops/training.py:65 2019-01-16 21:35:47.899682: step 7462, loss = 0.69123 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:35:48.792824 ops/training.py:65 2019-01-16 21:35:48.792761: step 7463, loss = 0.69361 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:35:49.686075 ops/training.py:65 2019-01-16 21:35:49.686016: step 7464, loss = 0.69203 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:35:50.579000 ops/training.py:65 2019-01-16 21:35:50.578937: step 7465, loss = 0.69667 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:35:51.474681 ops/training.py:65 2019-01-16 21:35:51.474600: step 7466, loss = 0.69636 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:35:52.370915 ops/training.py:65 2019-01-16 21:35:52.370831: step 7467, loss = 0.69579 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:35:53.266808 ops/training.py:65 2019-01-16 21:35:53.266718: step 7468, loss = 0.69428 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:35:54.161652 ops/training.py:65 2019-01-16 21:35:54.161570: step 7469, loss = 0.69329 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:35:55.056660 ops/training.py:65 2019-01-16 21:35:55.056560: step 7470, loss = 0.68788 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:35:55.951399 ops/training.py:65 2019-01-16 21:35:55.951339: step 7471, loss = 0.69821 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:35:56.845107 ops/training.py:65 2019-01-16 21:35:56.845047: step 7472, loss = 0.69381 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:35:57.738011 ops/training.py:65 2019-01-16 21:35:57.737952: step 7473, loss = 0.69252 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:35:58.632040 ops/training.py:65 2019-01-16 21:35:58.631979: step 7474, loss = 0.69359 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:35:59.527246 ops/training.py:65 2019-01-16 21:35:59.527167: step 7475, loss = 0.69131 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:36:00.422833 ops/training.py:65 2019-01-16 21:36:00.422732: step 7476, loss = 0.69051 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:36:01.319483 ops/training.py:65 2019-01-16 21:36:01.319387: step 7477, loss = 0.69040 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:36:02.216014 ops/training.py:65 2019-01-16 21:36:02.215920: step 7478, loss = 0.69295 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:36:03.111878 ops/training.py:65 2019-01-16 21:36:03.111821: step 7479, loss = 0.69246 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:36:04.006466 ops/training.py:65 2019-01-16 21:36:04.006407: step 7480, loss = 0.69340 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:36:04.900245 ops/training.py:65 2019-01-16 21:36:04.900184: step 7481, loss = 0.69475 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:36:05.792857 ops/training.py:65 2019-01-16 21:36:05.792797: step 7482, loss = 0.69253 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:36:06.685773 ops/training.py:65 2019-01-16 21:36:06.685712: step 7483, loss = 0.69371 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:36:07.579475 ops/training.py:65 2019-01-16 21:36:07.579414: step 7484, loss = 0.69036 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:36:08.474068 ops/training.py:65 2019-01-16 21:36:08.474006: step 7485, loss = 0.69572 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:36:09.368617 ops/training.py:65 2019-01-16 21:36:09.368561: step 7486, loss = 0.69598 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 21:36:10.261887 ops/training.py:65 2019-01-16 21:36:10.261826: step 7487, loss = 0.69172 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:36:11.154847 ops/training.py:65 2019-01-16 21:36:11.154773: step 7488, loss = 0.69322 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:36:12.049461 ops/training.py:65 2019-01-16 21:36:12.049395: step 7489, loss = 0.69312 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:36:12.942210 ops/training.py:65 2019-01-16 21:36:12.942149: step 7490, loss = 0.69395 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:36:13.835957 ops/training.py:65 2019-01-16 21:36:13.835892: step 7491, loss = 0.69301 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:36:14.730324 ops/training.py:65 2019-01-16 21:36:14.730264: step 7492, loss = 0.68995 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:36:15.625950 ops/training.py:65 2019-01-16 21:36:15.625890: step 7493, loss = 0.69181 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:36:16.519968 ops/training.py:65 2019-01-16 21:36:16.519895: step 7494, loss = 0.68814 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:36:17.413708 ops/training.py:65 2019-01-16 21:36:17.413645: step 7495, loss = 0.69398 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:36:18.307358 ops/training.py:65 2019-01-16 21:36:18.307297: step 7496, loss = 0.69711 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.21875
I1280 2019-01-16 21:36:19.200006 ops/training.py:65 2019-01-16 21:36:19.199941: step 7497, loss = 0.69199 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:36:20.092595 ops/training.py:65 2019-01-16 21:36:20.092536: step 7498, loss = 0.69796 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.25
I1280 2019-01-16 21:36:20.985837 ops/training.py:65 2019-01-16 21:36:20.985777: step 7499, loss = 0.69264 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:36:21.878845 ops/training.py:65 2019-01-16 21:36:21.878786: step 7500, loss = 0.69176 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:36:22.770957 ops/training.py:65 2019-01-16 21:36:22.770897: step 7501, loss = 0.69554 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:36:23.664248 ops/training.py:65 2019-01-16 21:36:23.664186: step 7502, loss = 0.69431 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:36:24.557006 ops/training.py:65 2019-01-16 21:36:24.556943: step 7503, loss = 0.69175 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:36:25.449706 ops/training.py:65 2019-01-16 21:36:25.449640: step 7504, loss = 0.69160 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:36:26.342653 ops/training.py:65 2019-01-16 21:36:26.342588: step 7505, loss = 0.69183 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:36:27.238365 ops/training.py:65 2019-01-16 21:36:27.238295: step 7506, loss = 0.69110 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:36:28.135619 ops/training.py:65 2019-01-16 21:36:28.135512: step 7507, loss = 0.70032 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:36:29.033367 ops/training.py:65 2019-01-16 21:36:29.033275: step 7508, loss = 0.68938 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:36:29.930564 ops/training.py:65 2019-01-16 21:36:29.930463: step 7509, loss = 0.68887 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:36:30.826338 ops/training.py:65 2019-01-16 21:36:30.826245: step 7510, loss = 0.69589 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:36:31.721254 ops/training.py:65 2019-01-16 21:36:31.721196: step 7511, loss = 0.69332 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:36:32.614839 ops/training.py:65 2019-01-16 21:36:32.614783: step 7512, loss = 0.69466 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:36:33.508458 ops/training.py:65 2019-01-16 21:36:33.508397: step 7513, loss = 0.69744 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:36:34.401998 ops/training.py:65 2019-01-16 21:36:34.401938: step 7514, loss = 0.69210 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:36:35.294880 ops/training.py:65 2019-01-16 21:36:35.294816: step 7515, loss = 0.69940 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:36:36.187122 ops/training.py:65 2019-01-16 21:36:36.187062: step 7516, loss = 0.69790 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:36:37.079583 ops/training.py:65 2019-01-16 21:36:37.079520: step 7517, loss = 0.69385 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:36:37.973468 ops/training.py:65 2019-01-16 21:36:37.973404: step 7518, loss = 0.68926 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:36:38.870205 ops/training.py:65 2019-01-16 21:36:38.870114: step 7519, loss = 0.68958 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:36:39.767041 ops/training.py:65 2019-01-16 21:36:39.766963: step 7520, loss = 0.69974 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:36:40.662407 ops/training.py:65 2019-01-16 21:36:40.662311: step 7521, loss = 0.69434 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:36:41.559323 ops/training.py:65 2019-01-16 21:36:41.559236: step 7522, loss = 0.69501 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:36:42.454151 ops/training.py:65 2019-01-16 21:36:42.454049: step 7523, loss = 0.70563 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.21875
I1280 2019-01-16 21:36:43.350006 ops/training.py:65 2019-01-16 21:36:43.349899: step 7524, loss = 0.70705 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.25
I1280 2019-01-16 21:36:44.247703 ops/training.py:65 2019-01-16 21:36:44.247600: step 7525, loss = 0.69296 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:36:45.147494 ops/training.py:65 2019-01-16 21:36:45.147392: step 7526, loss = 0.68863 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:36:46.041737 ops/training.py:65 2019-01-16 21:36:46.041670: step 7527, loss = 0.68823 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:36:46.936944 ops/training.py:65 2019-01-16 21:36:46.936876: step 7528, loss = 0.69780 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:36:47.831711 ops/training.py:65 2019-01-16 21:36:47.831641: step 7529, loss = 0.69080 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:36:48.724439 ops/training.py:65 2019-01-16 21:36:48.724378: step 7530, loss = 0.69357 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:36:49.617435 ops/training.py:65 2019-01-16 21:36:49.617371: step 7531, loss = 0.68901 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:36:50.511275 ops/training.py:65 2019-01-16 21:36:50.511216: step 7532, loss = 0.69723 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:36:51.405188 ops/training.py:65 2019-01-16 21:36:51.405119: step 7533, loss = 0.69300 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:36:52.299507 ops/training.py:65 2019-01-16 21:36:52.299449: step 7534, loss = 0.68654 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:36:53.194421 ops/training.py:65 2019-01-16 21:36:53.194361: step 7535, loss = 0.69210 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:36:54.088467 ops/training.py:65 2019-01-16 21:36:54.088417: step 7536, loss = 0.69397 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:36:54.980253 ops/training.py:65 2019-01-16 21:36:54.980192: step 7537, loss = 0.69121 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:36:55.873458 ops/training.py:65 2019-01-16 21:36:55.873393: step 7538, loss = 0.69431 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:36:56.767322 ops/training.py:65 2019-01-16 21:36:56.767258: step 7539, loss = 0.69645 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:36:57.663943 ops/training.py:65 2019-01-16 21:36:57.663838: step 7540, loss = 0.69305 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:36:58.561040 ops/training.py:65 2019-01-16 21:36:58.560927: step 7541, loss = 0.68727 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:36:59.455016 ops/training.py:65 2019-01-16 21:36:59.454954: step 7542, loss = 0.69284 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:37:00.349554 ops/training.py:65 2019-01-16 21:37:00.349471: step 7543, loss = 0.68932 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:37:01.242981 ops/training.py:65 2019-01-16 21:37:01.242926: step 7544, loss = 0.69150 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:37:02.136047 ops/training.py:65 2019-01-16 21:37:02.135991: step 7545, loss = 0.70419 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 21:37:03.035088 ops/training.py:65 2019-01-16 21:37:03.035025: step 7546, loss = 0.69596 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:37:03.930859 ops/training.py:65 2019-01-16 21:37:03.930754: step 7547, loss = 0.69401 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:37:04.826927 ops/training.py:65 2019-01-16 21:37:04.826869: step 7548, loss = 0.69291 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:37:05.719832 ops/training.py:65 2019-01-16 21:37:05.719766: step 7549, loss = 0.70055 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:37:06.613309 ops/training.py:65 2019-01-16 21:37:06.613244: step 7550, loss = 0.69364 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:37:07.507059 ops/training.py:65 2019-01-16 21:37:07.506994: step 7551, loss = 0.69332 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:37:08.400775 ops/training.py:65 2019-01-16 21:37:08.400714: step 7552, loss = 0.69920 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:37:09.294121 ops/training.py:65 2019-01-16 21:37:09.294069: step 7553, loss = 0.69654 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:37:10.188007 ops/training.py:65 2019-01-16 21:37:10.187946: step 7554, loss = 0.69901 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:37:11.080640 ops/training.py:65 2019-01-16 21:37:11.080565: step 7555, loss = 0.70123 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:37:11.975114 ops/training.py:65 2019-01-16 21:37:11.975051: step 7556, loss = 0.69359 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:37:12.869907 ops/training.py:65 2019-01-16 21:37:12.869849: step 7557, loss = 0.69128 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:37:13.764334 ops/training.py:65 2019-01-16 21:37:13.764273: step 7558, loss = 0.69097 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:37:14.658223 ops/training.py:65 2019-01-16 21:37:14.658162: step 7559, loss = 0.68550 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:37:15.552665 ops/training.py:65 2019-01-16 21:37:15.552604: step 7560, loss = 0.69156 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:37:16.447024 ops/training.py:65 2019-01-16 21:37:16.446963: step 7561, loss = 0.69143 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:37:17.340791 ops/training.py:65 2019-01-16 21:37:17.340731: step 7562, loss = 0.69397 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:37:18.235380 ops/training.py:65 2019-01-16 21:37:18.235320: step 7563, loss = 0.69216 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:37:19.128457 ops/training.py:65 2019-01-16 21:37:19.128398: step 7564, loss = 0.69916 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:37:20.022059 ops/training.py:65 2019-01-16 21:37:20.021999: step 7565, loss = 0.69426 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:37:20.915767 ops/training.py:65 2019-01-16 21:37:20.915708: step 7566, loss = 0.69588 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:37:21.810833 ops/training.py:65 2019-01-16 21:37:21.810763: step 7567, loss = 0.69218 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:37:22.706623 ops/training.py:65 2019-01-16 21:37:22.706528: step 7568, loss = 0.69091 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:37:23.602721 ops/training.py:65 2019-01-16 21:37:23.602624: step 7569, loss = 0.69155 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:37:24.497932 ops/training.py:65 2019-01-16 21:37:24.497855: step 7570, loss = 0.68964 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:37:25.395132 ops/training.py:65 2019-01-16 21:37:25.395021: step 7571, loss = 0.69576 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:37:26.292580 ops/training.py:65 2019-01-16 21:37:26.292477: step 7572, loss = 0.69258 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:37:27.190297 ops/training.py:65 2019-01-16 21:37:27.190186: step 7573, loss = 0.69567 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:37:28.085857 ops/training.py:65 2019-01-16 21:37:28.085797: step 7574, loss = 0.69109 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:37:28.981745 ops/training.py:65 2019-01-16 21:37:28.981687: step 7575, loss = 0.69801 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:37:29.879326 ops/training.py:65 2019-01-16 21:37:29.879220: step 7576, loss = 0.69463 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:37:30.774667 ops/training.py:65 2019-01-16 21:37:30.774606: step 7577, loss = 0.69291 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:37:31.669038 ops/training.py:65 2019-01-16 21:37:31.668977: step 7578, loss = 0.69752 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:37:32.562745 ops/training.py:65 2019-01-16 21:37:32.562682: step 7579, loss = 0.69377 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:37:33.456799 ops/training.py:65 2019-01-16 21:37:33.456741: step 7580, loss = 0.69613 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:37:34.349521 ops/training.py:65 2019-01-16 21:37:34.349459: step 7581, loss = 0.69004 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 21:37:35.243442 ops/training.py:65 2019-01-16 21:37:35.243381: step 7582, loss = 0.69772 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:37:36.137367 ops/training.py:65 2019-01-16 21:37:36.137305: step 7583, loss = 0.68953 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:37:37.030773 ops/training.py:65 2019-01-16 21:37:37.030714: step 7584, loss = 0.69805 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:37:37.923569 ops/training.py:65 2019-01-16 21:37:37.923510: step 7585, loss = 0.69151 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:37:38.816094 ops/training.py:65 2019-01-16 21:37:38.816034: step 7586, loss = 0.69730 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:37:39.707835 ops/training.py:65 2019-01-16 21:37:39.707769: step 7587, loss = 0.69420 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:37:40.601582 ops/training.py:65 2019-01-16 21:37:40.601519: step 7588, loss = 0.69804 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:37:41.496172 ops/training.py:65 2019-01-16 21:37:41.496089: step 7589, loss = 0.69059 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:37:42.390610 ops/training.py:65 2019-01-16 21:37:42.390512: step 7590, loss = 0.69353 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:37:43.284439 ops/training.py:65 2019-01-16 21:37:43.284375: step 7591, loss = 0.69007 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:37:44.177726 ops/training.py:65 2019-01-16 21:37:44.177663: step 7592, loss = 0.69290 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:37:45.070876 ops/training.py:65 2019-01-16 21:37:45.070807: step 7593, loss = 0.69262 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:37:45.963290 ops/training.py:65 2019-01-16 21:37:45.963230: step 7594, loss = 0.68609 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:37:46.855953 ops/training.py:65 2019-01-16 21:37:46.855893: step 7595, loss = 0.70103 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:37:47.751311 ops/training.py:65 2019-01-16 21:37:47.751251: step 7596, loss = 0.70456 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 21:37:48.646200 ops/training.py:65 2019-01-16 21:37:48.646134: step 7597, loss = 0.68993 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:37:49.541595 ops/training.py:65 2019-01-16 21:37:49.541510: step 7598, loss = 0.69365 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:37:50.438480 ops/training.py:65 2019-01-16 21:37:50.438376: step 7599, loss = 0.69970 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:37:51.335266 ops/training.py:65 2019-01-16 21:37:51.335168: step 7600, loss = 0.69038 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:37:52.232074 ops/training.py:65 2019-01-16 21:37:52.232012: step 7601, loss = 0.69441 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:37:53.125497 ops/training.py:65 2019-01-16 21:37:53.125448: step 7602, loss = 0.69327 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:37:54.019305 ops/training.py:65 2019-01-16 21:37:54.019246: step 7603, loss = 0.70262 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 21:37:54.914706 ops/training.py:65 2019-01-16 21:37:54.914639: step 7604, loss = 0.69166 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:37:55.811722 ops/training.py:65 2019-01-16 21:37:55.811614: step 7605, loss = 0.69674 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:37:56.709030 ops/training.py:65 2019-01-16 21:37:56.708932: step 7606, loss = 0.69786 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:37:57.604363 ops/training.py:65 2019-01-16 21:37:57.604302: step 7607, loss = 0.70358 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:37:58.499163 ops/training.py:65 2019-01-16 21:37:58.499102: step 7608, loss = 0.69407 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:37:59.393348 ops/training.py:65 2019-01-16 21:37:59.393287: step 7609, loss = 0.68873 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:38:00.286555 ops/training.py:65 2019-01-16 21:38:00.286496: step 7610, loss = 0.69349 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:38:01.179284 ops/training.py:65 2019-01-16 21:38:01.179226: step 7611, loss = 0.70027 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:38:02.071935 ops/training.py:65 2019-01-16 21:38:02.071873: step 7612, loss = 0.69787 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:38:02.964882 ops/training.py:65 2019-01-16 21:38:02.964824: step 7613, loss = 0.68974 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:38:03.857893 ops/training.py:65 2019-01-16 21:38:03.857833: step 7614, loss = 0.69609 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:38:04.751941 ops/training.py:65 2019-01-16 21:38:04.751878: step 7615, loss = 0.68627 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:38:05.646455 ops/training.py:65 2019-01-16 21:38:05.646392: step 7616, loss = 0.69582 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:38:06.539249 ops/training.py:65 2019-01-16 21:38:06.539186: step 7617, loss = 0.69426 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:38:07.432589 ops/training.py:65 2019-01-16 21:38:07.432528: step 7618, loss = 0.69504 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:38:08.325666 ops/training.py:65 2019-01-16 21:38:08.325615: step 7619, loss = 0.69465 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:38:09.219213 ops/training.py:65 2019-01-16 21:38:09.219152: step 7620, loss = 0.69306 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:38:10.114446 ops/training.py:65 2019-01-16 21:38:10.114375: step 7621, loss = 0.69161 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:38:11.011256 ops/training.py:65 2019-01-16 21:38:11.011175: step 7622, loss = 0.69191 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:38:11.907211 ops/training.py:65 2019-01-16 21:38:11.907110: step 7623, loss = 0.69234 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:38:12.803419 ops/training.py:65 2019-01-16 21:38:12.803321: step 7624, loss = 0.69223 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:38:13.700448 ops/training.py:65 2019-01-16 21:38:13.700340: step 7625, loss = 0.69279 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:38:14.598072 ops/training.py:65 2019-01-16 21:38:14.597964: step 7626, loss = 0.69372 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:38:15.493835 ops/training.py:65 2019-01-16 21:38:15.493744: step 7627, loss = 0.69588 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:38:16.390408 ops/training.py:65 2019-01-16 21:38:16.390330: step 7628, loss = 0.69760 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:38:17.287294 ops/training.py:65 2019-01-16 21:38:17.287194: step 7629, loss = 0.69498 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:38:18.184149 ops/training.py:65 2019-01-16 21:38:18.184042: step 7630, loss = 0.69318 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:38:19.078811 ops/training.py:65 2019-01-16 21:38:19.078723: step 7631, loss = 0.69571 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:38:19.972580 ops/training.py:65 2019-01-16 21:38:19.972519: step 7632, loss = 0.69493 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:38:20.865454 ops/training.py:65 2019-01-16 21:38:20.865392: step 7633, loss = 0.69369 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:38:21.761795 ops/training.py:65 2019-01-16 21:38:21.761728: step 7634, loss = 0.69216 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:38:22.657773 ops/training.py:65 2019-01-16 21:38:22.657674: step 7635, loss = 0.69326 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:38:23.553155 ops/training.py:65 2019-01-16 21:38:23.553082: step 7636, loss = 0.69462 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:38:24.448385 ops/training.py:65 2019-01-16 21:38:24.448325: step 7637, loss = 0.69235 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:38:25.341745 ops/training.py:65 2019-01-16 21:38:25.341683: step 7638, loss = 0.69106 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:38:26.234773 ops/training.py:65 2019-01-16 21:38:26.234711: step 7639, loss = 0.69402 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:38:27.130858 ops/training.py:65 2019-01-16 21:38:27.130786: step 7640, loss = 0.69389 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:38:28.027817 ops/training.py:65 2019-01-16 21:38:28.027710: step 7641, loss = 0.69162 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:38:28.923472 ops/training.py:65 2019-01-16 21:38:28.923409: step 7642, loss = 0.69493 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:38:29.818596 ops/training.py:65 2019-01-16 21:38:29.818527: step 7643, loss = 0.69505 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:38:30.715233 ops/training.py:65 2019-01-16 21:38:30.715151: step 7644, loss = 0.68913 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:38:31.611511 ops/training.py:65 2019-01-16 21:38:31.611424: step 7645, loss = 0.69200 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:38:32.506864 ops/training.py:65 2019-01-16 21:38:32.506772: step 7646, loss = 0.68707 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:38:33.403325 ops/training.py:65 2019-01-16 21:38:33.403225: step 7647, loss = 0.69327 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:38:34.299945 ops/training.py:65 2019-01-16 21:38:34.299847: step 7648, loss = 0.69901 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:38:35.194161 ops/training.py:65 2019-01-16 21:38:35.194099: step 7649, loss = 0.68907 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:38:36.087975 ops/training.py:65 2019-01-16 21:38:36.087913: step 7650, loss = 0.68914 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:38:36.981852 ops/training.py:65 2019-01-16 21:38:36.981794: step 7651, loss = 0.69434 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:38:37.876056 ops/training.py:65 2019-01-16 21:38:37.876000: step 7652, loss = 0.69561 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:38:38.769847 ops/training.py:65 2019-01-16 21:38:38.769778: step 7653, loss = 0.69774 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:38:39.664891 ops/training.py:65 2019-01-16 21:38:39.664829: step 7654, loss = 0.69608 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:38:40.558731 ops/training.py:65 2019-01-16 21:38:40.558674: step 7655, loss = 0.69306 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:38:41.452684 ops/training.py:65 2019-01-16 21:38:41.452603: step 7656, loss = 0.69300 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:38:42.346944 ops/training.py:65 2019-01-16 21:38:42.346851: step 7657, loss = 0.69895 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:38:43.240562 ops/training.py:65 2019-01-16 21:38:43.240501: step 7658, loss = 0.69672 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:38:44.134069 ops/training.py:65 2019-01-16 21:38:44.134009: step 7659, loss = 0.68676 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:38:45.030060 ops/training.py:65 2019-01-16 21:38:45.029983: step 7660, loss = 0.69448 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:38:45.927353 ops/training.py:65 2019-01-16 21:38:45.927267: step 7661, loss = 0.69266 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:38:46.824707 ops/training.py:65 2019-01-16 21:38:46.824617: step 7662, loss = 0.69218 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:38:47.722517 ops/training.py:65 2019-01-16 21:38:47.722420: step 7663, loss = 0.69525 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:38:48.620670 ops/training.py:65 2019-01-16 21:38:48.620558: step 7664, loss = 0.69195 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:38:49.518122 ops/training.py:65 2019-01-16 21:38:49.518029: step 7665, loss = 0.68467 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:38:50.412330 ops/training.py:65 2019-01-16 21:38:50.412271: step 7666, loss = 0.69533 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:38:51.305715 ops/training.py:65 2019-01-16 21:38:51.305655: step 7667, loss = 0.69240 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:38:52.201893 ops/training.py:65 2019-01-16 21:38:52.201824: step 7668, loss = 0.69096 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:38:53.097320 ops/training.py:65 2019-01-16 21:38:53.097244: step 7669, loss = 0.69282 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:38:53.994775 ops/training.py:65 2019-01-16 21:38:53.994681: step 7670, loss = 0.69225 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:38:54.889413 ops/training.py:65 2019-01-16 21:38:54.889355: step 7671, loss = 0.69383 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:38:55.784281 ops/training.py:65 2019-01-16 21:38:55.784207: step 7672, loss = 0.68238 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.78125
I1280 2019-01-16 21:38:56.679322 ops/training.py:65 2019-01-16 21:38:56.679229: step 7673, loss = 0.69424 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:38:57.573041 ops/training.py:65 2019-01-16 21:38:57.572946: step 7674, loss = 0.69027 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:38:58.467753 ops/training.py:65 2019-01-16 21:38:58.467650: step 7675, loss = 0.68512 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:38:59.363430 ops/training.py:65 2019-01-16 21:38:59.363340: step 7676, loss = 0.69066 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:39:00.257694 ops/training.py:65 2019-01-16 21:39:00.257584: step 7677, loss = 0.68958 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:39:01.153363 ops/training.py:65 2019-01-16 21:39:01.153269: step 7678, loss = 0.68745 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:39:02.049244 ops/training.py:65 2019-01-16 21:39:02.049182: step 7679, loss = 0.69822 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:39:02.942664 ops/training.py:65 2019-01-16 21:39:02.942607: step 7680, loss = 0.69780 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:39:03.837174 ops/training.py:65 2019-01-16 21:39:03.837109: step 7681, loss = 0.69509 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:39:04.731021 ops/training.py:65 2019-01-16 21:39:04.730959: step 7682, loss = 0.69635 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:39:05.623132 ops/training.py:65 2019-01-16 21:39:05.623067: step 7683, loss = 0.70005 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:39:06.515653 ops/training.py:65 2019-01-16 21:39:06.515594: step 7684, loss = 0.69704 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:39:07.410286 ops/training.py:65 2019-01-16 21:39:07.410223: step 7685, loss = 0.69273 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:39:08.304258 ops/training.py:65 2019-01-16 21:39:08.304207: step 7686, loss = 0.69643 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:39:09.197981 ops/training.py:65 2019-01-16 21:39:09.197920: step 7687, loss = 0.69394 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:39:10.092214 ops/training.py:65 2019-01-16 21:39:10.092153: step 7688, loss = 0.68670 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:39:10.984748 ops/training.py:65 2019-01-16 21:39:10.984670: step 7689, loss = 0.69072 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:39:11.880142 ops/training.py:65 2019-01-16 21:39:11.880077: step 7690, loss = 0.69051 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:39:12.773390 ops/training.py:65 2019-01-16 21:39:12.773301: step 7691, loss = 0.69340 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:39:13.666582 ops/training.py:65 2019-01-16 21:39:13.666514: step 7692, loss = 0.69592 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:39:14.559868 ops/training.py:65 2019-01-16 21:39:14.559808: step 7693, loss = 0.69609 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:39:15.455659 ops/training.py:65 2019-01-16 21:39:15.455594: step 7694, loss = 0.69196 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:39:16.350937 ops/training.py:65 2019-01-16 21:39:16.350832: step 7695, loss = 0.69419 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:39:17.246996 ops/training.py:65 2019-01-16 21:39:17.246893: step 7696, loss = 0.68975 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:39:18.143096 ops/training.py:65 2019-01-16 21:39:18.142984: step 7697, loss = 0.69616 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:39:19.039735 ops/training.py:65 2019-01-16 21:39:19.039674: step 7698, loss = 0.69550 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:39:19.932901 ops/training.py:65 2019-01-16 21:39:19.932840: step 7699, loss = 0.69344 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:39:20.826156 ops/training.py:65 2019-01-16 21:39:20.826096: step 7700, loss = 0.68913 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:39:21.719846 ops/training.py:65 2019-01-16 21:39:21.719786: step 7701, loss = 0.68840 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:39:22.613982 ops/training.py:65 2019-01-16 21:39:22.613924: step 7702, loss = 0.69213 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:39:23.507307 ops/training.py:65 2019-01-16 21:39:23.507254: step 7703, loss = 0.69356 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:39:24.403066 ops/training.py:65 2019-01-16 21:39:24.402997: step 7704, loss = 0.69952 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:39:25.300080 ops/training.py:65 2019-01-16 21:39:25.299967: step 7705, loss = 0.69085 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:39:26.195393 ops/training.py:65 2019-01-16 21:39:26.195304: step 7706, loss = 0.69601 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:39:27.090807 ops/training.py:65 2019-01-16 21:39:27.090709: step 7707, loss = 0.69802 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:39:27.986915 ops/training.py:65 2019-01-16 21:39:27.986818: step 7708, loss = 0.69265 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:39:28.882858 ops/training.py:65 2019-01-16 21:39:28.882752: step 7709, loss = 0.69223 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:39:29.780539 ops/training.py:65 2019-01-16 21:39:29.780461: step 7710, loss = 0.70296 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:39:30.677676 ops/training.py:65 2019-01-16 21:39:30.677568: step 7711, loss = 0.69935 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:39:31.573886 ops/training.py:65 2019-01-16 21:39:31.573784: step 7712, loss = 0.69126 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:39:32.468475 ops/training.py:65 2019-01-16 21:39:32.468417: step 7713, loss = 0.68561 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:39:33.361669 ops/training.py:65 2019-01-16 21:39:33.361605: step 7714, loss = 0.69578 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:39:34.257703 ops/training.py:65 2019-01-16 21:39:34.257626: step 7715, loss = 0.69203 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:39:35.160522 ops/training.py:65 2019-01-16 21:39:35.160410: step 7716, loss = 0.69981 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:39:36.058529 ops/training.py:65 2019-01-16 21:39:36.058438: step 7717, loss = 0.69171 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:39:36.956023 ops/training.py:65 2019-01-16 21:39:36.955951: step 7718, loss = 0.69282 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:39:37.851774 ops/training.py:65 2019-01-16 21:39:37.851675: step 7719, loss = 0.68563 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:39:38.747734 ops/training.py:65 2019-01-16 21:39:38.747663: step 7720, loss = 0.69316 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:39:39.643056 ops/training.py:65 2019-01-16 21:39:39.642980: step 7721, loss = 0.69486 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:39:40.539391 ops/training.py:65 2019-01-16 21:39:40.539289: step 7722, loss = 0.69912 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:39:41.435079 ops/training.py:65 2019-01-16 21:39:41.434999: step 7723, loss = 0.70162 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:39:42.330198 ops/training.py:65 2019-01-16 21:39:42.330130: step 7724, loss = 0.68873 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:39:43.226021 ops/training.py:65 2019-01-16 21:39:43.225930: step 7725, loss = 0.68696 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:39:44.121479 ops/training.py:65 2019-01-16 21:39:44.121391: step 7726, loss = 0.69493 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:39:45.017068 ops/training.py:65 2019-01-16 21:39:45.016975: step 7727, loss = 0.68695 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:39:45.913809 ops/training.py:65 2019-01-16 21:39:45.913705: step 7728, loss = 0.68802 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:39:46.807896 ops/training.py:65 2019-01-16 21:39:46.807798: step 7729, loss = 0.69473 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:39:47.704414 ops/training.py:65 2019-01-16 21:39:47.704337: step 7730, loss = 0.69390 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:39:48.600988 ops/training.py:65 2019-01-16 21:39:48.600889: step 7731, loss = 0.69536 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:39:49.497359 ops/training.py:65 2019-01-16 21:39:49.497264: step 7732, loss = 0.69190 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:39:50.390773 ops/training.py:65 2019-01-16 21:39:50.390706: step 7733, loss = 0.69522 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:39:51.286075 ops/training.py:65 2019-01-16 21:39:51.285989: step 7734, loss = 0.69561 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:39:52.180759 ops/training.py:65 2019-01-16 21:39:52.180695: step 7735, loss = 0.68765 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:39:53.073799 ops/training.py:65 2019-01-16 21:39:53.073741: step 7736, loss = 0.69005 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:39:53.965768 ops/training.py:65 2019-01-16 21:39:53.965711: step 7737, loss = 0.68860 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:39:54.858318 ops/training.py:65 2019-01-16 21:39:54.858257: step 7738, loss = 0.69659 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:39:55.751640 ops/training.py:65 2019-01-16 21:39:55.751579: step 7739, loss = 0.69449 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:39:56.643655 ops/training.py:65 2019-01-16 21:39:56.643591: step 7740, loss = 0.68655 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:39:57.541262 ops/training.py:65 2019-01-16 21:39:57.541191: step 7741, loss = 0.69559 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:39:58.438346 ops/training.py:65 2019-01-16 21:39:58.438238: step 7742, loss = 0.69732 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:39:59.333689 ops/training.py:65 2019-01-16 21:39:59.333630: step 7743, loss = 0.69624 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:40:00.227393 ops/training.py:65 2019-01-16 21:40:00.227333: step 7744, loss = 0.68871 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:40:01.120366 ops/training.py:65 2019-01-16 21:40:01.120310: step 7745, loss = 0.69607 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:40:02.012840 ops/training.py:65 2019-01-16 21:40:02.012768: step 7746, loss = 0.68628 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:40:02.905287 ops/training.py:65 2019-01-16 21:40:02.905219: step 7747, loss = 0.69421 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:40:03.798160 ops/training.py:65 2019-01-16 21:40:03.798091: step 7748, loss = 0.69020 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:40:04.693536 ops/training.py:65 2019-01-16 21:40:04.693457: step 7749, loss = 0.69663 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:40:05.590656 ops/training.py:65 2019-01-16 21:40:05.590547: step 7750, loss = 0.69135 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:40:06.486168 ops/training.py:65 2019-01-16 21:40:06.486067: step 7751, loss = 0.68817 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:40:07.383234 ops/training.py:65 2019-01-16 21:40:07.383168: step 7752, loss = 0.70637 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:40:08.280884 ops/training.py:65 2019-01-16 21:40:08.280803: step 7753, loss = 0.68750 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:40:09.177490 ops/training.py:65 2019-01-16 21:40:09.177387: step 7754, loss = 0.68534 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:40:10.073209 ops/training.py:65 2019-01-16 21:40:10.073117: step 7755, loss = 0.69724 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:40:10.968398 ops/training.py:65 2019-01-16 21:40:10.968294: step 7756, loss = 0.69789 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:40:11.864765 ops/training.py:65 2019-01-16 21:40:11.864664: step 7757, loss = 0.68934 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:40:12.761615 ops/training.py:65 2019-01-16 21:40:12.761520: step 7758, loss = 0.69884 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:40:13.660645 ops/training.py:65 2019-01-16 21:40:13.660541: step 7759, loss = 0.69612 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:40:14.555802 ops/training.py:65 2019-01-16 21:40:14.555740: step 7760, loss = 0.68366 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:40:15.450150 ops/training.py:65 2019-01-16 21:40:15.450085: step 7761, loss = 0.70480 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:40:16.343133 ops/training.py:65 2019-01-16 21:40:16.343065: step 7762, loss = 0.69191 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:40:17.237639 ops/training.py:65 2019-01-16 21:40:17.237518: step 7763, loss = 0.69780 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:40:18.132496 ops/training.py:65 2019-01-16 21:40:18.132433: step 7764, loss = 0.68902 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:40:19.025299 ops/training.py:65 2019-01-16 21:40:19.025241: step 7765, loss = 0.69110 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:40:19.919314 ops/training.py:65 2019-01-16 21:40:19.919253: step 7766, loss = 0.69273 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:40:20.812553 ops/training.py:65 2019-01-16 21:40:20.812495: step 7767, loss = 0.69564 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:40:21.708415 ops/training.py:65 2019-01-16 21:40:21.708364: step 7768, loss = 0.68727 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:40:22.603997 ops/training.py:65 2019-01-16 21:40:22.603907: step 7769, loss = 0.69379 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:40:23.500234 ops/training.py:65 2019-01-16 21:40:23.500160: step 7770, loss = 0.69512 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:40:24.396949 ops/training.py:65 2019-01-16 21:40:24.396841: step 7771, loss = 0.69459 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:40:25.292916 ops/training.py:65 2019-01-16 21:40:25.292835: step 7772, loss = 0.70988 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.21875
I1280 2019-01-16 21:40:26.187514 ops/training.py:65 2019-01-16 21:40:26.187452: step 7773, loss = 0.68582 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:40:27.080102 ops/training.py:65 2019-01-16 21:40:27.080044: step 7774, loss = 0.68947 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:40:27.973381 ops/training.py:65 2019-01-16 21:40:27.973326: step 7775, loss = 0.69559 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:40:28.870422 ops/training.py:65 2019-01-16 21:40:28.870381: step 7776, loss = 0.69722 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:40:29.766122 ops/training.py:65 2019-01-16 21:40:29.766051: step 7777, loss = 0.69477 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:40:30.661573 ops/training.py:65 2019-01-16 21:40:30.661477: step 7778, loss = 0.69309 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:40:31.557537 ops/training.py:65 2019-01-16 21:40:31.557441: step 7779, loss = 0.68285 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 21:40:32.454338 ops/training.py:65 2019-01-16 21:40:32.454244: step 7780, loss = 0.69107 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:40:33.351425 ops/training.py:65 2019-01-16 21:40:33.351316: step 7781, loss = 0.68228 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:40:34.247421 ops/training.py:65 2019-01-16 21:40:34.247351: step 7782, loss = 0.69539 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:40:35.142097 ops/training.py:65 2019-01-16 21:40:35.142006: step 7783, loss = 0.69961 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:40:36.038677 ops/training.py:65 2019-01-16 21:40:36.038571: step 7784, loss = 0.69117 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:40:36.933950 ops/training.py:65 2019-01-16 21:40:36.933890: step 7785, loss = 0.69422 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:40:37.826734 ops/training.py:65 2019-01-16 21:40:37.826672: step 7786, loss = 0.69673 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:40:38.719794 ops/training.py:65 2019-01-16 21:40:38.719743: step 7787, loss = 0.68975 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:40:39.612670 ops/training.py:65 2019-01-16 21:40:39.612604: step 7788, loss = 0.69976 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:40:40.506637 ops/training.py:65 2019-01-16 21:40:40.506566: step 7789, loss = 0.69153 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:40:41.401979 ops/training.py:65 2019-01-16 21:40:41.401904: step 7790, loss = 0.68874 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:40:42.298422 ops/training.py:65 2019-01-16 21:40:42.298341: step 7791, loss = 0.68418 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:40:43.193414 ops/training.py:65 2019-01-16 21:40:43.193310: step 7792, loss = 0.69371 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:40:44.090687 ops/training.py:65 2019-01-16 21:40:44.090589: step 7793, loss = 0.69207 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:40:44.985879 ops/training.py:65 2019-01-16 21:40:44.985812: step 7794, loss = 0.69430 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:40:45.881614 ops/training.py:65 2019-01-16 21:40:45.881509: step 7795, loss = 0.69716 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:40:46.778116 ops/training.py:65 2019-01-16 21:40:46.778012: step 7796, loss = 0.68811 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:40:47.671927 ops/training.py:65 2019-01-16 21:40:47.671820: step 7797, loss = 0.69079 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:40:48.567049 ops/training.py:65 2019-01-16 21:40:48.566982: step 7798, loss = 0.68278 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:40:49.460651 ops/training.py:65 2019-01-16 21:40:49.460585: step 7799, loss = 0.69530 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:40:50.353333 ops/training.py:65 2019-01-16 21:40:50.353272: step 7800, loss = 0.70110 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:40:51.246335 ops/training.py:65 2019-01-16 21:40:51.246276: step 7801, loss = 0.69322 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:40:52.139743 ops/training.py:65 2019-01-16 21:40:52.139677: step 7802, loss = 0.69487 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:40:53.032222 ops/training.py:65 2019-01-16 21:40:53.032162: step 7803, loss = 0.70929 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 21:40:53.926000 ops/training.py:65 2019-01-16 21:40:53.925942: step 7804, loss = 0.69406 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:40:54.818886 ops/training.py:65 2019-01-16 21:40:54.818825: step 7805, loss = 0.69456 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:40:55.712836 ops/training.py:65 2019-01-16 21:40:55.712774: step 7806, loss = 0.69868 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:40:56.605017 ops/training.py:65 2019-01-16 21:40:56.604953: step 7807, loss = 0.68601 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:40:57.497872 ops/training.py:65 2019-01-16 21:40:57.497809: step 7808, loss = 0.68859 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:40:58.390414 ops/training.py:65 2019-01-16 21:40:58.390355: step 7809, loss = 0.69974 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:40:59.286463 ops/training.py:65 2019-01-16 21:40:59.286418: step 7810, loss = 0.69191 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:41:00.181691 ops/training.py:65 2019-01-16 21:41:00.181601: step 7811, loss = 0.68733 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:41:01.078419 ops/training.py:65 2019-01-16 21:41:01.078326: step 7812, loss = 0.68750 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:41:01.973048 ops/training.py:65 2019-01-16 21:41:01.972952: step 7813, loss = 0.69927 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:41:02.871184 ops/training.py:65 2019-01-16 21:41:02.871128: step 7814, loss = 0.68123 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:41:03.767532 ops/training.py:65 2019-01-16 21:41:03.767431: step 7815, loss = 0.69064 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:41:04.666704 ops/training.py:65 2019-01-16 21:41:04.666624: step 7816, loss = 0.68959 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:41:05.563247 ops/training.py:65 2019-01-16 21:41:05.563153: step 7817, loss = 0.69742 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:41:06.458473 ops/training.py:65 2019-01-16 21:41:06.458372: step 7818, loss = 0.69514 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:41:07.353317 ops/training.py:65 2019-01-16 21:41:07.353214: step 7819, loss = 0.69131 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:41:08.247987 ops/training.py:65 2019-01-16 21:41:08.247937: step 7820, loss = 0.68483 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:41:09.140184 ops/training.py:65 2019-01-16 21:41:09.140120: step 7821, loss = 0.69682 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:41:10.033108 ops/training.py:65 2019-01-16 21:41:10.033039: step 7822, loss = 0.67860 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 21:41:10.925705 ops/training.py:65 2019-01-16 21:41:10.925642: step 7823, loss = 0.69799 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:41:11.818428 ops/training.py:65 2019-01-16 21:41:11.818352: step 7824, loss = 0.69403 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:41:12.714377 ops/training.py:65 2019-01-16 21:41:12.714282: step 7825, loss = 0.68916 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:41:13.611632 ops/training.py:65 2019-01-16 21:41:13.611528: step 7826, loss = 0.68912 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:41:14.505913 ops/training.py:65 2019-01-16 21:41:14.505820: step 7827, loss = 0.67755 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.78125
I1280 2019-01-16 21:41:15.400386 ops/training.py:65 2019-01-16 21:41:15.400326: step 7828, loss = 0.68725 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:41:16.293311 ops/training.py:65 2019-01-16 21:41:16.293251: step 7829, loss = 0.69941 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:41:17.186986 ops/training.py:65 2019-01-16 21:41:17.186916: step 7830, loss = 0.69742 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:41:18.083052 ops/training.py:65 2019-01-16 21:41:18.082982: step 7831, loss = 0.69581 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:41:18.982634 ops/training.py:65 2019-01-16 21:41:18.982529: step 7832, loss = 0.69605 (35.6 examples/sec; 0.899 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:41:19.879653 ops/training.py:65 2019-01-16 21:41:19.879541: step 7833, loss = 0.69694 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:41:20.774662 ops/training.py:65 2019-01-16 21:41:20.774599: step 7834, loss = 0.69770 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:41:21.667900 ops/training.py:65 2019-01-16 21:41:21.667842: step 7835, loss = 0.70174 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:41:22.561567 ops/training.py:65 2019-01-16 21:41:22.561509: step 7836, loss = 0.69176 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:41:23.454164 ops/training.py:65 2019-01-16 21:41:23.454112: step 7837, loss = 0.69511 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:41:24.349518 ops/training.py:65 2019-01-16 21:41:24.349433: step 7838, loss = 0.69228 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:41:25.245271 ops/training.py:65 2019-01-16 21:41:25.245167: step 7839, loss = 0.69647 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:41:26.141663 ops/training.py:65 2019-01-16 21:41:26.141570: step 7840, loss = 0.69516 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:41:27.036044 ops/training.py:65 2019-01-16 21:41:27.035984: step 7841, loss = 0.69179 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:41:27.930935 ops/training.py:65 2019-01-16 21:41:27.930870: step 7842, loss = 0.69248 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:41:28.824340 ops/training.py:65 2019-01-16 21:41:28.824283: step 7843, loss = 0.69027 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:41:29.720723 ops/training.py:65 2019-01-16 21:41:29.720638: step 7844, loss = 0.69522 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:41:30.616332 ops/training.py:65 2019-01-16 21:41:30.616230: step 7845, loss = 0.69502 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:41:31.513200 ops/training.py:65 2019-01-16 21:41:31.513106: step 7846, loss = 0.69732 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:41:32.410224 ops/training.py:65 2019-01-16 21:41:32.410130: step 7847, loss = 0.68949 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:41:33.307333 ops/training.py:65 2019-01-16 21:41:33.307226: step 7848, loss = 0.69369 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:41:34.202517 ops/training.py:65 2019-01-16 21:41:34.202455: step 7849, loss = 0.69496 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:41:35.095198 ops/training.py:65 2019-01-16 21:41:35.095134: step 7850, loss = 0.69269 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:41:35.989762 ops/training.py:65 2019-01-16 21:41:35.989694: step 7851, loss = 0.69209 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:41:36.884785 ops/training.py:65 2019-01-16 21:41:36.884727: step 7852, loss = 0.69815 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:41:37.777053 ops/training.py:65 2019-01-16 21:41:37.776992: step 7853, loss = 0.69590 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:41:38.669701 ops/training.py:65 2019-01-16 21:41:38.669650: step 7854, loss = 0.69236 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:41:39.562726 ops/training.py:65 2019-01-16 21:41:39.562668: step 7855, loss = 0.70089 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:41:40.455454 ops/training.py:65 2019-01-16 21:41:40.455399: step 7856, loss = 0.69640 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:41:41.347570 ops/training.py:65 2019-01-16 21:41:41.347497: step 7857, loss = 0.69359 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:41:42.240899 ops/training.py:65 2019-01-16 21:41:42.240837: step 7858, loss = 0.69637 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:41:43.133680 ops/training.py:65 2019-01-16 21:41:43.133622: step 7859, loss = 0.70061 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:41:44.027410 ops/training.py:65 2019-01-16 21:41:44.027350: step 7860, loss = 0.68433 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:41:44.920187 ops/training.py:65 2019-01-16 21:41:44.920128: step 7861, loss = 0.69227 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:41:45.816799 ops/training.py:65 2019-01-16 21:41:45.816726: step 7862, loss = 0.70190 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:41:46.714525 ops/training.py:65 2019-01-16 21:41:46.714420: step 7863, loss = 0.68761 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:41:47.610682 ops/training.py:65 2019-01-16 21:41:47.610572: step 7864, loss = 0.69602 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:41:48.505792 ops/training.py:65 2019-01-16 21:41:48.505727: step 7865, loss = 0.68527 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:41:49.398186 ops/training.py:65 2019-01-16 21:41:49.398129: step 7866, loss = 0.69825 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:41:50.291067 ops/training.py:65 2019-01-16 21:41:50.291003: step 7867, loss = 0.69557 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:41:51.184001 ops/training.py:65 2019-01-16 21:41:51.183942: step 7868, loss = 0.69215 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:41:52.077423 ops/training.py:65 2019-01-16 21:41:52.077362: step 7869, loss = 0.69604 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:41:52.971985 ops/training.py:65 2019-01-16 21:41:52.971922: step 7870, loss = 0.68808 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:41:53.870656 ops/training.py:65 2019-01-16 21:41:53.870556: step 7871, loss = 0.68343 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:41:54.768576 ops/training.py:65 2019-01-16 21:41:54.768470: step 7872, loss = 0.69762 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:41:55.665466 ops/training.py:65 2019-01-16 21:41:55.665399: step 7873, loss = 0.69428 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:41:56.562415 ops/training.py:65 2019-01-16 21:41:56.562324: step 7874, loss = 0.68440 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:41:57.459777 ops/training.py:65 2019-01-16 21:41:57.459672: step 7875, loss = 0.70077 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:41:58.357018 ops/training.py:65 2019-01-16 21:41:58.356943: step 7876, loss = 0.70072 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:41:59.253328 ops/training.py:65 2019-01-16 21:41:59.253224: step 7877, loss = 0.69574 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:42:00.149065 ops/training.py:65 2019-01-16 21:42:00.148958: step 7878, loss = 0.69723 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:42:01.042995 ops/training.py:65 2019-01-16 21:42:01.042940: step 7879, loss = 0.69973 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:42:01.938810 ops/training.py:65 2019-01-16 21:42:01.938752: step 7880, loss = 0.69753 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:42:02.835345 ops/training.py:65 2019-01-16 21:42:02.835255: step 7881, loss = 0.69299 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:42:03.731169 ops/training.py:65 2019-01-16 21:42:03.731069: step 7882, loss = 0.69870 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:42:04.627194 ops/training.py:65 2019-01-16 21:42:04.627134: step 7883, loss = 0.69437 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:42:05.524724 ops/training.py:65 2019-01-16 21:42:05.524665: step 7884, loss = 0.68990 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:42:06.420976 ops/training.py:65 2019-01-16 21:42:06.420871: step 7885, loss = 0.69358 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:42:07.317110 ops/training.py:65 2019-01-16 21:42:07.317053: step 7886, loss = 0.69912 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:42:08.210318 ops/training.py:65 2019-01-16 21:42:08.210255: step 7887, loss = 0.69328 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:42:09.103009 ops/training.py:65 2019-01-16 21:42:09.102950: step 7888, loss = 0.69429 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:42:09.995003 ops/training.py:65 2019-01-16 21:42:09.994943: step 7889, loss = 0.69466 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:42:10.888637 ops/training.py:65 2019-01-16 21:42:10.888577: step 7890, loss = 0.69068 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:42:11.785799 ops/training.py:65 2019-01-16 21:42:11.785728: step 7891, loss = 0.68727 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:42:12.682407 ops/training.py:65 2019-01-16 21:42:12.682324: step 7892, loss = 0.69671 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:42:13.578178 ops/training.py:65 2019-01-16 21:42:13.578078: step 7893, loss = 0.68922 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:42:14.473704 ops/training.py:65 2019-01-16 21:42:14.473604: step 7894, loss = 0.69390 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:42:15.369138 ops/training.py:65 2019-01-16 21:42:15.369068: step 7895, loss = 0.70049 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:42:16.264298 ops/training.py:65 2019-01-16 21:42:16.264227: step 7896, loss = 0.69279 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:42:17.162498 ops/training.py:65 2019-01-16 21:42:17.162414: step 7897, loss = 0.69346 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:42:18.059675 ops/training.py:65 2019-01-16 21:42:18.059575: step 7898, loss = 0.68896 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:42:18.953899 ops/training.py:65 2019-01-16 21:42:18.953831: step 7899, loss = 0.69439 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:42:19.847481 ops/training.py:65 2019-01-16 21:42:19.847421: step 7900, loss = 0.69343 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:42:20.740588 ops/training.py:65 2019-01-16 21:42:20.740528: step 7901, loss = 0.69487 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:42:21.633660 ops/training.py:65 2019-01-16 21:42:21.633596: step 7902, loss = 0.69463 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:42:22.526461 ops/training.py:65 2019-01-16 21:42:22.526400: step 7903, loss = 0.69138 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:42:23.420408 ops/training.py:65 2019-01-16 21:42:23.420361: step 7904, loss = 0.69269 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:42:24.313503 ops/training.py:65 2019-01-16 21:42:24.313444: step 7905, loss = 0.69069 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:42:25.206830 ops/training.py:65 2019-01-16 21:42:25.206768: step 7906, loss = 0.69318 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:42:26.102217 ops/training.py:65 2019-01-16 21:42:26.102155: step 7907, loss = 0.69381 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:42:26.995510 ops/training.py:65 2019-01-16 21:42:26.995440: step 7908, loss = 0.69241 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:42:27.889013 ops/training.py:65 2019-01-16 21:42:27.888953: step 7909, loss = 0.69057 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:42:28.782718 ops/training.py:65 2019-01-16 21:42:28.782657: step 7910, loss = 0.69372 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:42:29.675532 ops/training.py:65 2019-01-16 21:42:29.675468: step 7911, loss = 0.69538 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:42:30.569440 ops/training.py:65 2019-01-16 21:42:30.569382: step 7912, loss = 0.69023 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:42:31.464825 ops/training.py:65 2019-01-16 21:42:31.464758: step 7913, loss = 0.69334 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:42:32.360266 ops/training.py:65 2019-01-16 21:42:32.360170: step 7914, loss = 0.69267 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:42:33.256359 ops/training.py:65 2019-01-16 21:42:33.256251: step 7915, loss = 0.69406 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:42:34.151515 ops/training.py:65 2019-01-16 21:42:34.151456: step 7916, loss = 0.69492 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:42:35.044295 ops/training.py:65 2019-01-16 21:42:35.044235: step 7917, loss = 0.69259 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:42:35.936913 ops/training.py:65 2019-01-16 21:42:35.936856: step 7918, loss = 0.69087 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:42:36.829958 ops/training.py:65 2019-01-16 21:42:36.829893: step 7919, loss = 0.69563 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:42:37.722766 ops/training.py:65 2019-01-16 21:42:37.722703: step 7920, loss = 0.68937 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:42:38.615561 ops/training.py:65 2019-01-16 21:42:38.615509: step 7921, loss = 0.69780 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:42:39.508192 ops/training.py:65 2019-01-16 21:42:39.508125: step 7922, loss = 0.69497 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:42:40.403682 ops/training.py:65 2019-01-16 21:42:40.403616: step 7923, loss = 0.69076 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:42:41.300542 ops/training.py:65 2019-01-16 21:42:41.300457: step 7924, loss = 0.69614 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:42:42.195457 ops/training.py:65 2019-01-16 21:42:42.195357: step 7925, loss = 0.69747 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:42:43.088763 ops/training.py:65 2019-01-16 21:42:43.088695: step 7926, loss = 0.69384 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:42:43.981965 ops/training.py:65 2019-01-16 21:42:43.981898: step 7927, loss = 0.69107 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:42:44.873721 ops/training.py:65 2019-01-16 21:42:44.873658: step 7928, loss = 0.69331 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:42:45.766439 ops/training.py:65 2019-01-16 21:42:45.766366: step 7929, loss = 0.69585 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:42:46.662977 ops/training.py:65 2019-01-16 21:42:46.662905: step 7930, loss = 0.69031 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:42:47.558119 ops/training.py:65 2019-01-16 21:42:47.558024: step 7931, loss = 0.68780 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:42:48.454759 ops/training.py:65 2019-01-16 21:42:48.454651: step 7932, loss = 0.69405 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:42:49.349453 ops/training.py:65 2019-01-16 21:42:49.349348: step 7933, loss = 0.69835 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:42:50.244248 ops/training.py:65 2019-01-16 21:42:50.244189: step 7934, loss = 0.68720 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:42:51.137620 ops/training.py:65 2019-01-16 21:42:51.137558: step 7935, loss = 0.68986 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:42:52.031157 ops/training.py:65 2019-01-16 21:42:52.031094: step 7936, loss = 0.69391 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:42:52.927019 ops/training.py:65 2019-01-16 21:42:52.926952: step 7937, loss = 0.69181 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:42:53.823553 ops/training.py:65 2019-01-16 21:42:53.823461: step 7938, loss = 0.68861 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:42:54.719203 ops/training.py:65 2019-01-16 21:42:54.719140: step 7939, loss = 0.69501 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:42:55.613070 ops/training.py:65 2019-01-16 21:42:55.613006: step 7940, loss = 0.69294 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:42:56.509749 ops/training.py:65 2019-01-16 21:42:56.509677: step 7941, loss = 0.69024 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:42:57.405767 ops/training.py:65 2019-01-16 21:42:57.405665: step 7942, loss = 0.69624 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:42:58.302318 ops/training.py:65 2019-01-16 21:42:58.302221: step 7943, loss = 0.69401 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:42:59.196886 ops/training.py:65 2019-01-16 21:42:59.196825: step 7944, loss = 0.69705 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:43:00.090240 ops/training.py:65 2019-01-16 21:43:00.090177: step 7945, loss = 0.69142 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:43:00.982319 ops/training.py:65 2019-01-16 21:43:00.982249: step 7946, loss = 0.69996 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:43:01.875410 ops/training.py:65 2019-01-16 21:43:01.875347: step 7947, loss = 0.69729 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:43:02.770632 ops/training.py:65 2019-01-16 21:43:02.770565: step 7948, loss = 0.69019 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:43:03.667151 ops/training.py:65 2019-01-16 21:43:03.667045: step 7949, loss = 0.69463 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:43:04.563115 ops/training.py:65 2019-01-16 21:43:04.563014: step 7950, loss = 0.69456 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:43:05.459380 ops/training.py:65 2019-01-16 21:43:05.459279: step 7951, loss = 0.69367 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:43:06.355734 ops/training.py:65 2019-01-16 21:43:06.355631: step 7952, loss = 0.69407 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:43:07.252151 ops/training.py:65 2019-01-16 21:43:07.252045: step 7953, loss = 0.69849 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:43:08.150363 ops/training.py:65 2019-01-16 21:43:08.150256: step 7954, loss = 0.69858 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:43:09.048126 ops/training.py:65 2019-01-16 21:43:09.048043: step 7955, loss = 0.69066 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:43:09.942428 ops/training.py:65 2019-01-16 21:43:09.942368: step 7956, loss = 0.69957 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:43:10.835714 ops/training.py:65 2019-01-16 21:43:10.835657: step 7957, loss = 0.69739 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:43:11.729651 ops/training.py:65 2019-01-16 21:43:11.729573: step 7958, loss = 0.69892 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:43:12.624782 ops/training.py:65 2019-01-16 21:43:12.624680: step 7959, loss = 0.69184 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:43:13.519235 ops/training.py:65 2019-01-16 21:43:13.519169: step 7960, loss = 0.68700 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:43:14.412407 ops/training.py:65 2019-01-16 21:43:14.412344: step 7961, loss = 0.69934 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:43:15.305415 ops/training.py:65 2019-01-16 21:43:15.305354: step 7962, loss = 0.68815 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:43:16.198713 ops/training.py:65 2019-01-16 21:43:16.198652: step 7963, loss = 0.69135 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:43:17.092466 ops/training.py:65 2019-01-16 21:43:17.092403: step 7964, loss = 0.69614 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:43:17.984944 ops/training.py:65 2019-01-16 21:43:17.984886: step 7965, loss = 0.69192 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:43:18.877955 ops/training.py:65 2019-01-16 21:43:18.877886: step 7966, loss = 0.69580 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:43:19.771589 ops/training.py:65 2019-01-16 21:43:19.771530: step 7967, loss = 0.69038 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:43:20.665532 ops/training.py:65 2019-01-16 21:43:20.665473: step 7968, loss = 0.68807 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:43:21.560598 ops/training.py:65 2019-01-16 21:43:21.560563: step 7969, loss = 0.69969 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:43:22.456150 ops/training.py:65 2019-01-16 21:43:22.456056: step 7970, loss = 0.69678 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:43:23.352714 ops/training.py:65 2019-01-16 21:43:23.352644: step 7971, loss = 0.68530 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 21:43:24.250136 ops/training.py:65 2019-01-16 21:43:24.250056: step 7972, loss = 0.70318 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:43:25.146463 ops/training.py:65 2019-01-16 21:43:25.146365: step 7973, loss = 0.69664 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:43:26.042566 ops/training.py:65 2019-01-16 21:43:26.042467: step 7974, loss = 0.69056 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:43:26.938117 ops/training.py:65 2019-01-16 21:43:26.938014: step 7975, loss = 0.69643 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:43:27.833106 ops/training.py:65 2019-01-16 21:43:27.833004: step 7976, loss = 0.69819 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:43:28.730599 ops/training.py:65 2019-01-16 21:43:28.730492: step 7977, loss = 0.69748 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:43:29.626524 ops/training.py:65 2019-01-16 21:43:29.626419: step 7978, loss = 0.69994 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:43:30.521885 ops/training.py:65 2019-01-16 21:43:30.521823: step 7979, loss = 0.69550 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:43:31.416416 ops/training.py:65 2019-01-16 21:43:31.416355: step 7980, loss = 0.68261 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:43:32.309944 ops/training.py:65 2019-01-16 21:43:32.309883: step 7981, loss = 0.68940 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:43:33.203264 ops/training.py:65 2019-01-16 21:43:33.203204: step 7982, loss = 0.70089 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:43:34.096393 ops/training.py:65 2019-01-16 21:43:34.096330: step 7983, loss = 0.69417 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:43:34.989657 ops/training.py:65 2019-01-16 21:43:34.989595: step 7984, loss = 0.70360 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:43:35.883625 ops/training.py:65 2019-01-16 21:43:35.883562: step 7985, loss = 0.69873 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:43:36.779144 ops/training.py:65 2019-01-16 21:43:36.779072: step 7986, loss = 0.69338 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:43:37.675157 ops/training.py:65 2019-01-16 21:43:37.675058: step 7987, loss = 0.69579 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:43:38.573470 ops/training.py:65 2019-01-16 21:43:38.573387: step 7988, loss = 0.69514 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:43:39.472976 ops/training.py:65 2019-01-16 21:43:39.472869: step 7989, loss = 0.70336 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:43:40.368649 ops/training.py:65 2019-01-16 21:43:40.368592: step 7990, loss = 0.68924 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:43:41.261709 ops/training.py:65 2019-01-16 21:43:41.261633: step 7991, loss = 0.68693 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:43:42.156179 ops/training.py:65 2019-01-16 21:43:42.156116: step 7992, loss = 0.69727 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:43:43.052866 ops/training.py:65 2019-01-16 21:43:43.052763: step 7993, loss = 0.69356 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:43:43.951150 ops/training.py:65 2019-01-16 21:43:43.951045: step 7994, loss = 0.69365 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:43:44.846351 ops/training.py:65 2019-01-16 21:43:44.846261: step 7995, loss = 0.69019 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:43:45.741988 ops/training.py:65 2019-01-16 21:43:45.741919: step 7996, loss = 0.69156 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:43:46.638636 ops/training.py:65 2019-01-16 21:43:46.638538: step 7997, loss = 0.68945 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:43:47.535921 ops/training.py:65 2019-01-16 21:43:47.535854: step 7998, loss = 0.70161 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:43:48.432829 ops/training.py:65 2019-01-16 21:43:48.432731: step 7999, loss = 0.68976 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:48:03.430207 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I1280 2019-01-16 21:48:03.431185 ops/training.py:41 2019-01-16 21:48:03.431126: step 8000, loss = 0.69 (0.1 examples/sec; 254.102 sec/batch) | Training accuracy = 0.53125 | Validation accuracy = 0.50835 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_19_26_22_049623
I1280 2019-01-16 21:48:04.357456 ops/training.py:65 2019-01-16 21:48:04.357404: step 8001, loss = 0.69701 (34.6 examples/sec; 0.925 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:48:05.253005 ops/training.py:65 2019-01-16 21:48:05.252946: step 8002, loss = 0.70068 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:48:06.149914 ops/training.py:65 2019-01-16 21:48:06.149809: step 8003, loss = 0.68799 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:48:07.047131 ops/training.py:65 2019-01-16 21:48:07.047029: step 8004, loss = 0.68772 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:48:07.942673 ops/training.py:65 2019-01-16 21:48:07.942582: step 8005, loss = 0.68343 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:48:08.838260 ops/training.py:65 2019-01-16 21:48:08.838183: step 8006, loss = 0.69061 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:48:09.736864 ops/training.py:65 2019-01-16 21:48:09.736766: step 8007, loss = 0.68622 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:48:10.633995 ops/training.py:65 2019-01-16 21:48:10.633899: step 8008, loss = 0.69092 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:48:11.529663 ops/training.py:65 2019-01-16 21:48:11.529583: step 8009, loss = 0.69639 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:48:12.427065 ops/training.py:65 2019-01-16 21:48:12.426973: step 8010, loss = 0.69139 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:48:13.321596 ops/training.py:65 2019-01-16 21:48:13.321511: step 8011, loss = 0.68821 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:48:14.217467 ops/training.py:65 2019-01-16 21:48:14.217397: step 8012, loss = 0.69627 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:48:15.113780 ops/training.py:65 2019-01-16 21:48:15.113707: step 8013, loss = 0.69210 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:48:16.009238 ops/training.py:65 2019-01-16 21:48:16.009169: step 8014, loss = 0.69578 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:48:16.903960 ops/training.py:65 2019-01-16 21:48:16.903880: step 8015, loss = 0.69153 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:48:17.798192 ops/training.py:65 2019-01-16 21:48:17.798092: step 8016, loss = 0.68797 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:48:18.694074 ops/training.py:65 2019-01-16 21:48:18.693972: step 8017, loss = 0.69489 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:48:19.588920 ops/training.py:65 2019-01-16 21:48:19.588849: step 8018, loss = 0.68850 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:48:20.482659 ops/training.py:65 2019-01-16 21:48:20.482591: step 8019, loss = 0.69170 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:48:21.376954 ops/training.py:65 2019-01-16 21:48:21.376888: step 8020, loss = 0.68640 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:48:22.269292 ops/training.py:65 2019-01-16 21:48:22.269234: step 8021, loss = 0.69101 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:48:23.162069 ops/training.py:65 2019-01-16 21:48:23.161997: step 8022, loss = 0.69739 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:48:24.056837 ops/training.py:65 2019-01-16 21:48:24.056799: step 8023, loss = 0.69726 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:48:24.950444 ops/training.py:65 2019-01-16 21:48:24.950404: step 8024, loss = 0.69813 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:48:25.844215 ops/training.py:65 2019-01-16 21:48:25.844140: step 8025, loss = 0.69693 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:48:26.739785 ops/training.py:65 2019-01-16 21:48:26.739694: step 8026, loss = 0.70220 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:48:27.635732 ops/training.py:65 2019-01-16 21:48:27.635625: step 8027, loss = 0.69840 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:48:28.531189 ops/training.py:65 2019-01-16 21:48:28.531125: step 8028, loss = 0.68772 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 21:48:29.423479 ops/training.py:65 2019-01-16 21:48:29.423415: step 8029, loss = 0.69721 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:48:30.316702 ops/training.py:65 2019-01-16 21:48:30.316637: step 8030, loss = 0.69971 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:48:31.208855 ops/training.py:65 2019-01-16 21:48:31.208789: step 8031, loss = 0.69578 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:48:32.101751 ops/training.py:65 2019-01-16 21:48:32.101689: step 8032, loss = 0.69693 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:48:32.994345 ops/training.py:65 2019-01-16 21:48:32.994284: step 8033, loss = 0.69395 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:48:33.887288 ops/training.py:65 2019-01-16 21:48:33.887222: step 8034, loss = 0.68984 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:48:34.780540 ops/training.py:65 2019-01-16 21:48:34.780474: step 8035, loss = 0.69904 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:48:35.674206 ops/training.py:65 2019-01-16 21:48:35.674138: step 8036, loss = 0.69633 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:48:36.567128 ops/training.py:65 2019-01-16 21:48:36.567064: step 8037, loss = 0.69320 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:48:37.460841 ops/training.py:65 2019-01-16 21:48:37.460779: step 8038, loss = 0.68955 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:48:38.357439 ops/training.py:65 2019-01-16 21:48:38.357388: step 8039, loss = 0.69590 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:48:39.254815 ops/training.py:65 2019-01-16 21:48:39.254716: step 8040, loss = 0.69017 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:48:40.152643 ops/training.py:65 2019-01-16 21:48:40.152553: step 8041, loss = 0.68807 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:48:41.048436 ops/training.py:65 2019-01-16 21:48:41.048335: step 8042, loss = 0.69566 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:48:41.944647 ops/training.py:65 2019-01-16 21:48:41.944562: step 8043, loss = 0.69281 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:48:42.839958 ops/training.py:65 2019-01-16 21:48:42.839863: step 8044, loss = 0.69406 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:48:43.734996 ops/training.py:65 2019-01-16 21:48:43.734899: step 8045, loss = 0.69272 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:48:44.631272 ops/training.py:65 2019-01-16 21:48:44.631209: step 8046, loss = 0.68996 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:48:45.526968 ops/training.py:65 2019-01-16 21:48:45.526873: step 8047, loss = 0.69213 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:48:46.423652 ops/training.py:65 2019-01-16 21:48:46.423545: step 8048, loss = 0.70052 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:48:47.320772 ops/training.py:65 2019-01-16 21:48:47.320665: step 8049, loss = 0.69484 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:48:48.217210 ops/training.py:65 2019-01-16 21:48:48.217108: step 8050, loss = 0.69277 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:48:49.111985 ops/training.py:65 2019-01-16 21:48:49.111924: step 8051, loss = 0.68958 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:48:50.004991 ops/training.py:65 2019-01-16 21:48:50.004932: step 8052, loss = 0.69269 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:48:50.897877 ops/training.py:65 2019-01-16 21:48:50.897815: step 8053, loss = 0.68924 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:48:51.790975 ops/training.py:65 2019-01-16 21:48:51.790912: step 8054, loss = 0.68513 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:48:52.684240 ops/training.py:65 2019-01-16 21:48:52.684181: step 8055, loss = 0.69046 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:48:53.578238 ops/training.py:65 2019-01-16 21:48:53.578178: step 8056, loss = 0.69180 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:48:54.470971 ops/training.py:65 2019-01-16 21:48:54.470907: step 8057, loss = 0.70046 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:48:55.365424 ops/training.py:65 2019-01-16 21:48:55.365362: step 8058, loss = 0.69462 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:48:56.257637 ops/training.py:65 2019-01-16 21:48:56.257577: step 8059, loss = 0.68804 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:48:57.151570 ops/training.py:65 2019-01-16 21:48:57.151504: step 8060, loss = 0.69732 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:48:58.045708 ops/training.py:65 2019-01-16 21:48:58.045640: step 8061, loss = 0.69483 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:48:58.941661 ops/training.py:65 2019-01-16 21:48:58.941557: step 8062, loss = 0.68923 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:48:59.837623 ops/training.py:65 2019-01-16 21:48:59.837557: step 8063, loss = 0.69420 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:49:00.730695 ops/training.py:65 2019-01-16 21:49:00.730632: step 8064, loss = 0.69305 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:49:01.623618 ops/training.py:65 2019-01-16 21:49:01.623562: step 8065, loss = 0.69164 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:49:02.516782 ops/training.py:65 2019-01-16 21:49:02.516722: step 8066, loss = 0.69696 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:49:03.409717 ops/training.py:65 2019-01-16 21:49:03.409655: step 8067, loss = 0.69067 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:49:04.305230 ops/training.py:65 2019-01-16 21:49:04.305162: step 8068, loss = 0.69614 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:49:05.204733 ops/training.py:65 2019-01-16 21:49:05.204633: step 8069, loss = 0.69785 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 21:49:06.100403 ops/training.py:65 2019-01-16 21:49:06.100302: step 8070, loss = 0.69246 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:49:06.996790 ops/training.py:65 2019-01-16 21:49:06.996703: step 8071, loss = 0.69248 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:49:07.890629 ops/training.py:65 2019-01-16 21:49:07.890567: step 8072, loss = 0.69734 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:49:08.784251 ops/training.py:65 2019-01-16 21:49:08.784197: step 8073, loss = 0.69586 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:49:09.677124 ops/training.py:65 2019-01-16 21:49:09.677064: step 8074, loss = 0.69611 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:49:10.569723 ops/training.py:65 2019-01-16 21:49:10.569657: step 8075, loss = 0.70190 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:49:11.464364 ops/training.py:65 2019-01-16 21:49:11.464303: step 8076, loss = 0.69174 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:49:12.358151 ops/training.py:65 2019-01-16 21:49:12.358061: step 8077, loss = 0.69232 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:49:13.257769 ops/training.py:65 2019-01-16 21:49:13.257686: step 8078, loss = 0.68969 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:49:14.156577 ops/training.py:65 2019-01-16 21:49:14.156516: step 8079, loss = 0.69881 (35.7 examples/sec; 0.898 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:49:15.051848 ops/training.py:65 2019-01-16 21:49:15.051744: step 8080, loss = 0.69186 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:49:15.946957 ops/training.py:65 2019-01-16 21:49:15.946893: step 8081, loss = 0.69069 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:49:16.840516 ops/training.py:65 2019-01-16 21:49:16.840452: step 8082, loss = 0.69120 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:49:17.733785 ops/training.py:65 2019-01-16 21:49:17.733723: step 8083, loss = 0.69450 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:49:18.627697 ops/training.py:65 2019-01-16 21:49:18.627630: step 8084, loss = 0.68546 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:49:19.521896 ops/training.py:65 2019-01-16 21:49:19.521833: step 8085, loss = 0.69444 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:49:20.414551 ops/training.py:65 2019-01-16 21:49:20.414489: step 8086, loss = 0.69233 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:49:21.307883 ops/training.py:65 2019-01-16 21:49:21.307822: step 8087, loss = 0.68917 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:49:22.201887 ops/training.py:65 2019-01-16 21:49:22.201824: step 8088, loss = 0.69235 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:49:23.094879 ops/training.py:65 2019-01-16 21:49:23.094815: step 8089, loss = 0.69245 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:49:23.988642 ops/training.py:65 2019-01-16 21:49:23.988586: step 8090, loss = 0.69500 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:49:24.881221 ops/training.py:65 2019-01-16 21:49:24.881160: step 8091, loss = 0.69237 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:49:25.775110 ops/training.py:65 2019-01-16 21:49:25.775049: step 8092, loss = 0.68851 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:49:26.671170 ops/training.py:65 2019-01-16 21:49:26.671079: step 8093, loss = 0.69537 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:49:27.567126 ops/training.py:65 2019-01-16 21:49:27.566981: step 8094, loss = 0.69319 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:49:28.464781 ops/training.py:65 2019-01-16 21:49:28.464688: step 8095, loss = 0.69236 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:49:29.360690 ops/training.py:65 2019-01-16 21:49:29.360627: step 8096, loss = 0.69421 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:49:30.254075 ops/training.py:65 2019-01-16 21:49:30.254008: step 8097, loss = 0.69401 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:49:31.147527 ops/training.py:65 2019-01-16 21:49:31.147467: step 8098, loss = 0.69304 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:49:32.042816 ops/training.py:65 2019-01-16 21:49:32.042744: step 8099, loss = 0.68950 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:49:32.940957 ops/training.py:65 2019-01-16 21:49:32.940912: step 8100, loss = 0.69754 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 21:49:33.837222 ops/training.py:65 2019-01-16 21:49:33.837170: step 8101, loss = 0.69353 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:49:34.733601 ops/training.py:65 2019-01-16 21:49:34.733500: step 8102, loss = 0.69514 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:49:35.629893 ops/training.py:65 2019-01-16 21:49:35.629829: step 8103, loss = 0.69193 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:49:36.523024 ops/training.py:65 2019-01-16 21:49:36.522960: step 8104, loss = 0.69013 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:49:37.415367 ops/training.py:65 2019-01-16 21:49:37.415306: step 8105, loss = 0.69611 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:49:38.309301 ops/training.py:65 2019-01-16 21:49:38.309229: step 8106, loss = 0.69721 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:49:39.207084 ops/training.py:65 2019-01-16 21:49:39.207018: step 8107, loss = 0.69067 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:49:40.103100 ops/training.py:65 2019-01-16 21:49:40.103001: step 8108, loss = 0.69055 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:49:40.998515 ops/training.py:65 2019-01-16 21:49:40.998414: step 8109, loss = 0.69618 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:49:41.893040 ops/training.py:65 2019-01-16 21:49:41.892952: step 8110, loss = 0.69196 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:49:42.786878 ops/training.py:65 2019-01-16 21:49:42.786809: step 8111, loss = 0.69108 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:49:43.679802 ops/training.py:65 2019-01-16 21:49:43.679739: step 8112, loss = 0.69370 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:49:44.572166 ops/training.py:65 2019-01-16 21:49:44.572103: step 8113, loss = 0.69213 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:49:45.464289 ops/training.py:65 2019-01-16 21:49:45.464219: step 8114, loss = 0.69422 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:49:46.357265 ops/training.py:65 2019-01-16 21:49:46.357202: step 8115, loss = 0.69526 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:49:47.249401 ops/training.py:65 2019-01-16 21:49:47.249331: step 8116, loss = 0.69489 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:49:48.141833 ops/training.py:65 2019-01-16 21:49:48.141757: step 8117, loss = 0.68919 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:49:49.035808 ops/training.py:65 2019-01-16 21:49:49.035744: step 8118, loss = 0.69532 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:49:49.932027 ops/training.py:65 2019-01-16 21:49:49.931953: step 8119, loss = 0.69037 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:49:50.825795 ops/training.py:65 2019-01-16 21:49:50.825711: step 8120, loss = 0.69934 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:49:51.720893 ops/training.py:65 2019-01-16 21:49:51.720793: step 8121, loss = 0.69121 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:49:52.615173 ops/training.py:65 2019-01-16 21:49:52.615075: step 8122, loss = 0.68786 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:49:53.512409 ops/training.py:65 2019-01-16 21:49:53.512302: step 8123, loss = 0.68848 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:49:54.409053 ops/training.py:65 2019-01-16 21:49:54.408974: step 8124, loss = 0.69435 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:49:55.308350 ops/training.py:65 2019-01-16 21:49:55.308276: step 8125, loss = 0.69090 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:49:56.203269 ops/training.py:65 2019-01-16 21:49:56.203174: step 8126, loss = 0.69353 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:49:57.099021 ops/training.py:65 2019-01-16 21:49:57.098950: step 8127, loss = 0.69692 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:49:57.993707 ops/training.py:65 2019-01-16 21:49:57.993641: step 8128, loss = 0.68903 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:49:58.887902 ops/training.py:65 2019-01-16 21:49:58.887838: step 8129, loss = 0.69700 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:49:59.782869 ops/training.py:65 2019-01-16 21:49:59.782804: step 8130, loss = 0.69512 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:50:00.677097 ops/training.py:65 2019-01-16 21:50:00.676991: step 8131, loss = 0.69127 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:50:01.571832 ops/training.py:65 2019-01-16 21:50:01.571747: step 8132, loss = 0.69054 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:50:02.468551 ops/training.py:65 2019-01-16 21:50:02.468493: step 8133, loss = 0.69388 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:50:03.363373 ops/training.py:65 2019-01-16 21:50:03.363277: step 8134, loss = 0.69472 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:50:04.259283 ops/training.py:65 2019-01-16 21:50:04.259199: step 8135, loss = 0.68991 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:50:05.153339 ops/training.py:65 2019-01-16 21:50:05.153251: step 8136, loss = 0.68620 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:50:06.047546 ops/training.py:65 2019-01-16 21:50:06.047469: step 8137, loss = 0.69374 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:50:06.941383 ops/training.py:65 2019-01-16 21:50:06.941289: step 8138, loss = 0.68758 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:50:07.835985 ops/training.py:65 2019-01-16 21:50:07.835885: step 8139, loss = 0.69392 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:50:08.730947 ops/training.py:65 2019-01-16 21:50:08.730871: step 8140, loss = 0.69210 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:50:09.627077 ops/training.py:65 2019-01-16 21:50:09.626983: step 8141, loss = 0.69206 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:50:10.521235 ops/training.py:65 2019-01-16 21:50:10.521172: step 8142, loss = 0.69221 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:50:11.420828 ops/training.py:65 2019-01-16 21:50:11.420762: step 8143, loss = 0.69074 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:50:12.317065 ops/training.py:65 2019-01-16 21:50:12.316985: step 8144, loss = 0.69916 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:50:13.213211 ops/training.py:65 2019-01-16 21:50:13.213124: step 8145, loss = 0.69305 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:50:14.108865 ops/training.py:65 2019-01-16 21:50:14.108775: step 8146, loss = 0.69591 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:50:15.003054 ops/training.py:65 2019-01-16 21:50:15.002979: step 8147, loss = 0.69936 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:50:15.896532 ops/training.py:65 2019-01-16 21:50:15.896469: step 8148, loss = 0.69642 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:50:16.790988 ops/training.py:65 2019-01-16 21:50:16.790925: step 8149, loss = 0.69916 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:50:17.685692 ops/training.py:65 2019-01-16 21:50:17.685631: step 8150, loss = 0.68906 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:50:18.581760 ops/training.py:65 2019-01-16 21:50:18.581701: step 8151, loss = 0.69210 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:50:19.476898 ops/training.py:65 2019-01-16 21:50:19.476809: step 8152, loss = 0.69311 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:50:20.371658 ops/training.py:65 2019-01-16 21:50:20.371596: step 8153, loss = 0.69506 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:50:21.264386 ops/training.py:65 2019-01-16 21:50:21.264322: step 8154, loss = 0.69137 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:50:22.159497 ops/training.py:65 2019-01-16 21:50:22.159426: step 8155, loss = 0.69667 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:50:23.056519 ops/training.py:65 2019-01-16 21:50:23.056442: step 8156, loss = 0.69671 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:50:23.952763 ops/training.py:65 2019-01-16 21:50:23.952701: step 8157, loss = 0.69665 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:50:24.848170 ops/training.py:65 2019-01-16 21:50:24.848111: step 8158, loss = 0.69405 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:50:25.743205 ops/training.py:65 2019-01-16 21:50:25.743151: step 8159, loss = 0.69013 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:50:26.637808 ops/training.py:65 2019-01-16 21:50:26.637756: step 8160, loss = 0.68828 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:50:27.533831 ops/training.py:65 2019-01-16 21:50:27.533774: step 8161, loss = 0.69526 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:50:28.428263 ops/training.py:65 2019-01-16 21:50:28.428208: step 8162, loss = 0.68568 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.75
I1280 2019-01-16 21:50:29.322289 ops/training.py:65 2019-01-16 21:50:29.322232: step 8163, loss = 0.69002 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:50:30.215195 ops/training.py:65 2019-01-16 21:50:30.215136: step 8164, loss = 0.69322 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:50:31.108307 ops/training.py:65 2019-01-16 21:50:31.108251: step 8165, loss = 0.69709 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:50:32.001350 ops/training.py:65 2019-01-16 21:50:32.001295: step 8166, loss = 0.68885 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:50:32.895549 ops/training.py:65 2019-01-16 21:50:32.895494: step 8167, loss = 0.69231 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:50:33.789754 ops/training.py:65 2019-01-16 21:50:33.789697: step 8168, loss = 0.69563 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:50:34.683090 ops/training.py:65 2019-01-16 21:50:34.683030: step 8169, loss = 0.69203 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:50:35.577067 ops/training.py:65 2019-01-16 21:50:35.577002: step 8170, loss = 0.69765 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:50:36.472264 ops/training.py:65 2019-01-16 21:50:36.472177: step 8171, loss = 0.69799 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:50:37.367595 ops/training.py:65 2019-01-16 21:50:37.367511: step 8172, loss = 0.69300 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:50:38.262932 ops/training.py:65 2019-01-16 21:50:38.262876: step 8173, loss = 0.69126 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:50:39.155810 ops/training.py:65 2019-01-16 21:50:39.155763: step 8174, loss = 0.69135 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:50:40.050684 ops/training.py:65 2019-01-16 21:50:40.050623: step 8175, loss = 0.69649 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:50:40.946684 ops/training.py:65 2019-01-16 21:50:40.946603: step 8176, loss = 0.69424 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:50:41.841797 ops/training.py:65 2019-01-16 21:50:41.841733: step 8177, loss = 0.69247 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:50:42.735871 ops/training.py:65 2019-01-16 21:50:42.735804: step 8178, loss = 0.69159 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:50:43.630207 ops/training.py:65 2019-01-16 21:50:43.630122: step 8179, loss = 0.69350 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:50:44.525590 ops/training.py:65 2019-01-16 21:50:44.525507: step 8180, loss = 0.68787 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:50:45.420980 ops/training.py:65 2019-01-16 21:50:45.420897: step 8181, loss = 0.69305 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:50:46.315146 ops/training.py:65 2019-01-16 21:50:46.315068: step 8182, loss = 0.69256 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:50:47.212271 ops/training.py:65 2019-01-16 21:50:47.212187: step 8183, loss = 0.68983 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:50:48.107618 ops/training.py:65 2019-01-16 21:50:48.107541: step 8184, loss = 0.68746 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:50:49.001444 ops/training.py:65 2019-01-16 21:50:49.001387: step 8185, loss = 0.69607 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:50:49.894811 ops/training.py:65 2019-01-16 21:50:49.894752: step 8186, loss = 0.69485 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:50:50.787426 ops/training.py:65 2019-01-16 21:50:50.787373: step 8187, loss = 0.69300 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:50:51.680446 ops/training.py:65 2019-01-16 21:50:51.680392: step 8188, loss = 0.69366 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:50:52.574858 ops/training.py:65 2019-01-16 21:50:52.574805: step 8189, loss = 0.68937 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:50:53.468174 ops/training.py:65 2019-01-16 21:50:53.468120: step 8190, loss = 0.69352 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:50:54.363580 ops/training.py:65 2019-01-16 21:50:54.363531: step 8191, loss = 0.69470 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:50:55.258157 ops/training.py:65 2019-01-16 21:50:55.258084: step 8192, loss = 0.68902 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:50:56.152810 ops/training.py:65 2019-01-16 21:50:56.152730: step 8193, loss = 0.69191 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:50:57.049084 ops/training.py:65 2019-01-16 21:50:57.049004: step 8194, loss = 0.69385 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:50:57.945264 ops/training.py:65 2019-01-16 21:50:57.945175: step 8195, loss = 0.69213 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:50:58.841048 ops/training.py:65 2019-01-16 21:50:58.840989: step 8196, loss = 0.69495 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:50:59.738416 ops/training.py:65 2019-01-16 21:50:59.738348: step 8197, loss = 0.69415 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:51:00.635265 ops/training.py:65 2019-01-16 21:51:00.635178: step 8198, loss = 0.68987 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:51:01.532138 ops/training.py:65 2019-01-16 21:51:01.532055: step 8199, loss = 0.69309 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:51:02.426982 ops/training.py:65 2019-01-16 21:51:02.426927: step 8200, loss = 0.69066 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:51:03.321814 ops/training.py:65 2019-01-16 21:51:03.321757: step 8201, loss = 0.69349 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:51:04.216731 ops/training.py:65 2019-01-16 21:51:04.216675: step 8202, loss = 0.69936 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:51:05.111023 ops/training.py:65 2019-01-16 21:51:05.110967: step 8203, loss = 0.69256 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:51:06.004357 ops/training.py:65 2019-01-16 21:51:06.004301: step 8204, loss = 0.69316 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:51:06.897653 ops/training.py:65 2019-01-16 21:51:06.897595: step 8205, loss = 0.69181 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:51:07.791842 ops/training.py:65 2019-01-16 21:51:07.791786: step 8206, loss = 0.69414 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:51:08.686269 ops/training.py:65 2019-01-16 21:51:08.686215: step 8207, loss = 0.68952 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:51:09.580135 ops/training.py:65 2019-01-16 21:51:09.580077: step 8208, loss = 0.69846 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:51:10.474252 ops/training.py:65 2019-01-16 21:51:10.474197: step 8209, loss = 0.69512 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:51:11.367582 ops/training.py:65 2019-01-16 21:51:11.367525: step 8210, loss = 0.70333 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:51:12.260985 ops/training.py:65 2019-01-16 21:51:12.260922: step 8211, loss = 0.69177 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:51:13.155258 ops/training.py:65 2019-01-16 21:51:13.155176: step 8212, loss = 0.69377 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:51:14.050628 ops/training.py:65 2019-01-16 21:51:14.050542: step 8213, loss = 0.69263 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:51:14.944710 ops/training.py:65 2019-01-16 21:51:14.944653: step 8214, loss = 0.69492 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:51:15.838241 ops/training.py:65 2019-01-16 21:51:15.838187: step 8215, loss = 0.69129 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:51:16.732423 ops/training.py:65 2019-01-16 21:51:16.732365: step 8216, loss = 0.69198 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:51:17.629827 ops/training.py:65 2019-01-16 21:51:17.629742: step 8217, loss = 0.68437 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 21:51:18.526042 ops/training.py:65 2019-01-16 21:51:18.525987: step 8218, loss = 0.69734 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:51:19.420616 ops/training.py:65 2019-01-16 21:51:19.420559: step 8219, loss = 0.68974 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:51:20.313927 ops/training.py:65 2019-01-16 21:51:20.313875: step 8220, loss = 0.69283 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:51:21.207653 ops/training.py:65 2019-01-16 21:51:21.207589: step 8221, loss = 0.69421 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:51:22.104719 ops/training.py:65 2019-01-16 21:51:22.104634: step 8222, loss = 0.69225 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:51:23.000829 ops/training.py:65 2019-01-16 21:51:23.000750: step 8223, loss = 0.69047 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:51:23.895738 ops/training.py:65 2019-01-16 21:51:23.895695: step 8224, loss = 0.69271 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:51:24.790213 ops/training.py:65 2019-01-16 21:51:24.790147: step 8225, loss = 0.68640 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:51:25.684725 ops/training.py:65 2019-01-16 21:51:25.684648: step 8226, loss = 0.69771 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:51:26.580017 ops/training.py:65 2019-01-16 21:51:26.579941: step 8227, loss = 0.68642 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:51:27.477006 ops/training.py:65 2019-01-16 21:51:27.476922: step 8228, loss = 0.69602 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:51:28.373605 ops/training.py:65 2019-01-16 21:51:28.373545: step 8229, loss = 0.68685 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:51:29.266744 ops/training.py:65 2019-01-16 21:51:29.266682: step 8230, loss = 0.69480 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:51:30.160210 ops/training.py:65 2019-01-16 21:51:30.160155: step 8231, loss = 0.69221 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:51:31.055374 ops/training.py:65 2019-01-16 21:51:31.055306: step 8232, loss = 0.69651 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:51:31.952315 ops/training.py:65 2019-01-16 21:51:31.952239: step 8233, loss = 0.69404 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:51:32.848815 ops/training.py:65 2019-01-16 21:51:32.848757: step 8234, loss = 0.69059 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:51:33.742149 ops/training.py:65 2019-01-16 21:51:33.742065: step 8235, loss = 0.68856 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:51:34.639225 ops/training.py:65 2019-01-16 21:51:34.639180: step 8236, loss = 0.69486 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:51:35.536063 ops/training.py:65 2019-01-16 21:51:35.535975: step 8237, loss = 0.69374 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:51:36.431880 ops/training.py:65 2019-01-16 21:51:36.431827: step 8238, loss = 0.69345 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:51:37.328009 ops/training.py:65 2019-01-16 21:51:37.327953: step 8239, loss = 0.68901 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:51:38.225291 ops/training.py:65 2019-01-16 21:51:38.225219: step 8240, loss = 0.68762 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:51:39.122114 ops/training.py:65 2019-01-16 21:51:39.122039: step 8241, loss = 0.69499 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:51:40.018875 ops/training.py:65 2019-01-16 21:51:40.018821: step 8242, loss = 0.69961 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:51:40.914313 ops/training.py:65 2019-01-16 21:51:40.914259: step 8243, loss = 0.69411 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:51:41.810439 ops/training.py:65 2019-01-16 21:51:41.810375: step 8244, loss = 0.70347 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:51:42.706499 ops/training.py:65 2019-01-16 21:51:42.706417: step 8245, loss = 0.69428 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:51:43.602487 ops/training.py:65 2019-01-16 21:51:43.602409: step 8246, loss = 0.69551 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:51:44.496249 ops/training.py:65 2019-01-16 21:51:44.496167: step 8247, loss = 0.69274 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:51:45.391013 ops/training.py:65 2019-01-16 21:51:45.390924: step 8248, loss = 0.69579 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:51:46.285791 ops/training.py:65 2019-01-16 21:51:46.285704: step 8249, loss = 0.69825 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:51:47.179672 ops/training.py:65 2019-01-16 21:51:47.179614: step 8250, loss = 0.69699 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:51:48.075249 ops/training.py:65 2019-01-16 21:51:48.075180: step 8251, loss = 0.68354 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:51:48.971582 ops/training.py:65 2019-01-16 21:51:48.971511: step 8252, loss = 0.68699 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:51:49.867160 ops/training.py:65 2019-01-16 21:51:49.867085: step 8253, loss = 0.69128 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:51:50.764357 ops/training.py:65 2019-01-16 21:51:50.764271: step 8254, loss = 0.69376 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:51:51.661632 ops/training.py:65 2019-01-16 21:51:51.661579: step 8255, loss = 0.68925 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:51:52.556439 ops/training.py:65 2019-01-16 21:51:52.556359: step 8256, loss = 0.69059 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:51:53.451991 ops/training.py:65 2019-01-16 21:51:53.451937: step 8257, loss = 0.68948 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:51:54.344753 ops/training.py:65 2019-01-16 21:51:54.344704: step 8258, loss = 0.69780 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:51:55.238666 ops/training.py:65 2019-01-16 21:51:55.238612: step 8259, loss = 0.69531 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:51:56.131679 ops/training.py:65 2019-01-16 21:51:56.131622: step 8260, loss = 0.68931 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:51:57.025660 ops/training.py:65 2019-01-16 21:51:57.025603: step 8261, loss = 0.69432 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:51:57.918508 ops/training.py:65 2019-01-16 21:51:57.918456: step 8262, loss = 0.68647 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:51:58.811848 ops/training.py:65 2019-01-16 21:51:58.811794: step 8263, loss = 0.69794 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:51:59.705520 ops/training.py:65 2019-01-16 21:51:59.705467: step 8264, loss = 0.69731 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 21:52:00.599031 ops/training.py:65 2019-01-16 21:52:00.598977: step 8265, loss = 0.69915 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:52:01.491319 ops/training.py:65 2019-01-16 21:52:01.491265: step 8266, loss = 0.69410 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:52:02.384858 ops/training.py:65 2019-01-16 21:52:02.384806: step 8267, loss = 0.69470 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:52:03.278020 ops/training.py:65 2019-01-16 21:52:03.277967: step 8268, loss = 0.69011 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:52:04.171007 ops/training.py:65 2019-01-16 21:52:04.170950: step 8269, loss = 0.69235 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:52:05.064153 ops/training.py:65 2019-01-16 21:52:05.064097: step 8270, loss = 0.68966 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:52:05.957200 ops/training.py:65 2019-01-16 21:52:05.957143: step 8271, loss = 0.69363 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:52:06.850529 ops/training.py:65 2019-01-16 21:52:06.850460: step 8272, loss = 0.69495 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:52:07.744378 ops/training.py:65 2019-01-16 21:52:07.744323: step 8273, loss = 0.69083 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:52:08.637209 ops/training.py:65 2019-01-16 21:52:08.637155: step 8274, loss = 0.69382 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:52:09.532646 ops/training.py:65 2019-01-16 21:52:09.532597: step 8275, loss = 0.69271 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:52:10.428922 ops/training.py:65 2019-01-16 21:52:10.428836: step 8276, loss = 0.69255 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:52:11.325966 ops/training.py:65 2019-01-16 21:52:11.325902: step 8277, loss = 0.69391 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:52:12.221864 ops/training.py:65 2019-01-16 21:52:12.221796: step 8278, loss = 0.69675 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:52:13.116610 ops/training.py:65 2019-01-16 21:52:13.116530: step 8279, loss = 0.69163 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:52:14.011455 ops/training.py:65 2019-01-16 21:52:14.011399: step 8280, loss = 0.69603 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:52:14.907246 ops/training.py:65 2019-01-16 21:52:14.907193: step 8281, loss = 0.68954 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:52:15.803026 ops/training.py:65 2019-01-16 21:52:15.802954: step 8282, loss = 0.69819 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:52:16.700372 ops/training.py:65 2019-01-16 21:52:16.700283: step 8283, loss = 0.69144 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:52:17.596818 ops/training.py:65 2019-01-16 21:52:17.596736: step 8284, loss = 0.69834 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:52:18.493427 ops/training.py:65 2019-01-16 21:52:18.493380: step 8285, loss = 0.69268 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:52:19.388063 ops/training.py:65 2019-01-16 21:52:19.388002: step 8286, loss = 0.69519 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:52:20.285209 ops/training.py:65 2019-01-16 21:52:20.285112: step 8287, loss = 0.69145 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:52:21.181666 ops/training.py:65 2019-01-16 21:52:21.181578: step 8288, loss = 0.69406 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:52:22.077392 ops/training.py:65 2019-01-16 21:52:22.077336: step 8289, loss = 0.69322 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:52:22.972070 ops/training.py:65 2019-01-16 21:52:22.972019: step 8290, loss = 0.69408 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:52:23.867936 ops/training.py:65 2019-01-16 21:52:23.867881: step 8291, loss = 0.69728 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:52:24.762795 ops/training.py:65 2019-01-16 21:52:24.762713: step 8292, loss = 0.68874 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:52:25.659458 ops/training.py:65 2019-01-16 21:52:25.659373: step 8293, loss = 0.68972 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:52:26.554585 ops/training.py:65 2019-01-16 21:52:26.554499: step 8294, loss = 0.69082 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:52:27.449219 ops/training.py:65 2019-01-16 21:52:27.449140: step 8295, loss = 0.69636 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:52:28.346297 ops/training.py:65 2019-01-16 21:52:28.346209: step 8296, loss = 0.69854 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:52:29.242222 ops/training.py:65 2019-01-16 21:52:29.242168: step 8297, loss = 0.69473 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:52:30.136080 ops/training.py:65 2019-01-16 21:52:30.136025: step 8298, loss = 0.70076 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:52:31.029787 ops/training.py:65 2019-01-16 21:52:31.029734: step 8299, loss = 0.69380 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:52:31.924839 ops/training.py:65 2019-01-16 21:52:31.924784: step 8300, loss = 0.70045 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:52:32.818358 ops/training.py:65 2019-01-16 21:52:32.818299: step 8301, loss = 0.69519 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:52:33.712638 ops/training.py:65 2019-01-16 21:52:33.712583: step 8302, loss = 0.69510 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:52:34.607088 ops/training.py:65 2019-01-16 21:52:34.607028: step 8303, loss = 0.69363 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:52:35.504030 ops/training.py:65 2019-01-16 21:52:35.503980: step 8304, loss = 0.68573 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:52:36.400490 ops/training.py:65 2019-01-16 21:52:36.400401: step 8305, loss = 0.69592 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:52:37.296850 ops/training.py:65 2019-01-16 21:52:37.296787: step 8306, loss = 0.69698 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:52:38.191946 ops/training.py:65 2019-01-16 21:52:38.191861: step 8307, loss = 0.69886 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:52:39.088366 ops/training.py:65 2019-01-16 21:52:39.088302: step 8308, loss = 0.69528 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:52:39.984476 ops/training.py:65 2019-01-16 21:52:39.984431: step 8309, loss = 0.68874 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:52:40.879807 ops/training.py:65 2019-01-16 21:52:40.879752: step 8310, loss = 0.68788 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:52:41.774299 ops/training.py:65 2019-01-16 21:52:41.774233: step 8311, loss = 0.68564 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:52:42.669481 ops/training.py:65 2019-01-16 21:52:42.669397: step 8312, loss = 0.69467 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:52:43.566577 ops/training.py:65 2019-01-16 21:52:43.566519: step 8313, loss = 0.69324 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:52:44.462016 ops/training.py:65 2019-01-16 21:52:44.461936: step 8314, loss = 0.69567 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:52:45.358549 ops/training.py:65 2019-01-16 21:52:45.358459: step 8315, loss = 0.69677 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:52:46.255155 ops/training.py:65 2019-01-16 21:52:46.255070: step 8316, loss = 0.68599 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:52:47.149897 ops/training.py:65 2019-01-16 21:52:47.149836: step 8317, loss = 0.69029 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:52:48.042943 ops/training.py:65 2019-01-16 21:52:48.042883: step 8318, loss = 0.69528 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:52:48.937076 ops/training.py:65 2019-01-16 21:52:48.937020: step 8319, loss = 0.69705 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:52:49.830836 ops/training.py:65 2019-01-16 21:52:49.830779: step 8320, loss = 0.69595 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:52:50.725196 ops/training.py:65 2019-01-16 21:52:50.725136: step 8321, loss = 0.69634 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:52:51.621183 ops/training.py:65 2019-01-16 21:52:51.621113: step 8322, loss = 0.70315 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:52:52.517268 ops/training.py:65 2019-01-16 21:52:52.517191: step 8323, loss = 0.68413 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:52:53.413245 ops/training.py:65 2019-01-16 21:52:53.413172: step 8324, loss = 0.69085 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:52:54.308212 ops/training.py:65 2019-01-16 21:52:54.308164: step 8325, loss = 0.68558 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:52:55.203174 ops/training.py:65 2019-01-16 21:52:55.203098: step 8326, loss = 0.68934 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:52:56.100170 ops/training.py:65 2019-01-16 21:52:56.100083: step 8327, loss = 0.68717 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:52:56.996051 ops/training.py:65 2019-01-16 21:52:56.995983: step 8328, loss = 0.69729 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:52:57.888759 ops/training.py:65 2019-01-16 21:52:57.888709: step 8329, loss = 0.69511 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:52:58.782193 ops/training.py:65 2019-01-16 21:52:58.782145: step 8330, loss = 0.69064 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:52:59.677284 ops/training.py:65 2019-01-16 21:52:59.677231: step 8331, loss = 0.70028 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:53:00.574352 ops/training.py:65 2019-01-16 21:53:00.574291: step 8332, loss = 0.69631 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:53:01.471149 ops/training.py:65 2019-01-16 21:53:01.471074: step 8333, loss = 0.69469 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:53:02.368785 ops/training.py:65 2019-01-16 21:53:02.368702: step 8334, loss = 0.70065 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:53:03.264453 ops/training.py:65 2019-01-16 21:53:03.264367: step 8335, loss = 0.69456 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:53:04.160967 ops/training.py:65 2019-01-16 21:53:04.160906: step 8336, loss = 0.69541 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:53:05.055645 ops/training.py:65 2019-01-16 21:53:05.055590: step 8337, loss = 0.69580 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:53:05.949787 ops/training.py:65 2019-01-16 21:53:05.949731: step 8338, loss = 0.69385 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:53:06.844554 ops/training.py:65 2019-01-16 21:53:06.844508: step 8339, loss = 0.69340 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:53:07.741541 ops/training.py:65 2019-01-16 21:53:07.741452: step 8340, loss = 0.68795 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:53:08.638050 ops/training.py:65 2019-01-16 21:53:08.637993: step 8341, loss = 0.70247 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:53:09.532387 ops/training.py:65 2019-01-16 21:53:09.532326: step 8342, loss = 0.69619 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:53:10.428067 ops/training.py:65 2019-01-16 21:53:10.427984: step 8343, loss = 0.69084 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:53:11.323136 ops/training.py:65 2019-01-16 21:53:11.323081: step 8344, loss = 0.69377 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:53:12.216760 ops/training.py:65 2019-01-16 21:53:12.216683: step 8345, loss = 0.69602 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:53:13.112833 ops/training.py:65 2019-01-16 21:53:13.112757: step 8346, loss = 0.69727 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:53:14.007176 ops/training.py:65 2019-01-16 21:53:14.007095: step 8347, loss = 0.69573 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:53:14.901351 ops/training.py:65 2019-01-16 21:53:14.901295: step 8348, loss = 0.68935 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:53:15.796764 ops/training.py:65 2019-01-16 21:53:15.796715: step 8349, loss = 0.68841 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:53:16.691845 ops/training.py:65 2019-01-16 21:53:16.691786: step 8350, loss = 0.69160 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:53:17.586535 ops/training.py:65 2019-01-16 21:53:17.586452: step 8351, loss = 0.69433 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:53:18.481314 ops/training.py:65 2019-01-16 21:53:18.481231: step 8352, loss = 0.69176 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:53:19.377742 ops/training.py:65 2019-01-16 21:53:19.377679: step 8353, loss = 0.68998 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:53:20.275490 ops/training.py:65 2019-01-16 21:53:20.275412: step 8354, loss = 0.70109 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 21:53:21.172317 ops/training.py:65 2019-01-16 21:53:21.172260: step 8355, loss = 0.69538 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:53:22.065545 ops/training.py:65 2019-01-16 21:53:22.065493: step 8356, loss = 0.69404 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:53:22.959547 ops/training.py:65 2019-01-16 21:53:22.959496: step 8357, loss = 0.69419 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:53:23.854019 ops/training.py:65 2019-01-16 21:53:23.853961: step 8358, loss = 0.69108 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:53:24.746505 ops/training.py:65 2019-01-16 21:53:24.746454: step 8359, loss = 0.68816 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:53:25.639470 ops/training.py:65 2019-01-16 21:53:25.639411: step 8360, loss = 0.69371 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:53:26.531866 ops/training.py:65 2019-01-16 21:53:26.531810: step 8361, loss = 0.69854 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:53:27.425205 ops/training.py:65 2019-01-16 21:53:27.425146: step 8362, loss = 0.69195 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:53:28.320363 ops/training.py:65 2019-01-16 21:53:28.320307: step 8363, loss = 0.68769 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:53:29.216389 ops/training.py:65 2019-01-16 21:53:29.216300: step 8364, loss = 0.69479 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:53:30.114058 ops/training.py:65 2019-01-16 21:53:30.114002: step 8365, loss = 0.69046 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.75
I1280 2019-01-16 21:53:31.010709 ops/training.py:65 2019-01-16 21:53:31.010621: step 8366, loss = 0.69393 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:53:31.907275 ops/training.py:65 2019-01-16 21:53:31.907219: step 8367, loss = 0.69310 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:53:32.801387 ops/training.py:65 2019-01-16 21:53:32.801334: step 8368, loss = 0.69264 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:53:33.695162 ops/training.py:65 2019-01-16 21:53:33.695105: step 8369, loss = 0.69102 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:53:34.589345 ops/training.py:65 2019-01-16 21:53:34.589290: step 8370, loss = 0.69055 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:53:35.483231 ops/training.py:65 2019-01-16 21:53:35.483176: step 8371, loss = 0.69343 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:53:36.376656 ops/training.py:65 2019-01-16 21:53:36.376601: step 8372, loss = 0.69198 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:53:37.273663 ops/training.py:65 2019-01-16 21:53:37.273606: step 8373, loss = 0.69464 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:53:38.170217 ops/training.py:65 2019-01-16 21:53:38.170137: step 8374, loss = 0.69973 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:53:39.066358 ops/training.py:65 2019-01-16 21:53:39.066323: step 8375, loss = 0.69263 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:53:39.961827 ops/training.py:65 2019-01-16 21:53:39.961762: step 8376, loss = 0.69151 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:53:40.858332 ops/training.py:65 2019-01-16 21:53:40.858247: step 8377, loss = 0.69654 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:53:41.754142 ops/training.py:65 2019-01-16 21:53:41.754059: step 8378, loss = 0.69131 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:53:42.649523 ops/training.py:65 2019-01-16 21:53:42.649450: step 8379, loss = 0.69176 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:53:43.545196 ops/training.py:65 2019-01-16 21:53:43.545107: step 8380, loss = 0.69240 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:53:44.440161 ops/training.py:65 2019-01-16 21:53:44.440103: step 8381, loss = 0.69578 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:53:45.334090 ops/training.py:65 2019-01-16 21:53:45.334032: step 8382, loss = 0.69681 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:53:46.228076 ops/training.py:65 2019-01-16 21:53:46.228020: step 8383, loss = 0.68959 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:53:47.121232 ops/training.py:65 2019-01-16 21:53:47.121173: step 8384, loss = 0.69793 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:53:48.014669 ops/training.py:65 2019-01-16 21:53:48.014608: step 8385, loss = 0.69073 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:53:48.909405 ops/training.py:65 2019-01-16 21:53:48.909364: step 8386, loss = 0.69222 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:53:49.804781 ops/training.py:65 2019-01-16 21:53:49.804722: step 8387, loss = 0.68777 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:53:50.699595 ops/training.py:65 2019-01-16 21:53:50.699517: step 8388, loss = 0.69297 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:53:51.595737 ops/training.py:65 2019-01-16 21:53:51.595674: step 8389, loss = 0.69692 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 21:53:52.491616 ops/training.py:65 2019-01-16 21:53:52.491570: step 8390, loss = 0.69226 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:53:53.386683 ops/training.py:65 2019-01-16 21:53:53.386651: step 8391, loss = 0.69580 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:53:54.281695 ops/training.py:65 2019-01-16 21:53:54.281646: step 8392, loss = 0.69119 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:53:55.178625 ops/training.py:65 2019-01-16 21:53:55.178561: step 8393, loss = 0.69422 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:53:56.074267 ops/training.py:65 2019-01-16 21:53:56.074182: step 8394, loss = 0.69601 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:53:56.972325 ops/training.py:65 2019-01-16 21:53:56.972252: step 8395, loss = 0.69360 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:53:57.869417 ops/training.py:65 2019-01-16 21:53:57.869327: step 8396, loss = 0.69292 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:53:58.765943 ops/training.py:65 2019-01-16 21:53:58.765858: step 8397, loss = 0.69413 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:53:59.661680 ops/training.py:65 2019-01-16 21:53:59.661624: step 8398, loss = 0.68882 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:54:00.555063 ops/training.py:65 2019-01-16 21:54:00.555008: step 8399, loss = 0.69036 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:54:01.448945 ops/training.py:65 2019-01-16 21:54:01.448896: step 8400, loss = 0.69157 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:54:02.342022 ops/training.py:65 2019-01-16 21:54:02.341972: step 8401, loss = 0.69028 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:54:03.239862 ops/training.py:65 2019-01-16 21:54:03.239812: step 8402, loss = 0.69065 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:54:04.136916 ops/training.py:65 2019-01-16 21:54:04.136829: step 8403, loss = 0.68881 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:54:05.034525 ops/training.py:65 2019-01-16 21:54:05.034465: step 8404, loss = 0.69503 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:54:05.931420 ops/training.py:65 2019-01-16 21:54:05.931334: step 8405, loss = 0.69426 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:54:06.828614 ops/training.py:65 2019-01-16 21:54:06.828536: step 8406, loss = 0.69612 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:54:07.724745 ops/training.py:65 2019-01-16 21:54:07.724657: step 8407, loss = 0.70046 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:54:08.620411 ops/training.py:65 2019-01-16 21:54:08.620352: step 8408, loss = 0.69234 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:54:09.513557 ops/training.py:65 2019-01-16 21:54:09.513506: step 8409, loss = 0.69200 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:54:10.407046 ops/training.py:65 2019-01-16 21:54:10.406994: step 8410, loss = 0.69131 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:54:11.299503 ops/training.py:65 2019-01-16 21:54:11.299446: step 8411, loss = 0.69405 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:54:12.192929 ops/training.py:65 2019-01-16 21:54:12.192858: step 8412, loss = 0.69273 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:54:13.087300 ops/training.py:65 2019-01-16 21:54:13.087243: step 8413, loss = 0.69894 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:54:13.983865 ops/training.py:65 2019-01-16 21:54:13.983808: step 8414, loss = 0.69586 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:54:14.882398 ops/training.py:65 2019-01-16 21:54:14.882322: step 8415, loss = 0.69160 (35.7 examples/sec; 0.898 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:54:15.778653 ops/training.py:65 2019-01-16 21:54:15.778559: step 8416, loss = 0.69326 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:54:16.673583 ops/training.py:65 2019-01-16 21:54:16.673509: step 8417, loss = 0.69496 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:54:17.572258 ops/training.py:65 2019-01-16 21:54:17.572178: step 8418, loss = 0.68937 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:54:18.467440 ops/training.py:65 2019-01-16 21:54:18.467353: step 8419, loss = 0.69176 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:54:19.365022 ops/training.py:65 2019-01-16 21:54:19.364934: step 8420, loss = 0.69203 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:54:20.259402 ops/training.py:65 2019-01-16 21:54:20.259318: step 8421, loss = 0.69575 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:54:21.155236 ops/training.py:65 2019-01-16 21:54:21.155181: step 8422, loss = 0.69242 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:54:22.049241 ops/training.py:65 2019-01-16 21:54:22.049179: step 8423, loss = 0.69157 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:54:22.943700 ops/training.py:65 2019-01-16 21:54:22.943619: step 8424, loss = 0.69019 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:54:23.839138 ops/training.py:65 2019-01-16 21:54:23.839040: step 8425, loss = 0.69503 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:54:24.735472 ops/training.py:65 2019-01-16 21:54:24.735384: step 8426, loss = 0.69682 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:54:25.630845 ops/training.py:65 2019-01-16 21:54:25.630746: step 8427, loss = 0.69310 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:54:26.525426 ops/training.py:65 2019-01-16 21:54:26.525354: step 8428, loss = 0.69550 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:54:27.420293 ops/training.py:65 2019-01-16 21:54:27.420223: step 8429, loss = 0.69540 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:54:28.313697 ops/training.py:65 2019-01-16 21:54:28.313633: step 8430, loss = 0.69132 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:54:29.208541 ops/training.py:65 2019-01-16 21:54:29.208470: step 8431, loss = 0.69313 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:54:30.101187 ops/training.py:65 2019-01-16 21:54:30.101123: step 8432, loss = 0.69637 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:54:30.993686 ops/training.py:65 2019-01-16 21:54:30.993613: step 8433, loss = 0.69555 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:54:31.886859 ops/training.py:65 2019-01-16 21:54:31.886789: step 8434, loss = 0.69437 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:54:32.781584 ops/training.py:65 2019-01-16 21:54:32.781497: step 8435, loss = 0.69485 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:54:33.677787 ops/training.py:65 2019-01-16 21:54:33.677675: step 8436, loss = 0.69956 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:54:34.574134 ops/training.py:65 2019-01-16 21:54:34.574033: step 8437, loss = 0.69259 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:54:35.470703 ops/training.py:65 2019-01-16 21:54:35.470596: step 8438, loss = 0.69303 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:54:36.366446 ops/training.py:65 2019-01-16 21:54:36.366381: step 8439, loss = 0.69280 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:54:37.260540 ops/training.py:65 2019-01-16 21:54:37.260470: step 8440, loss = 0.69032 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:54:38.154948 ops/training.py:65 2019-01-16 21:54:38.154868: step 8441, loss = 0.69254 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:54:39.048914 ops/training.py:65 2019-01-16 21:54:39.048812: step 8442, loss = 0.69614 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:54:39.947027 ops/training.py:65 2019-01-16 21:54:39.946922: step 8443, loss = 0.69691 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:54:40.844090 ops/training.py:65 2019-01-16 21:54:40.843983: step 8444, loss = 0.68763 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:54:41.740704 ops/training.py:65 2019-01-16 21:54:41.740638: step 8445, loss = 0.69403 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:54:42.637101 ops/training.py:65 2019-01-16 21:54:42.637019: step 8446, loss = 0.69245 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:54:43.531627 ops/training.py:65 2019-01-16 21:54:43.531527: step 8447, loss = 0.69451 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:54:44.426912 ops/training.py:65 2019-01-16 21:54:44.426813: step 8448, loss = 0.69505 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:54:45.322180 ops/training.py:65 2019-01-16 21:54:45.322107: step 8449, loss = 0.69361 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:54:46.216926 ops/training.py:65 2019-01-16 21:54:46.216862: step 8450, loss = 0.69323 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:54:47.113463 ops/training.py:65 2019-01-16 21:54:47.113388: step 8451, loss = 0.68862 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 21:54:48.008502 ops/training.py:65 2019-01-16 21:54:48.008398: step 8452, loss = 0.69530 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:54:48.905196 ops/training.py:65 2019-01-16 21:54:48.905096: step 8453, loss = 0.69323 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:54:49.802777 ops/training.py:65 2019-01-16 21:54:49.802676: step 8454, loss = 0.69203 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:54:50.698621 ops/training.py:65 2019-01-16 21:54:50.698557: step 8455, loss = 0.69301 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:54:51.593787 ops/training.py:65 2019-01-16 21:54:51.593718: step 8456, loss = 0.69499 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:54:52.486884 ops/training.py:65 2019-01-16 21:54:52.486827: step 8457, loss = 0.69256 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:54:53.379370 ops/training.py:65 2019-01-16 21:54:53.379314: step 8458, loss = 0.69517 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:54:54.273664 ops/training.py:65 2019-01-16 21:54:54.273597: step 8459, loss = 0.69374 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:54:55.167428 ops/training.py:65 2019-01-16 21:54:55.167365: step 8460, loss = 0.69150 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:54:56.061076 ops/training.py:65 2019-01-16 21:54:56.061010: step 8461, loss = 0.69431 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:54:56.956011 ops/training.py:65 2019-01-16 21:54:56.955911: step 8462, loss = 0.69320 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:54:57.850721 ops/training.py:65 2019-01-16 21:54:57.850614: step 8463, loss = 0.70003 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 21:54:58.744700 ops/training.py:65 2019-01-16 21:54:58.744594: step 8464, loss = 0.69163 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:54:59.638939 ops/training.py:65 2019-01-16 21:54:59.638833: step 8465, loss = 0.69049 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.78125
I1280 2019-01-16 21:55:00.532395 ops/training.py:65 2019-01-16 21:55:00.532294: step 8466, loss = 0.68955 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:55:01.426361 ops/training.py:65 2019-01-16 21:55:01.426263: step 8467, loss = 0.69189 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:55:02.320333 ops/training.py:65 2019-01-16 21:55:02.320239: step 8468, loss = 0.69585 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:55:03.214452 ops/training.py:65 2019-01-16 21:55:03.214341: step 8469, loss = 0.69005 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:55:04.108681 ops/training.py:65 2019-01-16 21:55:04.108583: step 8470, loss = 0.69348 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:55:05.004788 ops/training.py:65 2019-01-16 21:55:05.004686: step 8471, loss = 0.69446 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:55:05.900393 ops/training.py:65 2019-01-16 21:55:05.900297: step 8472, loss = 0.69553 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:55:06.795594 ops/training.py:65 2019-01-16 21:55:06.795518: step 8473, loss = 0.69167 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:55:07.689882 ops/training.py:65 2019-01-16 21:55:07.689817: step 8474, loss = 0.69404 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:55:08.584257 ops/training.py:65 2019-01-16 21:55:08.584203: step 8475, loss = 0.69360 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:55:09.478978 ops/training.py:65 2019-01-16 21:55:09.478875: step 8476, loss = 0.69135 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:55:10.373973 ops/training.py:65 2019-01-16 21:55:10.373868: step 8477, loss = 0.69416 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:55:11.267814 ops/training.py:65 2019-01-16 21:55:11.267725: step 8478, loss = 0.69056 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:55:12.164990 ops/training.py:65 2019-01-16 21:55:12.164907: step 8479, loss = 0.69394 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:55:13.060409 ops/training.py:65 2019-01-16 21:55:13.060304: step 8480, loss = 0.69471 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:55:13.956196 ops/training.py:65 2019-01-16 21:55:13.956090: step 8481, loss = 0.69240 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:55:14.851966 ops/training.py:65 2019-01-16 21:55:14.851868: step 8482, loss = 0.69252 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:55:15.749112 ops/training.py:65 2019-01-16 21:55:15.749005: step 8483, loss = 0.69335 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:55:16.644407 ops/training.py:65 2019-01-16 21:55:16.644305: step 8484, loss = 0.69496 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:55:17.540117 ops/training.py:65 2019-01-16 21:55:17.540060: step 8485, loss = 0.68761 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:55:18.435747 ops/training.py:65 2019-01-16 21:55:18.435686: step 8486, loss = 0.69008 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:55:19.328808 ops/training.py:65 2019-01-16 21:55:19.328744: step 8487, loss = 0.69672 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:55:20.222118 ops/training.py:65 2019-01-16 21:55:20.222055: step 8488, loss = 0.70210 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:55:21.114341 ops/training.py:65 2019-01-16 21:55:21.114275: step 8489, loss = 0.69403 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:55:22.009021 ops/training.py:65 2019-01-16 21:55:22.008947: step 8490, loss = 0.69542 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:55:22.907865 ops/training.py:65 2019-01-16 21:55:22.907767: step 8491, loss = 0.68880 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:55:23.803376 ops/training.py:65 2019-01-16 21:55:23.803268: step 8492, loss = 0.69557 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:55:24.700315 ops/training.py:65 2019-01-16 21:55:24.700210: step 8493, loss = 0.69200 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:55:25.598121 ops/training.py:65 2019-01-16 21:55:25.598014: step 8494, loss = 0.69232 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:55:26.493172 ops/training.py:65 2019-01-16 21:55:26.493136: step 8495, loss = 0.68737 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:55:27.388508 ops/training.py:65 2019-01-16 21:55:27.388407: step 8496, loss = 0.69281 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:55:28.284820 ops/training.py:65 2019-01-16 21:55:28.284711: step 8497, loss = 0.69363 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:55:29.180295 ops/training.py:65 2019-01-16 21:55:29.180221: step 8498, loss = 0.69478 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:55:30.074654 ops/training.py:65 2019-01-16 21:55:30.074587: step 8499, loss = 0.70454 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 21:55:30.969292 ops/training.py:65 2019-01-16 21:55:30.969231: step 8500, loss = 0.69099 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:55:31.863395 ops/training.py:65 2019-01-16 21:55:31.863331: step 8501, loss = 0.69315 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:55:32.759267 ops/training.py:65 2019-01-16 21:55:32.759203: step 8502, loss = 0.69206 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:55:33.654661 ops/training.py:65 2019-01-16 21:55:33.654592: step 8503, loss = 0.69665 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:55:34.548281 ops/training.py:65 2019-01-16 21:55:34.548215: step 8504, loss = 0.69348 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:55:35.442102 ops/training.py:65 2019-01-16 21:55:35.442037: step 8505, loss = 0.69399 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:55:36.338235 ops/training.py:65 2019-01-16 21:55:36.338160: step 8506, loss = 0.69597 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:55:37.235106 ops/training.py:65 2019-01-16 21:55:37.234998: step 8507, loss = 0.69197 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:55:38.132187 ops/training.py:65 2019-01-16 21:55:38.132109: step 8508, loss = 0.69303 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:55:39.029067 ops/training.py:65 2019-01-16 21:55:39.028988: step 8509, loss = 0.69064 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:55:39.926615 ops/training.py:65 2019-01-16 21:55:39.926508: step 8510, loss = 0.70000 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:55:40.825069 ops/training.py:65 2019-01-16 21:55:40.824963: step 8511, loss = 0.69852 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:55:41.719913 ops/training.py:65 2019-01-16 21:55:41.719842: step 8512, loss = 0.69450 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:55:42.614720 ops/training.py:65 2019-01-16 21:55:42.614629: step 8513, loss = 0.69832 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:55:43.510479 ops/training.py:65 2019-01-16 21:55:43.510376: step 8514, loss = 0.69324 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:55:44.406589 ops/training.py:65 2019-01-16 21:55:44.406483: step 8515, loss = 0.69657 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:55:45.303304 ops/training.py:65 2019-01-16 21:55:45.303192: step 8516, loss = 0.69149 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:55:46.198590 ops/training.py:65 2019-01-16 21:55:46.198480: step 8517, loss = 0.69004 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:55:47.095801 ops/training.py:65 2019-01-16 21:55:47.095698: step 8518, loss = 0.69261 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:55:47.992148 ops/training.py:65 2019-01-16 21:55:47.992041: step 8519, loss = 0.68902 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:55:48.888131 ops/training.py:65 2019-01-16 21:55:48.888028: step 8520, loss = 0.69175 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:55:49.782252 ops/training.py:65 2019-01-16 21:55:49.782173: step 8521, loss = 0.69183 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:55:50.675485 ops/training.py:65 2019-01-16 21:55:50.675425: step 8522, loss = 0.69485 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:55:51.568251 ops/training.py:65 2019-01-16 21:55:51.568203: step 8523, loss = 0.69237 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:55:52.464452 ops/training.py:65 2019-01-16 21:55:52.464415: step 8524, loss = 0.69688 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:55:53.361998 ops/training.py:65 2019-01-16 21:55:53.361968: step 8525, loss = 0.69242 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:55:54.257995 ops/training.py:65 2019-01-16 21:55:54.257964: step 8526, loss = 0.68420 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 21:55:55.154786 ops/training.py:65 2019-01-16 21:55:55.154756: step 8527, loss = 0.69154 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:55:56.048360 ops/training.py:65 2019-01-16 21:55:56.048295: step 8528, loss = 0.69062 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:55:56.941852 ops/training.py:65 2019-01-16 21:55:56.941742: step 8529, loss = 0.69056 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:55:57.837148 ops/training.py:65 2019-01-16 21:55:57.837115: step 8530, loss = 0.69425 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:55:58.735417 ops/training.py:65 2019-01-16 21:55:58.735385: step 8531, loss = 0.69615 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:55:59.629585 ops/training.py:65 2019-01-16 21:55:59.629549: step 8532, loss = 0.69412 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:56:00.523084 ops/training.py:65 2019-01-16 21:56:00.523014: step 8533, loss = 0.68835 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:56:01.418185 ops/training.py:65 2019-01-16 21:56:01.418135: step 8534, loss = 0.69578 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:56:02.315445 ops/training.py:65 2019-01-16 21:56:02.315385: step 8535, loss = 0.69463 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:56:03.209593 ops/training.py:65 2019-01-16 21:56:03.209510: step 8536, loss = 0.68865 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:56:04.104352 ops/training.py:65 2019-01-16 21:56:04.104305: step 8537, loss = 0.69003 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:56:05.000754 ops/training.py:65 2019-01-16 21:56:05.000722: step 8538, loss = 0.70310 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.25
I1280 2019-01-16 21:56:05.896156 ops/training.py:65 2019-01-16 21:56:05.896127: step 8539, loss = 0.69307 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:56:06.790621 ops/training.py:65 2019-01-16 21:56:06.790590: step 8540, loss = 0.68810 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:56:07.687310 ops/training.py:65 2019-01-16 21:56:07.687280: step 8541, loss = 0.69435 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:56:08.585885 ops/training.py:65 2019-01-16 21:56:08.585856: step 8542, loss = 0.69200 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:56:09.483277 ops/training.py:65 2019-01-16 21:56:09.483246: step 8543, loss = 0.69190 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:56:10.378669 ops/training.py:65 2019-01-16 21:56:10.378589: step 8544, loss = 0.69010 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:56:11.272483 ops/training.py:65 2019-01-16 21:56:11.272417: step 8545, loss = 0.69334 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:56:12.169564 ops/training.py:65 2019-01-16 21:56:12.169486: step 8546, loss = 0.69806 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:56:13.067167 ops/training.py:65 2019-01-16 21:56:13.067069: step 8547, loss = 0.69207 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:56:13.963427 ops/training.py:65 2019-01-16 21:56:13.963331: step 8548, loss = 0.69267 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:56:14.860484 ops/training.py:65 2019-01-16 21:56:14.860420: step 8549, loss = 0.68884 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:56:15.756568 ops/training.py:65 2019-01-16 21:56:15.756477: step 8550, loss = 0.69896 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:56:16.651662 ops/training.py:65 2019-01-16 21:56:16.651599: step 8551, loss = 0.68860 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:56:17.547921 ops/training.py:65 2019-01-16 21:56:17.547846: step 8552, loss = 0.69324 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:56:18.444463 ops/training.py:65 2019-01-16 21:56:18.444367: step 8553, loss = 0.68849 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:56:19.338773 ops/training.py:65 2019-01-16 21:56:19.338707: step 8554, loss = 0.69281 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:56:20.231536 ops/training.py:65 2019-01-16 21:56:20.231472: step 8555, loss = 0.69228 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:56:21.125833 ops/training.py:65 2019-01-16 21:56:21.125767: step 8556, loss = 0.69548 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:56:22.019134 ops/training.py:65 2019-01-16 21:56:22.019067: step 8557, loss = 0.68923 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:56:22.912282 ops/training.py:65 2019-01-16 21:56:22.912216: step 8558, loss = 0.69483 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:56:23.805708 ops/training.py:65 2019-01-16 21:56:23.805649: step 8559, loss = 0.69683 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:56:24.700315 ops/training.py:65 2019-01-16 21:56:24.700255: step 8560, loss = 0.69564 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:56:25.595188 ops/training.py:65 2019-01-16 21:56:25.595079: step 8561, loss = 0.70430 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.15625
I1280 2019-01-16 21:56:26.491047 ops/training.py:65 2019-01-16 21:56:26.490940: step 8562, loss = 0.69113 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:56:27.386445 ops/training.py:65 2019-01-16 21:56:27.386339: step 8563, loss = 0.68916 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:56:28.282277 ops/training.py:65 2019-01-16 21:56:28.282211: step 8564, loss = 0.68522 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:56:29.175983 ops/training.py:65 2019-01-16 21:56:29.175919: step 8565, loss = 0.69743 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:56:30.069492 ops/training.py:65 2019-01-16 21:56:30.069429: step 8566, loss = 0.69547 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:56:30.963322 ops/training.py:65 2019-01-16 21:56:30.963256: step 8567, loss = 0.69649 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:56:31.858256 ops/training.py:65 2019-01-16 21:56:31.858182: step 8568, loss = 0.69026 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:56:32.752465 ops/training.py:65 2019-01-16 21:56:32.752396: step 8569, loss = 0.69264 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:56:33.646946 ops/training.py:65 2019-01-16 21:56:33.646879: step 8570, loss = 0.69407 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:56:34.542287 ops/training.py:65 2019-01-16 21:56:34.542225: step 8571, loss = 0.68595 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:56:35.439857 ops/training.py:65 2019-01-16 21:56:35.439748: step 8572, loss = 0.69210 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:56:36.338089 ops/training.py:65 2019-01-16 21:56:36.337983: step 8573, loss = 0.69082 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:56:37.234316 ops/training.py:65 2019-01-16 21:56:37.234256: step 8574, loss = 0.69943 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:56:38.128935 ops/training.py:65 2019-01-16 21:56:38.128887: step 8575, loss = 0.69814 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:56:39.025454 ops/training.py:65 2019-01-16 21:56:39.025356: step 8576, loss = 0.68573 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:56:39.922043 ops/training.py:65 2019-01-16 21:56:39.921937: step 8577, loss = 0.68913 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:56:40.818457 ops/training.py:65 2019-01-16 21:56:40.818353: step 8578, loss = 0.69954 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:56:41.714696 ops/training.py:65 2019-01-16 21:56:41.714593: step 8579, loss = 0.69415 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:56:42.610963 ops/training.py:65 2019-01-16 21:56:42.610882: step 8580, loss = 0.69009 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:56:43.507063 ops/training.py:65 2019-01-16 21:56:43.506961: step 8581, loss = 0.68623 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.75
I1280 2019-01-16 21:56:44.404085 ops/training.py:65 2019-01-16 21:56:44.403977: step 8582, loss = 0.69652 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:56:45.300528 ops/training.py:65 2019-01-16 21:56:45.300430: step 8583, loss = 0.69357 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:56:46.195992 ops/training.py:65 2019-01-16 21:56:46.195888: step 8584, loss = 0.69475 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:56:47.090211 ops/training.py:65 2019-01-16 21:56:47.090107: step 8585, loss = 0.68562 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:56:47.984674 ops/training.py:65 2019-01-16 21:56:47.984605: step 8586, loss = 0.70308 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:56:48.880056 ops/training.py:65 2019-01-16 21:56:48.879984: step 8587, loss = 0.69503 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:56:49.775686 ops/training.py:65 2019-01-16 21:56:49.775618: step 8588, loss = 0.68662 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:56:50.669115 ops/training.py:65 2019-01-16 21:56:50.669049: step 8589, loss = 0.69575 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:56:51.563182 ops/training.py:65 2019-01-16 21:56:51.563115: step 8590, loss = 0.69034 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:56:52.456166 ops/training.py:65 2019-01-16 21:56:52.456103: step 8591, loss = 0.69850 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:56:53.350849 ops/training.py:65 2019-01-16 21:56:53.350793: step 8592, loss = 0.69505 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:56:54.244425 ops/training.py:65 2019-01-16 21:56:54.244355: step 8593, loss = 0.69139 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:56:55.139274 ops/training.py:65 2019-01-16 21:56:55.139208: step 8594, loss = 0.69238 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:56:56.034145 ops/training.py:65 2019-01-16 21:56:56.034075: step 8595, loss = 0.69588 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:56:56.928421 ops/training.py:65 2019-01-16 21:56:56.928355: step 8596, loss = 0.69478 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:56:57.822814 ops/training.py:65 2019-01-16 21:56:57.822747: step 8597, loss = 0.69727 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:56:58.718864 ops/training.py:65 2019-01-16 21:56:58.718805: step 8598, loss = 0.68946 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:56:59.613545 ops/training.py:65 2019-01-16 21:56:59.613473: step 8599, loss = 0.69014 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:57:00.508272 ops/training.py:65 2019-01-16 21:57:00.508169: step 8600, loss = 0.69388 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:57:01.402106 ops/training.py:65 2019-01-16 21:57:01.402013: step 8601, loss = 0.69513 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:57:02.295665 ops/training.py:65 2019-01-16 21:57:02.295566: step 8602, loss = 0.69828 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:57:03.190240 ops/training.py:65 2019-01-16 21:57:03.190142: step 8603, loss = 0.69425 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:57:04.087986 ops/training.py:65 2019-01-16 21:57:04.087885: step 8604, loss = 0.69116 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:57:04.984882 ops/training.py:65 2019-01-16 21:57:04.984791: step 8605, loss = 0.69300 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:57:05.881234 ops/training.py:65 2019-01-16 21:57:05.881166: step 8606, loss = 0.69208 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:57:06.774588 ops/training.py:65 2019-01-16 21:57:06.774523: step 8607, loss = 0.69553 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:57:07.667794 ops/training.py:65 2019-01-16 21:57:07.667725: step 8608, loss = 0.69088 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:57:08.563389 ops/training.py:65 2019-01-16 21:57:08.563332: step 8609, loss = 0.69998 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:57:09.458481 ops/training.py:65 2019-01-16 21:57:09.458412: step 8610, loss = 0.69503 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:57:10.352601 ops/training.py:65 2019-01-16 21:57:10.352532: step 8611, loss = 0.69367 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:57:11.246002 ops/training.py:65 2019-01-16 21:57:11.245932: step 8612, loss = 0.69636 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:57:12.139934 ops/training.py:65 2019-01-16 21:57:12.139851: step 8613, loss = 0.69638 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:57:13.035913 ops/training.py:65 2019-01-16 21:57:13.035814: step 8614, loss = 0.69572 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:57:13.930877 ops/training.py:65 2019-01-16 21:57:13.930774: step 8615, loss = 0.69379 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:57:14.826729 ops/training.py:65 2019-01-16 21:57:14.826630: step 8616, loss = 0.69066 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:57:15.721954 ops/training.py:65 2019-01-16 21:57:15.721846: step 8617, loss = 0.68763 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:57:16.617961 ops/training.py:65 2019-01-16 21:57:16.617857: step 8618, loss = 0.69676 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:57:17.511462 ops/training.py:65 2019-01-16 21:57:17.511358: step 8619, loss = 0.69095 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:57:18.406343 ops/training.py:65 2019-01-16 21:57:18.406234: step 8620, loss = 0.69881 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:57:19.302361 ops/training.py:65 2019-01-16 21:57:19.302276: step 8621, loss = 0.69392 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:57:20.199032 ops/training.py:65 2019-01-16 21:57:20.198943: step 8622, loss = 0.69333 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:57:21.095025 ops/training.py:65 2019-01-16 21:57:21.094937: step 8623, loss = 0.69558 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:57:21.991290 ops/training.py:65 2019-01-16 21:57:21.991223: step 8624, loss = 0.69609 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:57:22.885948 ops/training.py:65 2019-01-16 21:57:22.885880: step 8625, loss = 0.69636 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:57:23.781658 ops/training.py:65 2019-01-16 21:57:23.781596: step 8626, loss = 0.69648 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:57:24.677133 ops/training.py:65 2019-01-16 21:57:24.677063: step 8627, loss = 0.69761 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:57:25.571007 ops/training.py:65 2019-01-16 21:57:25.570940: step 8628, loss = 0.70157 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:57:26.465921 ops/training.py:65 2019-01-16 21:57:26.465856: step 8629, loss = 0.68762 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:57:27.361104 ops/training.py:65 2019-01-16 21:57:27.361026: step 8630, loss = 0.69956 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:57:28.255640 ops/training.py:65 2019-01-16 21:57:28.255579: step 8631, loss = 0.69139 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:57:29.149815 ops/training.py:65 2019-01-16 21:57:29.149753: step 8632, loss = 0.68817 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:57:30.043438 ops/training.py:65 2019-01-16 21:57:30.043372: step 8633, loss = 0.68963 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:57:30.938576 ops/training.py:65 2019-01-16 21:57:30.938509: step 8634, loss = 0.69928 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:57:31.833022 ops/training.py:65 2019-01-16 21:57:31.832954: step 8635, loss = 0.69319 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:57:32.727773 ops/training.py:65 2019-01-16 21:57:32.727708: step 8636, loss = 0.68971 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:57:33.622085 ops/training.py:65 2019-01-16 21:57:33.622017: step 8637, loss = 0.69556 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:57:34.516636 ops/training.py:65 2019-01-16 21:57:34.516569: step 8638, loss = 0.69644 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:57:35.411026 ops/training.py:65 2019-01-16 21:57:35.410957: step 8639, loss = 0.69945 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:57:36.305053 ops/training.py:65 2019-01-16 21:57:36.304995: step 8640, loss = 0.69183 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:57:37.198680 ops/training.py:65 2019-01-16 21:57:37.198617: step 8641, loss = 0.68941 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:57:38.092127 ops/training.py:65 2019-01-16 21:57:38.092068: step 8642, loss = 0.69550 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:57:38.986454 ops/training.py:65 2019-01-16 21:57:38.986396: step 8643, loss = 0.69818 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:57:39.880574 ops/training.py:65 2019-01-16 21:57:39.880521: step 8644, loss = 0.68843 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:57:40.775323 ops/training.py:65 2019-01-16 21:57:40.775268: step 8645, loss = 0.69284 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:57:41.671191 ops/training.py:65 2019-01-16 21:57:41.671131: step 8646, loss = 0.68888 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:57:42.564686 ops/training.py:65 2019-01-16 21:57:42.564612: step 8647, loss = 0.69096 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:57:43.460760 ops/training.py:65 2019-01-16 21:57:43.460689: step 8648, loss = 0.68873 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:57:44.356446 ops/training.py:65 2019-01-16 21:57:44.356381: step 8649, loss = 0.69356 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:57:45.249778 ops/training.py:65 2019-01-16 21:57:45.249717: step 8650, loss = 0.69922 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:57:46.142853 ops/training.py:65 2019-01-16 21:57:46.142784: step 8651, loss = 0.68932 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:57:47.035682 ops/training.py:65 2019-01-16 21:57:47.035625: step 8652, loss = 0.69283 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:57:47.928675 ops/training.py:65 2019-01-16 21:57:47.928608: step 8653, loss = 0.70181 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:57:48.821787 ops/training.py:65 2019-01-16 21:57:48.821725: step 8654, loss = 0.69826 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:57:49.715717 ops/training.py:65 2019-01-16 21:57:49.715666: step 8655, loss = 0.69254 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:57:50.609941 ops/training.py:65 2019-01-16 21:57:50.609886: step 8656, loss = 0.69541 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:57:51.503401 ops/training.py:65 2019-01-16 21:57:51.503345: step 8657, loss = 0.68386 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:57:52.397455 ops/training.py:65 2019-01-16 21:57:52.397405: step 8658, loss = 0.68831 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:57:53.291629 ops/training.py:65 2019-01-16 21:57:53.291576: step 8659, loss = 0.68858 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:57:54.185004 ops/training.py:65 2019-01-16 21:57:54.184944: step 8660, loss = 0.68575 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:57:55.077850 ops/training.py:65 2019-01-16 21:57:55.077785: step 8661, loss = 0.69402 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:57:55.971782 ops/training.py:65 2019-01-16 21:57:55.971722: step 8662, loss = 0.69212 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:57:56.866118 ops/training.py:65 2019-01-16 21:57:56.866067: step 8663, loss = 0.69572 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:57:57.760389 ops/training.py:65 2019-01-16 21:57:57.760294: step 8664, loss = 0.69276 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:57:58.658330 ops/training.py:65 2019-01-16 21:57:58.658220: step 8665, loss = 0.69510 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:57:59.556653 ops/training.py:65 2019-01-16 21:57:59.556545: step 8666, loss = 0.69577 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:58:00.452950 ops/training.py:65 2019-01-16 21:58:00.452882: step 8667, loss = 0.69342 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:58:01.348075 ops/training.py:65 2019-01-16 21:58:01.348014: step 8668, loss = 0.68234 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:58:02.242255 ops/training.py:65 2019-01-16 21:58:02.242189: step 8669, loss = 0.69326 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:58:03.137372 ops/training.py:65 2019-01-16 21:58:03.137306: step 8670, loss = 0.69760 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:58:04.032375 ops/training.py:65 2019-01-16 21:58:04.032309: step 8671, loss = 0.69488 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:58:04.927253 ops/training.py:65 2019-01-16 21:58:04.927195: step 8672, loss = 0.69131 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:58:05.822324 ops/training.py:65 2019-01-16 21:58:05.822215: step 8673, loss = 0.69194 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:58:06.718146 ops/training.py:65 2019-01-16 21:58:06.718040: step 8674, loss = 0.69127 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:58:07.613519 ops/training.py:65 2019-01-16 21:58:07.613417: step 8675, loss = 0.69755 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:58:08.509596 ops/training.py:65 2019-01-16 21:58:08.509524: step 8676, loss = 0.69140 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:58:09.404865 ops/training.py:65 2019-01-16 21:58:09.404804: step 8677, loss = 0.68384 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:58:10.300819 ops/training.py:65 2019-01-16 21:58:10.300712: step 8678, loss = 0.68977 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:58:11.197503 ops/training.py:65 2019-01-16 21:58:11.197427: step 8679, loss = 0.69895 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:58:12.094761 ops/training.py:65 2019-01-16 21:58:12.094679: step 8680, loss = 0.69271 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:58:12.989825 ops/training.py:65 2019-01-16 21:58:12.989750: step 8681, loss = 0.68912 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:58:13.887904 ops/training.py:65 2019-01-16 21:58:13.887797: step 8682, loss = 0.69338 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:58:14.784153 ops/training.py:65 2019-01-16 21:58:14.784051: step 8683, loss = 0.69341 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:58:15.680497 ops/training.py:65 2019-01-16 21:58:15.680424: step 8684, loss = 0.70065 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:58:16.575702 ops/training.py:65 2019-01-16 21:58:16.575636: step 8685, loss = 0.69173 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:58:17.470695 ops/training.py:65 2019-01-16 21:58:17.470607: step 8686, loss = 0.70329 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:58:18.365622 ops/training.py:65 2019-01-16 21:58:18.365554: step 8687, loss = 0.68836 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:58:19.259643 ops/training.py:65 2019-01-16 21:58:19.259575: step 8688, loss = 0.69933 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:58:20.154693 ops/training.py:65 2019-01-16 21:58:20.154626: step 8689, loss = 0.69667 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:58:21.049243 ops/training.py:65 2019-01-16 21:58:21.049175: step 8690, loss = 0.69766 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:58:21.944447 ops/training.py:65 2019-01-16 21:58:21.944387: step 8691, loss = 0.69450 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:58:22.839531 ops/training.py:65 2019-01-16 21:58:22.839431: step 8692, loss = 0.70200 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:58:23.737263 ops/training.py:65 2019-01-16 21:58:23.737158: step 8693, loss = 0.68940 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:58:24.632158 ops/training.py:65 2019-01-16 21:58:24.632062: step 8694, loss = 0.69341 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:58:25.528124 ops/training.py:65 2019-01-16 21:58:25.528061: step 8695, loss = 0.68739 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:58:26.422486 ops/training.py:65 2019-01-16 21:58:26.422430: step 8696, loss = 0.69024 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:58:27.318146 ops/training.py:65 2019-01-16 21:58:27.318080: step 8697, loss = 0.69984 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:58:28.212717 ops/training.py:65 2019-01-16 21:58:28.212656: step 8698, loss = 0.70596 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 21:58:29.107137 ops/training.py:65 2019-01-16 21:58:29.107073: step 8699, loss = 0.69751 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:58:30.001670 ops/training.py:65 2019-01-16 21:58:30.001604: step 8700, loss = 0.69678 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:58:30.896643 ops/training.py:65 2019-01-16 21:58:30.896578: step 8701, loss = 0.69125 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:58:31.792542 ops/training.py:65 2019-01-16 21:58:31.792467: step 8702, loss = 0.69101 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:58:32.687255 ops/training.py:65 2019-01-16 21:58:32.687186: step 8703, loss = 0.69543 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:58:33.581714 ops/training.py:65 2019-01-16 21:58:33.581647: step 8704, loss = 0.68561 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:58:34.475336 ops/training.py:65 2019-01-16 21:58:34.475276: step 8705, loss = 0.69262 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:58:35.369559 ops/training.py:65 2019-01-16 21:58:35.369496: step 8706, loss = 0.69326 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:58:36.263120 ops/training.py:65 2019-01-16 21:58:36.263057: step 8707, loss = 0.69487 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:58:37.157394 ops/training.py:65 2019-01-16 21:58:37.157330: step 8708, loss = 0.69154 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:58:38.052874 ops/training.py:65 2019-01-16 21:58:38.052809: step 8709, loss = 0.69396 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:58:38.947999 ops/training.py:65 2019-01-16 21:58:38.947908: step 8710, loss = 0.70170 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:58:39.844588 ops/training.py:65 2019-01-16 21:58:39.844441: step 8711, loss = 0.69386 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:58:40.741681 ops/training.py:65 2019-01-16 21:58:40.741574: step 8712, loss = 0.70123 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:58:41.636505 ops/training.py:65 2019-01-16 21:58:41.636455: step 8713, loss = 0.69623 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:58:42.530852 ops/training.py:65 2019-01-16 21:58:42.530773: step 8714, loss = 0.69546 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:58:43.426943 ops/training.py:65 2019-01-16 21:58:43.426842: step 8715, loss = 0.68615 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:58:44.321240 ops/training.py:65 2019-01-16 21:58:44.321142: step 8716, loss = 0.68465 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:58:45.214835 ops/training.py:65 2019-01-16 21:58:45.214777: step 8717, loss = 0.69280 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:58:46.107944 ops/training.py:65 2019-01-16 21:58:46.107879: step 8718, loss = 0.68813 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:58:47.001730 ops/training.py:65 2019-01-16 21:58:47.001669: step 8719, loss = 0.69412 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:58:47.896722 ops/training.py:65 2019-01-16 21:58:47.896640: step 8720, loss = 0.70364 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:58:48.791886 ops/training.py:65 2019-01-16 21:58:48.791782: step 8721, loss = 0.69797 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:58:49.687065 ops/training.py:65 2019-01-16 21:58:49.686966: step 8722, loss = 0.69730 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:58:50.583152 ops/training.py:65 2019-01-16 21:58:50.583044: step 8723, loss = 0.68823 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:58:51.480239 ops/training.py:65 2019-01-16 21:58:51.480155: step 8724, loss = 0.68839 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:58:52.375390 ops/training.py:65 2019-01-16 21:58:52.375333: step 8725, loss = 0.69130 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:58:53.269060 ops/training.py:65 2019-01-16 21:58:53.268998: step 8726, loss = 0.68942 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:58:54.162103 ops/training.py:65 2019-01-16 21:58:54.162040: step 8727, loss = 0.69028 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:58:55.055735 ops/training.py:65 2019-01-16 21:58:55.055674: step 8728, loss = 0.68314 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:58:55.950348 ops/training.py:65 2019-01-16 21:58:55.950283: step 8729, loss = 0.69780 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:58:56.844987 ops/training.py:65 2019-01-16 21:58:56.844928: step 8730, loss = 0.70095 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:58:57.740900 ops/training.py:65 2019-01-16 21:58:57.740794: step 8731, loss = 0.69180 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:58:58.637644 ops/training.py:65 2019-01-16 21:58:58.637538: step 8732, loss = 0.70306 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:58:59.533899 ops/training.py:65 2019-01-16 21:58:59.533799: step 8733, loss = 0.69478 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:59:00.428143 ops/training.py:65 2019-01-16 21:59:00.428082: step 8734, loss = 0.69888 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:59:01.322613 ops/training.py:65 2019-01-16 21:59:01.322555: step 8735, loss = 0.69224 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:59:02.218261 ops/training.py:65 2019-01-16 21:59:02.218153: step 8736, loss = 0.68453 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:59:03.115311 ops/training.py:65 2019-01-16 21:59:03.115208: step 8737, loss = 0.70057 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:59:04.011686 ops/training.py:65 2019-01-16 21:59:04.011623: step 8738, loss = 0.70267 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:59:04.905933 ops/training.py:65 2019-01-16 21:59:04.905871: step 8739, loss = 0.70037 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:59:05.799954 ops/training.py:65 2019-01-16 21:59:05.799894: step 8740, loss = 0.68714 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:59:06.694260 ops/training.py:65 2019-01-16 21:59:06.694192: step 8741, loss = 0.69417 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:59:07.588700 ops/training.py:65 2019-01-16 21:59:07.588639: step 8742, loss = 0.69223 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:59:08.484332 ops/training.py:65 2019-01-16 21:59:08.484273: step 8743, loss = 0.69819 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:59:09.380807 ops/training.py:65 2019-01-16 21:59:09.380729: step 8744, loss = 0.69520 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:59:10.276905 ops/training.py:65 2019-01-16 21:59:10.276802: step 8745, loss = 0.69437 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:59:11.172379 ops/training.py:65 2019-01-16 21:59:11.172318: step 8746, loss = 0.70198 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:59:12.066193 ops/training.py:65 2019-01-16 21:59:12.066134: step 8747, loss = 0.68741 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:59:12.959291 ops/training.py:65 2019-01-16 21:59:12.959213: step 8748, loss = 0.68623 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:59:13.854366 ops/training.py:65 2019-01-16 21:59:13.854267: step 8749, loss = 0.69762 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:59:14.748751 ops/training.py:65 2019-01-16 21:59:14.748684: step 8750, loss = 0.69749 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:59:15.642292 ops/training.py:65 2019-01-16 21:59:15.642229: step 8751, loss = 0.70049 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:59:16.537484 ops/training.py:65 2019-01-16 21:59:16.537411: step 8752, loss = 0.69307 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:59:17.432992 ops/training.py:65 2019-01-16 21:59:17.432895: step 8753, loss = 0.70049 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:59:18.331032 ops/training.py:65 2019-01-16 21:59:18.330924: step 8754, loss = 0.69415 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:59:19.227101 ops/training.py:65 2019-01-16 21:59:19.227041: step 8755, loss = 0.68737 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:59:20.120720 ops/training.py:65 2019-01-16 21:59:20.120658: step 8756, loss = 0.69486 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:59:21.016197 ops/training.py:65 2019-01-16 21:59:21.016151: step 8757, loss = 0.69389 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:59:21.911237 ops/training.py:65 2019-01-16 21:59:21.911158: step 8758, loss = 0.69372 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:59:22.808028 ops/training.py:65 2019-01-16 21:59:22.807931: step 8759, loss = 0.69536 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:59:23.704058 ops/training.py:65 2019-01-16 21:59:23.703999: step 8760, loss = 0.69096 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:59:24.597725 ops/training.py:65 2019-01-16 21:59:24.597667: step 8761, loss = 0.69516 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:59:25.492774 ops/training.py:65 2019-01-16 21:59:25.492698: step 8762, loss = 0.68967 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:59:26.390901 ops/training.py:65 2019-01-16 21:59:26.390821: step 8763, loss = 0.69346 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:59:27.286275 ops/training.py:65 2019-01-16 21:59:27.286211: step 8764, loss = 0.69181 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:59:28.179888 ops/training.py:65 2019-01-16 21:59:28.179824: step 8765, loss = 0.69706 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:59:29.075685 ops/training.py:65 2019-01-16 21:59:29.075613: step 8766, loss = 0.68888 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:59:29.971892 ops/training.py:65 2019-01-16 21:59:29.971791: step 8767, loss = 0.69418 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:59:30.868288 ops/training.py:65 2019-01-16 21:59:30.868223: step 8768, loss = 0.69473 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:59:31.765284 ops/training.py:65 2019-01-16 21:59:31.765179: step 8769, loss = 0.69247 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:59:32.660506 ops/training.py:65 2019-01-16 21:59:32.660446: step 8770, loss = 0.69904 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 21:59:33.554474 ops/training.py:65 2019-01-16 21:59:33.554413: step 8771, loss = 0.70021 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 21:59:34.448404 ops/training.py:65 2019-01-16 21:59:34.448338: step 8772, loss = 0.69092 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:59:35.341202 ops/training.py:65 2019-01-16 21:59:35.341136: step 8773, loss = 0.68699 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:59:36.234219 ops/training.py:65 2019-01-16 21:59:36.234160: step 8774, loss = 0.68986 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:59:37.128852 ops/training.py:65 2019-01-16 21:59:37.128786: step 8775, loss = 0.69221 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:59:38.024372 ops/training.py:65 2019-01-16 21:59:38.024272: step 8776, loss = 0.69518 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:59:38.919285 ops/training.py:65 2019-01-16 21:59:38.919225: step 8777, loss = 0.69217 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:59:39.812758 ops/training.py:65 2019-01-16 21:59:39.812694: step 8778, loss = 0.69177 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:59:40.706473 ops/training.py:65 2019-01-16 21:59:40.706409: step 8779, loss = 0.68898 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:59:41.599938 ops/training.py:65 2019-01-16 21:59:41.599886: step 8780, loss = 0.69372 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:59:42.494032 ops/training.py:65 2019-01-16 21:59:42.493952: step 8781, loss = 0.69379 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 21:59:43.391034 ops/training.py:65 2019-01-16 21:59:43.390963: step 8782, loss = 0.69577 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:59:44.287014 ops/training.py:65 2019-01-16 21:59:44.286914: step 8783, loss = 0.69201 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:59:45.182424 ops/training.py:65 2019-01-16 21:59:45.182327: step 8784, loss = 0.69330 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:59:46.077456 ops/training.py:65 2019-01-16 21:59:46.077387: step 8785, loss = 0.68835 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:59:46.971755 ops/training.py:65 2019-01-16 21:59:46.971686: step 8786, loss = 0.69762 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 21:59:47.868884 ops/training.py:65 2019-01-16 21:59:47.868781: step 8787, loss = 0.69461 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 21:59:48.765153 ops/training.py:65 2019-01-16 21:59:48.765058: step 8788, loss = 0.69384 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:59:49.662266 ops/training.py:65 2019-01-16 21:59:49.662156: step 8789, loss = 0.68653 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 21:59:50.558177 ops/training.py:65 2019-01-16 21:59:50.558117: step 8790, loss = 0.68761 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:59:51.451747 ops/training.py:65 2019-01-16 21:59:51.451688: step 8791, loss = 0.69481 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 21:59:52.345806 ops/training.py:65 2019-01-16 21:59:52.345743: step 8792, loss = 0.69224 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:59:53.239831 ops/training.py:65 2019-01-16 21:59:53.239769: step 8793, loss = 0.69070 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 21:59:54.133741 ops/training.py:65 2019-01-16 21:59:54.133677: step 8794, loss = 0.69231 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:59:55.026670 ops/training.py:65 2019-01-16 21:59:55.026612: step 8795, loss = 0.69064 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 21:59:55.920278 ops/training.py:65 2019-01-16 21:59:55.920212: step 8796, loss = 0.69544 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:59:56.813428 ops/training.py:65 2019-01-16 21:59:56.813370: step 8797, loss = 0.69126 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 21:59:57.705788 ops/training.py:65 2019-01-16 21:59:57.705725: step 8798, loss = 0.69127 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 21:59:58.599140 ops/training.py:65 2019-01-16 21:59:58.599080: step 8799, loss = 0.69597 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 21:59:59.495673 ops/training.py:65 2019-01-16 21:59:59.495591: step 8800, loss = 0.69443 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 22:00:00.392556 ops/training.py:65 2019-01-16 22:00:00.392451: step 8801, loss = 0.69029 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 22:00:01.288136 ops/training.py:65 2019-01-16 22:00:01.288067: step 8802, loss = 0.69853 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 22:00:02.184907 ops/training.py:65 2019-01-16 22:00:02.184803: step 8803, loss = 0.69601 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 22:00:03.080024 ops/training.py:65 2019-01-16 22:00:03.079922: step 8804, loss = 0.69638 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 22:00:03.975234 ops/training.py:65 2019-01-16 22:00:03.975169: step 8805, loss = 0.69651 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 22:00:04.869851 ops/training.py:65 2019-01-16 22:00:04.869785: step 8806, loss = 0.69670 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 22:00:05.765824 ops/training.py:65 2019-01-16 22:00:05.765745: step 8807, loss = 0.69068 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 22:00:06.661713 ops/training.py:65 2019-01-16 22:00:06.661615: step 8808, loss = 0.69350 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 22:00:07.557836 ops/training.py:65 2019-01-16 22:00:07.557728: step 8809, loss = 0.69687 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 22:00:08.454882 ops/training.py:65 2019-01-16 22:00:08.454816: step 8810, loss = 0.69163 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 22:00:09.351465 ops/training.py:65 2019-01-16 22:00:09.351362: step 8811, loss = 0.69460 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 22:00:10.246801 ops/training.py:65 2019-01-16 22:00:10.246739: step 8812, loss = 0.69138 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 22:00:11.139660 ops/training.py:65 2019-01-16 22:00:11.139595: step 8813, loss = 0.69135 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 22:00:12.033025 ops/training.py:65 2019-01-16 22:00:12.032966: step 8814, loss = 0.69775 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 22:00:12.926984 ops/training.py:65 2019-01-16 22:00:12.926907: step 8815, loss = 0.69392 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 22:00:13.822274 ops/training.py:65 2019-01-16 22:00:13.822144: step 8816, loss = 0.69661 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 22:00:14.718530 ops/training.py:65 2019-01-16 22:00:14.718457: step 8817, loss = 0.68671 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.71875
I1280 2019-01-16 22:00:15.615095 ops/training.py:65 2019-01-16 22:00:15.614990: step 8818, loss = 0.69725 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 22:00:16.509740 ops/training.py:65 2019-01-16 22:00:16.509644: step 8819, loss = 0.69480 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 22:00:17.403387 ops/training.py:65 2019-01-16 22:00:17.403325: step 8820, loss = 0.69766 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 22:00:18.297345 ops/training.py:65 2019-01-16 22:00:18.297275: step 8821, loss = 0.69674 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 22:00:19.192050 ops/training.py:65 2019-01-16 22:00:19.191984: step 8822, loss = 0.69267 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 22:00:20.086137 ops/training.py:65 2019-01-16 22:00:20.086072: step 8823, loss = 0.69351 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 22:00:20.978667 ops/training.py:65 2019-01-16 22:00:20.978605: step 8824, loss = 0.69829 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 22:00:21.872678 ops/training.py:65 2019-01-16 22:00:21.872618: step 8825, loss = 0.69505 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 22:00:22.766661 ops/training.py:65 2019-01-16 22:00:22.766595: step 8826, loss = 0.69251 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 22:00:23.660391 ops/training.py:65 2019-01-16 22:00:23.660329: step 8827, loss = 0.68993 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 22:00:24.554129 ops/training.py:65 2019-01-16 22:00:24.554066: step 8828, loss = 0.69504 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 22:00:25.446301 ops/training.py:65 2019-01-16 22:00:25.446235: step 8829, loss = 0.69795 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 22:00:26.338965 ops/training.py:65 2019-01-16 22:00:26.338914: step 8830, loss = 0.69327 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 22:00:27.234636 ops/training.py:65 2019-01-16 22:00:27.234596: step 8831, loss = 0.69888 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 22:00:28.131479 ops/training.py:65 2019-01-16 22:00:28.131416: step 8832, loss = 0.69200 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 22:00:29.024921 ops/training.py:65 2019-01-16 22:00:29.024827: step 8833, loss = 0.69553 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 22:00:29.919522 ops/training.py:65 2019-01-16 22:00:29.919425: step 8834, loss = 0.69408 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 22:00:30.815473 ops/training.py:65 2019-01-16 22:00:30.815374: step 8835, loss = 0.69531 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 22:00:31.711329 ops/training.py:65 2019-01-16 22:00:31.711265: step 8836, loss = 0.69195 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 22:00:32.605560 ops/training.py:65 2019-01-16 22:00:32.605497: step 8837, loss = 0.69482 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 22:00:33.501527 ops/training.py:65 2019-01-16 22:00:33.501423: step 8838, loss = 0.69258 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 22:00:34.397761 ops/training.py:65 2019-01-16 22:00:34.397699: step 8839, loss = 0.69334 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 22:00:35.291129 ops/training.py:65 2019-01-16 22:00:35.291066: step 8840, loss = 0.69251 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 22:00:36.184190 ops/training.py:65 2019-01-16 22:00:36.184128: step 8841, loss = 0.69379 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 22:00:37.078360 ops/training.py:65 2019-01-16 22:00:37.078290: step 8842, loss = 0.69271 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 22:00:37.973951 ops/training.py:65 2019-01-16 22:00:37.973819: step 8843, loss = 0.69435 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 22:00:38.870965 ops/training.py:65 2019-01-16 22:00:38.870858: step 8844, loss = 0.69265 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 22:00:39.767603 ops/training.py:65 2019-01-16 22:00:39.767498: step 8845, loss = 0.69059 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 22:00:40.663936 ops/training.py:65 2019-01-16 22:00:40.663864: step 8846, loss = 0.69258 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 22:00:41.562784 ops/training.py:65 2019-01-16 22:00:41.562690: step 8847, loss = 0.69629 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 22:00:42.462079 ops/training.py:65 2019-01-16 22:00:42.461998: step 8848, loss = 0.68959 (35.6 examples/sec; 0.898 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 22:00:43.358005 ops/training.py:65 2019-01-16 22:00:43.357900: step 8849, loss = 0.69485 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 22:00:44.252629 ops/training.py:65 2019-01-16 22:00:44.252539: step 8850, loss = 0.69500 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 22:00:45.145987 ops/training.py:65 2019-01-16 22:00:45.145923: step 8851, loss = 0.69195 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 22:00:46.039994 ops/training.py:65 2019-01-16 22:00:46.039921: step 8852, loss = 0.69457 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 22:00:46.935127 ops/training.py:65 2019-01-16 22:00:46.935067: step 8853, loss = 0.69732 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 22:00:47.829545 ops/training.py:65 2019-01-16 22:00:47.829479: step 8854, loss = 0.69415 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 22:00:48.724242 ops/training.py:65 2019-01-16 22:00:48.724175: step 8855, loss = 0.69474 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 22:00:49.618788 ops/training.py:65 2019-01-16 22:00:49.618720: step 8856, loss = 0.68336 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 22:00:50.512622 ops/training.py:65 2019-01-16 22:00:50.512555: step 8857, loss = 0.68923 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 22:00:51.406607 ops/training.py:65 2019-01-16 22:00:51.406541: step 8858, loss = 0.69058 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 22:00:52.302138 ops/training.py:65 2019-01-16 22:00:52.302078: step 8859, loss = 0.68972 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 22:00:53.197324 ops/training.py:65 2019-01-16 22:00:53.197236: step 8860, loss = 0.69996 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I1280 2019-01-16 22:00:54.091671 ops/training.py:65 2019-01-16 22:00:54.091580: step 8861, loss = 0.68988 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 22:00:54.986235 ops/training.py:65 2019-01-16 22:00:54.986172: step 8862, loss = 0.69136 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 22:00:55.880221 ops/training.py:65 2019-01-16 22:00:55.880160: step 8863, loss = 0.69275 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 22:00:56.774089 ops/training.py:65 2019-01-16 22:00:56.774031: step 8864, loss = 0.69901 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 22:00:57.669765 ops/training.py:65 2019-01-16 22:00:57.669700: step 8865, loss = 0.70313 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 22:00:58.565346 ops/training.py:65 2019-01-16 22:00:58.565241: step 8866, loss = 0.68935 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 22:00:59.460357 ops/training.py:65 2019-01-16 22:00:59.460252: step 8867, loss = 0.69578 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 22:01:00.356609 ops/training.py:65 2019-01-16 22:01:00.356531: step 8868, loss = 0.68849 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 22:01:01.251317 ops/training.py:65 2019-01-16 22:01:01.251242: step 8869, loss = 0.69216 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 22:01:02.145514 ops/training.py:65 2019-01-16 22:01:02.145437: step 8870, loss = 0.69907 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 22:01:03.040642 ops/training.py:65 2019-01-16 22:01:03.040552: step 8871, loss = 0.69632 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 22:01:03.935555 ops/training.py:65 2019-01-16 22:01:03.935457: step 8872, loss = 0.69334 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 22:01:04.829723 ops/training.py:65 2019-01-16 22:01:04.829654: step 8873, loss = 0.68935 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 22:01:05.726534 ops/training.py:65 2019-01-16 22:01:05.726491: step 8874, loss = 0.69016 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 22:01:06.623002 ops/training.py:65 2019-01-16 22:01:06.622970: step 8875, loss = 0.68925 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 22:01:07.519514 ops/training.py:65 2019-01-16 22:01:07.519483: step 8876, loss = 0.69409 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 22:01:08.414239 ops/training.py:65 2019-01-16 22:01:08.414159: step 8877, loss = 0.69194 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 22:01:09.310754 ops/training.py:65 2019-01-16 22:01:09.310671: step 8878, loss = 0.68891 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 22:01:10.206727 ops/training.py:65 2019-01-16 22:01:10.206629: step 8879, loss = 0.69333 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 22:01:11.101346 ops/training.py:65 2019-01-16 22:01:11.101256: step 8880, loss = 0.69281 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 22:01:11.996564 ops/training.py:65 2019-01-16 22:01:11.996500: step 8881, loss = 0.68689 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I1280 2019-01-16 22:01:12.889913 ops/training.py:65 2019-01-16 22:01:12.889829: step 8882, loss = 0.69668 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.3125
I1280 2019-01-16 22:01:13.786394 ops/training.py:65 2019-01-16 22:01:13.786332: step 8883, loss = 0.69749 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 22:01:14.682206 ops/training.py:65 2019-01-16 22:01:14.682107: step 8884, loss = 0.69392 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 22:01:15.578714 ops/training.py:65 2019-01-16 22:01:15.578611: step 8885, loss = 0.69267 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 22:01:16.473870 ops/training.py:65 2019-01-16 22:01:16.473764: step 8886, loss = 0.69523 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 22:01:17.368396 ops/training.py:65 2019-01-16 22:01:17.368327: step 8887, loss = 0.69104 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 22:01:18.261917 ops/training.py:65 2019-01-16 22:01:18.261858: step 8888, loss = 0.69113 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 22:01:19.154932 ops/training.py:65 2019-01-16 22:01:19.154869: step 8889, loss = 0.69213 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 22:01:20.047848 ops/training.py:65 2019-01-16 22:01:20.047788: step 8890, loss = 0.69512 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 22:01:20.940342 ops/training.py:65 2019-01-16 22:01:20.940273: step 8891, loss = 0.69613 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 22:01:21.833402 ops/training.py:65 2019-01-16 22:01:21.833341: step 8892, loss = 0.69378 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 22:01:22.725320 ops/training.py:65 2019-01-16 22:01:22.725263: step 8893, loss = 0.68977 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 22:01:23.619241 ops/training.py:65 2019-01-16 22:01:23.619179: step 8894, loss = 0.69137 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 22:01:24.516275 ops/training.py:65 2019-01-16 22:01:24.516206: step 8895, loss = 0.69089 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 22:01:25.412316 ops/training.py:65 2019-01-16 22:01:25.412207: step 8896, loss = 0.69318 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 22:01:26.308566 ops/training.py:65 2019-01-16 22:01:26.308472: step 8897, loss = 0.69664 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 22:01:27.203416 ops/training.py:65 2019-01-16 22:01:27.203336: step 8898, loss = 0.69337 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 22:01:28.099341 ops/training.py:65 2019-01-16 22:01:28.099238: step 8899, loss = 0.69300 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 22:01:28.996738 ops/training.py:65 2019-01-16 22:01:28.996628: step 8900, loss = 0.69380 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 22:01:29.893161 ops/training.py:65 2019-01-16 22:01:29.893066: step 8901, loss = 0.69349 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 22:01:30.791670 ops/training.py:65 2019-01-16 22:01:30.791565: step 8902, loss = 0.69506 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 22:01:31.688904 ops/training.py:65 2019-01-16 22:01:31.688806: step 8903, loss = 0.68996 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 22:01:32.585069 ops/training.py:65 2019-01-16 22:01:32.584974: step 8904, loss = 0.69366 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 22:01:33.482863 ops/training.py:65 2019-01-16 22:01:33.482764: step 8905, loss = 0.69468 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 22:01:34.380507 ops/training.py:65 2019-01-16 22:01:34.380422: step 8906, loss = 0.69302 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 22:01:35.276503 ops/training.py:65 2019-01-16 22:01:35.276412: step 8907, loss = 0.69252 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 22:01:36.171818 ops/training.py:65 2019-01-16 22:01:36.171731: step 8908, loss = 0.69349 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 22:01:37.067092 ops/training.py:65 2019-01-16 22:01:37.067004: step 8909, loss = 0.69259 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I1280 2019-01-16 22:01:37.961814 ops/training.py:65 2019-01-16 22:01:37.961754: step 8910, loss = 0.69297 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 22:01:38.856907 ops/training.py:65 2019-01-16 22:01:38.856836: step 8911, loss = 0.69105 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I1280 2019-01-16 22:01:39.751494 ops/training.py:65 2019-01-16 22:01:39.751416: step 8912, loss = 0.69514 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I1280 2019-01-16 22:01:40.646014 ops/training.py:65 2019-01-16 22:01:40.645929: step 8913, loss = 0.69927 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I1280 2019-01-16 22:01:41.542797 ops/training.py:65 2019-01-16 22:01:41.542707: step 8914, loss = 0.69061 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.625
I1280 2019-01-16 22:01:42.438637 ops/training.py:65 2019-01-16 22:01:42.438565: step 8915, loss = 0.69522 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 22:01:43.333072 ops/training.py:65 2019-01-16 22:01:43.332991: step 8916, loss = 0.69209 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 22:01:44.231167 ops/training.py:65 2019-01-16 22:01:44.231072: step 8917, loss = 0.69334 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 22:01:45.128340 ops/training.py:65 2019-01-16 22:01:45.128239: step 8918, loss = 0.68655 (35.7 examples/sec; 0.896 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 22:01:46.024028 ops/training.py:65 2019-01-16 22:01:46.023926: step 8919, loss = 0.68896 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I1280 2019-01-16 22:01:46.920136 ops/training.py:65 2019-01-16 22:01:46.920037: step 8920, loss = 0.69179 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 22:01:47.816517 ops/training.py:65 2019-01-16 22:01:47.816410: step 8921, loss = 0.69087 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I1280 2019-01-16 22:01:48.710407 ops/training.py:65 2019-01-16 22:01:48.710328: step 8922, loss = 0.69304 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 22:01:49.604494 ops/training.py:65 2019-01-16 22:01:49.604396: step 8923, loss = 0.68101 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.75
I1280 2019-01-16 22:01:50.499080 ops/training.py:65 2019-01-16 22:01:50.498992: step 8924, loss = 0.70320 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.28125
I1280 2019-01-16 22:01:51.393754 ops/training.py:65 2019-01-16 22:01:51.393672: step 8925, loss = 0.69424 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 22:01:52.287525 ops/training.py:65 2019-01-16 22:01:52.287426: step 8926, loss = 0.68782 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I1280 2019-01-16 22:01:53.182269 ops/training.py:65 2019-01-16 22:01:53.182172: step 8927, loss = 0.69674 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 22:01:54.078709 ops/training.py:65 2019-01-16 22:01:54.078601: step 8928, loss = 0.69821 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.46875
I1280 2019-01-16 22:01:54.973278 ops/training.py:65 2019-01-16 22:01:54.973175: step 8929, loss = 0.69632 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I1280 2019-01-16 22:01:55.868155 ops/training.py:65 2019-01-16 22:01:55.868091: step 8930, loss = 0.69529 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
